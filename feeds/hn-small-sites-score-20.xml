<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 27 Jul 2020 08:19:20 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 27 Jul 2020 08:19:20 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Wayland and LVGL on PinePhone with Ubuntu Touch]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23947176">thread link</a>) | @lupyuen
<br/>
July 24, 2020 | https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland | <a href="https://web.archive.org/web/*/https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

        <!-- Begin scripts/rustdoc-before.html: Pre-HTML for Custom Markdown files processed by rustdoc, like chip8.md -->

    <!-- Begin Theme Picker -->
    
    
    
    <!-- Theme Picker -->

    <!-- End scripts/rustdoc-before.html -->
    

    
    <nav id="TOC"><ul>
<li><a href="#how-x11-works">1 How X11 works</a><ul></ul></li>
<li><a href="#wayland-on-ubuntu-touch">2 Wayland on Ubuntu Touch</a><ul></ul></li>
<li><a href="#render-opengl-graphics-with-wayland">3 Render OpenGL Graphics with Wayland</a><ul></ul></li>
<li><a href="#get-egl-context-from-wayland">4 Get EGL Context from Wayland</a><ul></ul></li>
<li><a href="#build-and-test-wayland-app-on-linux">5 Build and Test Wayland App on Linux</a><ul></ul></li>
<li><a href="#fetch-wayland-interfaces">6 Fetch Wayland Interfaces</a><ul></ul></li>
<li><a href="#render-opengl-bitmap-texture-with-wayland">7 Render OpenGL Bitmap Texture with Wayland</a><ul></ul></li>
<li><a href="#lvgl-toolkit-for-graphical-user-interfaces">8 LVGL Toolkit for Graphical User Interfaces</a><ul></ul></li>
<li><a href="#port-lvgl-to-wayland">9 Port LVGL to Wayland</a><ul></ul></li>
<li><a href="#build-lvgl-on-pinephone-with-ubuntu-touch">10 Build LVGL on PinePhone with Ubuntu Touch</a><ul></ul></li>
<li><a href="#inject-lvgl-into-file-manager-app">11 Inject LVGL into File Manager App</a><ul></ul></li>
<li><a href="#run-lvgl-on-pinephone-with-ubuntu-touch">12 Run LVGL on PinePhone with Ubuntu Touch</a><ul></ul></li>
<li><a href="#overcome-apparmor-security-on-ubuntu-touch">13 Overcome AppArmor Security on Ubuntu Touch</a><ul></ul></li>
<li><a href="#what-i-like-about-ubuntu-touch-on-pinephone">14 What I like about Ubuntu Touch on PinePhone</a><ul>
<li><a href="#ubports-on-ubuntu-touch-wayland-and-mir">14.1 UBports on Ubuntu Touch, Wayland and Mir</a><ul></ul></li>
<li><a href="#gnome-and-gtk-on-wayland">14.2 GNOME and GTK on Wayland</a><ul></ul></li>
<li><a href="#wayland-on-xfce">14.3 Wayland on Xfce</a><ul></ul></li></ul></li>
<li><a href="#whats-next">15 What's Next?</a><ul></ul></li>
<li><a href="#configure-ssh-on-pinephone">16 Configure SSH on PinePhone</a><ul>
<li><a href="#generate-ssh-keys">16.1 Generate SSH Keys</a><ul></ul></li>
<li><a href="#install-ssh-keys">16.2 Install SSH Keys</a><ul></ul></li>
<li><a href="#start-ssh-service">16.3 Start SSH Service</a><ul></ul></li></ul></li>
<li><a href="#copy-files-from-microsd-card-on-pinephone">17 Copy Files from MicroSD Card on PinePhone</a><ul></ul></li>
<li><a href="#build-and-test-lvgl-app-on-linux">18 Build and Test LVGL App on Linux</a><ul></ul></li></ul></nav><p><img src="https://lupyuen.github.io/images/wayland-title.jpg" alt="Work-in-progress LVGL GUI Framework ported to Wayland EGL on PinePhone with Ubuntu Touch"></p>
<p><em>Work-in-progress LVGL GUI Framework ported to Wayland EGL on PinePhone with Ubuntu Touch</em></p>
<p><strong>We ‚ù§Ô∏è &nbsp; Old Underwear...</strong></p>
<p>They feel comfy, they fit our contours. Nevermind the holes and the old stains ü§¢</p>
<p><strong>X11 is like Old Underwear.</strong> It's been around for 30 years... Yet we still use it in spite of its feature gaps and wonky quirks.</p>
<p><a href="https://wiki.pine64.org/PinePhone"><strong>PinePhone on Ubuntu Touch feels like... New Underwear.</strong></a></p>
<p>It runs Linux but it has none of the legacy X11 code. Because it's optimised for a great mobile experience with <strong>Wayland.</strong></p>
<p>But New Underwear feels uncomfortable. So today we'll learn Wayland and understand how apps are built with Wayland.</p>
<p>Hopefully someday we'll move on to newer, simpler app frameworks (like <a href="https://lvgl.io/">LVGL</a> and Flutter) as we discard our Old Underwear: X11, SDL, GTK, Qt, ...</p>
<p>The source code for this article may be found here...</p>
<ul>
<li>
<p><a href="https://github.com/lupyuen/lvgl-wayland"><code>github.com/lupyuen/lvgl-wayland</code></a></p>
</li>
<li>
<p><a href="https://github.com/lupyuen/pinephone-mir"><code>github.com/lupyuen/pinephone-mir</code></a></p>
</li>
</ul>

<p><a href="https://en.wikipedia.org/wiki/X_Window_System">X11</a> is the Graphical Display Service that runs on most Linux desktops and notebooks.</p>
<p>Let's hunt for the X11 Service on Pinebook Pro...</p>
<p><img src="https://lupyuen.github.io/images/wayland-pinebook.png" alt="X11 Service on Pinebook Pro"></p>
<p>That's the X11 Service... A <strong>2.2 MB</strong> executable named <strong><code>Xorg</code></strong>. </p>
<p>The X11 Service controls the rendering of Linux apps (as well as the keyboard and mouse input) like this...</p>
<p><img src="https://lupyuen.github.io/images/wayland-x11.png" alt="X11 Architecture"></p>
<p>(Adapted from <a href="https://wayland.freedesktop.org/architecture.html">"Wayland Architecture"</a>)</p>
<ol>
<li>
<p>At the top we have the Linux programs running on our Linux machine: <strong>Terminal, Editor, Web Browser</strong>.</p>
<p>Each program renders its graphical display and transmits the raw graphics to the X11 Service (via a local TCP socket).</p>
</li>
<li>
<p>X11 Service forwards the rendered graphics to the <a href="https://en.wikipedia.org/wiki/Compositing_window_manager"><strong>Window Manager / Compositor</strong></a>.</p>
<p>The Window Manager / Compositor is provided by the <strong>Desktop Environment</strong>: Xfce, KDE, Gnome, ...</p>
</li>
<li>
<p>The Window Manager / Compositor wraps the rendered graphics into Display Windows and <strong>"decorates"</strong> them with scrollbars, title bar and minimise / maximise / close buttons.</p>
<p>The Window Manager / Compositor then draws the Display Windows into a <strong>Screen Buffer</strong> according to their screen coordinates.</p>
</li>
<li>
<p>The Screen Buffer is rendered to our screen by the X11 Service, talking to the <strong>Linux Display Driver</strong>.</p>
</li>
<li>
<p>Any <strong>keyboard and mouse input</strong> is captured by the X11 Service, and forwarded to the programs.</p>
</li>
</ol>
<p><em>Why is X11 so complex? So many hops?</em></p>
<p>Because X11 was designed for Distributed Computing Systems.</p>
<p>Here's how I used (abused?) X11R4 at <a href="http://srg.cs.illinois.edu/">UIUC Systems Research Group</a> way back in 1990 (30 years ago!)...</p>
<p><img src="https://lupyuen.github.io/images/wayland-uiuc.png" alt="Distributed X11 System"></p>
<p>Thankfully things are a lot simpler now, lemme explain...</p>

<p><em>Do we need overlapping or tiled windows on PinePhone?</em></p>
<p><em>Do we need to need to decorate PinePhone windows with a title bar and minimise / maximise / close buttons?</em></p>
<p><em>Do we even need any windows on PinePhone?</em></p>
<p>No! Because each PinePhone app takes control of the entire screen!</p>
<p>PinePhone uses a simpler Graphical Display Service: the <a href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)#Wayland_compositors"><strong>Wayland Compositor</strong></a>.</p>
<p>Let's hunt for the Wayland Compositor on PinePhone...</p>
<p><img src="https://lupyuen.github.io/images/wayland-compositor.png" alt="Wayland Compositor on PinePhone"></p>
<p>That's the Wayland Compositor... A <strong>262 KB</strong> executable named <code>unity-system-compositor</code>. </p>
<p><em>Compare that with the 2.2 MB X11 Server on Pinebook Pro!</em></p>
<p>Here's how the Wayland Compositor controls apps and touchscreen input on PinePhone with Ubuntu Touch...</p>
<p><img src="https://lupyuen.github.io/images/wayland-arch.png" alt="Wayland Architecture"></p>
<p>(Adapted from <a href="https://wayland.freedesktop.org/architecture.html">"Wayland Architecture"</a> and <a href="https://en.wikipedia.org/wiki/EGL_(API)">"EGL API"</a>)</p>
<ol>
<li>
<p>At the top we have the apps running on our phone: <strong>Terminal, Editor, Web Browser</strong>.</p>
<p>Since each app runs fullscreen, only the active app will be rendered.</p>
<p>When then app starts, it queries the <strong>Wayland Compositor</strong> for the graphical display interfaces available. (They talk via a <a href="https://en.wikipedia.org/wiki/Unix_file_types#Socket">Linux socket file</a>: <code>/run/user/32011/wayland-0</code>)</p>
</li>
<li>
<p>Wayland Compositor returns the <a href="https://en.wikipedia.org/wiki/EGL_(API)"><strong>EGL Interface</strong></a> to the app.</p>
</li>
<li>
<p>App calls the EGL Interface to <a href="https://en.wikipedia.org/wiki/OpenGL"><strong>render OpenGL graphics</strong></a> directly to the <strong>Linux Display Driver</strong>.</p>
</li>
<li>
<p>Linux Display Driver forwards the OpenGL rendering commands to the <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit"><strong>GPU to update the screen</strong></a>.</p>
</li>
<li>
<p>Any <strong>touchscreen input</strong> is captured by the Wayland Compositor, and forwarded to the active app.</p>
</li>
</ol>
<p>Wayland looks so much simpler and faster than X11!</p>
<p><em>Wayland is designed for OpenGL and GPUs?</em></p>
<p>Yes! And I lied about Wayland being New Underwear... Wayland is not really that New!</p>
<p>Wayland was first released in 2008 (<a href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)">11 years ago</a>)... Yet it was designed around OpenGL and GPUs, the same tech that powers our beautiful games today. (<a href="https://youtu.be/DNBk9hnPkTY">And websites too</a>)</p>
<p>Read on to learn how to render our own OpenGL graphics with Wayland and Ubuntu Touch on PinePhone...</p>
<p><img src="https://lupyuen.github.io/images/wayland-egl.jpg" alt="Rendering a yellow rectangle with Wayland and OpenGL on PinePhone"></p>
<p><em>Rendering a yellow rectangle with Wayland and OpenGL on PinePhone</em></p>

<p>Here's the function that calls OpenGL to render the yellow box above: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L44-L60"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Render the OpenGL ES2 display
static void render_display() {
    //  Fill the rectangular region with yellow
    glClearColor(
        1.0,  //  Red
        1.0,  //  Green
        0.0,  //  Blue
        1.0   //  Alpha
    );
    glClear(GL_COLOR_BUFFER_BIT);

    // Render now
    glFlush();
}
</code></pre>
<p><code>render_display()</code> looks exactly like normal OpenGL, and it works on PinePhone with Wayland! (Thanks to Ubuntu Touch)</p>
<p>Two things to note...</p>
<ol>
<li>
<p>PinePhone supports a popular subset of OpenGL, known as <a href="https://en.wikipedia.org/wiki/OpenGL_ES"><strong>OpenGL for Embedded Systems</strong></a> Version 2.0.</p>
<p>OpenGL ES is optimised for Embedded Devices. It's used by many mobile and console games today.</p>
</li>
<li>
<p>To render OpenGL ES graphics, we need to get the <strong>OpenGL ES Context</strong> and <strong>Window Surface</strong> from Wayland</p>
</li>
</ol>
<p>Before calling <code>render_display()</code>, we fetch the OpenGL Window Surface from Wayland like so: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L167-L189"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Dimensions of the OpenGL region to be rendered
static int WIDTH  = 480;
static int HEIGHT = 360;

static struct wl_egl_window *egl_window;  //  Wayland EGL Window
static EGLSurface egl_surface;            //  EGL Surface

//  Create the EGL Window and render OpenGL graphics
static void create_window(void) {
    //  Create an EGL Window from a Wayland Surface 
    egl_window = wl_egl_window_create(surface, WIDTH, HEIGHT);
    assert(egl_window != EGL_NO_SURFACE);  //  Failed to create OpenGL Window

    //  Create an OpenGL Window Surface for rendering
    egl_surface = eglCreateWindowSurface(egl_display, egl_conf,
        egl_window, NULL);
    assert(egl_surface != NULL);  //  Failed to create OpenGL Window Surface

    //  Set the current rendering surface
    EGLBoolean madeCurrent = eglMakeCurrent(egl_display, egl_surface,
        egl_surface, egl_context);
    assert(madeCurrent);  //  Failed to set rendering surface

    //  Render the display
    render_display();

    //  Swap the display buffers to make the display visible
    EGLBoolean swappedBuffers = eglSwapBuffers(egl_display, egl_surface);
    assert(swappedBuffers);  //  Failed to swap display buffers
}
</code></pre>
<p>Functions named <code>wl_egl_...</code> are provided by the Wayland EGL Interface.  Functions named <code>egl...</code> come from the cross-platform <a href="https://docs.mesa3d.org/egl.html#:%7E:text=The%20main%20library%20(%20libEGL%20)%20is,directly%20dispatched%20to%20the%20drivers.">Mesa 3D Graphics Library</a>.</p>
<p><em>EGL vs OpenGL... What's the difference?</em></p>
<p>In Wayland, EGL is the Enabler for OpenGL. </p>
<p>Wayland only understands EGL and it will gladly hand us EGL objects... But it's up to us to transform EGL into OpenGL for rendering.</p>
<p>Thus in the code above, we take a Wayland Surface <code>surface</code> and transform it into an EGL Window <code>egl_window</code>...</p>
<pre><code>//  Create an EGL Window from a Wayland Surface 
egl_window = wl_egl_window_create(surface, WIDTH, HEIGHT);
</code></pre>
<p>Then we create an OpenGL Window Surface <code>egl_surface</code> from that EGL Window...</p>
<pre><code>//  Create an OpenGL Window Surface for rendering
egl_surface = eglCreateWindowSurface(egl_display, egl_conf,
    egl_window, NULL);
</code></pre>
<p>And we begin the OpenGL rendering...</p>
<pre><code>//  Set the current rendering surface
eglMakeCurrent(egl_display, egl_surface,
    egl_surface, egl_context);

//  Render the display
render_display();

//  Swap the display buffers to make the display visible
eglSwapBuffers(egl_display, egl_surface);
</code></pre>
<p>Here's how we create a Wayland Region for OpenGL rendering: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L103-L112"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>static struct wl_region *region;  //  Wayland Region

//  Create the Wayland Region for rendering OpenGL graphics
static void create_opaque_region(void) {
    //  Create a Wayland Region
    region = wl_compositor_create_region(compositor);
    assert(region != NULL);  //  Failed to create EGL Region

    //  Set the dimensions of the Wayland Region
    wl_region_add(region, 0, 0, WIDTH, HEIGHT);

    //  Add the Region to the Wayland Surface
    wl_surface_set_opaque_region(surface, region);
}
</code></pre>
<p>To learn more about EGL, check out <a href="https://jan.newmarch.name/Wayland/EGL/">"Programming Wayland Clients"</a></p>
<p>The Wayland EGL code in this article was adapted from that document.</p>

<p>Earlier in <code>create_window()</code> we called an <strong>EGL Context</strong> <code>egl_context</code> to render OpenGL graphics.</p>
<p>Here's how we get the EGL Context: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L113-L165"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Wayland EGL Interfaces for OpenGL Rendering
static EGLDisplay egl_display;  //  EGL Display
static EGLConfig  egl_conf;     //  EGL Configuration
static EGLContext egl_context;  //  EGL Context

//  Create the EGL Context for rendering OpenGL graphics
static void init_egl(void) {
    //  Attributes for our EGL Display
    EGLint config_attribs[] = {
        EGL_SURFACE_TYPE,    EGL_WINDOW_BIT,
        EGL_RED_SIZE,        8,
        EGL_GREEN_SIZE,      8,
        EGL_BLUE_SIZE,       8,
        EGL_RENDERABLE_TYPE, EGL_OPENGL_ES2_BIT,
        EGL_NONE
    };
    static const EGLint context_attribs[] = {
        EGL_CONTEXT_CLIENT_VERSION, 2,
        EGL_NONE
    };

    //  Get the EGL Display
    egl_display = eglGetDisplay((EGLNativeDisplayType) display);
    assert(egl_display != EGL_NO_DISPLAY);  //  Failed to get ‚Ä¶</code></pre></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland">https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland</a></em></p>]]>
            </description>
            <link>https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland</link>
            <guid isPermaLink="false">hacker-news-small-sites-23947176</guid>
            <pubDate>Sat, 25 Jul 2020 06:02:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloomfilters debunked: Dispelling 30 Years of math with Coq]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 60 (<a href="https://news.ycombinator.com/item?id=23946793">thread link</a>) | @gopiandcode
<br/>
July 24, 2020 | https://gopiandcode.uk/logs/log-bloomfilters-debunked.html | <a href="https://web.archive.org/web/*/https://gopiandcode.uk/logs/log-bloomfilters-debunked.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org5efdc67">
<p>
There's this rather nifty feature of modern web browsers (such as
<b>Firefox</b> or <b>Chrome</b>) where the browser will automatically warn the
user if they happen to navigate to a "<i>malicious</i>" URL:
</p>

<p><img src="https://gopiandcode.uk/images/malicious-site.png" alt="malicious-site.png">
</p> 


<p>
While <i>conceptually</i> simple, this feature actually requires more
engineering effort than one would expect - in particular, tracking the
set of known malicious URLs in a practical manner turns out to be
somewhat difficult.
</p>

<p>
This is because, on one hand, trying to store the database of <i>all</i>
known malicious URLs, which, bear in mind, may contain <i>millions and
millions</i> of entries, is something that is just practically
infeasible for most users. </p><p><img src="https://gopiandcode.uk/images/database_local.png" alt="database_local.png"> </p>


<p>
Conversely, sending <i>every</i> URL that a user visits to some external
service, where it could be <i>logged</i> and <i>data-mined</i> by nefarious
third parties, is something that most users should
probably not be comfortable with.
</p>

<p>
As it turns out, browsers actually implement this functionality by
means of a rather interesting <i>compromise</i><sup><a id="fnr.1" href="#fn.1">1</a></sup>.
</p>

<p>
Using a probabilistic data structure known as a <b>Bloom filter</b>,
Browsers maintain a approximate representation of the set of known
malicious URLs locally.  By querying this <i>space-efficient</i> local set,
browsers will only send up a <i>small proportion</i> of the honest URLs.
</p>

<p><b><i>Use a Bloom filter to act as a local proxy for queries to an external database</i>.</b>
</p>


<p>
This proxy technique, which safe-guards the privacy of millions of
users ever day, depends on <b>two key properties</b> of Bloom filters:
</p>

<dl>
<dt>No false negatives</dt><dd>This states that if a query for an URL in the
Bloom filter returns negative, then the queried item can be
guaranteed to not be present in the set of malicious URLs - i.e
<i>the Bloom filter is guaranteed to return a positive result for
all known malicious URLs</i>.</dd>

<dt>Low false positive rate</dt><dd>This property states that for any URL
that is <i>not in the set of malicious</i> URLs, the likelihood of a
Bloom filter query returning a positive result should be <i>fairly
low</i> - thus minimising the number of <i>unnecessary</i> infractions on
user privacy.</dd>
</dl>


<p>
This mechanism works <i>quite</i> well, and the guarantees of a Bloom filter
seem to be perfectly suited for this particular task, however it has
one small problem, and that is:
</p>

<p><b><i>The</i> widely cited expression <i>for the</i> false positive rate <i>of a bloom filter is</i> wrong!</b>
</p>


<p>
In fact, as it turns out, the behaviours of a Bloom filter have
actually been the subject of 30 years of mathematical contention,
requiring <i>multiple</i> corrections and even <i>corrections of these
corrections</i>.
</p>

<p>
<b>Given this history of errors, can we really have any certainty in our
understanding of a Bloom filter at all?</b>
</p>

<p>
Well, <i>never fear</i>, I am writing this post to inform you that we have
just recently used <code>Coq</code> to produce the <i>very first</i> <b>certified</b> proof
of the false positive rate of a Bloom filter, finally putting an end to
this saga of errors and returning certainty (pardon the pun<sup><a id="fnr.2" href="#fn.2">2</a></sup>) to a
mechanism that countless people rely on <i>every single</i> day.
</p>

<p>
In the rest of this post, we'll explore the main highlights of this
research, answering the following questions:
</p>
<ul>
<li>What is a Bloom filter?</li>
<li>Why did these errors initially arise?</li>
<li>What is the true behaviour of a Bloom filter? and how can we be certain?</li>
</ul>


<p>
This research was just recently presented at CAV2020 under the title
"Certifying Certainty and Uncertainty in Approximate Membership Query
Structures", you can find the paper <a href="https://www.springerprofessional.de/en/certifying-certainty-and-uncertainty-in-approximate-membership-q/18186934">here</a>, and a video presentation of
it <a href="https://invidio.us/D80VCsVeCMs?t=4482">here</a>.
</p>

<p>
The code and proofs used in this research project are FOSS, and can be
found on the Ceramist repo: <a href="https://github.com/certichain/ceramist">https://github.com/certichain/ceramist</a>
</p>
</div></div>]]>
            </description>
            <link>https://gopiandcode.uk/logs/log-bloomfilters-debunked.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23946793</guid>
            <pubDate>Sat, 25 Jul 2020 04:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The futility of ‚ÄúI told you so‚Äù in software engineering teams]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23944816">thread link</a>) | @shs7777
<br/>
July 24, 2020 | https://humza.sh/2020/07/24/the-futility-of-i-told-you-so.html | <a href="https://web.archive.org/web/*/https://humza.sh/2020/07/24/the-futility-of-i-told-you-so.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <header>  <img src="https://user-images.githubusercontent.com/4441006/55256114-2c91e480-5254-11e9-9f51-dc1b42fc0980.jpg" alt="Logo"> <p>Engineering leader. Likes coffee. Loves to travel. Runs on a combination of optimism and pragmatism.</p> <p> Read more about him <a href="https://humza.sh/cv">here</a>. </p> </header> <section>  <p>Ever had the urge to use one of these during a post-mortem meeting?</p> <blockquote> <p>‚ÄúI told you so!‚Äù</p> </blockquote> <blockquote> <p>‚ÄúI told them that this would happen!‚Äù</p> </blockquote> <blockquote> <p>‚ÄúShould‚Äôve listened to me - this design was never going to scale!‚Äù</p> </blockquote> <p>If yes, then <strong>fight</strong> that urge!</p> <p>Your audience will not marvel at your foresight. You will not be hailed as a tech god. And, most importantly, you will not be contributing to any solutions.</p> <p>Your <em>‚ÄúI told you so‚Äù</em> only highlights that you need to construct stronger arguments.</p> <p>In today‚Äôs increasingly data-driven teams, managers and leaders rely on team members to construct clear, concise, factual, and data-driven arguments.</p> <p>If your past warnings were ignored and you do not feel that there are any politics / biases / prejudices in active play, it is time to introspect, reflect, and ask:</p> <p><em>‚ÄúHow will I make my case differently next time?‚Äù</em></p> </section>  </div></div>]]>
            </description>
            <link>https://humza.sh/2020/07/24/the-futility-of-i-told-you-so.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23944816</guid>
            <pubDate>Fri, 24 Jul 2020 21:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kalman filter works, in pictures]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23943836">thread link</a>) | @gballan
<br/>
July 24, 2020 | https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/ | <a href="https://web.archive.org/web/*/https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I have to tell you about the Kalman filter, because what it does is pretty damn amazing.</p>
<p>Surprisingly few software engineers and scientists seem to know about it, and that makes me sad because it is such a general and powerful tool for <strong>combining information</strong> in the presence of uncertainty. At times its ability to extract accurate information seems almost magical‚Äî and if it sounds like I‚Äôm talking this up too much, then take a look at <a href="https://www.bzarg.com/p/improving-imu-attitude-estimates-with-velocity-data">this previously posted video</a> where I demonstrate a Kalman filter figuring out the <em>orientation</em> of a free-floating body by looking at its <em>velocity</em>. Totally neat!</p>

<p>You can use a Kalman filter in any place where you have <strong>uncertain information</strong> about some dynamic system, and you can make an <strong>educated guess</strong> about what the system is going to do next. Even if messy reality comes along and interferes with the clean motion you guessed about, the Kalman filter will often do a very good job of figuring out what actually happened. And it can take advantage of correlations between crazy phenomena that you maybe wouldn‚Äôt have thought to exploit!</p>
<p>Kalman filters are ideal for systems which are <strong>continuously changing</strong>. They have the <span id="more-491"></span>advantage that they are light on memory (they don‚Äôt need to keep any history other than the previous state), and they are very fast, making them well suited for real time problems and embedded systems.</p>
<p>The math for implementing the Kalman filter appears pretty scary and opaque in most places you find on Google. That‚Äôs a bad state of affairs, because the Kalman filter is actually super simple and easy to understand if you look at it in the right way. Thus it makes a great article topic, and I will attempt to illuminate it with lots of clear, pretty pictures and colors. The prerequisites are simple; all you need is a basic understanding of probability and matrices.</p>
<p>I‚Äôll start with a loose example of the kind of thing a Kalman filter can solve, but if you want to get right to the shiny pictures and math, feel free to <a href="#mathybits">jump ahead</a>.</p>

<p>Let‚Äôs make a toy example: You‚Äôve built a little robot that can wander around in the woods, and the robot needs to know exactly where it is so that it can navigate.</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/robot_forest-300x160.png" alt="Your little robot" width="300" height="160" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/robot_forest-300x160.png 300w, https://www.bzarg.com/wp-content/uploads/2015/08/robot_forest.png 553w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>We‚Äôll say our robot has a state \( \vec{x_k} \), which is just a position and a velocity:</p>
<p>\(\vec{x_k} = (\vec{p}, \vec{v})\)</p>
<p>Note that the state is just a list of numbers about the underlying configuration of your system; it could be anything. In our example it‚Äôs position and velocity, but it could be data about the amount of fluid in a tank, the temperature of a car engine, the position of a user‚Äôs finger on a touchpad, or any number of things you need to keep track of.</p>
<p>Our robot also has a GPS sensor, which is accurate to about 10 meters, which is good, but it needs to know its location more precisely than 10 meters. There are lots of gullies and cliffs in these woods, and if the robot is wrong by more than a few feet, it could fall off a cliff. So GPS by itself is not good enough.</p>
<p><a href="https://www.bzarg.com/wp-content/uploads/2015/08/robot_ohnoes.png"><img src="https://www.bzarg.com/wp-content/uploads/2015/08/robot_ohnoes-300x283.png" alt="Oh no." width="300" height="283" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/robot_ohnoes-300x283.png 300w, https://www.bzarg.com/wp-content/uploads/2015/08/robot_ohnoes.png 403w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>We might also know something about how the robot moves: It knows the commands sent to the wheel motors, and its knows that if it‚Äôs headed in one direction and nothing interferes, at the next instant it will likely be further along that same direction. But of course it doesn‚Äôt know everything about its motion: It might be buffeted by the wind, the wheels might slip a little bit, or roll over bumpy terrain; so the amount the wheels have turned might not exactly represent how far the robot has actually traveled, and the prediction won‚Äôt be perfect.</p>
<p>The GPS <strong>sensor</strong> tells us something about the state, but only indirectly, and with some uncertainty or inaccuracy. Our <strong>prediction</strong> tells us something about how the robot is moving, but only indirectly, and with some uncertainty or inaccuracy.</p>
<p>But if we use all the information available to us, can we get a better answer than <strong>either estimate would give us by itself</strong>? Of course the answer is yes, and that‚Äôs what a Kalman filter is for.</p>


<p>Let‚Äôs look at the landscape we‚Äôre trying to interpret. We‚Äôll continue with a simple state having only position and velocity. $$<br>
\vec{x} = \begin{bmatrix}<br>
p\\<br>
v<br>
\end{bmatrix}$$</p>
<p>We don‚Äôt know what the <em>actual</em> position and velocity are; there are a whole range of possible combinations of position and velocity that might be true, but some of them are more likely than others:</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_0.png" alt="gauss_0" width="310" height="325" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_0.png 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_0-287x300.png 287w" sizes="(max-width: 310px) 100vw, 310px"></p>
<p>The Kalman filter assumes that both variables (postion and velocity, in our case) are random and <em>Gaussian distributed.</em> Each variable has a <strong>mean</strong> value \(\mu\), which is the center of the random distribution (and its most likely state), and a <strong>variance</strong> \(\sigma^2\), which is the uncertainty:</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_1.png" alt="gauss_1" width="310" height="276" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_1.png 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_1-300x267.png 300w" sizes="(max-width: 310px) 100vw, 310px"></p>
<p>In the above picture, position and velocity are <strong>uncorrelated</strong>, which means that the state of one variable tells you nothing about what the other might be.</p>
<p>The example below shows something more interesting: Position and velocity are <strong>correlated</strong>. The likelihood of observing a particular position depends on what velocity you have:</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_3.png" alt="gauss_3" width="310" height="286" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_3.png 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_3-300x276.png 300w" sizes="(max-width: 310px) 100vw, 310px">This kind of situation might arise if, for example, we are estimating a new position based on an old one. If our velocity was high, we probably moved farther, so our position will be more distant. If we‚Äôre moving slowly, we didn‚Äôt get as far.</p>
<p>This kind of relationship is really important to keep track of, because it gives us <strong>more information: </strong>One measurement tells us something about what the others could be. And that‚Äôs the goal of the Kalman filter, we want to squeeze as much information from our uncertain measurements as we possibly can!</p>
<p>This correlation is captured by something called a <a href="https://en.wikipedia.org/wiki/Covariance_matrix">covariance matrix</a>. In short, each element of the matrix \(\Sigma_{ij}\) is the degree of correlation between the <em>ith</em> state variable and the <em>jth</em> state variable. (You might be able to guess that the covariance matrix is <a href="https://en.wikipedia.org/wiki/Symmetric_matrix">symmetric</a>, which means that it doesn‚Äôt matter if you swap <em>i</em> and <em>j</em>). Covariance matrices are often labelled ‚Äú\(\mathbf{\Sigma}\)‚Äù, so we call their elements ‚Äú\(\Sigma_{ij}\)‚Äù.</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_2.png" alt="gauss_2" width="310" height="286" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_2.png 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_2-300x276.png 300w" sizes="(max-width: 310px) 100vw, 310px"></p>

<p>We‚Äôre modeling our knowledge about the state as a Gaussian blob, so we need two pieces of information at time \(k\): We‚Äôll call our best estimate \(\mathbf{\hat{x}_k}\) (the mean, elsewhere named \(\mu\) ), and its covariance matrix \(\mathbf{P_k}\). $$<br>
\begin{equation} \label{eq:statevars}<br>
\begin{aligned}<br>
\mathbf{\hat{x}}_k &amp;= \begin{bmatrix}<br>
\text{position}\\<br>
\text{velocity}<br>
\end{bmatrix}\\<br>
\mathbf{P}_k &amp;=<br>
\begin{bmatrix}<br>
\Sigma_{pp} &amp; \Sigma_{pv} \\<br>
\Sigma_{vp} &amp; \Sigma_{vv} \\<br>
\end{bmatrix}<br>
\end{aligned}<br>
\end{equation}<br>
$$</p>
<p>(Of course we are using only position and velocity here, but it‚Äôs useful to remember that the state can contain any number of variables, and represent anything you want).</p>
<p>Next, we need some way to look at the <span><strong>current state</strong></span> (at time <span><strong>k-1</strong></span>) and <strong>predict the <span>next state</span></strong> at time <span><strong>k</strong></span>. Remember, we don‚Äôt know which state is the ‚Äúreal‚Äù one, but our prediction function doesn‚Äôt care. It just works on <em>all of them</em>, and gives us a new distribution:</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_7.jpg" alt="gauss_7" width="310" height="286" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_7.jpg 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_7-300x276.jpg 300w" sizes="(max-width: 310px) 100vw, 310px">We can represent this prediction step with a matrix, \(\mathbf{F_k}\):</p>
<p><img src="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_8.jpg" alt="gauss_8" width="310" height="286" srcset="https://www.bzarg.com/wp-content/uploads/2015/08/gauss_8.jpg 621w, https://www.bzarg.com/wp-content/uploads/2015/08/gauss_8-300x276.jpg 300w" sizes="(max-width: 310px) 100vw, 310px">It takes <em>every point</em> in our original estimate and moves it to a new predicted location, which is where the system would move if that original estimate was the right one.</p>
<p>Let‚Äôs apply this. How would we use a matrix to predict the position and velocity at the next moment in the future? We‚Äôll use a really basic kinematic formula:$$<br>
\begin{split}<br>
\color{deeppink}{p_k} &amp;= \color{royalblue}{p_{k-1}} + \Delta t &amp;\color{royalblue}{v_{k-1}} \\<br>
\color{deeppink}{v_k} &amp;= &amp;\color{royalblue}{v_{k-1}}<br>
\end{split}<br>
$$ In other words: $$<br>
\begin{align}<br>
\color{deeppink}{\mathbf{\hat{x}}_k} &amp;= \begin{bmatrix}<br>
1 &amp; \Delta t \\<br>
0 &amp; 1<br>
\end{bmatrix} \color{royalblue}{\mathbf{\hat{x}}_{k-1}} \\<br>
&amp;= \mathbf{F}_k \color{royalblue}{\mathbf{\hat{x}}_{k-1}} \label{statevars}<br>
\end{align}<br>
$$</p>
<p>We now have a <strong>prediction matrix</strong> which gives us our next state, but we still don‚Äôt know how to update the covariance matrix.</p>
<p>This is where we need another formula. If we multiply every point in a distribution by a matrix \(\color{firebrick}{\mathbf{A}}\), then what happens to its covariance matrix \(\Sigma\)?</p>
<p>Well, it‚Äôs easy. I‚Äôll just give you the identity:$$<br>
\begin{equation}<br>
\begin{split}<br>
Cov(x) &amp;= \Sigma\\<br>
Cov(\color{firebrick}{\mathbf{A}}x) &amp;= \color{firebrick}{\mathbf{A}} \Sigma \color{firebrick}{\mathbf{A}}^T<br>
\end{split} \label{covident}<br>
\end{equation}<br>
$$</p>
<p>So combining \(\eqref{covident}\) with equation \(\eqref{statevars}\):$$<br>
\begin{equation}<br>
\begin{split}<br>
\color{deeppink}{\mathbf{\hat{x}}_k} &amp;= \mathbf{F}_k \color{royalblue}{\mathbf{\hat{x}}_{k-1}} \\<br>
\color{deeppink}{\mathbf{P}_k} &amp;= \mathbf{F_k} \color{royalblue}{\mathbf{P}_{k-1}} \mathbf{F}_k^T<br>
\end{split}<br>
\end{equation}<br>
$$</p>
<h2>External influence</h2>
<p>We haven‚Äôt captured everything, though. There might be some changes that <strong>aren‚Äôt related to the state</strong> itself‚Äî the outside world could be affecting the system.</p>
<p>For example, if the state models the motion of a train, the train operator might push on the throttle, causing the train to accelerate. Similarly, in our robot example, the navigation software might issue a command to turn the wheels or stop. If we know this additional information about what‚Äôs going on in the world, we could stuff it into a vector called \(\color{darkorange}{\vec{\mathbf{u}_k}}\), do something with it, and add it to our prediction as a correction.</p>
<p>Let‚Äôs say we know the expected acceleration \(\color{darkorange}{a}\) due to the throttle setting or control commands. From basic kinematics we get: $$<br>
\begin{split}<br>
\color{deeppink}{p_k} &amp;= \color{royalblue}{p_{k-1}} + {\Delta t} &amp;\color{royalblue}{v_{k-1}} + &amp;\frac{1}{2} \color{darkorange}{a} {\Delta t}^2 \\<br>
\color{deeppink}{v_k} &amp;= &amp;\color{royalblue}{v_{k-1}} + &amp; \color{darkorange}{a} {\Delta t}<br>
\end{split}<br>
$$ In matrix form: $$<br>
\begin{equation}<br>
\begin{split}<br>
\color{deeppink}{\mathbf{\hat{x}}_k} &amp;= \mathbf{F}_k \color{royalblue}{\mathbf{\hat{x}}_{k-1}} + \begin{bmatrix}<br>
\frac{\Delta t^2}{2} \\<br>
\Delta t<br>
\end{bmatrix} \color{darkorange}{a} \\<br>
&amp;= \mathbf{F}_k ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/">https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</a></em></p>]]>
            </description>
            <link>https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23943836</guid>
            <pubDate>Fri, 24 Jul 2020 20:02:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paul Graham Essay Notes]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23940167">thread link</a>) | @acangiano
<br/>
July 24, 2020 | https://www.notion.so/Paul-Graham-Essay-Notes-c7e4b66321434ecfac25d475607f4f83 | <a href="https://web.archive.org/web/*/https://www.notion.so/Paul-Graham-Essay-Notes-c7e4b66321434ecfac25d475607f4f83">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Paul-Graham-Essay-Notes-c7e4b66321434ecfac25d475607f4f83</link>
            <guid isPermaLink="false">hacker-news-small-sites-23940167</guid>
            <pubDate>Fri, 24 Jul 2020 14:50:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To Get More Replies, Say Less (2017)]]>
            </title>
            <description>
<![CDATA[
Score 367 | Comments 114 (<a href="https://news.ycombinator.com/item?id=23939462">thread link</a>) | @gk1
<br/>
July 24, 2020 | https://www.gkogan.co/blog/increase-reply-rates/ | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/increase-reply-rates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a story of how a software company was able to start a conversation with 8x more of their users by cutting&nbsp;the length of their emails by 90%. You could set up a test of this method in less than an hour.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/c377678ef05df48ca100bc7c0c7b4ee18ae4292d/5f0ab/images/uploads/0356.jpg" alt="Cartoon About Saying Less"></p>

<h2>The Problem</h2>

<p><strong>One of the most valuable things you could do for your software business is talk to your users.</strong> You can help them get more value from your software, learn how they use your product, hear their feedback, and demonstrate the quality and commitment of your support.</p>

<p>However, if you‚Äôve ever tried to talk to your users by email, you probably ran into a problem:&nbsp;<strong>Many users&nbsp;don‚Äôt respond.</strong></p>

<p>Even if you follow all the best practices around emails, genuinely want to help them, and spend a long time writing a personalized email, people&nbsp;still don‚Äôt respond. That can be very frustrating.</p>

<p>Netlify‚Äî<a href="https://www.netlify.com/">a platform for static sites</a>‚Äîwas feeling this frustration, so they brought me in to help.</p>

<p>Knowing that signups don‚Äôt matter if new users aren‚Äôt starting to use and get value from the software, Netlify was emailing every new user with an offer to help or answer any questions.</p>

<p>By most measures, the email was good: It was personalized, sent within&nbsp;a day, sent by a real person (their head of customer success), and had&nbsp;<a href="https://www.gkogan.co/blog/dont-design-emails/">no flashy design</a>.</p>

<p><strong>Unfortunately it had a reply rate of just 1%.</strong> They were missing a huge opportunity by&nbsp;failing to reach 99 of every 100 users.</p>

<h2>The Solution: Saying Less</h2>
<p>When I saw the length of the original email, I suspected users are:</p>

<ul>
 	<li>Not&nbsp;bothering to read it because of its length.</li>
 	<li>Assuming it's a template email because of its length, and therefore don't believe the offer to help is sincere.</li>
</ul>

<p>The first thing I&nbsp;did was delete most of the email text&nbsp;and run an A/B test against the original‚Ä¶</p>

<h3>First A/B Test:&nbsp;Original vs Short Email</h3>
<p><img src="https://d33wubrfki0l68.cloudfront.net/7fe4ca1e7b73c29c841ee396bc6a727fcf546bbd/4f5e5/images/uploads/onboarding-email-1.jpg" alt="Long Onboarding Email"></p>

<p>This original email had 150+ words and a reply rate of 1% (1 of every 100 users).</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/a0b1c850a8b4f90c586af96347a02cce4516fe5d/2c0d2/images/uploads/onboarding-email-2.jpg" alt="Short Onboarding Email"></p>

<p>This variation&nbsp;had 37 words&nbsp;and resulted in a reply&nbsp;rate&nbsp;of 4% (1 of every 25 users).</p>

<p><strong>Cutting the original email text by 75% increased the reply rate by 300%.</strong></p>

<p>That‚Äôs a terrific&nbsp;result for a few minutes of work. I&nbsp;could have stopped there, but wondered how far I&nbsp;could take this before seeing diminishing returns.</p>

<p>On to the second test‚Ä¶</p>

<h3>Second A/B Test: Short vs Very Short</h3>

<p>I&nbsp;took the winning email from the first test and cut another 50% of the text, taking out as much as possible while retaining the email‚Äôs meaning, then tested it against the previous winner.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/277ca277bbecd4e9282c4bd579557b6029cae3f1/513f3/images/uploads/onboarding-email-3.jpg" alt="Very Short Onboarding Email"></p>

<p>This version has just 14 words. It resulted in a reply rate of 8% (1 of every 12 users).</p>

<p><strong>Cutting the email text by another 50% <em>doubled</em> the&nbsp;reply rates from the previous version.</strong> Compared to the original, the length was cut by 90% and reply rates increased by 700%.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/164e960178dbe5fd0019901e2da78a68bcb38406/55ff3/images/uploads/reply-rates.png" alt="Email Reply Rates"></p>

<p><strong>Imagine you could onboard 8x more people to your software&nbsp;and hear 8x more feedback from new users.</strong> That‚Äôs the power of saying less.</p>

<h2>Try It Yourself</h2>

<p>Take your welcome&nbsp;or onboarding&nbsp;email‚Äî<a href="https://www.gkogan.co/blog/question-for-saas-trial-users/">start here</a> if you don‚Äôt have one‚Äîand cut out any text that isn‚Äôt&nbsp;necessary. When you feel you‚Äôre done, take out another 50%. Finally,&nbsp;run an A/B test and measure positive replies to this shorter email versus your original.</p>

<p>Tell me&nbsp;how it goes for you! You may also be interested to read why <a href="https://www.gkogan.co/blog/dont-design-emails/">plain emails work better</a>, why <a href="https://www.gkogan.co/blog/simple-systems/">simple systems have less downtime</a>, and <a href="https://www.gkogan.co/case-studies/netlify/">more about my work with Netlify</a>.</p>


    <p>‚óº</p>

    <p>PS - Liked this article? I write one every month or so, covering lessons learned on B2B startup growth. Don't miss the next one:</p>

    <!-- Begin MailChimp Signup Form -->
    

    <!--End mc_embed_signup-->
    
    <p>If you need help with marketing and revenue growth, <a href="https://www.gkogan.co/contact/">get in touch</a>.</p>

  </div>

  

  
  
  



</article>

<!-- Begin MailChimp popup signup form -->



<!-- End MailChimp popup signup form -->
      </div>
    </div></div>]]>
            </description>
            <link>https://www.gkogan.co/blog/increase-reply-rates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23939462</guid>
            <pubDate>Fri, 24 Jul 2020 13:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a simple geolocation service]]>
            </title>
            <description>
<![CDATA[
Score 333 | Comments 168 (<a href="https://news.ycombinator.com/item?id=23936647">thread link</a>) | @maxko
<br/>
July 24, 2020 | https://maxkostinevich.com/blog/serverless-geolocation/ | <a href="https://web.archive.org/web/*/https://maxkostinevich.com/blog/serverless-geolocation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>If you ever tried to make a Geo-location service (e.g. define a user country based on user IP address), most likely you heard about <a href="https://www.maxmind.com/">MaxMind</a>. </p>
<p>MaxMind - is probably one of best companies who provides Geo IP databases and services. </p>
<p>However, there is a number of limitations: if you're making a side-project, most likely you do not want to pay extra $$$ for geolocation services. And for this case MaxMind offers GeoLite2 database, however you'll be in charge of hosting this database on your server and making regular updates of the database. You also need to make sure your project is compliant with MaxMind's License.</p>
<h2>Why to use Cloudflare Workers instead of AWS Lambda?</h2>
<p>In this particular example, I needed a simple geo-location service which will be used in embeddable javascript code (similar to Google Analytics or other tracking service), so the response time is quite crucial.</p>
<p>In my first attempt I tried to use Serverless framework to host simple geo-location function on AWS Lambda (this function uses MaxMind GeoLite2 database). However, I quickly realized that the response time isn't what I've expected - on average the response took somewhere between from 200ms to 500ms. So I started looking for other options.  </p>
<p>So, I thought - if I could not host it on AWS Lambda, where else I could host my serverless function? The next service I tried - is <a href="https://workers.cloudflare.com/">Cloudflare Workers</a>. I created a simple function to test the reponse time, and it was really impressive - on average it was between from 30ms to 80ms, I've got almost x10 better performance in comparison to AWS. </p>
<p>However, this solution had one really big caveat - MaxMind GeoLite2 database does not work on Cloudflare Workers due to some runtime limitations.</p>
<h2>MaxMind alternative</h2>
<p>And then I thought - hey, wait a second, as Cloudflare provides DDoS protection services, they might provide some interesting features in Cloudflare Workers. And after exploring their documentation, I realized that the <code>Request</code> object in function have an access to <code>cf</code> object, which contains some useful information about the visitor, including visitor's country!</p>
<p>That's exactly what I was looking for, within a few dozens of lines of code I got my geolocation function up and running.</p>
<h2>The source code</h2>
<p>If you haven't worked with Cloudflare before, you need to signup at <a href="https://www.cloudflare.com/">Cloudflare.com</a> and go to Workers directory.</p>
<p>Then, create a new worker with the following source code:</p>

<p>Then you can start making requests to your Worker's endpoint.</p>    </div></div>]]>
            </description>
            <link>https://maxkostinevich.com/blog/serverless-geolocation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23936647</guid>
            <pubDate>Fri, 24 Jul 2020 07:17:41 GMT</pubDate>
        </item>
    </channel>
</rss>
