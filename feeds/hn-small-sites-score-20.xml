<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 30 Oct 2020 08:19:16 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 30 Oct 2020 08:19:16 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Grand Unified Theory of Software Architecture]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24915497">thread link</a>) | @nreece
<br/>
October 27, 2020 | https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html | <a href="https://web.archive.org/web/*/https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                <p>Take <strong>Uncle Bob's</strong> Clean Architecture and map its correspondences with <strong>Gary Bernhardt's</strong> thin imperative shell around a functional core, and you get an understanding of how to cheaply maintain and scale software!</p>
<p>This is what <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a> did. It's not every day that I find such clear insight.</p>
<p>I am honored to have found his <a href="https://rhodesmill.org/brandon/talks/#clean-architecture-python">presentation</a> and <a href="https://rhodesmill.org/brandon/slides/2014-07-pyohio/clean-architecture/">slides</a> explaining  <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture</a> and Gary Bernhardt's PyCon talks of <a href="https://archive.org/details/pyvideo_422___units-need-testing-too">2011</a>, <a href="https://pycon-2012-notes.readthedocs.io/en/latest/fast_tests_slow_tests.html">2012</a>, and <a href="https://www.destroyallsoftware.com/talks/boundaries">2013</a>.</p>
<p>Mr. Rhodes offers such a distilled view, that he can show you these crucial concepts in 3 slides of code. I will go ahead and summarize what he said and add a tiny bit of my insight.</p>
<p>Copyright of all Python code on this page belongs to <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a>, and copyright of the diagram belongs to <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Robert C. Martin (Uncle Bob)</a>. I use these under (hopefully) fair use (nonprofit and educational).</p>


<p>First of all, we need to be on the same page, in order to be able to understand each other. Here are the words I'll use:</p>
<ul>
<li>Function: I use "function" or "pure function" to refer to a Python "function" that only uses its parameters for input, returns a result as output, and does not cause any other side-effects (such as I/O). <ul>
<li>A pure function returns the same output given the same inputs.</li>
<li>A pure function may be called any number of times without changing the system state - it should have no influence on DB, UI, other functions or classes.</li>
<li>This is very similar to a mathematical function: takes you from <em>x</em> to <em>y</em> and nothing else happens.</li>
<li>Sadly we can't have only pure functions; software has a <strong>purpose</strong> of causing side-effects.</li>
</ul>
</li>
<li>Procedure, Routine, or Subroutine: A piece of code that executes, that may or may not have side effects. This is a "function" in Python, but might not be a "pure function".</li>
<li>Tests: automated unit tests. By "unit" I mean not necessarily just a class, but a behavior. If you want, see more details in <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a>.</li>
</ul>

<div><pre><span></span><code><span>import</span> <span>requests</span>                      <span># Listing 1</span>
<span>from</span> <span>urllib</span> <span>import</span> <span>urlencode</span>

<span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, we have a piece of code that prepares a URL, then gets some data over the network (I/O), then validates the result (a word definition) and returns it.</p>
<p>This is a bit much: a procedure should ideally do one thing only. While this small-ish procedure is quite readable still, it is a metaphor for a more developed system - where it could be arbitrarily long.</p>
<p>The current knee-jerk reaction is to <em>hide</em> the I/O operations somewhere far away. Here is the same code after extracting the I/O lines:</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 2</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>data</span> <span>=</span> <span>call_json_api</span><span>(</span><span>url</span><span>)</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>

<span>def</span> <span>call_json_api</span><span>(</span><span>url</span><span>):</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>return</span> <span>data</span>
</code></pre></div>
<p>In Listing #2, the I/O is extracted from the top-level procedure. </p>
<p>The problem is, the code is still <strong>coupled</strong> - <code>call_json_api</code> is called whenever you want to test anything - even the building of the URL or the parsing of the result.</p>
<p><strong>Coupling kills software.</strong></p>
<p>A good rule of thumb to spot coupling is this: Can you test a piece of code without having to mock or dependency inject like Frankenstein?</p>
<p>Here, we can't test <code>find_definition</code> without somehow replacing <code>call_json_api</code> from inside it, in order to avoid making HTTP requests.</p>
<p>Let's find out what a better solution looks like.</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 3</span>
    <span>url</span> <span>=</span> <span>build_url</span><span>(</span><span>word</span><span>)</span>
    <span>data</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span><span>.</span><span>json</span><span>()</span>  <span># I/O</span>
    <span>return</span> <span>pluck_definition</span><span>(</span><span>data</span><span>)</span>

<span>def</span> <span>build_url</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>return</span> <span>url</span>

<span>def</span> <span>pluck_definition</span><span>(</span><span>data</span><span>):</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, the procedure at the top (aka. the <span><strong>imperative shell</strong></span> of the program) is handling the I/O, and everything else is moved to <span><strong>pure functions</strong></span> (<code>build_url</code>, <code>pluck_definition</code>). The <span><strong>pure functions</strong></span> are easily testable by just calling them on made-up data structures; no Frankenstein needed.</p>
<p>This separation into an <span><strong>imperative shell</strong></span> and <span><strong>functional core</strong></span> is an encouraged idea by Functional Programming.</p>
<p>Ideally, though, in a real system, you wouldn't test elements as small as these routines, but integrate more of the system. See <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a> to understand the trade-offs.</p>

<p>Look at <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture chart</a> (Copyright Robert C. Martin aka. Uncle Bob) :
<img alt="The Clean Architecture" src="https://danuker.go.ro/images/CleanArchitecture.jpg"></p>
<p>Uncle Bob's <span><strong>Use Cases</strong></span> and <span><strong>Entities</strong></span> (red and yellow circles of the chart) map to the <span><strong>pure functions</strong></span> we saw earlier - <code>build_url</code> and <code>pluck_definition</code> from Listing 3, and the <span><strong>plain objects</strong></span> they receive as parameters and send as outputs. <em>(updated 2020-10-28)</em></p>
<p>Uncle Bob's <span><strong>Interface Adapters</strong></span> (green circle) map to the top-level <span><strong>imperative shell</strong></span>  from earlier - <code>find_definition</code> from Listing 3, handling only I/O to the outside (Web, DB, UI, other frameworks).</p>
<p><a href="https://www.reddit.com/r/programming/comments/jj7ave/the_grand_unified_theory_of_software_architecture/gabst6z/?context=3">Update 2020-10-28</a>: A "Model" object in today's MVC frameworks is a poisoned apple: it is not a <a href="https://khanlou.com/2014/12/pure-objects/">"pure" object</a> or <a href="http://xunitpatterns.com/Humble%20Object.html">"humble" object</a>, but one that can produce side effects like saving or loading from the database. Their "save" and "read" methods litter your code with untestable side-effects all over. Avoid them, or confine them to the periphery of your system and reduce their influence accordingly (they are actually a hidden <span><strong>Interface Adapter</strong></span>) due to interacting with the DB.</p>
<p>Notice the arrows on the left side of the circles, pointing inwards to more and more abstract parts. These are procedure or function calls. Our code is called by the outside. <strong>This has some exceptions. Whatever you do, the database won't call your app. But the web can, a user can through a UI, the OS can through STDIN, and a timer can, at regular intervals (such as in a game).</strong> <em>(updated 2020-10-28)</em></p>
<p>The top-level procedure:</p>
<ol>
<li>gets the input, </li>
<li>adapts it to simple objects acceptable to the system,</li>
<li>pushes it through the functional core,</li>
<li>gets the returned value from the functional core,</li>
<li>adapts it for the output device,</li>
<li>and pushes it out to the output device.</li>
</ol>
<p>This lets us easily test the functional core. Ideally, most of a production system should be pure-functional.</p>

<p>If you reduce the <span><strong>imperative shell</strong></span> and move code into the <span><strong>functional core</strong></span>, each test can verify almost the entire (now-functional) stack, but stopping short of actually performing external actions.</p>
<p>You can then test the imperative shell using <strong>fewer integration tests</strong>: you only need to check that it is <strong>correctly connected</strong> to the functional core.</p>
<p>Having two users for the system - the real user and the unit tests - and listening to both, lets you guide your architecture so as to <strong>minimize coupling</strong> and build a more <strong>flexible system</strong>.</p>
<p>Having a flexible system lets you implement new features and change existing ones <strong>quickly and cheaply</strong>, in order to <strong>stay competitive as a business</strong>.</p>
<p>Comments are much appreciated. I am yet to apply these insights, and I may be missing something!</p>
<p><strong>Edit 2020-10-28:</strong> I have tried out this methodology in some small TDD Katas, and together with TDD, it works great. But I am not employed right now, so I can't say I've <em>really</em> tried it.</p>
            </div>
            <!-- /.entry-content -->


        </article>
    </section>

        </div>
        
    </div>
</div></div>]]>
            </description>
            <link>https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915497</guid>
            <pubDate>Wed, 28 Oct 2020 05:19:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Dual-Boot Ubuntu 20.04 and Windows 10 with Encryption]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24914573">thread link</a>) | @Fiveplus
<br/>
October 27, 2020 | https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html | <a href="https://web.archive.org/web/*/https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><img src="https://www.mikekasberg.com/images/posts/dual-boot-encryption-full.jpg" alt="Image for "></p>
  <p><span>08 Apr 2020</span></p><p>When you run the Ubuntu installer, there’s an option to dual-boot Ubuntu with an
existing Windows installation. There’s also an option to encrypt your Ubuntu
installation, but <em>only if you erase everything and install ubuntu</em>. There’s no
automatic way to install Ubuntu alongside Windows 10 with encryption. And while
there are plenty of tutorials for dual-booting Ubuntu and Windows, many of them
are outdated – often referencing an MBR partition table – and almost none of
them seem to address encrypting your Ubuntu partition.</p>

<blockquote>
  <p>Dual-booting with encrypted storage should not be this hard in 2020.</p>

  <p>–Me, while figuring out how to do this.</p>
</blockquote>

<p>In reality, once you figure it out, it’s not that hard. The tricky thing is that
this isn’t well-documented <strong>anywhere</strong>! So I’m hoping to fix that with this
tutorial blog post. Honestly, if you know enough about Ubuntu to set up a
dual-boot with Windows, it’s only a little bit harder to do it with encryption.
I prepared this tutorial on a Dell Latitude e7450, and I fine-tuned it when I
tested it on my Dell Precision 5510. So it should work with almost no
modification on most Dell systems, and with only minor modifications
(particularly around BIOS setup) on most other types of computers.</p>

<h2 id="references">References</h2>

<p>To write this guide, I compiled information from several sources. Here are some
of the most useful references I found:</p>

<ul>
  <li><a href="https://gist.github.com/luispabon/db2c9e5f6cc73bb37812a19a40e137bc">XPS 15 9560 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/luispabon">luispabon</a>. I followed these notes pretty
closely, but modified some partition sizes and names based on other guides.</li>
  <li><a href="https://gist.github.com/mdziekon/221bdb597cf32b46c50ffab96dbec08a">XPS 15 9570 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/mdziekon">mdziekon</a>, upon which the above is based.</li>
  <li><a href="https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019">Full Disk Encryption HowTo 2019</a>,
from the Ubuntu Community Wiki. This is a great resource, but deals with
encryption without dual-booting.</li>
  <li><a href="https://help.ubuntu.com/community/ManualFullSystemEncryption">Manual Full System Encryption</a>,
from the Ubuntu Community Wiki. This is longer, and isn’t focused on
dual-booting, but provides great details on the way certain things work.</li>
</ul>

<p>It is worth noting that this method doesn’t encrypt <code>/boot</code>. While there are
valid reasons for encrypting /boot, the graphical installer does not encrypt it
when you do a graphical install with LUKS. As such, I’m matching that precedent,
and keeping the simplicity of an unencrypted /boot partition. Thus, the guide
I’ve compiled below is just about the <strong>simplest way to have a LUKS encryption
with dual-boot.</strong></p>

<h2 id="why-encryption-is-important">Why encryption is important</h2>

<p>I began using encrypted storage on all my personal computers 5 or 6 years ago
after noticing that all the companies I’d worked for required it, and had good
reason to. Laptops get lost and stolen all the time. They’re high-value items
that are small and easy to carry. And when a thief gets your laptop, there’s
tons of valuable information on it that they can use or sell. Even if you use a
password to log in, it’s easy for an attacker to gain access to your data if
your disk isn’t encrypted – for example, by using a live USB stick. And once
they have that data, they might get access to online accounts, bank statements,
emails, and tons of other data. For me, an encrypted hard disk isn’t optional
anymore – its a necessity.</p>

<h2 id="an-overview">An Overview</h2>

<p>So what are we going to do? This tutorial will help you set up a system to
<strong>dual-boot Ubuntu 20.04 and Windows 10</strong>. (I haven’t tested it, but it should
work with most other modern versions (~16.04+) of Ubuntu or Windows.) The system
will use a GPT hard disk with UEFI (your BIOS must support UEFI). The Ubuntu
partition will be encrypted with LUKS.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The Windows partition can optionally
be encrypted with BitLocker. I’m going to keep the Ubuntu installation as close
to a “default” installation as possible – no fancy tricks like a separate
<code>/home</code> partition, but it should be somewhat easy to add that yourself if you
really want to.</p>

<p>I’m going to start with a blank hard disk, installing both Windows 10 and Ubuntu
from scratch. If you already have Windows installed and you want to keep it, you
should be able to shrink your windows partition and join us in phase 3 (though
you might want to skim phases 1 and 2 to understand what we did).</p>

<p>To give you a broad overview of where we’re headed, here’s what we’re going to
do:</p>

<ol>
  <li>Prepare the installation media and computer</li>
  <li>Install Windows 10</li>
  <li>Create an encrypted partition for Ubuntu</li>
  <li>Install Ubuntu</li>
</ol>

<p>Of course, as with any new OS installation, you should back up any important
data before proceeding. <strong>The instructions below will erase all the data on your
hard disk.</strong> Proceed at your own risk; I’m not responsible for any damage or
data loss.</p>



<p>Since we’re installing both Windows 10 and Ubuntu from scratch, we’ll need a USB
stick for each. If you don’t already have a computer running Ubuntu or Windows,
making the installation media will be a little harder – but there are tutorials
for that and I’ll let you figure it out on your own.</p>

<ol>
  <li>Create a Windows Installer USB stick.  The easiest way is to use the <a href="https://www.microsoft.com/software-download/">Windows
10 Media Creation Tool</a> from a
computer that’s already running Windows.</li>
  <li>Create an Ubuntu 20.04 USB stick. The easiest way is to <a href="https://ubuntu.com/download/desktop">download the
ISO</a> and use the Startup Disk Creator on a
computer that’s already running Ubuntu.</li>
</ol>

<p>Great! We’ve got our USB sticks ready to go! One final thing before we get
started – we need to make sure our BIOS is set up correctly. In particular, we
want to make sure we’re using UEFI to boot our OS.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/dell-bios.jpg" alt="The Dell BIOS"></p>

<ol start="3">
  <li>Ensure your computer is running the latest BIOS available. This is important
because an out-of-date BIOS can have bugs, and those bugs sometimes affect
things like UEFI, non-Windows operating systems, or other components we’ll be
touching.</li>
  <li>Edit your BIOS settings. The following names are probably specific to Dell
BIOS, but other manufacturers will have similar settings.
    <ol>
      <li>Under <code>General</code> and <code>Boot Sequence</code>, make sure your <code>Boot
List Option</code> is set to <code>UEFI</code>.</li>
      <li>Under <code>General</code> and <code>Advanced Boot Options</code>, I disabled
<code>Legacy Option ROMs</code>. It’s important that both OSes install in UEFI mode.
(You can probably enable this when installation is complete if you care).</li>
      <li>Under <code>Security</code>, <code>TPM Security</code> must be enabled if you
want to easily set up BitLocker in Windows.</li>
      <li>I disabled <code>Secure Boot</code>. I’m not sure if this is absolutely required, and
you can try leaving it on or re-enabling it when you’re done if you want.</li>
    </ol>
  </li>
</ol>

<p>Now that our BIOS is configured for UEFI, we’re going to set up our hard disk.</p>

<div>
<p><b>For this tutorial, your BIOS must support UEFI!</b></p>
<p>Most modern computers support this, but if yours doesn't this tutorial won't
work for you. You should consider:</p>

<ul>
  <li>Installing only Linux with encryption using the graphical installer.</li>
  <li>OR Installing only Windows with encryption.</li>
  <li>OR Dual-booting Linux and Windows without encryption using Ubuntu's graphical installer.</li>
  <li>OR Finding another tutorial or figuring out how to do this with an MBR disk.</li>
</ul>
</div>

<ol start="5">
  <li><strong>Completely erase</strong> your hard disk and set it up for UEFI by doing the
following.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>
    <ol>
      <li>Boot your Ubuntu USB stick and use <code>Try without installing</code>.</li>
      <li>Open a terminal. Make it fullscreen while you’re at it.</li>
      <li>Figure out what your primary hard disk is called. It will probably be
either <code>/dev/sda</code> or <code>/dev/nvme0n1</code>. Importantly, it’s <strong>not</strong> <code>/dev/sda1</code> or
<code>/dev/nvme0n1p1</code> – those are partitions of the disk. One way to figure out what
yours is called is to run <code>lsblk</code> and look at the disk size. Throughout the rest
of this guide, I’m going to refer to <code>/dev/sda</code>. <strong>If yours is not
<code>/dev/sda</code>, replace <code>/dev/sda</code> with your own (perhaps <code>/dev/sdb</code> or
<code>/dev/nvme0n1</code>) for the rest of this guide.</strong></li>
      <li>
        <p>Run the following commands. This will initialize the drive as a GPT drive
and create a 550M EFI system partition formatted as FAT32.</p>

        <div><div><pre><code>$ sudo su
# sgdisk --zap-all /dev/sda
# sgdisk --new=1:0:+550M /dev/sda
# sgdisk --change-name=1:EFI /dev/sda
# sgdisk --typecode=1:ef00 /dev/sda
# mkfs.fat -F 32 /dev/sda1
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ol>

<p>OK, phase 1’s complete. We have our installation media ready to go and the
computer’s BIOS and hard drive is set up correctly. Next, we’ll install Windows.</p>

<h2 id="phase-2-install-windows">Phase 2: Install Windows</h2>

<p>In this phase, we’re going to install Windows. Note that when we do this, we’re
going to leave some unallocated space to install Linux later. This is a good
approach because the Windows installer will mess with our partitions a little
bit, and its easier to let it do so before finalizing our Linux partitions.</p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/windows-installer.jpg" alt="The Windows installer"></p>

<ol>
  <li>Boot from your Windows Installer USB stick.</li>
  <li>Choose a <code>Custom (advanced)</code> install to get to the Windows partitioning tool.</li>
  <li>Create a new partition. The size of this partition should be the amount of
disk space you want to use for Windows. In this example, I did 80G since the SSD
on my computer is relatively small. If unsure, do about half of your hard
disk.</li>
  <li>Windows will warn you that it is going to create an extra system partition.
This is good.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
  <li>Install Windows onto the partition you just made. There’s no need to format
any partitions – the Windows installer will take care of that for you.</li>
  <li>When the Windows installation is finished, log in and enable BitLocker on
drive <code>C:</code>. This will automatically create yet another partition on your disk
(a Windows recovery partition) - which is why we’re doing it before
partitioning for Ubuntu.</li>
</ol>

<p>At this point, you can start using Windows. But I’d avoid doing too much setup
or personalization yet so you don’t have to do it again if something goes wrong
below. If you want to double check your partitions, this is what you’ll be left
with after installing Windows and enabling BitLocker:</p>

<div><div><pre><code>ubuntu@ubuntu:~$ sudo sgdisk --print /dev/sda
Disk /dev/sda: 500118192 sectors, 238.5 GiB

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048         1128447   550.0 MiB   EF00  EFI
   2         1128448         1161215   16.0 MiB    0C01  Microsoft reserved ...
   3         1161216       167825076   79.5 GiB    0700  Basic data partition
   4       167825408       168900607   525.0 MiB   2700
</code></pre></div></div>

<h2 id="phase-3-partition-the-drive-for-ubuntu">Phase 3: Partition the drive for Ubuntu</h2>

<p>This is the trickiest phase since this is where we need to manually set up our
encrypted disks for Ubuntu. We’re going to make it work very similar to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</a></em></p>]]>
            </description>
            <link>https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914573</guid>
            <pubDate>Wed, 28 Oct 2020 02:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When is no-code useful?]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24914062">thread link</a>) | @thesephist
<br/>
October 27, 2020 | https://linus.coffee/note/no-code/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/no-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>To talk about what no-code is good for, we need to first take a digression on what makes no-code fundamentally different from “yes-code” software.</p>
<h2 id="the-grain-of-abstractions">The grain of abstractions</h2>
<p>Software – yes-code software – has been around for a while. One of the things we’ve learned as an industry is how to write software <em>that gracefully evolves</em>. We’re not perfect – sad, legacy systems still proliferate – but we as a technical industry have learned how to build and evolve software systems against changing requirements and constraints that span years and decades.</p>
<p>When we first solve a problem with software, we write some code against the constraints of that particular day. We don’t necessarily know how the problem is going to change. Maybe there will be different customers or stakeholders tomorrow, or maybe the product will expand to serve a related, but different, problem space. We need to be able to change software to accommodate changing circumstances without rewriting it, and that is fundamentally what <em>software engineering</em> is: how to change software systems. <em>Change</em> is the name of the game.</p>
<p>We’ve gotten decent at change. We’ve built tools like Git and patterns like continuous integration and code autoformatting to make it easier to change code and remain stable. We’ve learned how to operate large software teams, especially in open source. We’ve also learned to use better abstractions. Abstractions are conceptual wrappers that isolate different parts of a codebase – say, a data source from a user interface – so that one part may change while another doesn’t. In general we have started to figure out how to make the DNA of software systems resilient against the changing tides of time.</p>
<p>No-code seems to reject a lot of those learnings, for better or worse. I haven’t seen any no-code company or product that allows source control (and I’ve seen many no-code companies, but you’re welcome to prove me wrong.) I have yet to find no-code products that allow for natural construction of abstraction between layers of a no-code workflow. No-code software is also scarily ill-prepared for large scale development: we have software systems being worked on by tens of thousands of engineers – what does it look like for a team of 1000 engineers to be working on a set of thousands of no-code workflows? Chaos.</p>
<blockquote>
<p>Traditional software has learned the abstractions and patterns that make software resilient and adaptable to change and scale. No-code software is not ready for changing constraints nor development scale.</p>
</blockquote>
<p>Despite these limitations, I think no-code has a few niches where making tradeoffs in adaptability and scale allows no-code tools to be much, much better. So, given this, <em>when is no-code useful?</em></p>
<h2 id="1-transitionary-ephemeral-software">1. Transitionary, ephemeral software</h2>
<p>The obvious answer, and one I had before our conversation, was <em>transitionary</em> software, software with <em>a defined lifetime</em>. If your software system has a finite, pre-defined lifetime and team, it doesn’t need to worry about changing constraints or team growth. It just needs to worry about solving a problem well, now.</p>
<p>Lots of software has predictably finite lifetime: a product prototype for an early-stage company, a game or app used as a part of an interactive online ad, a quick sketch or solution to patch a particularly urgent problem in a product, an app built for an event or a conference or a recruiting cycle or a quarterly goal tracker… all of these are projects with a pre-defined, maximum lifetime. They don’t need to last or grow or change – they just need to work now, and by giving up some of the adaptability of software abstractions of code, no-code software benefits from way faster prototyping speed. This is a plus.</p>
<p>I think we see lots of finite-time software in transitions. Transitions from having no product to having a product, in a prototype. Transitions in the process of brainstorming a solution and trying multiple designs. Software with a finite shelf life is a good fit for no-code tools.</p>
<h2 id="2-high-churn-code">2. High-churn code</h2>
<p>There’s another category of software for which long-term maintainability matters little – code with high churn.</p>
<p>By high churn, I mean that requirements are changing almost daily, and very little of the code written today will exist in a month or a quarter’s time. If the code you write today doesn’t have to last and evolve, because something new is going to take its place tomorrow, what matters is the speed to build, not resilience to change.</p>
<p>There’s lots of high-churn code in businesses. Marketing websites and landing pages, data pipelines for analytics, e-commerce storefronts, marketing campaigns, payment portals – requirements for these kinds of solutions change quickly enough that code is constantly being rewritten, and if code needs to <em>be replaced</em> more than it needs to <em>last</em>, no-code tools are a great fit.</p>
<h2 id="avoiding-the-same-mistakes">Avoiding the same mistakes</h2>
<p>I think “no-code” is a misnomer. It leads us to think that no-code software is the start of a trend in which general software will involve less coding, and software engineering will become easier. This is not the case. Software engineering is not about building solutions, it’s about evolving them. But change resiliency over time is not the focus of no-code tools, and I think that’s ok.</p>
<p>I think no-code tools are instead an extension of a different trend: <a href="https://thesephist.com/posts/text/">reifying workflows</a>. Business processes and workflows used to be documented in Word docs strewn about the office or on a shared folder, or even just passed down by oral tradition in companies. Now, we have tools that allow us to build these workflows, talk about them, edit them, and share them more concretely. This is a huge boon for more repeatable business processes and for getting things done quickly! I think this is the true win of no-code tools: concretizing workflows.</p>
<p>If no-code wants to be a serious competitor against “traditional” software – though I don’t think it should try – no-code needs to learn from the mistakes of early software. No-code tools need to understand that products and software systems need to live on for decades against changing teams and requirements, and against products and companies and standards that die out and get replaced. This requires a cultural shift, a tooling shift, and a new class of abstractions in our toolbelt as no-code engineers. Anytime we try to introduce more tooling and abstraction to no-code, I think no-code gets just a little more “code” in it. And perhaps that’ll bring us right back to where we started, discovering that code is good.</p>
<p>After all, the world is complex. And when we build software against the complexity of the world, that <a href="https://thesephist.com/posts/complexity-conservation/">complexity needs to go somewhere</a>. Software is complex, but only as much as the world it attempts to make sense of.</p>
<p>It feels like we’re getting off the edge of a discovery phase of no-code, and into a time when we’re starting to understand what problems no-code tools are great for. I think it’s important that no-code tool builders focus on those strengths, or risk falling into the trap of repeating the software industry’s mistakes from the ground up.</p>

        <hr>
        <p>
            
            Next:
            <a href="https://linus.coffee/note/scannability/"><em>Scannability is king</em></a>
            
        </p>
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/no-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914062</guid>
            <pubDate>Wed, 28 Oct 2020 01:36:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years, 8 months and 12 days]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24911784">thread link</a>) | @app4soft
<br/>
October 27, 2020 | https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/ | <a href="https://web.archive.org/web/*/https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="lesanimals-page-wrapper" role="main">
        <section id="template-post-single" data-view-name="template-post-single" data-id="2969">

        <canvas data-text="News"></canvas>

        <span></span>

        

        <div>

            
            <div>
                <p>This article could have been entitled&nbsp;337,737,600 seconds, but hiding the fact that Prototypo started more than 10 years ago would have been a missed opportunity to show the dedication the team and I, as a founder, put in this project over the years.</p>
<p>Prototypo started as a student project when I studied Graphic Design at H.E.A.R Strasbourg in France. As a non-savvy Type Designer I was frustrated to not be able to complete the typeface projects I had in mind. Typefaces are made of rules and systems, right? Catcha! We can code something that follows rules, so we should succeed in coding fonts. That was the starting point of the next 10 years, and the beginning of the Roller Coaster, a.k.a creating a startup company.</p>
<p>Prototypo is a startup like many others: before having a stable and reliable business model, we put a lot of energy into developing innovative and useful technologies for our users.</p>
<p>But before being a startup, Prototypo is a company. Today we have reached the end of our resources without having found the expected Product Market Fit, and so the Break-even.</p>
<p>After several years of a strong dedication and passion for what we’ve built, we decided to shutdown the company.</p>
<p>Since the first second, I knew that it would be a hard journey with many obstacles on the path. But I regret nothing. The next 337,737,599 seconds were full of great experiences, shared with amazing people.</p>
<p>Thank you for those who supported us along the road, it was a great adventure.</p>
<p><a href="https://www.linkedin.com/in/yannick-mathey/">Yannick,</a> (former) CEO</p>

            </div>

            

        </div>

                    
        
    </section>
</section></div>]]>
            </description>
            <link>https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911784</guid>
            <pubDate>Tue, 27 Oct 2020 20:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring Myths Common in Hacker News Discussions]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24911758">thread link</a>) | @Ozzie_osman
<br/>
October 27, 2020 | https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-222">

	

	
	<div>
		
<p>Another day, another HackerNews discussion about hiring being broken. The most recent one I saw was triggered by <a href="https://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">a blog post</a> by the formidable Aline Lerner (disclaimer: Aline is a friend and we collaborated on a <a href="https://www.holloway.com/g/technical-recruiting-hiring/about">hiring book</a> last year). Now, I 100% agree that hiring is broken, and Aline’s post is really thoughtful. In fact, a lot of “hiring is broken” articles are thoughtful.</p>



<p>But the discussion threads are something else—they miss the point of the article. The discussion threads are even more broken than hiring. And they’re really repetitive. They always do contain grains of truth, but inevitably have us reaching conclusions that are simplistic, and in my opinion, create a pretty bad attitude in the tech industry.</p>



<p><strong>Conclusion #1: “Hiring sucks for candidates, but hiring managers can do what they want</strong>“</p>



<p>The truth is that hiring is hard for everyone. There’s no question about it. It’s hard for both candidates and for hiring managers. Sure, FAANGs and the startup-du-jour might have a leg up, but most people who are hiring are trying to hire at a non-FAANG, non-sexy company. If you’ve never done it, you should try it at some point in your career. It’s an <em>incredibly </em>humbling experience. Or, at the very least, find a friend who’s spent time on hiring, and ask them for their favorite battle story. They’ve been ghosted by candidates. They’ve spent hours trying to convince people to talk to them. They’ve spent even more time getting candidates to the offer stage, only to lose out to the FAANG / startup-du-jour.</p>



<p>And yes, on the balance, power and information asymmetry work out in favor of the companies hiring. And that asymmetry is much larger with FAANGs. But even FAANGs have to invest a tremendous amount of time and energy into hiring. It’s not really easy for anyone. </p>



<p>Especially if you want to do it <em>well</em>. Ask any successful leader (entrepreneur, manager) what they spend most of their time on, and it’ll either involve a large chunk spent on hiring (if they appreciate the problem and give it the attention it deserves) or dealing with the consequences of bad hiring (if they don’t).</p>



<p><strong>Conclusion #2: “Hiring is a crap-shoot—it’s a roll of the dice</strong>“</p>



<p>I strongly disagree with this one. When writing the <a href="https://www.holloway.com/g/technical-recruiting-hiring">Holloway Guide to Technical Hiring and Recruiting</a>, I got to interview dozens of really thoughtful hiring managers and recruiters. They were really good at their jobs. And there were some common themes. They were thoughtful about every step of their process. They kept their process balanced and fair, holding a high bar but respecting candidates and their time. They didn’t chase the same pool of candidates everyone else was chasing—instead, they found non-traditional ways to discover really talented and motivated people who weren’t in the pool of usual suspects. They were thoughtful about what signals they were looking for and how best to assess them. And, they deeply understood their team’s needs, and candidates’ needs, and were really good at deciding when there was or wasn’t a fit. But most of all, they were effective: they built really talented teams.</p>



<p>There are a handful of companies that have built amazing hiring engines, and the proof is that they’ve been able to put together really strong teams. You can generally tell that if a person worked at a certain company at a certain time, that person is probably incredibly intelligent and incredibly motivated (some examples are Google, Facebook, Stripe, Dropbox at different points in time). There will always be noise. Even the best hiring managers will sometimes make hiring mistakes. And of course, even the best engineers may not be a fit for every role or every company. </p>



<p>Again, hiring is hard. But there is not a shred of doubt in my mind that if you are thoughtful about it, you can hire well. And really, you don’t need to be perfect at it. You just need to be better than the rest.</p>



<p><strong>Conclusion #3: “FAANGs suck at hiring”</strong></p>



<p>This one has some truth to it, but it’s a lot more subtle than “FAANGs suck at hiring”. Because let’s face it, they do hire really smart people. Some of the smartest people I know are at FAANGs right now. So let’s decouple that statement a little more.</p>



<p>FAANGs <em>do </em>suck at parts of hiring, like their candidate experience. They can be really slow at making hiring decisions. Their hiring process might be tedious and seem arbitrary. But <em>they usually can get away with it</em>, <em>and you probably can’t!</em> They’ve got a strong brand, interesting technical challenges (interesting for some people, at least), and a lot of money. In fact, one FAANG VP of Engineering told me: “our process is what we can get away with”. To the point that they can even play it off as a positive: “our process is slow and long because we are <em>very</em> selective”.</p>



<p>And look, I’m sure FAANGs lose some talented candidates who get turned off by their “you’d-be-blessed-to-work-with-us” attitude. They definitely have a lot of room for improvement. But at the end of the day, they’re operating a process that’s delivering large quantities of really smart people at scale. In fact, I’d argue their internal processes around strategy, performance management / promotions, etc cause incredibly <em>more</em> damage to them than broken hiring—if you lose out on hiring one talented person when you have thousands applying to work for you, that’s one story, but if you hire someone really talented and driven, and they work for you for 6 to 12 months but don’t meet their potential and leave in bitter frustration… well, that’s a subject for another post)</p>



<p>“But”, people go on, “FAANGs <em>also</em> don’t know how to interview!” Which brings me to trope #4.</p>



<p><strong>Conclusion #4: “Whiteboard</strong> <strong>and algo/coding interviews suck”</strong></p>



<p>Again, this one has some truth to it, but if you just stop at the above statement, you miss the point.</p>



<p>Algo/coding interviews are one of the primary hiring mechanisms used by FAANG companies. And they are incredibly unpopular—at least in discussion threads. But big companies have spent years looking at their hiring data and feeding that back into their hiring process (coining the term “<a href="https://rework.withgoogle.com/subjects/people-analytics/">people analytics</a>” along the way).</p>



<p>The argument against them is usually a combination of:</p>



<ul><li>they really only assess pattern-matching skills (map a problem to something you’ve seen before)</li><li>they only assess willingness to spend time preparing for these types of interviews</li></ul>



<p>These are fair criticisms, but that doesn’t mean these interviews are actually terrible. I mean, they might be terrible for you if you’re interviewing and you don’t get the job. You’re probably a brilliant engineer, and I agree, these interviews certainly don’t fully assess your ability (or maybe you’re a shit engineer, I don’t know you personally). In any case, the leap from “this interview sucked for me” to “this interview sucks” is still pretty big.</p>



<p>If you’re a large tech co with a big brand and a salary scale that ranks at the top of&nbsp;<a href="https://www.levels.fyi/">Levels.fyi</a>, you probably get a lot of applications. So a good interview process is one that weeds out people who wouldn’t do well at your company. To do well at a large tech company, you need to (and I’m painting with a really broad brush, but this is true for 90% of roles at these companies):</p>



<ol><li>Some sort of problem-solving skill that’s a mix of raw intelligence and/or ability to solve problems by pattern-matching to things you’ve seen before.</li><li>Ability/commitment to work on something that may not&nbsp;<em>always&nbsp;</em>be that intrinsically motivating, in the context of getting/maintaining a well-paying job at a large, known company.</li></ol>



<p>Hopefully you can see where I’m going with this. Basically, the very criticisms thrown at these types of interviews are the reason they work well for these companies. They’re a good proxy for the work you’d be doing there and how willing you are to do it. If you’re good at pattern matching, and are willing to invest effort into practicing to get one of these jobs, you’ll probably do well at the job.</p>



<p>Not that there’s anything wrong with that type of work. I spent several years at big tech co’s, and the work was intellectually stimulating most of the time. But a lot of times it wasn’t. It was a lot of pattern-matching. Looking at how someone else had solved a problem in a different part of the code-base, and adapting that to my use-case.</p>



<p>On the other hand, if you’re an engineer (no matter how brilliant) who struggles with being told what to do or doing work that you can’t immediately connect to something intrinsically motivating to you, that FAANG interview just did both you and the company a favor by weeding you out of the process.</p>



<p>So the truth is, there is no single “best interview technique”. In our book, we wrote several chapters about different interviewing techniques and their pros and cons. In-person algo/coding interviews on a whiteboard, in-person interviews where you work in an existing code base, <a href="https://www.holloway.com/g/technical-recruiting-hiring/sections/take-homes">take-home interviews</a>, pairing together, having a trial period, etc all have pros and cons. The trick is finding a technique that works for both the company and the candidate. </p>



<p>And that can really differ from company to company and candidate to candidate. A VP at Netflix told me about how they had a really strong candidate come in, but when asked to do a whiteboard-type interview, informed them (politely) that they might as well just reject him then. He was no good at whiteboard interviews… But if they allowed him to go home and write some code, he’d be happy to talk through it. And since then, many Netflix teams have offered candidates the choice of doing a take home.</p>



<p>And really, any interview format can suck. It can fail to assess a candidate for the things a company needs and it can be a negative candidate experience. Which would you rather have:</p>



<ul><li>A whiteboard interview with heavy algorithms for a role where that knowledge (or ability to develop that knowledge) isn’t critical, delivered by an apathetic engineer who doesn’t care about their job.</li><li>A …</li></ul></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</a></em></p>]]>
            </description>
            <link>https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911758</guid>
            <pubDate>Tue, 27 Oct 2020 20:53:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get started with 2-minute rule]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24911312">thread link</a>) | @hoanhan101
<br/>
October 27, 2020 | https://hoanhan.co/2-minute-rule | <a href="https://web.archive.org/web/*/https://hoanhan.co/2-minute-rule">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Scale any task down into a 2-minute version to make it easier to get started.</p><time datetime="2020-10-27T00:00:00-04:00"> October 27, 2020 · 1 min read · <a href="https://hoanhan.co/category/Motion">Motion</a><hr> </time><p>Whenever you find it hard to get started on a task, consider scaling it down into a 2-minute version. For example,</p><ul><li>Read a book → Read one page</li><li>Write an essay → Write one sentence</li><li>Run 10 miles → Wear my running shoes</li><li>Do 100 push-ups → Do 1 push up</li><li>Eat more vegetables → Eat an apple</li><li>Study for interview → Skim through my notes</li><li>Build a program → Code a function</li></ul><p>The idea is to make it super easy to get started. Once you pass the starting point, which is arguably the hardest step, you start to gain momentum to keep doing the task itself:</p><ul><li>Read one page → Read 10 pages → Finish the first chapter</li><li>Write one sentence → Write an opening paragraph → Write the body</li><li>Wear my running shoes → Walk for 5 minutes → Run for 5 minutes</li></ul><p>As you can see, once you start, it is much easier to continue doing it. Sometimes, you’ll find yourself completing the task even before you even notice it.</p><blockquote><p>For more insights on system planning and goal setting, feel free to check out <a href="https://hoanhan.co/motion">this guide</a>. If you’re curious about how I apply it on a daily basis, <a href="https://motion.hoanhan.co/goals/hoanhan/">check this out →</a></p></blockquote><hr><p><strong>References:</strong></p><ul><li><a href="https://jamesclear.com/how-to-stop-procrastinating">https://jamesclear.com/how-to-stop-procrastinating</a></li><li><a href="https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html">https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html</a></li></ul><hr><hr><p> Tagged: <a href="https://hoanhan.co/tag/motion.hoanhan.co">#motion.hoanhan.co</a>, <a href="https://hoanhan.co/tag/consistency">#consistency</a>, <a href="https://hoanhan.co/tag/start">#start</a></p><br> </article></div></div>]]>
            </description>
            <link>https://hoanhan.co/2-minute-rule</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911312</guid>
            <pubDate>Tue, 27 Oct 2020 20:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Will Never Have Enough Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24910949">thread link</a>) | @bartdegoede
<br/>
October 27, 2020 | https://whoisnnamdi.com/never-enough-developers/ | <a href="https://web.archive.org/web/*/https://whoisnnamdi.com/never-enough-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://whoisnnamdi.com/content/images/size/w300/2020/10/header-v2-resized.png 300w,
                            https://whoisnnamdi.com/content/images/size/w600/2020/10/header-v2-resized.png 600w,
                            https://whoisnnamdi.com/content/images/size/w1000/2020/10/header-v2-resized.png 1000w,
                            https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png" alt="Why We Will Never Have Enough Software Developers">
            </figure>

            <section>
                <div>
                    <p>We will never have enough software developers.</p><p>Developers are dropping out of the profession in large numbers despite efforts to grow the number of computer science graduates and software engineers.</p><p>Here's why.</p><h2 id="developer-dropout-is-real">Developer dropout is real</h2><p>Software development has a <em>serious</em> retention problem:</p><ul><li>At age 26, 59% of engineering and computer science grads work in occupations <em>related</em> to their field of study. By age 50, only 41% work in the same domain, meaning a full <strong>~30% drop out of the field by mid-career</strong></li><li>In contrast, engineering and computer science majors who join <em>unrelated</em> fields upon graduation retain at much higher rates, with only 10-15% switching out after the age of 26:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/W-kECKz1nw.png"></figure><p>Engineers often leave engineering for non-STEM management roles. Graduation into management is not surprising. What's surprising is that these are <strong>non-STEM</strong> positions. Engineers swap technical roles for <em>non-technical</em> roles over time.</p><p>This phenomenon, which I'll call "<strong>developer dropout</strong>," is a real problem. What's behind it?</p><!--kg-card-begin: html--><section>
    <h3>Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>
                

</section><!--kg-card-end: html--><h2 id="out-with-the-old-skills-in-with-the-new-skills">Out with the old skills, in with the new skills</h2><p>Programming-related jobs have high rates of skill turnover. Over time, the types of skills required by companies hiring software developers change more rapidly than any other profession.</p><p>To demonstrate this, <a href="https://academic.oup.com/qje/article/135/4/1965/5858010">researchers</a> analyzed job postings on more than 40,000 online job boards and company websites between 2007 and 2019, controlling for employer, location, and occupation. They defined "new" skills as those that were rare or non-existent in 2007 but prevalent in 2019 and "old" skills as those that were prevalent in 2007 but rare or extinct in 2019.</p><ul><li>While only 30% of all job vacancies required at least one new skill by 2019, <strong>47% of computer and mathematical jobs required at least one new skill</strong> (i.e. a skill that was not common back in 2007)</li><li>This compares to <em>less than 20%</em> of jobs in fields like education, law, and community and social services</li><li>In addition, <strong>16% of jobs in computer and mathematical fields in 2007 required a skill that was obsolete by 2019</strong> (i.e. a skill that was common in 2007 but relatively rare in 2019), more than double any other job category:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/azDsA9n3rx.png"></figure><p>About a third of the change in required skills in computer-related occupations is due to specific new software:</p><ul><li>The fastest-growing software skills between 2007 and 2019 include <strong>Python, R, and Apache Hadoop</strong></li><li>Software that was popular in 2007 but effectively obsolete by 2019 includes QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah, finally a name I recognize)</li></ul><p>Data science, machine learning, and AI saw big increases among technology-intensive jobs as well. For example, the number of STEM-related jobs requiring skills in machine learning and AI grew more than 4x from 2007-2017, touching more than 15% of STEM jobs:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Pc3AjVflhW.png"></figure><p>To better compare rates of skill change across occupations, the researchers came up with a measure of skill change that tracks the absolute growth or decline of various skills within each profession from 2007 to 2019. Occupations whose required skills change rapidly in prevalence among job postings receive a high score, while jobs whose skills do not change much receive a lower score:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/xfeKvOWxo-.png"></figure><ul><li><strong>Computer-related occupations receive the highest score by far, 4.8</strong>. Note that the mean and standard deviation of this measure are ~3 and ~1 respectively, so computer-related jobs are <strong>nearly two standard deviations away from the typical job in America</strong></li><li>Meanwhile, jobs in education and and those involving manual labor have very low skill change scores, typically less than 2.</li></ul><p>We can get even more granular and look at specific job roles. This level of detail makes the difference even more stark (only showing the fastest changing roles):</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OwoB5xsSdO.png"></figure><p>Web development has the highest rate of skill change <em>among all jobs in the country</em>. Next up are sales engineers, another often technical role. Database administrators, computer network architects, sysadmins, and application developers all make the top 10, and we see many other technical roles among the top 30. The mean and standard deviation are similar here, placing web development <strong>more than 3 standard deviations away from the typical job in America</strong> in terms of skill change over time.</p><p>Suffice to say, <strong>software development is a rapidly changing profession</strong>.</p><p>You might think, however, that skill change would eventually settle down as one becomes more experienced.</p><p><em>You'd be wrong.</em> The skills for software engineering jobs change rapidly throughout the entire career lifecycle:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/7ItjXMaTE-.png"></figure><ul><li>In entry-level roles in computer and engineering occupations all the way through those requiring 12+ years of experience, <strong>the proportion of job postings requiring at least one new skill in 2019 was effectively the same, 40-45%</strong></li><li>In contrast, <strong>29% of entry-level non-computing and engineering roles in 2019 required at least one new skill, but this proportion declines to 24%</strong> for jobs requiring more than four years of experience</li></ul><blockquote>This means that experienced STEM workers seeking employment in 2019 are often required to possess skills that <strong>were not required</strong> when they entered the labor market in 2007 or earlier.</blockquote><p>Software engineers <strong>never</strong> escape the skill-change vortex, even many years into their careers. Experienced engineers must learn and adopt technologies that didn't even exist when they started out. Developers must constantly retool themselves, even well after their <a href="https://whoisnnamdi.com/college-degrees-software-engineers/">formal education</a> ends.</p><h2 id="nothing-s-changed-but-my-change"><a href="https://youtu.be/m1ERvlxgCD8?t=166">Nothing's changed but my change</a></h2><p><strong>College majors associated with faster changing jobs pay more early on.</strong></p><ul><li>In professions with one standard deviation increased skill change, pay is <strong>~30%</strong> higher in the first few years of one's career</li><li>If we exclude both the fastest and slowest-changing fields (Engineering/Computer Science at the high end, Health/Education at the low end), the early earnings premium for faster-changing roles increases to <strong>~60%</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/heMo13OsG1.png"></figure><p><strong>Fast-changing fields pay better.</strong></p><p>Notice however that the pay advantage declines over time. By the time one approaches the age of 50, the pay premium for working in rapidly changing fields falls dramatically to only 20-30% vs slower changing professions.</p><p>Here's another way to see the eroding pay advantage. The below chart simulates the earnings of the average worker by category of college degree from ages 23 to 50 in 2016 dollars.</p><ul><li>Computer science and engineering grads start off with sizable advantage vs any other major</li><li>However, this premium <em>falls</em> over time as the earnings of CS and engineering graduates plateau over time while the earnings of their peers grow <em>faster</em> for <em>longer</em></li><li>In fact, <strong>life and physical science graduates' earnings surpass their computer and engineering classmates by the age of 40</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Lifecyle-Earnings-by-Degree-Category.png"></figure><p>Excluding business majors, the earnings premium of software engineering declines over time in both percentage <em>and</em> absolute dollar terms, to the point where engineers barely out-earn social science majors:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Engineering-_-Computer-Science-Earnings-Premium.png"></figure><p>But the focus on college major is somewhat misleading. This phenomenon has less to do with one's field of study and more to do with <em>choice of occupation</em>.</p><p>To show this, researchers plotted the earnings premium of various categories workers relative to those with a non-Engineering/Computer Science major working in a non-Engineering/Computer Science job.</p><ul><li>Workers who major in Engineering or Computer Science but work in unrelated fields actually see their earnings advantage <em>compound</em> over time, rather than decline</li><li>On the other hand, regardless of major, individuals who work in Engineering or Computer Science jobs see their earnings advantage erode over the years:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OFffH9kBKA.png"></figure><blockquote><strong>Declining relative returns is a feature of STEM jobs, not majors.</strong> The earnings premium for non-STEM majors in STEM occupations starts off near 40%, but declines to 20% within a decade. In contrast, the relative earnings advantage grows over time for computer science and engineering majors working in non-STEM occupations.</blockquote><p>The <strong>profession</strong> of software development drives the declining earnings premium, <strong>not the college major</strong>.</p><p>In fact, computer science majors who work in non-CS fields experience the <em>opposite</em> dynamic of their non-developer peers — their relative earnings premium rises as they advance. A CS major who eschews the profession doesn't earn much more than otherwise similar non-CS majors early on, but eventually out-earns their peers by nearly 20%.</p><p>OK, that's enough about <em>what</em> is happening. Now let's see <em>why</em> it's happening.</p><h2 id="human-capital-depreciates-too"><em>Human</em> capital depreciates too</h2><p>Imagine a simple model where workers choose their profession in order to maximize income, which is a derivative of their own skill or human capital. Over time, workers gain new skills, while the value of their existing skills depreciates somewhat due to changing times.</p><p>Some workers, endowed with superior ability, learn faster than others, picking up skills at a quicker pace. Those workers will tend to sort into high-skilled, fast-changing professions initially, maximizing their early career earnings. Less impressive workers will sort into low-skilled, slower-changing professions.</p><p>In a world where human capital never depreciated, we could imagine that high-skilled individuals like software developers would maintain a relative human capital (and earnings) advantage over other professionals, leading to consistently increasing pay and a stable relative premium:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_o-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_o-Depreciation-.png"></figure><p>But, if human capital depreciates over time and that rate of depreciation is higher in rapidly-changing fields like software development, then developers' initial advantage would erode over time, narrowing the gap vs. non-developers:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_-Depreciation-.png"></figure><p>This simple model helps explain what we see in the data — the software engineering earnings advantage disappears as the <em>effective</em> human capital gap narrows.</p><blockquote>Applied majors such as computer science, engineering, and business teach vintage-specific skills that become less valuable as new skills are introduced to the workplace …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://whoisnnamdi.com/never-enough-developers/">https://whoisnnamdi.com/never-enough-developers/</a></em></p>]]>
            </description>
            <link>https://whoisnnamdi.com/never-enough-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910949</guid>
            <pubDate>Tue, 27 Oct 2020 19:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s A14 Packs 134M Transistors/mm²]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24910778">thread link</a>) | @jonbaer
<br/>
October 27, 2020 | https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
				
<article id="post-604">
	
   
   
   <div>

   
   
      

   	
   	<div>
   		
<figure><amp-img width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9Jzg1Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>Our friends over at ICmasters have delved into the package of the Apple A14 Bionic. The die size has been unmasked, and it stands in at 88mm<sup>2</sup>. Despite cramming in 11.8 billion transistors, the die size is incredibly small thanks to utilization of TSMC’s 5nm process node.</p>



<figure><amp-img width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>The march of progress is not all rosy. Apple’s chips have historically achieved 90%+ of the process node’s theoretical density in their processors. This generation stands out by missing that mark by a large amount. A14 comes in at a cool 78% effective transistor density when compared to theoretical density. Despite TSMC claiming a 1.8x shrink for N5, Apple only achieves a 1.49x shrink.</p>



<figure><amp-img width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI2Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>This is not due to a failure of TSMC or Apple. These companies are clear leaders for the manufacturing and design of semiconductors respectively. Instead, this failure to convert theoretical to effective density stems from the slow death of SRAM scaling. SRAM is extensively used throughout a processor from registers to caches. Geoffrey Yeap of TSMC claims that the typical mobile SoC which consists of 60% logic, 30% SRAM, and 10% analog/IO.</p>



<figure><amp-img width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>TSMC’s N5 node diverges from prior shrinks by showing signs of slowing SRAM scaling. Despite being a full shrink with logic, the SRAM is a 1.35x shrink. This figure is overstated as it will end up being even lower once other the other assist circuitry is accounted for. Hence TSMC’s guidance of chip area reduction at 35%-40% with N5. SemiAnalysis expects this to be a trend that will persist with new nodes. TSMC and Samsung are already demonstrating 3D stacked SRAM which will help alleviate the issue of density.</p>



<figure><amp-img width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>3D Stacking is not the silver bullet. Cost scaling has begun slowing dramatically. With TSMC N5 wafer pricing in the ~$17k range, it is clear cost per transistor has not fallen. Even if SRAM scaling kept up, the cost per transistor would still have remained flat from N7 to N5.</p>



<figure><amp-img width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU5Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>




   	</div>

   </div>

	</article>

			
		</div></div>]]>
            </description>
            <link>https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910778</guid>
            <pubDate>Tue, 27 Oct 2020 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla's Fix the Internet Showcase]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24910188">thread link</a>) | @lightninglu10
<br/>
October 27, 2020 | https://talium.co/doc/xboZza/s/ | <a href="https://web.archive.org/web/*/https://talium.co/doc/xboZza/s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p dir="ltr">Our mission is to support founders and companies building amazing internet products that care about the health of the internet. Grow, but not at all costs. Build delightful products and retain your users, but not because you've exploited someone's addictive triggers. <span>Privacy, sustainability, inclusivity, are not something to "figure out later", but are core in the company culture. </span></p><p dir="ltr"><span>We want all of our founders building big, massive products and companies. Hopefully as big as Mozilla Firefox. We just want everyone to do it ethically.</span></p><p dir="ltr">Since our launch this Spring, weâ€™ve funded 50 amazing teams in our Incubator, and weâ€™ve mentored over 300 different projects in our Open Lab. All of these teams are working on building a better internet.</p><p dir="ltr"><span size="5">We're <b>thrilled</b> to announce the <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">Inaugural Mozilla Builders Fix The Internet Showcase</a> this Thursday, October 29 from 11:00am-12:30pm PDT.</span></p><p dir="ltr"><span>Our Showcase will feature:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘©â€�ðŸ�« Mozillaâ€™s CEO Mitchell Baker kicking us off with her thoughts on the state of the internet and What Needs Building</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ”¥ A fireside chat with founders on "Conscious Capitalism"</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span><span>ðŸ”¥ </span>Hot takes from Mozilla builders and mentors (incl. Rotten Tomatoes founder Patrick Lee, and others) on â€œHow To Build A Better Internetâ€�!  </span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘¥ Weâ€™ll be showing off the top projects weâ€™ve funded through our Incubator and helped along through our Open Lab.</span></p></li></ul><p dir="ltr"><span>Featured companies are building </span><a href="https://shopneutral.io/" target="_blank">Honey for carbon offsets</a>,<span> </span><a href="https://www.thekanary.com/" target="_blank">Swiffer for personal data</a><span>, high interest savings through crypto, </span><a href="https://www.inmotion.app/" target="_blank">Superhuman for the browser</a><span>, </span><a href="https://www.bravedns.com/" target="_blank">next-gen DNS resolvers</a>, top tech publication <a href="https://hackernoon.com/" target="_blank">Hacker Noon</a>, decentralized farming networks, and <a href="https://builders.mozilla.community/alumni.html" target="_blank">so much more</a>.</p><p dir="ltr"><span>Some of the problems our teams are solving include:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>How do we shift the balance of power from centralized forces back towards individuals, citizens and communities?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build a new way to communicate online that favors privacy and people? How do we make platforms safe for usersâ€™ voices while protecting their personal and professional interests? What needs to evolve?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build new business models for messaging, social networking, news and information that donâ€™t rely on excessive data mining or hijacking our attention?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>What will the next evolution of the internet networkâ€™s architecture and infrastructure look like?  How can decentralized technologies move the internet further towards the edge and the people?</span></p></li></ul><p dir="ltr"><span>With missions that large, it may feel like we need to rewire everything... but getting started doesnâ€™t have to be overwhelming.</span></p><p dir="ltr"><span>So if you want to learn from our </span><a href="https://builders.mozilla.community/?utm_source=www.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=builders-redirect" target="_blank">amazing mentors</a> and founders, or if you're a startup and want to learn more about our $75k and $16k funding opportunities, <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">come join us at the event</a>!</p><p dir="ltr"><span>If you're also a concerned internet citizen, help us spread the word by sharing the event with one or two of your friends. </span></p><p dir="ltr"><span>We're also doing a giveaway on Twitter of our </span><a href="https://twitter.com/mozillabuilders/status/1319380829303238656" target="_blank">Mozilla Builders Fix-The-Internet swag box</a><span>. All you need to do is </span><a href="https://talium.co/doc/xboZza/s/I'm%20going,%20are%20you?%20%20On%20October%2029th,%20join%20@mozillabuilders%20and%20@mozilla%20CEO%20and%20Founder%20@MitchellBaker%20for%20their%20inaugural%20Fix%20the%20Internet%20Showcase%20to%20learn%20from%20entrepreneurs%20and%20mentors%20on%20how%20to%20build%20a%20better%20net%20for%20all!%20RSVP:%20https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">tweet this tweet</a>, and <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">RSVP for the showcase</a> <span>to be eligible to win.</span></p><p dir="ltr">See you at our Showcase!</p><p dir="ltr">p.s. this post was written on&nbsp;<a href="http://talium.co/" target="_blank">talium.co</a>, one of the awesome products from our Summer batch!</p></div></div>]]>
            </description>
            <link>https://talium.co/doc/xboZza/s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910188</guid>
            <pubDate>Tue, 27 Oct 2020 18:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OberonScript: a safe scripting language and runtime for web apps (2007)]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24909114">thread link</a>) | @lproven
<br/>
October 27, 2020 | http://www.ralphsommerer.com/obn.htm | <a href="https://web.archive.org/web/*/http://www.ralphsommerer.com/obn.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="flowhor">
  
  <div id="flowvert">
   
   <div id="mainbody">
       
<h2>OberonScript</h2>
<p>Oberon Script is a scripting language and runtime system for building interactive Web Client applications. It consists of a compiler that translates the full Oberon language into JavaScript code, and a small runtime system that detects and compiles at load-time script sections written in Oberon Script.</p>
<p>It is a complete re-implementation from scratch of an earlier compiler that I built
while being with <a href="http://research.microsoft.com/">Microsoft Research</a>
in <a href="http://en.wikipedia.org/wiki/Cambridge">Cambridge</a>. For legal reasons I was unable to take the code with me
but I cleared the code by MSR's legal department for publication via <a href="http://research.microsoft.com/research/downloads/default.aspx">Microsoft Research's code posting tool</a>.
However, I left MSR before completing the process, hence the complete rewrite.</p>
<h3>Code</h3>
<p>The code of the compiler is available in its current, far from final version in source code (obviously...) for personal,
non-commercial and non-governmental use. The usual disclaimers apply.</p>
<p>A very minimal documentation is also available. I may merge it some time with the prettyprinted HTML version below.</p>

<p>V2.0beta [<a href="http://www.ralphsommerer.com/oberon.js">JavaScript</a>] [<a href="http://www.ralphsommerer.com/oberon.js.htm">HTML</a> <small>color coded</small>] [<a href="http://www.ralphsommerer.com/obndoc.htm">Docu</a>] <small>July 6, 2007</small></p>

<h3>Presentations</h3>
<ul>
<li><a href="http://www.oberon-industry.ethz.ch/">Oberon Day 2007</a>, ETH Zürich, Switzerland, June 29, 2007</li>
<li>Joint Modular Languages Conference (<a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>), Oxford, UK, September 13-15, 2006</li>
</ul>
<h3>Publications</h3>
<p>Ralph Sommerer: 
<i>Oberon Script: A Lightweight Compiler and Runtime System for the 
Web</i>, Proceedings of the 7th Joint Modular Languages Conference, <a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>, Oxford, UK, September 13-15, 2006,
<a href="http://www.springer.com/dal/home/generic/search/results?SGWID=1-40109-22-173677107-0">LNCS Vol 4228</a>, Springer, 2006 
<small>[also available as <a href="http://research.microsoft.com/research/pubs/view.aspx?tr_id=1094">MSR 
Technical Report 2006-50</a>]</small> </p>

</div>
   
  </div>
 </div></div>]]>
            </description>
            <link>http://www.ralphsommerer.com/obn.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909114</guid>
            <pubDate>Tue, 27 Oct 2020 16:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing Teams client protocol to bypass Teams security policies]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24908776">thread link</a>) | @tommoor
<br/>
October 27, 2020 | https://o365blog.com/post/teams-policies/ | <a href="https://web.archive.org/web/*/https://o365blog.com/post/teams-policies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<figure>
				<img src="https://o365blog.com/images/posts/teams-policies.png" alt="Abusing Teams client protocol to bypass Teams security policies">
			</figure>
				<nav id="TableOfContents">
<ul>
<li><a href="#what-are-teams-policies">What are Teams policies?</a></li>
<li><a href="#bypassing-teams-policies">Bypassing Teams policies</a>
<ul>
<li><a href="#initial-discovery">Initial discovery</a></li>
<li><a href="#observing-teams-client-behaviour">Observing Teams client behaviour</a></li>
<li><a href="#testing-in-action">Testing in action</a></li>
</ul></li>
<li><a href="#detecting-and-protecting">Detecting and protecting</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References:</a></li>
</ul>
</nav>
			<p>Administrators can use teams policies for controlling what users can do in Microsoft Teams.</p>

<p>In this blog, I’ll show that these policies are applied only in client and thus can be easily bypassed.</p>





<p>Policies are used in Microsoft Office 365 and Azure AD for securing access to services and data. Besides the <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">common identity and device access policies</a>,
Microsoft has provided a set of <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Teams specific policies</a>:</p>

<ul>
<li>Teams and channel policies</li>
<li>Messaging policies</li>
<li>Meeting policies</li>
<li>App permission policies</li>
</ul>

<p>For example, administrators can configure Teams so that external users are not able to edit or delete any messages they’ve sent. Or, an owner of a Teams site can disable message editing for members of a certain channel.</p>



<h2 id="initial-discovery">Initial discovery</h2>

<p>While I was working with the previous version (v0.4.4) of <a href="https://o365blog.com/aadinternals" target="_blank">AADInternals</a> Teams functions I noticed an interesting thing: I was able to edit and delete chat messages using AADInternals as a guest
even when it was not allowed.</p>

<p>This led to a question that <strong>what if the policies are applied only at the client end?</strong> In practice this would mean that the Teams service tells to your Teams client that “Though shall not edit messages!” but the client
could still do so.</p>

<h2 id="observing-teams-client-behaviour">Observing Teams client behaviour</h2>

<p>I started by watching what was going on between the client and cloud when the Teams client started. The first observation was that the client made about 120 http requests to the cloud.
While browsing through those requests, I spotted one that caught my interest (headers stripped):</p>

<pre><code>POST https://teams.microsoft.com/api/mt/part/emea-02/beta/users/useraggregatesettings HTTP/1.1

{
    "tenantSettingsV2": true,
    "userResourcesSettings": true,
    "messagingPolicy": true,
    "clientSettings": true,
    "targetingPolicy": true,
    "tenantSiteUrl": true,
    "userPropertiesSettings": true,
    "callingPolicy": true,
    "meetingPolicy": true,
    "educationAssignmentsAppPolicy": true
}
</code></pre>

<p>The response contained all the settings and policies the Teams client is allowed to do as the logged in user. Below can be seen the <strong>messagingPolicy</strong> section:
</p><div><pre><code data-lang="json"><span></span><span>"messagingPolicy"</span><span>:</span> <span>{</span>
	<span>"value"</span><span>:</span> <span>{</span>
		<span>"allowUserEditMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserDeleteMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserChat"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowGiphy"</span><span>:</span> <span>true</span><span>,</span>
		<span>"giphyRatingType"</span><span>:</span> <span>"Moderate"</span><span>,</span>
		<span>"allowGiphyDisplay"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPasteInternetImage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowMemes"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowStickers"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserTranslation"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUrlPreviews"</span><span>:</span> <span>true</span><span>,</span>
		<span>"readReceiptsEnabledType"</span><span>:</span> <span>"UserPreference"</span><span>,</span>
		<span>"allowImmersiveReader"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPriorityMessages"</span><span>:</span> <span>true</span><span>,</span>
		<span>"audioMessageEnabledType"</span><span>:</span> <span>"ChatsAndChannels"</span><span>,</span>
		<span>"channelsInChatListEnabledType"</span><span>:</span> <span>"DisabledUserOverride"</span><span>,</span>
		<span>"allowRemoveUser"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowSmartReply"</span><span>:</span> <span>true</span>
	<span>}</span>
<span>}</span>
</code></pre></div>


<p>What we can learn here is that the Teams client asks from the cloud what the current user is allowed to do, which was the expected behaviour.</p>

<h2 id="testing-in-action">Testing in action</h2>

<p>Next I decided to try whether I could lie to Teams client:</p>

<ol>
<li><p>I saved the response from above to be used as a baseline.</p></li>

<li><div><p>I created a new Messaging policy to disable editing and deleting of sent messages.</p><p>
I applied the policy to a single demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies1.png" alt="Custom policy"></p><p>Now I had two policies, the default organisation wide and the restricted one for demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies2.png" alt="Policies"></p></div></li>

<li><p>I restarted the Teams client and noticed that the editing and deleting were correctly disabled (didn’t exists).</p></li>

<li><div><p>I compared the returned policies from the <strong>useraggregatesettings</strong> requests<br>
and as we can see, the request was missing two lines:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies3.png" alt="Policy comparison"></p></div></li>

<li><div><p>I closed the client and configured Fiddler to do an autoresponse using the saved http response from above:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies4.png" alt="Fiddler autoresponse"></p><p>
Now, when the client is requesting the settings file, it will be served the one that allows editing and deleting.</p></div></li>

<li><p>I started the Teams client and <strong>the editing and deleting were again allowed</strong> and I was able to edit and delete (my own) messages!</p></li>
</ol>

<p>What we can lean here is that <strong>we can lie to Teams client</strong> and change its behaviour 😂 <br>
Moreover, we learnt that <strong>Teams policies are applied only on the client</strong> 🤦‍♂</p>

<p>Here is the video demonstrating this with <strong>AADInternals</strong> and <strong>Fiddler</strong> (sorry for the bad audio after 03:20):</p>

<div><iframe width="560" height="315" src="https://www.youtube.com/embed/Zcqig-OyUMY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>

<p>Below is a video that shows in action that this works also with <strong>cloud file storage restrictions</strong>:<br></p>

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/a32TkLIBwS4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<br><strong>Note:</strong> Although not seen on the video, I was able to add my Google Drive account to Teams so this is not just a UI thing.</p>



<p>As far as I know, the “uncompliant” Teams client behaviour can not be detected.</p>

<p>Same verdict with protecting. Well, one could try to use Conditional Access (CA) with device ownership and compliance restrictions, but that doesn’t cover all scenarios.</p>



<p>Our little test here proves that <strong>Teams policies are applied ONLY on the client!</strong>.</p>

<p>If the user (or guest) is utilising Teams APIs directly, using for instance AADInternals <a href="https://o365blog.com/aadinternals/#teams-functions" target="_blank">Teams functionality</a>, he or she can bypass the restrictions set by the policies.
However, this is not a bug or vulnerability as such, but a (very very bad) design choice by Microsoft.</p>

<p>Users can do at least the following:</p>

<ul>
<li>Bypass messaging policies</li>
<li>Bypass cloud file storage restrictions</li>
<li>Bypass meetings policies</li>
</ul>

<p>⚠️ <strong>Teams policies are NOT a security measure and organisations should not rely on them!</strong> ⚠️</p>



<ul>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">Common identity and device access policies</a></li>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Policy recommendations for securing Teams chats, groups, and files</a></li>
</ul>
		</div></div>]]>
            </description>
            <link>https://o365blog.com/post/teams-policies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908776</guid>
            <pubDate>Tue, 27 Oct 2020 16:07:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Notion Landing Pages]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24906774">thread link</a>) | @saviorand
<br/>
October 27, 2020 | https://optemization.com/notion-landing-page-guide | <a href="https://web.archive.org/web/*/https://optemization.com/notion-landing-page-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="notion-landing-page-guide"><div id="4ef8369dd07944578af5ecae07585f8f"><div id="ec8a50571edc41dea01826949daf52b2"><p><span><span>We at Optemization know a thing or two about  Notion landing pages. In fact, Tem published the first Notion website back in March 2020 (oh, how the world has changed). </span></span></p><p><span><span>Thanks in large to awesome projects like Super and Fruition, building websites on Notion became easier and faster. </span></span></p><p><span><span>Given the surge in popularity, I deciced to pen this comprehensive guide and create some duplicable blocks, so you can create your own Notion website in no time — enjoy 🙌</span></span></p></div></div><h2><span id="cc149452e88b42e8b29622443a589d9c"></span><span><span>🔑 An overview of the guide</span></span></h2><div id="c496b9ce8126498e85222feb210e850b"><div id="4e7f6e020650473a8d103736b9068090"><p><span><span>Making a landing page with Notion is easy to the point of enjoyable — you don't need any coding skills at all. It's also flexible — you can mix, match, and style various blocks to get the look and feel needed to present your idea (or product) just the right way.</span></span></p><p><span><span>This guide will walk you through every step of setting up your landing with Notion, publishing it to the web, adding analytics and custom styling. As a cherry on top, we've also curated 10 ready-made components that you can use to get your Notion landing page out in no time.</span></span></p></div></div><h2><span id="4b158c7e538e49518051b4d9b3d1f780"></span><span><span>🎯 Setting your landing page goals</span></span></h2><p><span><span>Landing pages are the best way to "sell" something, to tell people about a specific product, service or a resource, and make them do a specific action. </span></span></p><p><span><span>When user does an action, this is called "conversion", and usually landing pages are fine-tuned to get as much conversions as possible. Conversions could be anything: from subscribing to a newsletter or joining a community, to buying a product or a service. Landing pages can be purely informational, too. </span></span></p><p><span><span>Think what's the purpose of your page, and what the user needs to do to contribute.</span></span></p><h2><span id="cbfc301b7d274e27a06afc720d7eb511"></span><span><span>🤔 Deciding on what to show on the landing page</span></span></h2><p><span><span>Defining your goal was the hard part — after you know what action you want the user to make, it's easy to define what to show on your landing. </span></span></p><p><span><span>If they're subscribing to a newsletter, tell what it's about. If the goal is to grow a community, tell about the people already there and show what's the purpose of this community. If you're selling a product, focus on the value it offers and on core functionality. Don't forget call-to-actions to let the user actually realize their interest when they're convinced.</span></span></p><p><span><span>Take a look at </span><span><a target="_blank" rel="noopener noreferrer" href="https://demandcurve.com/#1opac8uusrjldfqjb39wpp">Demand Curve</a></span><span>'s landing page, for example. </span></span></p><div id="54fa9f431f9a45fc970d6e7fc90bf338"><picture><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>They're advertising their start-up program, focusing on what the program is about, how it's structured and why people learn valuable things during that program. It's all there — right on the first screen you can see the bullet points describing what the program is about (Growth Strategy, Ads, etc.).</span></span></p><p><span><span>Demand Curve's team also put a special emphasis on social proof — there's a ton of different testimonials and stories from people on the page.</span></span></p><p><span><span>Sometimes short landing pages that span 1-2 screens have higher conversion that longer ones, that span 3 and more screens. When you need your user to perform a simple action, like sharing their email, a short page works better. Short landings also make more sense for "warm" clients who already know what you are offering.</span></span></p><p><span><span>Longer landings with lots of information work better for "cold" clients, because they need more context. After you have an idea on what size is appropriate in your case, you can start experimenting with content.</span></span></p><h2><span id="3812d49b74904f9d961961ff3c8b07b9"></span><span><span>🖋️ Adding some content</span></span></h2><p><span><span>On a typical landing page, the information is arranged into standard "blocks" with valuable information:  there's an eye-catching Hero image, simple text blocks describing your value proposition, a call-to-action that lets you collect interest, and a footer with terms. </span></span></p><p><span><span>Like on </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.refactoringgrowth.com/">Refactoring Growth</a></span><span>'s landing page, you have an elaborate introduction, several sections with a value proposition (simple text) block and a picture or a graphic, a pricing block and a Call-to-Action.</span></span></p><div id="c32142c387d44b52b7995b22ae6c17c9"><picture><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Optionally, you can add more useful stuff. It's a good idea to include social proof (which is very important for conversions and creates a sense of community around your value prop), juicy product shots or screenshots and a blog section linking to your posts somewhere else. </span></span></p><div id="d3e8989030c247cba938e6e513c95e1d"><picture><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500" alt="image" loading="lazy"></picture></div><h2><span id="f07e89f0db6c4c5188083b57316e7685"></span><span><span>🎁 Ready-made landing page blocks</span></span></h2><p><span><span>We've assembled some common sections in Notion so you can borrow them for your website.</span></span></p><p><span><span>Just open the component you like below, click on the bookmark, then click "Duplicate" and drag your component's page into any page you like. Select "Turn into", then "text". You've got your landing page! Add some space between the blocks, change the content and delete the toggle. Then customize it as you like.</span></span></p><p><span><span>Here's a 53-second demo: </span></span></p><p><span><span>Mix and match the blocks and add your own section to make your own converting landing page in 10 minutes.</span></span></p><h2><span id="dbfa3c0dca5f4aada94f5376166f8281"></span><span><span>🌐 Publish your page to the web </span></span></h2><p><span><span>It's easy to publish your page and make it accessible from a custom domain. 
We like two services: </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">Fruition</a></span><span> is free and open-source, while </span><span><a target="_blank" rel="noopener noreferrer" href="https://super.so/">Super</a></span><span> offers more functionality and better performance. </span></span></p><p><span><span>Fruition has a </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">very elaborate guide</a></span><span> right on their home page, and a </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=aw0x54PzCaI">video tutorial</a></span><span>, and Super gives a good onboarding when you sign up, leading you through all the necessary steps. 

</span><span><span>Here's a step-by-step to get you going on Super:</span></span></span></p><ol><li id="30fa5f0ef68b4ad79354c951f1b9aba1"><span><span>Sign up, select a plan (essentially boils down to how many sites you need, keep in mind that one site can have many subpages, like any website on the Web)
</span></span></li><li id="787193987a0b4c7c95437a027e1bd716"><span><span>Select whether you want to make a static website out of your page, or go with a default Notion-based method. 

First option offers great performance, but doesn't allow for filtered views and calendars on your page. 

Default Notion page is relatively poor in terms of performance and SEO, but all Notion functionality will work and it's still enough for simple personal websites or pages where you don't need fast loading.
</span></span></li><ol></ol><li id="e44a993f1fce466193429d780f87fd90"><span><span>Select your site name used in Super, a custom domain from a domain provider, and the URL to your original Notion page with the page set to public via the "Share" menu at the top ("Share" → "Share to the Web")
</span></span></li><li id="2aa6fd185ae9449084ed3674d150ac83"><span><span>Add one or more pretty URLs if you need them. By default, all the sub-pages you add inside your home page will have ugly Notion URLs. You can change that by providing links to sub-pages you want to add slugs to and specifying the slug (e.g. </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/preconceived">optemization.com/preconceived</a></span><span>)
</span></span></li><li id="ff4df464b80145149fe1675f38702e2b"><span><span>Add A and CNAME records to point Super to your domain name (Super provides these and you need to enter them in your domain provider's control panel). You can also provide an API Key if it's GoDaddy.</span></span></li><ol></ol><li id="52d2dce988b94c798bc7fafc30303552"><span><span>Enter your site's description, attach an image and an icon for social sharing. You can also select a custom font for your page's contents at this point.
</span></span></li></ol><p><span><span>Voila! The site should now be public. You're awesome.</span></span></p><h2><span id="728b3a07a7f3429b818b7992351d8dfa"></span><span><span>🔢 Add analytics</span></span></h2><p><span><span>With both Super and Fruition, you can inject your own Javascript into your page. This means you can use most of analytics solutions available.</span></span></p><p><span><span>For example, you can get your Fathom Analytics script to inject by going to Settings → Site → Site ID. Here's their own Fathom's </span><span><a target="_blank" rel="noopener noreferrer" href="https://usefathom.com/support/tracking">instruction</a></span><span>. Google Analytics also has a global site tag you can inject. </span></span></p><p><span><span>Both look like this (from Super's landing):</span></span></p><pre id="c777ed719650472ea7f2d1bb17322dd3"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://cdn.analytics.com"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span></code></pre></span></code></pre><p><span><span>After you copy and paste the script into the right field in Super or with Fruition, it should should auto-magically start collecting your stats and you'll be able to see them in your analytics dashboard. These are statistics we measure for </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/">optemization.com</a></span><span>:</span></span></p><h2><span id="4b1780ab79904f75abb4ecda48f54fd6"></span><span><span>✨Add styling </span></span></h2><p><span><span>In theory, with Super or Fruition you can style practically any part of your page. One of the simple things to do is to change default Notion colors. To change any color on your page just add a script (the same way you add an analytics script) that replaces Notion's CSS values.</span></span></p><p><span><span><a target="_blank" rel="noopener noreferrer" href="https://demo.super.so/guides/colors">Super</a></span><span> has a great mini-guide on doing that, below is the script with every default Notion color. Just replace the color you want to change with a HEX value (#000 for black, #fff for white) and delete the rest to change colors for a site hosted with Super (Fruition works the same way).</span></span></p><details id="cd15c584098c4a26b2e6aeadc95bd312"><summary><span><span>Notion's core colors (check the full list here: </span><span><span><a id="/fed8e0f6059d469fadaeeac47812b6e7" href="https://optemization.com/fed8e0f6059d469fadaeeac47812b6e7"><div><p><img src="https://super.so/icon/dark/hexagon.svg" alt="Notion Colors"></p><p><span><span>Notion Colors</span></span></p></div></a></span></span><span>)</span></span></summary><div><pre id="675898bed12c4045ac7bdd3c20ed3ae3"><code><span><pre><code><span>&lt;</span><span>style</span><span>&gt;</span><span>
</span><span>  </span><span>:</span><span>root </span><span>{</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>:</span><span> #</span><span>37352</span><span>f</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.6</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>gray</span><span>:</span><span> #</span><span>9</span><span>b9a97</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>brown</span><span>:</span><span> #</span><span>64473</span><span>a</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>orange</span><span>:</span><span> #d9730d</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>yellow</span><span>:</span><span> #dfab01</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>green</span><span>:</span><span> #</span><span>0</span><span>f7b6c</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>blue</span><span>:</span><span> #</span><span>0</span><span>b6e99</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>purple</span><span>:</span><span> #</span><span>6940</span><span>a5</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>pink</span><span>:</span><span> #ad1a72</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>red</span><span>:</span><span> #e03e3e</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>default</span><span>:</span><span> #fff</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>:</span><span> #ebeced</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>:</span><span> #e9e5e3</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>:</span><span> #faebdd</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>:</span><span> #fbf3db</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>:</span><span> #ddedea</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>:</span><span> #ddebf1</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>:</span><span> #eae4f2</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>:</span><span> #f4dfeb</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>:</span><span> #fbe4e4</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>235</span><span>,</span><span>236</span><span>,</span><span>237</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>229</span><span>,</span><span>227</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>250</span><span>,</span><span>235</span><span>,</span><span>221</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>243</span><span>,</span><span>219</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>237</span><span>,</span><span>234</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>235</span><span>,</span><span>241</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>234</span><span>,</span><span>228</span><span>,</span><span>242</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>244</span><span>,</span><span>223</span><span>,</span><span>235</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>228</span><span>,</span><span>228</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>default</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>206</span><span>,</span><span>205</span><span>,</span><span>202</span><span>,</span><span>0.5</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>gray</span><span>:</span><span> </span><span>hsla</span><span>(</span><span>45</span><span>,</span><span>2</span><span>%</span><span>,</span><span>60</span><span>%</span><span>,</span><span>0.4</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>brown</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>140</span><span>,</span><span>46</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>orange</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>245</span><span>,</span><span>93</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>yellow</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>168</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>green</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>135</span><span>,</span><span>107</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>blue</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>120</span><span>,</span><span>223</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>purple</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>103</span><span>,</span><span>36</span><span>,</span><span>222</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>pink</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>0</span><span>,</span><span>129</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>red</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>255</span><span>,</span><span>0</span><span>,</span><span>26</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>ui</span><span>-</span><span>hover</span><span>-</span><span>bg</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.08</span><span>)</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span></span><span>&lt;</span><span>/</span><span>style</span><span>&gt;</span></code></pre></span></code></pre></div></details><h2><span id="86c16edd25c04182b7d14ae872bed16d"></span><span><span>🍾 Add a pop-up Call-to-Action block</span></span></h2><p><span><span>We've made an opinionated CTA block you can use to ask your user to sign up at some point when they engage with the page. This one is shown 3 seconds after the page is opened (change the "3000" value inside the window.onload to adjust the duration).</span></span></p><div id="735cc70d16a944f19b754c5ed6b73d83"><picture><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Simply include the following script in your Super or Fruition "Inject scripts" section, similar to how you included analytics:</span></span></p><pre id="567243414569454490cb895f08584391"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://unpkg.com/sweetalert/dist/sweetalert.min.js"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>// Thanks Sweetalert for the alert! </span><span>
</span><span></span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>window</span><span>.</span><span>on…</span></code></pre></span></code></pre></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://optemization.com/notion-landing-page-guide">https://optemization.com/notion-landing-page-guide</a></em></p>]]>
            </description>
            <link>https://optemization.com/notion-landing-page-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906774</guid>
            <pubDate>Tue, 27 Oct 2020 12:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research team discovers breakthrough with potential to reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24906758">thread link</a>) | @elorant
<br/>
October 27, 2020 | https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary’s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer’s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer’s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>“The significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer’s disease benefits can’t be overstated,” says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer’s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer’s disease is driven by a vicious cycle of the protein amyloid β (Aβ) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn’t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen’s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer’s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>“We treated them for a month and the effect was quite amazing,” says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer’s disease. “We couldn’t tell the drug-treated disease models and the healthy models apart.” </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, noting the next step will be clinical trials in people.</span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906758</guid>
            <pubDate>Tue, 27 Oct 2020 12:32:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How you could have come up with Paxos yourself]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24906225">thread link</a>) | @todsacerdoti
<br/>
October 27, 2020 | https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html | <a href="https://web.archive.org/web/*/https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the field of computer science, the Paxos algorithm is notorious for how difficult it is to understand. I had to learn the Paxos algorithm in my distributed systems class. I even have "implemented" it by translating Leslie Lamport's TLA+ to Python. But I didn't understand it until much much later.</p>

<p>Now I have a better understanding of Paxos than I used to, I want to explain it to other people. Not because I'd like to help people, rather, I find that explaining things is a very good way to find blind spots in my own understanding.</p>

<p>So, where do we start? Personally, I dislike explanations that start with a step-by-step breakdown of the algorithm, followed by a proof of why those steps do what they claim to do. Instead, I much prefer to start with the problem the algorithm tries to solve, then iteratively come up with a solution together with the reader. So that's what I am going to do. And now you understand the title.</p>

<p><em>Small disclaimer:</em> The glossaries used in this article is different from what is commonly used for Paxos. I just picked the ones that made the most sense for my narrative.</p>

<h2 id="the-problem">The problem</h2>

<p>The distributed consensus problem is widely useful, so the reader probably doesn't need to be motivated. Here I will just simply state the problem.</p>

<p>There is a group of agents (let's call them $\sc{CLIENT}s$), who want to choose a number among their selections. Any number is fine, as long as everyone agrees on the same number.</p>

<p>Here, there are a few assumptions we will make to make this problem meaningful:</p>

<ul>
  <li>All the agents - including but not limited to the $\sc{CLIENT}s$, as we will add more types of agents later - are well-behaved. Meaning they all execute the prescribed algorithms faithfully, and don't maliciously try to trick other agents. (If you like jargons: Byzantine failures don't occur.)</li>
  <li>Agents can talk to each other by sending each other messages, but the messages they send to each other could take arbitrarily long before reaching their destination, and might get lost (but never altered).</li>
</ul>

<p>The agents could also "fail". However, failing is equivalent to all messages sent to/from that agent being lost forever. So whether we have this assumption or not won't change the algorithm we come up with.</p>

<p>Also, to not complicate things, we are only solving the "single-round" consensus problem in this article, meaning as the output of this algorithm, all of the $\sc{CLIENT}s$ will get a single number which they agree on.</p>

<h2 id="solution-searching-adventure">Solution searching adventure</h2>

<h3 id="iteration-0">Iteration 0</h3>

<p>When trying to solve a complex problem such as this one, it's usually a good idea to start by simplifying the problem.
As a start, let's just ignore the need to be reliable entirely.</p>

<p>If we throw reliability out the window, it should be easy to come up with a very simple solution: we add an agent (let's call it $\sc{COORDINATOR}$).
The $\sc{CLIENTS}$ send whatever number they pick to the $\sc{COORDINATOR}$ in a $\sc{PROPOSAL}(client_i, x)$ message, where $x$ is the number
proposed by the $i$-th $\sc{CLIENT}$. The $\sc{COORDINATOR}$ picks an arbitrary proposal (say, $x'$),
and informs the other $\sc{CLIENT}s$ about this decision.
Specifically, the $\sc{COORDINATOR}$ will just reply with a $\sc{CHOSEN}(x')$ message to all the $\sc{PROPOSAL}(\ldots)$ messages it has
received and will receive.</p>

<p>If we assume no messages ever get lost, it is quite easy to see that every $\sc{CLIENT}$ will get a number. And because only one number is ever chosen, they will all get the same number.</p>

<p>It is also easy to see why this solution is impractical: it has a single point of failure. Once the singular $\sc{COORDINATOR}$ fails, no further progress can be made.</p>

<h3 id="iteration-1">Iteration 1</h3>

<p>To improve this almost looks easy at first glance: just add more $\sc{COORDINATOR}s$!</p>

<p>Sure, more $\sc{COORDINATOR}s$ would remove the single point of failure. However, if there are more than one $\sc{COORDINATOR}s$, they might individually make different decisions, which results in the $\sc{CLIENT}s$ having disagreement.</p>

<p>What if we let the $\sc{COORDINATOR}s$ reach an agreement among themselves before responding? But wait, doesn't that sound familiar? Having a group of agents reaching an agreement, that's exactly what we added the $\sc{COORDINATOR}s$ to solve. We just made the problem cyclic.</p>

<p>Let's take a step back. Is there a way for the clients to reach an agreement without having the $\sc{COORDINATOR}s$ communicate with each other?</p>

<p>In other words, among the decisions of the $\sc{COORDINATOR}s$, is there an deterministic algorithm to pick out a specific one that is robust against message losses?</p>

<p>This might sound hard, but it's actually quite simple: pick the decision that is backed by more than half of the $\sc{COORDINATOR}s$.</p>

<p>There can't be two decisions both with more than half of the $\sc{COORDINATOR}s$ backing them; and if a decision doesn't have that many $\sc{COORDINATOR}s$ backing it, it won't appear to have more backing $\sc{COORDINATOR}s$ through message losses.</p>

<p>Since this approach resembles a majority vote, let's call $\sc{COORDINATOR}$ decisions $\sc{VOTE}(coord_i, x)$ from now on, where $x$ is the number picked by the $i$-th $\sc{COORDINATOR}$. Each $\sc{COORDINATOR}$ has a single vote, because each of them only makes a single decision.</p>

<p>Obviously, our solution cannot be infinitely reliable. If more than half of the $\sc{COORDINATOR}s$ went down, there will never be a majority reached. But this is already vastly better than our first solution, and the reliability scales with the number of $\sc{COORDINATOR}s$. So we will call it good enough.</p>

<p>Sadly, this solution doesn't actually work: there might not be a majority at all! For example, it's possible that three of the proposals each get a third of the votes. We would have a stalemate in that case.</p>

<h3 id="iteration-2">Iteration 2</h3>

<p>Again, a solution seems straightforward: just try again in case of a stalemate.</p>

<p>But then again, things aren't that simple.</p>

<p>First of all, the $\sc{COORDINATOR}s$ need to be made aware of a retry. Otherwise, because each $\sc{COORDINATOR}$ only has one vote, they won't be able to vote again even if the $\sc{CLIENT}s$ retry.</p>

<p>To do that, we attach an attempt id to all the messages sent. i.e. $\sc{PROPOSAL}(client_i, x)$ becomes $\sc{PROPOSAL}(\#attempt, client_i, x)$, and so forth. Each time a $\sc{CLIENT}$ retries, it bumps $\#attempt$ to the maximum $\#attempt$ it knows of plus 1. And the $\sc{COORDINATOR}s$ should only responds to messages with the most recent $\#attempt$.</p>

<p>Hopefully the intent of the $\#attempt$ number is clear. (<a href="https://github.com/yshui/explain-algorithms/issues/new">Let me know</a> if not.)</p>

<p>Are we good now? Unfortunately, no. Consider this scenario:</p>

<p>There were 2 clients. They proposed their numbers, the $\sc{COORDINATOR}$ voted on them and all agreed on a single number, $x_1$, all is good. But, all of the $\sc{VOTE}(\ldots)$ messages got lost on the way to $client_2$, while $client_1$ received all of the messages just fine. At this point, $client_1$ thought $x_1$ is the number, but $client_2$ went on to retry. The $\sc{COORDINATOR}s$ voted again, and got $x_2$. This time, all the messages sent to $client_1$ got lost.</p>

<p>And behold, we got the two clients to disagree.</p>

<p>There is an important insight to be had here. Whenever a $\sc{COORDINATOR}$, say $coord_i$, sends out a $\sc{VOTE}(\ldots, coord_i, x)$, there is a chance that some $\sc{CLIENT}$ would adopt $x$. If $coord_i$ ever sends out two votes with different $x$, there is a chance that some of the $\sc{CLIENT}s$ would disagree.</p>

<p>In other words, once a $\sc{COORDINATOR}$ has revealed its vote, it has to stick to it.</p>

<p>This seems to run contrary to our attempt: if the $\sc{COORDINATOR}s$ cannot change their votes, what's the point of retrying? A stalemate will be a stalemate forever.</p>

<p>Looks like we reached a dead end with this type of voting. It appears the problem stems from the fact that the $\sc{COORDINATOR}s$ have to commit to their votes.</p>

<p>So, what if we introduce a form of non-commitment voting?</p>

<h3 id="iteration-3">Iteration 3</h3>

<p>Let's explore this idea. Say, the $\sc{COORDINATOR}s$ could now send a $\sc{TENTATIVE}\sc{VOTE}(\#attempt, coord_i, x)$ message, to tentatively vote for $x$.</p>

<p>Obviously, the $\sc{CLIENT}s$ couldn't adopt $x$ right away. So what's this vote good for?</p>

<p>Ah, right, it could get us to a majority.</p>

<p>It is correct that tentative votes don't lead directly to an agreement among $\sc{CLIENT}s$, but it can show us when a majority has formed among the $\sc{COORDINATOR}s$.</p>

<p>Once a $\sc{CLIENT}$ sees a majority tentative vote, it can then message the $\sc{COORDINATOR}s$ to ask for an actual vote. (Let's call this message $\sc{PLEASE}\sc{VOTE}(\#attempt, client_i)$). Intuitively, the $\sc{COORDINATOR}s$ have to make the same vote in the actual vote as their tentative votes.</p>

<p>If all goes well, we would get a majority and an agreement. If there is no majority, the $\sc{COORDINATOR}s$ won't even start a vote, so they are free to change their mind. So the $\sc{CLIENT}s$ could start another attempt which might have a different outcome.</p>

<p>What if things don't go well? What if the $\sc{PLEASE}\sc{VOTE}$ messages weren't received by some of the $\sc{COORDINATOR}s$?
In that case, some of the $\sc{COORDINATOR}s$ would have voted, and their decisions cannot be changed. That is to say, in all subsequent attempts, these $\sc{COORDINATOR}s$ will always vote for what they have voted for, whether it's a tentative vote, or the actual vote. But that doesn't create a problem for us. There was a majority in the tentative votes, and now we solidified part of the tentative votes. There is at least one way we can still reach a majority in the next round: everyone votes the same as they did in this round. And we can prove this inductively for all future rounds.</p>

<p>From this, we can have a rough image of how the algorithm functions: as attempts are being made, more and more $\sc{COORDINATOR}s$ start to make up their mind which number they will commit to, while making sure a majority could still be reached. Eventually, …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</a></em></p>]]>
            </description>
            <link>https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906225</guid>
            <pubDate>Tue, 27 Oct 2020 11:06:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text layout is a loose hierarchy of segmentation]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24906010">thread link</a>) | @adamnemecek
<br/>
October 27, 2020 | https://raphlinus.github.io/text/2020/10/26/text-layout.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/text/2020/10/26/text-layout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I love text layout, and have been working with it in one form or other for over 35 years. Yet, knowledge about it is quite arcane. I don’t believe there is a single place where it’s all properly written down. I have some explanation for that: while basic text layout is very important for UI, games, and other contexts, a lot of the “professional” needs around text layout are embedded in <em>much</em> more complicated systems such as Microsoft Word or a modern Web browser.</p>

<p>A complete account of text layout would be at least a small book. Since there’s no way I can write that now, this blog post is a small step towards that – in particular, an attempt to describe the “big picture,” using the conceptual framework of a “loose hierarchy.” Essentially, a text layout engine breaks the input into finer and finer grains, then reassembles the results into a text layout object suitable for drawing, measurement, and hit testing.</p>

<p>The main hierarchy is concerned with laying out the entire paragraph as a single line of text. Line breaking is also important, but has a separate, parallel hierarchy.</p>

<h2 id="the-main-text-layout-hierarchy">The main text layout hierarchy</h2>

<p>The hierarchy is: paragraph segmentation as the coarsest granularity, followed by rich text style and BiDi analysis, then itemization (coverage by font), then Unicode script, and shaping clusters as the finest.</p>

<p><img src="https://raphlinus.github.io/assets/layout_pyramid.svg" alt="diagram of layout hierarchy"></p>

<h3 id="paragraph-segmentation">Paragraph segmentation</h3>

<p>The coarsest, and also simplest, segmentation task is paragraph segmentation. Most of the time, paragraphs are simply separated by newline (U+000A) characters, though Unicode in its infinite wisdom specifies a number of code point sequences that function as paragraph separators in plain text:</p>

<ul>
  <li>U+000A LINE FEED</li>
  <li>U+000B VERTICAL TAB</li>
  <li>U+000C FORM FEED</li>
  <li>U+000D CARRIAGE RETURN</li>
  <li>U+000D U+000A (CR + LF)</li>
  <li>U+0085 NEXT LINE</li>
  <li>U+2008 LINE SEPARATOR</li>
  <li>U+2009 PARAGRAPH SEPARATOR</li>
</ul>

<p>In rich text, paragraphs are usually indicated through markup rather than special characters, for example <code>&lt;p&gt;</code> or <code>&lt;br&gt;</code> in HTML. But in this post, as in most text layout APIs, we’ll treat rich text as plain text + attribute spans.</p>

<h3 id="rich-text-style">Rich text style</h3>

<p>A paragraph of rich text may contain <em>spans</em> that can affect formatting. In particular, choice of font, font weight, italic or no, and a number of other attributes can affect text layout. Thus, each paragraph is typically broken into a some number of <em>style runs,</em> so that within a run the style is consistent.</p>

<p>Note that some style changes don’t <em>necessarily</em> affect text layout. A classic example is color. Firefox, rather famously, does <em>not</em> define segmentation boundaries here for color changes. If a color boundary cuts a ligature, it uses fancy graphics techiques to render parts of the ligature in different color. But this is a subtle refinement and I think not required for basic text rendering. For more details, see <a href="https://gankra.github.io/blah/text-hates-you/">Text Rendering Hates You</a>.</p>

<h3 id="bidirectional-analysis">Bidirectional analysis</h3>

<p>Completely separate from the style spans, a paragraph may in general contain both left-to-right and right-to-left text. The need for bidirectional (BiDi) text is certainly one of the things that makes text layout more complicated.</p>

<p>Fortunately, this part of the stack is defined by a standard (<a href="http://www.unicode.org/reports/tr9/">UAX #9</a>), and there are a number of good implementations. The interested reader is referred to <a href="https://www.w3.org/International/articles/inline-bidi-markup/uba-basics">Unicode Bidirectional Algorithm basics</a>. The key takeaway here is that BiDi analysis is done on the plain text of the entire paragraph, and the result is a sequence of <em>level runs,</em> where the level of each run defines whether it is LTR or RTL.</p>

<p>The level runs and the style runs are then merged, so that in subsequent stages each run is of a consistent style and directionality. As such, for the purpose of defining the hierarchy, the result of BiDi analysis could alternatively be considered an implicit or derived rich text span.</p>

<p>In addition to BiDi, which I consider a basic requirement, a more sophisticated text layout engine will also be able to handle vertical <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/writing-mode">writing modes</a>, including mixed cases where short strings are horizontal within the vertical primary direction. Extremely sophisticated layout engines will also be able to handle ruby text and other ways of annotating the main text flow with intercalated strings. See <a href="https://www.w3.org/TR/jlreq/">Requirements for Japanese Text Layout</a> for many examples of sophisticated layout requirements; the scope of this blog post really is basic text layout of the kind needed in user interfaces.</p>

<h3 id="itemization-font-coverage">Itemization (font coverage)</h3>

<p>Itemization is the trickiest and least well specified part of the hierarchy. There is no standard for it, and no common implementation. Rather, each text layout engine deals with it in its own special way.</p>

<p>Essentially, the result of itemization is to choose a single concrete font for a run, from a <em>font collection.</em> Generally a font collection consists of a main font (selected by font name from system fonts, or loaded as a custom asset), backed by a <em>fallback stack,</em> which are usually system fonts, but thanks to <a href="https://www.google.com/get/noto/">Noto</a> it is possible to bundle a fallback font stack with an application, if you don’t mind spending a few hundred megabytes for the assets.</p>

<p>Why is it so tricky? A few reasons, which I’ll touch on.</p>

<p>First, it’s not so easy to determine whether a font can render a particular string of text. One reason is <a href="https://unicode.org/reports/tr15/">Unicode normalization</a>. For example, the string “é” can be encoded as U+00E9 (in NFC encoding) or as U+0065 U+0301 (in NFD encoding). Due to the principle of <a href="https://en.wikipedia.org/wiki/Unicode_equivalence">Unicode equivalence</a>, these should be rendered identically, but a font may have coverage for only one or the other in its <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cmap">Character to Glyph Index Mapping</a> (cmap) table. The shaping engine has all the Unicode logic to handle these cases.</p>

<p>Of course, realistic fonts with Latin coverage will have both of these particular sequences covered in the cmap table, but edge cases certainly do happen, both in extended Latin ranges, and other scripts such as Hangul, which has complex normalization rules (thanks in part to a Korean standard for normalization which is somewhat at odds with Unicode). It’s worth noting that <a href="https://devblogs.microsoft.com/oldnewthing/20201009-00/?p=104351">DirectWrite gets Hangul normalization quite wrong</a>.</p>

<p>I believe a similar situation exists with the Arabic presentation forms; see <a href="https://www.arabeyes.org/Developing_Arabic_fonts">Developing Arabic fonts</a> for more detail on that.</p>

<p>Because of these tricky normalization and presentation issues, the most robust way to determine whether a font can render a string is to try it. This is how LibreOffice has worked for a while, and in 2015 <a href="https://lists.freedesktop.org/archives/harfbuzz/2015-October/005168.html">Chromium followed</a>. See also <a href="https://www.chromium.org/teams/layout-team/eliminating-simple-text">Eliminating Simple Text</a> for more background on the Chromium text layout changes.</p>

<p><em>Another</em> whole class of complexity is emoji. A lot of emoji can be rendered with either <a href="https://en.wikipedia.org/wiki/Emoji#Emoji_versus_text_presentation">text or emoji presentation</a>, and there are no hard and fast rules to pick one or the other. Generally the text presentation is in a symbol font, and the emoji presentation is in a separate color font. A particularly tough example is the smiling emoji, which began its encoding life as 0x01 in <a href="https://en.wikipedia.org/wiki/Code_page_437">Code page 437</a>, the standard 8-bit character encoding of the original IBM PC, and is now U+263A in Unicode. However, the suggested default presentation is text, which won’t do in a world which expects color. Apple on iOS unilaterally chose an emoji presentation, so many text stacks follow Apple’s lead. (Incidentally, the most robust way to encode such emoji is to append a <a href="https://en.wikipedia.org/wiki/Variation_Selectors_(Unicode_block)">variation selector</a> to pin down the presentation.)</p>

<p>Another source of complexity when trying to write a cross-platform text layout engine is querying the system fonts. See <a href="https://raphlinus.github.io/rust/skribo/text/2019/04/04/font-fallback.html">Font fallback deep dive</a> for more information about that.</p>

<p>I should note one thing, which might help people doing archaeology of legacy text stacks: it used to be pretty common for text layout to resolve “compatibility” forms such as NFKC and NFKD, and this can lead to various problems. But today it is more common to solve that particular problem by providing a font stack with <em>massive</em> Unicode coverage, including all the code points in the relevant compatibility ranges.</p>

<h3 id="script">Script</h3>

<p>The <em>shaping</em> of text, or the transformation of a sequence of code points into a sequence of positioned glyphs, depends on the script. Some scripts, such as Arabic and Devanagari, have extremely elaborate shaping rules, while others, such as Chinese, are a fairly straightforward mapping from code point into glyph. Latin is somewhere in the middle, starting with a straightforward mapping, but ligatures and kerning are also required for high quality text layout.</p>

<p>Determining script runs is reasonably straightforward - many characters have a Unicode script property which uniquely identifies which script they belong to. However, some characters, such as space, are “common,” so the assigned script just continues the previous run.</p>

<p>A simple example is “hello мир”. This string is broken into two script runs: “hello “ is <code>Latn</code>, and “мир” is <code>Cyrl</code>.</p>

<h3 id="shaping-cluster">Shaping (cluster)</h3>

<p>At this point, we have a run of constant style, font, direction, and script. It is ready for <em>shaping.</em> Shaping is a complicated process that converts a string (sequence of Unicode code points) into positioned glyphs. For the purpose of this blog post, we can generally treat it as a black box. Fortunately, a very high quality open source implementation exists, in the form of HarfBuzz.</p>

<p>We’re not <em>quite</em> done with segmentation, though, as shaping assigns substrings in the input to <a href="https://harfbuzz.github.io/clusters.html">clusters</a> of glyphs. The correspondence depends a lot on the font. In Latin, the string “fi” is often shaped to a single glyph (a ligature). For complex scripts such as Devanagari, a cluster is most often a syllable in the source text, and complex reordering can happen within the cluster.</p>

<p>Clusters are important for <em>hit testing,</em> or determining the correspondence between a physical cursor position in the text layout and the offset within the text. Generally, they can be ignored if the text will only be rendered, not edited (or selected).</p>

<p>Note that these shaping clusters are distinct from grapheme clusters. The “fi” example has two grapheme clusters but a single shaping cluster, so a grapheme cluster boundary can cut a shaping cluster. Since …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/text/2020/10/26/text-layout.html">https://raphlinus.github.io/text/2020/10/26/text-layout.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/text/2020/10/26/text-layout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906010</guid>
            <pubDate>Tue, 27 Oct 2020 10:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics in Qt 6.0: QRhi, Qt Quick, Qt Quick 3D]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24905634">thread link</a>) | @MikusR
<br/>
October 27, 2020 | https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Monday October 26, 2020 by <a href="https://www.qt.io/blog/author/laszlo-agocs">Laszlo Agocs</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Last year we had a three part blog series about Qt's new approach to working with 3D graphics APIs and shading languages: <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-direct3d">part 1</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-2">part 2</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-3">part 3</a>. For <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-index.html">Qt Quick</a>, an early, opt-in preview of the new rendering architecture was shipped in Qt 5.14, with some improvements in Qt 5.15. With the release of Qt 6.0 upcoming, let's see what has happened since Qt 5.15. It will not be possible to cover every detail of the graphics stack improvements for Qt Quick here, let alone dive into the vast amount of Qt Quick 3D features, many of which are new or improved in Qt 6.0. Rather, the aim is just to give an overview of what can be expected from the graphics stack perspective when Qt 6.0 ships later this year.</p>
<p>Note that the documentation links refer to the Qt 6 snapshot documentation. This allows seeing the latest C++ and QML API pages, including all changed and new functions, but the content is also not final. These links may also break later on.</p>
<!--more-->
<h2>QRhi improvements</h2>
<p>QRhi, the Qt Rendering Hardware Interface, is Qt's internal graphics abstraction when 3D APIs, such as OpenGL, Vulkan, Metal, and Direct 3D, are involved. Compared to 5.15, the main improvements in 6.0 are a lot of polishing fixes here and there, and, most importantly, a large set of performance optimizations. While benefitting Qt Quick as well, these become especially important with Qt Quick 3D when complex scenes with many renderable objects are involved.</p>
<p>With some simplifications, the main layers of the Qt 6.0 graphics stack can be visualized like this:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png" alt="rhiarch-3" width="800" srcset="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=400&amp;name=rhiarch-3.png 400w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png 800w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1200&amp;name=rhiarch-3.png 1200w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1600&amp;name=rhiarch-3.png 1600w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2000&amp;name=rhiarch-3.png 2000w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2400&amp;name=rhiarch-3.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<h2>Shader management</h2>
<p>The Qt Shader Tools module is now a selectable module in the installer. For applications this can be relevant because this is the module that provides the <em>qsb</em> command-line tool (not to be confused with <em>qbs</em>) and its associated CMake build system integration. In addition, the module is a mandatory dependency for Qt Quick 3D at the moment.</p>
<p>Qt 6 no longer uses OpenGL-compatible GLSL source snippets directly. Rather, shaders are all written in Vulkan-style GLSL, then reflected and translated to other shading languages, and finally packaged up into a serializable QShader object that can be consumed by QRhi. The shader preparation pipeline in Qt 6 is the following:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png" alt="shaderconditioning" width="1280" srcset="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=640&amp;name=shaderconditioning.png 640w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png 1280w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1920&amp;name=shaderconditioning.png 1920w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=2560&amp;name=shaderconditioning.png 2560w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3200&amp;name=shaderconditioning.png 3200w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3840&amp;name=shaderconditioning.png 3840w" sizes="(max-width: 1280px) 100vw, 1280px"></p>
<p>In QML applications using Qt Quick, whenever working with ShaderEffect, or subclassing QSGMaterialShader, the application will need to provide a baked shader pack in form of a .qsb file. These are generated by the <em>qsb</em> tool. This does not however mean that developers have to start dealing with a new tool directly: with the CMake integration one can easily list the vertex, fragment, and compute shaders in CMakeLists.txt via the qt6_add_shaders() CMake function. Invoking qsb and packing the resulting .qsb files into the Qt resource system is then taken care of by the build system.</p>
<p>See <a href="https://doc-snapshots.qt.io/qt6-dev/qtshadertools-index.html">the shadertools documentation</a> for an overview of how graphics and compute shaders are handled in Qt 6 and the details of the qsb tool and its CMake integration.</p>
<h2>Direct OpenGL is no more for Qt Quick</h2>
<p>In Qt 5.14 and 5.15, Qt Quick shipped with an optional QRhi-based rendering path that could be enabled by setting the environment variable <em>QSG_RHI</em>. This allowed painless experimenting with the new stack, while keeping the traditional, battle tested direct OpenGL code path the default.</p>
<p>In Qt 6.0 all such switches are gone. There is no way get rendering go directly to OpenGL with Qt Quick scenes. Rather, the new default is the QRhi-based rendering path of the Qt Quick scene graph. Other than the defaults changing, the ways to configure what QRhi backend, and so which graphics API to use are mostly unchanged compared to Qt 5.15. See <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph-renderer.html#rendering-via-the-qt-rendering-hardware-interface">the documentation</a> for details. One difference is better API naming: in C++ code to request, and so effectively tie the application to, a given QRhi backend (and by extension graphics API) is now done through the <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#setGraphicsApi">QQuickWindow::setGraphicsApi()</a> function, whereas in 5.15 this task used to be pushed onto an overload of setSceneGraphBackend(), leading to fairly inaccurate naming.</p>
<p>There are a number of implications, although many applications will not notice any of these. If an application uses neither shader code (ShaderEffect, QSGMaterial) nor does it perform its own rendering with OpenGL directly, there is a very high chance that it will need no migration steps at all. (at least not because of graphics)</p>
<h4>Applications using OpenGL directly</h4>
<p>What about applications that use OpenGL directly in one way or another, and are not interested in functioning with other graphics APIs? For example, applications that use <a href="https://doc-snapshots.qt.io/qt6-dev/qquickframebufferobject.html">QQuickFramebufferObject</a>, or connect to signals like <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRendering">QQuickWindow::beforeRendering()</a> to inject their own OpenGL rendering under or above the Qt Quick scene. This is when the setGraphicsApi() function mentioned above comes into play for real: if an application wishes, it can always state that it wants OpenGL (or Vulkan, or Metal, or D3D) only, and nothing else. That way it is guaranteed that Qt Quick is going to use the corresponding QRhi backend (or else it will fail to initialize), so the application can safely assume that going directly to OpenGL is safe, because Qt Quick will also end up rendering through OpenGL. Note that this does not exempt the application from having to do other type of porting steps: for example, if it in addition uses ShaderEffect or creates its own custom materials, it will still need to migrate to the new ways of handling shaders and materials.</p>
<h4>QSG* and QQuick* API changes</h4>
<p>The API changes mainly fall into 3 categories. This is not going to be an exhaustive list, but rather just a peek at some of the important changes. Detailed change lists and porting guides are expected to be available with the final Qt 6.0 release.</p>
<ul>
<li>
<div><p>Different approach to shaders and materials: <a href="https://doc-snapshots.qt.io/qt6-dev/qsgmaterialshader.html">QSGMaterialShader</a> received a full revamp (matching more or less what the now-removed QSGMaterialRhiShader used to be in 5.14 and 5.15). <a href="https://doc-snapshots.qt.io/qt6-dev/qml-qtquick-shadereffect.html">ShaderEffect</a> no longer allows inline shader strings. Rather, the vertexShader and fragmentShader properties are URLs, similarly to <span>Image.source</span> and others. They can refer to a local .qsb file, or a .qsb file embedded via the Qt resource system (qrc).</p></div>
</li>
<li>
<p>Removing OpenGL-specifics from QQuickWindow, QSGTexture, and elsewhere. It should come as no surprise that functions like <em>GLuint textureId()</em>, <em>createTextureFromId(GLuint textureId, ...)</em>, or <em>setRenderTarget(GLuint fboId)</em> are now gone. Adopting (wrapping) an existing OpenGL texture, Vulkan image, Metal texture, or D3D11 texture, or accessing the underlying native texture for a QSGTexture is still perfectly possible, but now is done via a different set of APIs, such as <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qsgvulkantexture.html">QSGVulkanTexture</a> and the <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-sub-qtquick.html">other similar classes</a>, instances of which are <a href="https://doc-snapshots.qt.io/qt6-dev/qsgtexture.html?__hstc=233546881.8510e053e4fb66e1a58543a6e9886427.1603454017210.1603454017210.1603454017210.1&amp;__hssc=233546881.1.1603454017210&amp;__hsfp=1285229618#nativeInterface" rel="noopener">queryable from QSGTexure</a>.</p>
<ul>
<li>
<div><p>Integrating the application's own custom rendering with the graphics API that Qt Quick renders with is fully supported, not just for OpenGL, but also Vulkan, Metal, and D3D11. Due to their nature however, some of these APIs will need more than connecting to one single signal like beforeRendering() or afterRendering(). For example, we now also have <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRenderPassRecording">beforeRenderPassRecording()</a>. See the relevant section in the <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph.html#mixing-scene-graph-and-the-native-graphics-api">scenegraph overview docs</a> for more details and links to examples. Finally, the number of native graphics resources queryable via <a href="https://doc-snapshots.qt.io/qt6-dev/qsgrendererinterface.html">QSGRendererInterface</a> has been extended, now covering Vulkan, Metal, and Direct 3D too.</p></div>
</li>
</ul>
</li>
<li>
<p>Extending support for redirecting the Qt Quick scene into an offscreen render target. <a href="https://www.qt.io/blog/%3Ehttps://doc-snapshots.qt.io/qt6-dev/qquickrendercontrol.html">QQuickRenderControl</a> and the related infrastructure has been heavily enhanced. This was done not just to enable working with graphics APIs other than OpenGL the same way as in Qt 5 (for example, to render a Qt Quick scene into a Vulkan VkImage without an on-screen window), but also to enable integration with AR/VR frameworks and APIs such as <a href="https://www.khronos.org/openxr/">OpenXR</a> (in combination with any of Vulkan, D3D11, or OpenGL). Besides the slightly changed QQuickRenderControl interface, we now have a number of helper classes that improve the configurability of a QQuickWindow: <a href="https://doc-snapshots.qt.io/qt6-dev/qquickrendertarget.html">QQuickRenderTarget</a>, <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsdevice.html">QQuickGraphicsDevice</a>, and <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsconfiguration.html">QQuickGraphicsConfiguration</a>. These are essential in scenarios where a more fine grained control is needed: integrating with APIs like OpenXR is not always straightforward when an existing rendering engine is involved, with a number of potential chicken-egg problems when it comes to the creation, initialization, and ownership of instance, device, and other graphics objects: Which Vulkan instance should Qt Quick use, or should it create a new one upon initializing the scenegraph for the first time? Which Vulkan physical device or DXGI adapter should Qt Quick pick, or just stay with the default? Which VkDevice extensions should be enabled in addition to what Qt itself needs? What 2D image/texture should rendering target, who creates that and when? The expectation is that Qt 6.0 will be well-prepared and providing the foundations for further exploring the world of AR/VR during the rest of the Qt 6.x series.</p>
</li>
</ul>
<h4>New approach to handling shader code in ShaderEffect</h4>
<p>A comprehensive example of the new approach to shader code in ShaderEffect is the Qt 6 port of the classic Qt 5 Cinematic Experience demo. <a href="https://github.com/alpqr/qt5-cinematic-experience" rel="noopener">(GitHub repo)</a> This version is ported to CMake and is fully functional with all graphics APIs, including all shader and particle effects.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png" alt="cinematic" width="702" srcset="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=351&amp;name=cinematic.png 351w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png 702w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1053&amp;name=cinematic.png 1053w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1404&amp;name=cinematic.png 1404w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1755&amp;name=cinematic.png 1755w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=2106&amp;name=cinematic.png 2106w" sizes="(max-width: 702px) 100vw, 702px"></p>
<p>Looking at the QML source code, for example the code for the <a href="https://github.com/alpqr/qt5-cinematic-experience/blob/master/content/CurtainEffect.qml" rel="noopener">curtain effect </a>shows that indeed it has all inline GLSL strings removed.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png" width="354" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=177&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 177w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 354w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=531&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 531w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=708&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 708w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=885&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 885w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=1062&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 1062w" sizes="(max-width: 354px) 100vw, 354px"></p>
<p>Instead, the vertex and fragment shaders now live as <a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener">ordinary files in the source tree</a>, not bundled with the application executable anymore.</p>
<p><a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener"><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png" width="300" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=150&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 150w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 300w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=450&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 450w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=600&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 600w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=750&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 750w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=900&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 900w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>It is now up to the build system and Qt Shader Tools to compile, reflect, and translate at build time - with the added benefit of shader compilation errors becoming proper build errors instead of …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905634</guid>
            <pubDate>Tue, 27 Oct 2020 09:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga 1000 Phoenix Project]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905247">thread link</a>) | @retrohax
<br/>
October 27, 2020 | https://retrohax.net/amiga-1000-project-phoenix-motherborad/ | <a href="https://web.archive.org/web/*/https://retrohax.net/amiga-1000-project-phoenix-motherborad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11666">

<div>
<p>… or failures are your friends :&gt;</p>
<p>&lt;INTRO&gt;</p>
<figure><img src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>&lt;/INTRO&gt;</p>
<p>The story behind this whole post is a bit lengthy but I’ll try to be brief 🙂</p>
<p>In August of 2019, I’ve received an email from MrTrinsic. Back then, I didn’t yet know what is coming lol.</p>
<p>It turned out that MrTrinsic is a great Amiga enthusiast and he’d asked me to work on his Amiga 1000 … but no on a standard A1000 but with an Amiga 1000 Phoenix motherboard!</p>
<p>Amiga 1000 Phoenix Enhanced mobo is an extremely rare motherboard replacement for Amiga 1000. Some people think there were no more than 200 units manufactured, others say it was no more than 2000. I’ve no idea either but still, it is very rare so a magic smoke is not an option lol.</p>
<p>This motherboard is an awesome hack in itself and that is why MrTrinsic refers to it as DIVA 😀</p>
<p>Let me quote an excerpt from one of emails.</p>
<p><em>You should mention or point out more clearly that the Phoenix Board is a … DIVA!<br>It is a hack. Just look at the manual what kind of things you can modify and what kind of headers there are to change stuff.<br>The price is that it has an extremely bad signal quality. Plus, it lacks the Buster-Chip that the Amiga 2000 has.<br>The Phoenix is a bad version of the original A2000 from Braunschweig, which in itself was a hacked and beefed-up version of the A1000.<br>Plus, the Phoenix only has two layers. It’s a nightmare as we have seen.</em></p>
<p>It simply always has some problems like stability and compatibility issues which I’ve tried to sort out.</p>
<p>Phoenix mobo was developed in 1989/1990 by our fellow friends from Australia and was one of the very first crowd-funding campaigns! You can read/watch more on one of my fav websites -&gt; <a rel="noreferrer noopener" href="https://www.amigalove.com/viewtopic.php?t=476" target="_blank">www.amigalove.com</a></p>
<p>Hardware specs are available here -&gt;<a rel="noreferrer noopener" href="https://amiga.resource.cx/exp/phoenix" target="_blank"> amiga.resource.cx</a></p>
<h4>The plan</h4>
<p>Initially, MrTrinsic asked me to work on some external floppy replacements by Dell which I will cover in another post. Once I’ve figured out that floppy drive issue he’d decided we should start working on The Phoenix project.</p>
<p>At first, he’d send me a large box with gear that he wanted to have in this Amiga. I was like OMG! Not only Phoenix but the whole large project was about to begin!</p>
<p>The plan was to run lots of modern hardware add-ons with Amiga 1000 Phoenix and later try to squeeze it into a nice looking case, plus make it alive and stable.</p>
<p>The first package arrived and I was really excited by what I’ve seen.</p>
<p>Amiga 1000 Phoenix in an A1000 case with lots of mods and hacks already installed, plus, tons of other hardware mods still in boxes … and that was only for starters …</p>
<figure><img src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, the original plan was to MAKE Amiga 1000 Phoenix GREAT AGAIN!</p>
<p>Jokes aside, the main goal was to run a graphics card along with <a href="http://wiki.icomp.de/wiki/ACA500plus" target="_blank" rel="noreferrer noopener">ACA500plus</a> + <a href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank" rel="noreferrer noopener">ACA1233n</a> accelerator card by iComp</p>
<p>On top of tons of other minor hardware mods, He’d also sent me two graphic cards – <a rel="noreferrer noopener" href="https://shop.mntmn.com/products/zz9000-for-amiga-preorder" target="_blank">ZZ9000 by MNT</a> and GBAPII++ by KryoFlux.</p>
<figure><img src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Running it</h4>
<p>First things first. Phoenix motherboard is so rare that I first had to learn how it works and how it is all connected etc.</p>
<p>As it gave me a black screen at the very first run, I had to start learning about jumper settings and the board in general</p>
<p>Below, you can see a block diagram of particular parts location to give you an idea of what is where.</p>
<figure><img src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I would not move on quickly without MrTrinsics support. He’d pointed me to several sites and sent over some more info about the board itself. One of the most important documents I’ve received was <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/phoenix_jumpers_english.pdf" target="_blank">the jumper settings file</a> along with the <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/Phoenix.pdf" target="_blank">original manual</a>.</p>
<p>The above documents gave me the general idea of how things should work. The very first thing that I did was the removal of all added mods. I’ve then tried to run the A1K but still no luck – black screen. MrTrinsic then pointed me to jumper L35 which could cause such behavior if set incorrectly and bingo! It worked! </p>
<p>Since Phoenix has slots for more than one ROM chip, it is possible to install three KickStarts – 1.3. and 3.1 and third as a custom option. That was already done, along with a switch hack.</p>
<figure><img src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The problem was that Amiga wasn’t starting every single time. Instead, it booted every couple of times. My next move was to take it out and try running it outside of the case. This is where I’ve started noticing all the awesome texts on the PCB itself. I took PCB out started shooting pics of those texts and greetz for various hackers of that era.</p>
<figure><img src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Next, I’ve checked for any obvious problems and when I was happy with this inspection, I’ve put it back to a case to simply avoid any accidental short circuits caused by beer-drinking ;P</p>
<p>I’ve decided that I will try to run it with only Indivision ECS2, and KryoFlux GBAPII++ inserted.</p>
<p>I’ve then located the switch setting for the first ROM and put an awesome<a href="http://www.diagrom.com/" target="_blank" rel="noreferrer noopener"> DiagROM by John “<em>Chucky</em>” Hertell</a> in a socket. Yeah, I know, it is a quite a large resistor ;P</p>
<figure><img src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked flawlessly and I was greeted by a known diag info and a menu a bit later.</p>
<figure><img src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Once it worked, I’ve figured that it might be as simple as a flaky ROM socket problem. I’ve put a 2.0 ROM in the place of DiagROM and Viola! It works!</p>
<figure><img src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>When I’ve figured that part out, I could move on and start working on the alternative power supply which was …</p>
<h4>HDPLEX + Uber nice Amiga adapter</h4>
<p>MrTrinsic sent me this HQ HDPLEX Pico PSU but he’d also sent me a very cool DIY KIT – ATX2.0d-Amiga adapter which has super cool features like over-voltage/current protection outputs all needed voltages, and has additional floppy power outputs. Moreover, it generates a TICK signal which is good to have for testing.</p>
<p>However, it was a DIY KIT so I had to solder it all up first.</p>
<figure><img src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Combined together, it created an awesome and stable power source for this Amiga project.</p>
<figure><img src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>All I needed to do next was to prepare all the wiring. That was a trivial job after taking some measurements. I’ve used wires from my Nissan Patrol spare wiring kit as these are thick (copper) and nice, hence the color mismatch ;P</p>
<figure><img src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>It worked like a charm so now I had two working power supplies – original and superior to it HDPLEX with a kickass adapter.</p>
<h4>030 cards</h4>
<p>The next step was about adding 68030 CPU to the system. I had two options as MrTrinsic sent me two different solutions.</p>
<p>The First solution was an <a rel="noreferrer noopener" href="https://icomp.de/shop-icomp/en/produkt-details/product/ACA500plus.html" target="_blank">ACA500plus</a> card along with <a rel="noreferrer noopener" href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank">an ACA1233n</a> accelerator card by Individual Computers. ACA500plus also had an Ethernet add-on – X-Surf 500</p>
<p>These two make a great solution but for AMIGA 500. There are not many folks out there who played it with it in an A1000 and especially with a Phoenix mobo!</p>
<figure><img src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The first run was promising …</p>
<figure><img src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve added ACA1233n on an EXTREMELY WANTED DURING PANDEMIC stand 😀 😀 😀</p>
<figure><img src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked!</p>
<figure><img src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Below, a demo running on this setup</p>
<figure><p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/PJYyBRBnhu8?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<p>The second setup was a bit different. It is made of four devices.</p>
<ul><li>Open 68000 relocator card</li><li>68030 accelerator card </li><li>SDRam + IDE interface</li><li>IDE2CF interface</li></ul>
<p>This setup also appeared to be working nicely after some tests, however as MrTrinsic pointed out, it has some stability issues and will not allow running some software so it was a backup card in case ACA failed. I don’t have a video of it running though.</p>
<figure><img src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Other mods and add-ons</h4>
<p>Once accel-cards were tested, I’ve started installing OS and testing other mods. To name the few:</p>
<ul><li>X-surf 500 Ethernet card</li><li>RapidRoad USB</li><li>Indivision ECS v2</li><li>SCSI2SD </li><li>KryoFlux GBAPII++</li></ul>
<figure><img src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Indivision ECS v2 and SCSI2SD worked flawlessly so I started playing with other gear.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>After installing all the needed software I’ve finally managed to get an IP addr from my local DHCP server</p>
<figure><img src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, I wouldn’t be myself if I didn’t destroy something. I’ve accidentally connected the RapidRoad USB module to a clock port the other way around. The magic smoke appeared and…</p>
<figure><img src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I had to fix it. After a while, it turned out that only 3R3 resistor was fried.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>I’ve quickly replaced it and started testing USB functionality.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>GFX cards</h4>
<p>Once all other major mods were working more or less correctly, I could start testing GFX cards high-res modes.</p>
<p>This is where it all started to go wrong …</p>
<p>I had two cards to test with this setup – GBAPII++ by Kryoflux and ZZ9000 by MNT. </p>
<p>GBAPII++ worked nicely only with green 030 cards, but in such config, there would be no Ethernet card.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve tried running ZZ9000 along with green 030 and ACA cards but I’ve encountered autoconfig problems.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Finally, I’ve focused on ACA500plus with ACA1233n and I just couldn’t make it work. </p>
<p>When ACA was inserted then GBAPII++ was completely invisible to the system.</p>
<p>After updating tons of libraries, firmware and reinstalling OS a few times without any luck, we’ve figured out that it might be a power issue. MrTrinsic ordered an adapter for A500 which would allow pumping in more power.</p>
<p>I’ve first tested it with a stock A500.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Same story, GBAPII++ was invisible but I’ve checked it with A1K and power injector adapter just to be sure … unfortunately no luck again.</p>
<figure><img src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Unfinished 🙁</h4>
<p>I’ve invested weeks of time into this GFX problem research but finally, I had to give up on this project for now. It is still in an unfinished state until we will find a solution to all problems. The project is partially done but it requires more work and I hope to cover it someday in one of the future posts making Amiga 1000 Phoenix great again!</p>
<p>But worry not, this gave birth to a new project which is even more awesome.</p>
<p>Currently, it is a work-in-progress but that is a story for another blog post 🙂</p>
<figure><img src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>OUTRO</h4>
<p>If any of my readers know any solution, hints, or knows where I did mistakes, then please leave a comment here or on FB and Twitter pages.</p>
<p>If you want to get retro gear or hardware modules, please visit <a href="https://retrohax.net/shop/">our shop</a> -&gt; https://retrohax.net/shop/</p>
<p>Please support our work by commenting here and on our <a href="https://www.facebook.com/Retrohax.net">Facebook</a> and <a href="https://twitter.com/RetrohaxN">Twitter</a> pages.</p>
<p>If you want to donate a dead computer then <a href="https://retrohax.net/contact/">drop me an email</a>. Extreme cases are welcome 🙂</p>

 </div>

</article></div>]]>
            </description>
            <link>https://retrohax.net/amiga-1000-project-phoenix-motherborad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905247</guid>
            <pubDate>Tue, 27 Oct 2020 07:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rachel Whiteread’s House: why was this Bow landmark demolished? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905103">thread link</a>) | @BerislavLopac
<br/>
October 27, 2020 | https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/ | <a href="https://web.archive.org/web/*/https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			
<p>Every day people walk past Wennington Green, on the corner of Grove Road and Roman Road, without realising this was the spot on which stood Rachel Whiteread’s controversial inside-out concrete cast of an East End terraced house. Why was this Bow landmark demolished?</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house For Sale signs" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house For Sale © David Hoffman</figcaption></figure>



<h2>Wennington Green, Bow, London</h2>



<p>At the intersection of Roman Road and Grove Road lies Wennington Green – a patch of land in <a href="https://romanroadlondon.com/mile-end-park-history/" target="_blank" rel="noreferrer noopener">Mile End Park </a>principally sculpted by flying bombs. In fact, an English Heritage plaque on the railway bridge a little further down Grove Road commemorates the first one to strike London.</p>



<p>The blitz largely levelled the hundred or so turn-of-the-century terraces, common stock of the working class East End, on what is now the Green but up until the early ‘90s a row of dilapidated dwellings persisted. These residences were mostly derelict, abandoned and occasionally squatted, but for one, ex-docker Mr Sidney Gale of No. 193, a condemned house remained a home.</p>



<p>Indeed, in 1993, the final row was fated to be demolished as part of Tower Hamlet’s council’s plan to create a Green Corridor, unifying the broken line of parkland between the Isle of Dogs and the established lung of <a href="https://romanroadlondon.com/victoria-park-east-london-bow/">Victoria Park</a>. It was a means to cleanse the area of the legacy of prefabs that had homed the dislocated population post-war and a redemptive space for those in the high-rise accommodation which had replaced the traditional terraces. ‘What people who live in tower blocks want is parkland,’ declared Councillor Eric Flounders.</p>



<p>Yet psychogeographer Iain Sinclair was sceptical of the council’s motives, calling it ‘an Arcadia for the underclass… the whole scheme was a disinterested attempt at municipal aesthetics’. Pointedly, the area was in direct sight of Mrs Thatcher’s commerce baby, Canary Wharf, and the call for a Green was not a far cry from the original motivations to create Victoria Park, opened in 1845. Vicky Park is the oldest purpose built recreation ground in London, conceived to curb disease contracted in damp and cramped conditions and as a means harness working-class wildness. Indeed, Bow is an area rich with connotations of a strong working-class community, but also radicalism and revolt.</p>



<p>Mr Gale forcefully resisted eviction from No. 193 by the council for a number of years, even festooning the property with banners to affirm his unrelenting presence, but, realising his campaign was ultimately futile, he eventually yielded and was re-homed nearby. Gale’s loss was artist Rachel Whiteread’s gain. The practitioner had been seeking a condemned property in London for over two years to realise a project which was essentially a development upon her Turner Prize nominated sculpture, Ghost (1990); a room-sized cast of a bedsit contained in a Victorian property in Archway.</p>



<p>Whiteread, supported by art commissioners Artangel, approached the London Borough of Tower Hamlets&nbsp;council about utilising the property and the authorities duly consented. In the beginning, the council were of the opinion that, ‘It won’t cost the neighbourhood a penny and will provide an unusual landmark for the area,’ however, by the time the bricks were removed and the sculpture was exposed, Councillor Flounders, Chair of Bow Parks Board, denounced it as ‘excrescent.’</p>



<h2>Building Rachel Whiteread’s House</h2>



<figure><img loading="lazy" width="1024" height="692" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg" alt="Rachel Whiteread's House on Grove Road in Bow, photo by David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-300x203.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-768x519.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house view of Grove Road © David Hoffman</figcaption></figure>



<p>To make House, Whiteread used the physical house as&nbsp;a&nbsp;mould, making a cast from the interior by spraying a skin of liquid concrete around a metal armature constructed to support the weight of the work. Coating the whole house took over a month and an additional ten days were needed for the concrete to cure and set. Once solid, scaffolding was erected and Whiteread and her assistants began to remove the exterior brick structure.</p>



<p>What was revealed was an uncanny sight – the concrete impressed with the idiosyncrasies of over a century of domestic habitation. Depressions translated into protrusions; the industrial material betraying past human intimacies: soot marking the fire; yellow paint from a top-floor bedroom. The floors in-between stories could not be cast so, as local Markham Hall recalls, it resembled a ‘wedding cake.’ But the marriage at hand, between the art world and the East End, was to be short-lived and volatile.</p>



<h2>Reactions to Rachel Whiteread’s House</h2>



<p>It was essentially a neutral process, with no specific moral agenda, but Whiteread conceded ‘I knew of course, while I was making House, it had a political dimension. You can’t make a cast of a house in a poor area of London and not be political.’ Yet it became ‘far more political than I could have predicted.’ Seemingly, the council had also underestimated its resonance, as it quickly became front-page news, attracting scores of art-pilgrims and causing traffic chaos. Its status was even brought to debate in the House of Commons. The council couldn’t wait to get rid of the work fast enough, coming to regard it as a politically embarrassing monument to an impoverished history and standing in the way of the construction of a less threatening green space.</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house with Wot For Why Not graffiti © David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Wot For? Why Not? © David Hoffman</figcaption></figure>



<p>People reacted to House so strongly as it transcended the individual and became an archetype; an emblem for the area’s time-honoured mode of living. Indeed, it raised pressing questions regarding degrading housing stock and what should be done with it, the creeping gentrification of a historically tight working class community and scepticism towards the authority of those instigating change for the supposed ‘greater good’. In whose name was this change really for? And poignantly, it confronted these questions on its own material terms – concrete being the material used to fix the original Victorian House’s bricks; the embossed surface betraying the umbilical cords of pipes and power-lines which linked the individual house with the local, national and global public.</p>



<p>At base, Whiteread made an empty space, the negative void of the vacated property, into a positive object but insists ‘the work is to do with absence not presence.’ Implicitly, House was defined by the object it was not. When one refers to a ‘house’ we generally mean the façade as publicly viewed from the street, the interior is intimate – that is the home. Whiteread’s sculpture was resolutely an interior; an unsettling mass of inside, out.</p>



<p>The form elicited unease as when we have an intimate relationship with a space, we start to ignore its intricacies, instead handling navigating through the general form unconsciously. Thus, the sculpture was uncanny as it solidified the overlooked, demanding a long-looking, deep contemplation, as one attempted to decipher the inverted forms. Whiteread neglected to furnish her House with meaning but it was predominantly envisioned as what the populace of Bow would soon lose sight of. The interior, a family home, was left out in the cold and significantly, Whiteread chose not to cast the attic space, as if riffing on the idiom ‘left with no roof over their heads.’</p>



<p>It’s understandable then, that there was some resentment from locals towards House as they perceived it to be adding insult to injury over the demolition of such homes in the area, and a crassness in exposing working-class abode for the ‘arty’ leisure classes. Yet, this wasn’t just a case of Art World vs. East Enders, the opinions were split within both camps: in the Art World, Andrew Graham-Dixon proclaimed it ‘a strange and fantastical object which also amounts to one of the most extraordinary and imaginative public sculptures created by an English artist this century.’ To Brian&nbsp;Sewell, it was a ‘meritless gigantism.’ Sewell’s scorn found resonance in one local’s assertion that ‘an engineer could have done it; I don’t see it as creative.’ Whereas, another neighbour to the site regarded it as ‘brilliant,’ reckoning it to be ‘a new way of looking at traditional things.’</p>



<p>House’s evicted resident, Mr Gale, protested, ‘They’re taking the wee-wee.’ He questioned, ‘How can they get grants for arts projects when we can’t get grants for homes? I could have bought a new home for my family with this money.’ His sentiment was echoed in graffiti scrawled on the sculpture: ‘WOT FOR?’ Another renegade scribe rebuffing ‘Why not!’</p>



<p>House’s economics became even more contentious when Whiteread won the £20,000 Turner Prize for the work (the first woman to receive the honour), and then £40,000 from the rebel K Foundation (composed of members of the defunct pop group KLF) for the ‘worst artist of the year.’ Whiteread split the latter money between Shelter, a charity for the London’s homeless, and a fund to supplement young artists. On the same day, the&nbsp;Council made the decision to refuse House a stay of execution. By this time, many people (philanthropists, dealers, galleries) had offered to purchase House, but money offered to the Council to retain its presence was blasted by the authorities as ‘bribes.’ In any case, Whiteread was adamant that the sculpture was ‘absolutely specific to the site’ thus preferred its destruction to relocation.</p>



<p>The bulldozers came on January 11th 1994. The <em>East London Advertiser</em> reports that ‘art lovers’ chained themselves to the railings in attempt to save the work, quoting one as protesting, ‘We’re doing this because House represents the destruction of not only homes but whole communities in East London.’ Another suggested its removal was a sacrilegious act, perceiving House as ‘a headstone to the houses that were here.’ But the sculpture’s fate was sealed. As Whiteread succinctly mused ‘it took three and a half years to develop, four months to make, and thirty minutes to demolish.’</p>



<h2>The legacy of Rachel Whiteread’s House</h2>



<p>The Houseless Park has now had over 20 years to bed in to the community’s psyche and flourish naturally. In all of the articles and art history books I have trawled to substantiate …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</a></em></p>]]>
            </description>
            <link>https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905103</guid>
            <pubDate>Tue, 27 Oct 2020 07:21:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIOS: IBM 5150 BIOS Replacement Project]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24904148">thread link</a>) | @userbinator
<br/>
October 26, 2020 | http://www.mtmscientific.com/mios.html | <a href="https://web.archive.org/web/*/http://www.mtmscientific.com/mios.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.mtmscientific.com/mios.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904148</guid>
            <pubDate>Tue, 27 Oct 2020 03:09:44 GMT</pubDate>
        </item>
    </channel>
</rss>
