<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 30 Jul 2020 12:22:33 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 30 Jul 2020 12:22:33 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[WasmBoxC: Simple, Fast, and VM-Less Sandboxing]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23972929">thread link</a>) | @syrusakbary
<br/>
July 27, 2020 | https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html | <a href="https://web.archive.org/web/*/https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The software ecosystem has a lot of useful but unsafe code, and the easier it is to sandbox that code, the more
often that’ll happen. If it were as simple as passing the compiler a <code>--sandbox</code> flag
that makes an unsafe library unable to see or affect anything
outside of it, that would be incredible! We can’t get it quite that easy,
but this post describes <strong>WasmBoxC</strong>, a sandboxing approach that is
very simple to use. All you need to do is:</p>

<ul>
  <li><strong>Compile the unsafe library using a <a href="https://webassembly.org/">WebAssembly</a> (wasm) compiler instead of the normal system compiler</strong>.
That uses wasm internally, but you don’t need to care about that —
all you see is it emits a C file with sandboxed code.</li>
  <li><strong>Write some C to interface with the compiled C of the unsafe library</strong>. (This is
necessary because the sandboxed code can’t access outside memory, and also it
uses the portable wasm ABI.)</li>
</ul>

<p>Compile and link that C code, and now that unsafe library is sandboxed from the rest of your application!
In a later section we’ll see concrete examples of how easy both those steps are.</p>

<p>Here is the approach in more detail:</p>

<p><img src="https://kripken.github.io/blog/assets/wasmboxc.png" alt="unsafe code => safe wasm => safe c => safe native"></p>

<p>By <strong>compiling to wasm</strong> we sandbox the code, preventing it from accessing
anything on the outside.
That includes both <em>memory</em> - the sandboxed code can’t read or write to anywhere outside it -
and <em>capabilities</em> - the sandboxed code can’t do anything but pure computation,
unless you give it a function to call to do things like read from a file, tell
the time, etc.
We also get the rest of the wasm guarantees on
<a href="https://webassembly.org/docs/security/">safety</a> and
<a href="https://webassembly.org/docs/portability/">portability</a>. Wasm
sandboxing is even safe to run in the same process as other code (at least modulo
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre-type</a>
vulnerabilities), much like
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Software Fault Isolation (SFI)</a>.</p>

<p>After we’ve compiled an unsafe library to wasm, how can we run it as part of our
application?
We could integrate a wasm VM and run the wasm there. But instead,
with WasmBoxC we take a <strong>VM-less</strong> approach and compile the wasm into native
code, while preserving the wasm semantics, including the sandboxing.
That native code can be linked normally into an application, which
is much simpler than integrating a wasm VM.</p>

<p>The specific approach WasmBoxC takes to compile wasm into native code is to
<strong>compile it to C</strong> using
<a href="https://github.com/WebAssembly/wabt">wabt</a>’s
<a href="https://github.com/WebAssembly/wabt/tree/master/wasm2c">wasm2c</a> tool,
and then run a standard C compiler on it. In fact,
WasmBoxC’s approach compiles into a <strong>simple subset of C</strong>.
This is a big part of what makes this approach so simple, and
brings several advantages:</p>

<ul>
  <li>It’s easy to read and verify the generated C for security.</li>
  <li>It lets us use a C compiler like clang or gcc to make the sandboxed
code very fast.</li>
  <li>It’s very easy to use the code in existing build systems.</li>
  <li>It’s easy to write code to interact with the sandbox.</li>
  <li>A single build of C code can be compiled and run on practically any platform,
and code to interact with the sandbox also only needs to be written once.</li>
</ul>

<p>Despite the simplicity of using C, WasmBoxC sandboxing has low
overhead: just <strong>14%</strong> with some non-portable C code (the
“signal handler trick”, see later), or <strong>42%</strong> in 100% portable C
(with no OS- or CPU-specific operations at all). We’ll also see that there are options
in between those 14% and 42% numbers.</p>

<p>The basic idea in WasmBoxC is simple and
<a href="https://twitter.com/FlohOfWoe/status/1011523018428780544">not original</a>.
What is
new in this post is showing that the approach works, doing
benchmarking on real-world code to show it is fast, presenting complete examples of how
easy it is to sandbox real-world libraries, and writing up the approach in
detail to describe the benefits (see in particular the section on memory-safe
languages).
This post also invents a name for the technique.</p>

<h2 id="speed">Speed</h2>

<p>To get an idea of WasmBoxC’s speed, let’s take a look at
<a href="https://github.com/emscripten-core/emscripten/blob/master/tests/test_benchmark.py">20 benchmarks</a>,
comparing clang 9.0.1, clang 11 (dev version as of May 23 2020), gcc 9.2.1, and
WasmBoxC. All numbers are normalized to clang 9 (which is therefore equal to 1; lower numbers are better).</p>

<p><img src="https://kripken.github.io/blog/assets/wasmboxc-perf.png" alt="performance results"></p>

<table>
  <thead>
    <tr>
      <th>compiler</th>
      <th>relative speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>clang 9.0.1</td>
      <td>1.00</td>
    </tr>
    <tr>
      <td>clang 11 (dev)</td>
      <td>0.97</td>
    </tr>
    <tr>
      <td>gcc 9.2.1</td>
      <td>0.93</td>
    </tr>
    <tr>
      <td>WasmBoxC (explicit)</td>
      <td>1.42</td>
    </tr>
    <tr>
      <td>WasmBoxC (OS-based)</td>
      <td>1.14</td>
    </tr>
  </tbody>
</table>

<p>These benchmarks include a wide variety of code, and the ones prefixed with <code>zzz_</code> are real-world
codebases or benchmarks:
the 
<a href="https://box2d.org/">Box2D</a> and
<a href="https://en.wikipedia.org/wiki/Bullet_(software)">Bullet</a>
physics engines, the
<a href="https://en.wikipedia.org/wiki/Coremark">CoreMark</a> and
<a href="https://en.wikipedia.org/wiki/LINPACK_benchmarks">LINPACK</a>
benchmarks, the
<a href="https://www.lua.org/">Lua</a> VM (one GC and one computational benchmark),
the
<a href="https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Markov_chain_algorithm">LZMA</a>
and
<a href="https://zlib.net/">zlib</a>
compression libraries,
and the
<a href="https://www.sqlite.org/index.html">SQLite</a> database.
Incidentally, this shows WasmBoxC can run all of
these today!</p>

<p>Two results are shown for WasmBoxC, representing two implementations of memory sandboxing. The first is <strong>explicit</strong> sandboxing, in which each memory load and store is explicitly verified to be within the sandboxed memory using an explicit check (that is, an <code>if</code> statement is done before each memory access). This has <strong>42%</strong> overhead.</p>

<p>The <strong>OS-based</strong> implementation uses the
“<a href="https://github.com/WebAssembly/wabt/pull/1442/files#diff-e962256d2c336a13791ce03c1dae5d2fR106">signal handler trick</a>” that
<a href="https://hg.mozilla.org/mozilla-central/file/3334d8dff757051c7a359818e0ceb5ad7852fdbc/js/src/wasm/WasmSignalHandlers.cpp">wasm</a>
<a href="https://docs.google.com/document/d/17y4kxuHFrVxAiuCP_FFtFA2HP5sNPsCD10KEx17Hz6M/edit#heading=h.tbi7hpbheoai">VMs</a>
use.
This technique reserves lots of memory around the valid range and relies on
CPU hardware to give us a signal if an access is out of bounds
(for more background see section 3.1.4 in
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Tan, 2017</a>).
That is fully safe and has the benefit of avoiding explicit bounds checks. It has
just <strong>14%</strong> overhead! However, it cannot be used everywhere (it needs
signals and CPU memory protection, and only works on 64-bit systems).</p>

<p>There are more options in between those 14% and 42% figures.
Explicit and OS-based sandboxing preserve wasm semantics perfectly, that is, a trap
will happen exactly when a wasm VM would have trapped. If we are willing to relax
that
(but we may not want to <a href="https://github.com/WebAssembly/wabt/pull/1432">call it wasm</a> if we do)
then we can use masking sandboxing instead
(see section 3.1.3 in
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Tan, 2017</a>),
which is 100% portable like explicit sandboxing and also prevents any accesses
outside of the sandbox, and is somewhat faster at <strong>29%</strong> overhead. Other sandboxing
improvements are possible too - almost no effort has gone into this yet.</p>

<p>An interesting thing happens in the <code>lua_binarytrees</code> and <code>havlak</code> benchmarks,
where WasmBoxC is actually faster than both gcc and clang in all sandboxing modes,
up to 32%! How can we beat normal native builds, and by so much?
<a href="https://twitter.com/kripken/status/1262092956070109185">Looking into this</a>,
both of these benchmarks use a lot of <code>malloc</code>s and data structures with pointers.
Like the <a href="https://en.wikipedia.org/wiki/X32_ABI">x32 ABI</a>, wasm is 32-bit,
so pointers take half the space. Measuring the maximum process memory used
in <code>lua_binarytrees</code>, WasmBoxC uses 33% less which helps a lot with CPU cache usage.
While this makes a big difference on these two benchmarks, we are likely
getting some speedup on the others as well due to this factor, as on average x32
is faster than normal x64
<a href="https://en.wikipedia.org/wiki/X32_ABI#Details">by around 5-8%</a>.
Wasm is a nice way to get something
like x32’s benefits!</p>

<p>The benchmarking here measures performance <em>within</em> the sandbox. It
does not measure the speed of calls from the outside in or inside out. Such
calls can be very fast because the sandboxed code is just C, which means that
we can even inline across the sandbox boundary — safely! — if we do
LTO. I verified that happens in the sandboxing example in the next section,
see later. (Note, however, then using the signal handler trick may make things
more complicated here.)</p>

<p>Some final notes on performance:</p>

<ul>
  <li>
    <p>We can compile WasmBoxC’s C code with any native compiler. In the
above we did so always with clang 9 for simplicity. The results vary a little
when changing the compiler, for example the “explicit” sandboxing results go from
14% up to 16% with gcc 9.2 or down to 11% with clang 11. There’s nothing magical about
that 14% figure — we are at the point where native compiler differences matter.</p>
  </li>
  <li>
    <p>Results should improve over time as wasm adds more performance features
like <a href="https://github.com/WebAssembly/simd">simd</a> (note that the native compilers we
compared to may have gained an advantage from autovectorization).</p>
  </li>
  <li>
    <p>That WasmBoxC can reach 14% overhead shows that the
cost of compiling through wasm (which cannot represent irreducible control
flow, for example) is fairly low, and also that current compilers to wasm are
not introducing significant unnecessary overhead.</p>
  </li>
</ul>

<p>I’ve done my best to measure everything here carefully and accurately, but
it’s possible I’ve made a mistake somewhere. Please check my work and see if you
get similar results!</p>

<h2 id="ease-of-use">Ease of use</h2>

<p>This section has a full example of WasmBoxC usage. Here are the source files:</p>

<div><div><pre><code><span>// my-code.c</span>

<span>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>// We could also include the .wasm.h file for these,</span>
<span>// but let's declare externs manually for the example.</span>

<span>extern</span> <span>void</span> <span>wasmbox_init</span><span>(</span><span>void</span><span>);</span>

<span>extern</span> <span>uint32_t</span> <span>(</span><span>*</span><span>Z_twiceZ_ii</span><span>)(</span><span>uint32_t</span><span>);</span>

<span>extern</span> <span>uint32_t</span> <span>(</span><span>*</span><span>Z_do_bad_thingZ_ii</span><span>)(</span><span>uint32_t</span><span>);</span>

<span>int</span> <span>main</span><span>()</span> <span>{</span>
  <span>puts</span><span>(</span><span>"Initializing sandboxed unsafe library"</span><span>);</span>
  <span>wasmbox_init</span><span>();</span>
  <span>printf</span><span>(</span><span>"Calling twice on 21 returns %d</span><span>\n</span><span>"</span><span>,</span> <span>Z_twiceZ_ii</span><span>(</span><span>21</span><span>));</span>
  <span>puts</span><span>(</span><span>"Calling something bad now..."</span><span>);</span>
  <span>Z_do_bad_thingZ_ii</span><span>(</span><span>1</span><span>);</span>
  <span>puts</span><span>(</span><span>"(this will never be printed, as the bad thing will trap)"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p><code>main()</code> is pretty simple: Initialize, call something in the sandbox that does a
computation for us, and call something that will trap inside the sandbox.
(What’s with the <code>Z_</code> stuff? See later in “API”.)</p>

<div><div><pre><code><span>// unsafe-lib.c</span>

<span>#include &lt;stdlib.h&gt;
</span>
<span>__attribute__</span><span>((</span><span>used</span><span>))</span>
<span>int</span> <span>twice</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>{</span>
  <span>return</span> <span>x</span> <span>+</span> <span>x</span><span>;</span>
<span>}</span>

<span>__attribute__</span><span>((</span><span>used</span><span>))</span>
<span>int</span> <span>do_bad_thing</span><span>(</span><span>int</span> <span>size</span><span>)</span> <span>{</span>
  <span>// Allocate an unknown size here (so the LLVM optimizer doesn't know if the</span>
  <span>// store later down is valid or not).</span>
  <span>char</span><span>*</span> <span>x</span> <span>=</span> <span>malloc</span><span>(</span><span>size</span><span>);</span>
  <span>// Write to an address that is definitely not in the sandbox (the default</span>
  <span>// memory size is much smaller), which in wasm will trap.</span>
  <span>x</span><span>[</span><span>1024</span> <span>*</span> <span>1024</span> <span>*</span> <span>1024</span><span>]</span> <span>=</span> <span>42</span><span>;</span>
  <span>// Avoid the optimizer knowing the store can never be observed.</span>
  <span>return</span> <span>(</span><span>int</span><span>)</span><span>x</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><code>twice()</code> does what you’d expect, and <code>do_bad_thing</code> does a store that will
definitely trap. (Ignore the details there; for this example we need the LLVM optimizer not to
remove the bad code as undefined behavior!)</p>

<p>And here’s how easy it is to use WasmBoxC to get a fully sandboxed library linked with our normal code:</p>

<div><div><pre><code><span># build our main code to an object normally</span>
<span>$ </span>clang my-code.c         <span>-c</span> <span>-O3</span> <span>-o</span> my-code.o
<span># build the unsafe library to C with emcc</span>
<span>$ </span>emcc unsafe-lib.c          <span>-O3</span> <span>-o</span> unsafe-lib.wasm <span>-s</span> WASM2C <span>--no-entry</span>
<span># build the unsafe …</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html">https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html</a></em></p>]]>
            </description>
            <link>https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23972929</guid>
            <pubDate>Tue, 28 Jul 2020 06:34:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fewer premature babies born since Covid-19 lockdown]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 134 (<a href="https://news.ycombinator.com/item?id=23972152">thread link</a>) | @breitling
<br/>
July 27, 2020 | https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Doctors in countries&nbsp;including Denmark, Ireland, Australia, the U.S. and Canada&nbsp;have been reporting that fewer preterm babies are being born.</p><div><p><span><span><span></span><span>Dr. Belal Alshaikh says COVID-19 has brought a curious development to some maternity wards, and he is trying to help researchers from around the world find out why.<!-- --> <!-- -->4:35</span></span></span></p><p><span><p>Count this one as a positive side-effect of the COVID-19 pandemic.</p>  <p>Doctors in countries&nbsp;including Denmark, Ireland, Australia, the U.S. and Canada&nbsp;have been reporting that fewer preterm babies are being born.</p>  <p>While&nbsp;peer-reviewed studies investigating the drop&nbsp;are pending, and the downward&nbsp;trend across countries is currently anecdotal,&nbsp;Neonatologist Dr. Belal Alshaikh has been studying the possible&nbsp;phenomenon&nbsp;in Calgary.</p>  <p>"It's actually not that common to see this drop down in the numbers in many countries," said Alshaikh, who is&nbsp;also the medical director of the neonatal intensive care unit at the South Health Campus,&nbsp;and&nbsp;has seen the trend right here in Calgary.</p>  <p>Alshaikh told<em> <a href="https://www.cbc.ca/listen/live-radio/1-97-the-homestretch">The Homestretch</a></em> there are two ways to measure preterm birth — gestational age and actual birth weight. And by both measures, the numbers are dramatically lower.</p>  <p>Births considered very premature —&nbsp;born at fewer than 29 to 32 weeks&nbsp;— have&nbsp;dropped by&nbsp;34&nbsp;to 40 per cent, he said.</p>  <p>"If we use their gestational age and if we are talking about the very earliest preemies,"&nbsp;Alshaikh&nbsp;said.</p>  <p>"That's kind of dramatic, actually, and surprising for us."</p>  <p>The numbers are even more dramatic for babies under one kilogram.</p>  <p>"If we used birth weight, those babies born less than one kilo, the number was actually very low and half of what we used to see in the last few years, during the same period of time of the year."</p>    <p>Alshaikh said the trend is very unusual.</p>  <p>"Soon after the lockdown in mid-March, we started to see fewer babies coming to our unit and to intensive care units, and these numbers of preemies were also low in April and mid-May," Alshaikh said.&nbsp;</p>  <p>"So by that time, by late May, we felt like we needed to look at the numbers, and see where we are. And also at that time we started hearing that other hospitals, in Ireland and Denmark, have also noticed the drop down in the number of preemies."</p>  <p>When Calgary doctors took a good look at the numbers and compared them to the same time last year, it was an eyeopener.</p>  <p>"We were surprised," Alshaikh said. "We saw that our number is way lower than what we used to see during this period of time."</p>  <p>There are three main causes that doctors are looking at.</p>  <p>One is social distancing, which may have cut down on the amount of general infection from contact with others.</p>  <p>Another is less air pollution, from fewer cars being on the roads.</p>  <p>"This might actually help because studies in the past showed that air pollution actually increases the risk for preterm birth," Alshaikh said.</p>  <p>And simply not going out to work — resting — may be a final key.</p>  <p>"By staying home, a pregnant woman may have less stress from commuting and from work,&nbsp; and that might have helped them," Alshaikh said, adding it's too soon to know for sure which of these lockdown-related factors have contributed the most.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/premature-babies.jpg 300w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/premature-babies.jpg 460w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/premature-babies.jpg 620w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/premature-babies.jpg 780w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/premature-babies.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/premature-babies.jpg"></p></div><figcaption>Calgary doctors who noticed a reduced number of premature births during the pandemic lockdown, are seeing those numbers rise again as restrictions have eased.<!-- --> <!-- -->(Jim Lynch, Flickr cc)</figcaption></figure></span></p>  <p>&nbsp;"We see sometimes variation during the year, but it's not to the degree that we see fewer babies," Alshaikh said. "And the fact that we see the same trend in Ireland, in Denmark in Australia, it's kind of surprising for everyone working in this field."</p>  <p>Preterm birth comes with a host of challenges for the babies and their parents.</p>  <p>"The risk is high on children and their families, and also medical care resources," Alshaikh said. "For children, the risk increases for vision and hearing problems, and also for learning disability. It's higher even as the gestational age goes down. For example,&nbsp; 24 weeks is at very high risk compared to babies born at 28 weeks gestation or at 32 weeks gestation."</p>  <h2>Doctors teaming up to study</h2>  <p>The Calgary doctors will continue to study the phenomenon, which could hold clues to reducing preterm births in general.</p>  <p>For now, Alshaikh said it's too early to provide any specific advice to pregnant woman — other than to avoid stress, try to rest at home, get a lot of sleep&nbsp;and focus on good nutrition.&nbsp;</p>  <p>"We've teamed up, actually, with the teams across the world, in Ireland and also in Denmark, and there is also a group in Manitoba working on this project, and we are hoping to understand more the ways to prevent the preterm birth, and also like to see if we can understand more on risk factors that are affecting preterm birth," Alshaikh said.&nbsp;</p>  <p>But the Calgary doctor said there is one alarming development already —&nbsp;as the lockdown restriction ease, those preterm birth numbers are already on the rise again.</p>  <p>"We are actually noticing, even in Calgary, that when the restrictions started to be eased, the number of preterm babies coming to our unit and intensive care is going up again, which is quite actually interesting for us," Alshaikh said. "And we are trying to tease out what factors are affecting this trend."</p>  <p><strong>With files from <em><a href="https://www.cbc.ca/listen/live-radio/1-97-the-homestretch">The Homestretch</a></em>.</strong></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089</link>
            <guid isPermaLink="false">hacker-news-small-sites-23972152</guid>
            <pubDate>Tue, 28 Jul 2020 04:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Double-Entry Counting Method (2016)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23971567">thread link</a>) | @dragonsh
<br/>
July 27, 2020 | https://beancount.github.io/docs/the_double_entry_counting_method.html | <a href="https://web.archive.org/web/*/https://beancount.github.io/docs/the_double_entry_counting_method.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>

<p>Martin Blais, December 2016</p>
<p><a href="http://furius.ca/beancount/doc/double-entry"><span>http://furius.ca/beancount/doc/double-entry</span></a></p>
<p><a href="#introduction"><span>Introduction</span></a></p>
<p><a href="#basics-of-double-entry-bookkeeping"><span>Basics of Double-Entry Bookkeeping</span></a></p>
<blockquote>
<p><a href="#statements"><span>Statements</span></a></p>
<p><a href="#single-entry-bookkeeping"><span>Single-Entry Bookkeeping</span></a></p>
<p><a href="#double-entry-bookkeeping"><span>Double-Entry Bookkeeping</span></a></p>
<p><a href="#many-accounts"><span>Many Accounts</span></a></p>
<p><a href="#multiple-postings"><span>Multiple Postings</span></a></p>
</blockquote>
<p><a href="#types-of-accounts"><span>Types of Accounts</span></a></p>
<p><a href="#trial-balance"><span>Trial Balance</span></a></p>
<p><a href="#income-statement"><span>Income Statement</span></a></p>
<p><a href="#clearing-income"><span>Clearing Income</span></a></p>
<p><a href="#equity"><span>Equity</span></a></p>
<p><a href="#balance-sheet"><span>Balance Sheet</span></a></p>
<p><a href="#summarizing"><span>Summarizing</span></a></p>
<p><a href="#period-reporting"><span>Period Reporting</span></a></p>
<p><a href="#chart-of-accounts"><span>Chart of Accounts</span></a></p>
<blockquote>
<p><a href="#country-institution-convention"><span>Country-Institution Convention</span></a></p>
</blockquote>
<p><a href="#credits-debits"><span>Credits &amp; Debits</span></a></p>
<p><a href="#accounting-equations"><span>Accounting Equations</span></a></p>
<p><a href="#plain-text-accounting"><span>Plain-Text Accounting</span></a></p>
<p><a href="#the-table-perspective"><span>The Table Perspective</span></a></p>
<h2 id="introduction">Introduction<a id="introduction"></a><a href="#introduction" title="Permanent link"></a></h2>
<p>This document is a gentle introduction to the double-entry counting method, as written from the perspective of a computer scientist. It is an attempt to explain basic bookkeeping using as simple an approach as possible, doing away with some of the idiosyncrasies normally involved in accounting. It is also representative of how <a href="http://furius.ca/beancount/"><span>Beancount</span></a> works, and it should be useful to all users of <a href="http://plaintextaccounting.org/"><span>plain-text accounting</span></a>.</p>
<p>Note that I am not an accountant, and in the process of writing this document I may have used terminology that is slightly different or unusual to that which is taught in perhaps more traditional training in accounting. I granted myself license to create something new and perhaps even unusual in order to explain those ideas as simply and clearly as possible to someone unfamiliar with them.</p>
<p>I believe that the method of double-entry counting should be taught to everyone at the high school level everywhere as it is a tremendously useful organizational skill, and I hope that this text can help spread its knowledge beyond professional circles.</p>
<h2 id="basics-of-double-entry-bookkeeping">Basics of Double-Entry Bookkeeping<a id="basics-of-double-entry-bookkeeping"></a><a href="#basics-of-double-entry-bookkeeping" title="Permanent link"></a></h2>
<p>The double-entry system is just a simple <em>method of counting</em>, with some simple rules.</p>
<p>Let’s begin by defining the notion of an <strong>account</strong>. An account is something that can contain things, like a bag. It is used to count things, to accumulate things. Let’s draw a horizontal arrow to visually represent the evolving contents of an account over time:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/5b1da6643866c557b2a5ce687e70ee1db16b14de.png"></p>
<p>On the left, we have the past, and to the right, increasing time: the present, the future, etc.</p>
<p>For now, let’s assume that accounts can contain only one kind of thing, for example, <em>dollars</em>. All accounts begin with an empty content of zero dollars. We will call the number of units in the account the <strong>balance</strong> of an account. Note that it represents its contents at a particular point in time. I will draw the balance using a number above the account’s timeline:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/842dcb36da9e0e70c35d1023d65d8a571062baf0.png"></p>
<p>The contents of accounts can change over time. In order to change the content of an account, we have to add something to it. We will call this addition a <strong>posting</strong> to an account, and I will draw this change as a circled number on the account’s timeline, for example, adding $100 to the account:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/5e5e7897a346355eccd4d21ec9485c3464a2d996.png"></p>
<p>Now, we can draw the updated balance of the account after the posting with another little number right after it:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/0c8a78dac61ae7fddde25761f036e7f379cad247.png"></p>
<p>The account’s balance, after adding $100, is now $100.</p>
<p>We can also remove from the contents of an account. For example, we could remove $25, and the resulting account balance is now $75:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/98e314125325ecc72262a73a21b74db3200414fd.png"></p>
<p>Account balances can also become <em>negative</em>, if we remove more dollars than there are in the account. For example, if we remove $200 from this account, the balance now becomes $-125:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/bdc8a23347040de123e3359a7c8f0cc253c6d7d2.png"></p>
<p>It’s perfectly fine for accounts to contain a negative balance number. Remember that all we’re doing is counting things. As we will see shortly, some accounts will remain with a negative balance for most of their timeline.</p>
<h3 id="statements">Statements<a id="statements"></a><a href="#statements" title="Permanent link"></a></h3>
<p>Something worthy of notice is how the timeline notation I’ve written in the previous section is analogous to paper account statements institutions maintain for each client and which you typically receive through the mail:</p>
<table><thead><tr><th><em><strong>Date</strong></em></th><th><em><strong>Description</strong></em></th><th><em><strong>Amount</strong></em></th><th><em><strong>Balance</strong></em></th></tr></thead><tbody><tr><td>2016-10-02</td><td>...</td><td>100.00</td><td>1100.00</td></tr><tr><td>2016-10-05</td><td>...</td><td>-25.00</td><td>1075.00</td></tr><tr><td>2016-10-06</td><td>...</td><td>-200.00</td><td>875.00</td></tr><tr><td><em><strong>Final Balance</strong></em></td><td>875.00</td><td></td><td></td></tr></tbody></table>
<p>Sometimes the amount column is split into two, one showing the positive amounts and the other the negative ones:</p>
<table><thead><tr><th><em><strong>Date</strong></em></th><th><em><strong>Description</strong></em></th><th><em><strong>Debit</strong></em></th><th><em><strong>Credit</strong></em></th><th><em><strong>Balance</strong></em></th></tr></thead><tbody><tr><td>2016-10-02</td><td>...</td><td></td><td>100.00</td><td>1100.00</td></tr><tr><td>2016-10-05</td><td>...</td><td>25.00</td><td></td><td>1075.00</td></tr><tr><td>2016-10-06</td><td>...</td><td>200.00</td><td></td><td>875.00</td></tr><tr><td><em><strong>Final Balance</strong></em></td><td>875.00</td><td></td><td></td><td></td></tr></tbody></table>
<p>Here, “debit” means “removed from your account” and “credit” means “deposited in your account.” Sometimes the words “withdrawals” and “deposits” will be used. It all depends on context: for checking and savings accounts it is usual to have both types of postings, but for a credit card account typically it shows only positive numbers and then the occasional monthly payment so the single column format is used.</p>
<p>In any case, the “balance” column always shows the resulting balance <em>after</em> the amount has been posted to the account. And sometimes the statements are rendered in decreasing order of time.</p>
<h3 id="single-entry-bookkeeping">Single-Entry Bookkeeping<a id="single-entry-bookkeeping"></a><a href="#single-entry-bookkeeping" title="Permanent link"></a></h3>
<p>In this story, this account belongs to someone. We’ll call this person the <strong>owner</strong> of the account. The account can be used to represent a real world account, for example, imagine that we use it to represent the content of the owner’s checking account at a bank. So we’re going to label the account by giving it a name, in this case “Checking”:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/380ec8fea9ee9069411a61ccabcc838de44042ef.png"></p>
<p>Imagine that at some point, this account has a balance of $1000, like I’ve drawn on the picture. Now, if the owner spends $79 of this account, we would represent it like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b24d8c1e40edf6fd7e9d768ba8f0df279cd41f0e.png"></p>
<p>Furthermore, if the expense was for a meal at a restaurant, we could flag the posting with a <strong>category</strong> to indicate what the change was used for. Let’s say, “Restaurant”, like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/7ee843cd9b997a9447bb022d7d35121a820e296d.png"></p>
<p>Now, if we have a lot of these, we could write a computer program to accumulate all the changes for each category and calculate the sums for each of them. That would tell us how much we spent in restaurants in total, for example. This is called the <strong>single-entry method</strong> of accounting.</p>
<p>But we’re not going to do it this way; we have a better way. Bear with me for a few more sections.</p>
<h3 id="double-entry-bookkeeping">Double-Entry Bookkeeping<a id="double-entry-bookkeeping"></a><a href="#double-entry-bookkeeping" title="Permanent link"></a></h3>
<p>An owner may have multiple accounts. I will represent this by drawing many similar account timelines on the same graphic. As before, these are labeled with unique names. Let’s assume that the owner has the same “Checking” account as previously, but now also a <strong>“</strong>Restaurant<strong>”</strong> account as well, which can be used to accumulate all food expenses at restaurants. It looks like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/3c380375442a643877c59660832bd7df6192e9cb.png"></p>
<p>Now, instead of <em>categorizing</em> the posting to a “restaurant category” as we did previously, we could create a matching posting on the “Restaurant” account to record how much we spent for food, with the amount spent ($79):</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b86a7242b92effc613f88bc0cc70381d72e774f0.png"></p>
<p>The “Restaurant” account, like all other accounts, also has an accumulated balance, so we can find out how much we spent in “Restaurant” in total. This is entirely symmetrical to counting changes in a checking account.</p>
<p>Now, we can associate the two postings together, by creating a kind of “parent” box that refers to both of them. We will call this object a <strong>transaction</strong>:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b77efafcf2d6a6f1afbfb13da70be2f892b339b4.png"></p>
<p>Notice here that we’ve also associated a description to this transaction: “Dinner at Uncle Boons”. A transaction also has a <strong>date</strong>, and all of its postings are recorded to occur on that date. We call this the transaction date.</p>
<p>We can now introduce the fundamental rule of double-entry bookkeeping system:</p>
<pre><code>The sum of all the postings of a transaction must equal zero.
</code></pre>
<p>Remember this, as this is the foundation of the double-entry method, and its most important characteristic. It has important consequences which I will discuss later in this document.</p>
<p>In our example, we remove $79 from the “Checking” account and “give it” to the “Restaurant” account. ($79) + ($-79) = $0. To emphasize this, I could draw a little summation line under the postings of the transaction, like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b4182b9f64113868123cbcec20d468ab18b2786f.png"></p>
<h3 id="many-accounts">Many Accounts<a id="many-accounts"></a><a href="#many-accounts" title="Permanent link"></a></h3>
<p>There may be many such transactions, over many different accounts. For example, if the owner of the accounts had a lunch the next day which she paid using a credit card, it could be represented by creating a “Credit Card” account dedicated to tracking the real world credit card balance, and with a corresponding transaction:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/f85a66510ce2e3bb614edca76463a9c4752a7d26.png"></p>
<p>In this example, the owner spent $35 at a restaurant called “Eataly.” The previous balance of the owner’s credit card was $-450; after the expense, the new balance is $-485.</p>
<p>For each real world account, the owner can create a bookkeeping account like we did. Also, for each category of expenditure, the owner also creates a bookkeeping account. In this system, there are no limits to how many accounts can be created.</p>
<p>Note that the balance in the example is a negative number; this is not an error. Balances for credit card accounts are normally negative: they represent an amount <em>you owe</em>, that the bank is lending you <em>on credit</em>. When your credit card company keeps track of your expenses, they write out your statement from their perspective, as positive numbers. For you, those are amounts you need to eventually pay. But here, in our accounting system, we’re representing numbers from the owner’s point-of-view, and from her perspective, this is money she owes, not something she has. What we have is a meal sitting in our stomach (a positive number of $ of “Restaurant”).</p>
<h3 id="multiple-postings">Multiple Postings<a id="multiple-postings"></a><a href="#multiple-postings" title="Permanent link"></a></h3>
<p>Finally, transactions may have more than two postings; in fact, they may have any number of postings. The only thing that matters is that the sum of their amounts is zero (from the rule of double-entry bookkeeping above).</p>
<p>For example, let’s look at what would happen if the owner gets her salary paid for December:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/18980f41275676c5c7cf3b39dd256512bb45b78b.png"></p>
<p>Her gross salary received in this example is recorded as $-2,905 (I’ll explain the sign in a moment). $905 is set aside for taxes. Her “net” salary of $2,000, the remainder, is deposited in her “Checking” account and the resulting balance of that account is $2,921 (the previous balance of $921 + $2,000 = $2,921). This transaction has three postings: (+2,000) + (-2,905) + (+905) = 0. The double-entry rule is respected.</p>
<p>Now, you may ask: Why is her salary recorded as a negative number? The reasoning here is similar to that of the credit card above, though perhaps a bit more subtle. These accounts exist to track all the amounts from the owner’s point-of-view. The owner gives out work, and receives money and taxes in exchange for it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beancount.github.io/docs/the_double_entry_counting_method.html">https://beancount.github.io/docs/the_double_entry_counting_method.html</a></em></p>]]>
            </description>
            <link>https://beancount.github.io/docs/the_double_entry_counting_method.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23971567</guid>
            <pubDate>Tue, 28 Jul 2020 01:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alignment]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23971455">thread link</a>) | @gazzini
<br/>
July 27, 2020 | https://gazzini.com/essays/posts/alignment/ | <a href="https://web.archive.org/web/*/https://gazzini.com/essays/posts/alignment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2 id="internally">Internally</h2>
<p>I’ve managed a few small teams, and the worst situations always happen when I avoid conflict early.</p>
<p>Hypothetically, if Sam does 3 problematic things, I might only address 2 of them. Maybe I don’t want Sam to think I’m mean, or maybe I need Sam to stay encouraged. Regardless of my intent, it becomes increasingly difficult for me to address that 3rd behavior, and increasingly burdensome to spin my wheels serving as an unnecessary intermediary in Sam’s interactions, trying to create a buffer between that 3rd behavior and the rest of the office. This is obviously stupid and unsustainable, and becomes more awkward to correct over time.</p>
<p>This often creeps up in more subtle ways. A developer might provide a lot of critical feedback on every new round of designs. I want the designer to feel empowered and trusted, but I also want the developer to care about the overall product. It’s perfectly possible to strike a good balance &amp; accurately communicate with everybody… However, it’s human-instinct to optimize each message for the receiver, and to sliiiightly oversell the degree to which I agree with the developer’s criticisms, or to soften those same criticisms when speaking with the designer. These little tweaks, which feel like hard work &amp; good management in the short-term, can really snowball over time.</p>

  <p><img src="https://gazzini.com/essays/posts/alignment/expectations.jpg" alt="A graph with time on the X axis and reckoning on the Y axis. It demonstrates that for any initial degree of misunderstanding, the expectations deviate further from reality until it is corrected."></p><p>To minimize the magnitude of reckoning:</p>
<ul>
<li>A good manager will force the reckoning sooner</li>
<li>A great manager will avoid the misalignment in the first place</li>
<li>An excellent manager will avoid this misalignment without making anyone feel bad</li>
</ul>
<h2 id="externally">Externally</h2>
<p>Unfortunately, many people believe that the role of a great recruiter (or salesperson, marketer, director, or anybody) is to actually increase the degree of misalignment in the above graph… In other words, that they should oversell. In a large enough company, someone else downstream will have to deal with the reckoning:</p>

  <p><img src="https://gazzini.com/essays/posts/alignment/before.jpg" alt="A graph where most recruiters tell the truth, but 1 evil recruiter lies and is rewarded for it."></p><p>If this incentive system goes unchecked, it quickly devolves into a situation where everybody knows that everybody oversells, and so the common wisdom is to mentally discount any promise made by a salesperson, recruiter, marketer, engineer, or really anybody:</p>

  <p><img src="https://gazzini.com/essays/posts/alignment/after.jpg" alt="A graph where most recruiters lie, but the candidates all adjust their expectations accordingly. This causes the truthful recruiters to suffer, because their truth is also discounted."></p><p>I’ve noticed that a lot of mentorship involves helping newcomers recognize the overselling for themselves &amp; learn to navigate these worlds of semi-truths &amp; complex incentives. I’ve also noticed that this flavor of BS is always bad for the overall system / company / marketplace / world.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Externally, this pattern is unavoidable. Free markets will always be susceptible to some assumed misalignment, although regulations can help.</p>
<p>Within a company, however, this behavior is toxic. Whenever I see a team sugar-coating metrics, I know that it won’t be fun to work in implementation at that company. When the rubber meets the road, the fingers will start pointing.</p>
<h2 id="misc">Misc</h2>
<p>Here are some other things that I did to make myself miserable as a new manager:</p>
<ul>
<li>Lacking the confidence to make hard decisions, and offloading them to someone more confident but less informed</li>
<li>Waiting waaaay too long to fire people</li>
<li>Reading a lot of books on management, and expecting <em>my</em> manager to immediately live the ideals of those specific books</li>
<li>Trying to manage former peers without intentionally, drastically resetting the relationship</li>
</ul>
<p>I can avoid most of these by constantly asking myself what issues I’m avoiding today, and pursuing the ones that might turn into big issues later.</p>

  </div></div>]]>
            </description>
            <link>https://gazzini.com/essays/posts/alignment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23971455</guid>
            <pubDate>Tue, 28 Jul 2020 01:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Did the Casio F91W Become a Terrorist Icon?]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 74 (<a href="https://news.ycombinator.com/item?id=23971045">thread link</a>) | @joeschmoe83
<br/>
July 27, 2020 | https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/ | <a href="https://web.archive.org/web/*/https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>The humble Casio F91W has been an iconic watch since it was first made in Japan back in 1989. Upon its release, it was sold for around $20 making it one of the world’s first affordable digital watches. Today, Casio still produces over 3 million of the F91W every year. The prevalence of this iconic timepiece through the years means it’s likely you’ve worn one at some point. If you have, then it’s probably the only thing you have in common with Osama bin Laden, Chechen militants, and Napoleon Dynamite. Congratulations!</p>



<p>As a kid in school, I personally remember being told off for talking in the back of the class. I had been caught excitedly telling my friends that I had just figured out what kind of watch the most wanted man on earth, Osama bin Laden, wears. As punishment, I was called up to answer the maths question on the board, at which I failed miserably. <em>”You need to focus on what matters! You can’t solve maths problems but you can tell everyone about the watches worn by terrorists?”</em> screamed my teacher. <a href="https://reaperfeed.com/about-reaper-feed/">Looking back</a>, I feel I prioritized the right kind of knowledge.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?w=696&amp;ssl=1" alt="Inventor of the Casio FW91" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?w=860&amp;ssl=1 860w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=300%2C228&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=768%2C584&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=696%2C529&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=552%2C420&amp;ssl=1 552w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=80%2C60&amp;ssl=1 80w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Inventor of the Casio F91W, Ryusuke Moriai, polishes a Samurai sword in Tokyo. Photo from <a href="https://www.ablogtowatch.com/tokyo-man-designs-casio-g-shock-watches-ryusuke-moriai/">A Blog to Watch.</a></figcaption></figure>



<p>The Casio F91W was designed by Ryusuke Moriai which he described as “small, flat and simple”. The watch features a seven-segment numerical display on a grey LCD screen. Water-resistant, extremely durable and accurate to within 30 seconds a month, it’s a tried and tested piece of kit.</p>



<hr>



<figure><a href="https://www.amazon.com/Military-Grade-Travel-Guide-Dangerous-ebook/dp/B086JBW97K"><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=696%2C392&amp;ssl=1" alt="" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=2048%2C1152&amp;ssl=1 2048w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=696%2C392&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1068%2C601&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1920%2C1080&amp;ssl=1 1920w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=747%2C420&amp;ssl=1 747w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></a></figure>



<hr>



<p>If there’s one thing that’s to be said for international terrorists, they know a thing or two about choosing reliable products for waging war. The F-91W joined the ranks of other terrorist accessories like the Kalashnikov and the Toyota technical because it’s cheap, solid, and reliable. Oh, and it also doubles as a bombmaking accessory which we’ll look into later.</p>



<h3><strong><em>A Terrorist Fashion Icon</em></strong></h3>



<p>Whilst Casio has advanced further into combat watches through its iconic Casio G-Shock range, the F91W has remained the true battlefield accessory throughout modern warfare. Aside from iconic weapons, the Casio F-91W is the only branded accessory that Osama bin Laden was ever seen wearing in the open. Al-Qaeda was reported to <a href="https://wikileaks.org/gitmo/prisoner/720.html">hand the watches out to recruits</a> at their terror training camps across Afghanistan and Pakistan throughout the 1990s and early 2000s. Thus, it was al-Qaeda and bin Laden who arguably started the terrorist trend surrounding the watch.</p>



<div><figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?w=696&amp;ssl=1" alt="Osama Bin Laden wearing Casio FW91" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?w=371&amp;ssl=1 371w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?resize=239%2C300&amp;ssl=1 239w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?resize=335%2C420&amp;ssl=1 335w" sizes="(max-width: 371px) 100vw, 371px" data-recalc-dims="1"><figcaption>Osama bin Laden wearing the iconic F-91W.</figcaption></figure></div>



<p>During the height of the War on Terror, it didn’t take long for the US government to spot the prevalence of the Casio F91W amongst terrorists. In 2011, Wikileaks released a document labeled the “Matrix of Threat Indicators for Enemy Combatants” which was intended to assist staff at Guantanamo decide which detainees are more likely to carry out suicide attacks. According to the document, owning an F-91W was the biggest giveaway of a serious terror suspect alongside ownership of a satellite phone, a radio transceiver, or large quantities of cash.</p>



<p>However, this wasn’t just paranoia. Statistics in other similar documents released by Wikileaks revealed that around a third of inmates being held at Guantanamo that were captured whilst wearing an F-91W had a known correlation with explosives. The F-91W watch came up almost 150 times in the piles of leaked <a href="https://wikileaks.org/gitmo/pdf/ym/us9ym-000840dp.pdf">Guantanamo prisoner assessments</a>. Ironically, four of the chaplains who worked at Guantanimo Bay also wore the watch.</p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?fit=696%2C348&amp;ssl=1" alt="Casio FW91 Guantanamo Bay" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?w=1100&amp;ssl=1 1100w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=768%2C384&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=696%2C348&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=1068%2C534&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=840%2C420&amp;ssl=1 840w" sizes="(max-width: 696px) 100vw, 696px"></figure>



<p>One of the detainees at Guantanamo was grilled over the prevalence of the watch amongst suspected terrorists. He claimed that the water-resistant feature of the F91W watch was handy due to the Islamic requirement for followers to wash up to their elbows before prayers. Innocent enough explanation, right? Well not really. Interrogators smelled a rat when another prisoner claimed the prevalence of the watch amongst Jihadi inmates was simply due to the built-in compass that helped them pray towards Mecca. However, there is no compass in the F91W.</p>



<p>Despite the fairly frosty relationship between the two, ISIS didn’t let it get in between their choice of a good wristwatch. The F-91W was a feature of various ISIS militants including Tunisian born Tariq al-Harzi who was a high ranking Emir of the Islamic State. It was also worn by Kevin Chassin who was a French-born Jihadist who went to Syria to join ISIS. He was subsequently utilized for his high propaganda value in ISIS videos. </p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=696%2C364&amp;ssl=1" alt="Casio F91W." srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=300%2C157&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=768%2C402&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=696%2C364&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=1068%2C559&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=803%2C420&amp;ssl=1 803w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></figure>



<p>However, the leader of ISIS Abu Bakr al-Baghdadi wasn’t so fond of the cheap Casio F91W. Instead, al-Baghdadi opted for a flashy watch that sparked debate over the exact model. The watch was spotted during his infamous speech in Mosul that declared the formation of the so-called Caliphate. It was believed to be either a Rolex or an Omega Seamaster, both of which run north of $3,000 and contradict the contents of his speech as well as his ideals.</p>



<p>It’s not just Jihadist terrorist groups that wear the watch. Introducing Subcomandante Marcos who, until recently, led the Zapatista National Liberation Army (EZLN) in Mexico. The photogenic insurgent leader was pictured in an iconic photo on horseback while smoking a pipe and wearing, you guessed it! </p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?fit=696%2C364&amp;ssl=1" alt="subcomandante Marcos Casio FW91" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=300%2C157&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=768%2C402&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=696%2C364&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=1068%2C559&amp;ssl=1 1068w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=803%2C420&amp;ssl=1 803w" sizes="(max-width: 696px) 100vw, 696px"><figcaption>Subcomandante Marcos wearing the Casio F91W</figcaption></figure>



<p>Of course, the watch is not only appreciated by the terrorists of the world but likewise by the people who combat them. Various fighting forces across the Middle East have been seen using the watch. Such as the Syrian Democratic Forces which is a coalition waging an anti-ISIS campaign across war-torn Syria.</p>



<h3><em><strong> How the Casio F91W Became a Bomb Makers Accessory</strong></em></h3>



<p>The Casio F91W is not only the terrorist’s timepiece of choice due to its ruggedness and reliability. Due to its long-lead timer, it also doubles as a bomb-making accessory for various terror groups around the world from Afghanistan to Chechnya. Deadly usage of the watch has been well documented through various case studies.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=696%2C500&amp;ssl=1" alt="Casio FW91" width="696" height="500" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?w=600&amp;ssl=1 600w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=300%2C216&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=585%2C420&amp;ssl=1 585w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></figure>



<p>According to US intelligence officials, the watch doubles as a bomb timer as its alarm can be set beyond a 24-hour period. During the War on Terror, Pakistani ISI officials found more than 600 of the watches in a terrorist safe house in Karachi which led to a period of anybody being found wearing an F91W watch to be liable for arrest and questioning. However, with the watch being available for $4 dollars on Pakistani markets, simply possessing a Casio watch doesn’t prove anything and this tactic of arrest was soon dropped.</p>



<p>In September 1999, a series of bombs were detonated inside four Russian apartment buildings in the cities of Moscow, Volgodonsk, and Buinaksk. The blasts killed 367 people and injured over 1,000 others. Russian investigators concluded that the attackers had been trained in terror camps being run by Ibn al-Khattab inside Chechnya which had recently gained unstable independence following the First Chechen War.</p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?w=696&amp;ssl=1" alt="Casio F91W" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?w=800&amp;ssl=1 800w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=300%2C195&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=768%2C498&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=696%2C452&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=647%2C420&amp;ssl=1 647w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Fire and smoke rise from a destroyed apartment building as Russian firefighters try to save people in Moscow on Sept. 9, 1999.&nbsp;</figcaption></figure>



<p>Investigations carried out inside Chechnya discovered that the bombs used in the attacks were comprised of ammonium nitrate and aluminum powder, with plastic serving as an intermediate explosive. The detonator? A combination of a Krona battery and a Casio F-91W. </p>



<blockquote><p>“about a third of inmates at JTF-GTMO [the unit in charge of Guantanamo] who were captured wearing one of these watches had a known correlation with explosives”.</p><cite>– Prisoner evaluation sheet from Guantanamo.</cite></blockquote>



<p>In 1994, an al-Qaeda militant named Ramzi Yousef used the Casio F-91W as a 4-hour timer on the bomb he constructed in an airplane toilet of Philippine Airlines Flight 434. He proceeded to leave his deadly work under the seat before leaving the plane. It detonated on the next flight, killing a Japanese businessman named Haruki Ikegami who sat in Yousef’s seat. Thankfully, the bomb’s orientation caused the energy to be mostly absorbed by Ikegami. Thus other passengers and the plane were not catastrophically damaged.</p>



<p>So, to round off this article I feel it’s fitting to make a comparison between Ryusuke Moriai and Mikhail Kalashnikov. Just like when Kalashnikov designed the AK47 intended solely for the defense of his motherland, the innovative inventor Ryusuke Moriai could never have predicted that his creation would go on an unstoppable path of its own and be used for far more sinister purposes than ever intended. Mr. Moriai had unwittingly created a watch ideal for modern warfare.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?fit=696%2C923&amp;ssl=1" alt="Casio F91W" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=226%2C300&amp;ssl=1 226w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=772%2C1024&amp;ssl=1 772w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=768%2C1018&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=1159%2C1536&amp;ssl=1 1159w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=696%2C923&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=1068%2C1416&amp;ssl=1 1068w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=317%2C420&amp;ssl=1 317w" sizes="(max-width: 696px) 100vw, 696px"></figure>



<p>I was hoping to find a profound statement from Casio on the watch being used for deadly means by some pretty evil people. I was looking for something similar to what Kalashnikov said about the violent impact of his life’s work. <a href="https://www.theguardian.com/artanddesign/2011/apr/28/casio-f-91w-watch-design-hipsters-al-qaida">The Guardian</a> approached the PR department for Casio hoping for a similar statement on the widespread use of the F-91W amongst global terrorists. But they just received a blunt email stating: “Casio is not making any further comment on the F-91W watch at this point in time.” Damn.</p>



<p>For more stories like this as well as photography from the more bizarre sides of human conflict, you can stay up to speed with us on <a href="https://www.instagram.com/reaperfeed1/">Instagram</a> and <a href="https://twitter.com/Reaperfeed1">Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23971045</guid>
            <pubDate>Tue, 28 Jul 2020 00:40:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bitcoin is not a socialist’s ally]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 77 (<a href="https://news.ycombinator.com/item?id=23969359">thread link</a>) | @panarky
<br/>
July 27, 2020 | https://www.yanisvaroufakis.eu/2020/07/27/why-bitcoin-is-the-not-socialists-ally-reply-to-ben-arc/ | <a href="https://web.archive.org/web/*/https://www.yanisvaroufakis.eu/2020/07/27/why-bitcoin-is-the-not-socialists-ally-reply-to-ben-arc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article id="post-22754">

		<section>
			

			<h2>On 15th July, Ben Arc published in <a href="https://bitcoinmagazine.com/articles/an-open-letter-to-yanis-varoufakis-about-bitcoin">Bitcoin Magazine</a> an open letter addressed to me in a bid to convince me that I should re-assess my rejection of Bitcoin as a force for good; as a bulwark for democratising capitalism and paving the ground for socialism. Here is my reply:</h2>
<h3>Dear Ben Arc,</h3>
<h3>Thank you for your open letter and your efforts to bring a socialist perspective to bear upon my assessment of Bitcoin.</h3>
<h3>In my reply below, I shall address you as a fellow socialist, rather than put together a reply meant to address all sorts of different perspectives (e.g. Keynesian, Hayekian, neoclassical)</h3>
<h3>As you know, I am one of those who, back in 2011, were genuinely intrigued, fascinated even, by the remarkable blockchain algorithm. The prospect of a decentralised ledger controlled by its community of users was mesmerising.</h3>
<h3>As you also know, I was unimpressed by Bitcoin as an alternative to fiat money that is either likely, or indeed desirable, under our current capitalist predicament.</h3>
<h3>Having read your open letter, I remain as enthusiastic on blockchain’s capacities and as unimpressed by Bitcoin’s ability to help us either civilise or (as any socialist dreams of) transcend capitalism.</h3>
<h3>Two propositions support this view. In the hypothetical case where Bitcoin were, under presently-existing capitalism, to replace fiat money: (1) It would lack the mechanism necessary to stop capitalist crises from yielding depressions that benefit only the ultra-right; and, (2) Its community-based, democratic protocols would do little to democratise economic life.</h3>
<h3>I shall explain my two propositions briefly below. But, before you despair (at my continued negative take on Bitcoin), let me foreshadow the concluding sentence in the Epilogue below: Once (and, of course, if) socialism dawns, money will have to be founded on a distributed-ledger, monetary commons enabling tehnology.</h3>
<h3>In other words, I shall argue that Bitcoin is not fit for purpose under capitalism, or as a vehicle toward transcending capitalism, but something like Bitcoin will characterise monetary systems in a future world free of private banks and share markets.</h3>
<h3>OK, let me now support my two propositions:</h3>
<h2><strong><em>Proposition 1: Bitcoin lacks the shock absorbers necessary to prevent capitalist crises from doing untold damage to the working class</em></strong></h2>
<h3>Consider the Crash of 2008 or the more recent 2020 Covid-19-induced crisis. Suppose that Central Banks did not have the capacity instantly to create trillions of dollars, euros, pounds and yen – and instead had to rely on a spontaneous majority of Bitcoin’s users to agree to a massive increase in the supply of money. The result would be a 1929-like collapse of banks and corporations.</h3>
<h3>While socialists would shed no tears for the tragedy of the oligarchy, socialists should beware that a 1929-like systemic collapse is bound to strengthen the forces of the ultra-right – not of the socialist left (that has been, since at least 1991, languishing in the doldrums of political paralysis).</h3>
<h3>Technically, there is of course nothing that would prevent the Bitcoin community from agreeing instantly to even a doubling of the money base. However, the Tragedy of the Commons guarantees that Bitcoin owners will be subject to the usual prisoner’s dilemma dynamic that prevents the boost in the money supply necessary to avert the liquidation of potentially viable businesses and jobs. Moreover, this free-rider problem is made far, far worse by the fact that Bitcoin ownership is very unequally distributed, thus giving the Bitcoin-rich powerful incentives to restrain the growth of the money supply (since such restrictions would boost their private rents at the expense of the public interest).</h3>
<h3>In short, the free-rider problem that guarantees the maximal reinforcement of any capitalist crisis (in any economy relying on Bitcoin as its main currency) will be turbocharged by the unequal ownership of Bitcoin – which is unavoidable in any monetary system overlaid upon contemporary capitalism.</h3>
<h2><em>Proposition 2: Under capitalism, Bitcoin’s dominance will not democratise economic life – or give socialism a chance</em></h2>
<h3>Suppose, again, that some magic wand is waved and Bitcoin replaces fiat money under contemporary capitalist conditions. In other words, as Bitcoin replaced dollars, pounds, euros and yen, property rights over land, resources and machines remain as they are while private equity firms and pension funds continue to own the bulk of shares trading in Wall Street, the City etc. All that will have changed is that Central Banks will vanish and the community of Bitcoin users will determine the global money supply (subject to the free-rider problems mentioned above).</h3>
<h3>At the firm level, nothing will have changed. Jeff Bezos will still control a massive monopsony-cum-monopoly, Facebook will still own the whole marketplace within its platform, Exxon-Mobil will continue to lean on weaker developing country governments to drill for oil and gas that should be left in the Earth’s guts etc.</h3>
<h3>And what of private banks? They would, make no mistake here, find ways of creating complex derivatives based on Bitcoin – derivatives that will soon (just like Lehman Brothers’ CDOs prior to 2008) function as stores of value and means of exchange; i.e. as private money. Massive bubbles denominated in Bitcoin will build up and they will burst just as they did in the 19<sup>th</sup> century under the Gold Standard. And then?</h3>
<h3>In the absence of Central Banks and with the Bitcoin community in the clasps of the aforementioned free-rider problem, depression will follow – as it did before the Fed was instituted in the US. Thus, the tragedy mentioned in Proposition 1 above kicks in.</h3>
<h3>In short, not only will the democratisation of money via Bitcoin fail to democratise capitalism but it will also give an almighty boost to the forces of regression.</h3>

<h3>Bitcoin’s great appeal is that it breaks the cronyist chain linking central banks and private bankers. However, it does not undermine the cronyism of the network of bosses, politicians and private bankers.</h3>
<h3>Lest we forget, 19<sup>th</sup> Century bimetallic America also lacked a central bank. Under the gold and silver standards, the public money supply was fixed – and could not be easily manipulated by the state (either the government or the, then non-existent, Fed). But that did not stop private bankers from leveraging public money out of thin air to create huge quantities of private money with which to fund the Robber Barons, i.e. the Jeff Bezoses, of the era.</h3>
<h3>In this sense, replacing fiat money with Bitcoin would take us back to a postmodern version of 19<sup>th</sup> Century America – not exactly a prospect socialists should go to the barricades for.</h3>
<h3>In summary, the monetary system is like the dog’s tail. It cannot wag the capitalist dog, in the sense that democratising money by means of a monetary commons will not democratise economic life but, rather, make capitalism uglier, nastier and more dangerous for humanity.</h3>
<h3>Having said all this, a monetary commons (that may very well rely on something like the blockchain underpinning Bitcoin) will, I have no doubt, be an essential aspect of a democratised economy; of socialism.</h3>

		</section>

		

	</article>
</div></div>]]>
            </description>
            <link>https://www.yanisvaroufakis.eu/2020/07/27/why-bitcoin-is-the-not-socialists-ally-reply-to-ben-arc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23969359</guid>
            <pubDate>Mon, 27 Jul 2020 21:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How GPT3 Works – Visualizations and Animations]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 85 (<a href="https://news.ycombinator.com/item?id=23967887">thread link</a>) | @dsr12
<br/>
July 27, 2020 | https://jalammar.github.io/how-gpt3-works-visualizations-animations/ | <a href="https://web.archive.org/web/*/https://jalammar.github.io/how-gpt3-works-visualizations-animations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>(Live thread, will be updated with new visuals and polish over the next few days. Join <a href="http://eepurl.com/gl0BHL">the mailing list</a> to get updated when completed)</p>

<p>A trained language model generates text.</p>

<p>We can optionally pass it some text as input, which influences its output.</p>

<p>The output is generated from what the model “learned” during its training period where it scanned vast amounts of text.</p>

<p><img src="https://jalammar.github.io/images/gpt3/01-gpt3-language-model-overview.gif">
  <br>

</p>

<!--more-->

<p>Training is the process of exposing the model to lots of text. That process has been completed. All the experiments you see now are from that one trained model. It was estimated to cost 355 GPU years and cost $4.6m.</p>

<p><img src="https://jalammar.github.io/images/gpt3/02-gpt3-training-language-model.gif">
  <br>

</p>

<p>The dataset of 300 billion tokens of text is used to generate training examples for the model. For example, these are three training examples generated from the one sentence at the top.</p>

<p>You can see how you can slide a window across all the text and make lots of examples.</p>

<p><img src="https://jalammar.github.io/images/gpt3/gpt3-training-examples-sliding-window.png">
  <br>

</p>

<p>The model is presented with an example. We only show it the features and ask it to predict the next word.</p>

<p>The model’s prediction will be wrong. We calculate the error in its prediction and update the model so next time it makes a better prediction.</p>

<p>Repeat millions of times</p>

<p><img src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif">
  <br>

</p>

<p>Now let’s look at these same steps with a bit more detail.</p>

<p>GPT3 actually generates output one token at a time (let’s assume a token is a word for now).</p>

<p><img src="https://jalammar.github.io/images/gpt3/04-gpt3-generate-tokens-output.gif">
  <br>

</p>

<p>Please note: This is a description of how GPT-3 works and not a discussion of what is novel about it (which is mainly the ridiculously large scale). The architecture is a transformer decoder model based on this paper https://arxiv.org/pdf/1801.10198.pdf</p>

<p>GPT3 is MASSIVE. It encodes what it learns from training in 175 billion numbers (called parameters). These numbers are used to calculate which token to generate at each run.</p>

<p>The untrained model starts with random parameters. Training finds values that lead to better predictions.</p>

<p><img src="https://jalammar.github.io/images/gpt3/gpt3-parameters-weights.png">
  <br>

</p>

<p>These numbers are part of hundreds of matrices inside the model. Prediction is mostly a lot of matrix multiplication.</p>

<p>In my <a href="https://youtube.com/watch?v=mSTCzNgDJy4">Intro to AI on YouTube</a>, I showed a simple ML model with one parameter. A good start to unpack this 175B monstrosity.</p>

<p>To shed light on how these parameters are distributed and used, we’ll need to open the model and look inside.</p>

<p>GPT3 is 2048 tokens wide. That is its “context window”. That means it has 2048 tracks along which tokens are processed.</p>

<p><img src="https://jalammar.github.io/images/gpt3/05-gpt3-generate-output-context-window.gif">
  <br>

</p>

<p>Let’s follow the purple track. How does a system process the word “robotics” and produce “A”?</p>

<p>High-level steps:</p>

<ol>
  <li>Convert the word to <a href="https://jalammar.github.io/illustrated-word2vec/">a vector (list of numbers) representing the word</a></li>
  <li>Compute prediction</li>
  <li>Convert resulting vector to word</li>
</ol>

<p><img src="https://jalammar.github.io/images/gpt3/06-gpt3-embedding.gif">
  <br>

</p>

<p>The important calculations of the GPT3 occur inside its stack of 96 transformer decoder layers.</p>

<p>See all these layers? This is the “depth” in “deep learning”.</p>

<p>Each of these layers has its own 1.8B parameter to make its calculations. That is where the “magic” happens. This is a high-level view of that process:</p>

<p><img src="https://jalammar.github.io/images/gpt3/07-gpt3-processing-transformer-blocks.gif">
  <br>

</p>

<p>You can see a detailed explanation of everything inside the decoder in my blog post <a href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT2</a>.</p>

<p>The difference with GPT3 is the alternating dense and <a href="https://arxiv.org/pdf/1904.10509.pdf">sparse self-attention layers</a>.</p>

<p>This is an X-ray of an input and response (“Okay human”) within GPT3. Notice how every token flows through the entire layer stack. We don’t care about the output of the first words. When the input is done, we start caring about the output. We feed every word back into the model.</p>

<p><img src="https://jalammar.github.io/images/gpt3/08-gpt3-tokens-transformer-blocks.gif">
  <br>

</p>

<p>In the React code generation example (https://twitter.com/sharifshameem/status/1284421499915403264), the description would be the input prompt (in green), in addition to a couple of examples of description=&gt;code, I believe. And the react code would be generated like the pink tokens here token after token.</p>

<p>My assumption is that the priming examples and the description are appended as input, with specific tokens separating examples and the results. Then fed into the model.</p>

<p><img src="https://jalammar.github.io/images/gpt3/09-gpt3-generating-react-code-example.gif">
  <br>

</p>

<p>It’s impressive that this works like this. Because you just wait until fine-tuning is rolled out for the GPT3. The possibilities will be even more amazing.</p>

<p>Fine-tuning actually updates the model’s weights to make the model better at a certain task.</p>

<p><img src="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif">
  <br>

</p>

  </div></div>]]>
            </description>
            <link>https://jalammar.github.io/how-gpt3-works-visualizations-animations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967887</guid>
            <pubDate>Mon, 27 Jul 2020 18:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quiet route planning for pedestrians in traffic noise polluted environments]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 122 (<a href="https://news.ycombinator.com/item?id=23967306">thread link</a>) | @ericdanielski
<br/>
July 27, 2020 | http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/ | <a href="https://web.archive.org/web/*/http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>#Noise #pollution is one of the main stressors in urban environments, having negative impacts on people’s quality of life and health. For some groups of citizens, such as school children, patients, and elders, there is a need to support them in finding pedestrian routes in noise polluted areas of cities. In<a href="https://ieeexplore.ieee.org/document/9139350" target="_blank"> a new paper</a>, <a href="http://uni-heidelberg.de/gis" target="_blank">we</a> focus on the <strong>estimation of traffic noise</strong>, and present an approach to <strong>provide quiet routing services</strong>, <em>taking into account the estimated noise levels of roads</em>.</p>
<p>By combining Volunteered Geographic Information from OpenStreetMap (OSM), official socio-economic data, and open-access GPS trajectory data, we develop a set of traffic related variables, and apply machine learning methods to perform<strong> traffic volume estimations</strong>. Given the estimated traffic information, an existing traffic noise model is then employed to derive the noise polluted areas. For generation of quiet routes, a new routing algorithm is proposed. It minimizes the exposure of pedestrians to traffic noise pollution while taking into account the route distance constraint. We apply our quiet routing approach to the city of Heidelberg (Germany). The application results demonstrate the efficacy of our algorithms in the generation of quiet routes customized to pedestrian preferences.</p>
<blockquote><p>Z. Wang, T. Novack, Y. Yan and A. Zipf, “<a href="https://ieeexplore.ieee.org/document/9139350" target="_blank">Quiet Route Planning for Pedestrians in Traffic Noise Polluted Environments</a>,” in IEEE Transactions on Intelligent Transportation Systems, doi: 10.1109/TITS.2020.3004660.</p></blockquote>
<p><a href="http://k1z.blog.uni-heidelberg.de/files/2020/07/noiseroutehdgisciencehd.jpg"><img src="http://k1z.blog.uni-heidelberg.de/files/2020/07/noiseroutehdgisciencehd-300x221.jpg" alt="" width="300" height="221"></a></p>
<p>In earlier work we looked already into generating customized pleasant pedestrian routes based on several factors like greenness, noise and sociability, and added this to <a href="https://openrouteservice.org/" target="_blank">Openrouteservice</a> by <a href="http://heigit.org/" target="_blank">HeiGIT</a> &amp; <a href="http://uni-heidelberg.de/gis" target="_blank">GIScience HD</a>:</p>
<blockquote><p><span>Novack, T.; Wang, Z.; Zipf, A. (2018):&nbsp;<a href="https://www.mdpi.com/1424-8220/18/11/3794" target="_blank">A System for Generating Customized Pleasant Pedestrian Routes Based on OpenStreetMap Data</a>. </span><em>Sensors</em><span> </span><span>2018</span><span>, </span><em>18</em><span>, 3794.</span></p></blockquote>
<p>Also currently we started to <a href="http://k1z.blog.uni-heidelberg.de/2020/06/19/going-green-with-meingrun-today-app-launch-in-heidelberg-and-dresden/">test related approaches in Dresden and Heidelberg</a> in the context of the <a href="https://www.geog.uni-heidelberg.de/gis/meingruen_en.html" target="_blank">meinGrün</a> project.<br>
This builds upon early work by <a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/arcviewbuch-zipf-roether.pdf" target="_blank">Zipf and Röther (2000)</a>, But nowadays the needed data sources are much more available, so that it becomes possible to scale these ideas to new levels using open data which allow to finetune and evaluate the approach using real world data.</p>
<p>The relevance of green spaces for wellbeing and mental health in cities has been proofed by a study published in <a href="https://www.nature.com/articles/s41593-019-0451-y" target="_blank">Nature Neuroscience</a></p>
<blockquote><p><span>H. Tost, M. Reichert, U. Braun, I. Reinhard, R. Peters, S. Lautenbach, A. Hoell, E. Schwarz, U. Ebner-Priemer, A. Zipf, and A. Meyer-Lindenberg (2019): </span><a href="https://www.nature.com/articles/s41593-019-0451-y" target="_blank">Neural correlates of individual differences in affective benefits of real-life urban green space exposure.</a><span> Nature Neuroscience. https://doi.org/10.1038/s41593-019-0451-y</span></p></blockquote>
<blockquote><p><span>Zipf, A. &amp; Röther, S. (2000): </span><a title="im neuen Fenster öffnen" href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/arcviewbuch-zipf-roether.pdf" target="_blank">Tourenvorschläge für Stadttouristen mit dem ArcView Network Analyst.</a><span> In: Liebig, W. (Hrsg.): ArcView Arbeitsbuch. Hüthig Verlag. Heidelberg.</span></p></blockquote>
<p>Other early examples on using OpenStreetMap for specialized routing and navigation applications for large areas or specific scenarios (e.g. disaster management, wheelchairs etc.) are given below:</p>
<blockquote><p>Neis, P. &amp; Zipf, A (2008): <a href="https://openrouteservice.org/" target="_blank">OpenRouteService.org</a> is three times “Open”: Combining OpenSource, OpenLS and OpenStreetMap. GIS Research UK (GISRUK 08). Manchester.</p>
<p><span>Schmitz, S., Neis, P. &amp; Zipf, A. (2008): </span><a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/cmap2008.cartography-bonn.subm.pdf" target="_blank">New Applications based on Collaborative Geodata – the Case of Routing.</a><span> XXVIII INCA International Congress on Collaborative Mapping and SpaceTechnology, Gandhinagar, Gujarat, India.</span></p>
<p><span>Rousell A. and Zipf A. (2017): </span><a href="http://www.mdpi.com/2220-9964/6/3/64" target="_blank">Towards a landmark based pedestrian navigation service using OSM data.</a><span> International Journal of Geo-Information, ISPRS IJGI, 6(3): 64.</span></p>
<p><span>Neis, P., Singler, P. &amp; Zipf, A. (2010): </span><a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/un-osm-emergency-routing.gi-forum2010.full.pdf">Collaborative mapping and Emergency Routing for Disaster Logistics – Case studies from the Haiti earthquake and the UN portal for Afrika.</a><span> In: Car, A., Griesebner, G. &amp; Strobl, J. (Eds.): Geospatial Crossroads @ GI_Forum ‘10. Proceedings of the Geoinformatics Forum Salzburg.</span></p>
<p><span>Zipf, A., Mobasheri, A., Rousell, A. ,Hahmann, S. (2016): </span><a title="im neuen Fenster öffnen" href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/europ_handb_crowds_infozipf.pdf">Crowdsourcing for individual needs - the case of routing and navigation for mobility-impaired persons </a><span>. In: Capineri, C, Haklay, M, Huang, H, Antoniou, V, Kettunen, J, Ostermann, F and Purves, R. (eds.) European Handbook of Crowdsourced Geographic Information, p. 325–337. London: Ubiquity Press. DOI: dx.doi.org/10.5334/bax.x</span></p>
<p><span>Miksch, J., Hahmann, S., Resch, B., Lauer, J., Zipf, A. (2017): </span><a title="im neuen Fenster öffnen" href="http://www.tandfonline.com/doi/full/10.1080/10095020.2017.1399675">Routing Through Open Spaces - A Performance Comparison Of Algorithms. </a><span>Geo-Spatial information Science, 2017. Taylor &amp; Francis. Geo-Spatial information Science, 2017. Taylor &amp; Francis. https://doi.org/10.1080/10095020.2017.1399675</span></p></blockquote>
										<p>
            Tags: <a href="http://k1z.blog.uni-heidelberg.de/tag/meingrun/" rel="tag">meinGrün</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/noise/" rel="tag">noise</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/openrouteservice/" rel="tag">OpenRouteService</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/osm/" rel="tag">OSM</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/routing/" rel="tag">routing</a><br> </p>
				</div></div>]]>
            </description>
            <link>http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967306</guid>
            <pubDate>Mon, 27 Jul 2020 17:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a file system from scratch in Rust]]>
            </title>
            <description>
<![CDATA[
Score 318 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23967016">thread link</a>) | @carlosgaldino
<br/>
July 27, 2020 | https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html | <a href="https://web.archive.org/web/*/https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>27 Jul 2020</span></p><p>Data produced by programs need to be stored somewhere for future reference, and
there must be some sort of organisation so we can quickly retrieve the desired
information. A file system (FS) is responsible for this task and provides an
abstraction over the storage devices where the data is physically stored.</p>

<p>In this post, we will learn more about the concepts used by file systems, and
how they fit together when writing your own.</p>

<h2 id="structuring-the-disk">Structuring the disk</h2>
<p>When data is stored in a hard-disk drive (HDD) or solid-state drive (SSD), it is
written in small units called sectors (or pages in the SSD case). The drives
don’t have any information about what that piece of data represents, for all it
is worth, the disk is just a giant array of sectors. It is the job of the file
system to make sense of it all.</p>

<p>A file system will divide the disk into fixed-sized blocks. The FS uses the
majority of these blocks to store user data, but some blocks are used to store
metadata that is essential for the file system operation.</p>

<p>The following figure gives an example of how a file system structures the
information on the disk:</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_filesystem_blocks.svg" alt="">
    <figcaption>File system structure in a disk</figcaption>
</figure>

<p>In the next sections, we will understand what each type of block means.</p>

<h3 id="superblock-and-bitmaps">Superblock and bitmaps</h3>

<p>The superblock stores most of the metadata about the file system, such as the
following: block size, timestamps, how many blocks and files are in use and how
many are free, etc.</p>

<p>Bitmaps are one way of tracking which data blocks and inodes are free. An index
in the bitmap set to <code>0</code> indicates a free slot, and an index set to <code>1</code>
indicates an occupied slot.</p>

<h3 id="inode">Inode</h3>

<p>The inode is the structure that stores metadata about a file. Attributes such as
permissions, size, location of data blocks that form the file and more are saved
in an inode.</p>

<p>The inodes are stored in blocks that together form the <em>inode table</em> as the
following figure shows.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_inode_table.svg" alt="">
    <figcaption>Inode table (detailed view)</figcaption>
</figure>

<p>For each slot in the inode bitmap set to <code>1</code>, there will be a corresponding
inode in the table. The index of the slot is the same as the index in the table.
And this explains the name inode being a short name for <em>index node</em>.</p>

<h3 id="data-blocks">Data blocks</h3>

<p>As the name suggests, the data blocks are the blocks where the actual data
belonging to a file is written. These blocks are also used for different
purposes which we will see shortly.</p>

<h2 id="pointing-to-data">Pointing to data</h2>

<p>The inode needs to have a way of pointing to the data blocks that assemble the
file. The simplest way is to have <strong>direct pointers</strong>. In this case, each
pointer points to a block that has some of the file data. The problem is that
large files; where the size exceeds the number of direct pointers an inode can
have; are not supported in this mode. One way of overcoming this issue is to use
<strong>indirect pointers</strong>, which instead of storing user data they store pointers to
blocks that hold user data. For larger files, another layer of indirection is
added with <strong>double indirect pointers</strong>. And for even larger files, <strong>triple
indirect pointers</strong> are put to use.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_direct_pointers.svg" alt="">
    <figcaption>Inode multi-level index</figcaption>
</figure>

<p>To give an idea of the largest file size that each level permit let’s run an
example considering that each block size is 4 KiB. Research has shown that the
majority of files are small [1] so 12 direct pointers would allow for files up
to 48 KiB. Considering that each pointer takes 4 bytes, a single indirect
pointer would then allow a file to be up to around 4 MiB:</p>

<pre>(12 + 1024) * 4 KiB
</pre>

<p>With the addition of double indirect pointers the size would jump to around 4
GiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup>) * 4 KiB
</pre>

<p>And finally, with triple indirect pointers the files could have a size of around
4 TiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup> + 1024<sup>3</sup>) * 4 KiB
</pre>

<p>This approach might not be very efficient for handling large files. For example,
a file of 100 MiB requires the allocation of 25600 blocks. The performance can
be severely impacted in case the blocks were fragmented over the disk.</p>

<p>Some file systems use <strong>extents</strong> to help with this situation. In this approach,
there is a single pointer and a length to tell that the data starts at the
address of the pointer and runs for the given range of blocks. In our example
above, describing the same file would use a single extent of size 100 MiB.
Multiple extents can be used to support larger files.</p>

<h2 id="directories">Directories</h2>

<p>You may have noticed that there isn’t a specific structure for directories. The
reason behind it is the fact that inodes represent both files and directories.
The difference is in what is stored in the corresponding data blocks.
Directories are simply a list of all files that it includes. Each entry has the
form of <code>(name, index number)</code> so when looking up a particular file (or another
directory), the system uses the <code>name</code> to find the corresponding inode.</p>

<p>Searching for a file can be slow if a directory contains a large number of
files. This issue can be mitigated by maintaining the list sorted and using
binary search, or instead of representing it as a list, a hash table or a
balanced search tree could also be used.</p>

<h2 id="access-paths">Access paths</h2>

<h3 id="read">Read</h3>

<p>When reading from a file, the file system needs to traverse the entire path,
visiting each inode along the way until reaching the inode for the desired file.
Assuming the user has permission to access the file, the file system consults
which blocks are associated with it and then read the solicited data from them.</p>

<h3 id="write">Write</h3>

<p>When writing to a file, the same process has to happen to find the corresponding
inode. If a new block is required for the write, the file system has to allocate
the block, update the associated information (bitmap and inode), and write to
the block. So one write operation requires five I/O operations: one read to the
bitmap, one write to mark the new block as occupied, two to read and write to
the inode, and one writing the data in the block. This number can increase when
creating a new file because now the associated information of the directory also
has to be read and written to reflect this new file, and operations to create a
new inode.</p>

<h2 id="gotenksfs">GotenksFS</h2>

<p>As a side project, I decided to write my own file system in Rust as I’m learning
the language. Some aspects are inspired by ext4 [2] (and family), and in this
section, you will learn more about it. The file system uses FUSE [3], and the
disk is represented as a regular file. The block size can be configured as 1
KiB, 2 KiB, or 4 KiB. Files can have a size of up to 4 GiB for block sizes of 4
KiB while the file system could theoretically be up to 16 TiB in size.</p>

<h3 id="mkfs"><code>mkfs</code></h3>

<p>The first step is to create the image itself with the configuration values for
the file system. This is achieved via the <code>mkfs</code> command:</p>

<div><div><pre><code><span>$ </span>./gotenksfs mkfs disk.img <span>-s</span> <span>"10 GiB"</span> <span>-b</span> 4096
</code></pre></div></div>

<p>After running the command, the image is created with a total size of 10 GiB, and
each block in the file system has a size of 4 KiB.</p>

<p>In this step, the configuration values and other structures such as a root
directory are written to the image in the first block: the superblock. Its
corresponding bitmap entries, and data are also written. These values will be
necessary for the next step: mounting the file system.</p>

<h3 id="mount"><code>mount</code></h3>

<p>After creating the image, we need to mount it so we can start using it. The
<code>mount</code> command is used for this:</p>

<div><div><pre><code><span>$ </span>./gotenksfs mount disk.img gotenks
</code></pre></div></div>

<p>And you can see some information about it:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs-mount.png">
    <figcaption>File system after mounting</figcaption>
</figure>

<h3 id="on-disk-structure">On-disk structure</h3>

<p>The superblock is written in the first 1024 bytes, and it holds the
configuration values provided in the <code>mkfs</code> command.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Superblock</span> <span>{</span>
    <span>pub</span> <span>magic</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>block_size</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>last_mounted_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>inode_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_blocks</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_inodes</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>groups</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>data_blocks_per_group</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>uid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>gid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>The next two blocks represent the data bitmap and inode bitmap. Then, a run of
<code>n</code> blocks are used for the inode table. And the blocks following that are the
ones where user data will be written.</p>

<p>The inode is defined as follows:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Inode</span> <span>{</span>
    <span>pub</span> <span>mode</span><span>:</span> <span>libc</span><span>::</span><span>mode_t</span><span>,</span>
    <span>pub</span> <span>hard_links</span><span>:</span> <span>u16</span><span>,</span>
    <span>pub</span> <span>user_id</span><span>:</span> <span>libc</span><span>::</span><span>uid_t</span><span>,</span>
    <span>pub</span> <span>group_id</span><span>:</span> <span>libc</span><span>::</span><span>gid_t</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span> <span>// should be in 512 bytes blocks</span>
    <span>pub</span> <span>size</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>accessed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>changed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>direct_blocks</span><span>:</span> <span>[</span><span>u32</span><span>;</span> <span>DIRECT_POINTERS</span> <span>as</span> <span>usize</span><span>],</span>
    <span>pub</span> <span>indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>double_indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>As you can see above, inodes support double indirect pointers which means that
for a disk with a block size of 4 KiB, the maximum capacity of a file is 4 GiB.
The number of direct pointers is set to 12:</p>

<div><div><pre><code><span>pub</span> <span>const</span> <span>DIRECT_POINTERS</span><span>:</span> <span>u64</span> <span>=</span> <span>12</span><span>;</span>
</code></pre></div></div>

<p>When starting the FS for the first time, it will create the root directory using
the definition below:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Directory</span> <span>{</span>
    <span>pub</span> <span>entries</span><span>:</span> <span>BTreeMap</span><span>&lt;</span><span>OsString</span><span>,</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<h3 id="block-groups">Block groups</h3>

<p>The inode bitmap has 4 KiB meaning that each bitmap block will have a capacity
for 32768 inodes. Suppose we round up the size of an <code>Inode</code> to 128 bytes; the
corresponding inode table will require 4 MiB of space. One of the ways for
structuring them would be to have many blocks dedicated to the bitmaps, then the
corresponding number blocks to store the inodes, and the remaining blocks for
user data.</p>

<p>Instead of doing that, we can create <em>block groups</em> that will always have one
block for the data bitmap and one for the inode bitmap. The next 1024 blocks
contain the inode table, and following that, 32768 blocks which are used for
user data.</p>

<!--
For a disk as in our case of 10 GiB, how many blocks should be dedicated to inode bitmaps?

Increasing the number of blocks to be inode bitmaps reduces the amount of available data blocks. And reducing the number of inode bitmaps restricts the total number of files supported by the system.
-->

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs_block_group.svg" alt="">
    <figcaption>Block groups</figcaption>
</figure>

<h3 id="reading-and-writing-to-files">Reading and writing to files</h3>

<p>Now that the “disk” is set up, we can start writing and reading files from it. Creating a new directory using <code>mkdir</code>:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/mkdir.gif" alt="">
    <figcaption>Creating a directory</figcaption>
</figure>

<p>The process that occurs is the following: the system searches for the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html">https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</a></em></p>]]>
            </description>
            <link>https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967016</guid>
            <pubDate>Mon, 27 Jul 2020 17:04:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Your DevOps Control Plane, in Slack]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23967015">thread link</a>) | @slajax
<br/>
July 27, 2020 | https://cto.ai/blog/slack-control-plane-for-devops-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/slack-control-plane-for-devops-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<blockquote>We're <a href="https://news.ycombinator.com/show">trending on Hacker News</a> - Please join the conversation there!</blockquote><p>In today's remote first world, Slack is increasingly becoming the natural place that communication and collaboration happen in all aspects of work. Personally, I look at Slack each morning before I look at email or even social media, making it the natural jump off point for the most important interactions that I have professionally.</p><div><p>Never has this also been more true, than for complex developer workflows which teams need to share to ensure enablement across their entire development team.</p><p>Traditionally, a developer would have to interface with many different softwares in order to complete their tasks, increasing the context that they need within each domain in order to complete their job. All of this comes at the expense of developer productivity and this is why CTO.ai set out to improve the holistic developer experience by re-imagining what DevOps should look like, Slack first.</p><p>Today we are happy to announce that we're continuing to invest into our mission to make DevOps more accessible and enjoyable for the next 40 million developers with the release of our Slack Home feature, which naturally acts as an easily accessible Control Plane for all of your team's developer workflows!</p></div><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><div><p>Within the Slack Home, you can quickly navigate the CTO.ai teams which you have joined and easily execute the workflows associated to that team, simply by clicking the Run button and picking the channel that you want to run the workflow in.</p><p>This makes it even easier for DevOps teams and Senior Engineers to build and distribute their developer tools to their entire team by creating a centralized control plane for accessing these often privileged and complex workflows.</p><p>Team management has also become centralized. At a glance, leads can see what teams they have created, what channels are associated to them and who are the members of the teams. You can now add team members from this location as well.</p><p>Soon, we'll also allow you to look at Workflow Events and even Metrics associated to the custom workflows that each team has architected, which represent their deliverables and day to day work, empowering leads with a strong feedback loop.</p></div><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab-teams.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><p>When a developer executes a workflow, the workflow can be then targeted to run in any channel which is associated to the team, giving the same inherit benefits which many of our users are already enjoying with SlackOps, such as; Secrets, Configs, Logs, Events and ultimately the inherent transparency and accessibility of Slack.</p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab-runop.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><p>Here is a quick video overview of how this new feature works:</p><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/8RxGak-Bl3I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>A demo of the new Slack Home - a control plane for DevOps workflows</figcaption></figure><!--kg-card-end: embed--><p>We're really excited about what this new feature does to unlock the power of DevOps to truly enable Devs to leverage the 10x power of Ops. We believe this is a huge step in the right direction that will enable inclusivity and empowerment of developers on teams all around the world to adopt DevOps in their team.</p><div><p>We’re still just getting started though so if you have any suggestions or questions feel free to reach out to <a><span data-cfemail="8efdfbfefee1fcfaceedfae1a0efe7">[email&nbsp;protected]</span></a>. We are building where collaboration will happen for the next 40 million developers and we can't do it alone.</p><p>Sign up for more information and to get a free demo of our platform today!</p></div><!--kg-card-begin: html--><!--[if lte IE 8]>
<script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script>
<![endif]-->

<!--kg-card-end: html-->
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/slack-control-plane-for-devops-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967015</guid>
            <pubDate>Mon, 27 Jul 2020 17:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I couldn't buy a car because my email address was 'invalid']]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 20 (<a href="https://news.ycombinator.com/item?id=23965584">thread link</a>) | @jawns
<br/>
July 27, 2020 | https://shaungallagher.pressbin.com/blog/invalid-email.html?ref=hn | <a href="https://web.archive.org/web/*/https://shaungallagher.pressbin.com/blog/invalid-email.html?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="portfolio">
        <div>
            <div>
                <div>
<div>





<p>Our spunky little Honda Fit is now 13 years old, and although it has served us well, we have begun to outgrow it.</p>

<p>I started researching minivans, and one particular online-only auto seller seemed to have an attractive inventory.</p>

<p>So I decided to create an account with them and set up some filters and alerts.</p>

<p>But creating an account was harder than it appeared.</p>

<p>I entered my email address on their sign-up page.  The input field immediately turned red, and the page informed me that my email address was invalid.</p>

<p>I encounter this problem occasionally, because I use subaddressing in my email address.</p>

<p>A normal email address looks like this: <code>username@domain.com</code>.</p>

<p>When you use subaddressing, you tack on a little extra bit between your username and the @ sign: <code>username+subaddress@domain.com</code>.</p>

<p>When the site emails you, the subaddress gets ignored for the purpose of routing the message to you, 
   but it shows up in the "To" field of the email address.  That can be tremendously useful.  It allows
   you to set up filters to always allow or always deny messages that include a specific subaddress,
   and it can sometimes be used to determine whether a site has had a data breach or sold your contact
   information to spammers.</p>

<p>Although subaddressing is widely supported by email service providers, including Google's Gmail, it continues to trip up sites
   that perform email address validation using regular expressions, also known by the abbreviation regex.</p>
   
<p>Regex allows site developers to specify what a valid email address looks like.  
   It can determine whether an email address contains invalid characters, or whether it's missing an @ sign.</p>
   
<p>The problem is, valid email addresses come in many forms, and many regular expressions used to validate email addresses
   are not able to recognize the full range of valid formats.</p>
   
<p>In the case of the auto seller's form validation, I was able to inspect their Javascript code.
   The portion of the email validation regex that deals with the username (the part before the @ sign)
   looks like this:</p>
   
<p><code>^[_a-zA-Z0-9-]+(\.[_a-zA-Z0-9-]+)*</code></p>

<p>The key thing about this regex snippet is that the only characters that are considered valid are
   alphanumeric characters, hyphens, underscores, and periods.</p>
   
<p>If a plus sign is present, as when using subaddressing, it treats the email address as invalid, even though it is perfectly valid
   — and has been for years.</p>
   
<p>While it's frustrating that many sites continue to reject email addresses that use subaddressing, I have a Plan B.</p>

<p>I instead use a secondary email address without subaddressing, which is associated with <a href="https://newlywed.science/">newlywed.science</a>,
   a domain I use to promote my book <i>Experiments for Newlyweds</i>.</p>
   
<p>I entered that email address into the sign-up form, but again I was informed that it was invalid.</p>

<p>I took another look at the email validation regex and discovered an even stupider issue.</p>

<p>Here is the portion of their email validation regex that deals with the domain (the part after the @ sign):</p>
   
<p><code>[a-zA-Z0-9-]+(\.[a-zA-Z0-9-]+)*(\.[a-zA-Z]{2,4})$</code></p>

<p>The relevant part of this snippet is at the very end.  It says that the top-level domain (TLD) must be between two and four letters long.</p>

<p>The most well-known TLDs, such as .com, .org, .net, .edu, and .gov, tend to have three letters.  
   Country-specific TLDs, such as .uk or .de, tend to have two letters.</p>
   
<p>But starting around the turn of the century, more and more new TLDs came into use.  
   For instance, .museum became active in June 2001, and .travel began accepting registrations in January 2006.</p>
   
<p>So TLDs that exceed four letters in length have been around for quite a while.</p>

<p>Yet anyone with an email address associated with such a TLD is locked out of creating an account with this auto seller because of this regex.</p>

<p>It's frustrating that major websites continue to rely on such shoddy email address validation, and this time I decided to make my frustration known.</p>

<p>I searched around for a contact email address on the site, but the best I could find was a Live Chat feature.</p>

<p>So, at 2 p.m. Eastern, I opened a Live Chat session and encouraged them to fix their terrible regex.</p>

<p>A robo-responder informed me that unfortunately, my message could not be handled, because Live Chat is only available between 8 a.m. and 8:45 p.m. Eastern.</p>


</div>

                </div>
            </div>
        </div>
    </section></div>]]>
            </description>
            <link>https://shaungallagher.pressbin.com/blog/invalid-email.html?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23965584</guid>
            <pubDate>Mon, 27 Jul 2020 14:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing an Open Source Texture Synthesis Library]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23965457">thread link</a>) | @underanalyzer
<br/>
July 27, 2020 | http://peterstefek.me/texture-optimization.html | <a href="https://web.archive.org/web/*/http://peterstefek.me/texture-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>26 July 2020</strong></label></p><p><strong>Background</strong><br>
Near the end of 2019 I stumbled across this <a href="https://www.youtube.com/watch?v=fMbK7PYQux4&amp;t=6m57s">talk</a> by procedural generation researcher <a href="https://www.anastasiaopara.com/">Anastasia Opara</a>. In the talk she presents a novel algorithm for example based texture synthesis. The goal of example based texture synthesis is to take one or more example textures and synthesize a new visually similar output texture.    </p>
<p>Here's an example from the project README:
  </p><p>
    <img src="http://peterstefek.me/images/texture-optimization/readme-example.jpeg" width="70%"> 
</p> 
<p>I was really curious about this algorithm and wanted to see if I could make it run faster as an exercise in profiling.  </p>
<p><strong>Embarking on a Journey</strong><br>
While I'm not going to go into great detail about how the algorithm works (see Anastasia's talk if you're curious!) it's helpful to understand the basic idea.  </p>
<p>
    <img src="http://peterstefek.me/images/texture-optimization/synthesis-diagram.png" width="80%"> 
</p>

<div><p>We start with an empty output image and seed it with a few random pixels from our example images.<br>
Then repeat the following procedure until the output image is filled: </p><p> 
1. Choose an empty pixel in the output image. We will call this the center pixel.<br>
2. Find the k closest non empty pixels to the center in the output image. Note in the first few steps there might be fewer than k pixels in the entire output image. The locations of these k pixels relative to the center pixel define a neighborhood.<br>
3. Come up with a list of the most promising neighborhoods in the example image(s)<br>
4. Compare the most promising candidate neighborhoods in the example image(s) to the neighborhood around the center pixel and pick the most similar one.<br>
5. Fill the center pixel in the output image with the color of the center pixel in the best matching neighborhood.  </p></div>
<p>One last important detail is that the algorithm works on filling multiple empty pixels in parallel to take full advantage of multi core cpus.  </p>
<p><strong>Missteps and Micro optimizations</strong><br>
Now it was time to optimize. The first thing I did was to run the program on a few sample inputs with the xcode instruments profiler (partly because it was new to me). I even found a cool <a href="https://www.reddit.com/r/rust/comments/b20eca/introducing_cargoinstruments_zerohassle_profiling/">library</a> which made it easier to use instruments with rust. Using instruments I was able to see how much each instruction contributed to the overall runtime of the program.  </p>
<p>Being able to see time per instruction was perfect for me because I was looking for micro optimizations. I'm using the term micro optimization here to mean a very small change which has a relatively large impact compared to its size. Even though they are not always a good idea, micro optimizations seemed like the best place to start because they would be less of an investment on my end. I also didn't know if the project maintainers would be excited about large code changes.  </p>
<p>Looking at the profiler output I was drawn to this line which looked like an unnecessary array resize operation nested within our once per pixel loop.  </p>
<p>
    <img src="http://peterstefek.me/images/texture-optimization/first-profile.png" width="90%"> 
</p>

<p>An important note about interpreting the numbers above is that this algorithm runs in several passes and is divided among multiple threads. The image above only shows one pass which accounts for about 12.6% of the runtime of the entire program. However each pass contains the highlighted instruction and behaves similarly. To get a rough estimate of the true impact of this instruction these percentages should be multiplied by a factor of about 8 (100/12.6). So the highlighted instruction really accounts for about 9.5% of the total program runtime.</p>
<p>After I eliminated the unnecessary array resize instruction I ran the program through the profiler again which seemed to confirm that it had gotten about 10% faster which I figured was pretty good for a first try. Of course, the profiler adds some overhead to the program, so to truly confirm that my optimization worked I needed to run it on a couple of examples without any profiling. When I did this I was shocked to see no improvement. </p>
<p>So what was happening? It turns out the cargo-instruments command I was running compiled the program in <a href="https://users.rust-lang.org/t/why-does-cargo-build-not-optimise-by-default/4150">debug mode by default</a> which turned off significant optimizations. When I built the program in release mode the unnecessary array resize was automatically removed. I learned two very important lessons from this: First, of all when you benchmark you have to think carefully about what exactly you're benchmarking. Secondly, the compiler is smart and makes some micro optimizations for you.  </p>
<p>A little embarrassed and somewhat defeated, I went back to the drawing board.  </p>
<p>I grabbed a couple more profiles making sure this time to use release mode. After poking around some more I found that a significant amount of time was being spent loading pixels from the source images into intermediate buffers which were later used for neighborhood comparisons step of the algorithm.  </p>
<p>
    <img src="http://peterstefek.me/images/texture-optimization/second-profile.png" width="90%"> 
</p>

<p>Again using the same runtime adjustment from the last profiling section this function seemed to take about 37.6% of the total runtime. I suspected cache misses were a significant contributor here, but regardless of the actual problem source I knew that reading the neighborhood pixels for each candidate was expensive.   </p>
<p>Of course the algorithm still needed to do the candidate neighborhood comparisons so I couldn't completely eliminate reading each candidate's neighborhood pixels. Luckily for me there was already a related optimization in the project,</p>
<p>This related optimization targeted the actual comparison step when finding a best candidate neighborhood. In the comparison step each candidate neighborhood was assigned a score by summing up the differences (always positive) between it's pixels and the target's neighborhood pixels. It turned out that often you could stop summing up these differences early if you already knew this current candidate's score was going to be higher than the best candidate's score so far.   </p>
<p>Once I understood this I just extended the idea to avoid reading the pixels needed for the unnecessary comparisons by removing the intermediate buffers and reading pixels only as they were needed which seemed to greatly reduce the average number of reads. I tested my optimization on a few different laptops with several output sizes using references images from the repository as inputs. It seemed like I had improved performance by around 15-25% depending on the output texture size, reference images and the computer I was using.  </p>
<p>Quantifying performance impact was a lot harder than I thought it would be. There were so many different parameters to the program that could affect performance: size of the reference image(s), size of the output images, number of threads. Hardware differences were also a huge factor. If I were really being rigorous I would have tried to put together a large collection of images and output sizes to benchmark off of. Due to time and budget constraints I did not assemble a super rigorous benchmark but my appreciation for the problem of performance testing has grown tremendously.  </p>
<p>Once I was confident that my micro optimization worked I made my <a href="https://github.com/EmbarkStudios/texture-synthesis/pull/69">first pull request</a>. It was accepted but to my surprise the performance gains that the reviewers saw were not nearly as good as the ones I did. When one of them benchmarked it on an AMD Threadripper (with 64 virtual cores) the speed up was so small it might have just been noise.  </p>
<p><strong>Blocking And Locking</strong>  </p>
<p>At this point I decided to use some Google Cloud free trial credits I had lying around to spin up some larger machines to test on. Using a 64 core machine I noticed that just like on the thread ripper I didn't see much of a performance improvement from my micro optimization. I tried multiple tests with different numbers of threads (from 0 up to 64) and saw that as the number of threads increased the performance gain from my optimization dropped.  </p>
<p>So in my mind there were two explanations. First was that my optimization didn't save as much time when there were multiple threads. Second was that there was another source of latency which increased with the number of threads and that simply got so big it drowned out any noticeable effects of my optimization. It turned out this second explanation was correct.  </p>
<p>The additional source of latency turned out to be thread contention. To get the k nearest neighbors for each candidate pixel the algorithm was using a data structure called an r*tree. An r*tree provides a way to efficiently store points for nearest neighbor lookups. Exactly how an r*tree works is not actually super important here. The problem was that there was only one r*tree shared across the entire image. To prevent race conditions the r*tree had been wrapped in a read-write lock. This type of lock allows parallel reads but writes must happen in series. Reads also cannot occur while a write is in progress. With large numbers of threads, writing became a large bottleneck. Looking at a graph of program runtime versus number of cores also helps illustrate this effect.  </p>
<p>
    <img src="http://peterstefek.me/images/texture-optimization/before-graph.png" width="50%"> 
</p>

<p>What I realized is that after a few pixels had been filled in the chance that one of the k nearest neighbors would be super far away from the candidate pixel was negligible. So I broke the images in to a grid of r*trees. The basic idea was that writes in two close cells could still block but writes in two far away cells could now be done in parallel. More details can be dound in <a href="https://github.com/EmbarkStudios/texture-synthesis/pull/70">my second pull request</a>. To see the improvement from this change we can look at this graph below of synthesis speeds before / after:</p>
<p>
    <img src="http://peterstefek.me/images/texture-optimization/after-graph.png" width="50%"> 
</p>

<p>An important note here is that the improved version does not scale linearly either. In an ideal world maybe it would but there are several complicating factors that are at play here. First of all the program has some initialization costs as well as having to synthesize the first few pixels in series. Both of these steps cannot be parallelized. Secondly contention is complicated and can crop up in many places. I believe I did eliminate a large source of contention but I'm sure there is more that could be done. Finally this algorithm is not <a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a> and will ultimately have to have some amount of informtion shared between threads.</p>
<div><p><strong>Tricks and Trade Offs</strong><br>
Overall I …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://peterstefek.me/texture-optimization.html">http://peterstefek.me/texture-optimization.html</a></em></p>]]>
            </description>
            <link>http://peterstefek.me/texture-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23965457</guid>
            <pubDate>Mon, 27 Jul 2020 14:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of Synthetic Audio Deepfakes]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23965106">thread link</a>) | @ajay-d
<br/>
July 27, 2020 | https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes | <a href="https://web.archive.org/web/*/https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <h6>
        
        
        
        
        
        6 min read
        
      </h6>
        

        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><div class="page" title="Page 2">
<div>
<div>
<div>
<p><strong>Can Audio Deepfakes Really Fake a Human?</strong></p>
<p>Audio deepfakes are the new frontier for business compromise schemes and are becoming more common pathways for criminals to deceptively gain access to corporate funds. Nisos recently investigated and obtained an original attempted deepfake synthetic audio used in a fraud attempt against a technology company. The deepfake took the form of a voicemail message from the company’s purported CEO, asking an employee to call back to “finalize an urgent business deal.” The recipient immediately thought it suspicious and did not contact the number, instead referring it to their legal department, and as a result the attack was not successful.</p>
</div>
</div>
</div>
</div>
<!--more-->
<p>Nisos investigated the phone number the would-be attacker used and determined it was a VOIP service with no owner registration information. It was likely simply acquired and used as a “burner” for this fraud attempt only. While there was no actual voicemail message associated with the number, we made no attempt for live contact with the owner of the phone number for legal reasons.</p>

<p><strong>Deepfake Audio Analysis</strong></p>
<p>Nisos analyzed the deepfake voicemail audio recording with an audio spectrogram tool called Spectrum3d. Looking to detect any anomalies, we immediately noticed the highs spiking repeatedly in the spectrogram (see graphic below). We initially suspected the deepfake creator used audio playing over on multiple channels to help mask the voice.</p>
<p><strong><i><img src="https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=351&amp;name=pasted%20image%200%20(7).png" alt="pasted image 0 (7)" width="351" srcset="https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=176&amp;name=pasted%20image%200%20(7).png 176w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=351&amp;name=pasted%20image%200%20(7).png 351w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=527&amp;name=pasted%20image%200%20(7).png 527w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=702&amp;name=pasted%20image%200%20(7).png 702w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=878&amp;name=pasted%20image%200%20(7).png 878w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=1053&amp;name=pasted%20image%200%20(7).png 1053w" sizes="(max-width: 351px) 100vw, 351px"></i></strong><strong><i>Graphic 1: Spectrogram analysis of the deepfake audio, displaying major inconsistencies in pitch and tone.</i></strong></p>
<p>We additionally noticed the audio was very choppy and not consistent with a similar human voice recording. When we altered the audio speed and played back at 1.2 speed, the audio then sounded more like a standard text to speech system. Most interesting, when we amplified the sound to detect any background noise we were unable to find any traces, which further indicated this was manipulated audio.</p>
<p>We then compared the deepfake spectrogram analysis with results of a "normal" human voice on a similar recording. We can immediately see how the pitch and tone is more smoothed out, as well as the ability to detect faint background noise.</p>
<p><strong><i><img src="https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=351&amp;name=unnamed%20(4).png" alt="unnamed (4)" width="351" srcset="https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=176&amp;name=unnamed%20(4).png 176w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=351&amp;name=unnamed%20(4).png 351w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=527&amp;name=unnamed%20(4).png 527w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=702&amp;name=unnamed%20(4).png 702w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=878&amp;name=unnamed%20(4).png 878w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=1053&amp;name=unnamed%20(4).png 1053w" sizes="(max-width: 351px) 100vw, 351px"></i></strong><strong><i>Graphic 2: Spectrogram analysis of ‘normal’ human voice, displaying more consistent pitch and tone.</i></strong></p>
<p>We were unable to determine the exact software or voice model used to create this deepfake as we would have required access to a large enough sample of the attacker’s other deepfake audio files (we would likely need tens if not hundreds of files, and this assumes the attacker made more than just this one). However, we note several complicating factors an actor would have to overcome to create a more realistic deepfake audio:</p>
<ol>
<li>Capturing high quality audio with little to no background noise.</li>
<li>Staging the call for audio delivering in a realistic scenario (tone of the person talking, background noise and reason for the call) in which the person wouldn’t feel the need to call the person back.&nbsp;</li>
<li>Finding a way to leave a message, so they can avoid an in-person conversation.</li>
</ol>
<p>It is likely the attacker in this scenario above utilized a feature most cell/VOIP service providers offer, which is the ability to bypass the ring option and go straight into the voice mail using the `#` key.</p>

<p><strong>Has This Happened Before?</strong></p>
<p>The most famous use of deep fake synthetic audio technology in criminal fraud was a September 2019 incident involving a British energy company. The criminals reportedly used voice-mimicking software to imitate the British executive’s speech and trick his subordinate into sending hundreds of thousands of dollars to a secret account.&nbsp;</p>
<p>The managing director of this company, believing his boss was on the phone, followed orders to wire more than $240,000 to an account in Hungary.<sup>1</sup></p>
<p>Symantec security researchers reported in February on three cases of audio deepfakes used against private companies by impersonating the voice of the business’s CEO.<sup>2 </sup>The criminals reportedly trained machine learning engines from audio obtained on conference calls, YouTube, social media updates and even TED talks, to copy the voice patterns of company bosses.&nbsp;</p>
<p>They created audio deepfakes replicating the CEO’s voice and called senior members of the finance department to ask for funds to be sent urgently. There was no additional reporting on which companies these were, whether the techniques were successful, or whether Symantec was able to obtain recordings of the deepfakes themselves.</p>
<p>Without actual digital capture of the audio, and additional forensics analysis, it is unclear whether these attempts were in fact deepfake synthetic manipulated audio. Regardless, the ability to generate synthetic audio extends an e-criminal’s toolkit and the criminal at the end of the day still has to effectively use social engineering tactics to induce someone into taking an action.&nbsp;</p>
<p>Criminals and potentially broader nation state actors also learn from each other, so as these high-profile cases gain more notoriety and success, we anticipate more illicit actors trying them and learning from others who have paved the way.</p>
<p>Additionally, as deepfakes become easier to create or purchase, and the quality of synthetic manipulation -both audio (and video)- increases, we anticipate wider deployment of these e-crime exploits. If a fraud operation requires the use of a completely fake doctored video or audio for maximum impact, and it is worth the money and resources, it will be used. However, Nisos researchers have not seen the ability to easily outsource this type of deepfake for single individual or mass production.</p>
<p>Our researchers have contact with a few deepfake channels where we asked about this type of attack vector and participants were unsure something like this would be possible in the near future. The central issue with audio deepfakes has to do with capturing not only the person’s tone but also specific speech mannerisms. Future scenarios will likely materialize, however, where tools similar to a Yandex reverse image search (but for voice) could be used to gather numerous samples and then build and train a model that could help convert the source voice into the target voice.</p>

<p><strong>What Can Be Done?</strong></p>
<p>The most immediate action an employee can take, if they sense something suspicious in a voicemail (or any audio) instruction, is to call the person back directly using a known number and get them on the line.&nbsp;</p>
<p>Deepfake technology is not sophisticated enough to mimic an entire phone call with someone. Additionally, the company can exercise a series of ‘challenge questions’ using information that is not publicly known or conversation points that an actor could not readily answer, to vet the identity of the individual on the line.</p>
<p>This fraud scheme is a form of a business email compromise (a more sophisticated and AI-developed version) where typically the attacker will pretend to be a senior executive at a company and get a more susceptible ‘lower-level’ employee to send money to a bank account.&nbsp;</p>
<p>We would anticipate a deepfake audio would be the first step in a series of social engineering attempts to get an employee to wire money to a specific location. Phishing emails, additional phone calls, or even deepfake videos purporting to authorize an action could be used in furtherance of the criminal scheme.&nbsp;&nbsp;</p>
<p>Deepfake audio may also be used for reasons ancillary to the ones listed above. For example, criminals can leave fake messages instructing employees to provide network or physical access to the company, allowing attackers to easily compromise the network or physical assets of the company.</p>
<p>The availability of this nascent but rapidly-emerging technology emphasizes the criticality with which companies must develop security practices that encompass these measures. Any time an unusual incident occurs, and certainly when large financial transactions are involved, employees should be trained to ask challenge questions to senior executives.</p>

<p>Research featured in <a href="https://www.vice.com/en_us/article/pkyqvb/deepfake-audio-impersonating-ceo-fraud-attempt" rel=" noopener">Vice Article</a><span> by </span><a href="https://www.vice.com/en_us/contributor/lorenzo-franceschi-bicchierai">Lorenzo Franceschi-Bicchierai.</a></p>
<p>Twitter Handle: Rob Volkert <a href="https://twitter.com/DiligenceWatch" rel=" noopener"><span>@DiligenceWatch</span></a></p>
<hr>
<p><em>1. <a href="https://www.washingtonpost.com/technology/2019/09/04/an-artificial-intelligence-first-voice-mimicking-software-reportedly-used-major-theft/" rel=" noopener">https://www.washingtonpost.com/technology/2019/09/04/an-artificial-intelligence-first-voice-mimicking-software-reportedly-used-major-theft/</a></em></p>
<p><em>2. <a href="https://www.icaew.com/insights/features/2020/feb-2020/the-rise-of-deepfake-audio-fraud" rel=" noopener">https://www.icaew.com/insights/features/2020/feb-2020/the-rise-of-deepfake-audio-fraud</a></em></p>
</span>
        </p>
        
            
        

        
        
        
    </div>
</div></div>]]>
            </description>
            <link>https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23965106</guid>
            <pubDate>Mon, 27 Jul 2020 13:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s easier to manage four people than one person]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23964905">thread link</a>) | @chesterarthur
<br/>
July 27, 2020 | https://staysaasy.com/management/2020/07/24/Managing-One-Person.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/07/24/Managing-One-Person.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>It’s easier to manage 4 people than it is to manage one person. The primary reason for this is the inherent over-reliance in the relationship between a manager and a single report. Let’s dive deeper.</p>

<p>It’s not uncommon for a first-time manager to get a single direct report. Try it out. See how it goes. Here’s what this ends up looking like:</p>
<ul>
  <li>The new manager is over-reliant on making sure their single report likes them and is doing well. If they give feedback that their manager stinks, that’s 100% bad feedback from your reports. If the report doesn’t do well, that’s 100% of your reports that aren’t succeeding.* If the report quits, you just lost your whole team.</li>
  <li>The manager’s over-reliance on the direct report’s success and happiness leads to risk-averse behavior, like not giving critical feedback or overcompensating. It also regularly leads to micromanagement.</li>
  <li>The single report is isolated. They don’t have any peers on the team to reach out to for help. If their manager is bad, they don’t have any corroborating voices. Anything that goes wrong is a they-said I-said debate. Any debate inside of the team is a faceoff with your manager.</li>
  <li>No one in this relationship has the ability to get context. With more reports, a manager gets clearer signals when they’re wrong. A report could look to teammates to corroborate or dissuade their ideas. With one report, disagreements have little additional evidence, so people have to either approach the situation with a supreme lack of ego, or they can just assume it’s the other person’s fault. Guess which option happens most.</li>
</ul>

<p>To further the problematic conditions, the single report will often be a very junior hire. This compounds the issue. Straight-from-college hires don’t have great context for what it means to be in industry, to have a manager, to work a job with no end-of-semester in sight. And hires aren’t expected to have as much autonomy in their formative early years. With these variables, the requirements on the manager are higher than average.</p>

<p>It’s not uncommon for these relationships to turn sour. The manager makes mistakes as they always do. The report makes mistakes as they always do. Fingers are pointed. Times are dire. If you ever hear someone call their manager a “first-time manager”, you know the relationship has reached a special level of hell.</p>

<p>To avoid this situation, consider doing the following:</p>
<ul>
  <li>Avoid having first time managers have a team of 1 individual contributor for a prolonged amount of time. That team size is an <a href="https://staysaasy.com/management/2020/06/21/goldilocks-management-structure.html">anti-pattern</a> for more reasons than just this one.</li>
  <li>Try and make sure the manager of a team with 1 individual contributor is also an expert in the domain area. Sometimes managers are explicitly not the domain expert by design, but when you have 1 report, a lack of domain expertise is one of the sure-fire ways to make mistakes and a sure-fire way for your report to get the idea that you’re no good.</li>
  <li>Avoid at all costs the combination of: new manager, 1 report, report is new-to-industry, manager is not a subject-matter expert.</li>
</ul>

<p>* Note: mangers should be very invested in their report’s success. But when the manager is <em>over-invested</em> it leads to all sorts of unsavory things, some of which are called out above. Another example is when a report is doing well-enough, but because the manager is <em>over-reliant</em> on their performance, they try to push the report beyond what they can or want to do.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/07/24/Managing-One-Person.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964905</guid>
            <pubDate>Mon, 27 Jul 2020 13:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fanouts and Percentiles: Visualizing Latency in Distributed Systems]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23964821">thread link</a>) | @ptc
<br/>
July 27, 2020 | https://paulcavallaro.com/blog/fanouts-and-percentiles/ | <a href="https://web.archive.org/web/*/https://paulcavallaro.com/blog/fanouts-and-percentiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div role="main">
    <div>
      

      <article>
      



<p>In today’s post we’re going to talk about latencies in a common distributed
system architecture: The root-leaf, or parent-child, fanout architecture. We’ll
try to gain an intuition for what drives tail latency, derive a formula for
tying together the parent and child latency distributions, and provide a useful
interactive visualization to help understand tail latency in these systems.</p>

<h3 id="root-leaf-fanout-architecture">Root-Leaf Fanout Architecture</h3>

<p>When dealing with distributed systems, it’s a common pattern to have a root
aggregator node that fans-out requests to many leaf nodes that do work in
parallel, then send back their response to the root node to aggregate and
create a final response. Usually the API of the system is exposed through the
root-aggregator nodes, so the latency of these root nodes is what matters.</p>

<p>As seasoned distributed system developers, we know that latency (and
performance) is a
<a href="https://medium.com/lightstephq/performance-is-a-shape-not-a-number-a3c1a9ae19cc">shape not a number</a>.
What this means is that we shouldn’t concern ourselves solely with what the
average latency of a service is – we care about the full latency distribution
– and at the very least we should care about the tail. Usually people settle on
monitoring the $90^{th}$ or $99^{th}$ percentile (p90 or p99), and maybe use a
heatmap to visualize the whole latency distribution.</p>

<p>In the case of our parent-aggregator and many children setup, if we’re going to
concern ourselves with its p99 latency, it’d be nice to know for a given fanout,
how fast do our children nodes have to be to get a certain p99 parent
latency. This is also useful when debugging, but in reverse. If I see a p95
latency spike for the parent node, what percentile latency on the children nodes
do I need to care about? How does this change with the fanout size?</p>

<h3 id="defining-the-problem">Defining the Problem</h3>

<p>Before we analyze the problem any further, we should first define exactly what
problem we’re analyzing. In its simplest form, the parent-child system has two
defining properties:</p>

<ol>
<li>Parent latency for a request is greater than or equal to the max of all the children latencies, since the parent must wait for all child responses.</li>
<li>Child latency inevitably has a long tail.<sup id="fnref:1"><a href="#fn:1">1</a></sup></li>
</ol>

<p>These two properties mean that as we fan out to more children, our parent
latency will get worse, because we’re more likely to hit a long tail latency
event. And conversely if we can reduce our fanout or reduce the variance in our
child latency we’ll be able to drive down our overall latency.</p>

<p>What’s not immediately obvious though is the magnitude of the effect of reducing
fanout or improving child latency variance is. To try to gain some
understanding, let’s consider a situation where the child latency follows a
<a href="https://en.wikipedia.org/wiki/Log-normal_distribution">log normal distribution</a>
with $\mu = 3$ and $\sigma = 0.2$ and consider the latency distributions of the
child, and parents who fan out to varying number of children per request: 10,
100, 1000.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Now we’ll visualize the reconstructed
<a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density functions</a>
based on observations from generated data, for both the children and the parents:</p>

<p><img src="https://paulcavallaro.com/images/fanouts-child-parent-pdfs-density-plot.png" title="Density plot of child and parent latency probability density functions"></p>

<p>What’s immediately obvious is that as the fanout increases, the parent latency distribution gets worse and worse, and is dominated by the tail latency of the children. By the time we’re fanning out to 1000 children, the parent latency distribution looks almost completely unrelated to the child latency distribution. While we could have predicted this, hopefully this visualization helps build up our intuition of the problem.</p>

<h3 id="deriving-a-closed-form-solution">Deriving a Closed Form Solution</h3>

<p>We began this adventure trying to answer a question, and now it is time to return to it: <em>What child latency percentile drives a given parent latency percentile?</em></p>

<p>Although the problem is pretty simple, I wrestled with it a bit until a friend
pointed out that you can think of a percentile latency as not describing a point
in the latency distribution but instead as a <em>probability</em> that a request
finishes in a given amount of time. So if the p90 latency is 10ms, we can
reframe this as saying that the probability a request finishes within 10ms is
$90\%$.</p>

<p>When we combine this insight with the fact that a parent request only finishes
once all its children requests finish, we can derive a closed form solution to
our problem.</p>

<p>Since the parent request finishes only after all $N$ children requests finish,
then the probability the parent request finishes in time $t$, is the probability
that all $N$ children finish in time $t$. Assuming all children latencies are
<a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed</a><sup id="fnref:3"><a href="#fn:3">3</a></sup>
then we can calculate the parent probability as:</p>

<p>$$
P_{parent\ finishes\ in\ t\ secs} = (P_{child\ finishes\ in\ t\ secs})^N
$$</p>

<p>which when we solve for child latency percentile gives us the following formula:</p>

<p>$$
P_{child} \approx \sqrt[N]{P_{parent}}
$$</p>

<p>Now that we have a formula for our problem, we can begin inspecting some
secnarios. If we cared about the $90^{th}$ percentile latency of the parent,
and the fanout was to 2 children, then we would need to care about the
$94.86^{th}$ percentile at the children, since $\sqrt{0.9} \approx 0.9486$.</p>

<p>One thing about this formula that can be surprising, is how quickly the child
percentile we have to care about grows as we increase the fanout. Even fanning
out to 20 children, and monitoring the $90^{th}$ percentile latency of the parent,
we need to care about the $99.47^{th}$ percentile latency of the children!</p>

<p>The graph below shows how quickly $50^{th}$, $90^{th}$, and $99^{th}$ parent
percentile latency converges to being driven by the $100^{th}$ percentile child
latency as fanout size grows.</p>

<p><img src="https://paulcavallaro.com/images/fanouts-parent-latency-percentile.png" title="Graph of Child Percentile Latency vs. # of Children in Fanout"></p>

<p>Here is a zoomed-in view focusing on the $90^{th}$ percentile and above:</p>

<p><img src="https://paulcavallaro.com/images/fanouts-parent-latency-percentile-zoomed.png" title="Graph of Child Percentile Latency vs. # of Children in Fanout Zoomed"></p>

<p>We can see that if we’re monitoring the p90 latency of the parent, by the time we fan out to 10 children, we’ll have to start caring about the p99 latency of the children.</p>

<h3 id="trust-but-verify-and-visualize">Trust, but Verify (and Visualize)</h3>

<p>Although the formula makes sense, and the intuition behind it sounds reasonable<sup id="fnref:4"><a href="#fn:4">4</a></sup>, I often find it helpful when confronted with a formula to verify its correctness by simulation. So I below is a little simulation and visualization to do just that. <strong>The main spiffiness comes when you hover over a bar in either distribution</strong>, as the visualization will highlight both the percentile in its distribution as well as highlight the corresponding percentile in the other distribution:</p>






<p>The above is an example visualization generated from a generalized tool, simulating 3000 requests to a parent fanning out to 20 children, where the child latency distribution is a log normal distribution with $\mu = 3.4$ and $\sigma = 0.3$. The tool itself is <a href="https://paulcavallaro.com/standalone/fanouts.html">hosted here</a>, and the code is in this <a href="https://github.com/paulcavallaro/fanouts-and-percentiles">github repo</a>.</p>

<p>Now we can use this visualization to confirm our formula empirically. If we hover over the bar that correlates with the p95 latency in the parent distribution, our formula predicts that the child latency it corresponds to should be $\sqrt[20]{0.95} \approx .9974$ or p99.74, which is roughly what I get.</p>

<h3 id="bach-s-fanout-variations">Bach’s Fanout Variations</h3>

<p>While we now have a nice way to reason about and visualize the simplest version
of the problem, there are still many variations that would be useful to understand.</p>

<p>Here are some things we might want to do to our system to improve the overall latency:</p>

<ul>
<li>What happens if we drop the slowest child request?</li>
<li>What happens if we retry the slowest child request if it takes “too long”?</li>
<li>What happens if we send every child request to two children instead and just use the fastest response?</li>
</ul>

<p>I’m not the first person to think about this, lots of the ideas in this section
are stolen directly from the
<a href="https://ai.google/research/pubs/pub40801">Tail at Scale</a>, as well as things
I’ve observed in the wild.</p>

<p>This is a pretty rich topic, so hopefully in the future I can revisit it and
update the visualization to take account of these subtleties.</p>

<h3 id="acknowledgements">Acknowledgements</h3>

<p>Thanks to <a href="https://twitter.com/jcreed/status/1192779138282770432">Jason</a> for
helping me with the formula, and thanks to Paul Khuong and Ray Yang for reading
earlier drafts of this post.</p>

<!-- Replace this with a hugo partial -->




      </article>

      

      

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://paulcavallaro.com/blog/fanouts-and-percentiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964821</guid>
            <pubDate>Mon, 27 Jul 2020 13:24:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Entry Accounting for Developers]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 140 (<a href="https://news.ycombinator.com/item?id=23964513">thread link</a>) | @adamcharnock
<br/>
July 27, 2020 | https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html | <a href="https://web.archive.org/web/*/https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="double-entry-accounting-for-developers">

<p>Hordak is inherently aimed at software developers as it provides core
functionality only. Friendly interfaces can certainly be built on top of it, but
if you are here there is a good chance you are a developer.</p>
<p>If you are learning about accounting as developer you may feel – as I did – that
most of the material available doesn’t quite relate to the developer/STEM mindset. I
therefore provide some resources here that may be of use.</p>
<div>
<p>Note</p>
<p>According to this <a href="https://news.ycombinator.com/item?id=23964513">Hacker News discussion</a>, some of what follows may be either incorrect
or abhorrent to those with a good knowledge of accounting practices. I still
feel the following is useful, and that taken as a whole it describes a working
double entry accounting system.</p>
</div>

<div id="in-a-little-more-detail">
<h2>In a little more detail<a href="#in-a-little-more-detail" title="Permalink to this headline">¶</a></h2>
<p>I found <a href="http://www.mathstat.dal.ca/~selinger/accounting/tutorial.html">Peter Selinger’s tutorial</a> to be very enlightening and is less terse than the functional description above.
The first section is short and covers single entry accounting, and then shows how one can expand that to create double
entry accounting. I found this background useful.</p>
</div>
<div id="examples">
<h2>Examples<a href="#examples" title="Permalink to this headline">¶</a></h2>
<p>You live in a shared house. Everyone pays their share into a communal bank account
every month.</p>
<div id="example-1-saving-money-to-pay-a-bill-no-sign-flipping">
<h3>Example 1: Saving money to pay a bill (no sign flipping)<a href="#example-1-saving-money-to-pay-a-bill-no-sign-flipping" title="Permalink to this headline">¶</a></h3>
<p>You pay the electricity bill every three months. Therefore every month you take £100
from everyone’s contributions and put it into Electricity Payable account (a liability
account) in the knowledge that you will pay the bill from this account when it eventually arrives:</p>
<p>These accounts are income &amp; liability accounts, so neither balance needs to be flipped (flipping
only applies to asset &amp; expense accounts). Therefore:</p>
<ul>
<li>Balances before:<ul>
<li><em>Housemate Contribution</em> (income): £500</li>
<li><em>Electricity Payable</em> (liability): £0</li>
</ul>
</li>
<li><strong>Transaction</strong>:<ul>
<li>£100 from <em>Housemate Contribution</em> to <em>Electricity Payable</em></li>
</ul>
</li>
<li>Balances after:<ul>
<li><em>Housemate Contribution</em> (income): £400</li>
<li><em>Electricity Payable</em> (liability): £100</li>
</ul>
</li>
</ul>
<p>This should also make intuitive sense. Some of the housemate contributions will be used to pay the electricity
bill, therefore the former decreases and the latter increases.</p>
</div>
<div id="example-2-saving-money-to-pay-a-bill-with-sign-flipping">
<h3>Example 2: Saving money to pay a bill (with sign flipping)<a href="#example-2-saving-money-to-pay-a-bill-with-sign-flipping" title="Permalink to this headline">¶</a></h3>
<p>At the start of every month each housemate pays into the communal bank account. We
should therefore represent this somehow in our double entry system (something we ignored in
example 1).</p>
<p>We have an account called <em>Bank</em> which is an asset account (because this is money
we actually have). We also have a <em>Housemate Contribution</em> account which is an
income account.</p>
<p>Therefore, <strong>to represent the fact that we have been paid money, we must create a transaction</strong>.
However, money cannot be injected from outside our double entry system, so how do we deal with this?</p>
<p>Let’s show how we represent a single housemate’s payment:</p>
<ul>
<li>Balances before:<ul>
<li><em>Bank</em> (asset): £0</li>
<li><em>Housemate Contribution</em> (income): £0</li>
</ul>
</li>
<li><strong>Transaction:</strong><ul>
<li>£500 from <em>Bank</em> to <em>Housemate Contribution</em></li>
</ul>
</li>
<li>Balances after:<ul>
<li><em>Bank</em> (asset): -£500 * -1 = <strong>£500</strong></li>
<li><em>Housemate Contribution</em>  (income): £500</li>
</ul>
</li>
</ul>
<p>Because the bank account is an asset account, we flip the sign of its balance.
<strong>The result is that both accounts increase in value.</strong></p>
</div>
</div>
</div>


           </div>
           
          </div></div>]]>
            </description>
            <link>https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964513</guid>
            <pubDate>Mon, 27 Jul 2020 12:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Simplemvc.js – A highly opinionated web back end framework]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23964467">thread link</a>) | @jermaustin1
<br/>
July 27, 2020 | https://jeremyaboyd.com/post/simplemvc-js | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/simplemvc-js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://jeremyaboyd.com/post/simplemvc-js</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964467</guid>
            <pubDate>Mon, 27 Jul 2020 12:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Appreciating accessibility with a broken collar bone]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23964360">thread link</a>) | @yaszas
<br/>
July 27, 2020 | https://erresen.github.io/csharp/dotnet/accessibility/shortcuts/visualstudio/2020/07/26/appreciating-accessibility.html | <a href="https://web.archive.org/web/*/https://erresen.github.io/csharp/dotnet/accessibility/shortcuts/visualstudio/2020/07/26/appreciating-accessibility.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>You know what really sucks? Breaking bones. I’d been watching too many mountain biking videos on YouTube and after the first jump on a ride at my local bike trails, I came to realise that my enthusiasm and confidence far outweighed my skill. After over-jumping the jump, hitting a tree, flying over the bars and landing directly on my left shoulder 4 metres down the trail, I now have a broken clavicle (collar bone).</p>

<p>Living in the UK, we have public health care, so my brother drove me straight to Accident and Emergency. An x-ray soon confirmed that I’d snapped my collar bone in two, but apparently there’s not very much to be done. They gave me a sling, told me I’d need to take some pain killers for a few days, and booked me in at the fracture clinic for the following day. At the fracture clinic I go through the x-rays with a specialist doctor while he tells me about the next ten weeks of my life are going to be like. At this point I can barely move my arm. My shoulder’s the size of a water melon and turning yellow. Ten weeks like this. Shit.</p>

<p>I work as a software developer. Mainly ASP.NET and C# stuff. This means I live in Visual Studio… all day, everyday. Have you ever tried to work in VS one handed? Give it a try. It can be done but it’s not easy. One of the hardest things are keyboard shortcuts. Alt+Enter especially. I’ve got big hands, but even I struggle with that one using only my right hand. Luckily most functionality is available through context menus or through other parts of the UI.</p>

<p>A fantastic thing about VS is that nearly all keyboard shortcuts are remappable. I’d never thought of this as an accessibility feature before, but it really is. I’ve resisted changing anymore keyboard shortcuts than strictly necessary, as I’m intending to start using both arms again one day, but it’s fantastic that this is available in a tool that I rely on to work and pay the bills.</p>

<p>The majority of my work as a developer is web based, so when considering accessibility I tend to think about making things accessible for those with visual impairments; the blind and the partially sighted. Ensuring that the site works with screen readers and making sure controls and text have sufficient size and contrast is where a lot of accessibility effort is generally focused. There’s also things like not making tap targets not too close together, which is as much a mobile friendliness consideration as an accessibility consideration.</p>

<p>As most of my work is for the web, I don’t develop very many piece of software that utilise keyboard shortcuts extensively. If any of my future work does incorporate keyboard shortcuts, I’m certainly going to be considering how people with physical restrictions will be able to use them.</p>

<p>I don’t know what the “official” guidelines for keyboard shortcut accessibility are (or whether there are any guidelines!), but during the last few weeks of convalescence I’ve thought about the guidelines that I’d appreciate.</p>

<h2 id="accessibility-guidelines-for-keyboard-shortcuts">Accessibility guidelines for keyboard shortcuts</h2>

<ul>
  <li><strong>Single handed shortcuts:</strong> Prefer shortcut keys that can be reached with a single hand. Most shortcuts are comprised of a modifier key (Shift, Alt, Ctrl, Win, Cmd) along with another “normal” key. Try to keep the “normal” key within reasonable reach of the modifier. Shift and Ctrl <em>usually</em> have keys on both sides of the keyboard, so more keys can be paired with these. Note that although Alt appears on both sides of the space bar, the right hand key is AltGr. They are actually two different keys, so keep that in mind when mapping shortcuts.</li>
  <li><strong>Remappable:</strong> It’s not always reasonable to make all the default keyboard shortcuts single-handed. It’s also likely that for able bodied users, some single handed shortcuts may actually be less comfortable or convenient than shortcuts that require both hands. That’s fine, and it’s a good idea to cater to your primary demographic. It’s also a good idea to allow users to remap these shortcuts. It’s not simply an accessibility feature, it’s great for the types that love to customise everything.</li>
  <li><strong>Provide alternatives:</strong> Providing an interface to allow users to remap their keyboard shortcuts isn’t always feasible. Maybe there’s no budget, or the scope of the project simply doesn’t allow for it. In these cases it’s simple and quick to provide alternatives to more complex or finger-stretching shortcuts. It doesn’t have to be every shortcut, but for commonly used shortcuts that are more comfortable with two hands, consider adding single-handed alternatives.</li>
</ul>

<p>That’s it. Nothing fancy or too technical. If in doubt about whether a keyboard shortcut complies with these guidelines, just try it with one hand! Imagine having to do that every time you require that shortcut… you’ll soon figure out whether it’s accessible or not.</p>

  </article></div>]]>
            </description>
            <link>https://erresen.github.io/csharp/dotnet/accessibility/shortcuts/visualstudio/2020/07/26/appreciating-accessibility.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964360</guid>
            <pubDate>Mon, 27 Jul 2020 12:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Procedural cityscapes creation: Openstreetmap import in Unity and Houdini Engine]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23964079">thread link</a>) | @liotier
<br/>
July 27, 2020 | http://stinaflodstrom.com/projects/osm/osm.html | <a href="https://web.archive.org/web/*/http://stinaflodstrom.com/projects/osm/osm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

                  <div><p>

                  I set up a procedural content creation pipeline that imports <a href="http://stinaflodstrom.com/projects/osm/www.openstreetmap.org">OpenStreetMap</a> data into Unity and uses the Houdini Engine to create realistic cityscapes based on real world locations. The goal was to have an as automated process as possible for generating environments based on real cities. The buildings and the roads are generated from OSM building shapes and road splines using a procedural system for building type and prop placing. Traffic lights, Crossings and Trees also get their positions from OSM. Values and procedural parameters can be tweaked in Unity making it possible to create endless variations.

                  </p><p>The project was developed with the simulation team in one of the bigger automotive companies as a proof of concept for creating syntetic data for AI and render out annotated images. The environmant is complete with tags for segmentation. 

                </p></div>

            </div></div>]]>
            </description>
            <link>http://stinaflodstrom.com/projects/osm/osm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964079</guid>
            <pubDate>Mon, 27 Jul 2020 11:31:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grace of Manta Rays]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23963693">thread link</a>) | @dnetesn
<br/>
July 27, 2020 | http://oceans.nautil.us/feature/590/the-grace-of-manta-rays | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/590/the-grace-of-manta-rays">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>I</span> didnâ€™t really understand the word â€˜graceâ€™ until I swam with manta rays. These placid members of the shark family are the embodiment of grace; winged fish <a href="https://www.mantatrust.org/mobula-alfredi" target="_blank">14 feet</a> across who swoop and somersault with such precision that a manta scooping up plankton at speeds of up to <a href="https://www.deepseanews.com/2013/08/the-superhero-like-swimming-of-manta-rays/" target="_blank">22 miles per hour</a> can graze the hair of a SCUBA diver without touching her head. And as I experienced while diving in Hawaii, if you sit quietly on the ocean floor, theyâ€™ll do it not just once but again and again before disappearing into the blue abyss, as ephemeral as a cloud.&nbsp;<br></p>

<p>For both their grace and their sheer otherworldly coolness, people love manta rays. The animals generate $50 million a year from tourists like me who want to swim or dive with them. But given how popular they are, much about mantas remains a mystery. They're truly wild creatures, too big for most aquariums and too far-ranging to easily study. Their life history and migration patterns are little known.&nbsp;No one has ever seen a manta give birth in the wild; we have no idea where they do so.&nbsp;And&nbsp;until&nbsp;recently, scientists thought there was only one kind of&nbsp;manta. It wasnâ€™t until 2009 that&nbsp;the more transient oceanic mantas (<em>Mobula birostris</em>) were recognized as a distinct species from the slightly smaller reef mantas (<em>Mobula alfredi</em>).<sup>1</sup></p>
<p>â€œThere are these big, intelligent creatures roaming around and we just donâ€™t know much about them,â€� says&nbsp;Sammy&nbsp;Andrzejaczek, a shark scientist with the&nbsp;Hopkins Marine Station at Stanford University.&nbsp;</p>
<p>Studies have shown that <a href="https://www.researchgate.net/publication/237067445_Trends_in_sightings_and_environmental_influences_on_a_coastal_aggregation_of_manta_rays_and_whale_sharks" target="_blank">overfishing</a> has <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3770565/" target="_blank">reduced</a> some manta populations by <a href="https://saveourseas.com/project-leader/lauren-peel/" target="_blank">80 percent</a>, and the IUCN Red List classifies both species as <a href="https://www.iucnredlist.org/species/195459/68632178" target="_blank">Vulnerable</a> and declining. Scientists are now trying to gather the basic information that could help the animals survive. In the process,&nbsp;they're learning that&nbsp;manta rays&nbsp;are more complex and fascinating than anyone imagined—bestowing their grace not just on humans lucky enough to swim with them, but on entire ecosystems.</p>
<blockquote>The mere fact that we share a planet with manta rays is its own grace.</blockquote>
<p>One way mantas shape marine environments is by traveling regularly between the deep ocean and coral reefs. Lauren Peel, a biologist with the Manta Trust and Save Our Seas Foundation, explains that in doing so, mantas move nutrients through the ocean. They eat a certain type of zooplankton that only lives offshore, for example, then return to coral reefs and defecate, depositing a suite of nutrients not otherwise available in the shallow seas.&nbsp;â€œTheyâ€™re essentially fertilizing coral reefs,â€� says Peel, who published a <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.190599" target="_blank">2019 study</a> on the discovery.&nbsp;&nbsp;</p>
<p>Peel and her colleagues believe this fertilization may <a href="https://saveourseas.com/reef-manta-rays-may-promote-the-growth-of-coral-reefs-in-seychelles/" target="_blank">boost reef growth</a>, which not only leads to a greater biodiversity of corals and sponges but also supports the invertebrates, fish, mammals and reptiles that call reefs home. By analyzing tissue samples from 50 reef mantas and 20 different types of fish in the Seychelles, Peel also found that mantas are the only animals performing this essential fertilization. â€œOn top of being able to move such large distances and access different zooplankton sources, theyâ€™re consistently feeding, so theyâ€™re able to supply a larger amount of nutrients over a larger period of time over a larger spatial scale," Peel says.&nbsp;&nbsp;<br></p>
<p>Still, the realization that protecting mantas benefits entire coral communities isnâ€™t enough to save the species. Unlike some other imperiled fish, mantas are not targeted by an organized fishery that will grudgingly adhere to conservation measures like bag limits. Instead, mantas are killed by small local fisheries, poachers who sell their gills for traditional Chinese medicine, and commercial fishermen who accidentally take mantas as bycatch. That means the best way to protect them might be through refuges where no fishing is allowed at all.&nbsp;</p><p>Of course, keeping poachers out of vast, open marine protected areas (MPAs) is its own challenge. Thatâ€™s one reason why Andrzejaczek analyzed the movement of reef mantas in the British Indian Ocean Territory MPA. By showing where mantas hang out, <a href="https://www.int-res.com/abstracts/meps/v639/p137-153/" target="_blank">her data</a> are helping patrol boats better target their policing.</p>
<p>To create adequate marine refuges, scientists must also to figure out how far mantas roam. A <a href="https://mbr.biomedcentral.com/articles/10.1186/s41200-019-0173-6" target="_blank">2019 study</a> showed that one reef manta swam a whopping 714 miles—hundreds of miles farther than the previous known record. Andrzejaczek, on the other hand, found that all 33 tagged mantas in her study stayed within the <a href="http://www.mpatlas.org/mpa/sites/7707499/%252523:~:text=On%252525201st%25252520April%252525202010,%25252520the,unrivalled%25252520in%25252520scale%25252520and%25252520significance." target="_blank">200-mile span</a> of the British Indian Ocean Territory MPA. Perhaps, she theorizes, some reef mantas migrate long distances while others stay local to a particular reef.</p>
<p>Manta raysâ€™ charisma could play a role in saving them, too. After a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0065051" target="_blank">2013 study</a> showed that a live manta can bring $1 million in tourism revenue in over its lifetime, compared to $500 dead, <a href="https://www.thejakartapost.com/news/2014/02/21/indonesia-hopes-cash-manta-ray-tourism.html" target="_blank">Indonesia joined</a> Australia, Ecuador, the European Union, Mexico, New Zealand, the Philippines, Yap, Guam, the Northern Mariana Islands, Hawaii and Florida in banning manta ray fishing. The Manta Trust is also creating guidelines for sustainable manta ray tourism,&nbsp;like instructing divers to stay calm and let mantas guide the encounter.&nbsp;</p><p>â€œItâ€™s understandable that people get excited,â€� says Annie Murray, a marine biologist with the Manta Trust. â€œBut unfortunately that can lead to people swimming really fast, chasing the manta to try to get the best selfie, and thatâ€™s going to disturb them, especially when theyâ€™re feeding.â€�&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_aa7e40c628a36f3002fd99c31b2755ad.jpg" alt="Manta from below"><figcaption><span><strong>Manta from below </strong>No two mantas have the same pattern of underbelly spots, making these invaluable for identifying individuals. </span><br><span>Guy Stevens | Manta Trust</span></figcaption></figure>
<p>Murray herself has swam with dozens of mantas, each with distinct personalities. Without prompting, she, Peel and Andrzejaczek each described the animalsâ€™ curiosity and intellect with an awe thatâ€™s rare among scientists.&nbsp;â€œWhen you swim with mantas, itâ€™s an interaction between the two of you,â€� says Murray. â€œThatâ€™s what got me in the beginning. But from a more scientific point of view, Iâ€™m fascinated not only by how they interact with humans, but with each other.â€�<br></p>
<p>Manta rays have the largest brain-to-body ratios of any fish; <a href="https://link.springer.com/article/10.1007/s10164-016-0462-z" target="_blank">evidence suggests</a> they might also recognize themselves in mirrors, widely considered a hallmark of human-like self-awareness. She and others are studying how manta raysâ€™ clear intelligence manifests through social behaviors, and whether animals long considered solitary oceanic wanderers actually operate within social networks or hierarchies. While the social research is too new to draw conclusions from, itâ€™s within the realm of possibility that mantas form lifelong social bonds.</p>
<p>Indeed, the more we learn about mantas, the more it calls to mind another definition of grace—â€œthe&nbsp;free and unmerited favor of God, as manifested in the salvation of sinners and the bestowal of blessings.â€� The mere fact that we share a planet with manta rays is its own grace, a salve that can make even the most cynical scientist weep into her dive mask over the wonder that remains in this wild world.&nbsp;</p>

<p>1&nbsp;The mantas I swam with in&nbsp;Hawaii were reef mantas, which have a wingspan of up to 14 feet. Oceanic, or giant, mantas can be nearly 23 feet across.&nbsp;</p>
<ul><li> is a freelance journalist who writes about humans and the natural world for publications including The Atlantic, bioGraphic, Hakai, National Geographic and Outside. Follow her on Twitter <a href="https://twitter.com/cestmoilanglois">@cestmoiLanglois</a> and see more of her work at <a href="https://www.kristaleelanglois.com/">www.kristaleelanglois.com</a>.</li></ul>
<p>Lead image: A reef manta ray glides past a school of fusiliers. Credit: Guy Stevens&nbsp;| Manta Trust<em><em></em></em></p>

    </article></div>]]>
            </description>
            <link>http://oceans.nautil.us/feature/590/the-grace-of-manta-rays</link>
            <guid isPermaLink="false">hacker-news-small-sites-23963693</guid>
            <pubDate>Mon, 27 Jul 2020 10:11:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GnuTLS audit: passive cleartext recovery attack]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23962840">thread link</a>) | @masklinn
<br/>
July 27, 2020 | https://anarc.at/blog/2020-06-10-gnutls-audit/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-06-10-gnutls-audit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>So <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> came out while I wasn't looking last week. The
GnuTLS advisory (<a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">GNUTLS-SA-2020-06-03</a>) is pretty opaque so I'll
refer instead to <a href="https://twitter.com/FiloSottile/status/1270061316368224256">this tweet</a> from <a href="https://twitter.com/FiloSottile">@FiloSottile</a> (Go team
security lead):</p>

<blockquote><p>PSA: don't rely on GnuTLS, please.</p>

<p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> Whoops, for the past 10 releases most TLS 1.0–1.2
connection could be passively decrypted and most TLS 1.3 connections
intercepted. Trivially.</p>

<p>Also, <a href="https://blog.filippo.io/we-need-to-talk-about-session-tickets/">TLS 1.2–1.0 session tickets are awful</a>.</p></blockquote>

<p>You are reading this correctly: supposedly encrypted TLS connections
made with affected GnuTLS releases are vulnerable to <em>passive</em>
cleartext recovery attack (and active for 1.3, but who uses that
anyways). That is extremely bad. It's pretty close to just switching
everyone to HTTP instead of HTTPS, more or less. I would have a lot
more to say about the security of GnuTLS in particular -- and security
in general -- but I am mostly concerned about patching holes in the
roof right now, so this article is not about that.</p>

<p>This article is about figuring out what, exactly, was exposed in our
infrastructure because of this.</p>






<p>Assuming you're running Debian, this will show a list of packages that
<code>Depends</code> on GnuTLS:</p>

<pre><code>apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u
</code></pre>

<p>This assumes you run this only on hosts running Buster or
above. Otherwise you'll need to figure out a way to pick machines
running GnuTLS 3.6.4 or later.</p>

<p>Note that this list only <em>first level</em> dependencies! It is perfectly
possible that another package uses GnuTLS without being listed
here. For example, in the above list I have <code>libcurl3-gnutls</code>, so the
be really thorough, I would actually need to recurse down the
dependency tree.</p>

<p>On my desktop, this shows an "interesting" list of targets:</p>

<ul>
<li><code>apt</code></li>
<li><code>cadaver</code> - AKA WebDAV</li>
<li><code>curl</code> &amp; <code>wget</code></li>
<li><code>fwupd</code> - another attack on top of <a href="https://github.com/justinsteven/advisories/blob/master/2020_fwupd_dangling_s3_bucket_and_CVE-2020-10759_signature_verification_bypass.md">this one</a></li>
<li><code>git</code> (through the <code>libcurl3-gnutls</code> dependency)</li>
<li><code>mutt</code> - all your emails</li>
<li><code>weechat</code> - your precious private chats</li>
</ul>


<p>Arguably, fetchers like <code>apt</code>, <code>curl</code>, <code>fwupd</code>, and <code>wget</code> rely on HTTPS for
"authentication" more than secrecy, although <code>apt</code> has its own
OpenPGP-based authentication so that wouldn't matter anyways. Still,
this is truly distressing. And I haven't mentioned here things like
<code>gobby</code>, <code>network-manager</code>, <code>systemd</code>, and others - the scope of this is
broad. Hell, even good old <code>lynx</code> links against GnuTLS.</p>

<p>In our infrastructure, the magic command looks something like this:</p>

<pre><code>cumin -o txt -p 0  'F:lsbdistcodename=buster' "apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u" | tee gnutls-rdepds-per-host | awk '{print $NF}' | sort | uniq -c | sort -n
</code></pre>

<p>There, the result is even more worrisome, as those important packages seem to rely on GnuTLS for their transport security:</p>

<ul>
<li><code>mariadb</code> - all MySQL traffic and passwords</li>
<li><code>mandos</code> - full disk encryption</li>
<li><code>slapd</code> - LDAP passwords</li>
</ul>


<p><code>mandos</code> is especially distressing although it's probably not
vulnerable because it seems it doesn't store the cleartext -- it's
encrypted with the client's OpenPGP public key -- so the TLS tunnel
never sees the cleartext either.</p>

<p><a href="https://twitter.com/jedisct1/status/1270078914996682753">Other reports</a> have also mentioned the following servers link
against GnuTLS and could be vulnerable:</p>

<ul>
<li><code>exim</code></li>
<li><code>rsyslog</code></li>
<li><code>samba</code></li>
<li>various <code>VNC</code> implementations</li>
</ul>




<p>Those programs are not affected by this vulnerability:</p>

<ul>
<li><code>apache2</code></li>
<li><code>gnupg</code></li>
<li><code>python</code></li>
<li><code>nginx</code></li>
<li><code>openssh</code></li>
</ul>


<p>This list is not exhaustive, naturally, but serves as an example of
common software you don't need to worry about.</p>

<p>The vulnerability only exists in GnuTLS, as far as we know, so
programs linking against other libraries are not vulnerable.</p>

<p>Because the vulnerability affects session tickets -- and those are set
on the server side of the TLS connection -- only users of GnuTLS as a
server are vulnerable. This means, for example, that while <code>weechat</code>
uses GnuTLS, it will only suffer from the problem when acting as a
server (which it does, in relay mode) or, of course, if the remote IRC
server also uses GnuTLS. Same with apt, curl, wget, or git: it is
unlikely to be a problem because it is only used as a client; the
remote server is usually a webserver -- not git itself -- when using
TLS.</p>



<p>Keep in mind that it's not because a package links against GnuTLS that
it <em>uses</em> it. For example, I have been told that, on Arch Linux, if
both GnuTLS and OpenSSL are available, the <code>mutt</code> package will use the
latter, so it's not affected. I haven't confirmed that myself nor have I
checked on Debian.</p>

<p>Also, because it relies on session tickets, there's a time window
after which the ticket gets cycled and properly initialized. But that
is <a href="https://twitter.com/__agwa/status/1270054740559384576">apparently 6 hours by default</a> so it is going to protect only
really long-lasting TLS sessions, which are uncommon, I would argue.</p>

<p>My audit is limited. For example, it might have been better to walk
the shared library dependencies directly, instead of relying on Debian
package dependencies.</p>



<p>It seems the vulnerability might have been introduced in <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/695">this merge
request</a>, itself following a (entirely reasonable) <a href="https://gitlab.com/gnutls/gnutls/-/issues/184">feature request
to make it easier to rotate session tickets</a>. The merge request was
open for a few months and was thoroughly reviewed by a peer before
being merged. Interestingly, the vulnerable function
(<code>_gnutls_initialize_session_ticket_key_rotation</code>), explicitly says:</p>

<pre><code> * This function will not enable session ticket keys on the server side. That is done
 * with the gnutls_session_ticket_enable_server() function. This function just initializes
 * the internal state to support periodical rotation of the session ticket encryption key.
</code></pre>

<p>In other words, it thinks it is not responsible for session ticket
initialization, yet it is. Indeed, the <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275/">merge request fixing the
problem</a> unconditionally does this:</p>

<pre><code>memcpy(session-&gt;key.initial_stek, key-&gt;data, key-&gt;size);
</code></pre>

<p>I haven't reviewed the code and the vulnerability in detail, so take
the above with a grain of salt.</p>

<p>The <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275.patch">full patch is available here</a>. See also the <a href="https://gitlab.com/gnutls/gnutls/-/issues/1011">upstream issue
1011</a>, the <a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">upstream advisory</a>, the <a href="https://security-tracker.debian.org/tracker/CVE-2020-13777">Debian security
tracker</a>,
and the <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1843723">Redhat Bugzilla</a>.</p>



<p>The impact of this vulnerability depends on the affected packages and
how they are used. It can range from "meh, someone knows I downloaded
that Debian package yesterday" to "holy crap my full disk encryption
passwords are compromised, I need to re-encrypt all my drives",
including "I need to change all LDAP and MySQL passwords".</p>

<p>It promises to be a fun week for some people at least.</p>

<p>Looking ahead, however, one has to wonder whether we should follow
<a href="https://twitter.com/FiloSottile">@FiloSottile</a>'s advice and stop using GnuTLS altogether. There are
at least a few programs that link against GnuTLS because of the
<a href="https://en.wikipedia.org/wiki/OpenSSL#Licensing">OpenSSL licensing oddities</a> but that has been first announced in
2015, then <a href="https://www.openssl.org/blog/blog/2017/03/22/license/">definitely and clearly resolved in 2017</a> -- or <a href="https://opensource.com/article/19/2/top-foss-legal-developments">maybe
that was in 2018</a>? Anyways it's fixed, pinky-promise-I-swear,
except if you're one of those weirdos still using GPL-2, of
course. Even though OpenSSL isn't the simplest and secure TLS
implementation out there, it could preferable to GnuTLS and maybe we
should consider changing Debian packages to use it in the future.</p>

<p>But then again, the last time something like this happened, it was
<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a> and GnuTLS wasn't affected, so who knows... It is
likely that people don't have OpenSSL in mind when they suggest moving
away from GnuTLS and instead think of other TLS libraries like
<a href="https://tls.mbed.org/">mbedtls</a> (previously known as PolarSSL), <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a>, <a href="https://boringssl.googlesource.com/boringssl/">BoringSSL</a>,
<a href="https://www.libressl.org/">LibreSSL</a> and so on. Not that those are totally sinless either...</p>

<p>"This is fine", as they say...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            <div>
            <p><span>Created <time datetime="2020-06-11T15:47:35Z" pubdate="pubdate" title="Thu, 11 Jun 2020 11:47:35 -0400">tard dans la matinée de Thursday, June 11th, 2020</time>.</span>
            <span>
            
            <a href="http://source.anarcat.wiki.orangeseeds.org/?p=source.git;a=history;f=blog/2020-06-10-gnutls-audit.mdwn">Edited <time datetime="2020-06-11T16:18:48Z" title="Thu, 11 Jun 2020 12:18:48 -0400">Thursday, à l'heure du déjeuner, June 11th, 2020</time>.</a>
            
            </span>
            </p></div>

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-06-10-gnutls-audit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962840</guid>
            <pubDate>Mon, 27 Jul 2020 07:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ted Williams's Strike Zone]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 59 (<a href="https://news.ycombinator.com/item?id=23962339">thread link</a>) | @dedalus
<br/>
July 26, 2020 | http://tedwilliams.com/_data/hzone.htm | <a href="https://web.archive.org/web/*/http://tedwilliams.com/_data/hzone.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div height="31" rowspan="3"> 
	  <p><span color="#51504E">&nbsp;&nbsp;&nbsp;My 
		first rule of hitting was to get a good ball to hit. I learned down to 
		percentage points where those good balls were. The box shows my particular 
		preferences, from what I considered my “happy zone” - where I could hit 
		.400 or better - to the low outside corner - where the most I could hope 
		to bat was .230. Only when the situation demands it should a hitter go 
		for the low-percentage pitch.<p>
		
		&nbsp;&nbsp;&nbsp;Since some players are better high-ball hitters than 
		low-ball hitters, or better outside than in; each batter should work out 
		his own set of percentages. But more important, each should learn the 
		strike zone, because once pitchers find a batter is going to swing at 
		bad pitches he will get nothing else. The strike zone is approximately 
		seven balls wide (allowing for pitches on the corners). When a batter 
		starts swinging at pitches just two inches out of that zone (shaded area), 
		he has increased the pitcher’s target from approximately 4.2 square feet 
		to about 5.8 square feet - an increase of 37 percent. Allow a pitcher 
		that much of an advantage and you will be a .250 hitter.</p></span></p>
	</div></div>]]>
            </description>
            <link>http://tedwilliams.com/_data/hzone.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962339</guid>
            <pubDate>Mon, 27 Jul 2020 04:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird Shell – Structural Regular Expressions Unix Shell Made in Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23962017">thread link</a>) | @akkartik
<br/>
July 26, 2020 | https://git.sr.ht/~tudor/rwsh | <a href="https://web.archive.org/web/*/https://git.sr.ht/~tudor/rwsh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readme">
    <div>
      <div><h2 id="rwsh">rwsh</h2>
<p><a href="https://builds.sr.ht/~tudor/rwsh?" rel="nofollow noopener"><img alt="builds.sr.ht status" src="https://builds.sr.ht/~tudor/rwsh.svg"></a></p>
<p><em>(Better name ideas pending)</em></p>
<p>This is going to be a UNIX shell based around <a href="http://doc.cat-v.org/bell_labs/structural_regexps/" rel="nofollow noopener">Structural Regular Expressions</a> and the <a href="https://github.com/tudurom/usam" rel="nofollow noopener">usam experiment</a>.</p>
<h3 id="to-do">To do:</h3>
<p>See <code>todo/todo.txt</code>.</p>
<ul>
<li>[x] Basic command execution with quoted string rules</li>
<li>[x] Pipes</li>
<li>[x] Structural regular expressions
<ul>
<li>[x] Addresses</li>
<li>[x] Basic commands (<code>a</code>, <code>c</code>, <code>i</code>, <code>d</code>, <code>p</code>)</li>
<li>[x] Loops</li>
<li>[ ] Variable and command substitution (with capture group values)
<ul>
<li>[ ] In addresses</li>
<li>[x] In command parameters</li>
</ul>
</li>
<li>[ ] Shell commands in SRE</li>
</ul>
</li>
<li>[ ] Shell stuff:
<ul>
<li>[x] Load scripts</li>
<li>[x] <code>||</code>, <code>&amp;&amp;</code>, <code>!</code></li>
<li>[ ] Redirection</li>
<li>[ ] Job control (God have mercy)
<ul>
<li>[ ] Handle signals</li>
</ul>
</li>
</ul>
</li>
<li>[ ] Variables and variable substitution
<ul>
<li>[x] Strings</li>
<li>[x] Assignment</li>
<li>[ ] Arrays / Lists</li>
<li>[ ] Maps</li>
</ul>
</li>
<li>[x] Command substitution</li>
<li>[ ] Control flow structures
<ul>
<li>[x] If-else</li>
<li>[x] While</li>
<li>[ ] For
<ul>
<li>[x] String globbing</li>
</ul>
</li>
<li>[x] Switch</li>
<li>[x] Matches (awk-like pattern list)</li>
</ul>
</li>
<li>[ ] Functions</li>
<li>[ ] Builtins
<ul>
<li>[x] <code>cd</code></li>
<li>[x] <code>exit</code></li>
<li>[x] <code>true</code> / <code>false</code></li>
<li>[x] <code>eval</code></li>
<li>[x] <code>calc</code></li>
<li>...</li>
</ul>
</li>
</ul>
</div>
    </div>
  </div></div>]]>
            </description>
            <link>https://git.sr.ht/~tudor/rwsh</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962017</guid>
            <pubDate>Mon, 27 Jul 2020 03:30:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACCC alleges Google misled consumers about expanded use of personal data]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 78 (<a href="https://news.ycombinator.com/item?id=23961881">thread link</a>) | @Khaine
<br/>
July 26, 2020 | https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div property="content:encoded"><p><em>Correction: An earlier version of this media release used a hypothetical example that suggested that Google used information about users’ health to personalise or target advertisements. Google says that it does not show personalised ads based on health information. This example has been removed from the media release.</em></p>

<p>The ACCC has launched Federal Court proceedings against Google LLC (Google), alleging Google misled Australian consumers to obtain their consent to expand the scope of personal information that Google could collect and combine about consumers’ internet activity, for use by Google, including for targeted advertising.</p>

<p>The ACCC alleges Google misled consumers when it failed to properly inform consumers, and did not gain their explicit informed consent, about its move in 2016 to start combining personal information in consumers’ Google accounts with information about those individuals’ activities on non-Google sites that used Google technology, formerly DoubleClick technology, to display ads.</p>

<p>This meant this data about users’ non-Google online activity became linked to their names and other identifying information held by Google. Previously, this information had been kept separately from users’ Google accounts, meaning the data was not linked to an individual user.</p>

<p>Google then used this newly combined information to improve the commercial performance of its advertising businesses.</p>

<p>The ACCC also alleges that Google misled consumers about a related change to its privacy policy.</p>

<p>“We are taking this action because we consider Google misled Australian consumers about what it planned to do with large amounts of their personal information, including internet activity on websites not connected to Google,” ACCC Chair Rod Sims said.</p>

<p>“Google significantly increased the scope of information it collected about consumers on a personally identifiable basis. This included potentially very sensitive and private information about their activities on third party websites. It then used this information to serve up highly targeted advertisements without consumers’ express informed consent,” Mr Sims said.</p>

<p>“We allege that Google did not obtain explicit consent from consumers to take this step.”</p>

<p>“The use of this new combined information allowed Google to increase significantly the value of its advertising products, from which it generated much higher profits.”</p>

<p>“The ACCC considers that consumers effectively pay for Google’s services with their data, so this change introduced by Google increased the “price” of Google’s services, without consumers’ knowledge,” Mr Sims said.</p>

<p><strong>“I agree” notification</strong></p>

<p>The conduct is alleged to have impacted millions of Australians with Google accounts.</p>

<p>From 28 June 2016 until at least December 2018, Google account holders were prompted to click “I agree” to a pop-up notification from Google that purported to explain how it planned to combine their data, and sought the consumers’ consent for this.</p>

<blockquote>
	<p><em>Some new features for your Google Account</em></p>

	<p><em>We’ve introduced some optional features for your account, giving you more control over the data Google collects and how it’s used, while allowing Google to show you more relevant ads.</em></p>
</blockquote>

<p>The notification also stated,&nbsp;<em>“More information will be available in your Google Account making it easier for you to review and control”</em>; and&nbsp;<em>“Google will use this information to make ads across the web more relevant for you.”</em></p>

<p>Before June 2016, Google only collected and used, for advertising purposes, personally identifiable information about Google account users’ activities on Google owned services and apps like Google Search and YouTube.</p>

<p>After June 2016, when consumers clicked on the “I agree” notification, Google began to collect and store a much wider range of personally identifiable information about the online activities of Google account holders, including their use of third-party sites and apps not owned by Google.</p>

<p>Previously, this additional data had been stored separately from a user’s Google account.</p>

<p>Combined with the personal data stored in Google accounts, this provided Google with valuable information with which to sell even more targeted advertising, including through its Google Ad Manager and Google Marketing Platform brands.</p>

<p>The ACCC alleges that the “I agree” notification was misleading, because consumers could not have properly understood the changes Google was making nor how their data would be used, and so did not - and could not - give informed consent.</p>

<p>“We believe that many consumers, if given an informed choice, may have refused Google permission to combine and use such a wide array of their personal information for Google’s own financial benefit,” Mr Sims said.</p>

<p><strong>Privacy policy change</strong></p>

<p>Before 28 June 2016, Google stated in its privacy policy that it&nbsp;<em>“will not combine DoubleClick cookie information with personally identifiable information unless we have your opt-in consent.”</em></p>

<p>On 28 June 2016, Google deleted this statement and inserted the following statement:<em>&nbsp;“[d]epending on your account settings, your activity on other sites and apps may be associated with your personal information in order to improve Google’s services and the ads delivered by Google.”</em></p>

<p>Google’s privacy policy also states:&nbsp;<em>“[w]e will not reduce your rights under this Privacy Policy without your explicit consent.”</em></p>

<p>The ACCC alleges that Google did not in fact obtain consumers’ explicit consent for this change to the privacy policy, and that Google’s statement that it would not reduce consumers’ rights without their explicit consent was therefore misleading.</p>

<p>“Google made a clear representation about how it would protect users’ privacy. The ACCC alleges that Google made changes without obtaining the explicit consent it had promised consumers it would obtain before altering how it protected their private information,” Mr Sims said.</p>

<p><strong>DoubleClick</strong></p>

<p>In 2008, Google acquired DoubleClick, a supplier of ad-serving technology services to publishers and advertisers.</p>

<p>Google now supplies DoubleClick’s services through its Google Ad Manager and Google Marketing Platform brands, which are the leading suppliers of ad-tech intermediary services.</p>

<p>These services track users’ internet activity on third-party sites that display ads through the use of DoubleClick’s advertising technology.</p>

<p>Google’s acquisition of DoubleClick required approval by competition authorities including the US Federal Trade Commission and the European Commission. The ACCC also reviewed and cleared this transaction.</p>

<p>FTC and EC cleared the acquisition, and in doing so considered submissions from Google that it would not be able to combine DoubleClick’s data on consumers’ internet activity with its own data about consumers’ activity on Google services because, at the time, DoubleClick’s contracts with its users prevented Google from doing so.</p>

<p>The agencies did not, however, rely on these submissions in clearing the acquisition.</p>

<p>Before 28 June 2016, Google collected and stored this information on a non-personally identifiable basis, as stated in its privacy policy.</p>

<p>On 28 June 2016, it changed its privacy policy by removing the term explaining how it would treat this DoubleClick data.</p>

<p><strong>Images</strong></p>

<p>Depending on the device and Google service being used by the consumer, the notification published by Google from 28 June 2016 was presented in a variety of ways. A copy of the notification in the form published to consumers using desktop devices is provided below for reference.</p>





<p><em>Source: Provided to the ACCC by Google Australia Pty Ltd</em></p>

<p>The relevant changes to Google’s Privacy Policy made on 28 June 2016 are also shown below for reference:</p>



<p>Source: Accessed from https://policies.google.com/privacy/archive?hl=en-US on 24 June 2020</p>

<p><strong>Background</strong></p>

<p>Google LLC (Google) is a multinational company incorporated in the United States with its headquarters in Mountain View, California. It is a subsidiary of Alphabet Inc.</p>

<p>Google supplies a range of services to consumers in Australia including Google Search, Google Maps, Gmail, YouTube, Google Play and Google Chrome.</p>

<p>Google also provides advertising services and analytics services to individuals and businesses. Advertising services are provided on Google services, such as Google Search, Google Maps and YouTube, as well as on websites and mobile device based applications not published or controlled by Google that partner with Google to display advertisements.</p>

<p>Google derives the majority of its revenue from its advertising and analytics services.</p>

<p><strong>Note:</strong> The concise statement has not been attached as it has been filed on a confidential basis pending claims by Google.</p>
</div></div></div></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961881</guid>
            <pubDate>Mon, 27 Jul 2020 02:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eric Weinstein: The Mathematician Turned Physicist and Economist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23961509">thread link</a>) | @jdcampolargo
<br/>
July 26, 2020 | https://www.juandavidcampolargo.com/blog/ericweinstein | <a href="https://web.archive.org/web/*/https://www.juandavidcampolargo.com/blog/ericweinstein">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e31d7a75b991deb6415c"><div><h2>Who?</h2><p>I identified with Eric Weinstein so much because of the shared struggles with the educational system.&nbsp;</p><p>Eric became a <strong>beacon of hope</strong> for me when he started sharing his story and lessons he learned throughout his impressive career as an academic, mathematician, physicist, economist, managing director of Thiel Capital, and podcaster.&nbsp;</p><p>Although he’s been told he is dyslexic, dysgraphic, color blind, ADD, and kinesthetic reinforcement deficits, he is proof of the educational system debacles. He says, “All BS. I wasn’t meant for educators, as those are actually their issues with me (i.e. teaching disabilities).”</p><p>He’s an inspiration as I’ve faced similar obstacles especially with the focus of compliance in the educational system over creativity, curiosity, even intellect has <a href="https://www.juandavidcampolargo.com/blog/highschool" target="_blank">hurt me in my educational career</a>.&nbsp;</p><h2>Why Should You Care?</h2><p>I started writing these <a href="http://juandavidcampolargo.com/newsletter" target="_blank">essays</a> and making <a href="https://www.youtube.com/channel/UCU87CN_FxGC1q3hzWM0CCDA" target="_blank">videos</a> because <strong>ideas are the currency of the 21st century. </strong>I humbly believe the ideas I share could help others as I pursue my <a href="http://juandavidcampolargo.substack.com/" target="_blank">Curiosities</a><em>.</em></p><p>Eric Weinstein’s ideas have awakened me and showed a world unknown to most people, such as the real world of academia and science.&nbsp;</p><p>One of these ideas is what he calls the <strong>DISC</strong> (Distributed Idea Suppression Complex) which explains how disruptive and innovative ideas that challenge the status quo are suppressed. Keeping institutions safe from individuals who create change.&nbsp;</p><p>The DISC is spread throughout major institutions such as in academia, the mainstream media, and politics. It tries to undermine ideas that may challenge or weaken the elite. This isn’t directly planned, and it’s not under central control.&nbsp;</p><p>Eric and his family have been victims of the DISC multiple times. Eric in physics, his wife in economics, and his brother in biology. He started noticing the same pattern in politics when MSNBC hid polling graphics of presidential candidate Andrew Yang.&nbsp;</p><p>The DISC is only one of these marvelous ideas that Eric explores in his podcast called The Portal where he explores subjects including science, economics, culture, politics, and business.&nbsp;</p><p>The goal of the show is to help you see the world through a different lens, which opens up your mind to new ways of viewing events and your life. Each guest is a portal to a reality showcasing what we would normally consider impossible, are indeed possible.&nbsp;</p><p>Let’s visit The Portal!</p><h2>Favorite Episodes</h2><p>Eric launched The Portal in June 2019 and less than a year later has created a community of people who want to explore this hidden reality and discover new portals.&nbsp;</p><p>Eric has wide expertise in many fields, but what’s interesting is how he engages your mind, moves your heart, and lights a spark in your soul. Eric can discover unexplored worlds and bring them back to his audience. Sometimes, complex or hard to understand, but always interesting where you get the sense of upgrading your mind.&nbsp;</p><p>Here are my favorite episodes:</p><p><a href="https://www.youtube.com/watch?v=nM9f0W2KD5s" target="_blank"><strong>1: Peter Thiel:</strong></a><strong> </strong>this was how I found the podcast. Peter rarely appears on interviews, so I knew this one had to be special. Peter Thiel is one of the most influential and contrarian thinkers of the last decades. He’s also the co-founder of PayPal and Palantir. He was also the first big investor in Facebook.&nbsp;</p><p>Peter and Eric challenge our way of thinking and encourage us to see things differently. For instance, they discussed the relationship between growth and violence. Thiel argues that if economic growth is low, violence is more likely to arise. He highlights that violence among humans is high because according to Rene Girard, we want what other people want, giving rise to conflict.&nbsp;</p><p>This may be one of the best episodes in the history of podcasts. I found this conversion can help you understand Girard’s theories' implications in society, especially in a time of wealth gap inequality, racial conflicts, and a pandemic.&nbsp;</p><p>They also discussed the era of stagnation, the future of education, student debt, the broken world of academia, and polymaths.&nbsp;</p><p>Peter (a conservative) and Eric (a progressive) discuss ideas with unique and often opposing views as they try to find a solution and reach an agreement on his arguments.&nbsp;</p><p><a href="https://plinkhq.com/i/1469999563/e/1000462975502" target="_blank"><strong>19: Bret Weinstein - The Prediction and the DISC:</strong></a><strong> </strong>In this rigid conversation with Bret, they talked about the DISC and how it affected Bret with one of his biology discoveries.&nbsp;</p><p>In this episode, Eric eagerly tries to get his brother to tell the story of his powerful finding. Bret discovered that the mice we use for medical trials have ultra-long telomeres (something humans don’t have) and that these “hide” the dangers of certain medicines. This same discovery could cure cancer and end aging.&nbsp;</p><p>After he discovered this, he tried to go the usual path of peer-review and so on. According to the podcast, he was silenced. Yet his findings were taken and made someone else the Nobel Prize winner.&nbsp;</p><p>A mind-blowing episode that will stir your curiosity and make you learn about the findings, the DISC, and The Portal.</p><p><a href="https://plinkhq.com/i/1469999563/e/1000460365533" target="_blank"><strong>17: Anna Khachiyan - Reconstructing The Mystical Feminine From The Ashes Of “The Feminine Mystique”:</strong></a><strong> </strong>Eric interviews Anna, who is a Russian-American social, literary and artistic theorist. She is also the co-host of the fierce and popular Red Scare podcast.&nbsp;&nbsp;</p><p>At the beginning of the conversation, Eric tells her, “I've been addicted to your podcast not quite understanding why. It's one of the strangest things I've ever found.” That’s exactly how I felt.&nbsp;</p><p>They talked about mystery and how society thought we wanted clarity and directness. But what we actually want is mystery, especially in our relationships.&nbsp;</p><p>Then, they talked about the importance of mystery and what it means to be mysterious. This episode will help you perceive the significance of how we can use mystery in our lives.</p><p>I’ll be honest, I don’t know why I liked this episode, but I listened to it several times and it was weirdly fascinating.&nbsp;</p><p><strong>BONUS </strong><a href="https://plinkhq.com/i/1469999563/e/1000477637846" target="_blank"><strong>36: Dark Matter, Black Matters and All That Jazz</strong></a><strong> </strong>with Stephon Alexander is an amazing episode to learn more about physics, racial issues, and music.&nbsp;</p><h2>Geometrically Unified</h2><p>I disagree with many of Eric’s views, however I still consider him a role model because of his love and passion for science. He proposed a theory of everything called Geometric Unity where he tried to explain and combine all physical aspects of the universe.&nbsp;</p><p>I love learning about science. I read books, email experts, watch interviews, write essays, and listen to podcasts like The Portal to learn more about science.&nbsp;</p><p><strong>Science</strong> combined with <strong>entrepreneurship</strong> has the power to create a world of progress and technological advancement, so we create a world of equality, fairness, and peace.&nbsp; That’s what I hope to do with my life.&nbsp;</p><p>I hope you find Eric’s work as interesting, fascinating, and curious as I have.&nbsp;</p><p>Thanks to <a href="https://jenvermet.com/" target="_blank">Jen</a>, <a href="https://salman.io/" target="_blank">Salman</a>, <a href="https://juliasaxena.com/" target="_blank">Julia</a>, and <a href="https://fullofkrapp.com/" target="_blank">Kevin</a>  for reading drafts of this essay. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595770382135_5451"><p>If you’re into interesting ideas (like the one you just read), join us at our<a href="https://juandavidcampolargo.com/newsletter"> </a><a href="https://juandavidcampolargo.com/newsletter" target="_blank"><strong>newsletter</strong></a>, and I’ll send you new essays right when they come out. <br></p></div></div>]]>
            </description>
            <link>https://www.juandavidcampolargo.com/blog/ericweinstein</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961509</guid>
            <pubDate>Mon, 27 Jul 2020 01:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Hard-to-Read Gravestones (2014)]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23961343">thread link</a>) | @vinnyglennon
<br/>
July 26, 2020 | https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/ | <a href="https://web.archive.org/web/*/https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961343</guid>
            <pubDate>Mon, 27 Jul 2020 00:50:18 GMT</pubDate>
        </item>
    </channel>
</rss>
