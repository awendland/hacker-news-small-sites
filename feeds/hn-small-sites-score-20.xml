<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 16 Sep 2020 08:24:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 16 Sep 2020 08:24:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How Do Computers Generate Random Numbers?]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24465225">thread link</a>) | @aryamansharda
<br/>
September 13, 2020 | https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<p>Anyone with any programming experience understands that computers are deterministic machines. If you provide the same input, you’ll always get the same output. That’s why having computers generate something by chance is trickier than it may seem.</p>
<p>Computers use random numbers for everything from cryptography to gambling, generative algorithms, video games, and more. However, computers are inherently incapable of being random. Instead, programmers rely on pseudorandom number generators (PRNGs). These are simply a category of algorithms that programmatically generate new random numbers from a given starting value called the seed.&nbsp;</p>
<p>These algorithms are not without their own limitations. Since the random numbers are programmatically generated, if someone were able to identify the seed value and the PRNG algorithm you were using, they’d be able to predict the next random number in the sequence. This would allow an attacker to break encryption, predict the next playing card in a sequence, cheat in a video game, etc. </p>
<p>Despite this concern, PRNGs are extremely useful in situations involving modeling and simulations as it allows you to “replay” a series of random events by initializing your random number generator with the same seed.&nbsp;</p>
<p>In situations where the randomness of the random numbers is critical, we use a “true” random number generator (TRNGs). Unlike PRNGs that have an arbitrary seed value, TRNGs pick a seed value from their environment / external data. </p>
<p>Here are a few potential options:</p>
<ul><li>Mouse movements</li><li>Fan noise</li><li>Atmospheric pressure</li><li>Number of microseconds since the last whole second</li></ul>
<p>We just need to pick a seed that an attacker wouldn’t be able to predict. This seed value will then be passed into an algorithm, similar to PRNGs, that will generate a random number to use.&nbsp;</p>
<p>The use case will generally dictate whether a PRNG will suffice or if a “true” RNG is needed. Regardless, it’s important to understand the practical differences between both approaches. </p>
<p>PRNGs are faster than TRNGs and their determinism is extremely useful in cases where you want to replay a series of “random” events. Additionally, some PRNGs are periodic in nature, but modern PRNGs with the right initialization parameters have a period long enough that it’s not a major concern. Conversely, TRNGs are slower than PRNGs, are non-deterministic, and are not periodic.</p>
<h2>Linear Congruential Generator</h2>
<p>Let’s take a look at implementing a simple PRNG. We’ll implement a variant called the <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a> (LCG) algorithm. LCG was previously one of the most commonly used and studied PRNGs (<a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">more info</a>).&nbsp;</p>
<p>Here’s the recurrence relation for LCG:</p>
<div><figure><img src="https://lh3.googleusercontent.com/iNcDHvHA6BvD1fpYntUkZ-11dzW6EYoW5dHv7mMhPZhDNo5fJaIMZXUh7SmZq0AoobvHxg7K5MMvqoWav7ee0xHase0fhAjWmNWoW7RcT5GzAao1jVwtGY11q2yL6iuvWiYFgyHS" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">Wikipedia page on LCG</a> documents a few commonly used values for modulus, multiplier, and increment. There’s no consensus on the best values to use hence the differing values across implementations.&nbsp;</p>
<p>We have to be mindful of what values we use for these parameters. Choosing the wrong values can create a period that is too short which would render our random number generator useless. </p>
<p>In the image below, you can see that small changes to our parameters can greatly impact the period length.</p>
<div><figure><img src="https://lh4.googleusercontent.com/FVum2kuYt4oMYjOdzHx2txpQH0NgheDDSUSxyQJamzGbZgPcUALt3Mmv4H-BElodwXwTzcLaqicG8IdsPFAgolV4DK8NkZXtghDQ_hX6MyMsxU_irWeOxR1ijaoYgecOU3fbuPbQ" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h2>Implementation</h2>
<p>For our implementation, we’ll use the values documented in previous standards of the C languages (C90/C99/ANSI C,&nbsp; and C11).&nbsp;</p>
<p><code>a = 1103515245</code></p>
<p><code>m = 2³¹</code></p>
<p><code>c = 12345</code></p>
<blockquote><p>Whatever PRNG algorithm you choose should result in a uniform distribution of random numbers and a sufficiently long period.&nbsp;&nbsp;</p></blockquote>
<p>Here’s a simple implementation in Swift:</p>

<h2>Simulating Dice Rolls</h2>
<p>Let’s say you wanted to simulate a dice roll. </p>
<p>It might seem reasonable to change the modulus to 6, but this would create a period far too short to be usable. We need to stick with well-chosen and tested values for our parameters. </p>

<p>Instead, using the approach in the code above, we can simulate 40,000 dice rolls:</p>
<div><figure><img src="https://lh6.googleusercontent.com/uVT2lMlmWHcYIio5WmgkMMXz9nkkA_P4lzIVWeyVETxasCDn5s_5qQWgBh5FAvfPDwHipyMaqHWmb_lOp_J7oOXiRdxo_3lywqvrIo4Ky40QoDUYIrJ15w5mC6B9XWVLWvyySRWr" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>Dice Value: 40,000 Roll Simulations</p>
<blockquote><p>Looking at the results, we can see that it is indeed a uniform distribution of values.</p></blockquote>
<h2>Generating Random Numbers In A Range</h2>
<p>Next, let’s consider generating random numbers that fall in a range. Again, we shouldn’t change our parameters without fully understanding how it affects the period. </p>
<p>Instead, we should map our PRNG’s results to values in our desired range.&nbsp;</p>

<div><figure><img src="https://lh4.googleusercontent.com/A2h_s4Z_eN-qGkjEZabgPwWpOjMmIDdD9fQlYcdM344voNTlxPIvammtm6RRXJ6aDgG83h67zZYf4E4olN7jz5VRiIK10D_XeRTf0whcfHLZhn8Q9142vJBZU9Ma40DIvFVw7FdU" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>After a million simulations across the specified range [30, 80)</p>
<h2>Further Reading</h2>
<p>If you’re interested in a <a href="https://en.wikipedia.org/wiki/List_of_random_number_generators">more modern PRNG</a>, I’d recommend exploring the <a href="https://en.wikipedia.org/wiki/Mersenne_Twister">Mersenne-Twister</a> approach. It’s currently the most popular PRNG algorithm and currently used in Python (numpy), Ruby, PHP, R, and C++.&nbsp;This was meant to be a high-level introduction into this topic. If you’re interested in learning more about this topic, <a href="https://en.wikipedia.org/wiki/List_of_random_number_generators#Pseudorandom_number_generators_(PRNGs)">here a few other PRNGs to consider. </a> </p>
<p>Hope you enjoyed this article! Feel free to check out my other articles below!</p>
 
</div></div>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24465225</guid>
            <pubDate>Mon, 14 Sep 2020 00:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AresDB: Uber's GPU-Powered Open Source, Real-Time Analytics Engine]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24461844">thread link</a>) | @Recovery2020
<br/>
September 13, 2020 | https://ubere.ng/2HzMPVK | <a href="https://web.archive.org/web/*/https://ubere.ng/2HzMPVK">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1.png" data-caption=""><img width="696" height="298" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-696x298.png" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-696x298.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-300x128.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-768x329.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-1024x438.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-1068x457.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1-981x420.png 981w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/Featured-1.png 1500w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="Featured"></a></p>
        <p><span>At Uber, real-time analytics allow us to attain business insights and operational efficiency, enabling us to make data-driven decisions to improve experiences on the Uber platform. For example, our operations team relies on data to monitor the market health and spot potential issues on our platform; software powered by machine learning models leverages data to predict rider supply and driver demand; and data scientists use data to improve machine learning models for better forecasting. </span></p>
<p><span>In the past, we have utilized many third-party database solutions for real-time analytics, but none were able to simultaneously address all of our functional, scalability, performance, cost, and operational requirements. </span></p>
<p><span>Released in November 2018, AresDB is an open source, real-time analytics engine that leverages an unconventional power source, graphics processing units (GPUs), to enable our analytics to grow at scale. An emerging tool for real-time analytics, GPU technology has advanced significantly over the years, making it a perfect fit for real-time computation and data processing in parallel. </span></p>
<p><span>In the following sections, we describe the design of AresDB and how this powerful solution for real-time analytics has allowed us to more performatively and efficiently unify, simplify, and improve Uber’s real-time analytics database solutions. After reading this article, we hope you try out AresDB for your own projects and find the tool useful your own analytics needs, too! </span></p>
<h3>Real-time analytics applications at Uber</h3>
<p><span>Data analytics are crucial to the success of Uber’s business. Among other functions, these analytics are used to: </span></p>
<ul>
<li><span>Build </span><b>dashboards</b><span> to monitor our business metrics</span></li>
<li><span>Make </span><b>automated decisions</b><span> (such as </span><a href="https://www.uber.com/drive/partner-app/how-surge-works/" target="_blank" rel="noopener noreferrer"><span>trip pricing</span></a><span> and </span><a href="https://eng.uber.com/advanced-technologies-detecting-preventing-fraud-uber/" target="_blank" rel="noopener noreferrer"><span>fraud detection</span></a><span>) based on aggregated metrics that we collect</span></li>
<li><span>Make </span><b>ad hoc queries</b><span> to diagnose and troubleshoot business operations issues</span></li>
</ul>
<p><span>We can summarize these functions into categories with different requirements as follows:</span></p>
<table>
<tbody>
<tr>
<td></td>
<td><b>Dashboards</b></td>
<td><b>Decision Systems</b></td>
<td><b>Ad hoc Queries</b></td>
</tr>
<tr>
<td><span>Query Pattern</span></td>
<td><span>Well known</span></td>
<td><span>Well known</span></td>
<td><span>Arbitrary </span></td>
</tr>
<tr>
<td><span>Query QPS</span></td>
<td><span>High</span></td>
<td><span>High</span></td>
<td><span>Low</span></td>
</tr>
<tr>
<td><span>Query Latency</span></td>
<td><span>Low</span></td>
<td><span>Low</span></td>
<td><span>High</span></td>
</tr>
<tr>
<td><span>Dataset</span></td>
<td><span>Subset</span></td>
<td><span>Subset</span></td>
<td><span>All data</span></td>
</tr>
</tbody>
</table>

<p><span>Dashboards and decision systems leverage real-time analytical systems to make similar queries over relatively small, yet highly valuable, subsets of data (with maximum data freshness) at high QPS and low latency.</span></p>
<h4>The need for another analytical engine</h4>
<p><span>The most common problem that real-time analytics solves at Uber is how to compute time series aggregates, calculations that give us insight into the user experience so we can improve our services accordingly. With these computations, we can request metrics by specific dimensions (such as day, hour, city ID, and trip status) over a time range on arbitrarily filtered (or sometimes joined) data. Over the years, Uber has deployed multiple solutions to solve this problem in different ways.</span></p>
<p><span>Some of the third-party solutions we’ve used for solving this type of problem include:</span></p>
<ul>
<li><a href="https://github.com/apache/incubator-pinot" target="_blank" rel="noopener noreferrer"><b>Apache Pinot</b></a><span>, an open source distributed analytical database written in Java, can be leveraged for large-scale data analytics. Pinot employs a lambda architecture internally to query batch and real-time data in columnar storage, uses inverted bitmap index for filtering, and relies on star-tree for aggregate result caching. However, it does not support key-based deduplication, upsert, joins, and advanced query features such as geo-spatial-filtering. In addition, being a JVM-based database, query execution on Pinot runs at a higher cost in terms of memory usage.</span></li>
<li><a href="https://www.elastic.co/" target="_blank" rel="noopener noreferrer"><b>Elasticsearch</b></a><span> is used at Uber for a variety of streaming analytics needs. It was built on Apache </span><a href="http://lucene.apache.org/" target="_blank" rel="noopener noreferrer"><span>Lucene</span></a><span> for full-text keyword search that stores documents and inverted index. It has been widely adopted and extended to also support aggregates. The inverted index enables filtering, yet it is not optimized for time range-based storage and filtering. It stores records as JSON documents, imposing additional storage and query access overhead. Like Pinot, Elasticsearch is a JVM-based database, and as such, does not support joins and its query execution runs at a higher memory cost. </span></li>
</ul>
<p><span>While these technologies have strengths of their own, they lacked crucial functionalities for our use case. We needed a unified, simplified, and optimized solution, and thought outside-of-the-box (or rather, inside the GPU) to reach a solution.</span></p>
<h3>Leveraging GPUs for real-time analytics</h3>
<p><span>To render realistic views of images at a high frame rate, GPUs process a massive amount of geometries and pixels in parallel at high speed. While the clock-rate increase for processing units has plateaued over the past few years, the number of transistors on a chip has only increased per </span><a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="noopener noreferrer"><span>Moore’s law</span></a><span>. As a result, GPU computation speeds, measured in Gigaflops per second (GFLOP/s), are rapidly increasing. Figure 1, below, depicts the theoretical GFLOP/s trend comparing NVIDIA GPUs and Intel CPUs over the years:</span></p>
<figure id="attachment_5345" aria-describedby="caption-attachment-5345"><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png" alt="" width="600" height="314" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2.png 1999w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-300x157.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-768x402.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1024x536.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-696x365.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1068x559.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-802x420.png 802w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image11-2-1920x1006.png 1920w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-5345">Figure 1: Comparison of CPU and GPU single precision floating point performance through the years. Image taken from Nvidia’s CUDA C programming guide.</figcaption></figure>
<p><span>When designing our real-time analytics querying engine, integrating GPU processing was a natural fit. At Uber, the typical real-time analytical query processes a few days of data with millions to billions of records and then filters and aggregates them in a short amount of time. This computation task fits perfectly into the parallel processing model of general purpose GPUs because they:</span></p>
<ul>
<li><span>Process data in parallel very quickly. </span></li>
<li><span>Deliver greater computation throughput (GFLOPS/s), making them a good fit for heavy computation tasks (per unit data) that can be parallelized. </span></li>
<li><span>Offer greater compute-to-storage (ALU to GPU global memory) data access throughput (not latency) compared to central processing units (CPUs), making them ideal for processing I/O (memory)-bound parallel tasks that require a massive amount of data.</span></li>
</ul>
<p><span>Once we settled on using a GPU-based analytical database, we assessed a few existing analytics solutions that leveraged GPUs for our needs:</span></p>
<ul>
<li><a href="https://www.kinetica.com/" target="_blank" rel="noopener noreferrer"><b>Kinetica</b></a><span>, a GPU-based analytics engine, was initially marketed towards U.S. military and intelligence applications in 2009. While it demonstrates the great potential of GPU technology in analytics, we found many key features missing</span> <span>for our use case, including </span><span>schema alteration, partial insertion or updates, data compression, column-level memory/disk retention configuration, and join by geospatial relationships.</span></li>
<li><a href="https://www.omnisci.com/" target="_blank" rel="noopener noreferrer"><b>OmniSci</b></a><span>, an open source, SQL-based query engine, seemed like a promising option, but as we evaluated the product, we realized that it did not have critical</span><span> features for Uber’s use case, such as deduplication. While </span><span>OminiSci</span> <span>open sourced their project in 2017, after some analysis of their C++-based solution, we concluded that neither contributing back nor forking their codebase was viable.</span></li>
<li><span>GPU-based real-time analytics engines, including </span><a href="https://www.cse.ust.hk/gpuqp/" target="_blank" rel="noopener noreferrer"><span>GPUQP</span></a><span>, </span><a href="http://cogadb.dfki.de/" target="_blank" rel="noopener noreferrer"><span>CoGaDB</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p817-yuan.pdf" target="_blank" rel="noopener noreferrer"><span>GPUDB</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p709-heimel.pdf" target="_blank" rel="noopener noreferrer"><span>Ocelot</span></a><span>, </span><a href="http://www.vldb.org/pvldb/vol6/p1374-he.pdf" target="_blank" rel="noopener noreferrer"><span>OmniDB</span></a><span>, and </span><a href="https://github.com/bakks/virginian" target="_blank" rel="noopener noreferrer"><span>Virginian</span></a><span>, are frequently used by academic institutions. However, given their academic purpose, these solutions focus on developing algorithms and designing proof of concepts as opposed to handling real-world production scenarios. For this reason, we discounted them for our scope and scale.</span></li>
</ul>
<p><span>Overall, </span><span>these engines</span><span> demonstrate the great advantage and potential of data processing using GPU technology, and they inspired us to build our own GPU-based, real-time analytics solution tailored to Uber’s needs. With these concepts in mind, we built and open sourced AresDB.</span></p>
<h3>AresDB architecture overview</h3>
<p><span>At a high level, AresDB stores most of its data in host memory (RAM that is connected to CPUs), handling data ingestion using CPUs and data recovery via disks. At query time, AresDB transfers data from host memory to GPU memory for parallel processing on GPU. As shown in Figure 2, below, AresDB consists of a memory store, a meta datastore, and a disk store:</span></p>
<figure id="attachment_5346" aria-describedby="caption-attachment-5346"><a href="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png" alt="" width="600" height="340" srcset="https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20.png 1999w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-300x170.png 300w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-768x435.png 768w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1024x580.png 1024w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-696x394.png 696w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1068x605.png 1068w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-741x420.png 741w, https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/image20-1920x1088.png 1920w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-5346">Figure 2: The AresDB single instance architecture features memory and disk stores, and meta stores.</figcaption></figure>
<h4>Tables</h4>
<p><span>Unlike most </span><span>relational database management systems (</span><span>RDBMSs), there is no database or schema scope in AresDB. All tables belong to the same scope in the same AresDB cluster/instance, enabling users to refer to them directly. Users store their data as fact tables and dimension tables.</span></p>
<h5>Fact table</h5>
<p><span>A fact table stores an infinite stream of time series events. Users use a fact table to store events/facts that are happening in real time, and each event is associated with an event time, with the table often queried by the event time. An example of the type of information stored by fact tables are trips, where each trip is an event and the trip request time is often designated as the event time. In case an event has multiple timestamps associated with it, only one timestamp is designated as the time of the event displayed in the fact table.</span></p>
<h5>Dimension table</h5>
<p><span>A dimension table stores current properties for entities (including cities, clients, and drivers). For example, users can store city information, such as city name, time zone, and country, in a dimension table. Compared to fact tables, which grow infinitely over time, dimension tables are always bounded by size (e.g., for Uber, the cities table is bounded by the actual number of cities in the world). Dimension tables do not need a special time column.</span></p>
<h4>Data types</h4>
<p><span>Table below details the current data types supported in AresDB:</span></p>
<table>
<tbody>
<tr>
<td><a href="https://github.com/uber/aresdb/wiki/Data-Types" target="_blank" rel="noopener noreferrer"><b>Data Types</b></a></td>
<td><b>Storage (in Bytes)</b></td>
<td><b>Details</b></td>
</tr>
<tr>
<td><span>Bool</span></td>
<td><span>1/8</span></td>
<td><span>Boolean type data, stored as single bit</span></td>
</tr>
<tr>
<td><span>Int8, Uint8</span></td>
<td><span>1</span></td>
<td rowspan="3"><span>Integer number types. User can choose based on cardinality of field and memory cost.</span></td>
</tr>
<tr>
<td><span>Int16, Uint16</span></td>
<td><span>2</span></td>
</tr>
<tr>
<td><span>Int32, Uint32</span></td>
<td><span>4</span></td>
</tr>
<tr>
<td><span>SmallEnum</span></td>
<td><span>1</span></td>
<td><span>Strings are auto translated into enums. SmallEnum can holds string type with cardinality up to 256</span></td>
</tr>
<tr>
<td><span>BigEnum</span></td>
<td><span>2</span></td>
<td><span>Similar to SmallEnum, but holds higher cardinality up to 65535</span></td>
</tr>
<tr>
<td><span>Float32</span></td>
<td><span>4</span></td>
<td><span>Floating point number. We support Float32 and intend to add Float64 support as needed</span></td>
</tr>
<tr>
<td><span>UUID</span></td>
<td><span>16</span></td>
<td><a href="https://en.wikipedia.org/wiki/Universally_unique_identifier" target="_blank" rel="noopener noreferrer"><span>Universally unique identifier</span></a></td>
</tr>
<tr>
<td><span>GeoPoint</span></td>
<td><span>4</span></td>
<td><span>Geographic points</span></td>
</tr>
<tr>
<td><span>GeoShape</span></td>
<td><span>Variable Length</span></td>
<td><span>Polygon or multi-polygons</span></td>
</tr>
</tbody>
</table>
<p><span>With AresDB, strings are …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ubere.ng/2HzMPVK">https://ubere.ng/2HzMPVK</a></em></p>]]>
            </description>
            <link>https://ubere.ng/2HzMPVK</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461844</guid>
            <pubDate>Sun, 13 Sep 2020 16:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What If ‘Capitalism’ Isn't the Problem? [audio]]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24461604">thread link</a>) | @ojarow
<br/>
September 13, 2020 | https://musingmind.org/podcasts/julie-nelson | <a href="https://web.archive.org/web/*/https://musingmind.org/podcasts/julie-nelson">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-052ee15c0c629a5866d7"><div><p>My guest today is Julie Nelson: economist, and zen teacher. She co-edited a book in 1993 that became known to many as an early manifesto for feminist economics, and has spent her career questioning assumptions - of both the human mind and the discipline of economics.</p><p>She is an economics professor (emeritus) at the University of Massachusetts, Boston, a senior research fellow at the Global Development and Environment Institute at Tufts, and a senior assistant teacher at the Greater Boston Zen Center. She is author of the book <em>Economics for Humans, </em>co-editor of <em>Beyond Economic Man: Feminist Theory and Economics</em>, and a number of others.</p><p>A polarizing question lingers as the theme for our conversation: <em>what if capitalism isn’t the problem? </em>Julie suggests that many of the ills - greed, environmental degradation, extreme inequality - so many on the left are quick to blame capitalism for have little to do with capitalism. Rather, she targets ‘economism’ - a particular set of economic theories and assumptions, plus a layer of incentives we’ve built atop them. Neither updating our theories to better match reality, nor redesigning the incentive structures that underlie economic outcomes require an exit from capitalism.</p><p>Viewing capitalism as a rigid and dogmatic system that inherently produces certain outcomes, Julie suggests, are “short-cuts to thinking” that keep us from seeing the agency we already have to change the system.</p><p>A few other topics we explore:</p><ul data-rte-list="default"><li><p>Imaginative rationality.</p></li><li><p>The ‘emptiness’, or ‘no-nature’ of markets.</p></li><li><p>Are consciousness and materialism compatible?</p></li><li><p>Can waged work be intrinsically motivated?</p></li><li><p>How can we change our capitalist system from with?</p></li></ul><p>Enjoy!</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599754497552_93915"><div><h3>Time Map</h3><p>0:40 ~ How do Julie’s zen practice and economics research relate to one another?</p><p>8:30 ~ What is “imaginative rationality”, and what role can it play in economic thought?</p><p>13:20 ~ The mistake that is made by both free-market fundamentalists and eco-socialists: markets do not have fixed, inherent outcomes. They are responsive and adaptive to their social, political, and legal contexts.</p><p>21 ~ Example of “profit maximizing firms”. Corporate greed is not necessarily capitalism’s fault, but a particular system of incentives and corporate governance laws that we’re created <em>within</em> our form of capitalism.</p><p>26 ~ Does consciousness lack any ‘inherent nature’ in the same way that markets do? Is consciousness ‘unconditional’, or is it fundamentally expressed and shaped through and by the conditions of our lives?</p><blockquote><p><em>28:50 ~ “Our brains did not develop to help us think logically about things, our brains developed to help us survive.” </em></p></blockquote><p>36:30 ~ Does it make sense to think of progress as a gradual decreasing of the amount of time citizens are impelled by necessity to sell and exchange on labor markets in order to access the resources they need to survive? Should we return to the forgotten American dream of the late 19th century, where economic progress would deliver more leisure time for all?</p><p>39:20- ~ Julie makes a case <em>for</em> waged work. She wisely rejects my binary that if we work for wages, we’re extrinsically motivated, and only if we are free from wages can we tap into intrinsic motivation.</p><p>43:10 ~ How do we raise wages for socially valuable work, where we want high quality care, that is drastically underpaid, like early childhood education? </p><p>49:30 ~ Adapting Erik Olin Wright’s theory of change - “taming and eroding” capitalism - what are the leverage points inside our current capitalist system that we can focus on to drive change from within?</p><p>57:30 ~ The ‘mushroom man’ theory of human nature at the heart of outdated economic models.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599754497552_28871"><div><p>You can support the podcast by sharing on social media, with a friend, or leaving a rating &amp; <a href="https://podcasts.apple.com/us/podcast/musing-mind-podcast/id1480082389" target="_blank">review on Apple Podcasts</a>!</p><p>Receive new episodes &amp; related musings by <a href="https://musingmind.substack.com/" target="_blank">joining the newsletter community</a>. If you’d like to get in touch with me, you can reach me <a href="https://twitter.com/OshanJarow" target="_blank">on Twitter</a>, or <a href="https://musingmind.org/contact" target="_blank">directly</a>. </p><p>If you’re <em>really</em> interested in helping the podcast exist, consider <a href="https://www.patreon.com/OshanJarow" target="_blank">becoming a Patron</a> with a small monthly donation of even $1! Your support means the world, and goes directly towards improving the podcast’s audio quality, equipment, research, and overall experience.</p><p>Thank you!</p></div></div></div>]]>
            </description>
            <link>https://musingmind.org/podcasts/julie-nelson</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461604</guid>
            <pubDate>Sun, 13 Sep 2020 15:52:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disrespectful Design – Users aren’t stupid or lazy]]>
            </title>
            <description>
<![CDATA[
Score 382 | Comments 213 (<a href="https://news.ycombinator.com/item?id=24461365">thread link</a>) | @Ozzie_osman
<br/>
September 13, 2020 | https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-68">

	

	
	<div>
		
<p>It’s a common narrative in tech to design products with the assumption that users are stupid and lazy. I think that is both disrespectful and wrong.</p>



<p>The idea is rooted in a lot of research around product usability, but it has been bastardized. Thing of it as a perversion of the <a href="https://en.wikipedia.org/wiki/Don%27t_Make_Me_Think">Don’t Make Me Think</a> thesis.</p>



<p><em>Don’t Make Me Think</em>, the seminal web usability book by Steve Krug, tells us that products should be as simple as possible for users to use. Products shouldn’t be self-explanatory (ie understandable given a set of instructions), they should be self-evident (ie so obvious that they can be used <em>without</em> having to read instructions). A good door has a push/pull sign to make it self-explanatory, but it still requires you to read and think. An even better door wouldn’t even need that label at all—you know what to do instinctively.</p>



<p>But somehow, we’ve perverted that idea. Users are lazy, even stupid, we say. They just want to flick their fingers down an infinite feed, letting their eyes wander from item to item.</p>



<p>But in <em>Don’t Make Me Think</em>, Krug never refers to users in a derogatory way. He tells us how good products should work, and why basic psychology supports that. People want to reduce cognitive friction as much as possible. People don’t like unneeded cognitive friction. People skim quickly and “muddle through” products. And, most of all, people won’t undertake effort unless they believe it’s worth the cost. These are all facts backed by usability research and psychology.</p>



<p>In other words, he tells us <em>what</em> good products should look like, and <em>how</em> people use them. But he doesn’t pass judgment on users. That’s up to us.</p>



<p>And so naturally, we apply our view of the world, our values. If you view your users with contempt, then the reason behind why people don’t like complicated products is because they are stupid and lazy. If, on the other hand, you <em>respect</em> your users, you might view things differently.</p>



<p>Firstly, our brains have been wired, through millions of years of evolution, to conserve effort and time. That’s actually not being lazy, it’s being smart and protective of one of our most valuable assets. Naturally, we don’t undertake an activity unless we believe it’s worth the cost (though there are ways to trick us, more on that later). And if it takes effort to even figure out how much effort an activity will require, we’ll avoid that activity altogether. That’s the functional, practical piece of our brain at work.</p>



<p>Secondly, we are a complex bundle of emotions. Even if we’re smart, we don’t like <em>feeling</em> stupid. And complex, difficult things makes us feel stupid. They strike at our very identity and self-worth. So we try to avoid them like we avoid that hard topic we were never good at in school. <em>That</em> part is the emotional piece of our brain at work.</p>



<p>So what explains the rise of products like Facebook, which have gotten a large part of humanity mindlessly scrolling through feeds of what can most easily be described as garbage content? Well, we humans aren’t perfect. If you’ve got billions of dollars, some of the brightest minds, and a lot of data at your disposal, you can get a lot of people to do what you want. If you treat users as stupid and lazy, you can turn them into stupid and lazy people in the context of your product… but that’s a subject for another post.</p>



<p>So here’s how I think about people and product design.</p>



<p>Firstly, products should definitely be as simple as possible. Because I <em>respect </em>users’ time, not because I look down on their intelligence.</p>



<p>Second, have a theory of how people behave. I’m a big fan of <a href="https://en.wikipedia.org/wiki/Self-determination_theory">Self-determination Theory</a>, which states that people value autonomy, relatedness, and competence. And I love building product that help people improve all those three dimensions.</p>



<p>Three, have a set of principles for your product. For instance, of the three axes of self-determination, I particularly care about autonomy (control). And I’ve found that good products, ones that respect their users, <em>give them more control</em>. Bad products <em>take away control</em>. Simplicity can fulfill both of those purposes. It can give people control by abstracting away things they don’t care about and helping them focus. Or it can take away control by only letting users do things the product’s designers want them to do. So that’s one of my principles: give people control. Help them do things <em>they </em>want to do, not things <em>you</em> want them to do.</p>



<p>Let’s respect our users. Technology can bring out the best or worst in us, both individually and collectively. Let’s focus on the best.</p>



<hr>



<p><strong>EDIT:</strong> The above article is what I wrote, in its half-formed state on a Sunday morning. It looks like it’s blowing up on HackerNews, so I wanted to just add a few points.</p>



<ul><li>I know I can come across as idealistic. I’ve even gotten that as feedback on a formal performance review (but also, I’ve gotten that I’m cynical, so *shrug*). I’m not saying people can’t be lazy, entitled, or stupid. We can. We have that <em>capacity</em>. But we have the <em>capacity</em> for so much more than that. And we should focus our tools, our technology, on our best capacities.</li><li>If Self-determination Theory resonates with you, I’d urge you to think about how it applies to building teams or even parenting. Your employees and colleagues, or your children and family members, have all the human capacities as well (though obviously, for children, they are still under development). Since I’m much more experienced at managing teams (dozen years) than being a parent (two years), I’ll just say that companies that view employees as lazy and incompetent are a scourge. If you can afford to avoid working at companies like that, try your best. And if you’re tasked with building companies or teams, you get to choose. You still need rules, hierarchies, and processes, but if you give people autonomy and relatedness/purpose, and trust their competence, I hope you’ll be pleasantly surprised. If you treat employees as stupid and lazy, they will be.</li><li>On simplicity vs. control/flexibility: I’m a big fan of the Alan Kay quote that “<a href="https://en.wikiquote.org/wiki/Alan_Kay">simple things should be simple, complex things should be possible</a>.” I think great products find a way of achieving both those objectives. You keep things simple, but don’t throw out the baby with the bath-water. Like the word processor. 99% of the time, you just want to type some text, so you get a cursor and WYSIWIG typing. But sometimes, you want to style, you want to indent, you want to program macros. We apply this principle often at <a href="https://www.monarchmoney.com/">Monarch Money</a> (personal finance platform that I’m working on) and so far have found it to be quite successful.</li></ul>



<hr>



<p><em>About me:</em> <em>I’m a <a href="https://www.linkedin.com/in/oaosman/">software builder / entrepreneur</a>. I write about software, software engineering management, and product-building</em>. <em>I currently manage the engineering team at <a href="https://www.monarchmoney.com/">Monarch Money</a>, a personal finance platform. You can follow me here</em> <em>on this blog</em>, <a href="https://medium.com/@Oao84"><em>or on Medium</em></a>. <em>I also helped write a <a href="https://www.amazon.com/Holloway-Guide-Technical-Recruiting-Hiring/dp/195212008X">book on hiring/recruiting in the software world</a> with a group of really awesome people.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/13/disrespectful-design-users-arent-stupid-or-lazy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461365</guid>
            <pubDate>Sun, 13 Sep 2020 15:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Governments should adopt and invest in FOSS]]>
            </title>
            <description>
<![CDATA[
Score 328 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24461364">thread link</a>) | @nivenkos
<br/>
September 13, 2020 | http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en | <a href="https://web.archive.org/web/*/http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post covers why I believe local and national governments should
adopt and invest in <a href="https://www.gnu.org/philosophy/free-sw.en.html">Free and Open Source Software</a> (FOSS).</p>

<p>This has been in the news recently due to the city of Munich renewing 
it’s <a href="https://www.zdnet.com/article/linux-not-windows-why-munich-is-shifting-back-from-microsoft-to-open-source-again/">LiMux Linux distribution</a>
thanks to an agreement between the local SDP and Green politicians, and
the efforts of the <a href="https://publiccode.eu/">Public Money, Public Code</a> campaign.</p>

<!--more-->

<p>Opinions expressed are solely my own and do not express the views or opinions of my employer.</p>

<h2 id="limux">LiMux</h2>

<p><a href="https://en.wikipedia.org/wiki/LiMux">LiMux</a> is a project by the German city of Munich to migrate its desktop
infrastructure to FOSS solutions, specifically to the LiMux Linux
distribution (based on Ubuntu) and LibreOffice (initially to OpenOffice). The project was started in 2004, and
migration began in 2006.</p>

<p>By the end of 2013, 15,000 desktops had been migrated successfully.
However, in September 2016 <a href="https://mspoweruser.com/microsoft-germany-moves-into-a-new-headquarters/">Microsoft announced the opening of a new headquarters in Munich</a>, and then
in 2017 the <a href="https://www.techrepublic.com/article/end-of-an-open-source-era-linux-pioneer-munich-confirms-switch-to-windows-10/">city council decided to switch back to Microsoft Windows and Office</a>.
The timing of this decision led to many accusations of effective
bribery, using the potential office opening to pressure the council in to using
Microsoft products (note that there is no evidence of a kick-back scheme
<a href="https://www.zdnet.com/article/microsoft-to-pay-25m-to-doj-and-sec-in-hungary-bribery-case/">like practiced by Microsoft Hungary</a>).</p>

<p>Fortunately <a href="https://fsfe.org/news/2020/news-20200506-01.en.html">this decision has now been reversed</a>, and LiMux 
development and roll-out will continue.</p>

<h2 id="other-cities">Other cities</h2>

<p>Munich is not the only city choosing Free Software solutions, many
others are beginning to see the potential benefits too. In Catalonia,
Barcelona’s <a href="https://ajuntament.barcelona.cat/digital/es/transformacion-digital/tecnologia-para-un-gobierno-mejor/software-libre">Digital Transformation programme supports Free Software</a>.
From first-hand experience this means that the government transport /
road organisation use LibreOffice for all documents - so local driving
schools, etc. do not need a copy of Microsoft Office to handle the
necessary digital paperwork.</p>

<p>In Valencia, <a href="https://www.muylinux.com/2013/08/22/generalitat-valenciana-libreoffice/">the local government migrated its administration and
schools to LibreOffice</a>
saving 1.5 million euros per year, and saving students and other
end-users from having to purchase their own copies of Microsoft Office.</p>

<p>However, it is not always straightforward. <a href="https://lwn.net/Articles/737818/">Munich faced a lot of push-back in some areas</a>, and the <a href="https://cronicaglobal.elespanol.com/politica/colau-gasta-4-5-millones-en-microsoft-mientras-promete-software-libre_32165_102.html">city of Barcelona still pays almost 5 million
euros</a>
in license costs to Microsoft.</p>

<p>The main issue here is not so much the direct cost to the city itself
(which is substantial, but not critical compared to other costs -
especially since any migration will incur a significant short-term
cost), but more that the cost must be paid over and over again by all
users separately. Barcelona continues to pay millions to Microsoft every
year, but so will other cities in Spain and across Europe, and then so will all
users of those services that may have to use a copy of Microsoft Office for
compatibility reasons (i.e. students and small businesses).</p>

<p>The same cost is paid over and over again to a foreign company that will
not hire local developers or invest in the local economy, and <a href="https://en.wikipedia.org/wiki/Criticism_of_Microsoft#Vendor_lock-in">uses vendor lock-in</a>
to eventually control all of the critical infrastructure.</p>

<h2 id="benefits-of-foss">Benefits of FOSS</h2>

<p>The most commonly cited benefit of Free Software is certainly the cost
savings vs. proprietary licensing. Whilst this can be a benefit
in some circumstances, I think it overlooks many greater far-reaching
benefits, and may not actually manifest itself in the short-term due to
the additional costs of the actual migration (i.e. costs of deployment
and training).</p>

<h3 id="shared-investment">Shared investment</h3>

<p>The main benefit of using FOSS solutions is that any investment in the
development and improvement of the software also benefits all other
users of the software.</p>

<p>That is, whilst the city of Munich might need <a href="https://github.com/WollMux/WollMux">some improvements in
handling templates</a>, other cities
might need other improvements - however they can all benefit from
each others’ investment, with no need to pay again just to keep a license.</p>

<p>This helps to build up a commonwealth of high-quality, well-maintained
software which anyone can use. There is no central, unique
owner of the projects (any project could be forked if necessary), so
there is no company that can demand payments just to allow you to keep using the
existing software.</p>

<p>Any investment in development made is truly an investment, leading directly
to project improvements, rather than just money sent to a foreign
company whilst the customers have no ownership of the actual product,
allowing the company to charge even more in the future just for the
right to keep using it (usually this is done by giving discounts for the
early migration which then result in higher prices later once the
customer is locked in).</p>

<p>Note that this initial investment might be higher than the current costs
of existing proprietary software licensing, when considering the
migration and training costs and possible development costs. However,
unlike those licensing costs it is a one-time cost, and the customer
retains some ownership over the resulting product (i.e. there is not a
license that can be revoked).</p>

<h3 id="freedom-for-development">Freedom for development</h3>

<p>There is also more freedom in the development process. The fact that the
products aren’t owned by a company means that contributions can be made
by anyone, anywhere.</p>

<p>Users of the software (such as the cities mentioned above) could fund
<a href="https://github.com/hng/tech-coops">local co-operatives of developers</a> to add desired features and maintain
the projects, instead of being forced to fund a foreign corporation with
no local investment.</p>

<p>In the long-term this might also help to break up some of the monopolistic
Big Tech companies, and result in a freer society and business
environment for everyone.</p>

<h3 id="national-security">National security</h3>

<p>In Europe especially, the current dependence on proprietary software
often means a dependence on foreign corporations which operate in
co-operation with their country’s intelligence service. As revealed by
Edward Snowden, <a href="https://www.theguardian.com/world/2013/jul/11/microsoft-nsa-collaboration-user-data">Microsoft provided backdoor access to encrypted messages</a> to
the NSA, CIA and FBI as part of the <a href="https://en.wikipedia.org/wiki/PRISM_(surveillance_program)">PRISM programme</a>.</p>

<p>It is indefensible that such a company can run the critical infrastructure
of the vast majority of local and central government administrations, as
well as personal computers. Especially when the <a href="https://www.theguardian.com/us-news/2015/jul/08/nsa-tapped-german-chancellery-decades-wikileaks-claims-merkel">NSA has been proven to
intercept communications of supposedly allied nations</a>.</p>

<p>With FOSS software there is no central company to be pressured by
intelligence services or build in backdoors. All of the code can be
scrutinised by developers and users. <a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus’s Law</a> states:</p>

<blockquote>
  <p>Given enough eyeballs, all bugs are shallow.</p>
</blockquote>

<p>The same concept applies to introducing backdoors to access private data. It
might be possible to pressure or bribe one company to do so, but it
isn’t possible to do the same to tens of thousands of independent users and
developers.</p>

<h2 id="bigger-picture">Bigger picture</h2>

<p>The effects of co-ordinated FOSS adoption are much more far-reaching and
positive than solely saving the costs of current software licenses.</p>

<p>The adoption of FOSS and investment by many governments (at all levels)
would help to create a commonwealth of quality Free Software for all
citizens and government bodies to benefit from.</p>

<p>It would also allow development of these projects to be done from
anywhere, allowing users to fund local developers or co-operatives. This
would help to break up the massive, monopolistic Big Tech companies, and
could also be used as a way of bringing investment and jobs to parts of
the country/region that require it.</p>

<p>This would also be highly beneficial to developers, as they would have
more control over their own work (as they are not tied to the few
employers that own these popular products), and would also likely be
able to negotiate a larger portion of the compensation directly since
there would not be the overhead of salespeople and lawyers, etc. present in
current large software companies.</p>

<p>All Free Software users would benefit from the greater usage and
investment - GNU/Linux users could expect better hardware support for
example, as it becomes more commonplace.</p>

<h2 id="how-to-get-there">How to get there</h2>

<p>Whilst the benefits of adopting FOSS are clear, the cases in Munich and
Hungary show that it will not be an easy path to greater adoption. We
cannot just rely on central government eventually carry out the adoption
as the few representatives are easily pressured by the beneficiaries of
the status quo, and are serving a much larger political platform.</p>

<p>Ultimately, I think the solution lies in applying “Linus’s Law” to
politics itself. It is no coincidence that the successes in FOSS
adoption so far have been concentrated in local government - in specific
city councils and regional administrations, because it is easier for
engaged groups of citizens to have a direct effect in local government.</p>

<p>At a national level, it might be possible for a large software company
to pressure a few political leaders and policy makers, however, it is
much harder to do the same to a whole board of a dozen or more local
councillors (especially across the multitude of different counties and
regional administrations). There is “safety in numbers” as it becomes
unfeasible to pressure and manipulate large groups of
politically-engaged citizens.</p>

<p>It it is the responsibility of every citizen in a democratic society not
only to inform themselves and vote in national elections, but also to really partake in the
political system: by joining a political party, taking part in local and
regional elections, and ensuring that the democratic standards are
upheld both inside the party and in political institutions.</p>

<p>This should have support from across the political spectrum, as
guaranteeing the security and privacy of citizens’ data whilst also
cutting out the middlemen of massive foreign corporations, shouldn’t be
a controversial policy.</p>

<p>Efforts in local politics have already proven successful, such as the
LiMux project and others mentioned previously. So if you agree with the
points raised here I hope you will join whichever local political party
you agree most with, and help to bring about FOSS adoption by your
government.</p>

<h2 id="summary">Summary</h2>

<p>Greater FOSS adoption by our governments benefits the administrations
themselves by being free …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en">http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en</a></em></p>]]>
            </description>
            <link>http://jamesmcm.github.io/blog/2020/09/12/foss-government/#en</link>
            <guid isPermaLink="false">hacker-news-small-sites-24461364</guid>
            <pubDate>Sun, 13 Sep 2020 15:15:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's so hard about PDF text extraction?]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 157 (<a href="https://news.ycombinator.com/item?id=24460142">thread link</a>) | @fagnerbrack
<br/>
September 13, 2020 | https://filingdb.com/b/pdf-text-extraction | <a href="https://web.archive.org/web/*/https://filingdb.com/b/pdf-text-extraction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>There is a common view that extracting text from a PDF document should not be too difficult. After all, the text is right there in front of our eyes and humans consume PDF content all the time with great success. Why would it be difficult to automatically extract the text data? </p><p>Turns out, much how <a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">working with human names is difficult</a> due to numerous edge cases and incorrect assumptions, working with PDFs is difficult due to the extreme flexibility given by the PDF format.</p><p>The main problem is that PDF was never really designed as a data input format, but rather, it was designed as an output format giving fine grained control over the resulting document.</p><p>At its core, the PDF format consists of a stream of instructions describing how to draw on a page. In particular, text data isn’t stored as paragraphs - or even words - but as characters which are painted at certain locations on the page. As a result, most of the content semantics are lost when a text or word document is converted to PDF - all the implied text structure is converted into an almost amorphous soup of characters floating on pages.</p><p>As part of building <a href="https://www.filingdb.com/">FilingDB</a>, we’ve extracted text data from tens of thousands of PDF documents. In the process, we have seen how every single assumption we had about how PDF files are structured was proven incorrect. Our mission was particularly difficult as we had to process PDF documents coming from a variety of sources, with wildly different styling, typesetting and presentation choices.</p><p>The list below documents some of the ways PDF files have made it difficult (or even impossible) to extract text contents.</p><h2>PDF read protection</h2><p>You may have come across PDF files which refuse to let you copy their text content. For example, here is what SumatraPDF shows when attempting to copy text from a copy-protected document.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/tCFgGsFAVfhZQqJx.png" alt="copy denied.png"></p><p>Interestingly, the text is already visible, yet the PDF viewer is refusing to populate the clipboard with the highlighted text.</p><p>The way this is implemented is by having several “access permissions” flags, one of which controls whether copying content is allowed. It’s important to keep in mind that this restriction is not enforced by the PDF file - the actual PDF contents are unaffected and it is up to the pdf renderer to honour this flag.</p><p>Needless to say, this offers no real protection against extracting the text out of the PDF, as any reasonably sophisticated PDF handling library will allow the user to either toggle the flags or ignore them.</p><h2>Off-page characters</h2><p>It is not uncommon for PDF files to contain more textual data than is actually displayed on the page. Take this page from the 2010 Nestle annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/rWwxfWHHBcjvZQul.png" alt="Nestle hidden text.png"></p><p>There is more text associated with this page than meets the eye. In particular, the following can be found in the content data associated with this page:</p><blockquote>“KitKat celebrated its 75th anniversary in 2010 but remains young and in touch with trends, having over 2.5 million Facebook fans. It is sold in over 70 countries and enjoys good growth in the developed world and emerging markets, such as the Middle East, India and Russia. Japan is its second biggest market.”</blockquote><p>This text is actually positioned outside the page’s bounding box, so it is not displayed by most PDF viewers, but the data is there and will appear when programmatically extracting the text.</p><p>This occasionally happens due to last minute decisions to remove or replace text during the type setting process.</p><h2>Small / invisible characters on page</h2><p>PDFs occasionally introduce very small or hidden text on the page. For example, here is a page from the Nestle 2012 annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/kqduhxcugDRKTbDC.png" alt="hidden characters.png"></p><p>The page contains small white text on white background with the following contents:</p><blockquote>​“Wyeth Nutrition logo Identity Guidance to markets</blockquote><blockquote>Vevey Octobre 2012 RCC/CI&amp;D”</blockquote><p>This is sometimes done for the benefit of accessibility, similar to how the alt attribute is used in HTML.</p><h2>​Too many spaces</h2><p>Sometimes PDFs include extra spaces between letters in a word. This is most likely done for kerning purposes. (“Kerning” is the process of adjusting distances between characters during the type setting process)</p><p><strong>Example</strong>: the 2013 Hikma Pharma annual report contains the following text:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/LNAUhbShXUkPbOhc.png" alt="an_excellent.PNG"></p><p>Copying the text gives:</p><blockquote>“ch a i r m a n ' s s tat em en t”</blockquote><p>Reconstructing the original text is a difficult problem to solve generally. Our most successful approach has been applying OCR techniques.</p><h2>Not enough spaces</h2><p>Sometimes PDFs do not contain spaces or replace them with a different character.</p><p><strong>Example 1</strong>: The following extract from the 2017 SEB annual report.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/byRVQrWFscgwqUbM.png" alt="global trends.PNG"></p><p>The extracted text shows:</p><blockquote>“Tenyearsafterthefinancialcrisisstarted”</blockquote><p><strong>Example 2</strong>: The 2013 Eurobank annual report shows the following</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/cNjRRWVALUGfSnRl.png" alt="eurobank.PNG"></p><p>Extracting the text gives:</p><blockquote>“On_April_7,_2013,_the_competent_authorities”</blockquote><p>Again, our most successful solution was to run OCR on these pages.</p><h2>Embedded fonts</h2><p>PDF font handling is complex to say the least. To understand how PDF files store text data we must first know about glyphs, glyph names, fonts.</p><ul><li>A glyph is a set of instructions describing how to draw a symbol or character.</li><li>A glyph name is the name associated with that glyph. For example “trademark” for the “™” glyph and “a” for the “a” glyph.</li><li>Fonts are lists of glyphs with associated glyph names. For example, most fonts have a glyph that most humans would recognize as the letter “a”, with different fonts showing various ways of drawing that letter.</li></ul><p>In a PDF, the characters are stored as numbers, called “codepoints”. To decide what to draw on the screen, a renderer has to go:</p><p><code>codepoint -&gt; glyph name -&gt; glyph</code></p><p>For example, a PDF document can contain codepoint 116, which it maps into the glyph name “<code>t</code>” which, in turn, maps into the glyph describing how to draw “<code>t</code>” on the screen.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/boPNiRoKrNIlOHHD.png" alt="unicode glyphs.png"></p><p>Now, most PDF files use a standard codepoint encoding. A codepoint encoding is a set of rules that assign meaning to the codepoints themselves. For example:</p><ul><li>ASCII and Unicode both use codepoint 116 to represent the letter “<code>t</code>”.</li><li>Unicode maps codepoint 9786 to “<code>white smiley face</code>”, rendered as ☺, whereas ASCII is not defined at that codepoint. </li></ul><p>However, PDF documents occasionally use their own custom encoding together with custom fonts. It might seem strange, but a document can use codepoint 1 to represent the letter “<code>t</code>”. It will map codepoint 1 into the glyph name “<code>c1</code>”, which will map into a glyph describing how to draw the letter “<code>t</code>”.</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/oLGIEmjOegjUtsiQ.png" alt="custom glyphs.png"></p><p>While for a human the end result looks the same, a machine will get confused by the codepoints it is seeing. If the codepoints do not follow a standard encoding, then it is virtually impossible to programmatically know what codepoints 1, 2 and 3 represent.</p><p>Why would a PDF document contain nonstandard fonts and encodings?</p><ul><li>One reason is to make text extraction more difficult.</li><li>Another is the use of subfonts. Most fonts contain glyphs for a very large number of codepoints and a pdf might only use a subset of these. To save space, a PDF creator can strip away all unneeded glyphs and create a compact subfont which will most likely use a non-standard encoding.</li></ul><p>One workaround is to extract the font glyphs from the document, run them through OCR software and build the map from font glyph to unicode. This then lets you translate from the font-specific encoding to the unicode encoding e.g: codepoint 1 is mapped to name “<code>c1</code>” which, based on looking at the glyph, should be a “<code>t</code>”, which is unicode codepoint 116.</p><p>The encoding map that you’ve just generated, the one going from 1 to 116, is called a ToUnicode map in the PDF standard. PDF documents can provide their own ToUnicode map, but it’s optional and many do not.</p><h2>Word and paragraph detection</h2><p>Reconstructing paragraphs and even words from the amorphous character soup of PDF files is a difficult task.</p><p>The PDF document provides a list of characters on a page and it is up to the consumer to identify words and paragraphs. Humans are naturally effective at doing this as reading is a widespread skill.</p><p>The common approach is to have a grouping or clustering algorithm which compares letter sizes, positions and alignments in order to determine what is a word/paragraph.</p><p>Naive implementations can easily have complexity larger than O(n²), resulting in long processing times on busy pages.</p><h2>Text and paragraph order</h2><p>Deciding on text and paragraph order is difficult on two levels.</p><p>First, sometimes there is no correct answer. While documents with conventional, single column typesetting have a natural order of reading, documents with more adventurous layouts are challenging. As an example, it is not clear if the following inset should appear before, after, or during the article it is placed next to:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/tdNisrVDTpYeRiVU.png" alt="paragraph order.PNG"></p><p>Second, even when the answer is clear to a human, determining robust paragraph order is a very difficult problem to solve, perhaps even AI-hard. This might sound like an extreme statement, however there are cases where the correct paragraph order can only be decided by understanding the text content.</p><p>Consider the following two-columns layout, describing how to prepare a vegetable salad:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/LVpxBZtdQdXIYMfv.png" alt="recipe.png"></p><p>In the western world, a reasonable assumption is that reading is done left to right and top to bottom. So the best we can do without looking at the contents is to reduce the answer to 2 options: A B C D and A C B D.</p><p>By looking at the content, understanding what it is talking about and knowing that vegetables are washed before chopping, we can determine that A C B D is the correct order. Determining this algorithmically is a difficult problem.</p><p>That being said, a “works most times” approach is to rely on the order in which the text is stored inside the PDF document. This usually corresponds to the order the text was inserted at creation time and, for large bodies of text containing multiple paragraphs, they tend to reflect the writer-intended order.</p><h2>Embedded images</h2><p>It is not uncommon for some (or all) of the PDF content to actually be a scan. In these cases, there is no text data to extract directly, so we have to resort to OCR techniques.</p><p>As an example, the Yell 2011 annual report is only available as a document scan:</p><p><img src="https://landen.imgix.net/blog_HFohGeonJNaiykXv/assets/kMKEqcgsWNHNhiXI.png" alt="scan.PNG"></p><h2>Why not OCR all …</h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://filingdb.com/b/pdf-text-extraction">https://filingdb.com/b/pdf-text-extraction</a></em></p>]]>
            </description>
            <link>https://filingdb.com/b/pdf-text-extraction</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460142</guid>
            <pubDate>Sun, 13 Sep 2020 11:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nokia 3310 3G as a podcast player]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24460136">thread link</a>) | @progre
<br/>
September 13, 2020 | http://prog.re/blog/2020-09-13.html | <a href="https://web.archive.org/web/*/http://prog.re/blog/2020-09-13.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<h2>TLDR</h2>
<p><del>The Nokia 3310 3G is a</del> <em>Some versions</em> of the Nokia 3310 3G works as a descent podcast player, but you have to manage
your podcasts on a real computer.</p>
<h2>The story about why I bought candy bar feature phone in 2020</h2>
<p>Nokia 3310 3G is a feature phone with at least a design
heritage from the much loved Nokia 3310 of the late nineties.
A feature phone in 2020 is maybe not as strange as it might seem.
While the smart-phones are getting ever more advanced, there is also
a counter trend of digital decluttering.</p>
<p>I used to love my smartphone. I was on reddit (back when the mobile website worked)
and youtube all the time on my phone. I use it as a music player while I'm doing kitchen stuff.</p>
<p>But the main use was as a podcast player. Pre-corona I had a commute of
about an hour in each direction (bike + bus). I spent most of the bike time
with podcasts in my ear (the bus time was spent on hobby programming projects).</p>
<p>In January of 2020 I went on paternal leave and the podcast time picked up
significantly as I spent the days lugging around my sleeping then 7 months old boy
while walking the 8 months old lab. I would get about 10 hours of battery time out of
my phone, a 2016 model of Samsung A3. Now, clearly the battery had seen better
days. And it was never a high end phone to begin with. But 10 hours battery time
was getting to be a stress factor.</p>
<p>The thing is I sort of have to have a smartphone. Swish payments is one factor.
Most things that used to be actual currency transactions is Swish payments now.
Buy meat from the cattle farmer? Swish. Buy honey from the beekeeper? Swish. Buy socks
to support your coworkers kids soccer team? Swish. And Swish is available on phones only.
The chromebook that I use for mostly everything can run Android apps but the Swish app
refuses to install on a non phone device.</p>
<p>Another factor is BankID. BankID used to be only a bank issued smart card and a special
little card reader. You would stick the card into a slot in the reader and enter your pin
on the readers keypad. To log into you bank or to a government service you would get a 9 digit
code from the website that you would enter into the reader. The BankID reader would then display
a 6 digit answer code that you would enter into the website and the BankID system would then
guarantee your identity to the bank or government service. But then Mobile Bank Id showed up.
It's a smartphone app that does the same thing except the code-answer code exchange is done
automatically without user interaction now. And lots of websites are starting to retire
the old reader way identifying yourself, leaving Mobile BankID with the only option.</p>
<p>Being on paternal leave I did not have the money for a brand new smartphone, other than one
really low end one. It was also clear to me that it was the podcast consumption that was eating
up my battery. The days that I didn't listen to podcast I would get 24 hour of battery or more.
I'm not sure why podcasts in particular are so hard on the battery, it seemed that about equal
time on Spotify would not drain it nearly as much. I suspect that the fact that the podcast files
are stored on a external SD card has something to do with it.</p>
<p>I started looking at buying dedicated MP3 player. I know from buying an mp3 player for my oldest
daughter that the cheap ones are shit for podcasts and audio books. They reset the play list when
you turn them off and there is no way to have them turned on all the time. They power down when
taking a charge. San-disk still makes an mp3 player that are good for podcast and audio books.
"Resume function" is the keyword to look for. Roxcore also has one (I got one for my daughter when
the <em>really</em> cheap one turned our to be shit).</p>
<p>But then I saw the Nokia 3310 phones. At 600 SEK it's about the same price as a Roxcore mp3 player.
So I started to think I would get one and use it as an mp3 player <em>and</em> have it double as a backup
phone in case my smartphone had drained it's battery. But I was a bit hesitant, because I couldn't get
good information on weather the 3310 did the resume thing or not.</p>
<p>Eventually I bought one anyway. And I bought a 32 GB micro SD for it to store podcasts.
The 3310 has apps but no app store. You supposedly <em>can</em> download java apps for the Java Micro
framework or whatever its called and run them on the phone. But I haven't bothered. The phone has a
music player that picks up any mp3 file stored in the "Music" folder on the SD card, or the phone itself.
The music player really likes those mp3 tags for sorting the music by artist and albums, so it's not ideal
for podcasts. As a last ditch it sorts the files by name, so it kind of works out anyway. And yes, it does
"resume". Even if you exit the music player app it resumes where you stopped. And I get 4 to 5 days of battery
time even with rather heavy use. My old Samsung spends most of it's time in my bag now, and when not used, that
thing has pretty fantastic battery time too.</p>
<p>I use GPodder on windows to manage podcast downloads as the phone cant handle downloads.
It's pretty OK. I don't use the sync feature though, I just let it download everything,
and then I pick and choose what to transfer to the phone.</p>
<h2>Addendum</h2>
<p>I got a mail from <a href="http://ibawizard.net/">Jakub</a> where he wondered how I got the "resume" function
to work. He also has a 3310 (model of 2018), and apparently <em>his</em> phone does not resume anything,
but instead resets the player even on "stop". My phone has software version 30.0.0.17.03 (no build date), his phone
has software version V11.02.11, build date 2017-04-26. You can get the software version by dialing *#0000#
Since the version is completely differently formatted, I suspect that it's a different OS altogether.</p>
<p>So be careful I guess, some phones with earlier software may not work as a podcast player. My advice is do buy
from a bricks-and-mortar store and check the software version before you give them your money.</p>
    </article></div>]]>
            </description>
            <link>http://prog.re/blog/2020-09-13.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24460136</guid>
            <pubDate>Sun, 13 Sep 2020 11:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jugaad, an Indian Delivery Methodology]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24459888">thread link</a>) | @ggeorgovassilis
<br/>
September 13, 2020 | https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/ | <a href="https://web.archive.org/web/*/https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2>Introduction</h2>



<p>Jugaad is an attitude towards delivery which originated in India and consists of three simple tenets:</p>



<ul><li>Humility: use whatever works without prejudice</li><li>Openness: keep your options open</li><li>Frugality: small expenses keep regrets small</li></ul>



<p>Jugaad is agility taken to the extreme and most suitable for projects with a high degree of change, risk and uncertainty. Nothing demonstrates the essence of jugaad better than the homonymous improvised vehicles built in India. All essential mechanical parts lay open and are easily accessible instead of being enclosed in casings. The vehicle can be assembled from commonly available, repurposed parts. It can be customised and extended to fit a variety of personal and professional needs, workloads and environments. The choice of parts can adapt the jugaad vehicle to different types of terrain, usage, fuel and availability of parts.</p>



<figure><img data-attachment-id="1737" data-permalink="https://blog.georgovassilis.com/olympus-digital-camera/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg" data-orig-size="1024,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.9&quot;,&quot;credit&quot;:&quot;Picasa 2.0&quot;,&quot;camera&quot;:&quot;X100,D540Z,C310Z&quot;,&quot;caption&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;created_timestamp&quot;:&quot;-62169984000&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.8&quot;,&quot;iso&quot;:&quot;70&quot;,&quot;shutter_speed&quot;:&quot;0.003125&quot;,&quot;title&quot;:&quot;OLYMPUS DIGITAL CAMERA&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="OLYMPUS DIGITAL CAMERA" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=1024" src="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=1024" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg 1024w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=300 300w, https://georgovassilis.files.wordpress.com/2020/09/jugaad.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>By Sanjaykattimani at English Wikipedia – Transferred from en.wikipedia to Commons by Liftarn using CommonsHelper., Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=11937421" rel="nofollow">https://commons.wikimedia.org/w/index.php?curid=11937421</a></figcaption></figure>



<h2>Disclaimer</h2>



<p>This post is not the result of studying literature, most of which seems to have been written around the peek of the jugaad hype in 2010. It rather distils the experience of a decade working with delivery teams in India, what I learned from their approach to delivery and from being immersed in Indian corporate culture. Through large parts of this post it may seem that I advocate the adoption of jugaad and the abolition of other agile methods; the opposite is true – I will try to make the point that the wholistic approach of jugaad to solution design should be paired with the tactical discipline of a framework like agile or XP.</p>



<h2>The tenets work together</h2>



<p>The three tenets (Humility, Openness, Frugality) complement and contradict each other in a beautiful way: Humility <em>generates</em> options for a solution, openness <em>guides</em> and <em>combines</em> them and frugality <em>eliminates</em> them. Only solutions adhering to all three tenets are built in the jugaad spirit.</p>



<figure><img data-attachment-id="1741" data-permalink="https://blog.georgovassilis.com/options/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/options.png" data-orig-size="607,165" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="options" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=607" src="https://georgovassilis.files.wordpress.com/2020/09/options.png?w=607" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/options.png 607w, https://georgovassilis.files.wordpress.com/2020/09/options.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/options.png?w=300 300w" sizes="(max-width: 607px) 100vw, 607px"><figcaption>Tenets refine options</figcaption></figure>



<h2>Humility: use whatever works without prejudice</h2>



<p>Delivery methods like Waterfall, Scrum and XP wage religious wars over definitions (eg. what is the right sprint length?), processes (eg. degree of upfront planning), skills (eg. which framework should we use) and tools (eg. Maven or Gradle) all of which are more or less derivatives of adherence to a method. Jugaad replaces those definitions, processes, skills and tools with a central guidance: <em>be conscious about the shortcuts taken</em> with respect to the two other tenets. Jugaad frequently comes with a high degree of “out of the box” thinking and requires, for it to work, the humility to let go of technical and methodological preconceptions about what is the “appropriate” way and focus solely on the result.</p>



<p>Humility is the starting point in jugaad in that using “whatever works” generates a plethora of options. So how do we choose amongst these options? That is where Openness takes over.</p>



<h2>Openness: keep your options open</h2>



<p>The ostensible carelessness with which jugaad approaches delivery is built on the solid foundation of Openness. Whatever we build should be easy to extend, change or reverse. Openness often lacks elegance and conciseness, the inner workings of things are exposed, there is not much polish and one can see the parts a solution is made of – not to mention the security concerns arising from such solution. Just think of the jugaad vehicle we talked about earlier if you need a mental picture. But those trade-offs enable easily modifiable solutions and are exactly that: conscious trade-offs, not shortcomings. A solution which is open to change is a solid project or product foundation as it can adapt to unforeseen changes and doesn’t require much up-front design. Openness takes Humility’s options and guides them into coherent patterns. Not all options will form a good solution and not all combinations of options will work; Openness tells us which of them <em>might</em> work without losing an arm and a leg in the process of finding out.</p>



<h2>Frugality: small expenses keep regrets small</h2>



<p>Frugality is about risk management: reducing upfront costs <em>now </em>allows exploring more value propositions and solution approaches <em>now</em> while spending resources <em>later</em> on improving the solution. A low cost incurred early jeopardises a project less than a large cost incurred at the same time, especially if whatever that cost bought us turned out to be the wrong thing. Frugality is a holistic view on the patterns guided by Openness – it takes into consideration synergies between options and maximises value, both in terms of business value created for the solution (how many of the requirements were implemented at what effort) as well as value added to the project delivery (how much delivery and quality was improved, what was learned etc).</p>



<h2>Comparison by example</h2>



<p>Jugaad is illustrated best with a couple of examples which contrast traditional, “proper” design with improvised jugaad design.</p>



<h3>Example: receipt system</h3>



<p>Design a system that generates, stores and sends receipts via email to customers. Customer support should be able to retrieve receipts.</p>



<p>The traditional, “proper” solution:  we program a system that stores receipts in a relational database, generates receipt PDFs, stores those PDFs in the database, sends the PDFs to customers. We program a web interface for use by customer service which can query the database for receipts.</p>



<figure><img data-attachment-id="1742" data-permalink="https://blog.georgovassilis.com/traditional-solution/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png" data-orig-size="538,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="traditional-solution" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=538" src="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=538" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png 538w, https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/traditional-solution.png?w=300 300w" sizes="(max-width: 538px) 100vw, 538px"><figcaption>The traditional solution has many custom built components</figcaption></figure>



<p>The jugaad-engineered solution: we program a system that generates HTML receipts, emails them to customers and BCCs a customer support email account with the same receipt. Customer support can use their email client to retrieve receipts. These components are either packaged and require no development effort (Customer support E-Mail client, E-Mail server), there a only few components and they are easy to implement.</p>



<figure><img data-attachment-id="1744" data-permalink="https://blog.georgovassilis.com/jugaad-solution/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png" data-orig-size="538,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="jugaad-solution" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=300" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=538" src="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=538" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png 538w, https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=150 150w, https://georgovassilis.files.wordpress.com/2020/09/jugaad-solution.png?w=300 300w" sizes="(max-width: 538px) 100vw, 538px"><figcaption>The jugaad solution has few, mostly packaged components</figcaption></figure>



<p>Let’s evaluate the jugaad-engineered solution against jugaad’s tenets and compare it with the “traditional” solution.</p>



<p>Humility: the design relies on packaged components which probably already exist and it only minimally invades the existing IT landscape. It reuses high quality packaged solutions (e-mail server, e-mail client) which may already exist in the organisation and reduces implementation tasks to e-mail server and e-mail client configurations. The traditional delivery method places several requirements on how the solution is built: it mandates formal APIs, probably a particular technology platform, a pre-defined method according to which components are structured (eg. SOLID), technical documentation and thorough test automation long before it is clear that the project will make it into production, but nevertheless increasing conceptional and real complexity of the solution and the delivery process and requiring an increased skill set for project participants. </p>



<p>Openness: the e-mail protocols between the application, e-mail servers and e-mail clients are well understood and extensible. Using E-Mail clients requires low to no training and the IT department probably maintains them already. The components themselves can be substituted without affecting much the rest of the solution; eg. a new field can be added to future receipts without modifying already issued receipts. Because many components can be operated by human agents (the e-mail server and e-mail clients), many new features and workarounds can be implemented as manual processes before coding and automating them into software. Since not much effort has been put at the initial stage into upfront design there isn’t much effort wasted when requirements change and implementations follow.</p>



<p>Frugality: the use of packaged components, especially when they are already familiar, reduces implementation effort and speeds up delivery at the cost of the finished product showing incongruities where different components interface.  New requirements needing larger changes can be implemented by exchanging existing components for components better fitting the requirements or even rewriting them from scratch, if needed. In many cases the early progress made thanks to the low initial effort should more than make up for the higher, later cost. The traditional solution contrasts badly with jugaad in terms of effort. For example, it will mandate a particular API design such as a REST API for the receipt generator and receipt retrieval or even a REST API between the receipt generator and the email server, because… principles. Technical documentation will be written for the components long before it is clear that the project will ever go live, not considering that any effort spent on non-value adding features jeopardises a go-live. And last not least unit tests will be written to achieve an arbitrarily agreed upon test coverage before it is clear that they generate business value eg. by catching regressions. The jugaad-engineered solution will produce formal APIs, documentation and test automation when their added value outweighs the implementation effort.</p>



<h2>Contrast with agile</h2>



<p>Jugaad has no processes like Scrum or XP. It talks about the values worth striving for. It doesn’t talk about velocity or quality; even the focus on low cost introduces the discipline to achieving openness, thus being able to revisit a previously built solution. Agile highlights <em>reactiveness</em>, it’s main point being the ability to react to unforeseen changes, but it uses a predefined process such as Scrum or Kanban. The process must adapt to organisational changes or changing skill sets. Jugaad does not dictate any delivery process, so in a way it is orthogonal to existing agile practices. By adding formalised steps to it, a mature jugaad practice may evolve into Scrum or Kanban if that seems useful.</p>



<p>But jugaad is not about agile without …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/">https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/</a></em></p>]]>
            </description>
            <link>https://blog.georgovassilis.com/2020/09/13/draft-jugaad-takes-agile-to-the-extreme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24459888</guid>
            <pubDate>Sun, 13 Sep 2020 10:31:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Bloom's two sigma problem: A systematic review]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24458662">thread link</a>) | @bschne
<br/>
September 12, 2020 | https://nintil.com/bloom-sigma/ | <a href="https://web.archive.org/web/*/https://nintil.com/bloom-sigma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>One of the <a href="https://patrickcollison.com/questions">Collison questions</a> is</p>
<blockquote>
<p><strong>Is Bloom's "Two Sigma" phenomenon real? If so, what do we do about it?</strong></p>
<p>Educational psychologist <a href="https://en.wikipedia.org/wiki/Benjamin_Bloom">Benjamin Bloom</a> <a href="http://web.mit.edu/5.95/readings/bloom-two-sigma.pdf">found</a> that one-on-one tutoring using <a href="https://en.wikipedia.org/wiki/Mastery_learning">mastery learning</a> led to a <em>two sigma</em>(!) improvement in student performance. The results were replicated. He asks in his paper that identified the "2 Sigma Problem": how do we achieve these results in conditions more practical (i.e., more scalable) than one-to-one tutoring?</p>
<p>In a related vein, <a href="https://journals.sagepub.com/doi/abs/10.3102/0034654317751919">this large-scale meta-analysis</a> shows large (&gt;0.5 <a href="https://en.wikiversity.org/wiki/Cohen%27s_d">Cohen's d</a>) effects from direct instruction using mastery learning. "Yet, despite the very large body of research supporting its effectiveness, DI has not been widely embraced or implemented."</p>
</blockquote>
<hr>
<p>Answering the question requires first to explain what <em>Direct Instruction</em> and <em>Mastery Learning</em> mean.</p>
<h3 id="scope-of-the-present-article">Scope of the present article</h3>
<p>This article is concerned with a general study of Bloom's two sigma problem, which in turn involves an examination of an educational method, mastery learning, and tutoring. I have also included a review of software-based tutoring. Later on I look at educational research in general, spaced repetition, and deliberate practice, as these seem closely related to the core topics of this review for reasons that will be obvious after reading through it.</p>
<p>I am only concerned here with student performance in tests, not with other putative benefits from education; I don't look in detail at what keeps students motivated, what makes them feel well, what makes them more creative, or better citizens.. I could have looked at longer term measures of success (e.g. income later on in life) but I couldn't find such studies.</p>
<p>As a general note, when discussing effect sizes here,  unless otherwise noted, the effect sizes are of the intervention being discussed vs business as usual, using whatever educational method the school was using.</p>
<h3 id="definitions">Definitions</h3>
<h4 id="the-two-sigma-problem">The Two Sigma problem</h4>
<p>Benjamin Bloom, decades ago, <a href="http://web.mit.edu/5.95/www/readings/bloom-two-sigma.pdf">found</a> that individual tutoring raised student's performance relative to a baseline class by two standard deviations, which is a MASSIVE<sup><a href="#massive">1</a></sup> effect. As 1:1 tutoring is very expensive, he wondered if there are approaches that approximate such an effect that were applicable for larger classrooms. Finding such a method was the "two sigma problem". And Mastery Learning seemed to be the promising way to solve it.</p>
<p><img src="https://nintil.com/images/2019-07-03-bloom-sigma/bloom.png" alt="Image result for bloom two sigma"></p>
<h4 id="direct-instruction">Direct Instruction</h4>
<p>From the meta-analysis cited above, Direct Instruction is a teaching program originally developed by Siegfried Engelmann in the 60s that assumes that any student can learn any given piece of material, and this will happen when </p>
<blockquote>
<p>(a) they have mastered prerequisite knowledge and skills and (b) the instruction is unambiguous. </p>
</blockquote>
<p>This doesn't sound that helpful; fortunately the <a href="https://www.nifdi.org/what-is-di/basic-philosophy.html">National Institute for Direct Instruction</a> has a bit more information. </p>
<blockquote>
<p>There are four main features of DI that ensure students learn faster and more efficiently than any other program or technique available:</p>
<p><strong>Students are placed in instruction at their skill level.</strong> 
When students begin the program, each student is tested to find out which skills they have already mastered and which ones they need to work on. From this, students are grouped together with other students needing to work on the same skills. These groups are organized by the level of the program that is appropriate for students, rather than the grade level the students are in.</p>
<p><strong>The program’s structure is designed to ensure mastery of the content.</strong> 
The program is organized so that skills are introduced gradually, giving children a chance to learn those skills and apply them before being required to learn another new set of skills. Only 10% of each lesson is new material. The remaining 90% of each lesson’s content is review and application of skills students have already learned but need practice with in order to master. Skills and concepts are taught in isolation and then integrated with other skills into more sophisticated, higher-level applications. All details of instruction are controlled to minimize the chance of students' misinterpreting the information being taught and to maximize the reinforcing effect of instruction.</p>
<p><strong>Instruction is modified to accommodate each student’s rate of learning.</strong> 
A particularly wonderful part about DI is that students are retaught or accelerated at the rate at which they learn. If they need more practice with a specific skill, teachers can provide the additional instruction within the program to ensure students master the skill. Conversely, if a student is easily acquiring the new skills and needs to advance to the next level, students can be moved to a new placement so that they may continue adding to the skills they already possess.</p>
<p><strong>Programs are field tested and revised before publication.</strong> 
DI programs are very unique in the way they are written and revised before publication. All DI programs are field tested with real students and revised based on those tests before they are ever published. This means that the program your student is receiving has already been proven to work.</p>
</blockquote>
<p>Direct Instruction is  <a href="https://en.wikipedia.org/wiki/Scripted_teaching">highly scripted</a>, <a href="https://en.wikibooks.org/wiki/Contemporary_Educational_Psychology/Chapter_8:_Instructional_Strategies/Mastery_Learning"><em>including even the words they should speak while teaching</em></a>.</p>
<p>Note that Direct Instruction (titlecase) is not the same as <a href="https://www.nifdi.org/what-is-di/di-vs-di">direct instruction</a> (lowercase), there are various programmes around that have "direct instruction" in the name, like <a href="https://dataworks-ed.com/blog/2014/07/direct-instruction-di-vs-explicit-direct-instruction-edi/">Explicit Direct Instruction</a> . Unless otherwise noted, we'll be talking about Direct Instruction in this review. Both are teacher-centered methods in that the teacher is seen as the one who is transmitting knowledge to the student rather than, say, the student being aided by the teacher in a quest to discover knowledge. Direct Instruction is regulated by the National Institute for Direct Instruction, as mentioned above, while direct instruction is not.</p>
<h4 id="mastery-learning">Mastery learning</h4>
<p>Mastery learning (ML) is not the same as Direct Instruction, but ML <em>is a component of Direct Instruction</em>. It is also one of the methods Bloom originally looked at, so we also examine ML in this review. One key difference is that ML does not called for scripted lessons, while DI requires them.</p>
<p>The key principle of ML is simply to force students to master a lesson before moving on to the next one. At the end of each lesson, on a monthly or weekly basis, students' knowledge is tested. Those students that do not pass are given remediation classes, and they have to re-sit the test until they master it. This can be done in a group setting, as with Bloom's original Learning for Mastery (LFM) programme, or individually, as in Keller's Personalized System of Instruction (PSI), where each student advances as their own pace.</p>
<h3 id="summary">Summary</h3>
<ul>
<li>The literatures examined here are full of small sample, non-randomized trials, and highly heterogeneous results.</li>
<li>Tutoring in general, most likely, does not reach the 2-sigma level that Bloom suggested. Likewise, it's unlikely that mastery learning provides a 1-sigma improvement.
<ul>
<li>But high quality tutors, and high quality software are likely able to reach a 2-sigma improvement and beyond. </li>
</ul>
</li>
<li>All the methods (mastery learning, direct instruction, tutoring, software tutoring, deliberate practice, and spaced repetition) studied in this essay are found to work to various degrees, outlined below.</li>
<li>This essay covers many kinds of subjects being taught, and likewise many groups (special education vs regular schools, college vs K-12). The effect sizes reported here are averages that serve as general guidance.</li>
<li>The methods studied tend to be more effective for lower skilled students relative to the rest.</li>
<li>The methods studied work at all levels of education, with the exception of direct instruction: There is no evidence to judge its effectiveness at the college level.</li>
<li>The methods work substantially better when clear objectives and facts to be learned are set. There is little evidence of <a href="https://www.econlib.org/archives/2012/08/low_transfer_of.html">learning transfer</a>: Practicing or studying X subject does not improve much performance outside of X.</li>
<li>There is some suggestive evidence that the underlying reasons these methods work are increased and repeated exposure to the material, the <a href="https://en.wikipedia.org/wiki/Testing_effect">testing effect</a>, and fine-grained feedback on performance in the case of tutoring.</li>
<li>Long term studies tend to find evidence of a fade-out effect, effect sizes decrease over time. This is likely due to the skills being learned not being practiced.</li>
</ul>
<h4 id="effect-sizes">Effect sizes</h4>
<p>Assessing if an effect size is meaningful may be hard. A common way of doing so is as <a href="https://en.wikipedia.org/wiki/Effect_size">follows</a>:</p>
<table><thead><tr><th><em>Effect size</em></th><th><em>d</em></th></tr></thead><tbody>
<tr><td>Very small</td><td>0.01</td></tr>
<tr><td>Small</td><td>0.20</td></tr>
<tr><td>Medium</td><td>0.50</td></tr>
<tr><td>Large</td><td>0.80</td></tr>
<tr><td>Very large</td><td>1.20</td></tr>
<tr><td>Huge</td><td>2.0</td></tr>
</tbody></table>
<p>However, one should be able to finetune the descriptive language used, by using a domain-specific reference. In this case, the average effect on performance from one year of schooling  (going from 5th to 6th grade) is d=0.26 for reading performance, and the average effect from 141 large scale RCTs of educational interventions is 0.06, from  Hugues &amp; Matthew (<a href="http://eprints.whiterose.ac.uk/141754/">2019</a>). Because of this, I will be using a scale adapted from Kraft (<a href="https://scholar.harvard.edu/files/mkraft/files/kraft_2018_interpreting_effect_sizes.pdf">2018</a>):</p>
<table><thead><tr><th><em>Effect size</em> (E.S.)</th><th><em>d</em></th></tr></thead><tbody>
<tr><td>Small</td><td>&lt;0.05</td></tr>
<tr><td>Medium</td><td>0.05-0.2</td></tr>
<tr><td>Large</td><td>0.2-0.5</td></tr>
<tr><td>Very large</td><td>0.5-1</td></tr>
<tr><td>Extremely large</td><td>1-1.5</td></tr>
<tr><td>Huge</td><td>&gt;1.5</td></tr>
</tbody></table>
<p>With that in mind, here is the summary of the main results, along with the best studies I could find to back up the claims. For comparison, I include Bloom's findings:</p>
<table><thead><tr><th><em>Method</em></th><th>E.S. (general)</th><th>E.S. (disadvantaged)</th><th>E.S. (Bloom)</th><th>Key references</th></tr></thead><tbody>
<tr><td>Tutoring*</td><td>Very large</td><td>-</td><td>Huge</td><td>VanLehn (<a href="http://www.public.asu.edu/%7Ekvanlehn/Stringent/PDF/EffectivenessOfTutoring_Vanlehn.pdf">2011</a>)</td></tr>
<tr><td>Software-based tutoring (High quality)*</td><td>Very large</td><td>-</td><td>-</td><td>VanLehn (<a href="http://www.public.asu.edu/%7Ekvanlehn/Stringent/PDF/EffectivenessOfTutoring_Vanlehn.pdf">2011</a>), Kulik &amp; <a href="https://journals.sagepub.com/doi/abs/10.3102/0034654315581420">Fletcher (2016)</a></td></tr>
<tr><td>Mastery learning**</td><td>Medium</td><td>Large</td><td>Extremely large</td><td>Kulik et al. (<a href="http://www.uky.edu/%7Egmswan3/575/kulik_kulik_Bangert-Drowns_1990.pdf">1990</a>), Slavin (<a href="https://journals.sagepub.com/doi/10.3102/00346543057002175">1987</a>)</td></tr>
<tr><td>Direct Instruction**</td><td>Medium</td><td>Large</td><td>-</td><td>Borman et al. (<a href="https://journals.sagepub.com/doi/10.3102/00346543073002125">2003</a>), Stockard et al. (<a href="https://journals.sagepub.com/doi/abs/10.3102/0034654317751919">2018</a>)</td></tr>
</tbody></table>
<p>* With really good tutors and really good software, the effect size can indeed be Huge.</p>
<p>** When considering narrow knowledge of a series of facts, or basic skills taught at the elementary level, the effects of ML and DI can be Large for the general population and Extremely Large for disadvantaged students. </p>
<h3 id="the-evidence-behind-direct-instruction">The evidence behind direct instruction</h3>
<p>The meta-analysis I start the article with has a literature review, noting that all the previous …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/bloom-sigma/">https://nintil.com/bloom-sigma/</a></em></p>]]>
            </description>
            <link>https://nintil.com/bloom-sigma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458662</guid>
            <pubDate>Sun, 13 Sep 2020 05:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brutality of Life Reading List]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24458522">thread link</a>) | @exolymph
<br/>
September 12, 2020 | https://www.sonyasupposedly.com/brutality-books/ | <a href="https://web.archive.org/web/*/https://www.sonyasupposedly.com/brutality-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://www.sonyasupposedly.com/content/images/size/w300/2020/09/DP823443.jpg 300w,
                                https://www.sonyasupposedly.com/content/images/size/w600/2020/09/DP823443.jpg 600w,
                                https://www.sonyasupposedly.com/content/images/size/w1200/2020/09/DP823443.jpg 1000w,
                                https://www.sonyasupposedly.com/content/images/size/w2000/2020/09/DP823443.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://www.sonyasupposedly.com/content/images/size/w2000/2020/09/DP823443.jpg" alt="Brutality of Life Reading List (12 Books)">
                </figure>
                <section>
                    <div>
                        <p>Earlier this year I summed up the perpetual utilitarian lament:</p><!--kg-card-begin: html--><blockquote darkmode="" data-title="All%20you%20can%20do%20is%20as%20much%20as%20you%20can." data-author="@sonyasupposedly" cite="https://www.sonyasupposedly.com/against-fatalism/">
                      <p>Despite <a href="https://rootsofprogress.org/smart-rich-and-free" target="_blank" rel="noopener">nigh-inestimable progress</a>, the world is pervaded by suffering. An unimaginable amount of suffering. Trying to comprehend it specifically and thoroughly makes me feel sick. It is staggering, the magnitude of pain.</p><p>At times the futility of <em>ever fixing this</em> breaks me. How Sisyphean it is, the prospect of searching interminably for new solutions to <a href="http://web.archive.org/web/20140801022058/http://slatestarcodex.com/2014/07/30/meditations-on-moloch/" target="_blank" rel="noopener">coordination problems</a>! I lament that positive-sum possibilities can barely be glimpsed through a tangle of innumerable constraints.</p><p>The fact is... it's true. There is tremendous suffering, beyond my ability to convey and beyond the auspices of the word "fix." Nothing can be said, no conclusion can be reached, that will negate that. It is what it is.</p><p>Reality does not have a human value system. The most you can say about the association between the two is that human value systems are figments within reality, gesturing at its structure. Sometimes the gesture is 🙏, sometimes it's 🖕, and everything in between.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>I'm not over it, and probably never will be. It's not that I'm inordinately empathetic or anything, but I share the typical concern for people's wellbeing. In particular, watching someone close to me Go Through Some Shit is gut-wrenching (again, as it is for most of us). And I know that it won't stop! "Life is pain, Highness. Anyone who says differently is selling something." Life is other things too, but it's definitely pain.</p><p>The Problem of Suffering seems like a category error, to borrow / repurpose a framing <a href="https://twitter.com/thesravaka/status/1292953978062475272">from @thesravaka</a>. Suffering <em>is</em>. The Problem of Suffering supposes a fantasy in which it is not, but no clever philosophizing can instantiate that fantasy. We live in the existent world, for which suffering poses no grand problems —&nbsp;that fate belongs to its inhabitants. But whaddaya know, <a href="https://www.gwern.net/Backstop#pain-is-the-only-school-teacher">pain is indispensable to survival</a>.</p><p>It's okay to grieve, I think — perhaps even unavoidable, or inadvisable to avoid. I don't know how I'd get through this <em>year</em> without befriending grief, let alone my whole life, and my experiences of both have been pretty good compared to what others have endured.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">one of the hardest parts of growing up has been letting myself feel the pain</p>— 🎀 sonyasupposedly.com 🤖 (@sonyasupposedly) <a href="https://twitter.com/sonyasupposedly/status/1302469281372749825?ref_src=twsrc%5Etfw">September 6, 2020</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr">I don't wanna feel the pain. it hurts. but that's the thing, it's gonna hurt one way or the other</p>— 🎀 sonyasupposedly.com 🤖 (@sonyasupposedly) <a href="https://twitter.com/sonyasupposedly/status/1302469601519783938?ref_src=twsrc%5Etfw">September 6, 2020</a></blockquote>

</figure><p>I mourn for my illusions —&nbsp;of control, of perfect knowledge... the latter in itself an illusion of control. The most cherished mirages I cry for repeatedly, since they sneak back into my mind to break my heart again. And again.</p><p>I mourn for my fears, for the awful possibility of dreaded outcomes. I mourn for the people I know who are dying, which is all of them, but some much quicker than others.</p><p>There's a lot to let go of, you know? A lot that I can't keep within my grasp. Nor can I pretend to be okay with this state of affairs. Sure, it's okay to <em>not feel okay</em>, but even if it weren't, would that change anything? I would still be appalled by the cruelty of life. I would still struggle with acceptance, despite the relative and objective ease of my circumstances. Likewise, I would still grieve.</p><p>For unnameable reasons I find it therapeutic to examine the facets of pain closely, specifically, and in depth. I want to know how bad it can be. Not firsthand, of course, and thus not with the visceral punch of having learned from experience. Regardless there is understanding to be gained from others' accounts. Would Elie Wiesel have written <em><a href="https://en.wikipedia.org/wiki/Night_(book)">Night</a></em> otherwise? (Look, I'm not above an occasional argument from authority.)</p><p>Sordid agony has always intrigued me — I was that kid reading about serial killers on Wikipedia in the library during high school. (<a href="https://en.wikipedia.org/wiki/Albert_Fish">Albert Fish</a> and the <a href="https://en.wikipedia.org/wiki/Murder_of_Junko_Furuta">torment of poor Junko Furuta</a> are my picks for most awful. We're talking very seriously awful, so click with caution.) These days I scarcely have the stomach for extended revelry in prurient gore, a la <a href="https://en.wikipedia.org/wiki/The_120_Days_of_Sodom">de Sade's work</a> or <a href="https://en.wikipedia.org/wiki/Hogg_(novel)">Samuel Delany's <em>Hogg</em></a>. But witness to profound hardship is available in other forms.</p><p>Lacking a deft resolution to this preamble, I'll just segue to the books that have helped me process [some of] my rage and frustration with, well... the Problem of Suffering. It may not be a problem for the universe, but it sure is a problem for me.</p><p>A few obvious titles were omitted, since flogging a <em>dead</em> horse doesn't comport with the spirit of the list — corpses can't feel any blows! Har har. Fine, I'll be straight with you, what I mean is that I considered recommending more Cormac McCarthy. <em>The Color Purple</em> would be a worthy inclusion. Etc. But I erred on the side of idiosyncrasy.</p><p>All of the following books are harrowing reads (in my opinion) and unlikely to cheer the soul. Steer clear if wallowing would be bad for you!</p><h2 id="fiction">Fiction</h2><p>In order of how strongly I feel about the book being crucial documentation of life's brutality:</p><p><strong><em>Johnny Got His Gun</em> by Dalton Trumbo</strong></p><ul><li><a href="https://amzn.to/3hpl5Q4">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780553274325">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Johnny_Got_His_Gun">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Johnny Got His Gun by Dalton Trumbo" data-author="Phil Mongredien" cite="https://www.theguardian.com/books/2009/aug/16/johnny-got-his-gun-trumbo">
                      <p>After his dugout suffers a direct hit from a German shell in the last days of the Great War, 20-year-old American infantryman Joe Bonham gradually comes to in a French hospital. As his thoughts become more lucid, he realises he has been left deaf, dumb and blind and that all four of his limbs have subsequently been amputated. His face, meanwhile, has been obliterated by the shell and what is left — "a red gash ... with mucus hanging from it" — is now covered by a mask to avoid distressing the nurses.</p>
<p>Despite his injuries, his mind still functions as well as ever, letting him think back to his childhood in small-town Colorado and allowing him to contemplate the full horror of his situation. Joe soon realises he is "the nearest thing to a dead man on Earth ... a dead man with a mind that could think".</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>A quote from the book: "Maybe nothing was real not even himself oh god and wouldn't that be wonderful." Imagine if <em>Slaughterhouse-Five</em> were markedly more grueling.</p><p><strong><em>A Canticle for Leibowitz</em> by Walter M. Miller</strong></p><ul><li><a href="https://amzn.to/2ZAwvKW">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780553273816">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/A_Canticle_for_Leibowitz">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Every%20Book%20I%20Read%20in%202017" data-author="Sonya Mann" cite="https://www.sonyaellenmann.com/2018/01/every-book-i-read-2017.html">
                      A very strong contender for Best Book I Read in 2017. After the nuclear apocalypse, history devours itself like an ouroboros. Science becomes religion becomes science becomes religion. Human nature doesn't improve, but it still has its moments of transcendent goodness.
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>With a little more time and distance, one of the best books that I've read <em>ever</em>.</p><p><strong><em>Bastard Out of Carolina</em> by Dorothy Allison</strong></p><ul><li><a href="https://amzn.to/3ir7xVx">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780452297753">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Bastard_Out_of_Carolina">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Just%20the%20way%20men%20are%3A%20Bastard%20out%20of%20Carolina" data-author="Maureen Freely" cite="https://www.independent.co.uk/arts-entertainment/book-review-just-the-way-men-are-bastard-out-of-carolina-dorothy-allison-flamingo-pounds-599-1481952.html">
                      Although her story has all the components of formulaic dirty realism, there is never any redneck posturing, no luxuriating in colourful bad language or behaviour. When she has a man cause a family crisis by telling his wife 'I wouldn't touch you even if you took a bath in whiskey tonic and put a bag over your head', it's not to glorify or denigrate a 'good ol' boy' but simply to report what he said.
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>A quote from the book: "Family is family, but even love can't keep people from eating at each other." Ain't that the truth.</p><p><strong><em>The Good Earth</em> by Pearl S. Buck</strong></p><ul><li><a href="https://amzn.to/35v8N6p">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780743272933">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/The_Good_Earth">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="The%20Good%20Earth%20by%20Pearl%20S%20Buck%20%5BA%20Review%5D" data-author="@talkabout_books" cite="https://weneedtotalkaboutbooks.com/2018/06/19/the-good-earth-by-pearl-s-buck-a-review/">
<p>I am not one to cry from reading, but I imagine many a reader would when reading of the despair of life with a young family during a famine and of what they witness. There is much more emotional engagement elsewhere in the story, whether it is the despair of poverty; the frustration of the inequities between rich and poor, men and women, workers and freeloaders; the fear of violence and disappointment in the character's choices. [...]</p>
<p>Wang has known nothing other than the hardworking, precarious, life of a peasant. The life within the House of Hwang is as alien to him as the life of a Westerner. He does not consider how different his life might have been if he had been born into privilege. Nor does he realise, since upward financial and social mobility is his dream, how, if he were to succeed, it would change the way he feels about his wife, the way he would raise his sons or the life he would choose to lead. The thought that his sons might grow up in a completely different environment to himself, with personalities, opportunities, ambitions and wants completely foreign to his own would baffle him.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p><strong><em>Outer Dark</em> by Cormac McCarthy</strong></p><ul><li><a href="https://amzn.to/2FB1lvx">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780679728733">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/Outer_Dark">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Outer Dark by Cormac McCarthy" data-author="Kirkus Reviews" cite="https://www.kirkusreviews.com/book-reviews/cormac-mccarthy/outer-dark/">
                      Against a landscape as sparse as the trees on the ridge just yonder, anonymous characters, the ferryman, the snake hunter, the beekeeper, the preacher, pursue an unyielding existence. Only a little more identified here are Culla Holme and Rinthy, his nineteen-year-old sister who has just had (his?) child in a cabin. A day or two later he tells her it has died, while going off with the tinker to leave the child elsewhere (where?). Rinthy as soon as she is strong enough goes on her long search to find the tinker and her child[.]
                      
                      </blockquote>
                      <!--kg-card-end: html--><p><a href="https://www.thesatirist.com/books/outerdark.html">Here's a better review</a> that unfortunately divulges nearly all of the plot details.</p><p><strong><em>The House of God</em> by Samuel Shem</strong> (because of the <a href="http://slatestarcodex.com/2016/11/10/book-review-house-of-god/">Slate Star Codex review</a>)</p><ul><li><a href="https://amzn.to/32rjK7k">Amazon</a> (affiliate link)</li><li><a href="https://www.indiebound.org/book/9780425238097">IndieBound</a></li><li><a href="https://en.wikipedia.org/wiki/The_House_of_God">Wikipedia</a> (spoilers)</li></ul><!--kg-card-begin: html--><blockquote darkmode="" data-title="Book%20Review%3A%20House%20of%20God" data-author="Scott Alexander" cite="https://slatestarcodex.com/2016/11/10/book-review-house-of-god/">
                      The whole thing had a touch of magical realism, which turns out to be exactly the right genre for a story about medicine. Real medicine is absolutely magical realist. It's a series of bizarre occurrences just …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sonyasupposedly.com/brutality-books/">https://www.sonyasupposedly.com/brutality-books/</a></em></p>]]>
            </description>
            <link>https://www.sonyasupposedly.com/brutality-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458522</guid>
            <pubDate>Sun, 13 Sep 2020 05:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Feedback Loop of Productivity]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24458482">thread link</a>) | @root993
<br/>
September 12, 2020 | https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Being productive all the time is not just difficult, it might actually burn you out, but that being said lack of productivity for an extended period of time is dangerous too because it gives the mind an excuse to start looking at all the negative things happening in the world, especially with the global pandemic going on. </p><p>So how does one stay productive consistently? I find that the only way to be productive is through feedback. To be productive you need to receive a small but noticeable reward for attempting to be productive. If that did not make any sense, let me try and explain it with an example.</p><p><strong>Kickstarting the loop</strong></p><p><strong>‍</strong><br></p><p>I wanted to write a piece of content today because I have not written anything in a long period of time. Once this piece is out there on a few social media platforms, I might see a small but noticeable spike in the traffic to my blog which I can confirm from my good friend google analytics. This little spike in traffic is my tiny reward which will kick start a feedback loop.</p><p>Now there is higher likelihood that I will try and write some more content next week because I still remember the feeling of that reward and I want to feel it again, but the difference now is that I have built a tolerance for this reward and the only way I would feel satisfied is if I receive a higher reward which in this case might translate to a higher spike in google analytics.</p><p><strong>Add incremental steps to the loop</strong></p><p><strong>‍</strong><br></p><p>To receive a higher reward I am now motivated to write better quality content which reaches a wider group of audience and what gets even better is if people start engaging with me after reading my post and wish to dwell further into the subject. </p><p>If I can keep this up every week while slightly increasing the quantum of work but also the quantum of reward, eventually it becomes a habit that I can no longer ignore.</p><p><strong>Use the feedback loop for everything</strong></p><p><strong>‍</strong><br></p><p>I build software, so for me the feedback loop translates to building a small software module that does one particular task, run a few tests on it to see if it functions like it should and this will kick start the feedback loop. I feel rewarded that I built one tiny part of a large project which works perfectly and is ready to be integrated with the rest of the project.</p><p>Incremental steps can then be added by combining different modules with each other and making them work together. The loop becomes much stronger once there is an actual visual component to look at and interact with because at this point you have basically created something tangible and the reward you get from that lasts much longer than the smaller rewards.</p><p><strong>Conclusion</strong></p><p><strong>‍</strong><br></p><p>It is entirely possible that I put out this piece of content today and nobody cares. Maybe I do not see any spike in google analytics at all. But the very fact that I managed to write something today and share it a few people who are at the very least likely to give it a read creates a feeling of accomplishment which serves as a small reward to kick start the feedback loop. </p><p>Sometimes the reward is not as great as expected but as long as it is not zero, the loop is strong enough to get you going.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/the-feedback-loop-of-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458482</guid>
            <pubDate>Sun, 13 Sep 2020 04:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Together vs. Alone: Thoughts on building a team]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24458258">thread link</a>) | @grwthckrmstr
<br/>
September 12, 2020 | https://www.preetamnath.com/blog/building-a-team | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-a-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We live in an incredible time in human history where the basic infrastructure for many of us is so good.</p><p>In today’s world it is possible to get ahead and achieve a lot all by yourself. You can be a writer with 1mn readers, a social media star with 1mn followers, or a SaaS business with $1mn in ARR.&nbsp;</p><p>That’s the mindset Sankalp and I both embodied when we first started on our journey. We had faith that just the 2 of us working together towards our shared goal is enough to get us really far.</p><p>Thankfully that faith turned into reality and lead to the success of SuperLemon.</p><h3>Challenging our beliefs</h3><p>But any great mindset or philosophy is only as great as the people who practice it, and people are always evolving and getting better. Mindset and philosophy evolves too.</p><p>The people in our lives who believed in us and wanted us to do even better challenged us on our beliefs of doing things amongst just the 2 of us.</p><p>One of them said - we are setting small goals, because we are afraid of hiring. If we had the confidence that we can put together a great team, we would think bigger and set higher goals.</p><p>We knew in our hearts that the challenge was genuine. Due to our poor experiences with hiring in the past, we started favouring the path of least resistance, which is to not try to hire anyone. Automatically our goals would only be as lofty as how much the two of us can achieve together. </p><p>We had to change this about ourselves. And so we immediately set out to <a href="https://twitter.com/hipreetam93/status/1296089975818055680" target="_blank">hire someone amazing</a> into our team. It was an exercise to prove to ourselves that we have what it takes to do this.</p><h3>An updated mindset</h3><p>Less than a month later, we hired an amazing <a href="https://twitter.com/akashjdotcom" target="_blank">first engineer</a> and have made an offer to another. This exercise has turned out way better than we anticipated, and it did exactly what it was supposed to do. It allowed us to dream bigger.</p><p>Our mindset and philosophy has thus been updated - We can get far in today’s world just by ourselves, but if we want to get really really far with our next venture <a href="https://delight.chat/" target="_blank">Delight.chat</a>, we need more than just the two of us.&nbsp;</p><p>While we suddenly haven't started wanting to build a 400 person company, our mindset has evolved enough to accept and understand how building a team of 5-15 people could produce a 100x result of what we had previously set out to achieve.</p><h3>People on the inside</h3><p>We need people on the inside (a team) who are aligned with our shared vision, and working together using their mind and abilities towards achieving that goal. </p><p>It's not just having more hands in the engineering team in building the product, or marketing team in creating content or distribution channels.</p><p>Their consciousness, ideas, problem solving abilities, attitude and values get added into a collective pool with our own. The sum is greater than the parts.</p><p>The people joining our team are entrepreneurial minds whose values align with ours, who want to build and grow something new and challenging from the ground up, learn from the experience, and eventually start their own companies. We will be their first supporters when they do. Psst, <a href="https://www.notion.so/Join-our-tribe-at-Delight-chat-dfb896c946a843ebb58bbb1cc161fe33#dfa80f89af17410e9076d1d4fbfcff35" target="_blank">we are hiring</a>.</p><h3>People on the outside</h3><p>We need people on the outside (advisors, investors) who are aligned with our end goal of building a great company, and are going out of their way in helping us get there. </p><p>They align with our mindset of building a real business that thrives without burning $1 for 70 cents,&nbsp;delivers real value to end users, and grows to a reasonably large size while being profitable.</p><p>Their experience observing other entrepreneurs and companies will help us avoid common pitfalls, make better connections like key hires, and open up doors that we can't even imagine today, because we don't know those doors exist. Serendipity.</p><h3>Onwards</h3><p>I feel incredibly lucky and grateful that we have a handful of such people who believe in us, and who are now working with us towards achieving our shared goal.</p><p>Together, we will reach farther than we previously dared to imagine.</p><p>Off we go towards the next milestone in this great adventure.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-a-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-24458258</guid>
            <pubDate>Sun, 13 Sep 2020 04:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Monte Carlo Tree Search Algorithm in an AI to Beat 2048]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24457625">thread link</a>) | @xtrp
<br/>
September 12, 2020 | https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/ | <a href="https://web.archive.org/web/*/https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently worked on an open source <a href="https://jupiter.xtrp.io/">project called Jupiter</a>, an online AI to beat the popular online game <a href="http://play2048.co/">2048</a>.</p>
<p>Go try out the AI:</p>
<p><a href="https://jupiter.xtrp.io/"><img src="https://raw.githubusercontent.com/xtrp/jupiter/master/demo-image.png" alt="Jupiter Screenshot"></a></p>
<p>In writing this AI, I decided to use a machine learning method called the Monte Carlo Tree Search (MCTS) algorithm. Monte Carlo algorithms like the one used in Jupiter have been used in several notable AIs, including DeepMind's <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, which famously beat the Go world champion in May 2017.</p>
<p>In this article, I'll explain:</p>
<ul>
<li>How and why the Monte Carlo method works</li>
<li>When and where Monte Carlo algorithms can be useful </li>
<li>How I used the Monte Carlo method in an AI to beat 2048</li>
<li>How to implement Monte Carlo algorithms in JavaScript and other languages</li>
</ul>
<p>Note: I got the idea of using a Monte Carlo method to beat 2048 from <a href="https://stackoverflow.com/a/23853848/10007107">this StackOverflow answer</a>.</p>
<h2>What is the Monte Carlo Method?</h2>
<p>The Monte Carlo method is the idea of using a large number of random simulations of an experiment to gain insights into the experiment's end results. Random simulations of an experiment are frequently referred to as <em>Monte Carlo simulations</em>.</p>
<p>For example, let's say that you were flipping a coin, and trying to figure out the probability of the coin landing heads. With the Monte Carlo method, we could simulate 10,000 coin tosses, and calculate the percentage of coins that landed heads.</p>
<p>Here's what that would look like.</p>
<p><img src="https://xtrp.io/api/content/static_files/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/coinflip.png" alt="Flip Coin Example Graph"></p>
<p>As can be seen, the result converges to the expected value, 50%. A notable feature of Monte Carlo simulations is that a higher number of simulations is correlated with higher accuracy. For example, if we only performed two simulations, there is a high (25%) probability of heads landing in both simulations, giving a result of 100%. This is very inaccurate in comparison to the expected result of 50%.</p>
<p>Monte Carlo simulations <strong>work because of the Law of Large Numbers</strong>, which says:</p>
<blockquote>
<p>If you simulate the same experiment many times, the average of the results should converge to the expected value of the simulation.</p>
</blockquote>
<p>In other words, Monte Carlo simulations are a way to estimate what will happen in a given experiment <strong>without having to implement any specific algorithms or heuristics</strong>.</p>
<h2>When and Where the Monte Carlo Method Can Be Useful</h2>
<p>The Monte Carlo method is used in a variety of fields, including game AI development, finance and economics, and evolutionary biology to name a few.</p>
<p>The Monte Carlo method can be useful in any experiment with a random factor, where end results cannot be predicted algorithmically. For example, in 2048, a new tile at a random location is added after every move, making it impossible to calculate the exact location of upcoming tiles and subsequently the end result of the game as well.</p>
<p>In these types of experiments, running a large number of Monte Carlo simulations can help get a sense of the average end results, the probability of various events occurring, and the relationship between the variables in the experiment.</p>
<p>For example, using the Monte Carlo method to in Jupiter allowed me to better understand how variables like starting move, number of moves in a game, and best tile in the board affected the end results of the game.</p>
<h2>How I Used the Monte Carlo Method in Jupiter, an AI to Beat 2048</h2>
<p>Let's start with a few definitions:</p>
<ul>
<li><strong>Board and Tiles</strong>: a 4x4 grid with tiles optionally placed on each grid spot</li>
<li><strong>Game State</strong>: a set of tiles on the board which represents the board at a specific time</li>
<li><strong>Game Score</strong>: the sum of all the tiles on the board</li>
<li><strong>Real Game</strong>: the game that is being played and shown on the browser, not a simulation</li>
</ul>
<p>At any given game state, let's assume that four possible moves can be made: left, right, up, or down.</p>
<blockquote>
<p>There are indeed cases where a certain move is not possible in a given game state. Removing impossible moves can be easily added to the algorithm later.</p>
</blockquote>
<p>With the Monte Carlo method, we can run a set of game simulations for every move.</p>
<p>For each possible move, the program simulates a set of simulations which <strong>start by playing the move for that set first</strong>. After that, the rest of the game can be played completely randomly until it is over.</p>
<p>In JavaScript, this algorithm looks something like:</p>
<pre><code>// assume Game object exists
// assume currentGame variable exists as the real game

const totalSimulations = 200; // 50 simulations are played for each move 

const possibleMoves = ["left", "right", "down", "up"];
possibleMoves.forEach((move) =&gt; { // simulations for all four possible starting moves
  for(let i = 0; i &lt; totalSimulations / 4; i++) {
    const simulation = new Game(); // create simulation
    simulation.board = currentGame.board; // copy current game state to simulation
    simulation.makeMove(move); // make initial move
    while(!simulation.gameover()) {
      simulation.makeMove(possibleMoves[Math.floor(Math.random() * 4)]);
    } // make random moves until simulation game is over
  }
});</code></pre>
<p>After all the simulations are completed, the program can gather the total final game scores of all the simulations, and average them for each move. We can then find the optimal move by optimizing for the highest final game score.</p>
<p>For example, if the simulations which started by playing left had an average final score of 250, whereas the ones which started by playing the other moves had an average final game score of 225, then left is the optimal move.</p>
<p>In this program, <strong>the optimal move is the one with simulations with the highest average final game score</strong>.</p>
<blockquote>
<p><strong>Note: I could have chosen to optimize for a different value such as the number of moves in the game.</strong></p>
<p>However, this would actually make no difference in how the algorithm functions, because the number of moves in the game almost exactly predicts the game score. In 2048, the new tile added after each game move is normally a 2 tile, but has a 10% chance of being a 4 tile instead. This means the expected value of the new tile is 2.2 (<code>2 × 90% + 4 × 10%</code>). The total value of tiles is also preserved after every tile combination (ex: 2 tile combined with another 2 tile gives a 4 tile). As a result, game score can be calculated by multiplying the expected value of the new tile by the number of moves in the game, or with this formula: <code>2.2 × (real game move count + average move count)</code>.</p>
</blockquote>
<p>To add this functionality of optimizing for highest score to our current code: add an array of total final scores for the simulations for each possible move, and choose the move with the highest value in that array to play like so:</p>
<pre><code>const possibleMoves = ["left", "right", "down", "up"];
const totalSimulations = 200;

let moveSimulationTotalScores = [0, 0, 0, 0];

possibleMoves.forEach((move, moveIndex) =&gt; { // simulations for all four possible starting moves
  for(let i = 0; i &lt; totalSimulations / 4; i++) {
    const simulation = new Game(); // create simulation
    simulation.board = currentGame.board; // copy current game state to simulation
    simulation.makeMove(move); // make initial move
    while(!simulation.gameover()) {
      simulation.makeMove(possibleMoves[Math.floor(Math.random() * 4)]);
    } // make random moves until simulation game is over
    moveSimulationTotalScores[moveIndex] += simulation.getScore();
  }
});

// make best move with highest total simulation scores
let topScore = Math.max(...moveSimulationTotalScores);
let topScoreIndex = moveSimulationTotalScores.indexOf(topScore);
let bestMove = possibleMoves[topScoreIndex];

currentGame.makeMove(bestMove);</code></pre>
<p>In the end, this algorithm is simple to implement given a well-written 2048 game class. In JavaScript, there are a number of performance upgrades that can be made, starting by adding concurrency with <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API">Web Workers</a> and pruning moves with very low final game scores.</p>
<h2>Conclusion</h2>
<p>I hope you enjoyed this post, and found it useful in helping you understand and implement the Monte Carlo method in your own projects.</p>
<p>Go check out <a href="https://jupiter.xtrp.io/">Jupiter</a> and <a href="https://github.com/xtrp/jupiter">its source code</a>.</p>
<p>Thanks for scrolling.</p>
<p><em>— Gabriel Romualdo, September 12, 2020</em></p></div></div>]]>
            </description>
            <link>https://xtrp.io/blog/2020/09/12/using-the-monte-carlo-tree-search-algorithm-in-an-ai-to-beat-2048-and-other-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24457625</guid>
            <pubDate>Sun, 13 Sep 2020 02:14:27 GMT</pubDate>
        </item>
    </channel>
</rss>
