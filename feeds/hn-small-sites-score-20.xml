<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 02 Jul 2020 00:38:59 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 02 Jul 2020 00:38:59 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Implementing a System Call for OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23685279">thread link</a>) | @soheilpro
<br/>
June 29, 2020 | https://poolp.org/drafts/2020-05-28-015100-copy/ | <a href="https://web.archive.org/web/*/https://poolp.org/drafts/2020-05-28-015100-copy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://poolp.org/drafts/2020-05-28-015100-copy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23685279</guid>
            <pubDate>Tue, 30 Jun 2020 00:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cancel Culture in 1974]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23684815">thread link</a>) | @riverlong
<br/>
June 29, 2020 | https://jayriverlong.github.io/2020/06/28/cancel-culture.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/06/28/cancel-culture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>In 2008, Facebook was the hot new thing, and social media had <em>just</em> started rising. One of my high-school classes was about trying to understand that shift better.<sup id="fnref:1"><a href="#fn:1">1</a></sup> We read about past problems with mass media, and thought about how they might manifest in new media. To that end, we read a German novel called <em>The Lost Honor of Katharina Blum</em> by Heinrich Böll. In recent years, with social media-induced cancel culture becoming a hot issue, that novel has been on my mind frequently.</p> <p>A quick summary:</p> <blockquote> <div><p>Katharina is a 27-year old housekeeper. She’s frugal, earnest, and hard-working – a model citizen. One evening, she meets a man named Ludwig at a party, and sleeps with him. Next day, the police knocks on her door: he’s a known communist terrorist, and suspected for robbery and murder. Katharina is taken in for questioning, and released. </p><p>  This episode is observed by a reporter for the tabloid NEWS. The reporter inquires with neighbors, stretches any statements, and publishes a piece declaring Katharina to be a gold-digging communist criminal, the depraved bride of a murderous terrorist. Katharina is swiftly excluded from society and receives death threats. Under the onslaught of harassment, her hospitalized mother dies from stress. </p><p>  In the meantime, Ludwig is found to have committed no robbery or murder, but by then, the campaign against Katharina has become its own force. One sympathizer argues that the actual facts are good, and that other newspapers are reporting the facts, but – as Katharina points out through her sobs – it doesn’t matter, because <em>everyone</em> reads the NEWS. </p><p>  For no fault of her own, Katharina’s life is in shambles: her career is over, and her friends distance themselves for self-preservation. In desperation, she tries to meet with the reporter who has been hounding her. The reporter tries to extort her for sex, whereupon she shoots him. Remorseless, she turns herself in to the police for justice.</p></div> </blockquote> <p>The 70s were a heyday for tabloid newspapers. Printing any scandal, no matter how thin the facts, the tabloids were like the clickbait outrage mills of today. Their reach was wide and deep: the NEWS of the novel was a depiction in all but name of the leading tabloid in Germany, BILD, which printed six million copies every day, purchased by one in ten Germans. To be depicted unfavorably in BILD was social execution, and – as a paper dealing primarily in outrage and gossip – BILD executed plenty. Capricious and careless, their reporters had the power to ruin lives effectively at random.</p> <p>That sounds a lot like getting cancelled: for effectively no fault of your own, the outrage mob, whether online or offline, can <a href="https://en.wikipedia.org/wiki/Newspeak#Vocabulary">unperson</a> you. While today’s media are global and more plentiful, it’s not clear that there’s been a net change in impact. Getting smeared by your local tabloid was just as radioactive as is getting smeared on Reddit, a career-ender all the same. Further, even though traditional, local media has a much smaller reach than global media, its local reach is what really matters to the person affected. Local media has a much deeper local reach, and a much greater capacity to “investigate” and report locally. While modern media operate at much greater scale, it also carries a dilutive effect. Net-net, people have always been getting disgraced, and I don’t think it’s much likelier now than it was in the past.</p> <p>In my view, cancel culture is an example of a pattern I like to call <em>there’s nothing new under the sun</em>: there are always scary changes between generations, but usually they are just new manifestations of issues as old as time. For example, many people today complain that the young spend less time on necessary schoolwork than the previous generation. But even Socrates said the exact same thing. In many domains, perceptions of progress have been pessimistic since antiquity – perhaps because memories of times past are always rose-colored by nostalgia – but reality works out.</p> <p>If today’s severity and randomness of cancel culture is not actually new, is it different in any important respects? Today’s cancel culture is one of escalating purity tests: born out of the more punitive contingents on the left, it’s not enough to not be a racist or a sexist, but one must take stronger, more condemnatory views, which function as powerful in-group signals.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Cancel culture is thus somewhat performative, and strongly ideologically motivated – some people are likening it to the witch hunts for communists in the 50s under Joseph McCarthy. The left is in a curious, self-damaging position, where lots of center-leaning moderates – who are genuine progressives – are not meeting the ideological standards of those further left, which functions to their exclusion, thereby weakening the left overall.</p> <p>Is that bad? Yes, probably. While I view the aims of social justice as largely correct and well-intentioned, cancel culture seems to produce unnecessary collateral damage that hurts its own cause. It both fragments the left – infighting over purity is a devastating waste in a time beset by serious problems requiring collective action – and it is unfair to the people it ultimately affects. But is any of this new? I don’t think it is. It’s the same old patterns and motivations under new cover. Thus, like everyone else, we acknowledge cancel culture as a trend, but unlike everyone else, we see it as a trend that is very <em>old</em> rather than <em>new</em>. In turn, the question we ask about is radically different: while everyone else asks “how has technology given rise to cancel culture”, we know that it hasn’t, and instead ask “how can we use technology to mitigate cancel culture?”</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/06/28/cancel-culture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23684815</guid>
            <pubDate>Mon, 29 Jun 2020 23:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things to know before starting a Patreon page]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23680591">thread link</a>) | @colebowl
<br/>
June 29, 2020 | http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&mc_eid=5ac3a20371 | <a href="https://web.archive.org/web/*/http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&mc_eid=5ac3a20371">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0e74a9a2acebd70c05fe"><div><p>For the three years starting in April of 2017, I ran much of <a href="http://theprepared.org/newsletter" target="_blank">The Prepared’s</a> (and ultimately my family’s) income through Patreon. I started doing so as an experiment - one that by any measure has been a success. But while Patreon was instrumental in that process, I recommend that creators <strong>not</strong> structure their incomes and careers around Patreon. Here’s why.</p><p>Like many creators, I chose Patreon’s “pay by the creation” (rather than “pay by the month) mode. This directly incentivizes creators to continue doing the actual work, and keeps them accountable to the commitments they make. </p><p>But what Patreon doesn’t tell you is that fans can optionally set a monthly cap on their spending, and that cap can be arbitrarily low - even <strong>less than your per-creation commitment level.</strong> In other words, a reader of my weekly newsletter could pledge $5 per newsletter, but then set a $2 monthly cap. The worst part about this is that there’s literally nowhere in the Patreon backend that I can see this cap. I spoke to Patreon’s product team about this in late 2018, and they told me that the best thing I could do is to look at my creation-by-creation analytics at the end of the month and see which of my patrons paid for which creations; if a person doesn’t show up at the end of the month, then they must have set a cap.</p><p>This is a totally unscalable solution, and it makes the process of issuing patron rewards excruciatingly hard to manage. Creators need the ability to quickly and easily determine <strong>who</strong> is paying them for <strong>what</strong>; Patreon makes this impractically hard.</p><p>Further:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593267194369_49688"><div><ul data-rte-list="default"><li><p>Patreon provides email alerts for when a new patron makes a pledge, but has <strong>no email or push notifications for when patrons delete pledges.</strong> </p></li><li><p>Patreon has no creator-side notification system for declined charges or charges that are flagged for fraud. Worse yet, their patron-side notification system appears to be totally ineffective; many long time patrons (and personal friends of mine) were genuinely shocked to hear, many months later, that their monthly charges had been declined - leading to their pledges being automatically canceled by Patreon. Even worse, Patreon’s “Declines” page, which shows the total declined amount on a month by month basis, has no way of showing which patrons’ pledges were declined - you instead need to go into the “Relationship Manager” and filter by “Declined” to see whose charges have gone through, and when.</p></li><li><p>If you, as a creator, go through all of the effort to find charges that<em> </em>have been declined or marked as fraud, it can then be really difficult to recoup that revenue. This is mostly a result of the fact that most Patreon creators charge a small amount of money (a couple dollars) per month. In theory you could email or message the patron when their charge doesn’t go through, but in practice it feels a bit weird to be hounding someone over (say) $4. If the pledge was billed on an annual basis, though, it might be a big enough sum to warrant the effort. </p></li><li><p>Patreon uses accounting terms with little regard for their generally accepted meaning. See the screenshot above, which is titled “Earnings Projections” but then actually lists <em>gross revenue.</em> In accounting, <em>earnings</em> is the same as <em>profit - </em>it’s what a company has left <strong>after every expense is paid, </strong>whereas <em>gross revenue</em> is the total amount that a company takes in and doesn’t take into account expenses at all. In other words, Patreon is suggesting that the numbers here are what will be deposited into my bank account - but once Patreon takes their platform fees, it’ll actually be significantly less. This kind of sloppy terminology is all over Patreon’s creator backend, and no matter how you slice it is either the result of gross incompetence or a deliberate desire to deceive creators.</p></li></ul><p>Between credit card processing fees (2.9% plus $0.30 per transaction) and Patreon’s cut (between 5% and a whopping 12%), your earnings will be <em>significantly</em> less than your top line pledged amount. In practice, I saw total fees of between 8-12%. (Note: I signed up for Patreon before they shifted to tiered pricing, and now have a “Founder” Pro plan at a 5% platform fee rate. If you signed up for a Pro or Premium account today, you’d pay Patreon 3% or 7% more than I do, respectively.)</p><p>If Patreon were actively bringing customers to me - if normal people were just out there browsing Patreon for awesome things to support - then that might make sense. <strong>But the reality is that success on Patreon is inextricably tied to having your own platform and community.</strong> All Patreon does is manage recurring payment processing - a commodity service that many companies do for a drastically lower fee structure. Sure, ostensibly you can also be having conversations with patrons, generating some kind of community there, etc - but every step you take to encourage users to interact with you on Patreon, the more you undermine your own platform. In other words, Patreon engages in rent seeking - but they ultimately do it on <strong>your</strong> platform, and don’t bring a built-in audience with which to raise you higher.</p><p>When I transitioned off of Patreon, I moved to a combination of Quickbooks Online ($645/year; note that <a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank">Intuit is a terrible company</a>) and Squarespace’s ($480/year) recurring products feature. The result is that my processing fees dropped dramatically. At my peak Patreon earnings, I was spending almost $300/month ($3600/year) on Patreon’s platform fees. My current revenue is roughly 3x what it was then, but I’m paying 68% less than I used to be.<strong> My current payments, web hosting, and accounting software outlay is $1,125 a year; if I had remained on Patreon my annual fees would be about $10,000.</strong></p><p>Okay, you’re saying - so Patreon isn’t the perfect all-in-one platform that will allow me to bill, chat with, and build my audience. But maybe it’s a piece of a larger puzzle?</p><p>It’s a great idea, but unfortunately Patreon does a terrible job integrating with the other services that I use to run my business.</p><p>The first thing I’d want from Patreon is an easy way to automatically share my content (which most creators distribute elsewhere - for me, it’s Mailchimp) to Patreon. But while Patreon does have a public API, it’s poorly developed (there is no sandbox/testing area, and the most recent updates to <a href="https://github.com/Patreon/patreon-python" target="_blank">their API libraries</a> are from January of 2019) and only allows browsing/looking up data on Patreon; you cannot post content to your Patreon account via the API. This lack of functionality also exists in Zapier’s implementation of the Patreon API: You can use Patreon as a trigger, but not as an action.</p><p>What this means is that creators are inherently tied to Patreon’s terrible, horrible, clicky clicky GUI. You are completely tied to the limitations that are built into Patreon’s web product, and don’t have the ability to build automations that’ll speed up your content and customer management.</p><p>Patreon also fails to integrate well with accounting software - something that flies in the face of their promise to give creators “the stability you need to build an independent creative&nbsp;career.” Their API (and Zapier’s implementation of it) only provides <em>pledge</em> activity, and is therefore inaccurate (caps, declines, and fraud aren’t factored in - it’s a guesstimate at what you might make in the future) in all of the ways described above.</p><p>I really can’t stress this enough: <strong>If your intention is to build a meaningful income, there are much better options out there than Patreon. </strong>What Patreon <em>does</em> offer is a quick way to see whether people on the internet will pay you a little money for something that you’re already doing for free. </p><p>This is a nontrivial thing, but it’s something that you should really think through before you start a Patreon page. If it’s a success, then it’ll likely make a lot of sense for you to transition <em>off</em> of Patreon at some point in the foreseeable future. That might be fine - especially if you’re really early on and success feels like a longshot - but The Prepared’s transition off of Patreon required a lot of management on my part and resulted in roughly 1/3 of my patrons dropping their pledges. </p><p>To be clear: I’m deeply appreciative of all of the people and companies who supported me through Patreon, and it really is true that those first couple of dollars made a big impact in the path of my career. But Patreon as a platform did remarkably little to support me along that journey, even after I became a moderately successful creator and took quite a bit of time to explain my frustrations to both their customer service &amp; user research teams.</p></div></div></div>]]>
            </description>
            <link>http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon?mc_cid=cb178f4bd4&amp;mc_eid=5ac3a20371</link>
            <guid isPermaLink="false">hacker-news-small-sites-23680591</guid>
            <pubDate>Mon, 29 Jun 2020 18:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Chernoff Faces]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23679014">thread link</a>) | @pxx
<br/>
June 29, 2020 | https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html | <a href="https://web.archive.org/web/*/https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-7486848344071731398" itemprop="description articleBody"><p>
One of my favorite<a href="#foot1" id="cite1">¹</a> concepts for multi-dimensional data visualization is the <a href="https://en.wikipedia.org/wiki/Chernoff_face">Chernoff Face</a>. The idea here is that for a dataset with many dependent variables, it is often difficult to immediately understand the influences one variable may have on another. However, humans are great at recognizing small differences in faces, so maybe we can leverage that!</p><h2>
Tired: traditional plotting</h2><p>
The example from Wikipedia plots the differences between a few judges on some rating dimensions:</p><p><a href="https://1.bp.blogspot.com/-I_lJGg7QnmM/Xvl1rXrnm-I/AAAAAAAA534/0wm9LMMmQ0kgtxdNq9exqELo-jgSsqCMACLcBGAsYHQ/s1600/1000px-Chernoff_faces_for_evaluations_of_US_judges.svg.png"><img data-original-height="750" data-original-width="1000" height="240" src="https://1.bp.blogspot.com/-I_lJGg7QnmM/Xvl1rXrnm-I/AAAAAAAA534/0wm9LMMmQ0kgtxdNq9exqELo-jgSsqCMACLcBGAsYHQ/s320/1000px-Chernoff_faces_for_evaluations_of_US_judges.svg.png" width="320"></a></p><p>
which already improves on the "traditional" way to present such data, which is something similar to a line chart:</p><p><a href="https://1.bp.blogspot.com/-vFSg9Y-NJYg/XvmB6rUCFmI/AAAAAAAA54g/pXmUUEPqWf4QXqrasbL_WxSjN3zWu1_TwCLcBGAsYHQ/s1600/x.png"><img data-original-height="353" data-original-width="583" height="193" src="https://1.bp.blogspot.com/-vFSg9Y-NJYg/XvmB6rUCFmI/AAAAAAAA54g/pXmUUEPqWf4QXqrasbL_WxSjN3zWu1_TwCLcBGAsYHQ/s320/x.png" width="320"></a></p>
<p>
or a radar chart:</p><p><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://1.bp.blogspot.com/-Dh3hoPt0f5A/XvmBsL-eM7I/AAAAAAAA54c/r0KXd9byh1wQ06Yp5Y3Ds-LV44p_DEfpQCLcBGAsYHQ/s1600/x.png"><img data-original-height="356" data-original-width="591" height="192" src="https://1.bp.blogspot.com/-Dh3hoPt0f5A/XvmBsL-eM7I/AAAAAAAA54c/r0KXd9byh1wQ06Yp5Y3Ds-LV44p_DEfpQCLcBGAsYHQ/s320/x.png" width="320"></a></p>


<p>
Clearly<a href="#foot2" id="cite2">²</a> the Chernoff faces are the best way to present this data, but they leave some of the gamut unexplored.</p>

<h2>
Wired: using GANs to synthesize faces</h2>


<p>
The GAN technique is pretty easily summarized. You set up two neural networks, a generator, which tries to generate realistic images, and a discriminator, which tries to distinguish between the output of the generator and a real corpus of images. By training the networks together, adding more layers, fooling around with hyperparameters and overall "the scientific process", you manage to get results where the generator network is able to fool the discriminator (and humans) with high-quality images of faces that do not actually map to anybody in the real world. StyleGAN improves on some of the basic structure here by using a novel generator architecture that stacks a bunch of layers together and ends up with an intermediate latent space that has "nice" properties.</p>

<p><a href="https://1.bp.blogspot.com/-JxAnoglX3VU/Xvl-BPsI1XI/AAAAAAAA54I/HTbKb0qKkhE88y4HzqyHwele2NAzZM0WgCLcBGAsYHQ/s1600/n9fgba8b0qr01.png"><img data-original-height="1461" data-original-width="1600" height="292" src="https://1.bp.blogspot.com/-JxAnoglX3VU/Xvl-BPsI1XI/AAAAAAAA54I/HTbKb0qKkhE88y4HzqyHwele2NAzZM0WgCLcBGAsYHQ/s320/n9fgba8b0qr01.png" width="320"></a></p>
<p><i>Basically how it works.</i></p>
<br>
<div><p>
A trained StyleGAN (1 or 2; the architecture for the dimensions does not change between versions), at the end of the day, takes a 512 element vector in the latent space "Z", then sends it through some </p><strike>nonsense</strike><p> fully-connected layers to form a "dlatent"<a href="#foot3" id="cite3">³</a> vector of size 18x512. The 18 here indicates how many layers there are in the generator proper—the trained networks that NVIDIA provides produce 1024x1024 images; there are 2 layers for each of the dimensions from 2^2=4 to 2^10=1024.</p></div>

<p><a href="https://1.bp.blogspot.com/-RLpfhFZBSuo/Xvl-Wzo0B2I/AAAAAAAA54Q/ztjxSsS_JJYSz9MZBXnXBYuGC2IkT9SAACLcBGAsYHQ/s1600/x.png"><img data-original-height="767" data-original-width="267" height="320" src="https://1.bp.blogspot.com/-RLpfhFZBSuo/Xvl-Wzo0B2I/AAAAAAAA54Q/ztjxSsS_JJYSz9MZBXnXBYuGC2IkT9SAACLcBGAsYHQ/s320/x.png" width="111"></a></p>
<p><i>What part of STACK MORE LAYERS did you not get?</i></p>
<br>
<div>
<p><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a>The upshot is that the 18x512 space has nice linearity properties that will be useful to us when we want to generate photorealistic faces that only differ on one axis of importance. The authors of the NVIDIA paper call each of the 18 layers a "style", and the observation is that copying qualities from each style gives qualitatively different results.</p><p>

The styles that correspond to coarse resolutions bring high-level aspects like pose, hair style, face shape; the styles that correspond to fine resolutions bring low-level aspects like color scheme. But they only roughly correspond to these, so it's going to be somewhat annoying to play around with the latent space! What we need is some way to automatically classify these images for the properties we want to use in our Chernoff faces...</p></div>
<p>
<br>
<h3>
Putting it all together</h3>
</p>
<div><p>
What I did was take an <a href="https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x">unofficial re-implementation of StyleGAN2</a> and run it to generate 4096 random images (corresponding actually to random seeds 0 - 4095 in the original repository). The reason why we're using an unofficial implementation is that the unofficial implementation ports everything to TensorFlow 2, which also enabled me to run it with (a) less GPU RAM (I only have a GTX 1080 at home) and (b) on the CPU if needed for a future project where I serve these images dynamically.</p><p>

I was also too lazy to train a network to recognize any features, so I fed these images through <a href="https://www.kairos.com/pricing">Kairos</a>'s free trial, receiving API responses that roughly looked like <a href="https://pastebin.com/PXWDKkYf">this</a>. (There's no code for this part, you can just do it with cURL<a href="#foot4" id="cite4">⁴</a>).</p><p>

<a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a><a href="https://www.blogger.com/blogger.g?blogID=2308943333455824725&amp;useLegacyBlogger=true"></a>Then, somewhere in this <a href="https://github.com/patrickxia/StyleGAN2-TensorFlow-2.x/blob/master/play_around_with_directions.ipynb">gigantic unorganized notebook</a>&nbsp;that I need to clean up, I train some <a href="https://en.wikipedia.org/wiki/Support_vector_machine#Linear_SVM">linear SVMs</a> to split our sample of the latent space; eventually I will clean this up and make it so it's a little more automated than the crazy experimentation I was doing. After I train the SVMs and receive the normal vector from their separating hyperplanes, I manually explore the latent space by considering only one style's worth of elements from each of the normal vectors, plotting the results, and seeing what changes about the photos (which could be different than the feature from the API response!). This could probably be automated; I should likely use the <a href="https://en.wikipedia.org/wiki/Conditional_entropy">conditional entropy</a> of the Kairos API responses given the SVM result to rank which styles are most important and then automatically return that instead of manually pruning styles.<br>
<span><br></span>
<span>I ended up with seven usable properties plus one I threw out before I got tired of doing this by hand.</span></p><ul>
<li>yaw</li>
<li>eye squint</li>
<li>age</li>
<li>smile</li>
<li>skin tone</li>
<li>gender</li>
<li>hair length</li>
<li>quality of photo</li>
</ul>
<div><p>
I decided not to use quality of photo (you can see the results in the notebook results) because I didn't want half the photos to just look terrible. The good news is that I made <a href="https://github.com/patrickxia/StyleGAN2-TensorFlow-2.x/blob/master/chernoff_faces.ipynb">a new notebook</a> for generating the actual faces, one that should actually work for you if you clone the repo.</p><p>

After generating a few images and using the `montage` command from ImageMagick, we get our preliminary results!</p><p><a href="https://1.bp.blogspot.com/-BUwEV9KxEHU/XvmKsnDLQdI/AAAAAAAA54w/LRRwtnI9zl80FV5sIQMEQfcmGFcX8cYCQCLcBGAsYHQ/s1600/out.png"><img data-original-height="426" data-original-width="512" height="331" src="https://1.bp.blogspot.com/-BUwEV9KxEHU/XvmKsnDLQdI/AAAAAAAA54w/LRRwtnI9zl80FV5sIQMEQfcmGFcX8cYCQCLcBGAsYHQ/s400/out.png" width="400"></a></p>

<br></div>
<p>
Now that's the future!</p>



<p><a href="#cite1" id="foot1">¹</a>&nbsp;"Favorite" might be code for "useless," going with the theme of this blog.<br>
<a href="#cite2" id="foot2">²</a>&nbsp;Clearly.<br>
<a href="#cite3" id="foot3">³</a>&nbsp;It's called a dlatent in the code, but the paper calls it the space W and the vectors w. I don't know.<br>
<a href="#cite4" id="foot4">⁴</a></p><tt>for q in `seq 0 4095`; do i=$(printf "%04d" $q); curl -d '{"image": "http://cantina.patrickxia.com/faces/seed'$i'.png"}' -H "app_id: xxx" -H "app_key: xxx" -H 'store_image: "false"' -H "Content-Type: application/json" http://api.kairos.com/detect &gt; $i.json; sleep 1; done</tt><p> and something similar for the `media` API, which gives you landmarks. If you care enough, I've hosted the images <a href="http://cantina.patrickxia.com/faces">here</a>, which lets you just look through them if you want.</p></div>

</div></div>]]>
            </description>
            <link>https://www.ihatethefuture.com/2020/06/deep-chernoff-faces.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23679014</guid>
            <pubDate>Mon, 29 Jun 2020 16:21:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The History of Usenet and FidoNet]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23678687">thread link</a>) | @cfmcdonald
<br/>
June 29, 2020 | https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Between roughly 1975 and 1995, access to computers accelerated much more quickly than access to computer networks. First in the United States, and then in other wealthy countries, computers became commonplace in the homes of the affluent, and nearly ubiquitous in institutions of higher education. But if users of those computers wanted to connect their machines together – to exchange email, download software, or find a community where they could discuss their favorite hobby, they had few options. Home users could connect to services like CompuServe. But, until the introduction of flat monthly fees in the late 1980s, they charged by the hour at rates relatively few could afford. Some university students and faculty could connect to a packet-switched computer network, but many more could not. By 1981, only about 280 computers had access to ARPANET. CSNET and BITNET would eventually connect hundreds more, but they only got started in the early 1980s. At that time the U.S. counted more than 3,000 institutions of higher education, virtually all of which would have had multiple computers, ranging from large mainframes to small workstations.</p>
<p>Both communities, home hobbyists and those academics who were excluded from the big networks, turned to the same technological solution to connect to one another. They hacked the plain-old telephone system, the Bell network, into a kind of telegraph, carrying digital messages instead of voices, and relaying messages from computer to computer across the country and the world.</p>
<p>These were among the earliest peer-to-peer computer networks. Unlike CompuServe and other such centralized systems, onto which home computers latched to drink down information like so many nursing calves, information spread through these networks like ripples on a pond, starting from anywhere and ending up everywhere. Yet they still became rife with disputes over politics and power. In the late 1990s, as the Internet erupted into popular view, many claimed that it would flatten social and economic relations. By enabling anyone to connect with anyone, the middle men and bureaucrats who had dominated our lives would find themselves cut out of the action. A new era of direct democracy and open markets would dawn, where everyone had an equal voice and equal access. Such prophets might have hesitated had they reflected on what happened on Usenet and Fidonet in the 1980s. Be its technical substructure ever so flat, every computer network is embedded within a community of human users. And human societies, no matter how one kneads and stretches, always seem to keep their lumps.</p>
<h2>Usenet</h2>
<p>In the summer of 1979, Tom Truscott was living the dream life for a young computer nerd. A grad student in computer science at Duke University with an interest in computer chess, he landed an internship at Bell Labs’ New Jersey headquarters, where he got to rub elbows with the creators of Unix, the latest craze to sweep the world of academic computing.</p>
<p>The origins of Unix, like those of the Internet itself, lay in the shadow of American telecommunications policy. Ken Thompson and Dennis Ritchie of Bell Labs decided in the late 1960s to build a leaner, much pared-down version of the massive MIT Multics system to which they had contributed as software developers. The new operating system quickly proved a hit within the labs, popular for its combination of low overhead (allowing it to run on even inexpensive machines) and high flexibility. However, AT&amp;T could do little to profit from their success. A 1956 agreement with the Justice Department required AT&amp;T to license non-telephone technologies to all comers at a reasonable rate, and to stay out of all business sectors other than supplying common carrier communications.</p>
<p>So AT&amp;T began to license Unix to universities for use in academic settings on very generous terms. These early licensees, who were granted access to the source code, began building and selling their own Unix variants, most notably the Berkeley Software Distribution (BSD) Unix created at the the University of California’s flagship campus. The new operating system quickly swept academia. Unlike other popular operating systems, such as the DEC TENEX / TOPS-20, it could run on hardware from a variety of vendors, many of them offering very low-cost machines. And Berkeley distributed the software for only a nominal fee, in addition to the modest licensing fee from AT&amp;T.<sup id="fnref-13802-fee"><a href="#fn-13802-fee">1</a></sup></p>
<p>Truscott felt that he sat at the root of all things, therefore, when he got to spend the summer as Ken Thompson’s intern, playing a few morning rounds of volleyball before starting work at midday, sharing a pizza dinner with his idols, and working late into the night slinging code on Unix and the C programming language. He did not want to give up the connection to that world when his internship ended, and so as soon as he returned to Duke in the fall, he figured out how to connect the computer science department’s Unix-equipped PDP 11/70 back to the mothership in Murray Hill, using a program written by one of his erstwhile colleagues, Mike Lesk. It was called <em><span>uucp</span></em> – Unix to Unix copy – and it was one of a suite of “uu” programs new to the just-released Unix Version 7, which allowed one Unix system to connect to another over a modem. Specifically, <em>uucp</em> allowed one to copy files back and forth between the two connected computers, which allowed Truscott to exchange email with Thompson and Ritchie.</p>
<figure data-shortcode="caption" id="attachment_14009" aria-describedby="caption-attachment-14009"><img data-attachment-id="14009" data-permalink="https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/truscott/" data-orig-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg" data-orig-size="171,187" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="truscott" data-image-description="" data-medium-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=171" data-large-file="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=171" src="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=739" alt="truscott" srcset="https://technicshistory.files.wordpress.com/2020/06/truscott.jpg 171w, https://technicshistory.files.wordpress.com/2020/06/truscott.jpg?w=137 137w" sizes="(max-width: 171px) 100vw, 171px"><figcaption id="caption-attachment-14009">Undated photo of Tom Truscott</figcaption></figure>
<p>It was Truscott’s fellow grad student, Jim Ellis, who had installed the new Version 7 on the Duke computer, but even as the new upgrade gave with one hand, it took away with the other. The news program that was distributed by the Unix users’ group, USENIX, which would broadcast news items to all users of a given Unix computer system, no longer worked on the new operating ssytem. Truscott and Ellis decided they would replace it with their own 7-compatible news program, with more advanced features, and return their improved software back to the community for a little bit of prestige.</p>
<p><span>At this same time, Truscott was also using <em>uucp</em> to connect with a Unix machine at the University of North Carolina ten miles to the southwest in Chapel Hill, and talking to a grad student there named Steve Bellovin.<sup id="fnref-13802-bellovin"><a href="#fn-13802-bellovin">2</a></sup> Bellovin had also started building his own news program, which notably included the concept of topic-based <em>newsgroups</em>, to which one could subscribe, rather than only having a single broadcast channel for all news. Bellovin, Truscot and Ellis decided to combine their efforts and build a networked news system with newsgroups, that would use <em>uucp</em> to share news between sites. They intended to distributed provide Unix-related news for USENIX members, so they called their system Usenet.&nbsp;</span></p>
<p>Duke would serve as the central clearinghouse at first, using its auto-dialer and <em>uucp</em> to connect to each other site on the network at regular intervals, in order to pick up it local news updates and deposit updates from its peers. Bellovin wrote the initial code, but it used shell scripts that operated very slowly, so Stephen Daniel, another Duke grad student, rewrote the program in C. Daniel’s version became know as A News. Ellis promoted the program at the January 1980 Usenix conference in Boulder, Colorado, and gave away all eighty copies of the software that he had brought with him. By the next Usenix conference that summer, the organizers had added A News to the general software package that they distributed to all attendees.</p>
<p>The creators described the system, cheekily, as a “poor man’s ARPANET.” Though one may not be accustomed to thinking of Duke as underprivileged, it did not have the clout in the world of computer science necessary at the time to get a connection to that premiere American computer network. But access to Usenet required no one’s permission, only a Unix system, a modem, and the ability to pay the phone bills for regular news transfers, requirements that virtually any institution of higher education could meet by the early 1980s.</p>
<p>Private companies also joined up with Usenet, and helped to facilitate the spread of the network. Digital Equipment Corporation (DEC) agreed to act as an intermediary between Duke and UC Berkeley, footing the long-distance telephone bills for inter-coastal data transfer. This allowed Berkeley to become a second, west-coast hub for Usenet, connecting up UC San Francisco, UC San Diego, and others, including Sytek, an early LAN business. The connection to Berkeley, an ARPANET site, also enabled cross-talk between ARPANET and Usenet (after a second re-write by Mark Horton and Matt Glickman to create B News). ARPANET sites began picking up Usenet content and vice versa, though ARPA rules technically forbid interconnection with other networks. The network grew rapidly, from fifteen sites carrying ten posts a day in in 1980, to 600 sites and 120 posts in 1983, and 5000 sites and 1000 posts in 1987.<sup id="fnref-13802-sitesandposts"><a href="#fn-13802-sitesandposts">3</a></sup></p>
<p>Its creators had originally conceived Usenet as a way to connect the Unix user community and discuss Unix developments, and to that end they created two groups, <em>net.general</em> and <em>net.v7bugs</em> (the latter for discussing problems with the latest version of Unix). However they left the system entirely open for expansion. Anyone was free to create a new group under “net”, and users very quickly added non-technical topics such as <em>net.jokes</em>. Just as one was free to send whatever one chose, recipients could also ignore whatever groups they chose, e.g. a system could join Usenet and request data only for <em>net.v7bugs,</em> ignoring the rest of the content. Quite unlike the carefully planned ARPANET, Usenet self-organized, and grew in an anarchic way overseen by no central authority.</p>
<p>Yet out of this superficially democratic medium a hierarchical order quickly emerged, with a certain subset of highly-connected, high-traffic sites recognized as the “backbone” of the system. This process developed fairly naturally. Because each transfer of data from one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/">https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/06/25/the-era-of-fragmentation-part-4-the-anarchists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678687</guid>
            <pubDate>Mon, 29 Jun 2020 15:52:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worrying about the NPM Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23678409">thread link</a>) | @diiq
<br/>
June 29, 2020 | https://sambleckley.com/writing/npm.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/npm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3>
<p>The <acronym>npm</acronym> ecosystem seems unwell. If you are concerned with security, reliability, or long-term maintenance, it is almost impossible to pick a suitable package to use — both because there are 1.3 million packages available, and even if you find one that is well documented and maintained, it might depend on hundreds of other packages, with dependency trees stretching ten or more levels deep — as one developer, it’s impossible to validate them all.</p>

<p>I spend some time measuring the extent of the problem.</p>

<p>I suggest that this is a social problem, more than a technical one, and propose a semi-social solution: a human-maintained subset of the total registry, based on shared criteria by which a “healthy” package can receive a seal of approval. One criterion would be to only depend on other approved packages.</p>

<h3 id="the-premise">The premise</h3>

<p>I don’t like the way I feel when I’m installing packages with npm. Selecting a package, installing it, discovering the 93 additional packages that were installed along with it, and hoping all of <em>them</em> are also suitable for my project… it feels out of control.</p>

<p>I feel unhappy because picking dependencies is hard, so I blame npm, and that way my problems are not my fault.</p>

<p>Is there some way for me to measure this badness, and thus more thoroughly escape the blame?</p>

<h3 id="thinking-a-bit-like-a-scientist-but-not-too-much">Thinking a bit like a scientist, but not too much</h3>

<p>Can we make meaningful empirical measurements of the health of the <acronym>npm</acronym> registry? I think so; but before I do, in order to maintain the slightest semblance of impartiality, I want to lay out what I <em>expect</em> a healthy package registry to look like. If it turns out that npm, taken as a whole, mostly looks the way I expect a healthy registry to look, I’ll have to put my tail between my legs and take ownership of my struggles. If it looks wildly different, I’ll still have hope for blaming the system.</p>

<h3 id="imagining-a-healthy-repository">Imagining a healthy repository</h3>

<p>In my ideal world there are, mostly, 4 types of packages:</p>

<ul>
  <li>
    <p><strong>Utilities:</strong></p>

    <p>A utility is a simple package, with no dependencies, that accomplishes a single small but onerous task. For example: lodash is a collection of utilities (and you can install each one separately). Controversially, left-pad.</p>
  </li>
  <li>
    <p><strong>Libraries:</strong></p>

    <p>A library is one step up in abstraction. It may depend on a handful of utilities, and it accomplishes a whole set of related tasks. For example: urlib has just a few simple dependencies, and while it does many things, it respects a clear unifying principle.</p>
  </li>
  <li>
    <p><strong>Frameworks:</strong></p>

    <p>A framework provides scaffolding for an entire project, and may depend on multiple libraries and utilities. You should only ever need zero or one of these in your project. Examples: React, angular, express.</p>
  </li>
  <li>
    <p><strong>Plugins:</strong></p>

    <p>A plugin enhances a framework with additional, special-use functionality. For a plugin, the framework should be a peer dependency, not a true dependency. It might also depend directly on a library, or a handful of utilities. Examples: an angular component or a jquery plugin.</p>
  </li>
</ul>

<p>Obviously, the world is messy! I don’t expect 100% of packages to fit into such simple categories, nor are any of these definitions strict and unyielding. But overall, I’d hope <em>many</em> or even <em>most</em> packages to <em>mostly</em> conform to a categorization <em>something</em> like that, with most packages being utilities and libraries, and the fewest packages being frameworks.</p>

<h3 id="what-would-that-mean-statistically">What would that mean statistically?</h3>

<p>In a world where packages fit mostly into that hierarchy, a registry of many packages would have these qualities:</p>

<ul>
  <li>No dependency cycles</li>
  <li>Most packages would have dependency trees 0-4 levels deep, leaning towards lower numbers</li>
  <li>Even the deepest and broadest frameworks would depend on fewer than 250 packages, including dependencies of dependencies (3-4 steps deep, with 3-4 dependencies per package, &lt;= 4<sup>4</sup> max). Most packages would install well under 30 other packages. These numbers are extremely generous; smaller numbers would make me even happier.</li>
</ul>

<h3 id="what-do-we-actually-see">What do we actually see?</h3>

<p>I downloaded the metadata for all 1.3 million packages in the npmjs.org repository and attempted to crunch some numbers. (For more technical details on how I did this, see the final section, titled “Appendix: Methods”)</p>

<p>I’m going to use “the number of other packages that depend on this one” as a poor-man’s proxy for how popular a package is. It’s not a <em>good</em> proxy, but neither is the other common choice: the number of downloads (see the section <a href="https://packaging.python.org/guides/analyzing-pypi-package-downloads/#background">“Background”</a>, from PyPI). The number of downloads would have been much more computationally expensive to acquire, so I used dependents.</p>

<h3 id="circular-dependencies">Circular dependencies</h3>

<p>Of those 1.3 million packages, 1,700 depend directly on themselves, either perfectly circularly, or a different version of the same package. I have no explanation for that.</p>

<p>2500 packages are part of a two-package dependency cycle.</p>

<p>Then ~500, ~125, and ~25 are part of 3-, 4-, and 5-package cycles, respectively. (These are not always simple circles; it may be three codependent packages in any loopy arrangement)</p>

<p>My immediate reaction was that those numbers seemed like good news; out of a million packages, only a tiny percentage of oddball packages have circular dependencies, and the rest are fine. Right?</p>

<p>Unfortunately, what I discovered was that almost 150,000 packages — more than 1 in 10 — had at least one of these circular dependencies <em>somewhere</em> in their dependency graph. That means at least a few of those “oddballs” are actually major, highly-referenced packages. Some examples:</p>

<ul>
  <li><code>babel-core</code> depends on <code>babel-register</code>, which depends on <code>babel-core</code>.</li>
  <li><code>yeoman-generator</code> depends on <code>yeoman-environment</code> which depends on <code>yeoman-generator</code>.</li>
</ul>

<p>Those are not isolated instances; I plucked them as the most easily recognizable out of a list of dozens of highly-depended-upon packages with circular dependencies.</p>

<p>I need to be clear, here, that this is not <em>technically</em> a problem! <acronym>npm</acronym> can install these packages just fine. They can circularly-depend on one another; there’s no technical problem. They work. Obviously. If <code>babel-core</code> didn’t work, someone would have said something by now.</p>

<p>But I’m not particularly comfortable with it. I’m especially uncomfortable when the cycles involved are longer than two packages, which makes them seem less intentional. Maybe there’s a good reason; these folks are smart, and I always try to assume that odd choices were made for important reasons. And yet…</p>

<h3 id="what-about-devdependencies">What about <code>devDependencies</code>?</h3>

<p>Among the most-depended-upon packages are</p>

<ul>
  <li><code>@types/</code>[something]</li>
  <li>compilers like <code>typescript</code> and <code>babel</code></li>
  <li>build systems like <code>gulp</code> and <code>webpack</code>.</li>
</ul>

<p>I’m <strong>not</strong> measuring that using <code>devDependencies</code> — <code>typescript</code> appears in over 12,000 “dependency” lists.</p>

<p>So while I am less concerned with packages having large and deep <code>devDependency</code> trees (I <em>am</em> still concerned, but less so), it seems that a large proportion of packages aren’t making use of the distinctions between <code>dependencies</code> and <code>devDependencies</code> in the first place. That <em>is</em> concerning.</p>

<h3 id="dependency-tree-depths">Dependency tree depths</h3>

<p>I am defining the depth of a package’s dependency tree as the longest dependency-of-a-dependency-of-a-dependency chain I can find. Especially deep dependency trees are a problem because of how difficult they make it to audit all the packages that will get installed when including a single new package.</p>

<p>The <em>average</em> dependency tree depth in npmjs.org is just under 4. Which doesn’t sound too bad!</p>

<p>As often happens, though, the mean does not tell the whole story. Almost half of all packages have no dependencies at all — which is a good thing! — but all those zeros dramatically drop the average of the packages that <em>do</em> have dependencies.</p>

<p>If we charted of the number of packages with each dependency tree depth greater than zero, then based on the idealized registry I imagined above, here’s what I’d hope to see:</p>

<p><strong>Imagined:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_ideal.svg" alt="Imaginary chart of package counts per tree depth"></p>

<p>And here’s what we actually get:</p>

<p><strong>Reality:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth.svg" alt="Real chart of package counts per tree depth"></p>

<p>Remember that we were hoping for mostly 2, 3, and 4. Instead, there is still a long tail of packages with tree depths <em>above 20</em>. 20 is… much larger than I was expecting, and I was expecting to be disappointed.</p>

<p>But let’s re-use the “oddball” theory: perhaps all those packages with extremely deep dependency trees are rarely used, and not worth worrying about. Let’s check.</p>

<p>Here’s a scatterplot, where each package is placed based on its tree depth plotted and how many other packages reference it. On the right of the plot are the most-referenced (~popular) packages; on the top are the deepest dependency trees. Again, my hopes first:</p>

<p><strong>Imagined:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_and_dependents_ideal.svg" alt="Imaginary scatterplot of package counts per tree depth"></p>

<p>Followed by reality:</p>

<p><strong>Reality:</strong></p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_tree_depth_and_dependents.svg" alt="Real scatterplot of package counts per tree depth"></p>

<p>There are heaps of 10+ tree-depths up among even the most popular packages, and a few even reach 20+. Extremely deep trees are not just a problem of “oddball” packages.</p>

<h3 id="direct-dependencies-branching-factor">Direct dependencies (branching factor)</h3>

<p>The average number of direct dependencies (among packages with any dependencies at all) is 5. That, by itself, doesn’t seem to bad. It feels a little alarming when combined with high tree depths, though. Does that mean some of these packages have 5<sup>10</sup> total dependencies? (Spoiler: no.)</p>

<p>Here’s a graph of how many packages have 1 dependency, 2 dependencies… up to 30 — a nice, neat exponential decay.</p>

<p><img src="https://sambleckley.com/assets/images/npm_packages_per_direct_dependencies.svg" alt="Chart of package counts per direct dependencies"></p>

<p>This curve is clean enough that I would not be surprised to see something pretty similar in any package registry — maybe not the exact same parameters, but a similar shape. Not shown here is an <em>incredibly</em> long tail; there are 4 packages tied for the most direct dependencies with exactly 1000, and there are runners-up spread pretty smoothly up to that maximum.</p>

<h3 id="indirect-dependencies">Indirect dependencies</h3>

<p>Knowing the average depth and branching factor, you have to imagine that counting the total dependencies of each package, including dependencies-of-dependencies, is not going to yield good news. But many of the branches of a large dependency tree are shared — multiple packages in the tree all depend on the same library. And the tree depth I have measured is the <em>maximum</em> depth for each package — not the average. So the picture is not necessarily as dire as an initial …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sambleckley.com/writing/npm.html">https://sambleckley.com/writing/npm.html</a></em></p>]]>
            </description>
            <link>https://sambleckley.com/writing/npm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23678409</guid>
            <pubDate>Mon, 29 Jun 2020 15:21:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Klutz Press: books built for learning stuff]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23676862">thread link</a>) | @whatrocks
<br/>
June 29, 2020 | https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>Create wonderful things, be good, have fun</p>
</blockquote>
<p>This is the credo of Klutz Press, the most important book publisher of my childhood. It being summer and all, Hobbes, ol' buddy... let's going exploring!</p>
<h2>What makes a Klutz Press book so good for learning stuff?</h2>
<p>If you've heard of Klutz, then you've likely seen their debut: <a href="https://www.amazon.com/gp/product/0932592007/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0932592007&amp;linkId=adaa512e8af09feab7c571ec8f2863cc">Juggling For the Complete Klutz</a>. </p>
<p><span>
      <a href="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/1cfc2/juggling.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="juggling" title="juggling" src="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/a6d36/juggling.png" srcset="https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/222b7/juggling.png 163w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/ff46a/juggling.png 325w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/a6d36/juggling.png 650w,
https://www.charlieharrington.com/static/c28fcf440265c6bea76d51f90e51b462/1cfc2/juggling.png 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>If not, I highly suggest seeking out a copy. Keep in mind, it's more than just a <em>book</em> -- <em>Juggling for the Complete Klutz</em> has these amazing attributes:</p>
<ul>
<li>It's spiral-bound</li>
<li>It has hilarious drawings</li>
<li>It comes attached with three real-life bean bags!</li>
</ul>
<p>These are book super-powers, in my book (a Klutz-worthy pun?). In our day, my sister and I owned, devoured, and treasured these Klutz titles:</p>
<ul>
<li><a href="https://www.amazon.com/gp/product/0932592082/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0932592082&amp;linkId=5bb878d785a02edc2b01eeffd63f9a76">Country and Blues Harmonica for the Musically Hopeless</a> (comes with instructional cassette and a gen-u-ine Hohner harmonica)</li>
<li><a href="https://www.amazon.com/gp/product/1591747007/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1591747007&amp;linkId=bf0dda95c016b59824316ebe42f872ec">Friendship Bracelets Craft Kit</a> (comes with string and supplies for making friendship bracelets)</li>
<li><a href="https://www.amazon.com/gp/product/1878257501/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257501&amp;linkId=7315967f85fba1c812b20b480b0bd966">Table Top Football: A Guide to the Classic Lunchroom Sport</a> (comes with an amazing leather-ish table top football)</li>
<li><a href="https://www.amazon.com/gp/product/1878257536/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257536&amp;linkId=58c3235cd298baf5ec29fb13ee806ced">Cats Cradle</a> (comes with a tie-die cat's cradle string)</li>
<li><a href="https://www.amazon.com/gp/product/1591745047/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1591745047&amp;linkId=905fbe99f4844c375f00baa92f1beee0">Bead Loom Bracelets: Learn to Make Beautiful Beaded Bracelets</a> (comes with beads and string)</li>
<li><a href="https://www.amazon.com/gp/product/1878257412/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257412&amp;linkId=d283508248a4016cd908bd8e37fcea68">Kids Shenanigans</a> (comes with a Whoopie cushion!)</li>
<li><a href="https://www.amazon.com/gp/product/1878257749/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257749&amp;linkId=99f448476dd4b6ce6baae76dbf048446">Earthsearch: A Kid's Geography Museum in a Book</a> (comes with interactive spinners, a sand-powered clock, and a real-life penny)</li>
<li><a href="https://www.amazon.com/gp/product/1878257145/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1878257145&amp;linkId=6b93493aa3d2cd5660e5e24c404ad5e6">Explorabook: A Kid's Science Museum in a Book</a> (comes with a bunch more interactive projects and whatnots inside the book, like mirrors, spinners, and a packet of algae that you can grow)</li>
</ul>
<p>As a kid, there was nothing better than getting a new Klutz book (ok, maybe a Super Nintendo game). But unlike a replay of <em>Super Mario RPG</em>, these Klutz books require no nostaglia goggles. Here's why I think they're magic:</p>
<h3>Klutz books are spiral-bound</h3>
<p>Books for learning stuff should be able to open up and stay flat. The old 1980s computer manuals for computers like the Commodore VIC-20, the Commodore 64, and <a href="https://www.charlieharrington.com/my-new-old-apple-iie-computer">my new old Apple IIe</a> knew this much -- their manuals were spiral-bound and spell-binding.</p>
<p>So, why don't we see more spiral-bound books? Without knowing that much about printing costs, I imagine they're more expensive. Also, they do look slightly worse on a bookshelf, especially if you're going for that 'grammable color pattern look (so, just don't do this).</p>
<h3>Klutz books come with the required materials</h3>
<p>The little "paper" football that came with the <em>Table Top Football: A Guide to the Classic Lunchroom Sport</em> was a revered grail of mine. I remember that my dad took a sheetrock knife and made a small incision in its plastic case attached to the book so that the football could be slid in and out, with the explicit rule that the football must either be <em>in the case</em> or <em>being used in a game</em>. This is much like the inexorable <a href="https://hypercritical.co/">Jon Siracusan</a> rule for Airpods. Obey, or the Airpods will be instantly lost forever.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="football" title="football" src="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg" srcset="https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/d2f63/football.jpg 163w,
https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/c989d/football.jpg 325w,
https://www.charlieharrington.com/static/e4a351feccb1c6d3e7524fa014860c7c/20f07/football.jpg 334w" sizes="(max-width: 334px) 100vw, 334px" loading="lazy">
  </a>
    </span></p>
<p>Side note that there are some people who just love making small cuts into the plastic cases for things, so that you easily return them to their "pristine" condition. I, myself, don't understand these people. I like wripping these cases to shreds instantly.</p>
<p>Anyway, back to these Klutz books. By including juggling bean bags, yarn for friendship bracelets, or a real harmonica, Klutz Press books gave you everything you needed to get your hands dirty. "Active learning", or something like that. Playing = learning. Etcetera.</p>
<h3>Klutz books have hilarious art</h3>
<p><span>
      <a href="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="shenanigan" title="shenanigan" src="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg" srcset="https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/d2f63/shenanigan.jpg 163w,
https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/c989d/shenanigan.jpg 325w,
https://www.charlieharrington.com/static/6c99ba6e2419ae976e32b7e293532a7a/20e5d/shenanigan.jpg 450w" sizes="(max-width: 450px) 100vw, 450px" loading="lazy">
  </a>
    </span></p>
<p>Just look at that paper airplane stuck in the teacher's hair!</p>
<p>Klutz had a particular art direction that spoke to me as a child. The goofy people in their guides made me feel like it was <em>okay to be a klutz</em>. </p>
<p>Which brings me to the most important reason that Klutz books are special.</p>
<h3>Klutz books embrace the Beginner's Mindset</h3>
<blockquote>
<p>In the beginner's mind there are many possibilities. In the experts mind there are few - Shunryū Suzuki</p>
</blockquote>
<p>Everyone starts out as a klutz. No matter what. That means it's okay to make mistakes. It can even be funny - in fact, it should be funny! Because it's fun to learn new things.</p>
<p>Being a klutz, making mistakes, having fun, this is the path to wonderful things.</p>
<h2>Who's behind Klutz Press?</h2>
<p>According to <a href="https://en.wikipedia.org/wiki/Klutz_Press">Wikipedia</a>, Klutz Press was founded in 1977 by three friends in Palo Alto.</p>
<p>The apocryphal story is that <a href="https://en.wikipedia.org/wiki/John_Cassidy_(author)">John Cassidy</a>, a recent Stanford grad working as a high school teacher, brought a bucket of tennis balls and some hand-written instructions for juggling to his remedial reading class. The laughs and learning and genuine reading and genuine juggling that ensued inspired Cassidy and his buddies from Stanford to publish <em>Juggling For the Complete Klutz</em> under their new company: Klutz Press.</p>
<p><em>Juggling For the Complete Klutz</em> has sold over 2.5 million copies. But Googling for Klutz Press is somewhat challenging these days. In 2000, Klutz was acquired by a company called Nelvana for $74 million, and in 2002 Klutz became a subsidiary of Scholastic, Inc. This latter merger is a good match in my book, as the Scholastic Book Fair also ranks heavily in my childhood memories of learning to love reading. The only other company I'd feel comfortable with owning Klutz Press is Pizza Hut - thanks to their delicious <a href="https://www.bookitprogram.com/">BOOK-IT!</a> reading program, which brought me dozens of delicious cheese Personal Pan Pizzas during the 1990s. My parents couldn't decide if they hated or loved Pizza Hut for this.</p>
<p>Nowadays, Klutz.com redirects to the Scholastic website, and it's unclear what's out-of-print or available from the voluminous Klutz catalog. So if you do find a genuine Klutz book and kit, I'd snag them quickly!</p>
<p>Luckily, I was able to find a good interview with Cassidy from 1995 on the <a href="https://web.archive.org/web/20110616182712/http://findarticles.com/p/articles/mi_m1154/is_n5_v83/ai_16857996/">Wayback Machine</a>. In 1995, Klutz was at the height of their power and influence in kid's minds. Here are some choice quotes from Cassidy:</p>
<p>On their company culture at Klutz Press:</p>
<blockquote>
<p>"In terms of being laid back, we take a back seat to nobody."</p>
</blockquote>
<p>On their "teaching" style:</p>
<blockquote>
<p>"Talk to a kid about fun and math, and it's like you're talking about two different sides of the universe. If we can climb this mountain, there's nothing we can't tackle."</p>
</blockquote>
<blockquote>
<p>"Kids don't learn all that much by listening or reading. They need to get elbow-deep in a subject and touch it, feel it, and smell it."</p>
</blockquote>
<p>This reminds me of Seymour Paypert's <a href="https://www.amazon.com/gp/product/0465046746/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0465046746&amp;linkId=2949aefc36d4bd9d9f632170d2ac23de">Mindstorms book</a> about his work with LOGO and the Turtle machine (you can check out <a href="https://www.charlieharrington.com/mindstorms">my notes</a> on the book)</p>
<p>The article explains a bit about their business:</p>
<ul>
<li>All of Klutz' books sell for less than $20</li>
<li>They can have low prices because: (1) the books (with their accompanying "stuff") are viewed as more than books - but "toys/novelties", so more retailers than booksellers are interesting in carring them, and (2) they do large printing runs (150k copies vs the usual 10k for children's books)</li>
</ul>
<p>And, importantly, the final word from Cassidy:</p>
<blockquote>
<p>"I can hang a spoon off my nose," Cassidy boasts, "and I take a lot of pride in that".</p>
</blockquote>
<h2>Create wonderful things, be good, have fun</h2>
<p>I just wanted to write that out again. I've decided to adopt their credo as my own life motto.</p>
<p>I learned so much from Klutz Press as a kid. I'm still learning now. Thank you, John Cassidy and team, for making these wonderful books. My juggling is finally starting to get pretty good, but I'll always be a klutz.</p></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676862</guid>
            <pubDate>Mon, 29 Jun 2020 12:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping Anything with BSicons]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23676585">thread link</a>) | @zetter
<br/>
June 29, 2020 | https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/ | <a href="https://web.archive.org/web/*/https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>If you go to the Wikipedia page for the <a href="https://en.wikipedia.org/wiki/Forth_and_Clyde_Canal">Forth and Clyde Canal</a>, the <a href="https://en.wikipedia.org/wiki/Trans-Siberian_Railway">Trans-Siberian Railway</a> or <a href="https://en.wikipedia.org/wiki/Circle_line_(London_Underground)">the London Circle Line</a> you may notice that they all have route maps with a similar visual style.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicons.png" alt="A diagram of the Glasgow subway loop that shows the route of the subway alongside station names and connecting rail services">
  
  <figcaption>A route map of the <a href="https://en.wikipedia.org/wiki/Glasgow_Subway">Glasgow subway</a> from Wikipedia.</figcaption>
</figure>

<p>How do the many Wikipedia contributors create all these similar-looking maps? The answer is <strong>BSicons</strong>.</p>

<h2 id="bsicons">BSicons</h2>

<p><a href="https://commons.wikimedia.org/wiki/BSicon">BSicons</a> are the building blocks for these route maps. They are an SVG icon set that Wikipedia contributors use to map railways, subways, footpaths, waterways, cycle paths and roads. Any transport system that they want to produce a simplified schematic for.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicon_grid.png" alt="A diagram of the Glasgow subway. The diagram is made up of square icons in a grid which is highlighted">
  
  <figcaption>The Glasgow subway map is made up of many BSicons icons. Most are square, but there are a few half-width icons too that allow for a more compact map.</figcaption>
</figure>

<p>The icons were first used on the German Wikipedia which is why most of their names are based on German words.
‘BSicons’ comes from the German word Bahnstrecken (Railway Lines).</p>

<p>Each icon has a shorthand name that follows some conventions:</p>
<ul>
  <li>A <strong>Root</strong> picks a given icon such as a station or a crossing.</li>
  <li><strong>Prefixes</strong> change it’s status, such as if it’s underground or disused.</li>
  <li><strong>Suffixes</strong> denote direction and positioning, such as if it curves to the left or is one way.</li>
</ul>

<p>Here are some of the icons:</p>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_STR.svg">
    <h3>STR</h3>
  </header>
  <p>A rail line</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_WASSER.svg">
    <h3>WASSER</h3>
  </header>
  <p>A river or other waterway</p><p>
  Root: WASSER (water)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_KRZu.svg">
    <h3>KRZu</h3>
  </header>
  <p>Two rail lines crossing with one going under the other</p><p>
  Root: <b>KRZ</b> → <b>KR</b>eu<b>Z</b>ung (crossing)<br>
  Suffix: <b>u</b> → <b>u</b>nter (under)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_STR%2Bl.svg">
    <h3>STR+l</h3>
  </header>
  <p>A rail line that comes from the left</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)<br>
  Suffix: <b>+l</b> → <b>+</b> (from), <b>l</b>inks (left)</p><p> Directions are relative to the line (which is drawn from top to bottom) rather than the page. This is why the suffix says the line is from the left rather than going to the right.</p>
</div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_utkBHF%2B1.svg">
    <h3>utkBHF+1</h3>
  </header>
  <p>A station on an underground light rail line that comes from the first corner</p><p>
  Root: <b>BHF</b>  →  <b>B</b>ahn<b>H</b>o<b>F</b> (station)<br>
  Prefix: <b>utk</b> → <b>u</b>-bahn, <b>t</b>unnel, <b>k</b>ombination (Compound)</p><p>the <b>k</b> denotes that the icon is for drawing compound turns that span four columns of icons.</p>
</div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_RP2r.svg">
    <h3>RP2r</h3>
  </header>
  <p>A two-lane paved road with a roundabout</p><p>
  Root: <b>RP2</b> → <b>R</b>oad <b>P</b>aved <b>2</b>-lane<br>
  Suffix: <b>r</b>  → <b>r</b>oundabout<sup id="fnref:clash"><a href="#fn:clash">1</a></sup><br>
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_tSTRa.svg">
    <h3>tSTRa</h3>
  </header>
  <p>A rail line that goes into a tunnel</p><p>
  Root: <b>STR</b> → <b>STR</b>eke (line)
  Prefix: <b>t</b> → <b>t</b>unnel<br>
  Suffix: <b>a</b> → <b>a</b>nfang (start)
</p></div>

<div>
  <header>
    <img src="https://chriszetter.com/assets/bsicons/BSicon_mhKRZho.svg">
    <h3>mhKRZho</h3>
  </header>
  <p>An elevated rail line going over a light elevated rail line</p><p>
  Root: <b>KRZ</b> → <b>KR</b>eu<b>Z</b>ung (crossing)<br>
  Prefix: <b>mh</b> → <b>m</b>ischbetrieb (mixed), <b>h</b>ochbahn (high level/elevated)<br>
  Suffix: <b>ho</b> → <b>h</b>ochbahn (high level/elevated), <b>o</b>verpass
</p></div>

<p>These are a few examples. The <a href="https://commons.wikimedia.org/wiki/BSicon/Catalogue">BSicon Catalogue</a> explains many more conventions.</p>

<h2 id="building-maps">Building maps</h2>

<p>To help put all these icons together into a map Wikipedia has a <a href="https://en.wikipedia.org/wiki/Template:Routemap">Routemap template</a>. The template defines a syntax to provide shortcuts to build maps.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/glasgow_subway_bsicons_row.png" alt="A diagram of the Glasgow subway loop that shows one line of icons highlighted.">
  
  <figcaption>Routemaps are made up of rows of icons </figcaption>
</figure>

<p>Here is the code used to generate the single highlighted row:</p>

<div><div><pre><code>
{{Subway|Hillhead}}! !\utkBHF+1\\\utkBHF+4\tSTRa~~{{Subway|St George's Cross}}

</code></pre></div></div>

<p>The syntax is a bit cryptic and uses the shorthand icons names we saw above. Here is what each part does:</p>

<ul>
  <li><strong><code>{{Subway|Hillhead}}</code></strong> is a link to the Wkipedia article about this station</li>
  <li><strong><code>! !</code></strong> separates the text on the left from the icons</li>
  <li><strong><code>\utkBHF+1</code></strong> is the first icon a light rail station in a tunnel that curves</li>
  <li><strong><code>\\</code></strong> adds in two empty icon-sized spaces</li>
  <li><strong><code>\utkBHF+4</code></strong> adds in the second icon, similar to the last but towards top-left corner</li>
  <li><strong><code>\tSTRa</code></strong> adds in the third icon, a start of a stretch of tunnel</li>
  <li><strong><code>~~~</code></strong> separates the icons from the text on the right</li>
  <li><strong><code>{{Subway|St George's Cross}}</code></strong>  a link to the Wikipedia article about this station.</li>
</ul>

<h2 id="hundreds-of-thousands-of-icons">Hundreds of thousands of icons</h2>

<p>There are <a href="https://commons.wikimedia.org/w/index.php?title=Special:Search&amp;search=File%3A+intitle%3A%22BSicon%22+intitle%3A%2FBSicon+.%2A%5C.svg%2F&amp;ns0=1&amp;ns6=1&amp;ns12=1&amp;ns14=1&amp;ns100=1&amp;ns106=1">more than 290,000 BSicons</a> out there due to an explosive number of combinations needed for different colours, rotations, intersections, bridges, curves, embankments and tunnels. Many obscure BSicons might only be used a few times across Wikipedia (like <a href="https://commons.wikimedia.org/wiki/File:BSicon_BHFABZgl%2Bl.svg">BHFABZgl+l</a>)<sup><a href="#fn:triangle">2</a></sup>.</p>

<p>Each icon is simple, so simple many of them are marked as ineligible for copyright on Wikipedia. Together the icons can combine to map more complex systems.
Seeing how these icons can be combined inspired me to make a <strong><a href="https://mapmaker.chriszetter.com/">random BSicon map generator</a></strong>.</p>

<figure>
  
  <img src="https://chriszetter.com/assets/bsicons/tiles-random-2.png" alt="A gird of icons showing train lines crossing over and under each other with stations.">
  
  <figcaption>A random tiling image made by my <a href="https://mapmaker.chriszetter.com/">random map generator</a></figcaption>
</figure>



</div></div>]]>
            </description>
            <link>https://chriszetter.com/blog/2020/06/25/mapping-anything-with-bsicons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676585</guid>
            <pubDate>Mon, 29 Jun 2020 11:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Antic Cyber Graphics Software (2002)]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23676333">thread link</a>) | @pavlov
<br/>
June 29, 2020 | https://doudoroff.com/atari/ | <a href="https://web.archive.org/web/*/https://doudoroff.com/atari/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="frame">

<div id="contentcenter">

<p><img src="https://doudoroff.com/atari/gfx/masthead-large.gif" alt="(Masthead) The Antic Cyber Graphics Software and the Pre-History of Autodesk 3D Studio and Discreet 3ds max" width="785" height="86">
		
<img src="https://doudoroff.com/atari/gfx/anthrobot_02.gif" width="275" height="186" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_03.gif" width="369" height="84" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_05.gif" width="227" height="132" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_07.gif" width="292" height="95" alt=""><img src="https://doudoroff.com/atari/gfx/anthrobot_09.gif" width="217" height="45" alt=""></p><p>By Martin Doudoroff<br>Edited by Monica J. Smith</p>


<p>This Web site documents some moderately obscure computer graphics software history: a suite of animation products produced in the late 1980’s for the Atari ST personal computer platform. Although the fact is not widely known, this Atari software, published by a defunct computer magazine called Antic, directly preceded and led to the Autodesk 3D Studio and Discreet 3ds max products used by thousands of people today.</p>
<p>The articles herein basically comprise an oral history: the information is drawn from interviews and hands-on exploration of the software, running under emulation or on original equipment.</p>
<p>The site is organized into a chronological history, followed by in-depth discussions of each major product.</p>


<p>Thanks to my editor, Monica Smith, for making this documentation more respectable.</p>
<p>Thanks to Gary Yost, Tom Hudson, Mark Kimball, Jim Kent, Andy Eddy, Maurice Molyneaux, Boris Tsikanovsky, Darrel Anderson, and Jack Powell for their enthusiastic participation in this project, which is really their project.</p>
<p>Thanks to James Green and Heidi Brumbaugh for their assistance.</p>
<p>Special thanks to Tom Hudson, Corey Kaup, Mike Mee (Liverpool), Tim Forcade, Richard Davey (<a href="http://www.atari.st/">The Little Green Desktop</a>) and Kevin Savetz (<a href="http://www.atarimagazines.com/"><em>Classic Computer Magazine Archive</em></a>) for their invaluable technical assistance and resources.</p>



		
</div>

<!--<br clear="all" />--><!-- without this little BR, NS6 and IE5PC do not stretch the frame div down to encopass the content DIVs -->




</div></div>]]>
            </description>
            <link>https://doudoroff.com/atari/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676333</guid>
            <pubDate>Mon, 29 Jun 2020 10:57:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurons that fire together, wire together, but how?]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23676233">thread link</a>) | @Anon84
<br/>
June 29, 2020 | http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/ | <a href="https://web.archive.org/web/*/http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="et-boc">
			
			<div><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div>
					
<p>One of my little pet projects is a neurology book for psychologists, coaches and the like. What most people in these fields imagine about the brain is somewhere between perplexing, preposterous and potentially poisonous. (Seriously, I could tell you stories…) So I kind of wanted to write something like this for them.</p>
<p>Now I do consider it a tall order for me – I have some knowledge of neurology, but actually writing a SENSIBLE, understandable guidebook to neurology, with some practical applications too, that’s a challenge. (Senseless guidebooks to neurology are a dime a dozen, of course. In fact, I’ve walled in at least two people in one library, using only senseless pop-neurology books and as far I can tell, the rotting skeletons still haven’t been found. But then again the rotting corpse smell really doesn’t stand out much in most libraries I’ve been to, so I shouldn’t be surprised.)</p>
<p><a href="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg"><img src="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg" alt="" width="1920" height="1280" srcset="http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920.jpg 1920w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-300x200.jpg 300w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-768x512.jpg 768w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-1024x683.jpg 1024w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-1080x720.jpg 1080w, http://dissociativediaries.com/wp-content/uploads/2019/02/neuron-3567980_1920-610x407.jpg 610w" sizes="(max-width: 1920px) 100vw, 1920px"></a></p>
<p>But back to my main point. The great thing about trying to write a book like that, even attempting to prepare for doing it at one point in the future, when you know enough, is finding all the lovely little holes in how you’re telling the story to yourself. The teeny-tiny little jumps in understanding, the „lies-to-children”, the simplifications.</p>

<p>And one of these, for me, was how neurons get to connect.</p>

<p>And when I asked around, it turned out I wasn’t the only one missing this little bit.</p>

<p>I mean, yeah, we all know Hebb. „Neurons that fire together, wire together”, the neurology mantra in flesh. I can just imagine NeuroZen masters, walking around meditating neurologists, „fiiiiiiiiireeee toooooogeeeether” instead of „ommmm” going around.</p>

<p>That’s how neurons connect. When two fire at once, their connection becomes stronger. The synapse gains long term potentiation/LTP, by both an increase in the neurotransmitters produced, and an increase in the postsynaptic receptors for the neurotransmitters. Short-term it happens through utilizing some of the additional AMPA receptors available near to the synaptic membrane in the postsynaptic cell, long term by changes in protein synthesis and gene expression, in order to ensure a larger number of receptors. So far so good, in one way or another pretty much anyone who understands anything about neurology understands this bit. It might be more or less simplistic, you might have the AMPA receptors memorized or not, but you get the gist of it.&nbsp;(Although this begs the question: does Dale’s principle means that the increase in presynaptic neurotransmitter production influence not just this single synapse, but also the concentration of neurotransmitters in all synaptic connections of the presynaptic neuron? Or perhaps does a reverse mechanism happen, with other connections of the presynaptic neuron being stripped bare of their neurotransmitters? Something I need to check! )</p>

<p>Now here’s the kicker: how do neurons that AREN’T already connected connect? How does their “fire/wire” rule go?</p>

<p>I mean, that still applies, doesn’t it?</p>

<p>Actually, it doesn’t apply in the original Hebb’s law, since that required the neurons to be connected already and a couple of other things as well. But still, the general principle is how we tend to explain things like associative learning, conditioning, etc. The direct wording of Hebb’s law can’t apply there, because then we’d need every neural network to be connected to every other neural network at once, and that’d be a mess that wouldn’t really work all that well. But the general principle seems to apply.</p>

<p>And when I started asking around, no one could tell me how exactly.</p>

<p>How does a neuron know to extend new axonal or dendric connections towards another neuron, so that they might actually form a synapse between the two? Because this has to happen somehow, and this has to happen in a fairly structured way. If it didn’t happen, if we were only left to the remains of the synaptic pruning we got since birth, then our neural networks would become pretty much immovable after were what, twelve? I mean yeah, I’ve met these people, and so have you, but they’re in the small minority… well, large minority… well, OK, a small majority. But even so, there are quite a few people who aren’t that way. And if the neural growth was haphazard, then we’d get a far more random jumble of associations, then the fairly clean ones we tend to get in any conditioning/associative learning experiences.</p>

<p>So I knew there must be some kind of system for neurons to detect other neurons it should be „aiming for” in their development.</p>

<p>And – this was about two or three years ago as of writing this – no one I asked could tell me what it was. I’ve reached out to a lot of people I’ve considered very competent in the field, including some of my old Uni professors, and no one could direct me. Nor could I find the answer in any of the textbooks I’ve referred to.</p>

<p>As it turns out, the answer is fairly recent, as articles about it only started to appear in the 2000s. Since it took me some time to find it back then, I figured I’d make this article to share it now, making the whole thing easier to find for others.</p>

<p>We’ve known from about 1890 that the endings of both the axon and the dendrites are covered in something known as a growth cone. Like the tip of the branch, this is the part where the cell can further develop and extend, either in original growth, in regeneration, or as a reaction to some factors (including a decrease in overall electric activity which causes a form of synaptic scaling – hence explaining the „devouring” of unused neural pathways of amputated body parts by nearby active structures). But how do the growth cones know how exactly to grow? The brain is a complex three-dimensional web of interconnected neurons, so „hitting” the right point is definitely too hard if the neurons just kept on growing until they hit anything at all.</p>

<p>Now, the synaptic scaling process is still a piece of the answer – even if a neuron forms a new synaptic connection with a different neuron, if the target neuron already has too many connections, it will tend to remove the weakest ones, and this includes the most recent ones. The scaling goes both ways after all – it goes for more synapses when it starts with too few, but for less, if it starts with too many.</p>

<p>But synaptic scaling is not everything. As it turns out, the tips of the growth cone constantly produce structures called filopodia, and these react to specific chemical attractants and repellents. These chemicals are produced by both cells at the target area, and by so-called guidepost cells along the way. There are suggestions that the system for such targeting is fairly robust, especially in early development (and its limitations in later life might explain why spinal cord injuries and the like are so hard to fix).</p>

<p>(There is one other process for directing cells, the growth along the radial glia, but since it mainly refers to embryonic development, it’s really not all that interesting for us in this topic.)</p>

<p>Now, the more perceptive of you will already have noticed that while what I’ve given is AN answer, it is not THE answer to the question I’ve originally asked. Or at least, not necessarily.</p>

<p>It might be possible, that the interaction of the three systems:<br>– a pre-set network of attractor/repellent chemical pathways for guiding axon/dendrite growth,<br>– the synaptic scaling mechanism of homeostatic plasticity, which limits the max connections and promotes new connections if existing neural excitability falls below what is the baseline for the network,<br>– and the good old Hebbian mechanism for strengthening existing neural connections,<br>is in fact enough. That the interplay of these systems does answer our basic question, and simple enough rules result in sufficient flexibility to explain what is observed.</p>

<p>But, obviously, the process might be a bit more complicated. There isn’t that much literature about it, unfortunately, so what I’m doing here is more of an (un)educated guess, but since guidepost cells tend to be neurons which have yet to develop an axon – but already have dendrites and can receive signals, a slightly more complex – but better targeted – system can be imagined, where guidepost cells would be a part of a wider neural network, the stimulation of which „calls forth” further cells to build connections. This, in my understanding (Again, limited, so don’t take my word for it. I mean it.) would be a more effective explanation of how we can rapidly learn to connect fairly new information, even across huge (neurologically-scaled) swaths of neural space. A strongly agitated system produces a stronger „call for connections”, hence mediating the faster development of new and broader associations.</p>

<p>So there you have it, a quick summary of one part of neural connectivity I’ve yet to see described in a textbook about the brain, but which really should be given out there, along with the classic Hebbian principle. Hope it’s useful 🙂</p>
				</div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->			</div>
			
		</div>					</div></div>]]>
            </description>
            <link>http://dissociativediaries.com/neurons-that-fire-together-wire-together-ok-but-how/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676233</guid>
            <pubDate>Mon, 29 Jun 2020 10:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has GitHub been down more since its acquisition by Microsoft?]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 138 (<a href="https://news.ycombinator.com/item?id=23676199">thread link</a>) | @tdrnd
<br/>
June 29, 2020 | https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/ | <a href="https://web.archive.org/web/*/https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				    
				<div>
    <article id="post-775">
	
	            
            

                
        <div>
                        
            
            
<p>Two years ago, on June 4th of 2018, Microsoft announced its acquisition of GitHub, unicorn darling of the developer tools startup ecosystem, <a rel="noreferrer noopener nofollow" href="https://techcrunch.com/2018/06/04/microsoft-has-acquired-github-for-7-5b-in-microsoft-stock/" target="_blank" data-wpel-link="external">for $7.5B in stock</a>. The announcement unearthed a wide range of <a href="https://news.ycombinator.com/item?id=17221527" data-wpel-link="external" target="_blank" rel="nofollow">opinions and pontifications</a>, ranging from “GitHub is doomed” to “Microsoft is smart”, with many predictions about GitHub’s future. Some thought Microsoft’s growing investments in its cloud offering, Azure, might help GitHub. Could an investment by Microsoft improve GitHub’s reliability or harden them against outages like <a href="https://www.wired.com/story/github-ddos-memcached/" data-wpel-link="external" target="_blank" rel="nofollow">DDOSes</a>? Have any of these predictions come true?</p>



<p>We set out to analyze one angle of the GitHub acquisition: Has GitHub become more reliable since its acquisition by Microsoft? Our service, <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>, monitors more than 700 status pages of cloud providers and SaaS companies large and small. We aggregate and normalize status page data and make it available to our subscribers however they need: in notifications by email, Slack, Teams, or webhook, and in a <a href="https://nimbleindustries.io/2020/01/24/how-to-save-precious-minutes-during-incident-response/" data-wpel-link="internal" rel="follow">unified status dashboard</a> for all service dependencies.</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png" alt="" srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1024x613.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-300x180.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-768x460.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-1536x919.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-720x431.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-580x347.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1-320x192.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-header-1.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For more than 5 years, we have analyzed the <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">GitHub status page</a> constantly. Every 5 minutes, StatusGator takes a screenshot and <a href="https://statusgator.com/services/github" data-wpel-link="internal" rel="follow">collects relevant data</a> about their service status. That means we are uniquely positioned to offer analysis of the downtime that GitHub themselves announce via their status page.</p>



<p>What does the data tell us? In the two years since the acquisition announcement, GitHub has reported a 41% increase in status page incidents. Furthermore, there has been a 97% increase in incident minutes, compared to the two years prior to the announcement. Does this actually point to a decrease in reliability? We can’t say. This could simply mean GitHub has increased its transparency, publishing to their status page more frequently.</p>



<h2>Incident Counts</h2>



<p>We calculated an incident count in the 24 months preceding the announcement and the 24 months after. We <a href="https://nimbleindustries.io/2019/12/26/under-the-hood-inside-a-status-page-aggregator/" data-wpel-link="internal" rel="follow">classify status pages</a> into four states: <em>up</em>, <em>warn</em>, and <em>down</em>, and <em>maintenance</em>. GitHub does not expose scheduled maintenance on their status page. For these calculations we consider an incident to be any change in status between <em>up</em> and <em>warn</em> or <em>down</em>.</p>



<p>Before the acquisition, there were 89 incidents published on the GitHub status page. After, there were 126 incidents. A 41% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png" alt="89 Incidents before the acquisition, 126 incidents after, a 41% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1024x422.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-300x124.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-768x316.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1536x633.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-2048x844.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-1920x791.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-720x297.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-580x239.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-counts-1-320x132.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident counts by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png" alt="Graph showing GitHub incidents by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1024x533.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-768x400.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-1536x799.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-720x375.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-580x302.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph-320x167.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-incident-graph.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<h2>Incident Minutes</h2>



<p>We calculated incident minutes by subtracting the start and end time of time of incidents. Although not 100% realtime, StatusGator checks frequently: every 5 minutes, so status page changes are detected quickly. We counted time where the page was not in an overall <em>up</em> state.</p>



<p>In the 24 months prior to the acquisition announcement, there were 6,110 minutes of downtime. During the 24 months after, there were 12,074 minutes of downtime, a 97% increase:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png" alt="6,110 Incidents before the acquisition, 12,074 incidents after, a 97% increase." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1024x420.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-300x123.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-768x315.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1536x630.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-2048x840.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-1920x788.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-720x295.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-580x238.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-counts-1-320x131.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In the graph below, we’ve charted the incident minutes by month. The left side shows the 24 months before and the right side shows the 24 months after:</p>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png" alt="Graph showing GitHub downtime minutes by month, before and after their acquisition by Microsoft." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1024x531.png 1024w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-300x156.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-768x399.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1536x797.png 1536w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-2048x1063.png 2048w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-1920x997.png 1920w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-720x374.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-580x301.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-downtime-minute-graph-1-320x166.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Status Page Evolution</h2>



<p>During these four years, GitHub has made enormous improvements in their status page information granularity and design. In December 2018, they switched from a home grown status page to one operated by Atlassian’s StatusPage service, <a href="https://nimbleindustries.io/2019/03/11/2019-statusgator-status-page-awards/" data-wpel-link="internal" rel="follow">the most popular status page provider</a>. In doing so, they added numerous <a href="https://nimbleindustries.io/2019/11/22/component-status-filtering-is-here/" data-wpel-link="internal" rel="follow">individual component statuses</a>. Here’s what GitHub’s status page looked like before their switch to Atlassian StatusPage:</p>



<h3>GitHub’s Old Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png" alt="GitHub status page showing only a single status across all GitHub services." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old.png 645w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-300x187.png 300w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-580x361.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-status-page-old-320x199.png 320w" sizes="(max-width: 645px) 100vw, 645px"><figcaption>GitHub status page showing only a single status across all GitHub services.</figcaption></figure>



<p>When they switched to their new status page format, GitHub took a huge step towards increased accountability and transparency by detailing the following individual service components:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Issues, PRs, Dashboard, Projects</li><li>Notifications</li><li>Gists</li><li>GitHub Pages</li></ul>



<p>Overtime, they have expanded and refined their component statuses. They also started showing historical data right on their status page. As you can see in their newest and most detailed status page format, it shows the following service component statuses:</p>



<ul><li>Git Operations</li><li>API Requests</li><li>Webhooks</li><li>Issues, PRs, Projects</li><li>GitHub Actions</li><li>GitHub Packages</li><li>GitHub Pages</li></ul>



<h3>GitHub’s New Status Page</h3>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png" alt="GitHub status page showing detailed statuses of each of the major components of their service." srcset="https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-944x1024.png 944w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-277x300.png 277w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-768x833.png 768w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-720x781.png 720w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-580x629.png 580w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new-320x347.png 320w, https://nimbleindustries.io/wp-content/uploads/2020/05/github-satus-page-new.png 1280w" sizes="(max-width: 944px) 100vw, 944px"><figcaption>GitHub status page showing detailed statuses of each of the major components of their service.</figcaption></figure>



<p>They also moved their status page to a dedicated domain, <a href="https://www.githubstatus.com/" data-wpel-link="external" target="_blank" rel="nofollow">githubstatus.com</a>, <a href="https://nimbleindustries.io/2020/04/21/your-status-page-deserves-its-own-domain/" data-wpel-link="internal" rel="follow">which follows a best practice we recommend</a> to anyone who hosts a status page. All of this additional transparency, details, and historical data is a commendable effort to relay the most up-to-date information about the status of all GitHub systems. More providers of critical cloud infrastructure should emulate what GitHub has done. <a href="https://nimbleindustries.io/2019/12/07/your-status-page-is-useless-if-you-dont-use-it/" data-wpel-link="internal" rel="follow">Your status page is useless if you don’t use it.</a></p>



<h2>Conclusion</h2>



<p>What can we conclude from all of this data? Objectively, we can conclude that GitHub has published to their status page more frequently in the two years after their acquisition announcement. They have posted more incidents of disruption and downtime. Those incidents have been longer in duration. According to the data they provided, GitHub has been down more since the acquisition by Microsoft. </p>



<p>But that could be all a part of coordinated effort to be more transparent about their service status, an effort that should be applauded.</p>



<p>Our goal at StatusGator is not to shame anyone for disruptions and outages. Everyone experiences unexpected downtime. We simply strive to make status page data available and accessible in more useful ways. From Slack and <a href="https://nimbleindustries.io/2020/04/03/status-page-monitoring-in-microsoft-teams/" data-wpel-link="internal" rel="follow">Microsoft Teams</a>, to <a href="https://nimbleindustries.io/2020/04/30/status-page-webhooks-new-and-improved/" data-wpel-link="internal" rel="follow">webhooks</a>, an API, and more. StatusGator aggregates status page data and empowers you to keep your team informed. </p>



<h2>Try StatusGator</h2>



<figure><img src="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png" alt="StatusGator logo" srcset="https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1024x175.png 1024w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-300x51.png 300w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-768x131.png 768w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-1920x329.png 1920w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-720x123.png 720w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-580x99.png 580w, https://nimbleindustries.io/wp-content/uploads/2019/03/logo-large-320x55.png 320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Is your team dependent on GitHub? Consider trying out <a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">StatusGator</a>,&nbsp;free for 30 days. You can get notifications about GitHub and more than 670 other services with status pages we monitor. You can receive notifications in Microsoft Teams, Slack, by email, SMS, or webhook. Our favorite feature is a Slack integration with a <code>/statuscheck</code> slash command that allows querying the status of any service, right from where your team hangs out.</p>



<p><a href="https://statusgator.com/" data-wpel-link="internal" rel="follow">Try a 30 day free trial</a>&nbsp;of StatusGator and let us know what you think.</p>

                        
                            
            
        </div>
        
                             
    </article>
</div>
				
								
							</div>

		
	



			

		</div></div>]]>
            </description>
            <link>https://nimbleindustries.io/2020/06/04/has-github-been-down-more-since-its-acquisition-by-microsoft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676199</guid>
            <pubDate>Mon, 29 Jun 2020 10:31:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arduino FIDO2 Authenticator]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 87 (<a href="https://news.ycombinator.com/item?id=23676006">thread link</a>) | @snakeye
<br/>
June 29, 2020 | https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/ | <a href="https://web.archive.org/web/*/https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<section>



<article>
<p>After publishing the URU Key project people keep asking me to make it open source. I have tried to organize sources in a more readable way but I still think that plain C and ESP IDF are too difficult for the broad audience. And, unfortunately, the biometrics part is covered by NDA and can not be published.</p>
<p>Therefore I am starting a new project to address these and other issues.</p>
<h2 id="size-and-form-factor">Size and form factor</h2>
<p>A few months ago I have finalized the <a href="https://en.ovcharov.me/2020/04/06/uru-key-final-hardware-design/">URU Key hardware design</a> and started working on housing for it. Yes, it is very small and lightweight but carrying it around is a kind of a problem. The device is too fragile to be worn on the keyring and a bit thick to put in the pocket. The necklace is not my style.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/31ed3b469871b100ae43a0dbae4930d2f3fb272b/61808/uploads/resized/uru-key-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-key-w150.jpg 150w, /uploads%2Fresized%2Furu-key-w300.jpg 300w, /uploads%2Fresized%2Furu-key-w600.jpg 600w, /uploads%2Fresized%2Furu-key-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Key with the battery" title="URU Key with the battery" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-key-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-key.jpg 1200w"><figcaption>URU Key with the battery</figcaption></figure>
<p>However, my wallet is always with me. The PCB sized as a standard credit card should perfectly fit there. The power source becomes a problem, that’s true. But, wait, is it difficult to find a charger or power bank with Micro USB nowadays?</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/1218f869b13f89ff97edd4cf56c554a12caa4e77/36a93/uploads/resized/uru-card-wallet-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, /uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, /uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, /uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card in the wallet" title="URU Card in the wallet" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-wallet-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-wallet.jpg 1200w"><figcaption>URU Card in the wallet</figcaption></figure>
<p>The name <strong>URU Card</strong> makes a lot of sense for this project, isn’t it?</p>
<h2 id="user-interface">User interface</h2>
<p>As on one hand, I can not use biometrics for open source project and on other hand, I do not want to omit the authentication completely leaving the device insecure there is a need for some form of user verification. Simple touch keyboard and OLED screen should allow people to enter pin code or password.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/421c686c17665f43cfbb25fd3059190a055e4ae5/b0f7c/uploads/resized/uru-card-2-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, /uploads%2Fresized%2Furu-card-2-w300.jpg 300w, /uploads%2Fresized%2Furu-card-2-w600.jpg 600w, /uploads%2Fresized%2Furu-card-2-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - touch keyboard and OLED screen" title="URU Card - touch keyboard and OLED screen" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-2-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-2.jpg 1200w"><figcaption>URU Card - touch keyboard and OLED screen</figcaption></figure>
<p>The keyboard should be implemented with the <strong>MPR121</strong> I2C touch-sensor controller, and the screen is a widely available <strong>OLED</strong> screen with the <strong>SSD1306</strong> controller. The screen is placed in the special cut in the PCB keeping the device thickness below 2 millimetres.</p>
<h2 id="framework-for-the-development">Framework for the development</h2>
<p>Fortunately, the <strong>Arduino</strong> framework is ported to the <strong>ESP32</strong> platform. There are hundreds of libraries for almost every use case and this factor should significantly simplify the project. There are libraries for <strong>ATECC508A</strong>, <strong>MPR121</strong> and <strong>SSD1306</strong> already. All that is needed is to wire everything together.</p>
<p>However, the Arduino IDE will be hardly usable for a project complex like this one. I am going to use Visual Studio Code + <strong>PlatformIO</strong> for the development and recommend others to do the same.</p>
<h2 id="the-current-state-of-the-project">The current state of the project</h2>
<p>At the moment the working <strong>BLE server</strong> with <strong>FIDO2</strong> endpoints is implemented. The device is “visible” and the computer connects to it in order to perform an authentication procedure. However, the commands are not implemented yet - it’s going to be the next step.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/42cf03f71cfe1940cec7bbce89f7b7689bcdc96f/5b9eb/uploads/resized/uru-card-3-w800.jpg" data-srcset="/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, /uploads%2Fresized%2Furu-card-3-w300.jpg 300w, /uploads%2Fresized%2Furu-card-3-w600.jpg 600w, /uploads%2Fresized%2Furu-card-3-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="URU Card - the components" title="URU Card - the components" srcset="https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Furu-card-3-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Furu-card-3.jpg 1200w"><figcaption>URU Card - the components</figcaption></figure>
<p>There is a PCB design as well and you can try to build the device, but do it on your own risk - it’s in a very early stage now.</p>
<h2 id="joining-the-project">Joining the project</h2>
<p>Sweetest part. The project is free to join for everyone. The minimal requirement is just an ESP32 development board like the one below.</p>
<figure>
<img src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-src="https://d33wubrfki0l68.cloudfront.net/69b040b8cb4968124bd224f9590788e74ac50f1d/f2b5c/uploads/resized/esp32-dev-board-w800.jpg" data-srcset="/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, /uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, /uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, /uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, /uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w" sizes="(max-width: 230px) 150px, (max-width: 380px) 300px, (max-width: 680px) 600px, (max-width: 880px) 800px, 1200px" alt="ESP32 development board" title="ESP32 development board" srcset="https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w150.jpg 150w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w300.jpg 300w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w600.jpg 600w, https://en.ovcharov.me/uploads%2Fresized%2Fesp32-dev-board-w800.jpg 800w, https://en.ovcharov.me/uploads%2F2020%2F06%2F29%2Fesp32-dev-board.jpg 1200w"><figcaption>ESP32 development board</figcaption></figure>
<p>The security element, screen and keyboard can be purchased separately and attached as external modules.</p>
<p>The links to the GitHub repository and other useful resources are given below.</p>
<p>I will be really thankful if consider sharing the project and leave comments with your thoughts and suggestions.</p>
<h2 id="references">References</h2>
<ul>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/uru-card/uru-card">GitHub repository</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://hackaday.io/project/173443-uru-card">Project on Hackaday.io</a></li>
<li><a rel="nofollow noopener noreferrer" target="_blank" href="https://platformio.org/">PlatformIO</a></li>
</ul>
</article>
</section>
</div>
</div>
</section>
</div></div>]]>
            </description>
            <link>https://en.ovcharov.me/2020/06/29/uru-card-arduino-fido2-authenticator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23676006</guid>
            <pubDate>Mon, 29 Jun 2020 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do call yourself a programmer, and other career advice (2013)]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23675363">thread link</a>) | @luu
<br/>
June 29, 2020 | http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This is a (very late) reply to Patrick McKenzie's "<a href="http://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">Don't Call Yourself A Programmer, And Other Career Advice</a>". I find much of his advice very sensible, and it might be very helpful to someone in the beginning of their career – assuming they can act upon it (and I really don't know whether my 20-year-old self could actually use the advice to improve his negotiation skills, for example).</p>
<p>A few things in the article I disagree with, however. Here I'll mostly focus on those few things, recommending you to read the original article so that you don't miss the rest of it.</p>
<p>"Disagree" is not necessarily the right word – a more precise way to put it would be "it's different in my experience". Which is to be expected because both of us are speaking based on our own careers, which have been rather different. Patrick McKenzie is a small business owner running <a href="http://www.bingocardcreator.com/">Bingo Card Creator</a> and a successful consultant. I'm a lead chip architect at a billion-dollar company. Both of us have thus traveled some distance away from "purely programming" (whatever that means), but in rather different directions.</p>
<p><strong>What company are you going to work for?<br>
</strong></p>
<p>Patrick McKenzie says 90% of the jobs involve things like implementing an internal travel expense reporting form, rather than a product shipped to external customers. He advises you to get used to the idea, even though such software is "soul-crushingly boring" as he puts it.</p>
<p>How bad is it, and is it really 90% of the jobs? Spolsky <a href="http://www.joelonsoftware.com/items/2007/12/04.html">thinks</a> it's maybe 80% – and that it's bad enough to "drain the life out of you". He goes on to elaborate why it "sucks to be an in-house programmer":</p>
<ul>
<li>There's rarely a business reason to improve in-house software past the point of "barely good enough". "Forget any pride of craftsmanship – you're going to churn out embarrassing junk".</li>
<li>At software companies, what you do is more directly related to the way the company makes money, so you're more likely to be respected. "A programmer is never going to rise to become CEO of Viacom, but you might well rise to become CEO of a tech company." "…no matter how critical it was for Viacom to get this internet thing  right, when it came time to assign people to desks, the in-house  programmers were stuck with 3 people per cubicle in a dark part of the  office".</li>
</ul>
<p>Note that McKenzie and Spolsky are in almost complete agreement over these points. But then Spolsky says you should be gunning for a position in a software company – the environment where creatures of your kind naturally thrive. Conversely, McKenzie explains how to prosper as a programmer outside software companies – <em>moving in the opposite direction of where things go by default</em> (being stuck in a dark part of the office while they're trying to outsource your job.)</p>
<p>So the question is which path you prefer. "Not so fast", you say: one of these jobs is way easier to land – 80-90% of the chances are you're not getting inside a software company – so it's not just a question of preference.</p>
<p>Here I disagree: even if only 10-20% of programmers work in software companies (where are the stats?..), and even if they're "the best" (according to what metric?), McKenzie himself says in that same article:</p>
<blockquote><p>You radically overestimate the average skill of the competition because of the crowd you hang around with:&nbsp; Many people already successfully employed as senior engineers cannot actually implement FizzBuzz.</p></blockquote>
<p>But if competition is relatively unskilled on average, you probably can land a job in the 10-20% of the sector that you want – as did most people who graduated around the time I did. So I rather firmly believe that it's a matter of choice: do you <em>want</em> to work on in-house software or one-off businessy projects of that kind, or do you prefer a software company?</p>
<p>Let's proceed to McKenzie's advice to in-house programmers – which should in itself help one make that choice.</p>
<p><strong>How to call yourself<br>
</strong></p>
<p>One such advice is:</p>
<blockquote><p>Don't call yourself a programmer. “Programmer” sounds like “anomalously high-cost peon who types some mumbo-jumbo into some other mumbo-jumbo.” Instead, describe yourself by what you have accomplished for previous employers vis-a-vis increasing revenues or reducing costs.</p></blockquote>
<p>Sure – an in-house programmer is likely doing some type of expensive mumbo-jumbo in the eyes of his non-technical MBA-wielding manager.</p>
<p>To me, however, a programmer is who I'm looking for, while a resume full of revenue increases and cost reductions sounds like an "anomalously high-cost parasite who types some mumbo-jumbo into Excel and PowerPoint, claiming credit for others' work".</p>
<p>McKenzie says a software company looks at this just like a company hiring internal programmers, essentially. His example is "the guy who wrote the backend billing code that 97% of Google’s revenue passes through – he’s now an angel investor". The guy apparently got rich by being near a "profit center" rather than through his unusual skills.</p>
<p>The thing is, in this case I believe he's talking about <a href="http://www.flownet.com/ron/">Ron Garret</a>, the PhD from NASA's Jet Propulsion Laboratory. Do you think they hired him because he described his work at the JPL in terms of revenues and costs? (BTW he didn't like working on the billing code, bought his stock options and quit, instead of choosing a career at the company's biggest "profit center".)</p>
<p>Did any unusual skills go into the billing code? Ron Garret <a href="http://www.flownet.com/ron/xooglers.html">says</a>:</p>
<blockquote><p>I did end up writing the credit card billing and accounting system, which is a nontrivial thing to get right. Fortunately for me, just before coming to Google I had taken some time to study computer security and cryptography, so I was actually well prepared for that particular task. …I designed the billing system to be secure against even a dishonest employee with root access (which is not such an easy thing to do). I have no idea if they are still using my system, but if they are then I'd feel pretty confident that my credit card number was not going to get stolen.</p></blockquote>
<p>Sounds to me that his technical knowledge and programming ability was the bulk of his contribution, whereas deep thoughts such as realizing that there will be some "cost reduction" due to not having credit card numbers stolen is not something an employer needs to hire anyone for.</p>
<p>So if I ever send out a resume as a chip architect, I will focus on my technical role in transitioning from fixed-function hardware accelerators to programmable processors, more than the manpower this saved and the business we won as a result (which I think were real outcomes of our work, but which is rather hard to quantify – as these things often are unless you're a business-friendly-sounding liar.)</p>
<p>Incidentally, I'm not sure <em>when </em>I'll send out that resume, which brings us to the next point.</p>
<p><strong>On job hopping, backstabbing, and the lack thereof </strong></p>
<blockquote><p>Co-workers and bosses are not usually your friends: You will spend a lot of time with co-workers.&nbsp; You may eventually become close friends with some of them, but in general, you will move on in three years…</p>
<p>&lt;your boss will&gt; attempt to do things that none of your actual friends would ever do,  like try to talk you down several thousand dollars in salary or  guilt-trip you into spending more time with the company when you could  be spending time with your actual friends. &nbsp;You will have other  coworkers who — affably and ethically — will suggest things which go  against your interests…</p></blockquote>
<p>There is a certain internal consistency to a view that your coworkers are not your friends, because you will move on in 3 years. In fact, it's a bit circular. They aren't your friends – because you'll move on. And why will you move on? Well, I dunno, maybe for a 10% salary increase. What's there to lose? Relationships with coworkers? But coworkers aren't your friends!</p>
<p>Again, I don't disagree, but rather offer an alternative view, equally internally consistent. I have stayed at one job for more than a decade, in large part because I'm rather attached to the people I work with. To be sure, I got raises, and I was ready to quit over employment terms – but it'd take much more than 10%.</p>
<p>Isn't it just a quantitative difference in preferences – a 10% raise not being fundamentally different than, say, 100%? Well, sufficiently large quantitative changes add up to qualitative changes, as Marxian dialectics or some other Soviet philosophy thingie that my parents sometimes quote taught us. What's going on is that both approaches can lead to career advancement, but they do so very differently.</p>
<p>If you're willing to change jobs over a small raise, you'll be changing them frequently. You won't get attached to people, or to the work you're doing together. You will be very good at finding jobs and you will know what's generally going on in the industry and what's in demand. You will <em>not </em>know that many things specific to any of your employers. <em>You and your employer will become very useful to each other fairly quickly, but you'll also be somewhat expendable for each other.</em></p>
<p>Alternatively, you can keep a job as long as it's a fun environment, requiring a significant raise once in a while. Your relationships with people combined with your long-term outlook can let you do things together that you otherwise couldn't plan or execute, and learn things you wouldn't have learned.</p>
<p>Much of my knowledge about chip design comes from ASIC hackers I worked with, and their willingness to develop their biggest ideas together with me came from trust that necessarily took time to build. It takes time to learn that none of you is in the habit of "suggesting things going against the other's interest", or pulling other unfriendly shenanigans.</p>
<p>Incidentally, if you stay at one place for a long while, then your worth to the employer grows to the point where you can get the significant raise that you'd quit over without actually quitting. Your worth can also grow well above what employers are willing to pay to experienced new hires, so there's no longer a point in switching jobs. This is somewhat analogous to becoming a consultant after having switched a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html">http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html</a></em></p>]]>
            </description>
            <link>http://yosefk.com/blog/do-call-yourself-a-programmer-and-other-career-advice.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23675363</guid>
            <pubDate>Mon, 29 Jun 2020 07:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Unix Pipes to Improve Chromecast Playback]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23673825">thread link</a>) | @lowmemcpu
<br/>
June 28, 2020 | https://alexdelorenzo.dev/linux/2020/03/14/pipes | <a href="https://web.archive.org/web/*/https://alexdelorenzo.dev/linux/2020/03/14/pipes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">  <p>When casting from YouTube to a Chromecast, sometimes the audio playback will <a href="https://support.google.com/chromecast/thread/13807879?hl=en">skip</a> and <a href="https://support.google.com/youtube/thread/17251626?hl=en">stutter</a>. This issue is independent of the quality of the video, the FPS, or the internet connection. Trying to watch certain videos will reliably cause playback issues on the Chromecast.</p> <p>According to <a href="https://support.google.com/chromecast/thread/13807879">this thread</a>, the playback issue only appeared in the latest and final firmware update for the Chromecast. Successful playback of the videos was possible in the past, and casting the downloaded YouTube videos eliminates the problem entirely. The problem exists solely when casting certain videos using the YouTube app.</p>  <p>Given that the problem only occurs with the YouTube app, you can download a video and cast it via <a href="https://github.com/xat/castnow"><code>castnow</code></a> or <a href="https://github.com/skorokithakis/catt"><code>catt</code></a>, skipping the YouTube app entirely.</p> <p>You could do something like:</p> <div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>export </span><span>url</span><span>=</span><span>"https://youtu.be/Kas0tIxDvrg"</span>

<span>function </span>cast<span>()</span> <span>{</span>
    <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>
    
    <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
    youtube-dl <span>"</span><span>$url</span><span>"</span>
    
    <span># wait a bit to download the file</span>
    castnow <span>"</span><span>$filename</span><span>"</span>
    <span>rm</span> <span>"</span><span>$filename</span><span>"</span>
<span>}</span>

cast <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>But having to skip using the YouTube app to cast is already a clunky solution, and downloading every video before playing them is an even worse user experience. Instant playback and ephemeral streams are what make for a pleasant video streaming experience in 2020, and this solution implements neither of them</p>  <p><a href="https://github.com/ytdl-org/youtube-dl/blob/master/README.md">Since <code>youtube-dl</code> allows us to output to <code>stdout</code></a>, if we can hook its <code>stdout</code> to a casting app, we could emulate the instant playback and ephemeral videos we expect because we don’t have to wait for an entire file to download.</p> <p>Unfortunately, <code>castnow</code> and <code>catt</code> won’t cast from <code>stdin</code>. You’re expected to pass it file locations to cast from.</p> <p>This is where one of my favorite shell features really shines: <a href="https://tldp.org/LDP/abs/html/process-sub.html">process substitution</a>.</p> <p>With process substitution, Bash gives us a convenient way to make ephemeral <a href="https://en.wikipedia.org/wiki/Anonymous_pipe">anonymous pipes</a>. This method is both efficient and concurrent, making this primitive an apt choice to build a solution to the problem at hand. A process reading the <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">pipe</a> blocks until the pipe is opened by another process for writing. A process writing to the pipe will suspend until the pipe’s buffer is read by another process. The anonymous pipe will automatically remove itself, and when it is manually removed, its dependent processes will be terminated.</p> <p>When using process substitution, a process’ <code>stdout</code> is hooked up to an anonymous pipe. That pipe can be accessed from a file descriptor, and the location of the pipe is given to the calling process.</p> <div><div><pre><code><span>$ </span><span>echo</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
/dev/fd/63

<span>$ </span><span>cat</span> &lt;<span>(</span><span>echo</span> <span>"Content sent to pipe"</span><span>)</span>
Content sent to pipe
</code></pre></div></div> <p>In the example above, the <code>&lt;(command)</code> syntax is how we invoke process substitution in Bash. The output of <code>command</code> is written to an anonymous pipe, and the calling process is given the location of the file descriptor to access that pipe.</p> <p>Using that example, we can take advantage of process substitution:</p> <div><div><pre><code>vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>The command above will play the YouTube video locally with <a href="https://www.videolan.org/vlc/index.html">VLC</a>, and illustrates that process substitution can work for our use case.</p> <p>However, when we try to use <code>castnow</code>, we can’t cast from the pipe:</p> <div><div><pre><code><span>$ </span>castnow &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: Load failed
</code></pre></div></div> <p>Nor can we cast with <code>catt</code>:</p> <div><div><pre><code><span>$ </span>catt cast &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
Error: The chosen file does not exist.
</code></pre></div></div> <p>We know we can use VLC locally, and VLC also lets you cast to a Chromecast using its IP address.</p> <p>Let’s try that again using VLC:</p> <div><div><pre><code><span>function </span>cast_vlc<span>()</span> <span>{</span>
    <span>path</span><span>=</span><span>"</span><span>$1</span><span>"</span>

    <span># get the ip address for chromecast.lan host</span>
    <span>ip</span><span>=</span><span>$(</span>dig +short chromecast.lan | <span>tail</span> <span>-n</span> 1<span>)</span>

    vlc <span>-I</span> ncurses <span>\</span>
      <span>--sout</span> <span>'#chromecast'</span> <span>\</span>
      <span>--sout-chromecast-ip</span><span>=</span><span>"</span><span>$ip</span><span>"</span> <span>\</span>
      <span>--demux-filter</span><span>=</span>demux_chromecast <span>\</span>
      <span>"</span><span>$path</span><span>"</span> &lt; /dev/tty
<span>}</span>

cast_vlc &lt;<span>(</span>youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span><span>)</span>
</code></pre></div></div> <p>That works.</p> <p>As an aside, we hook VLC’s <code>stdin</code> to <code>/dev/tty</code> so that we can use the ncurses interface even if we invoke the function from a script.</p> <p>Let’s look at the <a href="https://wiki.videolan.org/Documentation:Modules/ncurses/">ncurses interface</a>.</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/d0822203c304db88f3cbec618e94a3d9f55cd269/c5939/assets/imgs/converted/vlc-fs8.webp" loading="lazy"> </p> </div> <p>It only displays the file descriptor, and very little about the video itself. I’m not a fan of that.</p>  <p>Instead of using anonymous pipes, we can use <a href="https://en.wikipedia.org/wiki/Named_pipe">named pipes</a>. Named pipes are like anonymous pipes, except they are not anonymous (they have a name) nor are they ephemeral. Named pipes still give us the efficiency and concurrency benefits that anonymous pipes give us, but Bash lacks the syntactic sugar it has for process substitution when it comes to named pipes.</p> <p>This is how we create named pipes, write to them, read from them and remove them.</p> <div><div><pre><code><span>$ </span><span>mkfifo </span>ourpipe
<span>$ </span><span>echo</span> <span>"Content in pipe"</span> <span>&gt;</span> ourpipe &amp;
<span>$ </span><span>cat </span>ourpipe
Content <span>in </span>pipe
<span>$ </span><span>rm </span>ourpipe
</code></pre></div></div> <p>Not as pretty as <code>&lt;(command)</code>, but it gets the job done.</p> <p>We can give a named pipe the same name as our YouTube video, and that way, the VLC interface will show the name of what we’re watching.</p> <div><div><pre><code><span>function </span>cast_ytdl<span>()</span> <span>{</span>
  <span>url</span><span>=</span><span>"</span><span>$1</span><span>"</span>

  <span># create a temporary named pipe</span>
  <span># why? because vlc will show the file descriptor path if we just use process substitution</span>
  <span>filename</span><span>=</span><span>$(</span>youtube-dl <span>--get-filename</span> <span>"</span><span>$url</span><span>"</span><span>)</span>
  <span>path</span><span>=</span><span>"/tmp/</span><span>$filename</span><span>"</span>
  <span>mkfifo</span> <span>"</span><span>$path</span><span>"</span>

  <span># download in background, push to named pipe</span>
  youtube-dl <span>-q</span> <span>-o</span> - <span>"</span><span>$url</span><span>"</span> <span>&gt;</span> <span>"</span><span>$path</span><span>"</span> &amp;
  <span>pid</span><span>=</span><span>"</span><span>$!</span><span>"</span>
  <span>disown</span> <span>$pid</span>

  <span># cast from named pipe</span>
  cast_vlc <span>"</span><span>$path</span><span>"</span>

  <span># cleanup process and named pipe</span>
  <span>kill</span> <span>-9</span> <span>"</span><span>$pid</span><span>"</span> &amp;&gt; /dev/null
<span>}</span>

cast_ytdl <span>"</span><span>$url</span><span>"</span>
</code></pre></div></div> <p>This works, too.</p> <p>We need to manually create a named pipe with <a href="https://linux.die.net/man/1/mkfifo"><code>mkfifo</code></a>, redirect <code>youtube-dl</code>’s <code>stdout</code> to the named pipe while running the process in the background, and then cleanup the process after casting from it via VLC, otherwise it might linger in the background. Each of those tasks would have been handled for us automatically using process substitution.</p> <p>But it does look a bit better:</p> <div> <p><img src="https://d33wubrfki0l68.cloudfront.net/25d68fb2085191adb26bb931e9bb31c638e5a634/f664c/assets/imgs/converted/vlc3-fs8.webp" loading="lazy"> </p> </div>  <p>Pipes, anonymous pipes and named pipes are also known by another name because of the way they behave: <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)#Pipes">FIFOs</a>, or <strong>f</strong>irst <strong>i</strong>n, <strong>f</strong>irst <strong>o</strong>ut. What’s written to the pipe is read from the pipe in first in, first out order. This behavior maps well to video streaming.</p> <p>While you can interact with anonymous and named pipes like you would a file, the interface isn’t 1:1 with a <a href="https://en.wikipedia.org/wiki/Unix_file_types#Regular_file">standard file</a>. You cannot <code>seek()</code> forward or backward in pipe, you can just read the next forward values. For our use case, that means we cannot skip forward or backward in our streaming videos. We can only play, pause or stop the video.</p> <p>That’s not a problem for me, however it’s something that can be mitigated if it’s a problem for you. The first solution I can think of would be to write to a temporary file via <code>youtube-dl</code> and read from it. Or <a href="https://alexdelorenzo.dev/programming/2019/04/14/buffer">perhaps a temporary spooled file can act as a buffer for the pipe</a>, such that you can <code>seek()</code> through the buffer, but the buffer itself is ephemeral unlike a normal file.</p> </div></div>]]>
            </description>
            <link>https://alexdelorenzo.dev/linux/2020/03/14/pipes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673825</guid>
            <pubDate>Mon, 29 Jun 2020 02:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23673286">thread link</a>) | @yasp
<br/>
June 28, 2020 | https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    
    <section>
        <p>Local economies around the U.S. have continued to change quickly and dramatically – states and cities are slowly reopening, unemployment rates are starting to decline from the recent all-time high, COVID-19 cases are increasing in some states while decreasing in others, and communities are responding to the social unrest and George Floyd protests with city-wide curfews having impacted many businesses that were just able to reopen.</p>
        <p>Yelp last reported on the state of the local economy in <a target="_blank" href="https://www.yelpeconomicaverage.com/yea-q1-2020.html">our quarterly Yelp Economic Average report on April 28</a>, showing how much consumer activity in major swathes of Main Street had dropped off in just a couple of weeks in March. Now as states start to reopen and the nation responds to anti-Black racism and police brutality, a new set of challenges lay ahead for local economies.</p>
    </section>
    
    <section>
      <h2>Some Businesses Slowly Reopen, While Many Permanently Close</h2>
        <p>As of June 15, there were nearly 140,000 total business closures on Yelp since March 1. In April we reported more than 175,000 business closures, indicating that more than 20% of businesses closed in April have reopened. Las Vegas, NV, endured the highest number of closures relative to the number of businesses in the city (1,921 total closures), while Los Angeles, CA, had the largest total number of closures (11,774 total closures).</p>
    </section>
    
    <section>
    	<h3>Some Businesses are Slowly Reopening, Many Remain Closed</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Of all business closures on Yelp since March 1, 41% are permanent closures. Our data shows the largest spikes of permanent closures occurred in March, followed by May and June, indicating that the businesses that were already struggling had to permanently close right away and the businesses that were trying to hold on, but unable to weather the COVID-19 storm, were forced to shutter in recent months.</p>
    </section>
    
    <section>
      <h2>Retail and Restaurant Businesses Continue Innovating Amid High Closure Rates</h2>
        <p>While many business sectors have struggled during COVID-19 there are a few industries that have endured especially high closure rates. Among those with the highest rate of business closures are shopping and retail (27,663 closed businesses), restaurants (23,981 closed businesses), beauty (15,348 closed businesses) and fitness (5,589 closed businesses).</p>
        <p>Retail was by far the hardest hit, experiencing the highest number of total closures, with the average daily rate continuing to increase since March. Of all closures on Yelp since March 1, 20% are for retail businesses and 35% of closed retail businesses are indicated as permanent on Yelp.</p>
        <p>In March, Restaurants had the highest number of business closures, compared to other industries, and have continued to close at high rates. Of the businesses that closed, 17% are restaurants, and 53% of those restaurant closures are indicated as permanent on Yelp. Restaurants run on thin margins and can sometimes take months or even years to break even, resulting in this higher rate of permanent closures.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail have been Hit Hardest</h3>
    	<h4>Number of businesses marked temporarily or permanently closed on Yelp that were open on March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Category_Closures_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>Though some businesses have shut down permanently, many have found <a target="_blank" href="https://blog.yelp.com/2020/04/businesses-creatively-adapt-coronavirus-response?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">innovative ways</a> to weather the storm and continue serving consumers. Many restaurants pivoted to offering takeout and delivery, while some experimented with take home meal and drink kits, and even virtual cooking classes. Some are finding new ways to use existing technology, like <a target="_blank" href="https://blog.yelp.com/2020/04/use-waitlist-online-takeout-restaurants?utm_source=biz_blog&amp;utm_medium=yelp_blog&amp;utm_content=blog_text_link">Yelp Waitlist to manage curbside pickup</a>. Servicing food to-go produces high margins for restaurants, and we’ve seen a 10X increase in searches for takeout since March 10.</p>
        <p>With many retail businesses shifting to curbside pickup, we’ve seen consumer interest spike in obtaining their goods in this way with a 20% increase in searches for curbside pickup. In the beauty industry we’ve seen hair stylists offering video hair cutting tutorials, estheticians offering virtual consultations, and small shops shifting their focus to ecommerce. Fitness in particular has seen a significant shift in their business model with gyms and studios offering virtual classes and personal trainers offering one-on-one virtual training sessions. If nothing else, local businesses owners have proven themselves to be resilient and creative during these trying times.</p>
    </section>
    
    <section>
      <h2>The Desire to Support Black-Owned Businesses Continues to Grow</h2>
        <p>As acknowledgement of anti-Black racism and police brutality become more wide-spread across the nation people are continuing to look for ways to support the Black community. Since May 25, we’ve seen a 1785% relative increase in searches for Black-owned businesses, compared to the three weeks prior. Review mentions of “Black-owned” (and related terms) also skyrocketed, up 426%, as people look to support and surface these businesses to the community.</p>
        <p>D.C. had the highest number of Black-owned searches, accounting for nearly 1% of all searches on Yelp, followed by Minnesota, Maryland, Michigan and Georgia. In fact, every state has shown an increase in searches for Black-owned businesses. Looking at metros, Ann Arbor, MI has the highest increase in searches for Black-owned, up 105X (accounting for 3% of all searches), followed by Denver (up 27X), Minneapolis (up 23X) and Baltimore (up 19X).</p>
    </section>
    
    <section>
    	<h3>Interest Increased in Supporting Black-Owned Businesses</h3>
    	<h4>Percent of Yelp searches for Black-owned businesses by state</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Desktop.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/coronavirus/Searches_Mobile.png">
    	</p>
    </section>
    
    <section>
        <p>While searches for Black-owned businesses have increased across all categories, there has been a particular increase in review content for Black-owned restaurants and food businesses (up 9X), beauty businesses (up 3X), nightlife (up 13X) and shopping (up 3X).</p>
    </section>
    
    <section>
      <h2>The Recovering Economy May Look Different Than the Old Economy</h2>
        <p>While some normal activity is starting to bounce back, due to the many changes impacting local economies — state rules, consumer behavior, and social unrest — many of the consumer interest shifts we saw in March and April started to rebound in May, with dramatic shifts in June.</p>
        <p>Outdoor activities that became popular at the height of the pandemic as people were finding ways to stay active while social distancing – such as mountain biking (down 40%), lakes (down 34%), golf (down 33%) and hiking (down 28%) – have dropped in consumer interest since May 1 relative to other active activities. People are starting to feel more comfortable participating in indoor activities, with increased consumer interest for escape games (up 182%), Go Karts (up 147%), axe throwing (up 113%), gyms (up 81%), bowling (up 63%) and yoga (42%). That said, in some instances people are still finding ways to stay outdoors while social distancing with an increased interest in mini golf (up 132%), amusement parks (up 28%) and horseback riding (up 21%).</p>
        <p>The previous spike in community supported agriculture and grocery has started to dip (down 54% and 26%, respectively) as people start heading back into restaurants. In fact, Yelp’s diners seated data shows significantly more people are dining-in at restaurants. During the peak of the pandemic, the number of diners seated across Yelp Reservations and Waitlist dropped essentially to zero. In early June, we've seen diners seated come back substantially – now down 57% compared to pre-pandemic levels. Restaurants that cater to group dining are among those making a comeback – fondue (up 123%), tapas bars (up 98%), hot pot (up 49%) and surprisingly, even buffets (up 17%) – as foods that gained increased interest through takeout and delivery have started to fall – pizza (down 28%), chinese (down 26%), fast food (down 18%). That said, takeout and delivery has continued to sustain interest on Yelp, still up 148% based on consumer interest relative to pre-pandemic levels, indicating this could be a trend that’s here to stay.</p>
        <p>People are also headed back into malls with outlet stores, shopping centers and thrift stores all up (up 84%, 81%, 72%, respectively), as well as hosting or attending formal events with increased interest in bridal (up 70%) and formal wear (up 102%). The previous increase in cannabis dispensaries, head shops and tobacco shops has declined (down 40%, 35% and 32%, respectively). There have also been significant shifts in consumer interest for health and wellness businesses with an increased interest in saunas (up 75%), reflexology (up 69%) and dentists (up 28%), while skilled nursing (down 46%) and hospitals (down 37%) decline.</p>
    </section>
    
    <section>
      
    </section>
    
    <section>
      <h3>How Business Categories are Faring</h3>
      <h4>Change in share of relative consumer interest on Yelp for select business types</h4>
    	
      <!--<p class='q12020-footer'>Read about the methodology <a href='./yea-q1-2020.html#methodology' class=underline>here</a></p>-->
    </section>
    
    <section>
        <p>As economies reopen, warm summer months arrive and consumers start spending more time out of their homes, we expect these shifts to continue changing at a dramatic rate. We'll continue to measure and report on these changes in local economies in our upcoming Q2 Yelp Economic Average.</p>
        <p>—Daniel Gole and Amy Shapiro contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#fc8c8e998f8fbc8599908cd29f9391"><span data-cfemail="e29290879191a29b878e92cc818d8f">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
        <p><em>Want to work with Yelp data yourself? We make a sample of our data available for academic use, and we’ve just added a <a href="https://engineeringblog.yelp.com/2020/06/how-businesses-have-reacted-to-covid-19-using-yelp-features.html" target="_blank">new batch of data</a> that reflects how businesses have reacted to the pandemic. Read more …</em></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html">https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</a></em></p>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23673286</guid>
            <pubDate>Mon, 29 Jun 2020 00:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finishing a side project]]>
            </title>
            <description>
<![CDATA[
Score 423 | Comments 141 (<a href="https://news.ycombinator.com/item?id=23672686">thread link</a>) | @hugozap
<br/>
June 28, 2020 | https://hugozap.com/posts/how-to-finish-your-side-project/ | <a href="https://web.archive.org/web/*/https://hugozap.com/posts/how-to-finish-your-side-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><img src="https://hugozap.com/img/hands.jpg" alt="Illustration by Angélica Delvalle IG: ylikdelvalle"></p>
<p>It's no secret that finishing a side project is hard.</p>
<p>I've struggled with some side projects and had success with others. In this post, I'll focus on the actions and adjustments that have worked for me.</p>
<p>It's possible to work on and finish side projects even with a busy schedule, the key is to optimize for interruptability. You will be interrupted so instead of counting on having hours of deep work available, it's better to be realistic and make some adjustments to use available time in a better way and reducing the cost of interruptions by having tricks to switch context fast.</p>
<h2 id="a-failed-side-project-story">A failed side project story <a href="#a-failed-side-project-story">#</a></h2>
<p>Maybe you are familiar with a similar situation</p>
<p>At the beginning:</p>
<ul>
<li>High motivation.</li>
<li>Priority over other tasks.</li>
<li>Working long hours because it's fun.</li>
<li>Desire to work with a new technology</li>
<li>No problem working on weekends.</li>
</ul>
<p>After some time:</p>
<ul>
<li>Motivation decreases.</li>
<li>Feels overwheelming.</li>
<li>Harder to justify working on the project when there are other responsibilities.</li>
<li>Other stuff seems more interesting now.</li>
<li>Forgot how to set things up to continue working on the project.</li>
<li>Not sure what I was working on.</li>
<li>Forgetting about the project and archiving it.</li>
</ul>
<h2 id="the-challenges-with-side-projects">The challenges with side projects <a href="#the-challenges-with-side-projects">#</a></h2>
<ul>
<li>Context switching and high cognitive load is exhausting.</li>
<li><strong>Losing interest/ motivation</strong>.</li>
<li>Perfectionism - never ending projects.</li>
<li>Impostor syndrome.</li>
<li>Lack of focus.</li>
<li>Lack of time.</li>
<li>Unexpected life events.</li>
</ul>
<h2 id="re-framing-the-goal">Re framing the goal <a href="#re-framing-the-goal">#</a></h2>
<p>I believe you can set yourself for failure from the start if the goal is not clear.</p>
<p>I've been excited about ideas but later found that I was not really invested in the idea and just wanted to explore a cool feature/tool. It's good to go deeper to your true motivation.</p>
<p>Feeling overwhelmed can also contribute to abandoning the project, I'll talk about <strong>small steps</strong> and why it's key.</p>
<p>If your track record includes lots of ambitious projects and none of them finished, then starting with something smaller seems like the logical approach.</p>
<p>Pick a small battle, maybe just the key feature first, maybe support for just one platform. Cut off features for the first version, remember that there's a lot of forces against you completing your project so reducing load is important.</p>
<h2 id="the-approach">The approach <a href="#the-approach">#</a></h2>
<p>Now that you have a clear idea of what you want to finish, there's some actions and adjustments to your process that will increase the chance of winning the battle (shipping).</p>
<ul>
<li>Preparing your environment (painless context switch)</li>
<li>Work in <strong>Small steps</strong></li>
<li>Mental warm-up before each session.</li>
<li>Anticipate and expect interruptions.</li>
<li>Changing your physical location.</li>
<li>Writting down the ideas on your mind at the end of the session.</li>
</ul>
<h2 id="small-steps-are-key">Small steps are key <a href="#small-steps-are-key">#</a></h2>
<p>I like the idea of not having too many open boxes at the same time, where each box is a task/feature or something that you  started but haven't finished yet.</p>
<p>It's demoralizing to wait weeks or months for a win. Small steps give you small wins, it keeps the journey fun. There's less change of feeling stuck.</p>
<p><a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a> shares excellent resources on the topic of small steps in software.</p>
<h2 id="warming-up-before-each-session-to-reduce-cognitive-exhaustion">Warming up before each session to reduce cognitive exhaustion <a href="#warming-up-before-each-session-to-reduce-cognitive-exhaustion">#</a></h2>
<p>Before starting actual work, write about what would be good to achieve in the session. I find this ritual valuable as it helps me figure out the next small step. Writing the project goal (high level) every session is also a good way to switch context and reminding yourself what's it all about.</p>
<p>I'll talk about having a "context" log, where you write the current progress, and what to do next. If you have this file, reading the previous session log let's you resume your work faster.</p>
<h2 id="immediate-context-switching">Immediate context switching <a href="#immediate-context-switching">#</a></h2>
<p>With the limited amount of mental energy, is crucial to reduce the number of setup tasks required to do a working session on your project. The goal here is reducing the number of small decisions you have to make to have a working environment.</p>
<p>This is one of the most important things for me, and the way I approach it is:</p>
<ul>
<li>Creating a separated system User on my laptop.</li>
<li>Having an email address only for my project.</li>
<li>Having a "context" file where I log what's currently happening with my project, usually at the end of a work session.</li>
</ul>
<p>These have been valuable tools for me, let me explain why:</p>
<h3 id="a-separate-system-user-for-your-side-project">A separate system user for your side project <a href="#a-separate-system-user-for-your-side-project">#</a></h3>
<p>By creating a separate user, you automatically have all the operative system tools (calendar/notes/reminders , etc.) available ONLY for your project.</p>
<p>All the files on your desktop will have a relation to your project. This may not seem impressive but think about all the small distractions you find if you use the same user for your personal/work tasks:</p>
<ul>
<li>Time to find a file (filtering unrelated stuff will bring memories of other things)</li>
<li>Reminders/calendar notifications not related to your project</li>
<li>Dealing with other project setups can be stressful.</li>
</ul>
<p>I think it was Seth Godin who recommended having a separate laptop for a side project like writing a book. This is an alternative too.</p>
<p>You can add more extreme measures like redirecting distracting sites like news or reddit. If you need to login to one of those sites, it's better to switch user accounts. Try to keep your project user clean.</p>
<h3 id="having-an-separate-email-for-your-project">Having an separate email for your project <a href="#having-an-separate-email-for-your-project">#</a></h3>
<p><a href="https://hugozap.com/posts/ultimate-info-capturing-tool/">I'm a fan of email</a> as a note taking tool, it's available everywhere, the UI is simple. Having a separate email account lets you capture related notes/ideas/links from any device. This has been useful for me when I'm doing something else and have an idea, or find a resource that can be used to do something I want to incorporate into the project.</p>
<p>Later, when I log in to my project environment I'll get the emails with relevant information, no chance of getting distracted with other stuff.</p>
<h3 id="the-context-file%2C-(brain-dump).">The context file, (brain dump). <a href="#the-context-file%2C-(brain-dump).">#</a></h3>
<p>A context file is just a text file where you add a short summary of the current project status and what's on your mind at the time.</p>
<p>This has been valuable to me, because the act of writing it down helps me have a clear idea of things I could do next and next time I have time to work on my project I'll have a starting point and it reduces the cognitive load which maximizes the session efficiency.</p>
<h2 id="location">Location <a href="#location">#</a></h2>
<p>Going to a library or café (when possible) or event to another room and have a dedicated space for your current side project will make a difference.</p>
<p>Not sure about why, but using the same desk for different work and side projects is not ideal for me. If you can I recommend having a different place that helps you switch context quickly.</p>
<h2 id="abandoned-projects-may-not-be-a-failure-after-all.">Abandoned projects may not be a failure after all. <a href="#abandoned-projects-may-not-be-a-failure-after-all.">#</a></h2>
<p>Some abandoned projects end up being an inspiration to create something else years later. Maybe you learned something new, explored an idea, or found a problem not possible to solve with the knowledge and resources you had at the time.</p>
<p>It's good to have an open mind and be ok with finding dead-ends, they are powerful teachers.</p>
<p>However, shipping projects <strong>is awesome</strong> and by reducing scope and anticipating interruptions you will be able to complete your project and release it to the world.</p>
<h2 id="resources">Resources <a href="#resources">#</a></h2>
<p>For more information about the benefits of a "small step" approach to software development check the excellent resources from <a href="https://www.geepawhill.org/2020/06/26/more-on-small-steps/">Geepaw Hill</a></p>
<h2 id="credits">Credits <a href="#credits">#</a></h2>
<p>Illustration by <a href="https://www.instagram.com/ylikdelvalle/">Angelica Delvalle</a> (In case you need art for your company products contact her, she does awesome stuff!)</p>


<p><a href="https://hugozap.com/">← Home</a></p>

    </div></div>]]>
            </description>
            <link>https://hugozap.com/posts/how-to-finish-your-side-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672686</guid>
            <pubDate>Sun, 28 Jun 2020 22:48:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life is 90% of my use cases for org-mode]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 236 (<a href="https://news.ycombinator.com/item?id=23672473">thread link</a>) | @billwear
<br/>
June 28, 2020 | http://stormrider.io/ninety-pct.html | <a href="https://web.archive.org/web/*/http://stormrider.io/ninety-pct.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <h2>
      life is 90% of my use cases for org-mode
      <br>
      <small>
	<em>so what's the other 10%?</em><br>
      </small>
    </h2>
    <hr>
    <a href="http://stormrider.io/index.html">blog index</a><br>
    <hr>
    <p>
      To really explain why I use org-mode for <bold>everything</bold>, I probably first have to explain my rules, which also requires a backstory.  I'll keep it short, no problem.
    </p>
    <p>
      I jacked into Unix the first time at Calhoun Community College, in Decatur, Alabama, during the summer of 1974.  I was 15, and my dad was a part-time programming instructor.  Having been an avid reader since the age of 6 (I read the entire elementary school library before the middle of second grade), text and text-processing was much on my mind.
    </p>
    <p>So when I encountered a system where plain text is the raw material flowing through the pipes, I was hooked.
    </p>
    <blockquote>
      <br>
      ...what I really learned was that the rules of Unix could be adapted to life.
      </blockquote>
    
    <p>
      This led me to undertake an informal study of Unix, all the way back to the Tech Model Railroad Club and all the hackers that came from there.  Yeah, I read the story about Margaret and the groceries and the Volkswagen; I understand his pain.
    </p>
    <p>
      But what I really learned was that the rules of Unix could be adapted to life.
    </p>
    <p>
      After about 30 years as a tech writer and frequent programmer, I finally settled on a set that works for me.  Little did I know that these very principles would lead me to org-mode, which would later lead me to find my people.
    </p>
    <hr>
    <h3>
      <center>
	Unix rules for life
      </center>
    </h3>
    <ul>
      <li>Keep it simple: It's cheaper and easier to carry around.</li>
      <li>Do one thing at a time: Multitasking is a lie.</li>
      <li>Network: You were born to connect.</li>
      <li>Say what you mean; nothing is truer than the truth.</li>
      <li>Hack: Trial and error is the only way we learn anything</li>
      <li>Be who you are: Even a bent wire can carry a great light.</li>
      <li>Use leverage; a bigger hammer isn't always the answer.</li>
      <li>Use what you have: never dig diamonds with a brick of gold.</li>
      <li>Have faith; all's possible, except maybe skiing through a revolving door.</li>
      <li>Think ahead, but don't worship your plans; remember today is the first day of the rest of your learning experience.</li>
    </ul>
    <hr>

<h3>
  a vi convert
</h3>
<p>
  I didn't start with org-mode, actually, but with plain journal files labeled YYYYMMDD, in a special directory in <code>/var/log</code>.  I still have those going back to sometime in the 90's.  The format was simple, but using the files soon became complex:
  </p><pre>	  
    *** personal journal of stormrider
    tue, aug 04, 1992 / 712904400
    sweetmorn, confusion 70, 3158 YOLD
    
    *** fortune -s
    Cold hands, no gloves.
    
    *** appts
    09:00  staff meeting, conf rm
    18:30  dinner with amit &amp; bonnie
    
    *** to do
    finish revisions on x-windows book
    do syllabus for advanced C class
    read some in Stevens &amp; Rago
    shower
    shave
    dress
    take out the trash otw to work
    .
    .
    .
    
    *** daily journal
    06:43 - man, didn't sleep well
    last night; i think i'm overdoing
    it on the coffee at work; maybe i
    should cut back some?
    .
    .
    .
  </pre>
  The unwieldy part came with all the repeated tasks, and tasks that got carried over from one day to the next (or didn't get finished). I had to copy yesterday's file, change all the key info, sort out the todo list, erase yesterday's journal, and generally do far too much work to keep my journal up.

<blockquote>
  <br>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck....
  </blockquote>
<p>
  I did it, but intermittently, supplanting it with post-it notes, pads, planners galore, palm pilots, palmtop computers, etc.  It seemed like every day I was badly copying tasks from one day to the next. Meanwhile, my unwillingness to use Windows didn't give the the luxury of Outlook, when it came along.
</p>
<p>
  I got turned onto emacs sometime in the mid-nineties, when I moved to Atlanta to work for HP.  A fellow writer there used it, and suggested it might help me write and code up examples more effectively.  He was right, and it stuck as my editing platform of choice.
</p>
<p>
But I hadn't discovered org-mode yet. Either he didn't use it, or it hadn't been invented yet.  And to be honest, I kinda went back and forth between vi and emacs, depending on my "mood of the month."
</p>
<h3>
  a modem in the woods
</h3>
<p>
  Eventually, my HP job became a telecommuting-type arrangment, and I moved home to the farm, about an hour outside New Orleans, in the woods.  At that time, Internet was still modem-driven out here, so having command-line Linux with emacs on my laptop was a real lifesaver.
</p>
<p>
  Sometime not long before Katrina hit, I stumbled across org-mode.  I'd already used outline mode for some period of time (can't remember how long), and org-mode seemed like a logical follow-on from there.
      </p>
      <p>
	From there, org-mode just grew, and I grew with it.  All the features made it easy for me to both do what seemed natural for me, and do things in a way that felt like they supported my principles.  Gradually, my other methods of keeping track of things faded away, except for my alarm clock.  </p>
<p>
  Even when smart-phones took off, I was always trying to find some way to send org files over to my phone and use them there.  I think I even wrote some lua code in an iPhone wiki app to emulate org-mode with my files, though it was not fully satisfactory.
</p>
<h3>
  an org-mode resume
</h3>
      <p>
	Fast-forward to last May.  I'd been wanting to get on with Canonical for a long time, but hadn't found the right position, one that really matched my skills.  Then one Saturday, while I was waiting for my wife to meet me for some community event we were hosting, I saw a position that virtually described me.  I started to write a resume, but then decided that I would just take the job description elements, one-by-one, put them in an org file, and send them to the hiring manager.
      </p>
<p>
  Long-story short, almost everyone on this team used emacs, and org-mode, and lots of other .el packages that I also used every day.  I got the job, and so far, I'm very happy and feel like I fit in very well.
      </p>
      <h3>
	org-mode and my principles
      </h3>
      <p>
	Here's how I feel about using org-mode for everything: email, git, irc, web-browsing, organization, time-keeping, and so on.  And yes, I do use org-mode to connect with my email and the web, even though I use other packages (rmail, eww, magit, erc) to do the heavy lifing.  Let me walk it down, principle by principle:
	</p><ul>
	  <li><strong>Keep it simple:</strong> Granted, emacs isn't the simplest user interface, that is, until it becomes second nature.  After that, you'll find yourself accidentally erasing cells in your Google spreadsheet when you hit "C-x C-s" to try to save (good thing there's an undo). But the fact that you can use the same text for multiple functions: appointments, task states, task notes, clocking time, building an agenda, sending email, project planning, percentage completion, ....  The list is too long to quote, but just a simple statement, like "Get the discourse publishing tool working," can become the nucleus for a whole cycle's work and all the actions that go with it.</li><br>
	  <li><strong>Do one thing at a time:</strong> The window-driven nature of emacs makes it easy to switch tasks when you have to (just open another buffer) and then switch back later, and more quickly link back to where you were; not to mention that, if you become adept at using the agenda, you can keep yourself on track and move other things around with ease, and without any fear that they'll get lost.</li><br>
	  <li><strong>Network:</strong> Since I'm set up to send email, IRC, Mattermost, etc., directly from my org-mode tasks, it's easy to track where I am.  But even if I used another app, it's still really easy to just cut and paste a note next to a task and then set a follow-up time to prod, all without breaking your train of thought.  You're literally still looking at the work you're doing while you're messaging about it, so there's that.</li><br>
	  <li><strong>Say what you mean:</strong> You have the entire outline in front of you for whatever you're working on, so presentations, show-and-tell sessions, and status reports are really simple to give, whether verbally or in writing.</li><br>
	  <li><strong>Hack...:</strong> If it doesn't do what you want, you've got customizable variables, a huge library of packages, strong macro capability, and push-come-to-shove, emacs lisp, though I rarely have to go there, TBH.</li><br>
	  <li><strong>Be who you are:</strong> Org-mode matches my thinking style. Not true for everyone, but I tend to outline or mindmap (which you can do with org-mode, with the right .el package).</li><br>
	  <li><strong>Use leverage:</strong> Org-mode seriously leverages the power of plain text, in that you can either use the shortcuts to add an appointment, add tags, search tags -- or you can just do it by hand, because all of the special notation is plain text.  Leveraging human language in this way is helpful to me.</li><br>
	  <li><strong>Use what you have:</strong> Org-mode and emacs give me a stable platform that works everywhere, even on a printout.  I don't need license fees, special extensions, subscriptions, add-on tools, or constant updates to keep my life humming.</li><br>
	  <li><strong>Have faith:</strong> Org-mode has justified my faith, as has emacs.  Lots of tools I've used break, crash, or get killed by absorption (I once liked Astrid, e.g., but it suddenly got sold and went away).  Org-mode and emacs are pretty much here to stay, especially since there is no license fee, and I can keep a self-contained version backed up at home, should it ever stop being distributed.</li><br>
	  <li><strong>Think ahead:</strong> This is where org-mode, and especially the agenda, shine.  If I'm busy, I don't have to worry about keeping my outline clean.  I can stop in the middle of notes for another project, hit return, enter a to do for later (and tag it and schedule it to pop up later), and then move that to someplace more suitable later.  The agenda will clean it up and put it in perspective for me.  Or I can search for it, or pull up all open to-do items …</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://stormrider.io/ninety-pct.html">http://stormrider.io/ninety-pct.html</a></em></p>]]>
            </description>
            <link>http://stormrider.io/ninety-pct.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23672473</guid>
            <pubDate>Sun, 28 Jun 2020 22:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardest Part of Working at a Growth Startup]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23671824">thread link</a>) | @svmanager
<br/>
June 28, 2020 | https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/hardest_part_of_startup/office-space.jpeg" alt="The hardest part of working at a growth startup is having to re-interview for your job every year">
Growth startups require both personal and business scaling.</p>

<p>The hardest part of working at a growth startup is having to re-interview for your job every year.</p>

<h3 id="the-challenge-of-scaling">The challenge of scaling</h3>

<p>You’re heading a key function at your 25-person startup. Maybe you’re head of engineering; maybe you run marketing. Hell, maybe you’re the CEO. You kick ass and your startup grows fast – and with that growth, the needs of the company evolve. Things in the new world are now going okay, but perhaps not optimally. Eventually, the CEO and board of directors get in a room to discuss what to do.</p>

<p>I can tell you what will happen in this room. The board will discuss your performance, and compare it to the performance of other, hypothetical executives – just as if you were interviewing for your own job. In your favor: you are a known quantity, presumably viewed as talented, and perhaps even a close friend. Against you: you haven’t done this before, and we need results now.</p>

<p>In many cases this conversation will lead to you being demoted or asked to leave. In extra cruel circumstances, you can literally get fired for having done a great job. This is normal, semi-expected, and sucks. And this happens to everyone – even founding CEOs are not immune.</p>

<p>The hardest part of this situation? These hard truths often go unspoken. Sometimes it’s just too awkward to tell someone who’s been there through thick and thin that they’re expected to be a stand-in for a future big league exec. And if you have a first-time management team, they might not even realize what’s going on – they may also be in the process of not scaling fast enough, either. At least when you’re interviewing, you’re explicitly given the chance to shine; such opportunities may not be spoon-fed to you during hectic growth.</p>

<h3 id="how-to-scale-yourself">How to scale yourself</h3>

<p>To avoid this situation you need to become a self-scaling machine. Read voraciously, and find opportunities to put new skills into practice – during growth mode there’s always too much to do, so take advantage and gain actual battlefield experience. You should constantly have an image in your mind of where you expect your team to be in 6 months and steer towards that future world. Learning to see around corners allows you to scale independently, and independence is a key leadership trait since <a href="https://staysaasy.com/scaling/2020/05/07/startup-is-this-normal.html">startups are constantly on fire</a>. Finding mentors who are at least 2-3 years ahead of you in terms of their own careers is another great way to build these instincts.</p>

<p>And most importantly, <em>ask questions</em>. Ask your manager how they expect your job will be different in 6 months (if you’re the CEO, this advice will be slightly different –&nbsp;a trusted advisor and/or executive coach can help). Ask them what they see as your current trajectory in the role. In my experience people are way too shy about asking direct questions in general, especially to their managers – it is literally your manager’s job to provide high-quality answers to your career questions. If you nail this, it’s a fast track towards increasing responsibility and growth.</p>

<h3 id="this-isnt-a-bad-thing">This isn’t a bad thing!</h3>

<p>From the other perspective, well-run growth startups give you the regular opportunity to interview for roles that are a level higher (or two!). <a href="https://www.linkedin.com/in/marissamayer/">This</a> is a <a href="https://www.linkedin.com/in/marcbenioff/">proven way</a> to <a href="https://www.linkedin.com/in/ericsyuan/">accelerate</a> your <a href="https://en.wikipedia.org/wiki/Sundar_Pichai#Career">career</a>. If you scale with a growing organization, you can pack decades of experience into years.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671824</guid>
            <pubDate>Sun, 28 Jun 2020 20:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing the Exponential Function]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23671262">thread link</a>) | @hackernewsn00b
<br/>
June 28, 2020 | https://www.pseudorandom.com/implementing-exp | <a href="https://web.archive.org/web/*/https://www.pseudorandom.com/implementing-exp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>I explore several sophisticated approximation techniques for implementing the exponential function, $f(x) = e^x$, including Taylor series approximation, Lagrange interpolation, Chebyshev interpolation, Carathéodory-Fejer approximation and MiniMax approximation. This also serves as a more general introduction to the use of these methods for approximating other functions. In the process I walk through the relevant theory for each method and apply numerical analysis to navigate various forms of error. I also include my own Python and C++ implementations of each algorithm in double precision<label for="cb-1"><sup id="footnote-1"><span>1</span></sup></label><span><p>1:  Note that the implementations included here will both output <strong>and</strong> calculate in double precision. We can still apply sophisticated methods in this setting, but as a general rule you’ll need higher intermediate precision to obtain an approximation which is indistinguishable from the true value in double precision. This is one (but not the only) reason why it’s generally advisable to use an optimized <code>exp(x)</code> function provided by your platform rather than write one from scratch.</p></span> with heavy commentary. Finally, I analyze each implementation’s performance and accuracy characteristics using the hyper-optimized, platform-provided <code>exp(x)</code> function as a benchmark.<label for="cb-2"><sup id="footnote-2"><span>2</span></sup></label><span><p>2:  In most cases, whichever numerical library you’re using will map to the platform-provided <code>exp(x)</code> function. For example, this is what <code>numpy.exp</code> does <a href="https://github.com/numpy/numpy/blob/master/numpy/core/src/npymath/npy_math_internal.h.src#L451-L471">under the hood</a>.</p></span> The Background section opens with the motivating properties of $e^x$ and the basics of floating point systems. The code for each technique is included under the corresponding Implementation heading.</em></p>

<h2 id="section-0"><a href="#section-0">Background</a></h2>

<h3 id="section-1"><a href="#section-1">Taylor series</a></h3>

<p>To motivate the definition of $e$, we will recall some calculus. Let $f$ be a <a href="https://mathworld.wolfram.com/SmoothFunction.html">smooth</a> function at $a$. This is to say that $f$ is infinitely <a href="https://mathworld.wolfram.com/Differentiable.html">differentiable</a> at some real value $a$: for every $k^{\text{th}}$ derivative $f^{(k)}$, we can differentiate $f^{(k)}$ again to obtain the $(k + 1)^{\text{th}}$ derivative $f^{(k + 1)}$. By definition, any function with this property which can also be uniquely represented as a <a href="https://mathworld.wolfram.com/TaylorSeries.html">Taylor series</a> expansion “centered” at $a$ is called <a href="https://mathworld.wolfram.com/RealAnalyticFunction.html">analytic</a>. The Taylor series of $f$ centered at $a$ and evaluated at $x$ is defined to be</p>

<p>$$
f(x) = \frac{f(a)}{0!}(x - a)^0 + \frac{f’(a)}{1!}(x - a)^1 + \ldots + \frac{f^{(k)}(a)}{k!}(x - a)^k + \ldots
$$</p>

<p>This is a <a href="https://mathworld.wolfram.com/PowerSeries.html">power series</a>, or infinite polynomial with one variable. The center of expansion determines a neighborhood of values returned by the Taylor series, and the coefficient of each <em>Taylor term</em> is determined by repeatedly differentiating the function $f$ and evaluating it at $a$. A common center of expansion is $a$ = 0, in which case the Taylor series is also called a <a href="https://mathworld.wolfram.com/MaclaurinSeries.html">Maclaurin series</a> and the series is centered around the origin. This can be considered the “default” setting. If you cut off all terms of the Taylor expansion after some term $k$, you obtain a polynomial with degree $k$. The coefficient of the $k^{\text{th}}$ term of the series (or polynomial, if truncated) is given by</p>

<p>$$
a_{k} = \frac{f^{(k)}(a)}{k!}
$$</p>

<p>where 0! = 1.</p>

<p>For a concrete example, consider the Taylor series expansion of the <a href="https://mathworld.wolfram.com/Sine.html">sine</a> function. The sine function is not only infinitely differentiable, but cyclic.</p>

<p>$$
\begin{aligned}
\sin^{(1)}(x) &amp;= \cos(x), \\
\sin^{(2)}(x) &amp;= \cos^{(1)}(x) = -\sin(x), \\
\sin^{(3)}(x) &amp;= -\sin^{(1)}(x) = -\cos(x), \\
\sin^{(4)}(x) &amp;= -\cos^{(1)}(x) = \sin(x)
\end{aligned}
$$</p>

<p>We determine each $k^{\text{th}}$ coefficient of the Taylor series by evaluating $f^{(k)}$ at $a$ and dividing it by the factorial of $k$. If we want to expand the sine function around the origin ($a$ = 0), we obtain the cyclic coefficients</p>

<p>$$
\begin{aligned}
\sin(0) &amp;= 0, \\
\sin^{(1)}(0) &amp;= \cos(0) = 1, \\
\sin^{(2)}(0) &amp;= \cos^{(1)}(0) = -\sin(0) = 0, \\
\sin^{(3)}(0) &amp;= -\sin^{(1)}(0) = -\cos(0) = -1, \\
\sin^{(4)}(0) &amp;= -\cos^{(1)}(0) = \sin(0) = 0
\end{aligned}
$$</p>

<p>Since $(x - 0)^{k} = x^{k}$, we have the Taylor series expansion</p>

<p>$$
\sin(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \frac{x^9}{9!} - \ldots
$$</p>

<p>Truncating the Taylor expansion of a function $f$ at any term $k$ gives a finite approximation of $f$ using the $k$ degree <em>Taylor polynomial</em>. A Taylor polynomial of $f$ centered at $a$ produces very accurate approximations of $f(x)$ when $x$ is relatively close to $a$. As the absolute value of $x$ increases away from $a$, the accuracy of the Taylor polynomial rapidly decreases, which means it requires more terms of the Taylor series (i.e. a higher degree polynomial) for accurate approximation. Consider the following plot, which shows the values of $\sin(x)$ over the interval $[-20, 20]$ compared to its Taylor polynomials of degree 1, 3, 5, 7 and 9 centered at $a$ = 0.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/sin_taylor_series.svg"></a></p>
  <figcaption>$T_{n}$ denotes the degree $n$ Taylor polynomial of $\sin$</figcaption>
</figure>

<p>Observe that the Taylor approximation of $\sin(x)$ is more accurate when $x$ is near $a$ = 0, but quickly flies away from the true value of $\sin(x)$ further away from 0. The degree 1 Taylor polynomial is only an accurate approximation for $\sin(x)$ for a very small interval near the origin, whereas the degree 9 Taylor polynomial is very accurate within $[-5, 5]$. How long the approximation holds until it becomes extremely inaccurate depends on the number of terms of the Taylor polynomial. A higher degree polynomial will maintain a better approximation of $\sin(x)$ for longer, but any finite polynomial will eventually become extremely inaccurate.</p>

<h3 id="section-2"><a href="#section-2">Defining $e$</a></h3>

<p>The <a href="https://mathworld.wolfram.com/e.html">mathematical constant</a> $e$ is (almost) entirely motivated by the very nice properties it exhibits under exponentiation. In particular, the definition of $e$ was born out of the desire to find a continuous function which is its own derivative and which maps the additive identity 0 to the multiplicative identity 1. This is because solving difficult integration and differentiation problems is vastly more expedient with such a function. By extension a significant fraction of problems in applied mathematics and physics reduce to solving differential equations, for which such a function is fundamental.</p>

<p>As it happens, $f(x) = e^x$ uniquely satisfies this property. We can show this, and define $e$ directly in the process, by starting from the Taylor series representation of an arbitrary function $f$ infinitely differentiable at $a$ = 0. Suppose $a_0, a_1, \ldots$ are the coefficients of the Taylor series of $f$ centered at $a$. Then we have the Taylor series</p>

<p>$$
f(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \ldots
$$</p>

<p>It follows from the linearity of differentiation that the Taylor series expansion of the first derivative $f’$ is</p>

<p>$$
f’(x) = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>To determine a function which is its own derivative, we solve for the coefficients $a_0, a_1, \ldots$ which satisfy $f = f’$:</p>

<p>$$
a_0 + a_1 x + a_2 x^2 + \ldots = a_1 + 2a_2 x + 3a_3 x^2 + \ldots
$$</p>

<p>From here we can see the pattern</p>

<p>$$
\begin{aligned}
a_0 &amp;= a_1, \\
a_1 &amp;= 2a_2, \\
a_2 &amp;= 3a_3
\end{aligned}
$$</p>

<p>and so on, which is equivalent to</p>

<p>$$
\begin{aligned}
a_1 &amp;= a_0, \\
a_2 &amp;= \frac{a_1}{2}, \\
a_3 &amp;= \frac{a_2}{3}
\end{aligned}
$$</p>

<p>By induction we have a <a href="https://mathworld.wolfram.com/RecurrenceEquation.html">recurrence relation</a> which defines the $k^{\text{th}}$ coefficient $a_k$</p>

<p>$$
a_k = \frac{a_{k - 1}}{k}
$$</p>

<p>Given $a_0$ = 1, we find that the Taylor series of a function which is its own derivative is</p>

<p>$$
f(x) = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \ldots.
$$</p>

<p>We denote this function with $e^x$, where $e$ is defined to be the value of this function at $x$ = 1.</p>

<p>$$
e = f(1) = \sum_{k = 0}^{\infty}\frac{1}{k!} = 2.7183\ldots
$$</p>

<p>A more intuitive illustration of why $e^x$ is special is given by the following graph, in which exponential functions with various bases are plotted alongside their derivatives. An exponential function with a base less than $e$, like $b$ = 2, grows more quickly than its derivative. But when the base is greater than $e$, like $b$ = 4, it grows less quickly than its derivative.</p>

<figure>
  <p><a href="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"><img src="https://www.pseudorandom.com/assets/images/articles/implementing-exp/exp_comp.svg"></a></p>
  <figcaption>When $b &lt; e$, we have $f'(x) &lt; f(x)$. When $b &gt; e$, we have $f'(x) &gt; f(x)$. But $b = e$ is the "goldilocks" base at which $f'(x) = f(x)$.</figcaption>
</figure>

<h3 id="section-3"><a href="#section-3">Floating point</a></h3>

<p>There is an intrinsic tension in that we want to determine accurate values of $e^x$ without doing too much work. Before we can consider the efficiency of an algorithm, we need to consider its accuracy. This leads us to define a variety of types of error, the most important of which comes from the way we approximate real numbers. It’s often impossible to calculate the exact value of $f(x)$ for an arbitrary function $f$, because computers can’t work with arbitrary real numbers.<label for="cb-3"><sup id="footnote-3"><span>3</span></sup></label><span><p>3:  <a href="https://en.wikipedia.org/wiki/Almost_all">Almost all</a> real numbers are not <a href="https://mathworld.wolfram.com/ComputableNumber.html">computable</a>. The reals which are computable are frequently not exactly representable to a desirable level of accuracy because they’re either irrational (and therefore have infinite decimal expansions) or rational with very long decimal expansions.</p></span> The best we can do is approximate the value to some acceptable accuracy.</p>

<p>The <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> <em>floating point</em> standard discretizes real intervals into a computable form by mapping all nearby real values in given neighborhoods to a single rounded value. Internally, an IEEE 754 binary floating point number $N$ is represented using the normalized form</p>

<p>$$
N = \pm b_1.b_2b_3 \ldots b_p \times 2^{E_{k}}
$$</p>

<p>where the first bit is allocated for the sign (the <em>sign bit</em>), the $p$ bits $b_1.b_2b_3 \ldots b_p$ comprise the <em>mantissa</em>, or <em>significand</em>, and $E_{k}$ is an integer exponent consisting of $k$ bits. Note that since this form is normalized, $b_1 = 1$, while each of $b_2, \ldots b_p$ may equal 0 or 1. IEEE 754 single precision binary floating point numbers have a total size of $32$ bits: $8$ are allocated for the exponent $E \in [-126, 127]$ and $23$ are allocated for the mantissa (with $p$ = 24 accounting for the normalized bit). Thus you can represent $2^{32}$ different values in single precision floating point, with underflow and overflow limits of $2^{127} \approx 3.4 \times 10^{38}$ and $2^{-126} …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pseudorandom.com/implementing-exp">https://www.pseudorandom.com/implementing-exp</a></em></p>]]>
            </description>
            <link>https://www.pseudorandom.com/implementing-exp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671262</guid>
            <pubDate>Sun, 28 Jun 2020 19:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Geometry Through Graph Theory (2018)]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23671130">thread link</a>) | @prospero
<br/>
June 28, 2020 | http://ideolalia.com/2018/08/28/artifex.html | <a href="https://web.archive.org/web/*/http://ideolalia.com/2018/08/28/artifex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p><img src="http://ideolalia.com/images/artifex-set-operations.png" alt=""></p>

<h3 id="how-i-spent-my-summer">how I spent my summer</h3>

<p>A few months ago, I decided to implement set operations on curved regions.  I had the <a href="https://www.springer.com/us/book/9783540779735">the canonical textbook on computational geometry</a>, which described approaches for polygons comprised of straight lines, and it seemed like <a href="http://paperjs.org/">other projects</a> had extended these techniques to <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">parametric curves</a>.  I figured it would take a couple of weeks.</p>

<p>Unfortunately, the field of computational geometry embodies a fundamental contradiction.  In geometry, the angles of a triangle add up to exactly π radians, and if <em>u</em> is clockwise from <em>v</em> then <em>v</em> must be counter-clockwise from <em>u</em>.  Computers, on the other hand, use floating point representations which make a mockery of these simple Euclidean truths.</p>

<p>The academic literature largely ignores this.  Algorithms are proven to be geometrically sound, and robust implementations are left as an exercise for the reader.  This is akin to a world in which hash collisions caused unavoidable data loss, and the academic response was to implicitly assume the existence of a perfect hash function.  If a paper is predicated on unrealistic assumptions, we cannot evaluate it on its own terms; we must understand, empirically, how well it functions when these assumptions are broken.</p>

<p>With this in mind, we can now look at the existing algorithms for <a href="https://en.wikipedia.org/wiki/Clipping_(computer_graphics)">polygon clipping</a>, which is the term of art for polygon set operations.  Every technique is a variation on a common theme:</p>

<p><img src="http://ideolalia.com/images/artifex-clipping.png" alt=""></p>

<ul>
  <li>Given two or more rings, find every point of intersection</li>
  <li>Segment the rings at the points of intersection</li>
  <li>Decide whether each segment should be included, based on the operation being performed</li>
</ul>

<p>The dozen or so papers on this subject differ only in the third step.  Since our decision to include a segment typically inverts at an intersection point, they describe a variety of approaches for using our decision to about one segment to inform our decision about adjacent segments.</p>

<p>My textbook described a method using <a href="https://en.wikipedia.org/wiki/Doubly_connected_edge_list">doubly-connected edge lists</a>, which is a generic geometric data structure.  I assumed that meant it could be reused for other problems, so I started my implementation.</p>

<p>A month went by.</p>

<p>I had finished the implementation my first week, but it wasn’t reliable.  A DCEL is a collection of linked loops, which can be incrementally updated.  When performing a set operation, we incrementally bisect the original set of loops, and then determine which should and shouldn’t be included.  Despite my best efforts, I kept finding new shapes that caused adjacent faces to get tangled together, creating a Möbius strip that is simultaneously inside and outside the expected result.</p>

<p>Slowly, I realized the problem wasn’t the data structure, it was the first step that every paper glossed over: finding all the intersections.  The DCEL assumes the edges at a vertex have a total ordering: the previous edge is directly clockwise, and the next one is directly counter-clockwise.  If we miss an intersection, we might conclude two curves are both clockwise relative to the other, causing everything to fall apart.</p>

<p>I began to look for better ways to find intersections, hoping that if I found an approach that was sufficiently accurate, my work on the DCEL could be salvaged.  Unfortunately, the approaches I found in the literature and implemented in the wild were no better than what I had been using.  My data structure demanded precise inputs, without internal contradictions, and I couldn’t deliver.</p>

<p>At that point, I began to wonder if I had missed something fundamental.  I thought maybe if I dissected how other, more mature, libraries handled my pathological shapes, I could work backwards to see where I had gone wrong.  But when I began to feed these shapes into well-established projects like paper.js, I found they failed just as badly.</p>

<p>To find my pathological inputs, I had been using property-based testing.  Given a random combination of shapes, I would perform a point-in-region test and compare it to a reference result, generated by querying each shape individually and combining the results according to the operation.  Most inputs worked fine, but after a few hundred thousand inputs it would inevitably find some failure.</p>

<p>Other projects, it turned out, had been a little less eager to find their own failure modes.  Some only had a handful of example-based tests, others had a static suite of a few thousand inputs they used to validate their changes.  If I had missed something, it appeared to be that no one else expected these operations to be particularly robust.</p>

<hr>

<h3 id="why-is-this-so-hard">why is this so hard?</h3>

<p>Floating point arithmetic is best understood through a simple, maddening fact: <code>a + (b - a)</code> does not necessarily equal <code>b</code>.  It might be equal, or it might be off by just a little, where “little” is relative to the larger of the two numbers.  This means that when we compare two floating point numbers, we cannot do a precise comparison, we have to ask whether they differ by less than some <em>epsilon</em> value.</p>

<p>This epsilon represents the level of numerical uncertainty to which we’ve resigned ourselves.  There is vast folk wisdom around how to minimize this uncertainty, but the fact remains that every arithmetic operation injects a bit of uncertainty, and it grows cumulatively with each successive operation.  When dealing with small numbers, this uncertainty may dwarf the values themselves.</p>

<p>An intersection, in a precise mathematical sense, occurs wherever the distance between the curves is exactly zero:</p>

<p><img src="http://ideolalia.com/images/artifex-precise-intersection.png" alt=""></p>

<p>But in a practical sense, it is wherever the distance between the curves is close enough to zero:</p>

<p><img src="http://ideolalia.com/images/artifex-fuzzy-intersection.png" alt=""></p>

<p>This has at least one intersection, but we could just as easily return three or ten within that overlapping range.  This uncertainty is anathema to the published techniques, which rely on counting these intersections to determine whether we’re inside or outside the other shape.  A single spurious intersection may cause the entire result to vanish.  If two objects with similar curvature move across each other, the result will tend to flicker in and out of existence.</p>

<p>These techniques may suffice for straight lines, which require smaller epsilons, but they are wholly unsuited to the relative imprecision of parametric curves.</p>

<hr>

<h3 id="embracing-the-uncertainty">embracing the uncertainty</h3>

<p>As the weeks passed, the errors uncovered by my tests went from feeling random to feeling malicious.  Floating point arithmetic may be deterministic, but as I watched my screen, waiting for the tests to fail, I imagined a demon in the FPU nudging the values as they flowed past, trying to move them beyond the threshold of self-consistency.</p>

<p>One day, I realized this was exactly the narrative behind <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error-correcting codes</a>; we assume our data has been randomly altered en route, and we want to return it to a consistent state.  It didn’t seem like I could get it right the first time, so why not just fix it afterwards?</p>

<p>Consider the union of two ellipses:</p>

<p><img src="http://ideolalia.com/images/artifex-two-ellipses.png" alt=""></p>

<p>Ostensibly, there should only be three points of intersection, one on the left and two on the right.  But for the reasons described above, any intersection routine will likely find multiple points of intersection on the left as the curves converge on each other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-intersections.png" alt=""></p>

<p>The segments on the left are small enough, and thus imprecise enough, that our spatial intuition for the problem will just mislead us.  For this reason, it’s better to think of it as a graph:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-graph.png" alt=""></p>

<p>Now we have to decide which edges to include, and which to exclude.  Since we’re trying to find the union, we want to keep any segments that are outside the other shape:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-valid-result.png" alt=""></p>

<p>This is a well-formed result; there is a single cycle, and once we remove that cycle there are no leftover edges.  But we can’t rely on getting this lucky; the edges on the left might have succumbed to floating point error and believed they were both inside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-incomplete.png" alt=""></p>

<p>This is not a well-formed result; there are no cycles, and a bunch of leftover edges.  To make this consistent, we need to either close the loop, or remove the leftovers.  The cost of these changes is measured by the aggregate length of the edges we are adding or removing.</p>

<p>The minimal set of changes is equivalent to the shortest path between the dangling vertices.  Having found the path, we then invert the inclusion of every edge it passes through.  In this case, it passes through one of the edges we originally excluded, so we add that edge back in, and return the cycle we just created.</p>

<p>Alternately, both edges might think they are outside the other:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-redundant.png" alt=""></p>

<p>In this case, we have a complete cycle, but once we’ve extracted it there’s a single leftover edge:</p>

<p><img src="http://ideolalia.com/images/artifex-ellipses-leftover.png" alt=""></p>

<p>Here again, we search through all the remaining edges for the shortest path between the two dangling vertices.  Since it passes through our leftover edge, we remove it.</p>

<p>Every floating point inconsistency will surface as one of these two cases, or some combination thereof.  By searching for the shortest path between the dangling edges, we find the smallest possible edit that will yield a consistent result.  Of course, a consistent result is not necessarily the <em>correct</em> one, but the fact that floating point errors tend to cluster around the smallest edges makes this a reasonable heuristic.  More importantly, it has weathered tens of millions of generative test cases without any issues.</p>

<p>A complete implementation of this algorithm can be found <a href="https://github.com/lacuna/artifex/blob/master/src/io/lacuna/artifex/utils/regions/Clip.java">here</a>.</p>

<hr>

<p>I’m not sure if this is a novel approach, but at the very least it represents a meaningful improvement on the state of the art in open source.  Intuitively, it feels like this might be a means to avoid epsilon hell in a wide range of geometric and numerical algorithms.  If anyone is aware of prior art in this vein, I’d be very interested to see it.</p>

<p>My work on the <a href="https://github.com/lacuna/artifex">Artifex</a> library is ongoing, but I hope it proves useful to others, and look forward to sharing my own projects that it will enable in the near future.</p>

<hr>

<p><em>Thanks to Alex Engelberg, Elana Hashman, Angus Fletcher, Reid McKenzie, and Zack Maril for feedback on early drafts of this post.</em></p>

		</article>
	</div>

</div></div>]]>
            </description>
            <link>http://ideolalia.com/2018/08/28/artifex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23671130</guid>
            <pubDate>Sun, 28 Jun 2020 18:56:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does DARPA Work?]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 88 (<a href="https://news.ycombinator.com/item?id=23670246">thread link</a>) | @MKais
<br/>
June 28, 2020 | https://benjaminreinhardt.com/wddw | <a href="https://web.archive.org/web/*/https://benjaminreinhardt.com/wddw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="EssayContents">
<div id="EssayContentsInner">
<div>
  <div id="abstract-ish">
  <p>How can we enable more science fiction to become reality?</p>
  <p><span>If you want to do something, it usually pays to study those who have done that thing successfully in the past. Asking </span><span>‘what is this outlier’s production function?’
    </span><span>can provide a starting point. </span></p>
  <p><span>DARPA is an outlier organization in the world of turning science fiction into reality. Since 1958, it has been a driving force in the creation of weather satellites, GPS, personal computers, modern robotics, the
      Internet, autonomous cars, and voice interfaces, to name a few. However, it is primarily limited to the domain of defense technology – there are DARPA-style ideas that are out of its scope. &nbsp;Which emulatable attributes contributed to
      DARPA’s outlier results? </span><span>What does a</span>&nbsp;domain-independent&nbsp;“ARPA Model” look like? <span>Is it possible to
      build other organizations that generate equally huge results in other domains by riffing on that model?</span></p>
  <p>Gallons of ink have been spilled describing <span>how</span><span>&nbsp;DARPA works</span><a id="footnote_source_1" href="#footnote_1"><sup>1</sup></a><span>,
      but </span><span>in a nutshell here is</span><span>&nbsp;</span><span>how DARPA works.</span><span>&nbsp;Around 100 </span><span>program managers (PMs)</span><span>&nbsp;with ~5 year appointments create and run <span>programs</span> to pursue high-level visions like “actualize the idea of man-comp</span><span>uter symbiosis.” In these programs they fund researchers at universities and both
      big and small companies to do research </span><span>projects</span><span>&nbsp;of different sizes. Collectively, groups working on projects are called </span><span>performers</span>.&nbsp;Top-level
      authority lies with a <span>Director </span>who ultimately reports to the Secretary of Defense. </p>
  <p><span>DARPA has an incredibly powerful model for innovation in defense research, and I believe an abstract ‘<span>ARPA Model</span>’ could yield similar results in other domains. In this piece I’ll explain in detail why
      DARPA works. I’ll use that description to feel out and describe to the best of my ability a platonic ARPA Model. &nbsp;I’ll also distill some of the model’s implications for potential riffs on the model. Incidentally,
      I’m working on just such an imitator, and in future essays, I’ll explain why this model could be incredibly powerful when executed in a privately-funded context.</span></p>
  <h4>How to use this document</h4>
  
  <p>This document acts more like a collection of atomic notes than a tight essay – a DARPA-themed tapas if you will. The order of the sections is more of a guideline than a law so feel free to skip around. Throughout you will come across internal links that <a id="self-link" href="#self-link">look like this</a>.
    These links are an attempt to illustrate the interconnectedness of the ARPA Model.</p>
  <p><span>There are two stand-alone pieces to accomodate your time and interest:</span><span> a
    </span><span><a href="#distillation">distillation</a></span><span>, and the </span><span><a href="#h.nbyw8g2b67uk">full work</a></span><span>. </span><span>The
      distillation is meant to capture and compress the main points of the full work. Each section of the distillation internally links to the corresponding section one level deeper so if you want more info and nuance you can get it. </span></p>
      <p><span>I would rather this be read by a few people motivated to take action than by a broad audience who will find it merely interesting. In that vein, if you find yourself wanting to share this on Twitter or Hacker News, consider instead sharing it with one or two friends who will take action on it. Thank you for indulging me!</span></p>
      </div>
  
  <h2 id="program_managers_mini"><span>Program Managers</span></h2><p><span><a href="#at_the_end_of_the_day_the_arpa_model_depends_on_badass_program_managers_which_mirrors_the_obsession_with_“talent”_in_other_disciplines">At the end of the day the ARPA Model depends on badass program managers.</a></span><span>&nbsp;</span><span>Why is this the case? PMs need to
      think for themselves and go up and down the ladder of abstraction in an unstructured environment. On top of that they need to be effective communicators and coordinators because so much of their jobs is building networks. There’s a
      pattern that the abstract qualities that make “great talent” in different high-variance industries boils down to the ability to successfully make things happen under a lot of uncertainty. Given that pattern, the people who would
      make good DARPA PMs would <span>also</span> make good hedge fund analysts, first employees at startups, etc. so digging into </span><span><a href="#why_do_people_become_darpa_program_managers?">people’s motivations for becoming a PM</a></span><span>&nbsp;is important. More precise details about what makes a PM good prevent you from going after the exact same people as every other high-variance industry. When ‘talent’ isn’t code for ‘specialized
      training’ it means the role or industry has not been systematized. Therefore, despite all the talk here and elsewhere about ‘the ARPA Model’ we must keep in mind that we may be attributing more structure to the process than
      actually exists.</span></p><p><span><a href="#darpa_program_managers_pull_control_and_risk_away_from_both_researchers_and_directors">DARPA program managers pull control and risk away from both researchers and directors</a></span><span>.</span><span>&nbsp;PMs pull control away
      from directors by having only one official checkpoint before launching programs and pull control away from performers through their ability to move money around quickly. PMs design programs to be high-risk aggregations of lower-risk projects.
      Only 5–10 out of every 100 programs successfully produce transformative research, while only 10% of projects are terminated early. Shifting the risk from the performers to the program managers enables DARPA to tackle </span><span>systemic </span><span>problems where other models cannot.</span></p><p><span><a href="#the_best_darpa_program_managers_notice_systemic_biases">The best program managers notice systemic biases and attack them. </a></span><span>For example, noticing that all of the finite element modeling literature
      assumes a locally static situation and asking ‘what if it was dynamic?’ </span><span>“The best program managers can get into the trees and still see the forest.”</span><span> Obviously, this
      quality is rather fuzzy but leads to two precise questions:</span></p>
  <ol ="1"="">
    <li><span>How do you find people who can uncover systemic biases in a discipline? </span></li>
    <li><span>How could you systematize finding systemic biases in a discipline?</span></li>
  </ol>
  <p><span>The first question suggests that you should seek out heretics and people with expertise who are not experts. The second question suggests building structured frameworks for mapping a discipline and its assumptions.
    </span></p><p><span><a href="#a_large_part_of_a_darpa_program_manager’s_job_is_focused_network_building">A large part of a DARPA program manager’s job is focused network building</a></span><span>. </span><span>DARPA PMs network in the literal
      sense of creating networks, not just plugging into them. PMs meet disparate people working on ideas adjacent to the area in which they want to have an impact and bring them together in small workshops to dig into which possibilities are not
      impossible and what it would take to make them possible. The PMs host </span><span>performer days</span><span>&nbsp;— small private conferences for all the people working on different pieces of the program where
      performers can exchange ideas on what is working, what isn’t working, and build connections that don’t depend on the PM. </span><span><a href="https://en.wikipedia.org/wiki/J._C._R._Licklider">J.C.R. Licklider</a></span><a id="footnote_source_2" href="#footnote_2"><sup>2</sup></a><span>&nbsp;is a
      paragon here. He brought together all the crazy people interested in human-focused computing. On top of that, &nbsp;he also helped create the first computer science lab groups. PMs also build networks of people in different classes of organizations –
      government, academia, startups, and large companies. These connections smooth the path for technologies to go from the lab to the shelf. </span></p><p><span><a href="#darpa_pms_need_to_think_for_themselves,_be_curious,_and_have_low_ego">DARPA PMs need to think for themselves, be curious, and have low ego.</a></span><span>&nbsp;</span><span>Why does this matter? When you are
      surrounded by smart, opinionated people the easy option is to either 100% accept what they’re saying because it’s eloquent and well-thought through or reject it outright because it sounds crazy or goes against your priors. Thinking
      for yourself allows you to avoid these traps. PMs need to be curious because building a complete picture of a discipline requires genuine curiosity to ask questions nobody else is asking. A large ego would lead to a program manager imposing
      their will on every piece of the program, killing curiosity and the benefits of top down problems and bottom up solutions.</span></p><p><span><a href="#darpa_is_incredibly_flexible_with_who_it_hires_to_be_program_managers">DARPA is incredibly flexible with who it hires to be program managers.</a></span><span>&nbsp;</span><span>There are legal provisions in place that
      let DARPA bypass normal government hiring rules and procedures. Hiring flexibility is important because PMs are the sort of people who are in high demand, so they may be unwilling to jump through hoops. Bureaucracies ensure consistency through
      rules – minimal bureaucracy means there are no safeguards against hiring a terrible program manager so the principle that ‘A players hire A players and B players hire C players’ is incredibly important. &nbsp;</span></p><p><span><a href="#darpa_program_managers_have_a_tenure_of_four_to_five_years">DARPA Program managers have a tenure of four to five years.</a></span><span>&nbsp;</span><span>This transience is important for many reasons.
      Transience can inculcate PMs against the temptation to play it safe or play power games because there’s only one clear objective – make the program work. You’re out regardless of success or failure. Explicitly temporary roles can
      incentivize people with many options to join because they can have a huge impact, and then do something else. There’s no implicit tension between the knowledge that most people will leave eventually and the uncertainty about when that
      will be. Regular program manager turnover means that there is also turnover in ideas.</span></p><p><span><a href="#why_do_people_become_darpa_program_managers?">Why do people become DARPA Program managers? </a></span>From a career and money standpoint, being a program manager seems pretty rough.<span>&nbsp;There are unique benefits though. It offers an outlet for people frustrated with the conservative nature of academia. The prospect of getting to control a lot of money without a ton of oversight appeals to some people.
      Patriotism is definitely a factor, and hard to replicate outside of a government. Being a PM can gain you the respect of a small, elite group of peers who will know what you did. Finally, there may be a particular technological vision they want
      to see out in the world and DARPA gives them the agency to make it happen in unique ways.</span></p>
  <h2 id="incentives_and_structure_mini"><span>Incentives and Structure</span></h2><p><span><a href="#opacity_is_important_to_darpa’s_outlier_success">Opacity is important to DARPA’s outlier success.</a></span><span>&nbsp;</span><span>Congress and the DoD have little default oversight
      into how a PM is spending money and running a program. </span><span>Opacity removes incentives to go for easy wins or to avoid being criticized by external forces. Of course, opacity can also be abused in too many ways to list,
      so it’s important to ask: How does DARPA incentivize people not to abuse opacity? DARPA’s small size and flat structure enable peer pressure to work in …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjaminreinhardt.com/wddw">https://benjaminreinhardt.com/wddw</a></em></p>]]>
            </description>
            <link>https://benjaminreinhardt.com/wddw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23670246</guid>
            <pubDate>Sun, 28 Jun 2020 17:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hacker News front page in the style of a print newspaper]]>
            </title>
            <description>
<![CDATA[
Score 618 | Comments 132 (<a href="https://news.ycombinator.com/item?id=23669650">thread link</a>) | @wolfgang42
<br/>
June 28, 2020 | https://www.wolfgangfaust.com/project/paper-hn/ | <a href="https://web.archive.org/web/*/https://www.wolfgangfaust.com/project/paper-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This looks much nicer if you enable JavaScript.</p><div><section><img src="https://assets.mofoprod.net/network/images/mozilla-og-image-min.original.jpg"><h2><a href="https://foundation.mozilla.org/en/campaigns/oppose-earn-it-act/">Oppose the Earn IT Act</a></h2><p><code>mozilla.org</code> — While the senators championing the bill, which they’ve named the Eliminating Abusive and Rampant Neglect of Interactive Technologies Act (EARN IT Act), may have good intentions, they are seriously misguided about the impact of their proposal. Encryption ensures our information, from our sensitive financial and medical details to emails and text messages, is protected. But the EARN IT Act will create a broad path for government actors to seriously undermine strong encryption, putting our information at risk. That’s why Mozilla is joining dozens of other internet health and civil society organizations in calling on the U.S. Congress to vote no on the EARN IT Act. <strong><a href="https://news.ycombinator.com/item?id=23703367">OPPOSE</a>,&nbsp;1</strong></p></section><section><img src="https://avatars1.githubusercontent.com/u/342708?s=400&amp;v=4"><h2><a href="https://github.com/duckduckgo/Android/issues/527">DuckDuckGo browser seemingly sends domains a user visits to DDG servers</a></h2><p><code>github.com</code> — GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together. <strong><a href="https://news.ycombinator.com/item?id=23708166">DUCKDUCKGO</a>,&nbsp;2</strong></p></section><section><img src="https://nyansatan.github.io/lightning/resources/cover.jpg"><h2><a href="https://nyansatan.github.io/lightning/">Apple Lightning</a></h2><p><code>nyansatan.github.io</code> — Example of Tristar CRAM exchange #appleinternal pic.twitter.com/x9ffWWTlAb <strong><a href="https://news.ycombinator.com/item?id=23705546">LIGHTNING</a>,&nbsp;3</strong></p></section><section><img src="https://balkaninsight.com/wp-content/uploads/2020/06/poza_1_procuratura_0-e1593517418305.jpg"><h2><a href="https://balkaninsight.com/2020/06/30/moldova-shuts-down-bootleg-helicopter-factory/">Moldova Shuts Down Bootleg Helicopter Factory</a></h2><p><code>balkaninsight.com</code> —  Moldovan officers raid the clandestine helicopter factory in the eastern Criuleni district. Photo: Moldovan Police/Facebook. <strong><a href="https://news.ycombinator.com/item?id=23702564">MOLDOVA</a>,&nbsp;4</strong></p></section><section><img src="https://images.wsj.net/im-204654/social"><h2><a href="https://www.wsj.com/articles/who-is-the-mystery-shopper-leaving-behind-all-those-online-shopping-carts-11593617464">A Google bot scrapes pricing info by adding items to carts</a></h2><p><code>wsj.com</code> —  John Smith started shopping early on a recent Wednesday and didn’t stop for days.  <strong><a href="https://news.ycombinator.com/item?id=23704123">BOT</a>,&nbsp;5</strong></p></section><section><img src="https://nim-lang.org/assets/img/twitter_banner.png"><h2><a href="https://nim-lang.org/blog/2020/06/30/ray-tracing-in-nim.html">Ray Tracing in Nim</a></h2><p><code>nim-lang.org</code> — Trace of Radiance is an implementation of Ray Tracing in One Weekend in the Nim programming language. <strong><a href="https://news.ycombinator.com/item?id=23707286">RAY</a>,&nbsp;6</strong></p></section><section><h2><a href="https://jayriverlong.github.io/2020/06/30/coffee.html">No More Coffee</a></h2><p><code>jayriverlong.github.io</code> — I never identified as a coffee snob or someone with a serious habit – like everyone else, I made lots of self-deprecating jokes about how much coffee I drank – until one day I realized that I had been drinking more coffee than anyone else I knew for the past fifteen years. <strong><a href="https://news.ycombinator.com/item?id=23708204">COFFEE</a>,&nbsp;7</strong></p></section><section><img src="https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/all-new-f-150-017-1593110070.jpg?crop=0.702xw:0.526xh;0.0401xw,0.339xh&amp;resize=1200:*"><h2><a href="https://www.roadandtrack.com/new-cars/car-technology/a32970167/f-150-generator-pro-power-onboard/">How the 2021 Ford F-150's onboard generator works</a></h2><p><code>roadandtrack.com</code> — Putting household-style electrical outlets in a production vehicle is nothing new. Minivans, trucks, and family cars have long offered onboard power for charging devices or powering low-demand equipment. But for the new F-150, Ford stepped it up significantly. The new truck is equipped with a generator system that can run power tools, mini fridges, loudspeakers, and more. Getting to that level of power, though, wasn't easy. <strong><a href="https://news.ycombinator.com/item?id=23704497">F-150</a>,&nbsp;8</strong></p></section><section><h2><a href="https://www.kongregate.com/forums/1-kongregate/topics/1916387-important-kongregate-announcement">Kongregate closed to new games, shutting down forums and chat</a></h2><p><code>kongregate.com</code> — What does this mean for me? You will always be able to play your favorite games on Kongregate. However, certain site features may suddenly stop working and leave you with a severely degraded experience. <strong><a href="https://news.ycombinator.com/item?id=23705174">KONGREGATE</a>,&nbsp;9</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23702122">Ask HN: Who is hiring? (July 2020)</a></h2><p><code>news.ycombinator.com</code> — Please state the job location and include the keywords REMOTE, INTERNS and/or VISA when the corresponding sort of candidate is welcome. When remote work is not an option, include ONSITE. <strong><a href="https://news.ycombinator.com/item?id=23702122">JULY</a>,&nbsp;10</strong></p></section><section><img src="https://whimsical.club/assets/images/screenshots/webrocker.jpg"><h2><a href="https://whimsical.club/">The Whimsical Website Club</a></h2><p><code>whimsical.club</code> — A curated list of sites with an extra bit of fun. <strong><a href="https://news.ycombinator.com/item?id=23704270">WHIMSICAL</a>,&nbsp;11</strong></p></section><section><img src="https://i.guim.co.uk/img/media/be1720f693dc3ea978bc3abee7d0c99c28fdc5cd/0_96_1690_1014/master/1690.jpg?width=1200&amp;height=630&amp;quality=85&amp;auto=format&amp;fit=crop&amp;overlay-align=bottom%2Cleft&amp;overlay-width=100p&amp;overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&amp;enable=upscale&amp;s=73058ca5723010a00695e81ea02a2792"><h2><a href="https://www.theguardian.com/environment/2020/jul/01/more-than-350-elephants-dead-in-mysterious-mass-die-off-botswana-aoe">Hundreds of Botswana elephants dead in mysterious mass die-off</a></h2><p><code>theguardian.com</code> — Botswana’s government is yet to test the remains of the dead animals in what has been described as a ‘conservation disaster’ <strong><a href="https://news.ycombinator.com/item?id=23707920">HUNDREDS</a>,&nbsp;12</strong></p></section><section><img src="https://ciechanow.ski/images/anchor.png"><h2><a href="https://ciechanow.ski/lights-and-shadows/">Lights and Shadows</a></h2><p><code>ciechanow.ski</code> — It’s hard to describe how paramount light is. Ultimately, it is the only thing we see. But just as important the presence of light is, so is its absence. To talk about light we have to start in darkness so let’s jump straight into it. <strong><a href="https://news.ycombinator.com/item?id=23702552">LIGHTS</a>,&nbsp;13</strong></p></section><section><h2><a href="https://www.youtube.com/watch?v=zikI2fazPLo">Fighter pilot breaks down every button in an F-15 cockpit [video]</a></h2><p><code>youtube.com</code> —                                      <strong><a href="https://news.ycombinator.com/item?id=23702560">FIGHTER</a>,&nbsp;14</strong></p></section><section><h2><a href="https://www.youtube.com/watch?v=vuMg0QwKAGI">Not a Wheelchair [video]</a></h2><p><code>youtube.com</code> —                                      <strong><a href="https://news.ycombinator.com/item?id=23701394">WHEELCHAIR</a>,&nbsp;15</strong></p></section><section><h2><a href="http://www.gutenberg.org/files/9097/9097.txt">Robert's Rules of Order (1876)</a></h2><p><code>gutenberg.org</code> —  <strong><a href="https://news.ycombinator.com/item?id=23688430">ROBERT</a>,&nbsp;16</strong></p></section><section><img src="https://dpkqkssmbsv3o.cloudfront.net/social.png"><h2><a href="https://decentdrops.com/">Show HN: Browse recently expired, pronounceable domain names (Part II)</a></h2><p><code>decentdrops.com</code> — Our goal is to provide you with a goldmine. hide <strong><a href="https://news.ycombinator.com/item?id=23704983">BROWSE</a>,&nbsp;17</strong></p></section><section><img src="https://avatars1.githubusercontent.com/u/16842314?s=400&amp;v=4"><h2><a href="https://github.com/photonlines/Intuitive-Guide-to-Maxwells-Equations">Intuitive Guide to Maxwell's Equations</a></h2><p><code>github.com</code> —  An intuitive and visual guide to understanding Maxwell's equations.  <strong><a href="https://news.ycombinator.com/item?id=23700295">INTUITIVE</a>,&nbsp;18</strong></p></section><section><img src="https://mediadc.brightspotcdn.com/dims4/default/f203693/2147483647/strip/true/crop/2290x1202+0+60/resize/1200x630!/quality/90/?url=https%3A%2F%2Fmediadc.brightspotcdn.com%2F58%2F29%2Fd728e9724e3a84349c9c73874f87%2Fjosh-s-nuclear-story-1.jpg"><h2><a href="https://www.washingtonexaminer.com/policy/energy/california-developer-of-micro-nuclear-reactor-aims-to-prove-environmentalist-doubters-wrong">Oklo (YC S14), maker of 'micro' nuclear reactor, aims to prove doubters wrong</a></h2><p><code>washingtonexaminer.com</code> — Jacob DeWitte is determined to shake up the struggling nuclear energy industry by moving his company, Oklo, through the cumbersome U.S. regulatory process faster than anyone before. <strong><a href="https://news.ycombinator.com/item?id=23679934">OKLO</a>,&nbsp;19</strong></p></section><section><img src="https://image.cnbcfm.com/api/v1/image/106004126-1562333829839gettyimages-811025648.jpeg?v=1562333857"><h2><a href="https://www.cnbc.com/2020/07/01/san-francisco-one-bedroom-rent-price-drops-11point8percent-in-june-zumper.html">San Francisco apartment rent prices are dropping fast</a></h2><p><code>cnbc.com</code> — New monthly data from apartment rental platform Zumper shows San Francisco rents were down nearly 12% year over year in June, making the city's decline the largest in the nation, and a record slide for San Francisco. It's also the second consecutive month San Francisco rental prices have dropped, says the company, which based these statistics on 9,000 listings in San Francisco.  <strong><a href="https://news.ycombinator.com/item?id=23705741">APARTMENT</a>,&nbsp;20</strong></p></section><section><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg"><h2><a href="https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/">Raspberry Pi 4 PCIe bridge “chip”</a></h2><p><code>zakkemble.net</code> — AVR-GCC 10.1.0 for Windows 32 and 64 bit  <strong><a href="https://news.ycombinator.com/item?id=23701208">PCIE</a>,&nbsp;21</strong></p></section><section><img src="https://diamantidis.github.io/assets/social/tips/list-makefile-targets.png"><h2><a href="https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">How to list all the targets on a Makefile</a></h2><p><code>diamantidis.github.io</code> — make is great tool to orchestrate the setup and build process of a project. It expects a Makefile, where we define targets to execute, like for example install and run. Then we can use make install and make run to execute those tasks. <strong><a href="https://news.ycombinator.com/item?id=23702756">TARGETS</a>,&nbsp;22</strong></p></section><section><h2><a href="https://news.ycombinator.com/item?id=23700275">Launch HN: PostEra (YC W20) Medicinal Chemistry-as-a-Service and Covid Moonshot</a></h2><p><code>news.ycombinator.com</code> — Hey everyone! We’re Alpha, Matt and Aaron, co-founders of PostEra (https://postera.ai/). The title above is quite a mouthful (we used all 80 characters) so we'll begin by breaking down what it means. <strong><a href="https://news.ycombinator.com/item?id=23700275">POSTERA</a>,&nbsp;23</strong></p></section><section><img src="https://travis-ci.org/konlpy/konlpy.svg?branch=master"><h2><a href="https://konlpy.org/">KoNLPy: Korean NLP in Python</a></h2><p><code>konlpy.org</code> — KoNLPy (pronounced “ko en el PIE”) is a Python package for natural language processing (NLP) of the Korean language. For installation directions, see here. <strong><a href="https://news.ycombinator.com/item?id=23689258">KONLPY</a>,&nbsp;24</strong></p></section><section><img src="https://pbs.twimg.com/profile_images/1178728529187495937/xbH7cGaT_400x400.jpg"><h2><a href="https://www.rankscience.com/blog/pinterest-image-seo-growth-hack">Deconstructing Pinterest’s reverse-image-search SEO growth hack</a></h2><p><code>rankscience.com</code> — By Ryan Bednar (CEO of RankScience) <strong><a href="https://news.ycombinator.com/item?id=23701998">DECONSTRUCTING</a>,&nbsp;25</strong></p></section><section><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fs3-ap-northeast-1.amazonaws.com%2Fpsh-ex-ftnikkei-3937bb4%2Fimages%2F2%2F8%2F6%2F0%2F27940682-3-eng-GB%2FCropped-1593285664photo_Data.jpg?source=nar-cms&amp;width=1024&amp;height=512&amp;fit=cover&amp;gravity=faces"><h2><a href="https://asia.nikkei.com/Business/Automobiles/Japan-auto-companies-triple-Mexican-pay-rather-than-move-to-US">Japan auto companies triple Mexican pay rather than move to US</a></h2><p><code>nikkei.com</code> — Trump hailed new NAFTA as American job generator, but higher prices appear in offing <strong><a href="https://news.ycombinator.com/item?id=23706013">JAPAN</a>,&nbsp;26</strong></p></section><section><img src="https://cdn.substack.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png"><h2><a href="https://yassine.substack.com/p/the-gap-between-learning-code-and">The gap between learning code and producing usable software</a></h2><p><code>substack.com</code> — One of the unspoken areas about software development is building usable software. Learning how to code, coding something, and having it used by thousands is no easy task. In this article, I’ll be discussing the most important pillars that you need to address before launching your product.&nbsp; <strong><a href="https://news.ycombinator.com/item?id=23702061">PRODUCING</a>,&nbsp;27</strong></p></section><section><img src="https://cdn.cjr.org/wp-content/uploads/2020/07/AdobeStock_170520436-800x419.jpeg"><h2><a href="https://www.cjr.org/special_report/reporting-on-facebook.php">What It’s Like to Report on Facebook</a></h2><p><code>cjr.org</code> — One day in July 2016, Casey Newton, a tech reporter for The Verge, sat down at Facebook headquarters in Menlo Park for the biggest interview of his career. Across from him was Mark Zuckerberg. With his characteristic geeky excitement, Zuckerberg described the promising initial test flight of Aquila, a drone with a wingspan larger than a 737 jet that was part of his plan to provide internet connectivity all over the world.  <strong><a href="https://news.ycombinator.com/item?id=23701304">REPORT</a>,&nbsp;28</strong></p></section><section><img src="https://media1.fdncms.com/sevendaysvt/imager/u/slideshow/30705692/business1-03-31cb983461cb18ba.jpg"><h2><a href="https://www.sevendaysvt.com/vermont/magic-hat-leaves-behind-a-transformed-craft-beer-industry-in-vermont/Content?oid=30705701">Magic hat leaves behind a transformed craft beer industry in Vermont</a></h2><p><code>sevendaysvt.com</code> —  Seven Days needs your financial support! <strong><a href="https://news.ycombinator.com/item?id=23702415">BEER</a>,&nbsp;29</strong></p></section><section><p><a href="https://apply.workable.com/jerry/j/E627670571/"><strong>Jerry (YC S17) Is Hiring</strong> Senior Full Stack Engineers (Silicon Valley; Toronto)</a> <code>workable.com</code></p></section><section><p><a href="https://angel.co/company/lazylantern/jobs"><strong>Lazy Lantern (YC S19) is hiring</strong> senior back-end and full-stack engineers</a> <code>angel.co</code></p></section><section><p><a href="https://jobs.lever.co/givecampus/874d7233-b7a3-488d-892e-13ef717ceab7"><strong>GiveCampus (YC S15) hiring</strong> Sr Engineers and Product passionate about education</a> <code>lever.co</code></p></section></div></div>]]>
            </description>
            <link>https://www.wolfgangfaust.com/project/paper-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23669650</guid>
            <pubDate>Sun, 28 Jun 2020 16:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up function calls with lru_cache in Python]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23668914">thread link</a>) | @Immortal333
<br/>
June 28, 2020 | https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html | <a href="https://web.archive.org/web/*/https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
          
        
        <p>One line summary: Use <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">lru_cache decorator</a></p>

<h3 id="caching">Caching</h3>

<p>If we’re calling expensive functions in the program very frequently, It’s best to save the result of a function call and use it for future purposes rather than calling function every time. This will generally speed up the execution of the program.</p>
<blockquote>
  <p>The expensiveness of function can be in terms of computational (CPU usage) or latency (disk read, fetching a resource from the network).</p>
</blockquote>

<p>The saving result of function calls is generally referred to as caching. The naive way to do caching is to store every function calls. But, this doesn’t scale very well with the number of parameters of function and range of each parameter.</p>

<p>So, we need a smart way to do caching with a fixed amount of memory. And, there are plenty of <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies">caching strategies available</a> depending upon what type of information is available to us.</p>

<blockquote>
  <p>Caching is heavily used in plenty of areas from low-level (hardware/CPU) to high level (network/CDNs).</p>
</blockquote>

<p>In most of the languages, We will choose caching strategies of our choice and implement them using a few data structures (hashmap, priority queue). Depending upon the language, It might take as little as few minutes to few hours to implement the generic solution of our need.</p>

<p>But, Python’s standard library <a href="https://docs.python.org/3/library/functools.html">functools</a> already comes with one strategy of caching called <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">LRU(Least Recently Used)</a>. Thanks to <a href="https://wiki.python.org/moin/PythonDecorators">decorators</a> in python, It only takes one line to integrate into the existing codebase</p>

<h3 id="basic-recursive-implementation-of-fibonacci-numbers">Basic Recursive Implementation of <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci numbers</a></h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output : 
# Time taken: 0.3209421634674072
</span></code></pre></div></div>

<h3 id="speeding-up-recursive-implementation-with-lru">Speeding Up Recursive Implementation with LRU</h3>
<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span># saving all function calls
</span><span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>31</span><span>)</span>
<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
<span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>


<span># Output :
# Time taken: 1.7881393432617188e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>In this example, we have saved all function calls. But, We know that Fibonacci can be implemented using <a href="https://en.wikipedia.org/wiki/Dynamic_programming">DP</a>.</p>

<h3 id="iterative-implementation-of-fibonacci">Iterative implementation of Fibonacci</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>

<span>def</span> <span>fib_iterative</span><span>(</span><span>n</span><span>):</span>
  <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
    <span>return</span> <span>n</span>
  <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
  <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>n</span><span>-</span><span>1</span><span>):</span>
    <span>t</span> <span>=</span> <span>f</span> <span>+</span> <span>s</span>
    <span>f</span><span>,</span> <span>s</span> <span>=</span> <span>s</span><span>,</span> <span>t</span>
  <span>return</span> <span>t</span>

<span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
<span>fib_iterative</span><span>(</span><span>30</span><span>)</span>
<span>print</span> <span>(</span><span>f"Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>

<span># Output:
# Time taken: 5.0067901611328125e-06
</span></code></pre></div></div>

<h3 id="different-cache-size">Different Cache size</h3>

<div><div><pre><code><span>import</span> <span>time</span> <span>as</span> <span>tt</span>
<span>import</span> <span>functools</span>

<span>def</span> <span>lru_size</span><span>(</span><span>max_lru</span><span>):</span>
    <span>@</span><span>functools</span><span>.</span><span>lru_cache</span><span>(</span><span>maxsize</span><span>=</span><span>max_lru</span><span>,</span> <span>typed</span><span>=</span><span>False</span><span>)</span>
    <span>def</span> <span>fib_lru</span><span>(</span><span>n</span><span>):</span>
        <span>if</span> <span>n</span> <span>&lt;=</span> <span>1</span><span>:</span>
            <span>return</span> <span>n</span>
        <span>return</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib_lru</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
    <span>return</span> <span>fib_lru</span>

<span>for</span> <span>i</span> <span>in</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>5</span><span>,</span> <span>10</span><span>,</span> <span>31</span><span>]:</span>
    <span>t1</span> <span>=</span> <span>tt</span><span>.</span><span>time</span><span>()</span>
    <span>fib</span> <span>=</span> <span>lru_size</span><span>(</span><span>i</span><span>)</span>
    <span>fib</span><span>(</span><span>10</span><span>)</span>
    <span>print</span> <span>(</span><span>f"LRU size: </span><span>{</span><span>i</span><span>}</span><span> Time taken: </span><span>{</span><span>tt</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>t1</span><span>}</span><span>"</span><span>)</span>
    <span>print</span> <span>(</span><span>fib</span><span>.</span><span>cache_info</span><span>())</span>

<span># Output:
# LRU size: 1 Time taken: 0.6930997371673584
# CacheInfo(hits=0, misses=2692537, maxsize=1, currsize=1)
# LRU size: 2 Time taken: 0.012731075286865234
# CacheInfo(hits=8656, misses=41641, maxsize=2, currsize=2)
# LRU size: 5 Time taken: 5.817413330078125e-05
# CacheInfo(hits=28, misses=31, maxsize=5, currsize=5)
# LRU size: 10 Time taken: 3.9577484130859375e-05
# CacheInfo(hits=28, misses=31, maxsize=10, currsize=10)
# LRU size: 31 Time taken: 3.504753112792969e-05
# CacheInfo(hits=28, misses=31, maxsize=31, currsize=31)
</span></code></pre></div></div>

<p>As, <strong>we can see the optimal cache size of fib function is 5</strong>. Increasing cache size will not result in much gain in terms of speedup.</p>

<h3 id="important-note">Important Note</h3>

<p>I strictly suggest to use lru decorator in only deterministic functions.</p>

<h4 id="deterministic-functions">Deterministic Functions</h4>
<blockquote>
  <p>In computer science, a deterministic algorithm is an algorithm which, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states. Deterministic algorithms are by far the most studied and familiar kind of algorithm, as well as one of the most practical, since they can be run on real machines efficiently.</p>

  <p>– Wikipedia</p>
</blockquote>

<p>Because,</p>

<blockquote>
  <p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>

  <p>– Phil Karlton</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://hackeregg.github.io/2020/06/03/Speeding-up-function-calls-with-just-one-line-in-Python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668914</guid>
            <pubDate>Sun, 28 Jun 2020 14:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Promnesia – an attempt to fix broken web history]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 55 (<a href="https://news.ycombinator.com/item?id=23668507">thread link</a>) | @karlicoss
<br/>
June 28, 2020 | https://beepb00p.xyz/promnesia.html | <a href="https://web.archive.org/web/*/https://beepb00p.xyz/promnesia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
    
    <p>A journey in fixing browser history
    </p></section>
    <!-- are sections appropriate for that? -->

    <section>
    <p>
Promnesia is a browser extension (Chrome/Firefox/Firefox mobile) that serves as a web surfing copilot
by enhancing your browsing history, improving your web exploration experience, and integrating with your knowledge base.
</p>
<p>
<a href="https://github.com/karlicoss/promnesia#readme">The repository</a> contains more information about the project and the setup guide, this post is more about the motivation and the story of what led me to work on it.
</p>
<p>
Also, you can quickly skim through the <a href="https://github.com/karlicoss/promnesia#demos">demos</a> first before reading, if you prefer!
</p>

<div>
<h2 id="singularity_when"><a href="#singularity_when">¶</a><span>1</span> I want my singularity!</h2>
<div id="text-singularity_when">
<p>
I was raised on science fiction and grew up dreaming about technology drastically changing our lives.
Artificial intelligence, augmenting the brain with a math co-processor, head-up displays, neural interfaces, having perfect reaction and memory – many of you are on the same page and know the drill.
</p>
<p>
Years passed, I became a software engineer, and realized just how far we are from all these fancy technologies I wanted.
So my aspirations have become more modest, and I've chosen a more realistic and plausible target:
using my digital trace (such as browser history, webpage annotations and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>) to make up for my limited memory.
</p>
<p>
I'm exploring lots of information on the Internet, and it feels wasteful to use my <a href="https://beepb00p.xyz/tags.html#meatsack">meat resources</a> to keep track of it.
Meanwhile, web browsers keep a record automatically, without any manual and conscious effort.
Surely we can benefit from the immense computing power and memory capabilities of computers?
</p>
<p>
So I figured that I wanted:
</p>
</div>
</div>
<div>
<h2 id="what_i_want"><a href="#what_i_want">¶</a><span>2</span> Ok, maybe a web assistant at least?</h2>
<div id="text-what_i_want">
<p>
A web surfing companion. A copilot.
A <a href="https://en.wikipedia.org/wiki/Memex">Memex</a>.
A <a href="http://alumni.media.mit.edu/~rhodes/Papers/remembrance.html">Remembrance Agent</a>?
</p>
<p>
Call it whatever you like, I <i>wish</i> it were a concept with a widely accepted name. Something that will sit in my browser and:
</p>
<ul>
<li><p>
aid me with <b>information processing</b>
</p>
<p>
Keep track of what I've read, when, on which device, and for how long.
</p></li>
<li><p>
show me my <b>annotations and highlights</b>, within the original page
</p>
<p>
I don't want to keep wondering whether I have my notes and thoughts stashed in some app, I want the computer to let me know instead.
</p></li>
<li><p>
unify my <b>scattered and siloed bookmarks</b>
</p>
<p>
Firefox bookmarks; Reddit/Hackernews saves; "Watch later" on Youtube, saved links in my instant messenger.
</p>
<p>
These are the same damn thing, yet there is no way to oversee and process them through a single interface.
</p>
<p>
<a href="https://jborichevskiy.com/posts/digital-tools/#queue-management-for-inbound-digital-content">"Queue management for inbound digital content"</a>:
a post expanding further on this idea.
</p></li>
<li><p>
connect with my online presence: chats and social networks
</p>
<p>
If I tweeted about a page, surely this should be somehow recorded in the browsing history?
</p>
<p>
In fact, the page that I bothered to tweet about is <b>much</b> more important than a page I merely visited in the browser.
</p></li>
<li><p>
help me explore new information and <b>prioritize</b> it
</p>
<p>
There is so much awesome stuff on the Internet! The biggest problem I have is picking the next cool link to dig into.
</p>
<p>
Imagine if in one click, I could see which of my friends, or the people I follow have read a certain link.
What did they think? Have they posted about it, annotated, or something else? Do they follow the author, perhaps I should too?
</p></li>
<li><p>
bridge the gap between the browser and my <a href="https://beepb00p.xyz/tags.html#exobrain">personal wiki</a>
</p>
<p>
Whatever product I choose for managing my notes: Google Keep, Evernote, Roam Research, or even org-mode files on my disk,
they always end up <b>isolated and disconnected</b> from my web browsing.
</p></li>
</ul>
<p>
I searched for a system like this <a href="https://twitter.com/karlicoss/status/767412935316611072">for</a> several <a href="https://twitter.com/karlicoss/status/896313846159298560">years</a>.
</p>
<p>
After enough failed attempts at finding an <a href="#prior_art">existing solution</a>, I figured it was going to be yet another thing I'd have to implement myself.
</p>
<p>
The journey of building it took longer than I expected, led me through a rabbit hole of <a href="https://beepb00p.xyz/tags.html#dataliberation">data liberation</a>, lots of <a href="https://en.wiktionary.org/wiki/yak_shaving">yak shaving</a>,
and made me realize: <b>browser history is very, very broken</b>.
</p>
<p>
Note: the next two sections are (somewhat technical) rants. If you prefer a more positive/less boring agenda, feel free to skip them straight to <a href="#prior_art">"Existing solutions"</a>
, and you can return back later if you feel like it.
</p>
</div>
</div>
<div>
<h2 id="history_broken"><a href="#history_broken">¶</a><span>3</span> Browser history is broken</h2>
<div id="text-history_broken">
<p>
To a large extent, URLs express <b>relationships and hierarchy</b> between the bits of information. For example:  <code>blog &lt;-&gt; post &lt;-&gt; comment</code>, <code>person &lt;-&gt; tweet</code>, <code>playlist &lt;-&gt; video</code>.
</p>
<p>
With this information you should be easily able to find everything relevant to the current page and trace your jumps through past websites.
Merely by looking at URLs, without "AI" or some dubious machine learning algorithm!
Seems like a low hanging fruit to harvest, right?
</p>
<p>
Web browser history is a rich source of potentially useful information.
Just think about it: it's zero effort <a href="https://beepb00p.xyz/tags.html#lifelogging">lifelogging</a>.
It contains exact timestamps and links which <i>basically</i> address information.
</p>
<p>
Now think about the experience you actually have. What was the last time you used the browser history in any nontrivial way, for something other than reopening an accidentally closed tab?
</p>
<p>
Besides:
</p>
</div>
<div>
<h3 id="not_just_browser"><a href="#not_just_browser">¶</a>it's not just about web browsers</h3>
<div id="text-not_just_browser">
<div><p><span>
When you're using a native phone app (say, for Reddit or Twitter), your history either isn't logged anywhere or if it is, it's only stored locally on your phone.

</span></p></div>
<div><p><span>
On Android, it's likely to be in an Sqlite database in <code>/data/data/app.name</code>.
This directory is not accessible to normal users <b>unless your phone is rooted</b>.
Just think about how ridiculous this is. It's <b>your own data</b>, yet your OS babysits you, preventing access to it.

And yes, I know sandboxing and security are important, but locking my data inside the app is hardly an acceptable tradeoff.
</span></p></div>
<p>
As a specific example, the <a href="https://github.com/ccrama/Slide">Reddit Slide</a> app keeps your view history in <code>/data/data/me.ccrama.redditslide/SEEN</code>.
Okay, say you root your phone and access the database. Turns out the the app isn't persisting the data forever, it's merely keeping a few weeks' cache.
And I can hardly blame the developer for this: because of the data model, no one expects regular users to access this database.
</p>
<p>
So if you want your complete history, you have to backup this database regularly, keep the snapshots and <a href="https://beepb00p.xyz/exports.html#synthetic">somehow</a>
reconstruct it.
</p>
<p>
You may dismiss this as nitpicking and obsession over every last bit of my data.
But when <b>all</b> of your phone apps are doing this you're missing out on quite a lot of useful information.
</p>
</div>
</div>
<div>
<h3 id="siloed"><a href="#siloed">¶</a>it's scattered and siloed</h3>
<div id="text-siloed">
<p>
Building on the previous point:
</p>
<ul>
<li>for the most part, you can't access history in your phone apps</li>
<li>lots of data which <i>ought</i> to be counted as web history is scattered across silos

<ul>
<li><div><p><span>in the cloud: behind APIs (best case), GDPR and manual exports (worst case)

It is never easy to get hands on, <i>even</i> if you're an experienced software engineer.</span></p></div></li>
<li><p>
on the filesystem, for example in markdown/org-mode files
</p>
<p>
A slightly better scenario, but as far as the web browser is concerned, it doesn't make any difference.
</p></li>
</ul></li>
</ul>
<p>
Even <i>regular</i> browser history is not easy to get:
</p>
<ul>
<li>Firefox <a href="https://support.mozilla.org/en-US/questions/1080942">used to</a> silently 'expire' your browser history</li>
<li><p>
Chrome deletes history older than <a href="https://superuser.com/a/364475/300795">90 days</a>
</p>
<p>
The only way to access older history I'm aware of is <a href="https://myactivity.google.com/">Google Activity</a> and Takeout.
</p></li>
<li>Google Takeout <a href="https://beepb00p.xyz/takeout-data-gone.html">quietly recycles your history</a></li>
<li><p>
Migration is limited to the most popular browsers
</p>
<p>
The retention limits the migration as well.
E.g. if you migrate from Chrome to Firefox, history older than 90 days is locked and siloed in your Google Account.
</p></li>
<li><p>
You're going to have a hard time if you're not using Google/Mozilla sync
</p>
<p>
Your history will be scattered across devices and lost on OS reinstalls.
</p>
<p>
There are ways of self-hosting Firefox sync, and (<a href="https://superuser.com/questions/614744/how-to-set-up-a-own-chrome-sync-server">allegedly</a>) even Chrome sync,
but as you can imagine, is quite tedious.
</p></li>
</ul>
</div>
</div>
<div>
<h3 id="significance"><a href="#significance">¶</a>it's got varying significance</h3>
<div id="text-significance">
<p>
Not all links in your history are equally important:
</p>
<ul>
<li>some are clicked on by accident</li>
<li>some you've just skimmed</li>
<li>some are on your reading list</li>
<li>some you've been reading for hours and are full of your highlights and annotations</li>
<li>some you reference in your knowledge base/personal wiki</li>
<li>some of them you've shared with others on social media</li>
</ul>
<p>
The current browser history experience makes no distinction between these scenarios.
</p>
</div>
</div>
</div>
<div>
<h2 id="urls_broken"><a href="#urls_broken">¶</a><span>4</span> URLs are broken</h2>
<div id="text-urls_broken">
<p>
This topic probably deserves a separate post, but I'll keep it section-sized for now.
</p>
<p>
URLs might seem great because they mostly address content and are semi-descriptive: people <i>try</i> to keep URLs somewhat reasonable, tidy and working.
But in the real world:
</p>
<ul>
<li><p>
links <b>rot</b>
</p>
<p>
Many URLs are <a href="https://www.gwern.net/Archiving-URLs#link-rot"><b>literally</b> broken</a>.
We're lucky to have <a href="https://web.archive.org/">archive.org</a>, so you can at least access dead pages.
</p>
<p>
But there is no way to migrate your browser history, e.g. point old URLs to their respective archive.org entries or a new domain.
Similarly if you had the page annotated, your annotations become orphans without an easy way to relink them.
</p></li>
<li><p>
links are <b>obfuscated</b> by shortening and redirects
</p>
<div><p><span>
What happens to all the <code>t.co</code> links when Twitter as a service dies?

</span></p></div></li>
<li><p>
links are <b>obscured</b>
</p>
<p>
There is no easy way to know what's behind <code>https://www.instapaper.com/read/1265139707</code> without querying the Instapaper API.
</p>
<p>
Relations between data are often obscured as well. For example:
</p>
<ul>
<li><code>https://news.ycombinator.com/item?id=22918980</code> is a submission link</li>
<li><code>https://news.ycombinator.com/item?id=22919718</code> is a comment to that submission</li>
</ul>
<p>
These links are clearly related, but there is no way to tell it just from <samp>id</samp>.
</p>
<p>
Compare this to Reddit links:
</p>
<ul>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is</code> is a post link</li>
<li><code>https://reddit.com/r/orgmode/comments/g6ejwe/is_there_an_orgmode_workbook_tutorial_that_is/fo9qnen</code> is a comment to that post</li>
</ul>
<p>
The ids are obscure, but at least we can clearly see the <code>post &lt;-&gt; comment</code> relation merely by looking at the URLs.
Alas, browsers are just ignoring this useful information.
</p></li>
<li><p>
links are <b>unstandardized</b>
</p>
<p>
For example, <a href="https://en.wikipedia.org/wiki/Query_string">queries</a>
</p>
<ul>
<li>typically don't point to anything persistent and are used for querying (duh)</li>
<li>but other times they are used to address information: <code>http://wiki.c2.com/?LispLanguage</code> or <code>https://www.scottaaronson.com/blog/?p=2694</code></li>
<li>and in many cases are utter garbage used for <a href="https://en.wikipedia.org/wiki/Query_string#Tracking">tracking</a></li>
</ul>
<p>
The worst part is that these use cases overlap. For example, take a look at <code>youtube.com/watch?v=wHrCkyoe72U&amp;feature=share&amp;t…</code></p></li></ul></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beepb00p.xyz/promnesia.html">https://beepb00p.xyz/promnesia.html</a></em></p>]]>
            </description>
            <link>https://beepb00p.xyz/promnesia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668507</guid>
            <pubDate>Sun, 28 Jun 2020 13:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Controversies and Challenges in fMRI (2018)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23668279">thread link</a>) | @saadalem
<br/>
June 28, 2020 | http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/ | <a href="https://web.archive.org/web/*/http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-294">
	<!-- .entry-header -->

	
	
	<div>
		<h2><em><strong>•Neurovascular Coupling</strong></em><em><strong>•Draining Veins</strong></em><em><strong>•Linearity</strong></em><em><strong>•Pre-undershoot</strong></em><em><strong>•Post-undershoot</strong></em><em><strong>•Long duration</strong></em><em><strong>•Mental Chronometry</strong></em><em><strong>•Negative Signal Changes</strong></em><em><strong>•Resting state source</strong></em><em><strong>•Dead fish activation</strong></em><em><strong>•Voodoo correlations</strong></em><em><strong>•Global signal regression</strong></em><em><strong>•Motion artifacts</strong></em><em><strong>•The decoding signal</strong></em><em><strong>•non-neuronal BOLD</strong></em><em><strong>•relationship to other measures</strong></em><em><strong>•contrast: spin-echo vs gradient-echo</strong></em><em><strong>•contrast: SEEP contrast</strong></em><em><strong>•contrast: diffusion changes</strong></em><em><strong>•contrast: neuronal currents</strong></em><em><strong>•contrast: NMR phase imaging</strong></em><em><strong>•lie detection</strong></em><em><strong>•correlation ≠ connection</strong></em><em><strong>•clustering conundrum</strong></em><em><strong>•reproducibility</strong></em><em><strong>•dynamic connectivity changes</strong></em></h2>
<hr>
<h4><em><strong>This will be a chapter in my upcoming book “Functional MRI” </strong><strong>in the MIT Press Essential Knowledge Series&nbsp;</strong></em></h4>
<hr>
<p>Functional MRI is unique in that, in spite of being almost 30 years old as a method, it continues to progress in terms of sophistication of acquisition, hardware, processing, in our understanding of the signal itself. There has been no plateau in any of these areas. In fact, by looking at the literature, one gets the impression that this advancement is accelerating. Every new advance opens the potential range where it might have an impact, allowing new questions about the brain to be addressed.</p>
<p>In spite of its success – perhaps as a result of its success – it has had its share of controversies coincident with methods advancements, new observations, and novel applications. Some controversies have been more contentious than others. Over the years, I’ve been following these controversies and have at times performed research to resolve them or at least better understand them. A good controversy can help to move the field forward as it can focus and motivate groups of people to work on the issue itself, shedding a broader light on the field as these are overcome.</p>
<p>While a few of the controversies or issues of contention have been fully resolved, most remain to some degree unresolved. Understanding fMRI through its controversies allows a deeper appreciation for how the field advances as a whole – and how science really works – the false starts, the corrections, and the various claims made by those with potentially useful pulse sequences, processing methods, or applications. Below is the list of twenty-six major controversies in fMRI – in approximately chronological order.</p>
<h2>#1: The Neurovascular coupling debate.</h2>
<p>Since the late 1800’s, the general consensus, hypothesized by Roy and Sherrington in 1890 (1), was that activation-induced cerebral flow changes were driven by local changes in metabolic demand. In 1986, a publication by Fox et al. (2)challenged that view, demonstrating that with activation, localized blood flow seemingly increased beyond oxidative metabolic demand, suggesting an “uncoupling” of the hemodynamic response from metabolic demand during activation. Many, including Louis Sokolof, a well-established neurophysiologist at the National Institutes of Health, strongly debated the results. Fox nicely describes this period in history from his perspective in “The coupling controversy” (3).</p>
<p>I remember well, in the early days of fMRI, Dr. Sokolof standing up from the audience to debate Fox on several circumstances, arguing that the flow response should match the metabolic need and there should be no change in oxygenation. He argued that what we are seeing in fMRI is something other than an oxygenation change.</p>
<p>In the pre-fMRI days, I recall not knowing what direction the signal should go – as when I first laid eyes on the impactful video presented by Tom Brady during his plenary lecture on the future of MRI at the Society for Magnetic Resonance (SMR) Meeting in August of 1991, it was not clear from these time series movies of subtracted images the direction he performed the subtraction operation. Was it task minus rest or rest minus task? Did the signal go up or down with activation? I also remember very well, analyzing my first fMRI experiments, expecting to see a decrease in BOLD signal – as Ogawa, in an earlier paper(4), hypothesized that metabolic rate increases would lead to a decrease blood oxygenation thus a darkening of the BOLD signal during brain activation. Instead, all I saw were signal increases. It was Fox’s work that helped me to understand why the BOLD signal should <em>increase</em>with activation. Flow goes up and oxygen delivery exceeds metabolic need, leading to an increase in blood oxygenation.</p>
<p>While models of neurovascular coupling have improved, we still do not understand the precise need for flow increases. First, we had the “watering the whole garden to feed one thirsty flower” hypothesis which suggested that flow increases matched metabolic need for one area but since vascular control was coarse, the abundant oxygenation was delivered to a wider area than was needed, causing the increase in oxygenation. We also had the “diffusion limited” model, where it was hypothesized that in order to deliver enough oxygen to the furthest neurons from the oxygen supplying vessels, an overabundance of oxygen was needed at the vessel itself since the decrease of oxygen as it diffused from the vessel to the furthest cell was described as an exponential. &nbsp;This theory has fallen a bit from favor as the increases in CMRO<sub>2</sub>or the degree to which the diffusion of oxygen to tissue from blood is limited tend to be higher than physiologic measures. The alternative to the metabolic need hypothesis involves neurogenic “feed-forward” hypotheses – which still doesn’t get at the “why” of the flow response.</p>
<p>Currently, this is where the field stands. We know that the flow response is robust and consistent. We know that in active areas, oxygenation in healthy brains always increases, however we just don’t understand specifically why it’s necessary. Is it a neurogenic, metabolic, or some other mechanism to satisfy some evolutionary critical need that extends beyond simple need for more oxygen? We are still figuring that out. Nevertheless, it can be said that whatever the reason for this increase in flow, it is fundamentally important, as the BOLD response is stunningly consistent.</p>
<h2>#2: The Draining Vein Effect</h2>
<p>The question: “what about the draining veins?” I think was first posited at an early fMRI conference by Kamil Ugurbil of the University of Minnesota. Here and for the next several years he alerted the community to the observation that, especially at low field, draining veins are a problem as they smear and distort the fMRI signal change such that it’s hard to know specifically where the underlying neuronal activation is with a high degree of certainty. In the “20 years of fMRI: the science and the stories” special issue of NeuroImage, Ravi Menon writes a thorough narrative of the “Great brain vs vein” debate (5). &nbsp;When the first fMRI papers were published, only one, by Ogawa et al. (6), was at high field – 4 Tesla – and relatively high resolution. In Ogawa’s paper, it was shown that there was a differentiation between veins (very hot spots) and capillaries (more diffuse weaker activation in grey matter). Ravi followed this up with another paper (7)using multi-echo imaging, to show that blood in veins had an intrinsically shorter T2* decay than gray matter at 4T and appeared as dark dots in T2* weighted structural images yet appeared as bright functional hot spots in the 4T functional images. Because of the low SNR and CNR at 1.5T, allowing only the strongest BOLD effects to be seen, and because models suggested that at low field strengths, large vessels contributed the most to the signal, the field worried that all fMRI was looking at was veins – at least at 1.5T.</p>
<p>The problem of large vein effects is prevalent using standard gradient-echo EPI – even at high fields. Simply put, the BOLD signal is directly proportional to the venous blood volume contribution in each voxel. If the venous blood volume is high – as with the case of a vein filling a voxel – then the potential for high BOLD changes is high if there is a blood oxygenation change in the area. At high field, indeed, there is not much intravascular signal left in T2* weighted Gradient-echo sequences, however, the extravascular effect of large vessels still exists.&nbsp; Spin-echo sequences (sensitive to small compartments) still are sensitive to the susceptibility effects around intravascular red blood cells within large vessels – even at 7T where intravascular contribution is reduced. Even with some vein sensitivity, promising high resolution orientation column results have been produced at 7T using gradient-echo and spin-echo sequences (8). The use of arterial spin labeling has potential as a method insensitive to large veins, although the temporal efficiency, intrinsic sensitivity, and brain coverage limitations blunt its utility. Vascular Space Occupancy (VASO), a method sensitive to blood volume changes, has been shown to be exquisitely sensitive to blood volume changes in small vessels and capillaries. Preliminary results have shown clear layer dependent activation using VASO where other approaches have provided less clear delineation(9).</p>
<p>Methods have arisen to identify and mask large vein effects – including thresholding based on percent signal change (large veins tend to fill voxels and thus exhibit a larger fractional signal change), as well as temporal fluctuations (large veins are pulsatile thus exhibit more magnitude and phase noise). While these seem to be workable solutions, they have not been picked up and used extensively. With regard to using the phase variations as a regressor to eliminate pulsatile blood and tissue, perhaps the primary reason for this not being adopted is because standard scanners do not produce these images readily, thus users do not have easy access to this information.</p>
<p>The draining vein issue is least problematic at voxel sizes larger than 2mm, as at these resolutions, mostly the region of activation- as defined as &gt;1 cm “blob” is used and interpreted. Other than enhancing the magnitude of activation, vein effects do not distort these “blobs” thus are typically of no …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/">http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</a></em></p>]]>
            </description>
            <link>http://www.thebrainblog.org/2018/12/23/twenty-six-controversies-and-challenges-in-fmri/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668279</guid>
            <pubDate>Sun, 28 Jun 2020 12:27:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Linux System Calls (2016)]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23668186">thread link</a>) | @crunchbang123
<br/>
June 28, 2020 | https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/ | <a href="https://web.archive.org/web/*/https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This blog post explains how Linux programs call functions in the Linux kernel.</p><p>It will outline several different methods of making systems calls, how to handcraft your own assembly to make system calls (examples included), kernel entry points into system calls, kernel exit points from system calls, glibc wrappers, bugs, and much, much more. </p><div><p>Create a package repository in less than 10 seconds, free.</p></div><ul id="markdown-toc"><li><a href="#tldr" id="markdown-toc-tldr">TL;DR</a></li><li><a href="#what-is-a-system-call" id="markdown-toc-what-is-a-system-call">What is a system call?</a></li><li><a href="#prerequisite-information" id="markdown-toc-prerequisite-information">Prerequisite information</a><ul><li><a href="#hardware-and-software" id="markdown-toc-hardware-and-software">Hardware and software</a></li><li><a href="#user-programs-the-kernel-and-cpu-privilege-levels" id="markdown-toc-user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</a></li><li><a href="#interrupts" id="markdown-toc-interrupts">Interrupts</a></li><li><a href="#model-specific-registers-msrs" id="markdown-toc-model-specific-registers-msrs">Model Specific Registers (MSRs)</a></li><li><a href="#calling-system-calls-with-assembly-is-a-bad-idea" id="markdown-toc-calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</a></li></ul></li><li><a href="#legacy-system-calls" id="markdown-toc-legacy-system-calls">Legacy system calls</a><ul><li><a href="#using-legacy-system-calls-with-your-own-assembly" id="markdown-toc-using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</a></li><li><a href="#kernel-side-int-0x80-entry-point" id="markdown-toc-kernel-side-int-0x80-entry-point">Kernel-side: <code>int $0x80</code> entry point</a></li><li><a href="#returning-from-a-legacy-system-call-with-iret" id="markdown-toc-returning-from-a-legacy-system-call-with-iret">Returning from a legacy system call with <code>iret</code></a></li></ul></li><li><a href="#fast-system-calls" id="markdown-toc-fast-system-calls">Fast system calls</a><ul><li><a href="#32-bit-fast-system-calls" id="markdown-toc-32-bit-fast-system-calls">32-bit fast system calls</a><ul><li><a href="#sysentersysexit" id="markdown-toc-sysentersysexit"><code>sysenter</code>/<code>sysexit</code></a></li><li><a href="#__kernel_vsyscall-internals" id="markdown-toc-__kernel_vsyscall-internals"><code>__kernel_vsyscall</code> internals</a></li><li><a href="#using-sysenter-system-calls-with-your-own-assembly" id="markdown-toc-using-sysenter-system-calls-with-your-own-assembly">Using <code>sysenter</code> system calls with your own assembly</a></li><li><a href="#kernel-side-sysenter-entry-point" id="markdown-toc-kernel-side-sysenter-entry-point">Kernel-side: <code>sysenter</code> entry point</a></li><li><a href="#returning-from-a-sysenter-system-call-with-sysexit" id="markdown-toc-returning-from-a-sysenter-system-call-with-sysexit">Returning from a <code>sysenter</code> system call with <code>sysexit</code></a></li></ul></li><li><a href="#64-bit-fast-system-calls" id="markdown-toc-64-bit-fast-system-calls">64-bit fast system calls</a><ul><li><a href="#syscallsysret" id="markdown-toc-syscallsysret"><code>syscall</code>/<code>sysret</code></a></li><li><a href="#using-syscall-system-calls-with-your-own-assembly" id="markdown-toc-using-syscall-system-calls-with-your-own-assembly">Using <code>syscall</code> system calls with your own assembly</a></li><li><a href="#kernel-side-syscall-entry-point" id="markdown-toc-kernel-side-syscall-entry-point">Kernel-side: syscall entry point</a></li><li><a href="#returning-from-a-syscall-system-call-with-sysret" id="markdown-toc-returning-from-a-syscall-system-call-with-sysret">Returning from a <code>syscall</code> system call with <code>sysret</code></a></li></ul></li></ul></li><li><a href="#calling-a-syscall-semi-manually-with-syscall2" id="markdown-toc-calling-a-syscall-semi-manually-with-syscall2">Calling a syscall semi-manually with syscall(2)</a><ul><li><a href="#glibc-syscall-wrapper-internals" id="markdown-toc-glibc-syscall-wrapper-internals">glibc <code>syscall</code> wrapper internals</a></li></ul></li><li><a href="#virtual-system-calls" id="markdown-toc-virtual-system-calls">Virtual system calls</a><ul><li><a href="#vdso-in-the-kernel" id="markdown-toc-vdso-in-the-kernel">vDSO in the kernel</a></li><li><a href="#locating-the-vdso-in-memory" id="markdown-toc-locating-the-vdso-in-memory">Locating the vDSO in memory</a></li><li><a href="#vdso-in-glibc" id="markdown-toc-vdso-in-glibc">vDSO in glibc</a></li></ul></li><li><a href="#glibc-system-call-wrappers" id="markdown-toc-glibc-system-call-wrappers"><code>glibc</code> system call wrappers</a></li><li><a href="#interesting-syscall-related-bugs" id="markdown-toc-interesting-syscall-related-bugs">Interesting syscall related bugs</a><ul><li><a href="#cve-2010-3301" id="markdown-toc-cve-2010-3301">CVE-2010-3301</a></li><li><a href="#android-sysenter-abi-breakage" id="markdown-toc-android-sysenter-abi-breakage">Android <code>sysenter</code> ABI breakage</a></li></ul></li><li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li><li><a href="#related-posts" id="markdown-toc-related-posts">Related Posts</a></li></ul><p>When you run a program which calls <code>open</code>, <code>fork</code>, <code>read</code>, <code>write</code> (and many others) you are making a system call.</p><p>System calls are how a program enters the kernel to perform some task. Programs use system calls to perform a variety of operations such as: creating processes, doing network and file IO, and much more.</p><p>You can find a list of system calls by checking the <a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">man page for syscalls(2)</a>.</p><p>There are several different ways for user programs to make system calls and the low-level instructions for making a system call vary among CPU architectures.</p><p>As an application developer, you don’t typically need to think about how exactly a system call is made. You simply include the appropriate header file and make the call as if it were a normal function.</p><p><code>glibc</code> provides wrapper code which abstracts you away from the underlying code which arranges the arguments you’ve passed and enters the kernel.</p><p>Before we can dive into the details of how system calls are made, we’ll need to define some terms and examine some core ideas that will appear later.</p><h2 id="hardware-and-software">Hardware and software</h2><p>This blog post makes the following assumptions that:</p><ul><li>You are using a 32-bit or 64-bit Intel or AMD CPU. The discussion about the methods may be useful for people using other systems, but the code samples below contain CPU-specific code.</li><li>You are interested in the Linux kernel, version 3.13.0. Other kernel versions will be similar, but the exact line numbers, organization of code, and file paths will vary. Links to the 3.13.0 kernel source tree on GitHub are provided.</li><li>You are interested in <code>glibc</code> or <code>glibc</code> derived libc implementations (e.g., <code>eglibc</code>).</li></ul><p>x86-64 in this blog post will refer to 64bit Intel and AMD CPUs that are based on the x86 architecture.</p><h2 id="user-programs-the-kernel-and-cpu-privilege-levels">User programs, the kernel, and CPU privilege levels</h2><p>User programs (like your editor, terminal, ssh daemon, etc) need to interact with the Linux kernel so that the kernel can perform a set of operations on behalf of your user programs that they can’t perform themselves.</p><p>For example, if a user program needs to do some sort of IO (<code>open</code>, <code>read</code>, <code>write</code>, etc) or modify its address space (<code>mmap</code>, <code>sbrk</code>, etc) it must trigger the kernel to run to complete those actions on its behalf.</p><p>What prevents user programs from performing these actions themselves?</p><p>It turns out that the x86-64 CPUs have a concept called <a href="https://en.wikipedia.org/wiki/Privilege_level">privilege levels</a>. Privilege levels are a complex topic suitable for their own blog post. For the purposes of this post, we can (greatly) simplify the concept of privilege levels by saying:</p><ol><li>Privilege levels are a means of access control. The current privilege level determines which CPU instructions and IO may be performed.</li><li>The kernel runs at the most privileged level, called “Ring 0”. User programs run at a lesser level, typically “Ring 3”.</li></ol><p>In order for a user program to perform some privileged operation, it must cause a privilege level change (from “Ring 3” to “Ring 0”) so that the kernel can execute.</p><p>There are several ways to cause a privilege level change and trigger the kernel to perform some action.</p><p>Let’s start with a common way to cause the kernel to execute: interrupts.</p><h2 id="interrupts">Interrupts</h2><p>You can think of an interrupt as an event that is generated (or “raised”) by hardware or software.</p><p>A hardware interrupt is raised by a hardware device to notify the kernel that a particular event has occurred. A common example of this type of interrupt is an interrupt generated when a NIC receives a packet.</p><p>A software interrupt is raised by executing a piece of code. On x86-64 systems, a software interrupt can be raised by executing the <code>int</code> instruction.</p><p>Interrupts usually have numbers assigned to them. Some of these interrupt numbers have a special meaning.</p><p>You can imagine an array that lives in memory on the CPU. Each entry in this array maps to an interrupt number. Each entry contains the address of a function that the CPU will begin executing when that interrupt is received along with some options, like what privilege level the interrupt handler function should be executed in.</p><p>Here’s a photo from the Intel CPU manual showing the layout of an entry in this array:</p><p><img src="https://blog.packagecloud.io/images/idt.png" alt="Screenshot of Interrupt Descriptor Table entry diagram for x86_64 CPUs"></p><p>If you look closely at the diagram, you can see a 2-bit field labeled DPL (Descriptor Privilege Level). The value in this field determines the minimum privilege level the CPU will be in when the handler function is executed.</p><p>This is how the CPU knows which address it should execute when a particular type of event is received and what privilege level the handler for that event should execute in.</p><p>In practice, there are lots of different ways to deal with interrupts on x86-64 systems. If you are interested in learning more read about the <a href="http://wiki.osdev.org/8259_PIC">8259 Programmable Interrupt Controller</a>, <a href="http://wiki.osdev.org/APIC">Advanced Interrupt Controllers</a>, and <a href="http://wiki.osdev.org/IOAPIC">IO Advanced Interrupt Controllers</a>.</p><p>There are other complexities involved with dealing with both hardware and software interrupts, such as interrupt number collisions and remapping.</p><p>We don’t need to concern ourselves with these details for this discussion about system calls.</p><h2 id="model-specific-registers-msrs">Model Specific Registers (MSRs)</h2><p>Model Specific Registers (also known as MSRs) are control registers that have a specific purpose to control certain features of the CPU. The CPU documentation lists the addresses of each of the MSRs.</p><p>You can use the CPU instructions <code>rdmsr</code> to <code>wrmsr</code> to read and write MSRs, respectively.</p><p>There are also command line tools which allow you to read and write MSRs, but doing this is <em>not recommended</em> as changing these values (especially while a system is running) is dangerous unless you are really careful.</p><p>If you don’t mind potentially destabilizing your system or irreversibly corrupting your data, you can read and write MSRs by installing <code>msr-tools</code> and loading the <code>msr</code> kernel module:</p><figure><pre><code data-lang="sh">% <span>sudo </span>apt-get install msr-tools
% <span>sudo </span>modprobe msr
% <span>sudo </span>rdmsr</code></pre></figure><p>Some of the system call methods we’ll see later make use of MSRs, as we’ll see soon.</p><h2 id="calling-system-calls-with-assembly-is-a-bad-idea">Calling system calls with assembly is a bad idea</h2><p>It’s not a great idea to call system calls by writing your own assembly code.</p><p>One big reason for this is that some system calls have additional code that runs in glibc before or after the system call runs.</p><p>In the examples below, we’ll be using the <code>exit</code> system call. It turns out that you can register functions to run when <code>exit</code> is called by a program by using <a href="http://man7.org/linux/man-pages/man3/atexit.3.html"><code>atexit</code></a>.</p><p>Those functions are called from glibc, not the kernel. So, if you write your own assembly to call <code>exit</code> as we show below, your registered handler functions won’t be executed since you are bypassing glibc.</p><p>Nevertheless, manually making system calls with assembly is a good learning experience.</p><div><p>Create a package repository in less than 10 seconds, free.</p></div><p>Using our prerequisite knowledge we know two things:</p><ol><li>We know that we can trigger the kernel to execute by generating a software interrupt.</li><li>We can generate a software interrupt with the <code>int</code> assembly instruction.</li></ol><p>Combining these two concepts leads us to the legacy system call interface on Linux.</p><p>The Linux kernel sets aside a specific software interrupt number that can be used by user space programs to enter the kernel and execute a system call.</p><p>The Linux kernel registers an interrupt handler named <code>ia32_syscall</code> for the interrupt number: 128 (0x80). Let’s take a look at the code that actually does this.</p><p>From the <code>trap_init</code> function in the kernel 3.13.0 source in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/kernel/traps.c</code></a>:</p><figure><pre><code data-lang="c"><span>void</span> <span>__init</span> <span>trap_init</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
        <span>/* ..... other code ... */</span>

        <span>set_system_intr_gate</span><span>(</span><span>IA32_SYSCALL_VECTOR</span><span>,</span> <span>ia32_syscall</span><span>);</span></code></pre></figure><p>Where <code>IA32_SYSCALL_VECTOR</code> is a defined as <code>0x80</code> in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/kernel/traps.c#L770"><code>arch/x86/include/asm/irq_vectors.h</code></a>.</p><p>But, if the kernel reserves a single software interrupt that userland programs can raise to trigger the kernel, how does the kernel know which of the many system calls it should execute?</p><p>The userland program is expected to put the system call number in the <code>eax</code> register. The arguments for the syscall itself are to be placed in the remaining general purpose registers.</p><p>One place this is documented is in a comment in <a href="https://github.com/torvalds/linux/blob/v3.13/arch/x86/ia32/ia32entry.S#L378-L397"><code>arch/x86/ia32/ia32entry.S</code></a>:</p><figure><pre><code data-lang="c"> <span>*</span> <span>Emulated</span> <span>IA32</span> <span>system</span> <span>calls</span> <span>via</span> <span>int</span> <span>0x80</span><span>.</span>
 <span>*</span>
 <span>*</span> <span>Arguments</span><span>:</span>
 <span>*</span> <span>%</span><span>eax</span> <span>System</span> <span>call</span> <span>number</span><span>.</span>
 <span>*</span> <span>%</span><span>ebx</span> <span>Arg1</span>
 <span>*</span> <span>%</span><span>ecx</span> <span>Arg2</span>
 <span>*</span> <span>%</span><span>edx</span> <span>Arg3</span>
 <span>*</span> <span>%</span><span>esi</span> <span>Arg4</span>
 <span>*</span> <span>%</span><span>edi</span> <span>Arg5</span>
 <span>*</span> <span>%</span><span>ebp</span> <span>Arg6</span>    <span>[</span><span>note</span><span>:</span> <span>not</span> <span>saved</span> <span>in</span> <span>the</span> <span>stack</span> <span>frame</span><span>,</span> <span>should</span> <span>not</span> <span>be</span> <span>touched</span><span>]</span>
 <span>*</span></code></pre></figure><p>Now that we know how to make a system call and where the arguments should live, let’s try to make one by writing some inline assembly.</p><h2 id="using-legacy-system-calls-with-your-own-assembly">Using legacy system calls with your own assembly</h2><p>To make a legacy system call, you can write a small bit of inline assembly. While this is interesting from a learning perspective, I encourage readers to never make system calls by crafting their own assembly.</p><p>In this example, we’ll try calling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/">https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</a></em></p>]]>
            </description>
            <link>https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23668186</guid>
            <pubDate>Sun, 28 Jun 2020 11:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer on the cruel, tacit laws of type-level programming in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23667675">thread link</a>) | @tenslisi
<br/>
June 28, 2020 | https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html | <a href="https://web.archive.org/web/*/https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<h4 id="a-primer-on-the-cruel-tacit-laws-of-type-level-programming-in-haskell"><em>A primer on the cruel, tacit laws of type-level programming in Haskell</em></h4>

<p>Haskell programs are constructed at the junction of two worlds: one of types, and the other of values. Values are operational run-time entities that are denoted syntactically by <em>terms</em> in the code. To this end, types classify terms. They provide a powerful abstraction to organize data, determine how it should be stored in memory, passed through various operations, and more. On a superficial level, the difference between these worlds is simple: <em>types</em> refer to datatypes, which are either built-in (such as <code>Integer</code> and <code>String</code>), or user-declared, for example:</p>

<pre><code>data SpringFlingQueen = Cady | Regina
</code></pre>

<p>By comparison, <em>values</em> are denoted by <em>terms</em> those types categorize (such as <code>1</code> and <code>"abc"</code> described by the standard library’s <code>Integer</code> and <code>String</code> types, or <code>Cady</code> and <code>Regina</code> in the case of our user-declared type, <code>SpringFlingQueen</code>). Thus, the term <code>1</code> denotes a value that exists in memory only when the program is run.</p>

<p>In addition to these two worlds, a third, darker, and more elusive underworld of <em>kinds</em> also lurks in the shadows of Haskell programs. Haskell kinds can be as unpredictable and insidious as the soulless alpha-female of an elite high school clique. While daunting, understanding the coaction between these three worlds lays the foundation for type-level programming, a topic worth learning as it strengthens overall Haskell intuition.</p>

<p><img src="https://user-images.githubusercontent.com/875834/81239044-afe24580-8fd1-11ea-96b0-274cf839e834.png" alt="the haskell type system: a machine of constant, unforgiving judgement and rigid classification"></p>

<h3 id="kindness-is-a-virtue">Kindness is a virtue</h3>

<p>Much like counter-intuitive adolescent social dynamics, mastery of Haskell bears a steep learning curve because of its underlying complexity. It is difficult to wrap one’s head around the language’s typeclass hierarchies, category-theoretic roots, or the intricacies of compiler behavior. However, an intimate understanding of the type system lets programmers look beyond the chaos of code and apply a recognizable template by which to understand it.</p>

<h3 id="kindness-takes-patience">Kindness takes patience</h3>

<p>This topic is also difficult to master because it is both vast and subtle. Ideas underlying type-level programming are scattered across many disconnected resources focused on several corners of the Haskell ecosystem. Authoritative references on the topic (such as relevant library documentation) tend to assume familiarity with domain-specific terminology that may be unknown to non-experts. Due to the paucity of approachable materials on the subject, I’ve attempted to break down type-level programming into explanations of its constituent parts. While I don’t go into extensive depth on any individual section below, I hope to provide a valuable starting point with which readers can explore ideas in greater detail.</p>

<table>
  <thead>
    <tr>
      <th>Table of contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#Types-vs-Values">Types vs. Values</a></td>
    </tr>
    <tr>
      <td><a href="#Kinds">Kinds</a></td>
    </tr>
    <tr>
      <td><a href="#higher-kinded-types">Higher-kinded types</a></td>
    </tr>
    <tr>
      <td><a href="#constraint-kinds">Constraint kinds</a></td>
    </tr>
    <tr>
      <td><a href="#PolyKinds">Kind polymorphism</a></td>
    </tr>
    <tr>
      <td><a href="#DataKinds">DataKinds and type-level literals</a></td>
    </tr>
    <tr>
      <td><a href="#Datatype-promotion">Datatype promotion</a></td>
    </tr>
    <tr>
      <td><a href="#Relationship-between-values-terms-types-and-kinds">Relationship between values, terms, types, and kinds</a></td>
    </tr>
    <tr>
      <td><a href="#The-difference-between-type-and-type-level">The difference between “type” and “type-level”</a></td>
    </tr>
    <tr>
      <td><a href="#type-families">Type families</a></td>
    </tr>
    <tr>
      <td><a href="#associated-types">Associated types</a></td>
    </tr>
    <tr>
      <td><a href="#TypeLits">GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#Distinguishing-between-DataKinds-and-TypeLits">Distinguishing between DataKinds and GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#use-case-Marshaling-ASTs">Use-case: Marshaling ASTs</a></td>
    </tr>
    <tr>
      <td><a href="#The-hype-of-dependently-typed-langs">The hype of dependently-typed languages</a></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="types-vs-values">Types vs. Values</h3>

<p>As mentioned above, Haskell programs are divided into two worlds: the <em>type-level</em> and the <em>value-level</em>. The <em>type-level</em> refers to the part of a program analyzed by the static type-checking phase during compilation. Since every expression is assigned a type, code is checked against Haskell’s type system to ensure it fits <a href="https://www.haskell.org/ghc/">GHC</a>’s specified correctness criteria.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704534-fce9fd80-af27-11ea-9544-13961a56c444.png" alt="types classify terms, just like hostile teens with identity crises classify one another"></p>

<p>If the program is well-typed, the program will compile. However, this type-information evaporates once the compilation process terminates, leaving only <em>values</em> behind at run-time. In this way, types and values can be better distinguished by the phasing distinction, with types being compile-time entities and values being run-time entities.</p>

<p>For example, if a function takes a <code>String</code>, the type-checker doesn’t care if the <code>String</code> has a value denoted by <code>"abc"</code> or <code>"123"</code> or <code>"get in loser"</code>—so long as it’s a <code>String</code>. Type information gets discarded at run-time, leaving only the string’s value (ex.,<code>"get in loser"</code>). In some cases, however, we want the type system to care about what those values are and distinguish between them. The <code>DataKinds</code> extension, which we’ll explore below, lets us do that by allowing us to shove more information about our program into the type system. This lets us add meaning to the value of a <code>String</code> at the type-level, moving them from their usual, strictly run-time existence, into the compile-time phase. The technique allows us to use more information statically in the logical development and abstraction of the program’s behavior. We’re also able to add consequences that can halt compilation if the specific value of <code>String</code> doesn’t conform to the rules we’ve specified, or define classes over them.</p>

<h4 id="distinguishing-types-and-values-in-ghci">Distinguishing types and values in GHCi</h4>

<p>Let’s examine our aforementioned <code>SpringFlingQueen</code> datatype in GHCi. When we query the type of one of its constructors using <code>:t</code> (a handy shorthand for <code>:type</code>), we see that it is indeed of type <code>SpringFlingQueen</code>:</p>

<div><div><pre><code>λ data SpringFlingQueen = Cady | Regina
λ :t Cady
Cady :: SpringFlingQueen
</code></pre></div></div>

<p>Now consider literals <code>1</code>, <code>2</code>, <code>3</code>. These are <em>values</em> of a type that parameterizes the <code>Num</code> class:</p>



<p>Typing <code>:t 1</code> into GHCi gives us <code>Num p =&gt; p</code>, indicating that a literal such as <code>1</code> can be of any polymorphic type <code>p</code> as long as the <code>Num</code> type class has instances for that type (for example, <code>Integer</code> and <code>Float</code> both have <code>Num</code> instances and therefore are valid types that <code>p</code> could be instantiated with). This is possible due to <a href="https://wiki.haskell.org/Type_inference">type inference</a>.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704346-ae3c6380-af27-11ea-8078-6f1ddfc7b238.png" alt="type inference can be used to deduce concrete types wherever they're obvious. If a type looks like a mouse, it's a mouse—duh!"></p>

<h3 id="kinds">Kinds</h3>

<p>Just like types classify terms, <a href="https://www.haskell.org/onlinereport/decls.html#sect4.1.1">kinds</a> classify types, and therefore are frequently described as “types of types”, or referred to be “one level up.” The “star” syntax (i.e., <code>*</code>) denotes kinds. It is defiantly used in this post despite <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0143-remove-star-kind.rst">recent syntactic changes</a>. A prerequisite for understanding the kind system necessitates comprehending the differences between three pairs of ideas:</p>

<ol>
  <li>
    <p><strong>Data constructors vs. type constructors:</strong> data constructors create values, whereas type constructors create types. Type constructors take one or more type arguments and produce a datatype when enough arguments are provided. This means that through <a href="https://wiki.haskell.org/Currying">currying</a>, a type constructor can be <a href="https://wiki.haskell.org/Partial_application">partially applied</a>. For example, the list type constructor <code>[]</code> may take a single type argument (ex. <code>String</code>) to denote the elements of the list (i.e., <code>[String]</code>). <code>[String]</code> is simply syntactic sugar for <code>[] String</code>, where the type <code>[]</code> is applied to <code>String</code>.</p>
  </li>
  <li>
    <p><strong>Full vs. partial application</strong> A partially-applied type, like a <a href="https://wiki.haskell.org/Partial_application">partially-applied function</a>, is one that is missing some of its data constructors. For instance, consider the list type <code>[]</code>. The kind of <code>[]</code> is <code>* -&gt; *</code>. A fully-applied list has data constructors, such as <code>[Int]</code>, and its kind is <code>*</code>.</p>
  </li>
  <li>
    <p><strong>Inhabited types vs. uninhabited types:</strong> An inhabitant of a type is precisely a value of that type. This means that <em>inhabited</em> types refer to the types that contain concrete values, such as the value denoted by the term <code>1 :: Int</code>. This suggests that the type <code>Int</code> is inhabited by value denoted by <code>1</code>. By contrast, <em>uninhabited</em> types refer to type constructors to which no values are abstracted. For instance, <code>Void</code> is uninhabited because it has no data constructors, and thus can not be used to construct a valid term. While <code>Void</code> may seem pointless at first, it can be a useful way to represent that a container is empty (ex., <code>[Void]</code>, which <em>is</em> inhabited by the term <code>[]</code> and the value this term denotes).</p>
  </li>
</ol>

<p>How do these ideas relate to the kind system? Well, all fully-applied runtime values are of kind <code>*</code> <em>and</em> they are inhabited. You can confirm this by typing <code>:k Int</code> and <code>:k String</code> in GHCi. However, this doesn’t work the other way around—just because a type is inhabited, doesn’t necessarily mean it’s fully-applied (ex., <code>[]</code> is not fully-applied but it <em>is</em> inhabited, and its kind signature is <code>* -&gt; *</code>). Conversely, all partially-applied types are uninhabited (since they don’t correspond to a value), but not all uninhabited types are partially applied. <code>Void</code> for instance is not partially-applied, but it is uninhabited.</p>

<p>To get the hang of this idea, consider the following examples:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Inhabited?</th>
      <th>Fully-applied?</th>
      <th>Kind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Int</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>String</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>[]</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>[Int]</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>(,)</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Either</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Void</code></td>
      <td>No</td>
      <td>N/A</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>Either Void Void</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
  </tbody>
</table>

<p>Kind signatures can be specified manually in GHCi using the <a href="https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures"><code>XKindSignatures</code></a> extension. Try extending the above table by investigating the kind signatures of various types.</p>

<h3 id="higher-kinded-types">Higher-kinded types</h3>

<p>Just like there are higher-order functions (functions that take other functions as arguments), there are higher-kinded types (types constructors that take other type constructors as arguments). Type constructors such as <code>[]</code> are a first-class type, but also a higher-kinded type, given they take another type constructor to be reified:</p>



<p>Let’s consider <code>Functor</code>:</p>

<div><div><pre><code>λ :k Functor
Functor :: (* -&gt; *) -&gt; Constraint
</code></pre></div></div>

<p>We see that <code>Functor</code> takes a type constructor <code>* -&gt; *</code> and returns a <code>Constraint</code>. Let’s use <code>:info</code> to examine <code>Functor</code> a bit more closely:</p>

<div><div><pre><code>λ :info Functor
class Functor (f :: * -&gt; *) where
  fmap :: (a -&gt; b) -&gt; f a -&gt; f b
  (&lt;$) :: a -&gt; f b -&gt; f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor ((,,,) a b c) -- Defined in ‘Data.Orphans’
instance Functor ((,,) a b) -- Defined in ‘Data.Orphans’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((-&gt;) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
</code></pre></div></div>

<p>We see that <code>Functor</code> allows type constructors like <code>Maybe</code> and <code>[]</code> to have <code>Functor</code> instances, but not <code>Int</code> or <code>String</code>. This is because <code>Maybe</code> and <code>[]</code> are <code>* -&gt; *</code>, while <code>Int</code> has kind <code>*</code>. Similarly, <code>Either</code> has <code>* -&gt; * -&gt; *</code>, which is why its instance above is parameterized with a type parameter denoting something of kind <code>* -&gt; *</code>: <code>Either a</code>.</p>

<h3 id="constraint-kinds">Constraint kinds</h3>

<p>We got a glimpse of constraint kinds …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</a></em></p>]]>
            </description>
            <link>https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667675</guid>
            <pubDate>Sun, 28 Jun 2020 09:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ELF: Better Symbol Lookup via Dt_gnu_hash (2017)]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23667520">thread link</a>) | @fanf2
<br/>
June 28, 2020 | https://flapenguin.me/elf-dt-gnu-hash | <a href="https://web.archive.org/web/*/https://flapenguin.me/elf-dt-gnu-hash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2017-05-10">2017-05-10</time> |<p><code>DT_GNU_HASH</code> is a better hash table for the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a> used by GNU systems in GNU-compatible software, i.e. in almost every program compiled with gcc or clang for almost any Linux distribution.</p><p>The problem with it is that <code>DT_GNU_HASH</code> is not documented anywhere other than in <a href="https://www.gnu.org/software/binutils/">GNU binutils</a> and <a href="https://www.gnu.org/software/libc/">glibc</a> source code. You can either read source code to get some intel, or read emails with patches in mail list archives (<a href="https://sourceware.org/ml/binutils/2006-10/msg00377.html">Re: GNU_HASH section format</a> is a pretty good one). Those are the only places you can try to find the truth on the matter.</p><p>Of course, there're some articles on the web where people try to break it down. Like this one.</p><p>This article does not aspire to be the ultimate truth either. But I'll try to cover everything about GNU Hash Table and explain all aspects of its work.</p><p>Before reading any further please ensure that you understand what <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.symtab.html">Symbol Table</a> and <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.strtab.html">String Table</a> are in the <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/contents.html">ELF</a>. Also you may want to read my previous article <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> to know the standard (90s-ish) way of doing symbol lookup.</p><p><code>DT_GNU_HASH</code> has nothing in common with standard <code>DT_HASH</code>, apart from serving the same purpose. It has its own hashing function, its own layout, it adds restrictions for the symbol table and contains an additional <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to stop lookup for missing symbols early.</p><h2>Hashing function</h2><p>Let's start with the hashing function. It can be found in <a href="https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;a=blob;f=bfd/elf.c;h=a08e0f8ea6197f103908364665ec6e5f6c89927d;hb=HEAD#l222">bfd_elf_gnu_hash</a> or in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l569">dl_new_hash</a>.</p><pre><span>#<span>include</span> <span>&lt;stdint.h&gt;</span></span>

<span><span>uint32_t</span> <span>gnu_hash</span><span>(<span>const</span> <span>uint8_t</span>* name)</span> </span>{
    <span>uint32_t</span> h = <span>5381</span>;

    <span>for</span> (; *name; name++) {
        h = (h &lt;&lt; <span>5</span>) + h + *name;
    }

    <span>return</span> h;
}

gnu_hash(<span>""</span>)                == <span>0x00001505</span>
gnu_hash(<span>"printf"</span>)          == <span>0x156b2bb8</span>
gnu_hash(<span>"exit"</span>)            == <span>0x7c967e3f</span>
gnu_hash(<span>"syscall"</span>)         == <span>0xbac212a0</span>
gnu_hash(<span>"flapenguin.me"</span>)   == <span>0x8ae9f18e</span>
</pre><h2>Layout</h2><p>Not a valid C code, but gives an idea:</p><pre><span><span>struct</span> <span>gnu_hash_table</span> {</span>
    <span>uint32_t</span> nbuckets;
    <span>uint32_t</span> symoffset;
    <span>uint32_t</span> bloom_size;
    <span>uint32_t</span> bloom_shift;
    <span>uint64_t</span> bloom[bloom_size]; 
    <span>uint32_t</span> buckets[nbuckets];
    <span>uint32_t</span> chain[];
};
</pre><h2>Bloom filter</h2><p><a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filter</a> is used to stop the lookup for missing symbols early. <code>bloom_size</code>, <code>bloom_shift</code>, and <code>bloom</code> are parts of the structure, as their names suggest.</p><p>Bloom filter behaves slightly differently for various <code>ELFCLASS</code> binaries (defined by <code>EI_CLASS</code> field in <a href="https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html#elfid">ELF Identification</a>). Let's define <code>ELFCLASS_BITS</code> to be <code>64</code> for 64-bit binaries (<code>ELFCLASS64</code>) and <code>32</code> for 32-bit binaries (<code>ELFCLASS32</code>).</p><p>Before doing symbol lookup, take <code>bloom[(hash / ELFCLASS_BITS) % bloom_size]</code>. If bits <code>hash % ELFCLASS_BITS</code> and <code>(hash &gt;&gt; bloom_shift) % ELFCLASS_BITS</code> are set then a symbol <strong>may or may not</strong> be in the hash table, and you should proceed with a regular lookup through buckets and chains. But if at least one bit is not set then a symbol is <strong>certainly</strong> absent from the hash table.</p><h2>Buckets and chains</h2><p><code>DT_HASH</code> contains an element per symbol table's element. This leads to a waste of space because <code>STN_UNDEF</code> and some other symbols are in the hash table but are never looked up. GNU hash table allows to skip first <code>symoffset</code> symbols at the beginning of the symbol table.</p><p>Same as in <code>DT_HASH</code>, symbols are put in one of <code>nbuckets</code> buckets depending on their hashes. To be specific, each symbol should be placed into <code>hash % nbuckets</code> bucket.</p><p>Chains in the GNU hash table are nothing like strange linked lists in <code>DT_HASH</code>, they are contiguous sequences of hashes for symbols with the same index (remember that chains' indexes are shifted by <code>symoffset</code> relatively to the symbol table). The last bit in chains' element is discarded and instead used for indicating the chain's end. If it is set then the element is the last one in the chain.</p><p><code>bucket</code> array holds indexes of the first symbols in the chains. Note that those are not indexes for the <code>chain</code> array. Indexes for it will be <code>bucket[foobar] - symoffset</code>.</p><p>Chains being contiguous sequences imply that symbols within the same bucket must be stored contiguously. Order of buckets in the symbol table does not really matter but usually they're stored in an ascending order.</p><p>While looking extraneous, creating such restriction over the symbol table gives great advantage: a hash table now can store almost full hash (without the lowest bit) of a symbol within the same 32 bits. This allows linkers to compare hashes before comparing strings. Also, because <code>DT_GNU_HASH</code> requires symbol table ordering and <code>DT_HASH</code> doesn't, you can fit both into a single binary. This way both standard and GNU linkers can look up symbols in it.</p><h2>Example</h2><p>Nothing is better than a visual representation of the rules. So, let's create one.</p><p>I took the same symbols as in <a href="https://flapenguin.me/2017/04/24/elf-lookup-dt-hash">ELF: symbol lookup via DT_HASH</a> and created <code>DT_GNU_HASH</code> table from them. The example is for 64-bit ELF binaries, for 32-bit you'll need to recalculate bloom word and bits.</p><pre>nbuckets = 4      (because I decided that there will be four buckets)
symoffset = 1    (STN_UNDEF is not a part of the hash table)
bloom_size = 2   (because I decided that 16 byte bloom filter is sufficient)
bloom_shift = 5  (again, just because I can)

ix  bucket[ix]  name of first symbol in chain
--  ----------  -----------------------------
 0  1           cfsetispeed
 1  5           uselib
 2  8           freelocal
 3  13          getspen

Note that:
- symbol table is sorted by bucket
- chain[ix] is the same as hash but with set/cleared lowest bit

       SYMBOL TABLE              |              GNU HASH TABLE
                                 |
    name =                       |    hash %              bloom  bloom bits
ix  symtab[ix].st_name    hash   | ix nbuckets chain[ix]  word   #0    #1
--  ------------------  -------- | -- -------  ---------- -----  ---   ---
 0  &lt;STN_UNDEF&gt;                  |
 1  cfsetispeed         830acc54 |  0    0      830acc54    1    20    34
 2  strsigna            90f1e4b0 |  1    0      90f1e4b0    0    48    37
 3  hcreate_            4c7e3240 |  2    0      4c7e3240    1     0    18
 4  endrpcen            b6c44714 |  3    0      b6c44715    0    20    56
 5  uselib              2124d3e9 |  4    1      2124d3e8    1    41    31
 6  getttyen            fff51839 |  5    1      fff51838    0    57     1
 7  umoun               1081e019 |  6    1      1081e019    0    25     0
 8  freelocal           e3364372 |  7    2      e3364372    1    50    27
 9  listxatt            ced3d862 |  8    2      ced3d862    1    34     3
10  isnan               0fabfd7e |  9    2      0fabfd7e    1    62    43
11  isinf               0fabe9de | 10    2      0fabe9de    1    30    14
12  setrlimi            12e23bae | 11    2      12e23baf    0    46    29
13  getspen             f07b2a7b | 12    3      f07b2a7a    1    59    19
14  pthread_mutex_lock  4f152227 | 13    3      4f152226    0    39    17
15  getopt_long_onl     57b1584f | 14    3      57b1584f    1    15     2

Bloom filter:
   bit #      56       48       40       32       24       16        8        0
        xx..x.xx ...xxx.x xx...... x.x.xx.x ..x...x. ...x..x. ........ ......xx
        .x..x... .....x.. ....x.x. .....x.. xx..x.xx ...xxx.x xx...... x.x.xx.x

Or as two `uint64_t` values:
    cb1dc0ad22120003
    48040a04cb1dc0ad
</pre><p>Knowing the rules and having a built table, let's try to find some symbols by hand.</p><p>Note that when comparing hashes the lowest bit is set on both left and right hand sides.</p><ol><li><p>Existing symbol. <code>strsigna</code>:</p><pre>looking for "strsigna" (hash = 0x90f1e4b0)
checking word 0 in bloom filter for bits 48 and 37
        hash table may contain symbol
starting at ix = 1

compare hashes: (chain) 0x830acc55 == 0x90f1e4b1
wrong hash definitely not "strsigna"
moving to the next symbol

compare hashes: (chain) 0x90f1e4b1 == 0x90f1e4b1
hash matches. compare strings: "strsigna" == "strsigna"
found at index 2
</pre></li><li><p>Missing symbol. <code>foobar</code>:</p><pre>looking for "foobar" (hash = 0xfde460be)
checking word 0 in bloom filter for bits 62 and 5
        not in bloom filter
not found
</pre></li><li><p>Missing symbol with hash collision. <code>vLoun</code>:</p><pre>looking for "vLoun" (hash = 0x1081e019)
checking word 0 in bloom filter for bits 25 and 0
        hash table may contain symbol
starting at ix = 5

compare hashes: (chain) 0x2124d3e9 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0xfff51839 == 0x1081e019
wrong hash definitely not "vLoun"
moving to the next symbol

compare hashes: (chain) 0x1081e019 == 0x1081e019
hash matches. compare strings: "umoun" == "vLoun"
just hash collision
that was last symbol in this bucket
not found
</pre></li></ol><h2>Code</h2><p>Original algorithm is implemented in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=elf/dl-lookup.c;h=3d2369dbf2b7ca219eaf80a820e2a8e1329fbf50;hb=HEAD#l350">do_lookup_x</a> in <code>ld.so</code> source code.</p><p>Implementation is a little trickier than <code>DT_HASH</code>'s one, but with the example above it should be self-explanatory.</p><pre>
<span>typedef</span> Elf64_Sym Elf_Sym;
<span>typedef</span> <span>bloom_el_t</span> <span>uint64_t</span>;
<span>#<span>define</span> ELFCLASS_BITS 64</span>


<span><span>const</span> Elf_Sym* <span>gnu_lookup</span><span>(
    <span>const</span> <span>char</span>* strtab,      
    <span>const</span> Elf_Sym* symtab,   
    <span>const</span> <span>uint32_t</span>* hashtab, 
    <span>const</span> <span>char</span>* name         
)</span> </span>{
    <span>const</span> <span>uint32_t</span> namehash = gnu_hash(name);

    <span>const</span> <span>uint32_t</span> nbuckets = hashtab[<span>0</span>];
    <span>const</span> <span>uint32_t</span> symoffset = hashtab[<span>1</span>];
    <span>const</span> <span>uint32_t</span> bloom_size = hashtab[<span>2</span>];
    <span>const</span> <span>uint32_t</span> bloom_shift = hashtab[<span>3</span>];
    <span>const</span> <span>bloom_el_t</span>* bloom = (<span>void</span>*)&amp;hashtab[<span>4</span>];
    <span>const</span> <span>uint32_t</span>* buckets = (<span>void</span>*)&amp;bloom[bloom_size];
    <span>const</span> <span>uint32_t</span>* chain = &amp;buckets[nbuckets];

    <span>bloom_el_t</span> <span>word</span> = bloom[(namehash / ELFCLASS_BITS) % bloom_size];
    <span>bloom_el_t</span> mask = <span>0</span>
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; (namehash % ELFCLASS_BITS)
        | (<span>bloom_el_t</span>)<span>1</span> &lt;&lt; ((namehash &gt;&gt; bloom_shift) % ELFCLASS_BITS);

    
    <span>if</span> ((<span>word</span> &amp; mask) != mask) {
        <span>return</span> <span>NULL</span>;
    }

    <span>uint32_t</span> symix = buckets[namehash % nbuckets];
    <span>if</span> (symix &lt; symoffset) {
        <span>return</span> <span>NULL</span>;
    }

    
    <span>while</span> (<span>true</span>) {
        <span>const</span> <span>char</span>* symname = strtab + symtab[symix].st_name;
        <span>const</span> <span>uint32_t</span> hash = chain[symix - symoffset];

        <span>if</span> ((namehash|<span>1</span>) == (hash|<span>1</span>) &amp;&amp; <span>strcmp</span>(name, symname) == <span>0</span>) {
            <span>return</span> &amp;symtab[symix];
        }

        
        <span>if</span> (hash &amp; <span>1</span>) {
            <span>break</span>;
        }

        symix++;
    }

    <span>return</span> <span>NULL</span>;
}
</pre><h2>Total …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://flapenguin.me/elf-dt-gnu-hash">https://flapenguin.me/elf-dt-gnu-hash</a></em></p>]]>
            </description>
            <link>https://flapenguin.me/elf-dt-gnu-hash</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667520</guid>
            <pubDate>Sun, 28 Jun 2020 08:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Up Animation as a Hobby]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23667083">thread link</a>) | @luu
<br/>
June 27, 2020 | http://yosefk.com/blog/a-better-future-animated-post.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/a-better-future-animated-post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em>Whatever else happens, you made a movie… Nobody can take that away. A hundred years from now, when we're all dead and gone, people will be watching this fucking thing.</em></p>
<p><em>– <a href="http://en.wikipedia.org/wiki/Tony_Soprano">Tony Soprano</a> to his nephew (whom he murders over this movie in a few episodes)</em></p>
<p>So I made a 90-second animated, um, I guess it's a blog post. I don't know about a hundred years from now, but I proudly invite you to watch the fucking thing right now:</p>
<p><iframe src="//www.youtube.com/embed/xTOHyWphzFc" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>I hear that it's considered classy for animators, filmmakers and such to let their work stand on its own, either refraining from commentary or making it vague. However, anxious to secure my spot in eternity, I decided to rush my immortal masterpiece out the door, so I cut everything I could.</p>
<p>I then realized that I left out a delicate point which, despite my embarrassment, I must mention. Luckily, typing is much easier than animating, so the following afterthought was quick to put down [1]. Here goes.</p>
<p>The short isn't exactly a documentary, but real-life me did switch to a part-time job to free some time for animating, drawing, etc. I figured this mundane little step was a good topic for a starting filmmaker because it turned out to be surprisingly controversial. Here are some of the reactions I received:</p>
<ul>
<li>"So you finally got fed up with the job?"</li>
<li>"Part-time? But everyone here <em>needs</em> you!"</li>
<li>"Wow, I'm jealous! I want to work less, too. They pay you the same, right?" No, they pay less, I said. "Oh. Ha-ha. Work less, get less. Interesting!"</li>
<li>"You should really work more, not less, while you're young. Futurists predict a huge global pension crisis, so save for your retirement!"</li>
<li>"I doubt this will fly with the big deadline coming. Who's gonna do all the work? Not me!" (This guy works part-time himself – very productively.)</li>
<li>"Doesn't your wife object?" (Actually, my light table is Rachel's gift. I don't know when/if I'd ever get one on my own.)</li>
</ul>
<p>These comments suggest that many people want to work less, but something is keeping them from doing it. I can certainly relate to that. It took me 10 years to decide to work part-time – and then <em>5 more years to actually do it</em>.</p>
<p>Why is it so hard?</p>
<p>My own reasons mostly revolve around money. Where I live, money is much easier to make programming than animating (good luck even finding a half-stable job working on animated features.)</p>
<p>Hence "I went into programming for the money", as I said in the short – as I always say. And initially I figured I'd work all I can and retire early – the opposite of working part-time and animating in my spare time ("settling for a fraction of the dream"). And you've just seen how I changed my mind.</p>
<p>But there's another thing, which I usually<em> don't </em>say and which I must reluctantly admit. You see, I came for the money, and then I started liking the <em>getting paid</em> part.</p>
<p>What's the difference between money and getting paid? There's a world of difference!</p>
<p>Winning a lottery is a way to obtain money without getting paid for a service. And spending your wage on designer clothes is a way to get paid without having any money left. The difference is this:</p>
<ul>
<li><strong>Money</strong> lets you buy things – food, living space, spare time, etc. It's about <strong>options</strong>.</li>
<li><strong>Getting paid</strong> tells you the value of your service to whoever paid you. It's about <strong>achievement</strong>.</li>
</ul>
<p>I like getting paid, I must admit despite the embarrassment.</p>
<p>Note that I'm not ashamed in the slightest to like money (options) and to have chosen a profession with the sole purpose of maximizing income.</p>
<p>Some people believe that you can't be happy doing something you don't love – and that you can't be any good at it, hence you won't make that much money, either. I disagree.</p>
<p>I'll tell you who my role model is, as a computer programmer. It's neither Bill Gates nor <a href="http://en.wikipedia.org/wiki/Richard_stallman">Richard Stallman</a>. My role model is <a href="http://en.wikipedia.org/wiki/Alec_Guinness">Alec Guinness</a>, whom you probably remember as Obi-Wan Kenobi from Star Wars. Wikipedia says:</p>
<blockquote><p>In letters to his friends, Guinness described the film as "fairy tale rubbish" &lt;…&gt;</p>
<p>He was one of the few cast members who believed that the film would be a box office hit;&nbsp; he negotiated a deal for 2% of the gross royalties &lt;…&gt;</p>
<p>Lucas and fellow cast members … have spoken highly of his courtesy and professionalism, both on and off the set. Lucas &lt;said&gt; that Guinness contributed significantly to achieving completion of the filming.</p></blockquote>
<p>Here's a man working on something he disliked because it paid – and delighting his target audience and colleagues alike. To me it shows that "extrinsic motivation" – money – is a perfectly good primary motivation, contrary to <a href="http://lemire.me/blog/archives/2014/07/09/extrinsic-motivations-are-harmful/">some researchers' conclusions</a>.</p>
<p>I'm in it for the money – hence, I'll never get bored and lose interest, as long as there's money to be made. I'll dutifully work on the unpleasant parts necessary to get things actually done (and get paid). Not liking programming that much, I try to keep my programs short and easy to maintain and extend – so I can program less.</p>
<p>These are all desirable traits – and not everyone genuinely loving programming has them. Think about it. Who's the better henchman – the psychopath murdering for the thrill, or the coldblooded killer who's in it for an early retirement? Same thing here.</p>
<p>I'm your perfect henchman. Pay me, give me some time alone with your computers, and when you come back, you'll find them doing your bidding. Of this I am not ashamed.</p>
<p>Recently, however, I noticed that I'm no longer the coldblooded henchman I used to be, that I started to enjoy the thrill of the kill for its own sake. And this I cannot admit without blushing.</p>
<p>That's what getting paid does to the weak-minded. It warped my value system. The phases of my transition – or should I say my moral decay – went something like this:</p>
<ol>
<li>I program because they pay me.</li>
<li>Programming is good because they pay me.</li>
<li>Programming is good.</li>
<li>Programming is good! I think I'll go program right now. Or read about it. Or write something about it. All in my spare time.</li>
</ol>
<p>And there you have it. <strong>"Achievement" has been redefined to mean "that thing you get paid for".</strong></p>
<p>This is how I ended up with a website dedicated largely to programming. Then a programming blog on the site and&nbsp;<a href="http://www.embeddedrelated.com/blogs-1/nf/Yossi_Kreinin.php">a similar blog elsewhere</a>. Then came the ultimate downfall: <a href="https://github.com/yosefk">open-source programs on GitHub</a>, written during evenings and weekends.</p>
<p>And I don't regret the writing. Keeping readers' attention on my very dry programming-related subjects is a worthy challenge for any starting storyteller.</p>
<p>But <em>programming for free? Me?</em> <a href="http://www.imdb.com/title/tt0468569/quotes">If you're good at something, never do it for free!</a> Oh, how the weak-minded have fallen.</p>
<p>Sometimes you need to hit rock bottom to begin rising. So it was with me. Realizing that I've just programmed for free for several weekends in a row made me think. Hard.</p>
<p>"I can't believe you," I said to myself. "All this money-chasing at least made some sense. But programming for free? Why not <em>draw</em> in your spare time instead? What's <em>wrong </em>with you?"</p>
<p>"Not so fast," said self. "For free or not, at least here you are doing something you're good at. You know you're good – you get paid for it! Would they pay you for drawing? Not so soon. Maybe never. Even if you're any good. <strong>In fact you'll never know if you're any good. </strong>Not if you're never paid. Nor if you're paid badly, which happens all the time in those arty parts of the world, even to the best. Why not stick to things you're <em>good</em> at – that you <em>know </em>you're good at?"</p>
<p>Could you believe this guy? Well, I wouldn't have any of that.</p>
<p>"You shameless, hypocritical, baiting-and-switching COWARD," I screamed at self at the top of my lungs. "You always said programming was for the money – to buy time, to buy that bloody creative freedom you kept chattering about! And now you say I should keep programming because I got good at it? But of course I got good – I've been doing it all this time! I could have gotten just as good at drawing – <strong>I still can</strong> – if I have the time!"</p>
<p>"And you say that now when I can afford some spare time," I went on, "I should regardless stick to what I'm good at, which by now is programming? Are you hinting that I won't ever draw very well? Is <em>that </em>why you suggested a career in programming in the first place – because you didn't believe I could draw? Was that chanting about needing money one big lie all along? Tell me, you lying bastard! I'm gonna -"</p>
<p>"OK, OK, chill, man, CHILL!" Self looked scared and unsettled. He clearly didn't see it coming. Now he was looking for some way to appease me. "You know," said self, "maybe you're right. Remember how you're always proud of taking a long-term view? Of how you care today about things 5, even 10 years ahead?"</p>
<p>I smiled smugly. Indeed I was proud of my long-term-centered, strategic thinking. <a href="http://en.wikipedia.org/wiki/Bob_Colwell">Bob Colwell</a> – the legendary computer architect – once said that it's the architect's duty to think about the long term, because nobody else will. I <em>so</em> identified with that. (Colwell and I are both computer architects, you see – just, um, of different calibers.)</p>
<p>"Well," said self, "you <em>should</em> be proud. Too many lose sight of the future because of today's small but pressing worries!"</p>
<p>"Yeah, yeah, yeah." I was losing my patience. "Thanks but no thanks for your brown-nosing. Listen, are you playing bait and switch on me again? What does this have to do with drawing?"</p>
<p>"But that's the point – it's the same thing," self exclaimed, "it's about long-term thinking! Sure, in the short term, maybe you're better at programming than drawing. But keep practicing and yes, of course you'll get good at drawing! Use your favorite superpower – your ability to imagine the future vividly, to practically live there – to overcome the temptation to stick to your comfort zone! Secure a better future today! Be the shrewd guy investing in a little unknown startup – yourself the would-be animator – to reap great benefits down the road! Be -"</p>
<p>"I get it. That's what I said though, isn't it? Let's practice – let's draw in the spare time."</p>
<p>"Sure. Sure! You're right," said self submissively. "I'm actually helping you, see? I'm telling you how to use your strengths to take the plunge!"</p>
<p>"Thaaaanks. You know what? We'll …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://yosefk.com/blog/a-better-future-animated-post.html">http://yosefk.com/blog/a-better-future-animated-post.html</a></em></p>]]>
            </description>
            <link>http://yosefk.com/blog/a-better-future-animated-post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667083</guid>
            <pubDate>Sun, 28 Jun 2020 06:26:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we got our AWS bill to around 2% of revenue]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 224 (<a href="https://news.ycombinator.com/item?id=23666999">thread link</a>) | @grwthckrmstr
<br/>
June 27, 2020 | https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Server cost is usually not a concern for most funded startups, but for a boot strapped SaaS product like ours,&nbsp; it was important to have an AWS bill that is easy on the pocket and a little more proportional to the MRR.</p><p>‍</p><p>To that end when we started<a href="http://superlemon.xyz/" target="_blank"> superlemon.xyz</a> one of the first things I did was to find ways to consume the least amount of resources on the cloud. We currently serve a traffic of ~ 250 requests per second with our AWS setup.</p><p>‍<br></p><p>Most applications require certain common cloud resources and these include</p><p>‍<br></p><ul role="list"><li>Compute instances</li><li>Database instances</li><li>Caching instances</li><li>CDN&nbsp;</li><li>A web server that acts as a reverse proxy and load balancer</li></ul><p>‍<br></p><div><p>I will now go through each of these resources and talk about both the expensive way and the cheap way to implement them</p></div><p><strong>Compute instances</strong></p><p><strong>‍</strong><br></p><p>When it comes to compute instances, most people go with AWS EC2 instances. EC2 instances are the safest choice to make for running server applications as they are highly configurable, scalable and you can change the configuration on demand according to your needs. However, sometimes you do not really need this level of control on your compute instances and that brings us to <a href="https://aws.amazon.com/free/compute/lightsail/" target="_blank">AWS Lightsail</a>.</p><p>‍<br></p><p>Lightsail as the name suggests is a lightweight version of EC2. Under the hood Lightsail instances are actually EC2 instances, but this is not apparent to the user and unlike the highly configurable EC2, Lightsail comes with a fixed configuration that once you provision cannot be changed. The billing is also a fixed amount per month as opposed to EC2 which is billed by the hour.&nbsp;</p><p>‍<br></p><p>To give you a sense of how much less complicated Lightsail is, please take a look at these screenshots of the EC2 dashboard and Lightsail dashboard.</p><figure id="w-node-7afe1c2bdee3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef82a451ea3cd05dfd4c146_x93boOZlEeQGL9kcVSXPZyGOX3SNQJfDNyRC0qG3jNDCYeySdZpIgBzYgkVDZqq3DhR92f_Eqdp8sG-vIgkwltIW9ExWhshfDSsb-gd2qCah6E5VjydVhGxO4QFRA5qCR2KXqhP5.png" alt=""></p></figure><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-2074947a61a8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef737f4a33047deb1c0a4a6_ZMr0t2QqxGgPZ-Grg-TIHjpok_ujhoYzyHLQnsGzlSfLJj0wRrKWFMKNnVDwCoOorYJHs6j4aqKz_NgztOFGNSNc9Fw4nKGrwSRVK7E4hQtDkzE7OXIVaQp0lDjXxwjiKkHN1e3c.png" alt=""></p><figcaption>EC2 dashboard</figcaption></figure><p>‍</p><p>‍</p><p>But we are not here to debate the complexity of EC2 vs Lightsail, so let’s let us talk about the cost.</p><p>An EC2 instance with 2 virtual cores, 4GB RAM and a storage of 80GB costs roughly 37$ a month and a Lightsail instance with the exact same configuration costs 20$ a month which is almost half the cost!</p><p>‍<br></p><p>The only drawback here as previously mentioned is that the instance is fixed and neither the storage nor the compute power can be tweaked later according to spikes in traffic and usage.&nbsp;</p><p>‍<br></p><p>In our case we do not have a need for too much storage on the compute instance, and as for the computing power it was easy for us to simply provision another Lightsail instance when there is an increase in traffic and set it up behind a load balancer. This way our system is still scalable.</p><p><strong>Database instances</strong></p><p><strong>‍</strong><br></p><p>Choosing a database provider for your application can be a tricky decision, but on a high level there is just one thing that is absolutely required for any database provider - the ability to take regular backups of the DB automatically and the ability to restore the database from one of the backups.</p><p>‍<br></p><p>All of this functionality is provided by AWS RDS along with an array of other capabilities like autoscaling of storage, multiple availability zones, etc. However we did not not really need this level of control over the DB for our simple SaaS product, not to mention the fact that RDS would cost us a minimum of 200$ a month with the lowest acceptable configuration.&nbsp;</p><p>‍<br></p><p>Once again our saviour was Lightsail which provides managed Databases with a fixed storage at very cheap prices. Only MySQL and PostgreSQL are available though which was fine with us since I am quite comfortable with MySQL. We have currently provisioned one MySQL DB with 2 vCPUS, 4GB RAM and 120GB SSD and it costs us 60$ a month.</p><p>‍<br></p><p>And as mentioned before Lightsail provides the basic capabilities of backups and restoration.</p><figure id="w-node-e1f43dee380f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef731c812136072299e133c_Q2n6wprxbcqgh5vI97YqjWYkOYV52HGzRtHXIQFfpgxwlHkGaO8YDv3aO3V-PwM2SI4qxPty6ZMlK0siv1-lAizSl9hf_6RASDqzNrSfEmIeMdu8UeSTsRhu4Sk1Ofg6Uw8CPPuK.png" alt=""></p><figcaption>Database restoration from recent backup</figcaption></figure><p>‍</p><div><p>The drawback here is that the DB will not scale automatically so your will have to make sure that your application does not use storage beyond what is available in the instance you select. We do this by regularly purging our Database of data that is older than X days and data that belongs to users who churned from our app more than X days ago and haven’t come back since.&nbsp;</p></div><p><strong>Caching instances</strong></p><p><strong>‍</strong><br></p><p>For our application we needed a Caching layer as well as the ability to queue up jobs that can be executed asynchronously. The seasoned folks here might have realised that the best tool to use for this is Redis and AWS has a service called ElastiCache which is Redis under the hood.&nbsp;</p><p>‍<br></p><p>Once again this would be a very safe choice to make because it is completely managed and scalable. Our need was a Redis instance with at least 6GB of memory and 2vCPUs and if we went with ElastiCache our cost would roughly come out to be 112$ a month, not to mention the additional cost of running our async workers somewhere else.</p><p>‍<br></p><p>I might sound like a broken record at this point but what we ended up doing was to provision a Lightsail instance with 2vCPUs and 8GB of memory for the cost of 40$ a month and installed an open source version of Redis on this instance. We also use the same instance to run our asynchronous workers which read from the Redis queue and execute jobs.&nbsp;</p><p>‍<br></p><p>So what is the drawback? Well since it is not a managed service, you would have to monitor the Redis server yourself. There are many tools out there that help you do this and the one I would recommend is<a href="http://prometheus.io/" target="_blank"> prometheus.io</a>.</p><p>‍<br></p><p>This means that you have to do a little bit of extra work to setup metrics collection from your Redis instance and use a grafana dashboard where you can view these metrics, but this extra work saves a lot of money in the long run and you get to look at a super cool dashboard like this one</p><figure id="w-node-ed9ef23d383f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b6832df460f9189c1ef_8fAYGJqB0CXvglSTkg-wXPXqpKi2e3fusNyMcOaiepfnZ-dC1kjn2Do44sILw5lbKOSISB1CMTEdCzyqBcyggDwK4tJcDEA17xkWXb2J1tUjLHBJgtMa_t3ekfIUfOiImx5IaZd6.png" alt=""></p><figcaption>Grafana dashboard for monitoring redis instance</figcaption></figure><p><strong>CDN</strong></p><p><strong>‍</strong><br></p><p>Our application requires a javascript file to be loaded into the websites of our customers. This JS file gets a ton of traffic because this traffic scales according to how many visitors our customers get. Now this can be scary because it means we really had no idea how many requests the JS file might actually end up receiving so we hesitated to go with CloudFront which is the goto solution for a CDN on AWS.&nbsp;</p><p>‍<br></p><p>So we ended up taking an entirely different approach for this. Our application is a Shopify app and during the process of building the application we created a Shopify store. Every Shopify store gets its own personal CDN where you can manually upload anything and it will be served over the Shopify CDN. So we minified and uploaded our JS file to the CDN of our Shopify store and now we serve 20000 Shopify stores using this method at zero cost.</p><figure id="w-node-78b80f124ebd-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b68374cfd3932d127f5_z2vfALB6_5FJXMp4al-65PIczwKOE-wUb0TubqBXAFMiu0rnqPEKGAOl12Saf0Xn-Ay1DjWL7wIj7Vby1sNPfLHkpuXzHf17ytoJ5gQvql13DZl1BsIV2rJPeHgfnCnIdezWiddG.png" alt=""></p><figcaption>Shopify CDN&nbsp;that is free of cost</figcaption></figure><p>There is a glaring drawback to this approach. The Shopify store CDN does not provide an API that you can use to programmatically upload files and it has to be done manually. Also unlike CloudFront, there is no option of invalidating a file once it is uploaded. So If you have to make updates to your file you would have to upload a new file and migrate all of your existing users to this new file.&nbsp;<br></p><p>‍</p><p>This might sound like a big drawback, but it actually took me an hour to whip up a script that updates the JS file for all our existing 20000 stores to the updated JS file that I provide. So whenever I make a new release to this JS file, I simply upload a new file manually to the CDN, then take that file as the input and run this script and we re live! This approach works for us because we do not make too many releases to the JS&nbsp;file to begin with.</p><p><strong>Web server + load balancer</strong></p><p><strong>‍</strong><br></p><p>Every application requires the ability to route requests coming to their domain or subdomain to various applications running under the hood. The best way to do this is to use AWS ELB which can be used to automatically distribute incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions.&nbsp;</p><p>‍<br></p><p>This sounds quite fancy, but all we needed for our product was 4 things</p><p>‍</p><ul role="list"><li>Serving static files for our application dashboard</li><li>Distribute traffic among different Lightsail instances based on the path of the incoming URL</li><li>Load balance traffic that comes from our Merchants Shopify stores amongst N identical Lightsail instances.</li><li>Rate limiting of requests to prevent DDOS attacks.</li></ul><p>‍<br></p><p>All of this can be done using NGINX which is a great piece of software and is quite robust even with the default settings that it comes with.&nbsp;<br></p><p>So we simply installed a stable version of NGINX on one of our existing Lightsail instances which was already being used to host one of our server applications. We also use<a href="http://amplify.nginx.com/" target="_blank"> amplify.nginx.com</a> for monitoring it. This setup is pretty much equivalent to using a managed service at zero cost.</p><p>‍</p><figure id="w-node-26b2c44e15ee-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef730c34b26677e785fa7ea_w67-tKkFsy_LekSEhO_PXqnHGxDiREqENBgMBaEAOqotyjEDJoKXRk6Wpd5K86OOv2z_S-ejGOnL37l6lj6MWqE_x2ZvrIZ4FCQraAC1uDWMne7yi0Fme4Jap2sp2uH2zrKdvpTz.png" alt=""></p><figcaption>Amplify dashboard for monitoring health of the NGINX server</figcaption></figure><p>‍</p><p><strong>Summary</strong></p><p>‍</p><ul role="list"><li>Use lightsail instances (20$ per instance) instead of EC2 instances (37$ per instance)</li><li>Use a lightsail database (60$ per DB) instead of RDS (200$ per DB)</li><li>Use a self hosted redis server on a compute instance (40$) instead of ElastiCache (112$)&nbsp;</li><li>If feasible, use a free CDN (cost savings depends on traffic size)</li><li>Use a self hosted NGINX server (20$ fixed cost) instead of ELB (cost depends on traffic and usage)</li></ul><p><strong>Closing notes</strong></p><p><strong>‍</strong><br></p><p>I would like to put emphasis on the fact that we are a micro-SaaS product that solves a small and specific use case and therefore this kind of AWS setup worked for us. This may not work for big organisations or products where the traffic is erratic.&nbsp;</p><p>This setup will also not work for folks who have a ton of stuff to do already and would prefer to use managed services and not take the additional headache of monitoring, maintaining and provisioning hardware resources on a regular basis because this has a time cost to it.</p><p>We are a team of 2 people with a product that is not computation heavy and has cloud requirements that are quite straightforward. We have been running this product for a little over 1 year with this AWS setup and so far we have not encountered any problems.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666999</guid>
            <pubDate>Sun, 28 Jun 2020 05:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventures in booting Linux on Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23666564">thread link</a>) | @todsacerdoti
<br/>
June 27, 2020 | https://blog.mostlypointless.dev/posts/net-boot-rpi/ | <a href="https://web.archive.org/web/*/https://blog.mostlypointless.dev/posts/net-boot-rpi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
        
        
            <span> Jun 26, 2020</span>
            
                <a href="https://blog.mostlypointless.dev/tags/linux">linux</a>
            
                <a href="https://blog.mostlypointless.dev/tags/raspberry-pi">raspberry pi</a>
            
        
        <p>Almost two months ago, I started building a four node Raspberry Pi 4 cluster for a project I’m working on. Figuring out the best way to get Linux on each node lead me down a rabbit hole and I spent the next four weeks <a href="http://www.catb.org/~esr/jargon/html/Y/yak-shaving.html">yak shaving</a>.</p>
<p>The most common way to boot a Pi is from an SD card. But they are slow and unreliable - I don’t like them. Certain models of Pi 2 and Pi 3 support <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/msd.md">booting from USB storage</a>, but Pi 4 cannot do that yet. So, I’m stuck with using an SD card for each Pi. Or so I thought.</p>
<h3 id="enter-pxe-boot">Enter PXE boot</h3>
<p>Turns out, Raspberry Pi 2 and 3 also <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net.md">support network booting</a>. A beta firmware was released late last year that enables <a href="https://en.wikipedia.org/wiki/Preboot_Execution_Environment">PXE</a> for Pi 4. I found <a href="https://linuxhit.com/raspberry-pi-pxe-boot-netbooting-a-pi-4-without-an-sd-card">an article on LinuxHit</a> detailing the process of installing the firmware and setting up network boot.</p>
<p>Just to test this out, I updated the firmware and configured PXE server on one of the Pis. I tried booting another Pi over the network and…it worked!
Here is the gist of PXE server setup process:</p>
<ol>
<li>Copy the contents of <code>/boot</code> and the rest of <code>/</code> into separate folders on your local filesystem. I copied mine to <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code> respectively.</li>
<li>Install and configure <code>dnsmasq</code> to enable TFTP and use <code>/tftp</code> as <code>tftp-root</code></li>
<li>Install and configure NFS server to share <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code></li>
<li>Edit the contents of <code>/nfs/raspbian-root/fstab</code> to mount the boot partition.</li>
<li>Edit <code>/nfs/raspbian-boot/cmdline.txt</code> to</li>
</ol>
<div><pre><code data-lang="bash">console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/raspbian-root,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><h3 id="pxe-booting-3-nodes-using-overlayfs">PXE booting 3 nodes using OverlayFS</h3>
<p>I cannot just boot all three nodes from the same boot and root filesystems since they are not read-only. And I don’t want to maintain a copy of these for each node. But this is a solved problem - Docker already lets you spin up multiple containers from a single base image. So I’ll just do <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works">what Docker does</a> - create <a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">OverlayFS</a> for each node using raspbian-root and raspbian-boot as my lower directories. I’ll share them over NFS like before.</p>
<p>Configuration for one of the nodes is below. Other two nodes follow the same pattern. Note that I moved raspbian-root and raspbian-boot to a USB hard drive (mounted at <code>/mnt</code>) to get better r/w performance. dc-a6-32-XX-XX-XX is the MAC address of the node. I’m using <code>tftp-unique-root=mac</code> option in <code>dnsmasq</code> to maintain a separate boot environment for each node based on its MAC address.</p>
<div><pre><code data-lang="bash">$ mount -t overlay nog-boot -o lowerdir<span>=</span>/mnt/raspbian-boot,upperdir<span>=</span>/mnt/upper/nog-boot,workdir<span>=</span>/mnt/work/nog-boot -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /tftpboot/dc-a6-32-XX-XX-XX

$ mount -t overlay nog-root -o lowerdir<span>=</span>/mnt/raspbian-root,upperdir<span>=</span>/mnt/work/nog-root,workdir<span>=</span>/mnt/work/nog-root -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /nfs/nog

$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>(In case you are wondering what <code>nog</code> is: I name my servers after planets from the Star Wars universe. Following this tradition, I’ve named the Pis Mandalore (PXE server), Nog, Ordo and Werda)</p>
<p>You are probably thinking that this worked. It did not.</p>
<p>NFS and OverlayFS did not play nice with each other. After a weekend trying to work around some weird issues, I gave up.</p>
<p>But OverlayFS is not the only copy-on-write filesystem in existence, is it? ZFS and BTRFS offer <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">subvolumes and snapshots</a> that I can use instead. But not before I <del>procrastinate</del> spend 2 weeks deciding which one to use.</p>
<h3 id="moving-to-btrfs">Moving to BTRFS</h3>
<p>The plan is simple: I’ll create a subvolume each for raspbian-root and raspbian-boot. I’ll then create three snapshots of each subvolume - one for every node. I created a <a href="https://en.wikipedia.org/wiki/RAS_syndrome">btrfs file system</a> on my external drive and ran the following commands</p>
<div><pre><code data-lang="bash">$ btrfs subvolume create raspbian-root
$ btrfs subvolume create raspbian-boot

<span># Repeat the following for each node changing folder names as necessary</span>
$ btrfs subvolume snapshot raspbian-boot nog-boot
$ btrfs subvolume snapshot raspbian-root nog-root
$ mount --bind /mnt/nog-boot /tftpboot/dc-a6-32-XX-XX-XX
$ mount --bind /mnt/nog-root /nfs/nog

<span># Don’t forget to edit cmdline.txt for each node</span>
$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>Well, this worked! I have a Pi running without an SD card!! Now all I have to do is create systemd unit files to start all required services and mount snapshots. I can finally start working on my project.</p>
<p>Wait a minute. Take a closer look at the output of <code>cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.
If you are like me, you will realize for the first time that <code>root=</code> in this file defines where the root filesystem will be mounted from. Right now, we are telling it to mount from <code>/dev/nfs</code>. What if I attach an external drive and set <code>root=</code> to point to the external drive?</p>
<h3 id="network-booting-into-a-usb-hard-drive">Network booting into a USB hard drive</h3>
<p>RPi 4 cannot directly boot from a USB drive. As in - it cannot find <code>/boot</code> on a USB drive when powering on. But what if we provide <code>/boot</code> with network boot and mount <code>/</code> from a USB drive using <code>cmdline.txt</code>? Time to test.</p>
<p>I copied raspbian-root to a USB drive, edited <code>fstab</code> to mount <code>/</code> using the partition’s PARTUUID and connected it to Nog. I then updated the contents of <code>/tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.</p>
<div><pre><code data-lang="bash">$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
 console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>PARTUUID<span>=</span>c1f95d14-01 rootfstype<span>=</span>ext4 elevator<span>=</span>deadline fsck.repair<span>=</span>yes rootwait
</code></pre></div><p>After a couple of reboots, it worked! I now have a RPi 4 running off a USB hard drive!</p>
<h3 id="what-did-i-gain">What did I gain?</h3>
<p>Let’s start with what I was looking for. All I wanted was to not deal with SD cards because they are slow and unreliable. Reliability is relative - everything fails at some point. But a decent quality USB hard drive will likely outlive an SD card. So let’s just look at some read/write performance numbers and see how they compare.</p>
<div><pre><code data-lang="bash">$ sync; dd <span>if</span><span>=</span>/dev/zero of<span>=</span>twogeefile bs<span>=</span>1M count<span>=</span>2048; sync  <span># Write performance</span>
$ sudo sh -c <span>"sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches"</span>
$ dd <span>if</span><span>=</span>twogeefile of<span>=</span>/dev/null bs<span>=</span>1M count<span>=</span><span>2048</span>              <span># Read performance</span>
</code></pre></div><table>
<thead>
<tr>
<th>Storage</th>
<th>Read (MB/s)</th>
<th>Write (MB/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sandisk Ultra MicroSDXC Class 10</td>
<td>45.7</td>
<td>20.2</td>
</tr>
<tr>
<td>Network Boot with BTRFS</td>
<td>63.3</td>
<td>18.8</td>
</tr>
<tr>
<td>/ mounted from USB hard drive</td>
<td>113.0</td>
<td>92.7</td>
</tr>
</tbody>
</table>
<p>With network boot, I was able to get read and write speeds similar to a class 10 SD card. Note that the boot images are hosted on a USB hard drive connected to Mandalore (PXE server). NFS seems to be the bottleneck here - raw r/w speeds of the hard drive are much better than this. All Pis are connected to Netgear’s 8 port gigabit ethernet switch.</p>
<p>To no one’s surprise, things improve considerably when Pis are running off a USB hard disk. Note that the external drives I used are 5400RPM hard disks repurposed from very old MacBooks. I bought them on eBay for $10 a pop. YMMV.</p>
<h3 id="current-setup">Current setup</h3>
<p>Right now, I have Mandalore booting from an SD card and <code>/</code> mounted from a USB hard disk. Nog, Ordo and Werda fetch <code>/boot</code> from Mandalore over the network and <code>/</code> mounted from a USB hard disk.</p>
<p><img src="https://blog.mostlypointless.dev/img/pi-cluster.jpg" alt="from top to bottom - Mandalore, Nog, Ordo, Werda"></p>
<p>I can finally start working on my proj… wait, what?</p>
<p><a href="https://www.tomshardware.com/how-to/boot-raspberry-pi-4-usb">A new beta firmware is out for RPi 4 that lets you boot from USB drives directly.</a></p>
<p>Oh well…</p>
<p>¯\_(ツ)_/¯</p>
<p><em><strong>Update:</strong> This post was discussed on <a href="https://news.ycombinator.com/item?id=23666564">Hacker News</a>. As jordybg <a href="https://news.ycombinator.com/item?id=23667247">points out</a>, USB boot is no longer “beta” and is available in the latest (2020-06-15) “stable” firmware release.</em></p>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.mostlypointless.dev/posts/net-boot-rpi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666564</guid>
            <pubDate>Sun, 28 Jun 2020 03:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebTransport API]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23666364">thread link</a>) | @Jarred
<br/>
June 27, 2020 | https://wicg.github.io/web-transport/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/web-transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="introduction"><span>1. </span><span>Introduction</span><a href="#introduction"></a></h2>
   <p><em>This section is non-normative.</em></p>
   <p>This specification uses pluggable protocols, with QUIC <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a> as
one such protocol, to send data to and receive data from servers. It can be
used like WebSockets but with support for multiple streams, unidirectional
streams, out-of-order delivery, and reliable as well as unreliable transport.</p>
   <p role="note"><span>Note:</span> The API presented in this specification represents a preliminary proposal
based on work-in-progress within the IETF QUIC WG. Since the QUIC transport
specification is a work-in-progress, both the protocol and API are likely to
change significantly going forward.</p>
   <h2 data-level="2" id="conformance"><span>2. </span><span>Conformance</span><a href="#conformance"></a></h2>
   <p>As well as sections marked as non-normative, all authoring guidelines,
diagrams, examples, and notes in this specification are non-normative.
Everything else in this specification is normative.</p>
   <p>The key words <em>MUST</em> and <em>SHOULD</em> are to be interpreted as described in <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a>.</p>
   <p>This specification defines conformance criteria that apply to a single product:
the user agent that implements the interfaces that it contains.</p>
   <p>Conformance requirements phrased as algorithms or specific steps may be
implemented in any manner, so long as the end result is equivalent. (In
particular, the algorithms defined in this specification are intended to be
easy to follow, and not intended to be performant.)</p>
   <p>Implementations that use ECMAScript to implement the APIs defined in this
specification MUST implement them in a manner consistent with the ECMAScript
Bindings defined in the Web IDL specification <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>, as this
specification uses that specification and terminology.</p>
   <h2 data-level="3" id="terminology"><span>3. </span><span>Terminology</span><a href="#terminology"></a></h2>
   <p>The <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler">EventHandler</a></code> interface, representing a callback used for event
handlers, and the <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#errorevent" id="ref-for-errorevent">ErrorEvent</a></code> interface are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The concepts <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-task" id="ref-for-queue-a-task">queue a task</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#networking-task-source" id="ref-for-networking-task-source">networking task source</a> are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event" id="ref-for-concept-event">event</a>, <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handlers" id="ref-for-event-handlers">event handlers</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handler-event-type" id="ref-for-event-handler-event-type">event handler event types</a> are
defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>When referring to exceptions, the terms <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-throw" id="ref-for-dfn-throw">throw</a> and <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-create-exception" id="ref-for-dfn-create-exception">create</a> are defined in <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects">fulfilled</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①">rejected</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects②">resolved</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects③">pending</a> and <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects④">settled</a> used in the context of Promises are defined in <a data-link-type="biblio" href="#biblio-ecmascript-60">[ECMASCRIPT-6.0]</a>.</p>
   <p>The terms <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream">ReadableStream</a></code> and <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream">WritableStream</a></code> are defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.  Note that despite sharing the name "stream", these are
distinct from the IncomingStream, OutgoingStream, and BidirectionalStream
defined here. The IncomingStream, OutgoingStream, and BidirectionalStream
defined here correspend to a higher level of abstraction that contain and
depend on the lower-level concepts of "streams" defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.</p>
   <h2 data-level="4" id="unidirectional-streams-transport"><span>4. </span><span><code>UnidirectionalStreamsTransport</code> Mixin</span><a href="#unidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="unidirectionalstreamstransport"><code>UnidirectionalStreamsTransport</code></dfn> can send and receive
unidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order.  Data is generally sent
reliably, but retransmissions may be disabled or the stream may aborted to
produce a form of unreliability.  All stream data is encrypted and
congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#unidirectionalstreamstransport" id="ref-for-unidirectionalstreamstransport"><c- g="">UnidirectionalStreamsTransport</c-></a> {
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#sendstream" id="ref-for-sendstream"><c- n="">SendStream</c-></a>&gt; <a data-link-type="method" href="#dom-unidirectionalstreamstransport-createsendstream" id="ref-for-dom-unidirectionalstreamstransport-createsendstream"><c- g="">createSendStream</c-></a>(<c- b="">optional</c-> <a data-link-type="idl-name" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters"><c- n="">SendStreamParameters</c-></a> <dfn data-dfn-for="UnidirectionalStreamsTransport/createSendStream(parameters), UnidirectionalStreamsTransport/createSendStream()" data-dfn-type="argument" data-export="" id="dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"><code><c- g="">parameters</c-></code><a href="#dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"></a></dfn> = {});
  <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream①"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-unidirectionalstreamstransport-receivestreams" id="ref-for-dom-unidirectionalstreamstransport-receivestreams"><c- g="">receiveStreams</c-></a>();
};
</pre>
   <h3 data-level="4.1" id="#unidirectional-streams-transport-methods"><span>4.1. </span><span>Methods</span><a href="#%23unidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" data-lt="createSendStream(parameters)|createSendStream()" id="dom-unidirectionalstreamstransport-createsendstream"><code>createSendStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream①">SendStream</a></code> object.</p>
     <p>When <code>createSendStream()</code> method is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>createSendStream</code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑤">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑥">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream②">SendStream</a></code> object and <a data-link-type="dfn" href="#add-the-sendstream" id="ref-for-add-the-sendstream">add the
  SendStream</a> to <var>transport</var> when all of the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state①">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint.  For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑦">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑧">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror①">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑨">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-unidirectionalstreamstransport-receivestreams"><code>receiveStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream②">ReadableStream</a></code> of <code><a data-link-type="idl" href="#receivestream" id="ref-for-receivestream">ReceiveStream</a></code>s that have been received
 from the remote host.</p>
     <p>When <code>receiveStreams</code> is called, the user agent MUST run the following
 steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>receiveStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot">[[ReceivedStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each unidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#incomingstream" id="ref-for-incomingstream">IncomingStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot①">[[ReceivedStreams]]</a></code>. As data
  is received over the unidirectional stream, insert that data into the
  corresponding <code>IncomingStream</code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code>IncomingStream</code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="4.2" id="#unidirectional-streams-transport-procedures"><span>4.2. </span><span>Procedures</span><a href="#%23unidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="4.2.1" id="add-sendstream"><span>4.2.1. </span><span>Add SendStream to UnidirectionalStreamsTransport</span><a href="#add-sendstream"></a></h4>
   
   <h3 data-level="4.3" id="send-stream-parameters"><span>4.3. </span><span>SendStreamParameters Dictionary</span><a href="#send-stream-parameters"></a></h3>
   <p>The <dfn data-dfn-type="dictionary" data-export="" id="dictdef-sendstreamparameters"><code>SendStreamParameters</code></dfn> dictionary includes information
relating to stream configuration.</p>
<pre><c- b="">dictionary</c-> <a data-link-type="dictionary" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters①"><c- g="">SendStreamParameters</c-></a> {
};
</pre>
   <h2 data-level="5" id="bidirectional-streams-transport"><span>5. </span><span><code>BidirectionalStreamsTransport</code> Mixin</span><a href="#bidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="bidirectionalstreamstransport"><code>BidirectionalStreamsTransport</code></dfn> can send and receive
bidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order. Data is generally sent reliably,
but retransmissions may be disabled or the stream may aborted to produce a form
of unreliability.  All stream data is encrypted and congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport"><c- g="">BidirectionalStreamsTransport</c-></a> {
    <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#bidirectionalstream" id="ref-for-bidirectionalstream"><c- n="">BidirectionalStream</c-></a>&gt; <a data-link-type="method" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream"><c- g="">createBidirectionalStream</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream③"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-bidirectionalstreamstransport-receivebidirectionalstreams" id="ref-for-dom-bidirectionalstreamstransport-receivebidirectionalstreams"><c- g="">receiveBidirectionalStreams</c-></a>();
};
</pre>
   <h3 data-level="5.1" id="#bidirectional-streams-transport-methods"><span>5.1. </span><span>Methods</span><a href="#%23bidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-createbidirectionalstream"><code>createBidirectionalStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream①">BidirectionalStream</a></code> object.</p>
     <p>When <code>createBidirectionalStream</code> is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport①">BidirectionalStreamsTransport</a></code> on which <code><a data-link-type="idl" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream①">createBidirectionalStream</a></code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state②">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⓪">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror②">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state③">state</a></code> is <code>"connected"</code>, immediately
  return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①①">fulfilled</a> promise with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream②">BidirectionalStream</a></code> object, <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream">add the BidirectionalStream</a> to the
  transport and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①②">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream③">BidirectionalStream</a></code> object and <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream①">add the BidirectionalStream</a> to <var>transport</var> when all of the following
  conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state④">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint. For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①③">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①④">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror③">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⑤">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-receivebidirectionalstreams"><code>receiveBidirectionalStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream④">ReadableStream</a></code> of <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream④">BidirectionalStream</a></code>s that have been
 received from the remote host.</p>
     <p>When <code>receiveBidirectionalStreams</code> method is called, the user agent MUST run
 the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>BidirectionalStreamsTransport</code> on which <code>receiveBidirectionalStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot">[[ReceivedBidirectionalStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each bidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑤">BidirectionalStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot①">[[ReceivedBidirectionalStreams]]</a></code>.
  As data is received over the bidirectional stream, insert that data into the
  corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑥">BidirectionalStream</a></code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑦">BidirectionalStream</a></code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="5.2" id="#bidirectional-streams-transport-procedures"><span>5.2. </span><span>Procedures</span><a href="#%23bidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="5.2.1" id="add-bidirectionalstream"><span>5.2.1. </span><span>Add BidirectionalStream to BidirectionalStreamsTransport</span><a href="#add-bidirectionalstream"></a></h4>
   
   <h2 data-level="6" id="datagram-transport"><span>6. </span><span><code>DatagramTransport</code> Mixin</span><a href="#datagram-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="datagramtransport"><code>DatagramTransport</code></dfn> can send and receive datagrams.
Datagrams are sent out of order, unreliably, and have a limited maximum size.
Datagrams are encrypted and congestion controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#datagramtransport" id="ref-for-datagramtransport"><c- g="">DatagramTransport</c-></a> {
    <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short"><c- b="">unsigned</c-> <c- b="">short</c-></a> <a data-link-type="attribute" data-readonly="" data-type="unsigned short" href="#dom-datagramtransport-maxdatagramsize" id="ref-for-dom-datagramtransport-maxdatagramsize"><c- g="">maxDatagramSize</c-></a>;
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream①"><c- n="">WritableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams"><c- g="">sendDatagrams</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream⑤"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-receivedatagrams" id="ref-for-dom-datagramtransport-receivedatagrams"><c- g="">receiveDatagrams</c-></a>();
};
</pre>
   <h3 data-level="6.1" id="datagram-transport-attributes"><span>6.1. </span><span>Attributes</span><a href="#datagram-transport-attributes"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="attribute" data-export="" id="dom-datagramtransport-maxdatagramsize"><code>maxDatagramSize</code></dfn>, <span> of type <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short①">unsigned short</a>, readonly</span>
    </dt><dd data-md="">
     <p>The maximum size data that may be passed to <code><a data-link-type="idl" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams①">sendDatagrams</a></code>.</p>
   </dd></dl>
   <h3 data-level="6.2" id="datagram-transport-methods"><span>6.2. </span><span>Methods</span><a href="#datagram-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-senddatagrams"><code>sendDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Sends datagrams that are written to the returned <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream②">WritableStream</a></code>.</p>
     <p>When <code>sendDatagrams</code> is called, the user agent MUST run the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#datagramtransport" id="ref-for-datagramtransport①">DatagramTransport</a></code> on which <code>sendDatagram</code> is
  invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-sentdatagrams-slot" id="ref-for-dom-quictransport-sentdatagrams-slot">[[SentDatagrams]]</a></code> internal slot.</p>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-receivedatagrams"><code>receiveDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot">[[ReceivedDatagrams]]</a></code> internal slot.</p>
     <p>For each datagram received, insert it into <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot①">[[ReceivedDatagrams]]</a></code>. If too
 many datagrams are queued because the stream is not being read quickly
 enough, drop datagrams to avoid queueing. Implementations should drop older
 datagrams in favor of newer datagrams. The number of datagrams to queue
 should be kept small enough to avoid adding significant latency to packet
 delivery when the stream is being read slowly (due to the reader being slow)
 but large enough to avoid dropping packets when for the stream is not read
 for short periods of time (due to the reader being paused).</p>
   </dd></dl>
   <h2 data-level="7" id="web-transport"><span>7…</span></h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wicg.github.io/web-transport/">https://wicg.github.io/web-transport/</a></em></p>]]>
            </description>
            <link>https://wicg.github.io/web-transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666364</guid>
            <pubDate>Sun, 28 Jun 2020 02:26:47 GMT</pubDate>
        </item>
    </channel>
</rss>
