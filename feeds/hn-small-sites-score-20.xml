<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 26 Nov 2020 20:23:38 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 26 Nov 2020 20:23:38 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I‚Äôm not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019‚Äì2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system‚Äôs internals very excited like we saw with Zen 3‚Äôs launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been ‚Äúperfectly fine‚Äù for the last decade. We‚Äôve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call ‚Äúrevolutionary‚Äù.</p>
<p>Before we proceed, it‚Äôs essential to set the context that I‚Äôve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a ‚ÄúPC/Android Guy‚Äù, I have to admit what I saw this week is something special. I believe it‚Äôll go down as a significant milestone in computing history on par with some industry-defining chips like Intel‚Äôs 8086, 386, 486, Pentium, Conroe or AMD‚Äôs K8, Zen, etc. I hope for the return of Moore‚Äôs law and awakening of the x86 manufacturers from their slumber as this will be the ‚Äú<em>slowest</em>‚Äù CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year‚Äôs Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year‚Äôs Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft‚Äôs struggles in emulating x86 Windows apps on ARM CPUs. Apple‚Äôs answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That‚Äôs what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That‚Äôs on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they‚Äôre not currently, and so on, x86_64 performance should be very very decent. I‚Äôm going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it‚Äôs all said and done, it doesn‚Äôt take much working backwards to figure where they‚Äôd need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple‚Äôs new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who‚Äôs spending their money on them. There have been plenty of real-world experiences that I‚Äôve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards üëè</p>‚Äî DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens ‚Äî even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. üëç</p></div>‚Äî JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>‚Äî Blake Scholl üõ´ (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don‚Äôt get near one! I have the 12.9‚Äù iPad Pro, new Max iPhone, older 13‚ÄùMBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it‚Äôs eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn‚Äôt even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It‚Äôs honestly the best purchase I‚Äôve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I‚Äôm holding a magical device that shouldn‚Äôt exist. Haven‚Äôt felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15‚Äù MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it‚Äôs been painful to say the least. It‚Äôs quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I‚Äôve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor‚Äôs resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I‚Äôm impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I‚Äôve ever owned. First computer that hasn‚Äôt had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I‚Äôm mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June‚Ä¶ fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven‚Äôt plugged in this M1 Mac in almost 2 days. It‚Äôs only half dead. lol. What is this sorcery? üîã </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>‚Äî Computer Clan (üìåÔ£øM1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% ü§Øü§Øü§Ø</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>‚Äî William Lex Ham ‚úäüèΩüß¢ #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information ‚Äì shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways ‚Äì&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult ‚Äì&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018‚Äì2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let‚Äôs take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity ‚Äî it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn‚Äôt get to users‚Äô credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice ‚Äî it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it‚Äôs essential to <strong>notify users as fast as possible</strong> ‚Äî keeping silent will simply destroy your company‚Äôs reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world‚Äôs most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users‚Äô locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app‚Äôs users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn‚Äôt even found by the company ‚Äî it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can‚Äôt tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users‚Äô data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn‚Äôt run any security tests ‚Äî <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn‚Äôt even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn‚Äôt delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn‚Äôt available to everyone anymore ‚Äî to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn‚Äôt want to provide data for the heat map anymore, their data won‚Äôt be included in the next month‚Äôs map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren‚Äôt shown on the map until they‚Äôre used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals ‚Äî the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn‚Äôt pay enough attention to the potential outcome, and that was their main mistake ‚Äî they didn‚Äôt anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn‚Äôt have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it‚Äôs also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‚Äç<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 ¬µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable‚Äôs size is or is expected to be tightly constrained by the platform‚Äôs limitations. A questionable reason not to use them is performance, as it‚Äôs unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it‚Äôs often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder ‚Äì where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn‚Äôt apply. In software, that means something isn‚Äôt going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors‚Ä¶</p>



<p>In many of these cases, the program shouldn‚Äôt just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn‚Äôt its use case.</p>



<p>Examples of incorrect use of exceptions is when they‚Äôre thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise‚Ä¶</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 ‚Äì XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It‚Äôs definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 ‚Äì filling classes with the parsed XML</h2>



<p>For this test, I‚Äôve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 ‚Äì Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it‚Äôs not possible to exactly determine whether all of the message‚Äôs length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly ‚Äì so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests ‚Äì the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller‚Äôs caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that‚Äôs in the <code>catch</code> block.</p>



<p>If the errors ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P¬≤ quantile estimator ‚Äì estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its ‚Äúaverage‚Äù duration.
It‚Äôs not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It‚Äôs much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it‚Äôs a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it‚Äôs usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P¬≤ quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P¬≤ quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let‚Äôs say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nÍûå</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qÍûå</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qÍûå</span> <span>&amp;&amp;</span> <span>qÍûå</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qÍûå</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qÍûå</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P¬≤) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It‚Äôs time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P¬≤ quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It‚Äôs the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it ‚ÄúType 7‚Äù according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It‚Äôs my favorite option in real life for non-sequential cases because
it‚Äôs more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P¬≤ quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I‚Äôm pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P¬≤ quantile estimator allows estimating quantile values on a stream of numbers without storing individual ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can‚Äôt find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I‚Äôve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement‚Äù. I like that sentence, although one can point out that these traits are closely linked--you can‚Äôt have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call ‚Äúplaintext awareness.‚Äù Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‚Äòprovably-secure schemes‚Äô sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA‚Äôs Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it‚Äôs slow, it‚Äôs not flexible (if you change the protocol, good job changing the proof), and it‚Äôs limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint‚Äôs secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP‚Äôs WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don‚Äôt want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components ‚Äî handshake and encryption protocol ‚Äî&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I‚Äôm pretty sure there‚Äôs an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it‚Äôs a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we‚Äôre just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don‚Äôt further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I‚Äôd be interested‚Ä¶</p>
<p>In any case, what‚Äôs left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn‚Äôt been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we‚Äôve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I‚Äôm now the CTO. I
could‚Äôve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I‚Äôve worked on web apps that used libraries only‚Äîno frameworks‚Äîand all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team‚Äôs composition changed, managing these decisions was a constant tax.</p>

<p>‚Ä¶managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we‚Äôd hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don‚Äôt have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn‚Äôt matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don‚Äôt matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can‚Äôt
be used for ‚Äúserious‚Äù problems.  Those of us <em>with</em> Rails experience know this isn‚Äôt true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it‚Äôs obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails‚Äîand its ecosystem‚Äîtend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it‚Äôs still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That‚Äôs why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here ‚Äì On the absence of information in today‚Äôs media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today‚Äôs press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" ‚ÄîMartin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I‚Äôm fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>‚ÄúHam Radio is dying!‚Äù A phrase all to often uttered that it‚Äôs become clich√©, but it‚Äôs partly true. You can‚Äôt deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won‚Äôt be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren‚Äôt interested in pushing the limits of RF technology. To be blunt I‚Äôm talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word‚Äôs meaning. When I use the word hacker, I‚Äôm talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio‚Äôs role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that‚Äôs currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn‚Äôt be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink‚Äôs 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It‚Äôs been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I‚Äôve collected has suggested this is a common occurrence around the United States. This type of focus doesn‚Äôt foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who‚Äôs going provide communications ‚Äúsupport‚Äù on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can‚Äôt do that locally in person or over the air, then it‚Äôs time to turn to the digital voice modes. That‚Äôs right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one‚Äôs hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That‚Äôs what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I‚Äôm fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I‚Äôd love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype ‚Äì 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it‚Äôs a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it‚Äôs free to use!</p><p>We sometimes see it as an intimidating platform, but it‚Äôs not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don‚Äôt want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas‚Äô feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let‚Äôs say you create a tool for developers then I‚Äôd post to /r/webdev. You don‚Äôt need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don‚Äôt be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you‚Äôll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you‚Äôre ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I‚Äôd go with a small subreddit, and a super targeted one. Let‚Äôs say you created a no-code tool for startups, I‚Äôll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It‚Äôs a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of ‚Äúincremental launches‚Äù is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc‚Ä¶ It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it‚Äôs totally repeatable. As long as you can provide value you‚Äôll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I‚Äôll be happy to help ‚Üí <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn‚Äôt
include any sort of CSRF token and didn‚Äôt seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a ‚Äúpoor man‚Äôs CSRF token‚Äù, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski‚Äôs <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let‚Äôs examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let‚Äôs explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker‚Äôs site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn‚Äôt supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren‚Äôt there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn‚Äôt get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you‚Äôll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>‚ÄúDon‚Äôt make me think‚Äù is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today‚Äôs article, we‚Äôd like to look into enterprise design and its peculiarities. It‚Äôs essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug‚Äôs principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren‚Äôt inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn‚Äôt necessarily true of enterprise products.</p><p>Enterprise users are power users ‚Äî and it‚Äôs imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn‚Äôt inherently wrong. It allows users to work more efficiently once they‚Äôve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software ‚Äî most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they‚Äôll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We‚Äôre very well aware of the importance of keeping interfaces simple and obvious. However, it‚Äôs essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let‚Äôs envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren‚Äôt really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but‚Ä¶</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it‚Äôs not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be‚Ä¶ well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product ‚Äî it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They‚Äôve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don‚Äôt fix it if it‚Äôs not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn‚Äôt quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, ‚Äúreinventing the wheel‚Äù isn‚Äôt always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let‚Äôs go back to Excel once more ‚Äî imagine <a href="https://adamfard.com/blog/website-redesign">you‚Äôre trying to reinvent</a> a complex, spreadsheet-based product. You‚Äôre looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is ‚Äî why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we‚Äôve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of ‚Äúdon‚Äôt make me think‚Äù will most likely outlive us, it‚Äôs crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the ‚ÄúDon‚Äôt make me think‚Äù principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies‚Ä¶ that got me thinking about what you would see if you could pass iOS under X-Rays‚Ä¶</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>‚Ä¶</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, ‚Ä¶ are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, ‚Ä¶</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, ‚Ä¶</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, ‚Ä¶</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji ü§ü, News, iWork, Wallet, Shortcuts, ARKit, ‚Ä¶</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2Ôªø<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>Ôªø could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it‚Äôs injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world‚Äôs single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>üì© Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>üéô <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you‚Äôre serious about running software under Linux/Unix, you‚Äôre certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‚Äòbadness‚Äô (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I‚Äôve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I‚Äôve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>‚ÄúInvisible‚Äù OOMKills</h2> <p>For a brief moment, I‚Äôve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn‚Äôt see any alerts for it.</p> <p>At first, I wasn‚Äôt inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn‚Äôt even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I‚Äôve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container‚Äôs init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I‚Äôve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I‚Äôve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I‚Äôve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker‚Äôs events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I‚Äôve found was where I‚Äôve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‚Äòsee‚Äô what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I‚Äôve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying the second law of thermodynamics]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25191832">thread link</a>) | @akakievich
<br/>
November 23, 2020 | https://erischel.com/demystifying-the-second-law-of-thermodynamics/ | <a href="https://web.archive.org/web/*/https://erischel.com/demystifying-the-second-law-of-thermodynamics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        




<i data-feather="calendar"></i> <time datetime="2020-11-22">Nov 22, 2020</time>

  <br>
  <i data-feather="tag"></i>
  
  
  <a href="https://erischel.com/tags/physics">physics</a>
  
  
  <a href="https://erischel.com/tags/math">math</a>
  

<p>Thermodynamics is really weird. Most people have probably encountered a bad explanation of the basics at some point in school, but probably don‚Äôt remember more than</p>
<ul>
<li>Energy is conserved</li>
<li>Entropy increases</li>
<li>There‚Äôs something called the ideal gas law/ideal gas equation.</li>
</ul>
<p>Energy conservation is not very mysterious. Apart from some weirdness around defining energy in general, it‚Äôs just a thing you can prove from whatever laws of motion you‚Äôre using.</p>
<p>But <em>entropy</em> is very weird. You‚Äôve heard that it measures ‚Äúdisorder‚Äù in some vague sense.
Maybe you‚Äôve heard that it‚Äôs connected to the <a href="https://en.wikipedia.org/wiki/Entropy%5F(information%5Ftheory)">Shannon entropy</a> of a probability distribution \(H(p) = \sum_x - p(x)\ln p(x)\).
Probably the weirdest thing about it is the law it obeys: It‚Äôs not conserved, but rather it <em>increases</em> with time.
This is more or less the only law like that in physics.</p>
<p>It gets even weirder when you consider that at least classical Newtonian physics is <em>time-symmetric</em>.
Roughly speaking, this means if you have a movie of things interacting under the laws of Newton, and you play it backwards, they‚Äôre still obeying the laws of Newton. An orbiting moon just looks like it‚Äôs orbiting in the other direction, which is perfectly consistent. A stone which is falling towards earth and accelerating looks like it‚Äôs flying away from earth and decelerating - exactly as gravity is supposed to do.</p>
<p>But if there‚Äôs some ‚Äúentropy‚Äù quality out there that only increases, then that‚Äôs obviously impossible! When you played the movie backwards, you‚Äôd be able to tell that entropy was decreasing, and if entropy always increases, some law is being violated.
So what, is entropy some artefact of quantum mechanics? No, as it turns out. Entropy is an artefact of the fact that you can‚Äôt measure all the particles in the universe at once. And the fact that it seems to always increase is a consequence of the fact that matter is stable at large scales.</p>
<p>The points in this post are largely from E.T. Jaynes' <a href="https://bayes.wustl.edu/etj/articles/macroscopic.prediction.pdf">Macroscopic Prediction</a>.</p>
<h2 id="a-proof-that-entropy-doesn-t-always-increase">A proof that entropy doesn‚Äôt always increase</h2>
<p>Let \(X\) be the set of states of some physical system. Here I will assume that there is a finite number of states and time advances in discrete steps - there is some function \(T: X \to X\) which steps time forward one step. We assume that these dynamics are time-reversible in the weak sense that \(T\) is a bijection - every state is the future of exactly one ‚Äúpast‚Äù state.
Let \(S: X \to \mathbb{R}\) be some function. Assume \(S(x) \leq S(Tx)\) - in other words, \(S\) can never decrease.
Then \(S\) is constant, i.e \(S(x) = S(Tx)\).</p>
<p>Proof: Assume for contradiction \(S(x) &lt; S(Tx)\) for some \(x\). Since \(X\) is finite, let \(\sum_x S(x)\) be the sum of \(S\) over all states. Then clearly \(\sum_x S(x) = \sum_x S(Tx)\), since \(Tx\) just ranges over all the \(x\)s.
But on the other hand, we have \(S(x) \leq S(Tx)\) for all \(x\), and \(S(x) &lt; S(Tx)\) in at least one case. So we must have \(\sum_x S(x) &lt; \sum_x S(Tx)\) - contradiction.</p>
<p>This proof can be generalized to the continuous time and space case without too much trouble, for the types of dynamics that actually show up in physics (using <a href="https://en.wikipedia.org/wiki/Liouville%27s%5Ftheorem%5F(Hamiltonian)">Liouville‚Äôs Theorem</a>). The proof above still requires a <em>bounded</em> phase volume (corresponding to the finiteness of \(X\)). To generalize to other situations we need some more assumptions - the easiest thing is to assume that the dynamics are time-reversible in a stronger sense, and that this is compatible with the entropy in some way.</p>
<p>(You can find easy counterexamples in general, e.g. if \(X=\mathbb{Z}\) and the dynamics are \(T(x) = x+1\), then obviously we really do have that \(S(x) =x\) is increasing. Nothing to do about that.)</p>
<p>Anyways the bounded/finite versions of the theorems do hold for a toy thermodynamic system like particles in a (finite) box - here the phase volume really is bounded.</p>
<h2 id="the-true-meaning-of-entropy">The true meaning of entropy</h2>
<p>Okay, so what the hell is going on? Did your high school physics textbook lie to you about this?
Well, yes. But you‚Äôre probably never going to observe entropy going down in your life, so you can maybe rest easy.</p>
<p>Let \(X\) be the physical system under consideration again. But suppose now that we can‚Äôt observe \(x \in X\), but only some ‚Äúhigh-level description \(p(x) \in Y\). Maybe \(x\) is the total microscopic state of every particle in a cloud of gas - their position and momentum - while \(p(x)\) is just the average energy of the particles (roughly corresponding to the temperature).
\(x\) is called a <em>microstate</em> and \(y = p(x)\) is called a <em>macrostate</em>.
Then the <em>entropy</em> of \(y \in Y\) is \(S(y) = \ln (p^{-1}(\{y\})\) - the logarithm of the number of microstates \(x\) where \(p(x) = y\). We say these are the microstates that <em>realize</em> the macrostate \(y\).</p>
<p>The connection with Shannon entropy is now that this is exactly the Shannon entropy of the uniform distribution over \(p^{-1}(y)\). This is the distribution you should have over microstates if you know nothing except the microstate.
In other words, the entropy measures your uncertainty about the microstate given that you know nothing except the macrostate.</p>
<p>There are more sophisticated versions of this definition in general, to account for the fact that</p>
<ul>
<li>In general, your microstates are probably sets of real numbers, and there are probably infinitely many compatible with the macrostate, so we need a notion of ‚Äúcontinuous entropy‚Äù (usually called differential entropy, I think)</li>
<li>Your measurement of the macrostate is probably not that certain (but this turns out to matter surprisingly little for thermodynamic systems),</li>
</ul>
<p>but this is the basic gist.</p>
<h2 id="why-entropy-usually-goes-up">Why entropy usually goes up</h2>
<p>Okay, so why does entropy go up?
<em>Because there are more high-entropy states than low-entropy states</em>. That‚Äôs what entropy <em>means</em>.
If you don‚Äôt know anything about what‚Äôs gonna happen to \(x\) (in reality, you usually understand the dynamics \(T\) themselves, but have absolutely no information about \(x\) except the macrostate), it‚Äôs more likely that it will transfer to a macrostate with a higher number of representatives than to one with a low number of representatives.</p>
<p>This also lets us defuse our paradox from above. In reality, entropy doesn‚Äôt go down for literally every microstate \(x\).
It‚Äôs not true that \(S(p(Tx)) &gt; S(p(x))\) for all \(x\) - I proved that impossible above.
What <em>can</em> be true is this: given a certain macrostate, it‚Äôs more probable that entropy increases than that it decreases.</p>
<p>We can consider an extreme example where we have two macrostates \(L\) and \(H\), corresponding to low and high entropy.
Clearly the number of low-entropy states that go to a high-entropy state is exactly the same as the number of high-entropy states that go to a low-entropy state. That‚Äôs combinatorics.
But the <em>fraction</em> of low-entropy states that go to high-entropy is then necessarily larger than the fraction of high-entropy states that go to low-entropy states.</p>
<p>In other words, \(P(H(x_{t+1})|L(x_t)) &gt; P(L(x_{t+1})|H(x_t))\)</p>
<h2 id="why-entropy--almost--always-goes-up">Why entropy (almost) always goes up</h2>
<p>Okay, but that‚Äôs a lot weaker than ‚Äúentropy always increases‚Äù! How do we get from here to there?
I could say some handwavy stuff here about how the properties of thermodynamic systems mean that the differences in the number of representatives between high-entropy and low-entropy states are massive - and that means the right-hand probability above can‚Äôt possibly be non-neglible. And that in general this works out so that entropy is almost guaranteed to increase.</p>
<p>But that‚Äôs very unsatisfying. It just happened to work out that way? I have a much more satisfying answer: entropy almost always increases because matter is stable at large scales.</p>
<p>Wait, what? What does that mean?</p>
<p>By ‚Äúmatter is stable at large scales‚Äù, I mean that the macroscopic behaviour of matter is predictable only from macroscopic observations. When a bricklayer builds a house, they don‚Äôt first go over them with a microscope to make sure the microstate of the brick isn‚Äôt going to surprise us later. And as long as we know the temperature and pressure of a gas, we can pretty much predict what will happen if we compress it with a piston.</p>
<p>What this means is that, if \(p(x) = p(x')\), then <em>with extremely high probability</em>, \(p(Tx) = p(Tx')\). It might not be literally certain, but it‚Äôs sure enough.</p>
<p>Now, let‚Äôs say we‚Äôre in the macrostate \(y\). Then there is some macrostate \(y'\) which is <em>extremely likely</em> to be the next one. For very nearly all \(x\) so that \(p(x) = y\), we have \(p(Tx) = y'\).
But this means that \(y'\) must have at least that many microstates representing it, since \(T\) is a bijection.
So the entropy of \(y'\) can at most be a <em>tiny</em> bit smaller than the entropy of \(y\) - this difference would be as tiny as the fraction of \(x\) with \(p(Tx) \neq y'\), so we can ignore it.</p>
<p>So unless something super unlikely happens and \(p(Tx) \neq y'\), entropy goes up.</p>
<p>By the way, this also explains what goes wrong with time-reversibility, and why in reality, you can easily tell that a video is going backwards. The ‚Äúhighly probably dynamics‚Äù \(Y \to Y\), which takes each macrostate the the most probable next state, don‚Äôt have to be time-reversible. For instance, let‚Äôs return to the two-macrostate system above.
Suppose that with 100% certainty, low-entropy states become high-entropy.
Let there be \(N_L\) low-entropy states and \(N_H\) high-entropy states.
Then, just because \(T\) is a bijection, there must be \(N_L\) high-entropy states that become low-entropy.
Now if \(N_H \gg N_L\), then practically all high-entropy states go to other high-entropy states.
So \(L \mapsto H\) but \(H \mapsto H\).</p>
<p>Of course in reality, if you start with a low-entropy state and watch this unfold for a <em>really</em> long time, you‚Äôll eventually see it become a low-entropy state again. It‚Äôs just extremely unlikely to happen in a short amount of time.</p>
<h2 id="entropy-is-not-exactly-your-uncertainty-about-the-microstate">Entropy is not exactly your uncertainty about the microstate</h2>
<p>The entropy of a given macrostate is the uncertainty ‚Ä¶</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erischel.com/demystifying-the-second-law-of-thermodynamics/">https://erischel.com/demystifying-the-second-law-of-thermodynamics/</a></em></p>]]>
            </description>
            <link>https://erischel.com/demystifying-the-second-law-of-thermodynamics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25191832</guid>
            <pubDate>Mon, 23 Nov 2020 21:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Synthetic-Aperture Radar Imaging]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25189860">thread link</a>) | @parsecs
<br/>
November 23, 2020 | https://hforsten.com/synthetic-aperture-radar-imaging.html | <a href="https://web.archive.org/web/*/https://hforsten.com/synthetic-aperture-radar-imaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                
<p>Few years ago I did some <a href="https://hforsten.com/homemade-synthetic-aperture-radar.html">simple synthetic-aperture radar (SAR) imaging
experiments</a> with the second version of my homemade
FMCW radar. Since then I made a much improved <a href="https://hforsten.com/third-version-of-homemade-6-ghz-fmcw-radar.html">third version of the
radar</a> but didn't do any SAR measurements due to the
amount of effort it would have required. I did have plans to do some SAR
experiments afterwards but it took until now to have enough time and
motivation.</p>
<p>Synthetic aperture radar (SAR) imaging is a way to synthesize very large antenna
array by moving single antenna on a known path. If there are no moving targets
in the scene then one radar taking many measurements along a path gives the same
result as one ridiculously large radar that is as long as the movement path.</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xsar_imaging.png.pagespeed.ic.MP13OL2L7B.png" width="40%/"></p><p>SAR imaging of a single target. As the radar
    moves the measured distance follows a parabola.</p>
</div>

<p>If we move on a straight path while radar pointing 90 degrees from the direction
of the path measures a distance to the single target, we will find that the
measured distance follows a parabola. This follows directly from the Pythagorean
theorem. The SAR imaging problem is finding out the target position from the
measured distance data. Of course in a real scene we have multiple targets and
the solution isn't as simple as looking where the closest approach is as could
be done in the picture above.</p>

<p>There are few different algorithms for solving this problem, but the one I'm
going to use is called Omega-k algorithm. It is a fast imaging algorithm
utilizing FFT which also makes it efficient to calculate on GPU. The derivation
mostly follows <a href="https://ieeexplore.ieee.org/document/7878107">a paper by Guo and
Dong</a>.</p>
<p>The radar I have is a frequency modulated constant wave (FMCW) radar. It
transmits a short frequency sweep. The transmitted waveform can be modeled as: </p>
<p>$$ s_t(\tau) = \exp(j 2 \pi f_c \tau + \pi \gamma \tau^2),\quad -T_s/2 &lt; \tau &lt; T_s/2 $$</p>
<p>, where <span>\(j&nbsp;= \sqrt{-1}\)</span>, <span>\(f_c =\)</span> RF carrier frequency, <span>\(\tau =\)</span> time variable,
<span>\(\gamma = B/T_s =\)</span> sweep bandwidth / sweep length <span>\(=\)</span> sweep rate.</p>
<p>The transmitted wave reflects off a target at some distance and is received after
time <span>\(t_d\)</span>. Ignoring the amplitude, the received wave is a time-delayed copy
of the transmitted signal: <span>\(s_r(\tau) = s_t(\tau - t_d)\)</span>. Signals from multiple
targets are summed.</p>
<p>The receiver mixes the received signal with the transmitted signal. This mixing
is called dechirping and it removes the high frequency RF component. The result
is a low frequency signal, usually some few kHz to MHz and is easy to digitize
with low-cost ADC. With the complex signals we take complex conjugate of the
transmitted signal to get the low-pass product and the resulting mixing product is:</p>
<p>$$ s_{\text{IF}}(\tau) = s_t(\tau - t_d) s_t^*(\tau) = \exp(-j 2 \pi f_c t_d
- j 2 \pi \gamma t_d \tau + j \pi \gamma \tau^2) $$</p>
<p>During SAR measurement the radar repeats this measurement while moving on
a straight path with a constant speed. The position of the radar on the path is:
<span>\(x = v \tau + x_n\)</span>, where <span>\(v\)</span> is speed of the radar platform and <span>\(x_n
= v n T_p\)</span>. <span>\(n\)</span> is the index for measurements and <span>\(T_p\)</span> is the transmit
repetition interval.</p>
<p>If the radar target is at position <span>\((x_0, y_0)\)</span> the distance to the target can
be written as:</p>
<p>$$ R(x) = \sqrt{y_0^2 + (x_0 - x)^2}&nbsp;$$</p>
<p>We set the y-coordinate of the path to be 0 and x position is limited to <span>\(-L/2
&lt; x &lt; L/2\)</span>, where <span>\(L\)</span> is length of the path.</p>
<p>Since electromagnetic waves travel at the speed of light and radar signal needs
to travel to the target and back to the radar, we get expression
for received signal time delay <span>\(t_d = 2R(x)/c\)</span>, where <span>\(c\)</span> is the speed of light.</p>
<p>The recorded signal can be written as:</p>
<p>$$ s_{\text{IF}}(\tau, x) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) R(x)\right)
\exp\left(j \frac{4 \pi \gamma^2}{c^2} R^2(x)\right) $$</p>
<p>The last term in the above expression is called residual video phase term and
it's an undesirable by-product from dechirping operation. It should be removed
before further processing by multiplying by <span>\(\exp(-j \frac{4 \pi \gamma^2}{c^2}
R^2(x))\)</span>.  However this form is inconvenient because it depends on <span>\(R(x)\)</span>. Using
the fact that <span>\(R(x) = c t_d / 2\)</span> and that <span>\(t_d\)</span> can be expressed in terms of
frequency of the IF signal: <span>\(f = -2 \gamma R(x) / c = -\gamma t_d \Rightarrow
t_d = -\frac{f}{\gamma}\)</span> we can write the correction term as <span>\(\exp(-j \pi f^2
/ \gamma)\)</span>. This form can be applied easily to the Fourier transformed signal.</p>
<p>With RVP term removed the signal is:</p>
<p>$$ s(\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) \sqrt{y_0^2 + (x_n - x_0 + v \tau)^2}\right) $$</p>
<p>Ideally we would like to have the signal in form <span>\(\exp(-j 2 \pi f_y y_0)\exp(-j
2\pi f_x x_0)\)</span>, then we could apply two dimensional inverse Fourier transform to
get a delta function centered at <span>\((x_0, y_0)\)</span> focusing the image. Currently the
signal <span>\(s(\tau, x_n)\)</span> is not in this form and inverse Fourier transform doesn't
give anything interesting. We need to find some processing steps to apply to the
signal to get it to the required form so that inverse Fourier transform can be
applied. The reason to look specifically for this kind of form is that FFT can
be performed very efficiently.</p>
<p>As a first step, note that <span>\(\gamma\)</span> has units of Hz/s and <span>\(\tau\)</span> has units of s.
The product <span>\(\gamma \tau\)</span> has units of Hz so it's a frequency. This product is actually
instantenous modulation frequency of the sweep. We do substitution <span>\(\gamma
\tau \rightarrow f_\tau\)</span> to get rid of the time variable. <span>\(\tau\)</span> range was <span>\(-T/2
\ldots T/2\)</span> and the new range for <span>\(f_\tau\)</span> is <span>\(-B/2 \ldots B/2\)</span>.</p>
<p>$$ S(f_\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + f_\tau) \sqrt{y_0^2 + (x_n - x_0 + \frac{v f_\tau}{\gamma} )^2}\right) $$</p>
<p>Also instead of using frequency the math is cleaner and the implementation of
the algorithm is easier when using wavenumbers instead. We define range
wavenumber <span>\(K_r = K_{rc} + \Delta K_r\)</span>. <span>\(K_{rc} = \frac{4\pi f_c}{c}\)</span>, <span>\(\Delta
K_r = \frac{4\pi f_\tau}{c} = -\frac{2\pi B}{c} \ldots \frac{2\pi B}{c}\)</span>.</p>
<p>$$ S(K_r, x_n) = \exp\left(-j K_r \sqrt{y_0^2 + (x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} )^2}\right) $$</p>
<p>Next step is to do Fourier transform in azimuth direction (direction of the
movement) to move also the <span>\(x_n\)</span> variable to frequency domain.</p>
<p>$$ S(K_r, K_x) = \int_{-\infty}^\infty S(K_r, x_n) \exp(-j K_x x_n)\, dx_n  = \int_{-\infty}^\infty \exp(j\Phi(x_n))\, dx_n $$</p>
<p><span>\(K_x = 2\pi f_x\)</span> is wavenumber in the azimuth direction. This integral doesn't have
exact solution, but there is a method to calculate quite accurate approximation
using a method called principle of stationary phase (PSOP). Phase of the
function being integrated can be written as:</p>
<p>$$ \Phi(x_n) = -K_r \sqrt{y_0^2 + \left(x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} \right)^2} - K_x x_n $$</p>
<p>If we plot the phase <span>\(\Phi(x_n)\)</span> for some realistic values we get a plot that
looks something like below:</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xphi_plot.png.pagespeed.ic.0z1VF8YpRH.png" width="40%/"></p><p>Phase and real part of the function being
    integrated.</p>
</div>

<p>There is one point where derivative of the phase is zero (stationary point) and
the function varies slowly, but away from that point the function is highly
oscillatory. As we integrate the function the oscillations far away from the
stationary point cancel out and mainly the area around the stationary point
contributes to the result of the integral.</p>
<p>We can expand the function around the stationary point <span>\(\frac{d}{dx_n}\Phi(x_n) \rvert_{x_n=x_n^\star} = 0\)</span>, as
<span>\(\Phi(x_n) = \Phi(x_n^\star) + 0 + \frac{1}{2}\Phi^{''}(x_n - x_n^\star)^2\)</span>.</p>
<p>Plugging the Taylor expansion in to the integral we get:</p>
<p>$$ \begin{aligned}S(K_r, K_x) &amp;\approx \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)(x_n-x_n^\star)^2\right)\, d x_n \\
&amp;= \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)s^2\right)\, d s \\
&amp;= \exp(j\Phi(x_n^\star)) \sqrt{\frac{2\pi j}{\Phi^{''}(x_n^\star)}} \end{aligned}
$$</p>
<p>Since <span>\(\Phi(x_n)\)</span> is purely real function, if <span>\(\mu\)</span> is sign of the
<span>\(\Phi(x_n^\star)\)</span>, then the square root term can be written as
<span>\(\sqrt{\frac{2\pi}{|\Phi^{''}(x_n^\star)|}} exp(j\pi \mu/4)\)</span>. The second
derivative contributes amplitude term and constant phase term, neither of them
which is important for focusing image which mainly depends on aligning the
phases. We have ignored the amplitude since beginning and it ends up being slowly
varying function so we will just approximate it away.</p>
<p>The stationary point of the function <span>\(\frac{d}{dx_n}\Phi(x_n)
\rvert_{x_n=x_n^\star} = 0\)</span> can be solved to be:</p>
<p>$$ x_n^\star = x_0 - \frac{K_x y_0}{\sqrt{K_r^2 - K_x^2}} - \frac{c \Delta K_r
v}{4\pi\gamma} $$</p>
<p>Plugging in the stationary point to the <span>\(S(K_r, K_x)\)</span> equation above we get the
solution of the integral:</p>
<p>$$ S(K_r, K_x) \approx \exp\left(j(-y_0 \sqrt{K_r^2 - K_x^2} - K_x x_0 + \frac{c \Delta K_r K_x
v}{4\pi\gamma})\right) $$</p>
<p>The last term is phase offset caused by the movement of the radar during the
sweep. It can be removed by multiplying with exponential in the opposite phase.</p>
<p><span>\(x_0\)</span> term is already in the correct form as it is multiplied only by <span>\(K_x\)</span>, but
<span>\(y_0\)</span> term depends on both <span>\(K_r\)</span> and <span>\(K_x\)</span>. <span>\(K_r, K_x\)</span> dependence can be fixed
by making a substitution <span>\(\sqrt{K_r^2 - K_x^2} \rightarrow K_y\)</span>. This step is
called Stolt interpolation as it is implemented by interpolating the data to
a new grid.</p>
<p>After the Stolt interpolation the signal is in form:</p>
<p>$$ S(K_y, K_x) = \exp(j(-K_y y_0 - K_x x_0)) $$</p>
<p>Taking 2D inverse Fourier transform gives the focused image with delta function
centered at <span>\((x_0, y_0)\)</span>.</p>

<p>The Omega-k algorithm is mainly large FFTs and interpolation. Both can be
implemented well on GPU which requires large parallelism from the program. Well
written GPU implementation should be several times faster than CPU
implementation. For convenience I'll implement the algorithm using Tensorflow
library. Although it's ‚Ä¶</p></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hforsten.com/synthetic-aperture-radar-imaging.html">https://hforsten.com/synthetic-aperture-radar-imaging.html</a></em></p>]]>
            </description>
            <link>https://hforsten.com/synthetic-aperture-radar-imaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189860</guid>
            <pubDate>Mon, 23 Nov 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‚ÄòJetstream‚Äô. This router is part of Walmart‚Äôs new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>‚ÄúThank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.‚Äù</p></blockquote>
<p>CyberNews researchers also discovered that ‚ÄòWavlink‚Äô branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee‚Äôs Report</a> on ‚ÄòWavlink‚Äô routers‚Äô backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selling to unicorns from my parents basement]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25188716">thread link</a>) | @timjones
<br/>
November 23, 2020 | https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents | <a href="https://web.archive.org/web/*/https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>‚öîÔ∏è David selling to Goliath</h2><p><strong>Me</strong> - a <a href="https://www.themvpsprint.com/about">bootstrapped solopreneur</a> with a laptop and a dream.</p><p><strong>Them</strong> - a billion dollar unicorn with 10,000+ employees.</p><h4><strong>Will I really be able to sell into their corporate web of bureaucracy?</strong></h4><h2>üí∏ From idea to revenue</h2><p><em><a href="https://www.themvpsprint.com/about">I‚Äôm a solo, bootstrapped founder</a></em> building a SaaS startup in public.</p><p>Over the last 4 weeks, I‚Äôve <a href="https://mvpsprint.substack.com/p/choose-a-problem">chosen a problem to solve</a>, <a href="https://mvpsprint.substack.com/p/step-2-even-unicorns-walk-before-they-run">picked a niche</a>, <a href="https://www.themvpsprint.com/p/step-3-seeking-validation">validated my problem</a>, and <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">created a top-of-the-funnel distribution strategy</a>.</p><p>This week I create a strategy for selling <a href="https://www.hellohailey.io/">HelloHailey</a> into companies of all sizes - from small startups to billion dollar unicorns.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png&quot;,&quot;height&quot;:2774,&quot;width&quot;:971,&quot;resizeWidth&quot;:368,&quot;bytes&quot;:277261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm sharing all my product decisions, metrics, successes, and failures in public.</p><p><strong>Next Monday, I‚Äôll (finally) describe the product I‚Äôm building.</strong> Want to read it in your inbox?</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Get my real-time case study&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Get my real-time case study</span></a></p><h2>üöÄ Land and expand</h2><p>The traditional SaaS sales process follows a <strong>top-down approach</strong>. A sales rep targets a high-level decision maker for a high-priced deal.</p><p>After a long sales process, a company slowly integrates a piece of software. <strong>The command comes from high in the org chart and makes its way down.</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png&quot;,&quot;height&quot;:1190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:303429,&quot;alt&quot;:&quot;Top-down sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="Top-down sales strategy"></a><figcaption>A top-down sales approach targets the top of the org chart.</figcaption></figure></div><h3><strong>But I‚Äôll be selling bottom-up</strong> </h3><p><strong>I‚Äôll scale the corporate walls via product managers (PMs) and engineering managers (EMs)</strong>. </p><p>I‚Äôll look unintimidating - a low price product that eats up a small chunk of a budget these team leads control.</p><p><strong>Then I‚Äôll spread through the company like wildfire </strong>via growth mechanisms built into the product.</p><p>One team will adopt me.</p><p>Then two.</p><p>Then the entire department. </p><p>Then the entire company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png&quot;,&quot;height&quot;:2128,&quot;width&quot;:1456,&quot;resizeWidth&quot;:546,&quot;bytes&quot;:348487,&quot;alt&quot;:&quot;\&quot;Land and Expand\&quot; sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="&quot;Land and Expand&quot; sales strategy"></a><figcaption>A ‚ÄúLand and Expand‚Äù strategy starts at the bottom of the org chart; then expands via growth mechanisms built into the product.</figcaption></figure></div><p>I know what you‚Äôre thinking - <em>all this sounds great on paper. But how are you so confident it will work?</em></p><p><strong>I‚Äôm not </strong>üò≥</p><p><strong>Honestly, I don‚Äôt even know if I‚Äôll be able to ‚Äúland‚Äù, much less expand</strong>.</p><h3>It‚Äôs time to test out my landing gear</h3><p>‚Ä¶so I don‚Äôt build a product that crashes and burns on the runway.</p><p><strong>In <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">last week‚Äôs article</a>, I outlined my top-of-the-funnel strategy</strong> - how to get PM and EM eyeballs on <a href="https://www.hellohailey.io/">HelloHailey</a>.</p><p><strong>This week I‚Äôm focusing on the bottom of the funnel</strong> - converting those eyeballs into paid users.</p><p><strong>Here‚Äôs what that funnel looks like for a PM or EM:</strong></p><ol><li><p><strong>Discover</strong> through top-of-the-funnel distribution channels.</p></li><li><p><strong>Try for free</strong> with their team.</p></li><li><p><strong>Get value - </strong>signaled by high engagement and retention.</p></li><li><p><strong>Convert to paid tier</strong> - to unlock premium features or exceed maximum number of seats (users) in free tier.</p></li><li><p><strong>Expand </strong>- add more seats within their company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png&quot;,&quot;height&quot;:1760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308211,&quot;alt&quot;:&quot;HelloHailey user acquisition funnel&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="HelloHailey user acquisition funnel"></a><figcaption>HelloHailey user acquisition funnel</figcaption></figure></div></li></ol><h4><strong>My go-to-market strategy fails if I can‚Äôt convert free users into paid users.</strong></h4><p>But I know very little about B2B purchasing processes for low-ticket ($25-$50 / month) SaaS products:</p><ol><li><p><em>Will users have to fight tooth and nail for approval?</em></p></li><li><p><em>Who has a company credit card?</em></p></li><li><p><em>What budget will the money come from?</em></p></li></ol><p>To avoid this suc-SaaS story turning into a dis-SaaS-ter (üôÑ sorry, couldn‚Äôt resist), <strong>I‚Äôm going to invest a few days now into understanding what the purchasing process will look like.</strong></p><h2>üí∞ How low-ticket SaaS products get purchased</h2><p>I probed into my network of EMs and PMs for answers. </p><p><em>Big shoutout to all those who helped me! </em>üôè</p><p>It turns out that my fears of a long chain of approvals with stringent criteria were unfounded.</p><h3><strong>The approval and purchase process is just two steps:</strong></h3><h4>1. Ask a manager</h4><p>Approval is loose and informal. PMs and EMs briefly mention it to their managers over email or their regular check-in.</p><p>Managers won‚Äôt require much justification for approval. Why? Its an immaterial amount of money and they trust their employees‚Äô judgment.</p><h4>2. Find a credit card</h4><p>With very few exceptions, PMs and EMs (at the levels I‚Äôm targeting) don‚Äôt have company credit cards. So how do they pay after getting approval?</p><h5>Pay with personal credit card</h5><p>This is a common practice for team meals, social events, and one-off software purchases. A senior team member will pay with a personal card and file an expense report.</p><p>But people are more hesitant to pay for a <em><strong>recurring</strong></em> team subscription with a personal card.</p><h5>Find a company credit card</h5><p>This varies from company to company, but the most common places people go are:</p><ol><li><p><strong>Finance</strong> (manages budgets)</p></li><li><p><strong>IT</strong> (manages access to company subscriptions)</p></li><li><p><strong>Lowest person above them in the org chart with a company card</strong> (usually a Director or VP, depending on company size)</p></li></ol><h2>üòÅ Why my strategy will work</h2><h5>‚úÖ  Loose approval process</h5><p>I mentioned this before, but it‚Äôs worth restating. <strong>This means that the PM or EM using <a href="https://www.hellohailey.io/">HelloHailey</a> is the primary decision maker.</strong></p><p>No bureaucracy. No long, complex sales cycles.</p><p><strong>I just need to build a great product.</strong></p><h5>‚úÖ  Fits into an existing budget</h5><p>It‚Äôs my hypothesis that teams will pay for HelloHailey using their team ‚Äúsocial‚Äù budgets. These budgets cover expenses like meals, games, or team events.</p><h5>‚úÖ  Takes a small percentage of that budget</h5><p>Team social budgets range from $10-$100 / person / month, with a median somewhere in the middle.</p><p>With a price of $2-$3 / person / month, HelloHailey would eat up only 5% of that budget on average.</p><h5>‚úÖ  Social budgets have been underutilized with sudden shift to remote work</h5><p>Half the people I talked to haven‚Äôt used their social budgets at all since being forced into remote work.</p><p>Most of the other half has used it sparingly for virtual team events.</p><h2>üò¢ Why it might not work</h2><p>Until companies <em>actually</em> start paying me, my strategy will be full of uncertainty.</p><p>Here are some ways it might fail:</p><h5>üí©  Doesn‚Äôt fit into an existing budget</h5><p>Maybe companies don‚Äôt think it‚Äôs appropriate to pull from team social budgets for this kind of purchase.</p><p>If it doesn‚Äôt fit nicely into <em>any</em> existing category, it‚Äôll be much harder for companies to buy it.</p><h5>üí©  Hard to budget for a product with expanding price</h5><p><a href="https://www.hellohailey.io/">HelloHailey</a> will get more expensive as more users and teams are added within a company. </p><h5>üí©  <strong>What happens when a product purchased with Team A‚Äôs social budget adds users from Team B and gets more expensive? </strong></h5><p>I don‚Äôt know ü§∑‚Äç‚ôÇÔ∏è (<em>Do you? <a href="https://twitter.com/AnotherTimJones">Share your wisdom and help me out</a> </em>üôÇ ).</p><p>But I‚Äôm not the first person to face this problem. There are precedents in place and I‚Äôm confident I‚Äôll figure it out.</p><h5>üí©  Approval process is more difficult than expected</h5><p>The people I interviewed could be outliers. Maybe a typical manager requires more convincing to approve this kind of purchase.</p><h2>What about expanding?</h2><p>I now feel confident about landing. <strong>So how will I expand?</strong></p><p>I have some ideas for how I can build growth mechanisms into a product like this.</p><p>But if I‚Äôm being honest, I‚Äôm not sure yet ü§∑‚Äç‚ôÇÔ∏è. And I‚Äôm OK with that.</p><p><strong>With a successful ‚Äúland‚Äù strategy, and low to moderate expansion revenue, I can build a great business.</strong></p><p>Intra-company virality would be a must if I wanted to become a VC-backed rocket ship.</p><p><strong>But that‚Äôs not my goal.</strong></p><p><strong>I want to build a small, profitable company that solves a problem I‚Äôm passionate about.</strong></p><p>I can sell to unicorns. But I don‚Äôt want to <em>become</em> one.</p><h2>What did I get wrong?</h2><p>I learned a lot this week, but I‚Äôve never done this before. </p><p><strong>Do you have SaaS sales experience?</strong></p><p>Don‚Äôt pull your punches! Help me out on my Twitter thread:</p><p>Don‚Äôt have any tips for me? <strong>Maybe you could help me out with a like or a retweet.</strong></p><p><strong>As a solopreneur with no funding or income, I‚Äôll take all the help I can get üòÅ</strong></p><h2>ü§î Reducing uncertainty one week at a time</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cac3da08-e921-4064-b421-eebf46ef563b_920x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:920,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:29061,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png&quot;,&quot;height&quot;:184,&quot;width&quot;:478,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm finally feeling confident about my go-to-market strategy. Now it‚Äôs time to define the product I‚Äôll be going to market with‚Ä¶</p><p><strong>Over the next two weeks, I‚Äôll define my product vision and finalize requirements for an MVP (minimum viable product).</strong></p><p><strong>Curious to find out what I‚Äôll be building?</strong> </p><p>I‚Äôll tell you next Monday:</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Send me next week's update&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Send me next week's update</span></a></p><p><em>I‚Äôll be documenting my startup journey from idea to paying users over the coming weeks and months. I‚Äôd love to have you along for the ride.</em></p><p><em>Icons made by&nbsp;<a href="https://www.freepik.com/">Freepik</a>,&nbsp;<a href="https://www.flaticon.com/authors/icongeek26">Icongeek26</a>, and&nbsp;<a href="https://www.flaticon.com/authors/pixel-perfect">Pixel perfect</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/">Flaticon</a></em></p></div></div>]]>
            </description>
            <link>https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188716</guid>
            <pubDate>Mon, 23 Nov 2020 16:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>‚Äî Auriea Harvey &amp; Micha√´l Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>‚Äî @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>‚Äî Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>‚Äî Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>‚Äî Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann‚Äôs appraisal of Chopin‚Äôs preludes, defended their proportion in an interview: ‚ÄúMaybe [Chopin] felt like they were complete objects, but there wasn‚Äôt a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me ‚Ä¶ there is a lot that‚Äôs unspoken.‚Äù Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>‚Äî Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>‚Äî Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>‚Äî Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>‚Äî thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Somfy blinds automated via MQTT and Home Assistant]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25187945">thread link</a>) | @ggambetta
<br/>
November 23, 2020 | https://mwitkow.me/posts/2020-11-08_somfy/ | <a href="https://web.archive.org/web/*/https://mwitkow.me/posts/2020-11-08_somfy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I‚Äôll show you how to use a Raspberry Pi and some soldering skills to automate old Somfy blinds via the MQTT protocol exposed to Home Assistant and Google Home.</p><p>We‚Äôve moved to a new apartment and one of its features are external blinds (a.k.a. covers) that are controlled through a dedicated remote of the Somfy brand. However, just like with a TV, finding the remote is often tricky, so I decided to try and automate the external blind movements through Home Assistant and further voice commands of Google Home.</p><p>The system in place is a Somfy‚Äôs Telis 4 RTS Pure remote, with two remotes, each being able to program 5 channels (4 individual ones and combined). The system uses a legacy, proprietary radio protocol called <a href="https://service.somfy.com/downloads/nam_v4/rts_pocket_guide_dec_2017.pdf">RTS</a>, which only Somfy and Telis use.</p><p>Somfy offers a RTS bridge called <a href="https://www.somfysystems.com/en-us/products/1811403/mylink">Somfy MyLink</a> for a wooping ~300CHF, which is a little steep for something that is not necessary and just scratching an itch. Also, there‚Äôs not much fun in that.</p><p>Turns out, <a href="https://github.com/Nickduino/">Nickduino</a> had a similar itch to scratch. Using 3-4 CHF-worth of hardware components, it is quite easy to build a software radio that will immitate a Somfy Telis remote and control the blinds.</p><p>There‚Äôs an bare-bones <a href="https://github.com/Nickduino/Somfy_Remote/blob/master/Somfy_Remote.ino">Somfy Remote Arduino sketch</a> that shows how the protocol works. I originally wanted make the blind controller as small as possible and base it on an <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, taking that sketch and controlling it via <a href="https://github.com/256dpi/arduino-mqtt">arduino-mqtt</a>.</p><p>Turns out there is a full MQTT/web interface script <a href="https://github.com/Nickduino/Pi-Somfy">Nickduino/Pi-Somfy</a> that also only goes into the details of how to solder things, and connect things onto a Raspberry Pi. Laziness won the day, especially as I wanted to use my spare Pi for something anyway.</p><h2 id="the-hardware">The hardware</h2><p>Usually for 433MHz signals you could easily use a ready-made module such us <a href="https://www.berrybase.ch/raspberry-pi-co/raspberry-pi/module-sensoren/433mhz-sender-empf-228-nger-superregeneration-modul-fs1000a-xy-fst-xy-mk-5v">this 2CHF sender-receiver pair</a>. However, in order for Somfy to make their RTS even more proprietary than it already was, it is not using the typical <code>433.93MHz</code> frequency but <code>433.42MHz</code> ü§¶‚Äç‚ôÇÔ∏è. This means one will need to do some soldering.</p><p>The PiSomfy <a href="https://github.com/Nickduino/Pi-Somfy#2-hardware">hardware guide</a> is excellent in telling you what you need. I got:</p><ul><li><a href="https://www.ebay.com/itm/5x-433Mhz-RF-transmitter-and-receiver-kit-Module-Arduino-ARM-WL-MCU-Raspberry-Fc-/254607185239?hash=item3b47c55557">5 ready <code>433.93MHz</code> sender circuits</a></li><li><a href="https://www.ebay.com/itm/10pcs-433-42m-433-42mhz-r433-f433-saw-resonator-crystals-to-39-/331637441887?hash=item4d3721c55f">10 pieces of the <code>433.42MHz</code> oscilator</a> - because my soldering is terrible</li><li><a href="https://www.ebay.com/itm/40PCS-20cm-2-54MM-FF-FM-MM-Dupont-wire-jumper-cables-male-to-female-For-Arduino/312724733910?hash=item48cfd8bfd6:g:05sAAOSwlbZdSZ6E">male-male jumper cables</a> - to avoid soldering üòâ</li><li>(already had it) a solid copper cable to use as an antenna</li></ul><p>After 4 weeks, all the eBay items were in place, and I could start soldering. Turns out de-soldering things off is much harder than soldering things on. I managed to peel away the original oscillator with by applying leverage underneath it using a swiss army knife and heating its connectors one by one. Soldering the new one was quite easy in comparison.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/soldering.jpg" alt="It&amp;rsquo;s not pretty but it worked." width="600"><figcaption><p>It‚Äôs not pretty but it worked.</p></figcaption></figure><p>I then took a 17cm piece of solid copper cable, and wrapped it into a small coil. Turns out soldering a think 1mm cable to a tiny connector was the trickiest bit, but with the right amount of patience, things will stick eventually.</p><p>Eventually, the fully connected sender fits nicely into a Raspberry Pi enclosure after connecting everything to the GPIO 4 pin:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/final_side_by_side.jpg" alt="All fits nicely into a standard Pi enclosure. The remote we&amp;rsquo;ll be replacing are on the left." width="700"><figcaption><p>All fits nicely into a standard Pi enclosure. The remote we‚Äôll be replacing are on the left.</p></figcaption></figure><h2 id="programming">Programming</h2><p>Installing Pi-Somfy is super easy, just follow <a href="https://github.com/Nickduino/Pi-Somfy#3-software">these steps</a>. It assume you install it under the default <code>pi</code> user in <code>/home/pi</code>, and comes with a handy <code>systemctl</code> service for auto-starting the system.</p><p>By default it will come up on port <code>:80</code> of your Pi. Programming the blinds takes a little bit of time. The procedure is as follows:</p><ul><li>Set the right channel (individual blind, or all) on the remote you‚Äôre programming from.</li><li>Measure the time in seconds it takes for each blind to come fully down.</li><li>Click <em>Add new</em> to put in the name (this will be your MQTT name by the way) and add in the time.</li><li>Using a pen, press the ‚Äúhole‚Äù on the other side of the remote. This sends the signal to the blind to accept programming a new remote.</li><li>Press <em>Save</em> and follow the instructions. The blind should ‚Äúwiggle‚Äù once programmed.</li></ul><p><strong>Note</strong>: The system relies on time to figure out where the blind is percentage-wise. It can often get things wrong (e.g. if you stopped it mid-through), or on the all-channel if blinds have different lengths (e.g. balcony). But in practice it works remarkably well.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/pi_remote.png" alt="Fully programmed blinds." width="700"><figcaption><p>Fully programmed blinds.</p></figcaption></figure><p><a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> is a standard protocol for message brokers, and finds a lot of use in home IoT. For most use cases, it has a simple publish-subscribe mechanic based on topics.</p><h2 id="installing-mosquitto">Installing Mosquitto</h2><p>Home Assistant has an embedded MQTT broker, but it is <em>highly advised</em> to use an external one, such as Mosquitto. You should install it on the same machine that runs Home Assistant, as it will act as a hub for other MQTT-connected services. To do that on Ubuntu:</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get install mosquitto mosquitto-clients
</code></pre></div><p>Now let‚Äôs set up a password file in <code>/etc/mosquitto/passwd</code> with a user for <code>homeassistant</code> and <code>pisomfy</code>.</p><pre><code>sudo mosquitto_passwd -c /etc/mosquitto/passwd homeassistant
Password: YourHomeAssistantPassword
sudo mosquitto_passwd -c /etc/mosquitto/passwd pisomfy
Password: YourPiSomfyPassword
</code></pre><p>Then, enforce use of passwords in mosquitto by editing <code>/etc/mosquitto/conf.d/default.conf</code> and changing it to:</p><pre><code>allow_anonymous false
password_file /etc/mosquitto/passwd
</code></pre><p>For debugging purposes, open a separate tab on the same machine and subscribe to all messages under the <code>home-assistant/#</code> topic via:</p><pre><code>mosquitto_sub -u homeassistant -P YourHomeAssistantPassword -p 1883 -h 127.0.0.1 -v -t "home-assistant/#"
</code></pre><p>This will come in handy to check things are working.</p><h2 id="configuring-home-assistant">Configuring Home Assistant</h2><p>Update your <code>/etc/homeassistant/configuration.yaml</code> to add:</p><div><pre><code data-lang="yaml"><span>mqtt</span><span>:</span><span>
</span><span>  </span><span>broker</span><span>:</span><span> </span><span>127.0.0.1</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>homeassistant</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"YourHomeAssistantPassword"</span><span>
</span><span>  </span><span>discovery</span><span>:</span><span> </span><span>true</span><span>
</span></code></pre></div><p>Restart Home Assistant</p><pre><code>sudo systemctl restart homeassistant
</code></pre><h3 id="configure-pisomfy">Configure PiSomfy</h3><p>On your Pi machine, open <code>/home/pi/operateShutters.conf</code> and edit the `[MQTT] section to look as follows</p><div><pre><code data-lang="ini"><span>[MQTT]</span>
<span># Location (IP Address of DNS Name) of the MQTT Server</span>
<span>MQTT_Server</span> <span>=</span> <span>myHAmachine # or hostname of your home assistant machine</span>
<span># Port of the MQTT Server</span>
<span>MQTT_Port</span> <span>=</span> <span>1883</span>
<span># Username for the MQTT Server</span>
<span>MQTT_User</span> <span>=</span> <span>pisomfy</span>
<span># Password of the MQTT Server</span>
<span>MQTT_Password</span> <span>=</span> <span>YourPiSomfyPassword</span>
<span># Enable auto discovery</span>
<span>EnableDiscovery</span> <span>=</span> <span>true</span>
</code></pre></div><p>And restart the service:</p><pre><code>sudo systemctl restart shutters.conf`
</code></pre><p>At this point the tab with the subscriptions should be full of messages. These are auto-discovery messages over MQTT for each of the programmed covers. This will cause Home Assistant to automatically add the entities.</p><p>They should show up with the same names as in PiSomfy.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/home_assistant_entities.png" alt="Home Assistant Entities auto discovered via MQTT." width="800"><figcaption><p>Home Assistant Entities auto discovered via MQTT.</p></figcaption></figure><p>Adding them to a dashboard is relatively trivial, for example:</p><div><pre><code data-lang="yaml"><span>type</span><span>:</span><span> </span><span>entities</span><span>
</span><span></span><span>entities</span><span>:</span><span>
</span><span>  </span>- <span>entity</span><span>:</span><span> </span><span>cover.lr_all</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>Living Room Covers</span><span>
</span></code></pre></div><p>In order to simplify things, I wanted to only expose the <code>_all</code> blinds (a.k.a. covers) to Google Home/Assistant. For that I added an explicit section in the <code>/etc/homeassistant/configuration.yaml</code> section of <code>google_assistant</code>:</p><div><pre><code data-lang="yaml"><span>google_assistant</span><span>:</span><span>
</span><span>  </span><span># ...</span><span>
</span><span>  </span><span>exposed_domains</span><span>:</span><span>
</span><span>    </span>- <span>fan</span><span>
</span><span>  </span><span>entity_config</span><span>:</span><span>
</span><span>    </span><span>cover.br_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Bedroom Covers"</span><span>
</span><span>    </span><span>cover.lr_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Living Room Covers"</span><span>
</span></code></pre></div><p>After restarting Home Assistant, and uttering the magical <em>Ok Google, Sync All Devices</em>, the covers will show up in your Home App:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/google_home.jpg" alt="Looks like a blind, acts as a blind." width="300"><figcaption><p>Looks like a blind, acts as a blind.</p></figcaption></figure><p>This means you can controll it using keywords:</p><ul><li><em>Ok Google, close Bedroom covers</em></li><li><em>Ok Google, open Bedroom covers</em></li><li><em>Ok Google, set Bedroom covers to 50%</em></li></ul><p>The killer feature is setting this up as a routine to open/close the blind as you wake up, go to sleep.</p><p>Happy hacking :)</p></div></div>]]>
            </description>
            <link>https://mwitkow.me/posts/2020-11-08_somfy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187945</guid>
            <pubDate>Mon, 23 Nov 2020 15:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game ‚Äì can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 245 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There‚Äôs just something fascinating about getting to know what‚Äôs under the hood of other people‚Äôs businesses. It‚Äôs like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That‚Äôs why, in the same spirit as Jake Lazaroff‚Äôs <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it‚Äôs now my turn to do a short write up of the technologies I‚Äôm using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn‚Äôt bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I‚Äôd use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let‚Äôs Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There‚Äôs plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than ‚Äútop‚Äù if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the ‚Ä¶</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. ü§î</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detective Game Design Problems]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25185571">thread link</a>) | @jsnell
<br/>
November 23, 2020 | https://digitales.games/blog/detective-game-design-problems | <a href="https://web.archive.org/web/*/https://digitales.games/blog/detective-game-design-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog">
            <div>
                <div>
					
                    <div>

                        <div>


    <div>

                    <p>Game design is such a wide and varied discipline that job titles in the field have become increasingly granular over the years ‚Äì and ever since we started working on our debut title Lacuna, I've become more and more convinced that "detective game designer" merits its own denomination as well. Detective gameplay (or "investigation gameplay") poses a number of unique challenges centered around two main problems: the <strong>struggle between story and puzzles</strong> (or "cases") as well as <strong>communication between the player and the game</strong>.</p>
<p>Since some of the explanations will be using our own game as an example, let me give you a quick rundown: Lacuna is a story-driven adventure with platformer controls and investigation elements. Its four fundamental gameplay types are dialogs (with choices), moving around, examining objects, and solving puzzles. All of them are staples of the point &amp; click genre, but their execution is quite unique; I don't want to go into more detail here because it's not pertinent to the topic, but you can <a href="http://lacuna.game/">check out the game on Steam</a> if you want to know more.</p>
<p><img alt="Gameplay" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/gameplay-movement.gif"><br>
<em>This is what the game looks like</em></p>
<h2>Story vs. puzzles</h2>
<p>A handful of abstract game design principles lie at Lacuna's core. For instance, "no takebacks" dictates that the player only get one shot at every decision, dialog, and puzzle. The game auto-saves and doesn't allow you to go back if you performed poorly or regret an earlier decision. There's also "limited feedback", which means that the player often isn't told immediately whether a solution was correct and what the consequences of their actions and decisions will be.</p>
<p>However, there's one in particular I want to highlight here because it concerns the above mentioned divide between story and puzzling in detective games: <strong>No getting stuck.</strong></p>
<p>The thought process behind it was simple: In games with both a story and puzzles (e.g. most P&amp;C games), story progress is almost always tied directly to puzzle progress. Until you solve the puzzle at hand, you don't get to see the next part of the story. For some players, especially those most interested in the story, this can become a problem. If they're stuck for too long, there's a chance they'll just drop out and never pick the game up again. Even if that doesn't happen, hard puzzles always run the risk of messing up the story's pacing and interrupting your immersion in the game ‚Äì because you're becoming frustrated or, even worse, because you decide to tab out and Google the solution. To avoid people getting stuck, we considered a number of solutions:</p>
<p><strong>Solution 1: Make the puzzles very easy?</strong><br>
This isn't our favorite since it somewhat defeats the purpose of puzzles. They'd still play a role as a change of pace now and then, but if puzzles aren't a little hard, nobody will feel like a detective solving them. Some early puzzles in Lacuna are easy, but most aren't.</p>
<p><strong>Solution 2: Provide hints?</strong><br>
Hint systems can be found in many adventures featuring puzzles. Unfortunately, they often take the player out of the experience in one of three ways: In some cases, the hint is provided by extradiegetic UI (e.g. in the pause menu) and therefore seems to come out of nowhere in the game world. In other cases, the player character is the one giving the hint, disconnecting the player from their avatar‚Äôs perspective. The third option of NPCs providing hints is a little better; however, it is often hard to justify <em>why</em> an NPC would be able to point the player in the right direction without possessing the rest of the solution to the ongoing puzzle (and why they didn't volunteer it in the first place). The two types of (sort-of) hint systems we went with in Lacuna are <em>Highlight Mode</em>, which displays optional outlines around objects and NPCs that hold new information, and <em>redundant information</em>, meaning that sometimes the player is given two ways of obtaining an important clue.</p>
<p><img alt="Hints" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-hints.png"><br>
<em>"YOU ARE PLAYING A GAME RIGHT NOW"</em></p>
<p><strong>Solution 3: Decouple story progress from puzzle progress?</strong><br>
Why not simply make a story-driven game throughout which the player can solve the occasional puzzle if they feel like it? Well, because it would require that puzzles be somewhat detached from the story. As a result, they run the risk of feeling meaningless since solving them is not rewarding and failing is not punishing. However, this <em>can</em> work quite well when combined with...</p>
<p><strong>Solution 4: Make branching content for different solutions?</strong><br>
Instead of impeding the player‚Äôs progress, wrong or missing puzzle solutions could lead to a less desirable continuation and/or outcome of the story. Unfortunately, creating a new story branch for each and every wrong solution to a puzzle is hardly feasible. However, there are less extreme ways of realizing this. For instance, the game could account for the player‚Äôs <em>overall</em> puzzling performance at certain points in the game, e.g. trigger the ‚Äúgood‚Äù finale to an act if they got more than x% of the puzzles right, and the ‚Äúbad‚Äù one if not. There could also be cascading consequences of sorts, e.g. solving one case correctly may give the player an edge in a later one. These approaches have similar downsides as optional puzzles do, but to a lesser degree; puzzle success no longer being required for progress makes them feel more detached from the story and removes immediate feedback. Regardless, we have found this to be the best solution, which is why we employ it quite a bit in Lacuna (while trying to avoid all the pitfalls). By the way, if all of this is becoming too abstract for you, bear with us! The second half of this post is all about a real example from the game.</p>
<p><img alt="Detroit: Become Human" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-branching-content.jpg"><br>
<em>Detroit: Become Human offers an astonishing number of different outcomes depending on player action, but not everybody has that kind of money to burn</em></p>
<p>Despite all of these measures being taken to make sure that the player won't get stuck, Lacuna can still be called a hard game. While it's not difficult to get <em>to</em> the end, it's pretty difficult to get a <em>good</em> ending and not mess things up on your way there. In other words, rushing through the whole story is possible if you don't mind bringing it to a terrible conclusion.</p>
<h2>Communicating with the game</h2>
<p>While the previous chapter only concerns detective games that also prominently feature a story, this next one is relevant to pretty much every detective game every made. It addresses the topic of communication between the player and the game, and especially how the player can express their thoughts to it. Several principles have proven to make for a good experience across countless approaches to this problem over the years:</p>
<p><strong>Principle 1: Many channels out, few channels back in.</strong><br>
If the game conveys information to the player on many different channels and in many different ways, the process of piecing the solution together tends to feel more interesting and rewarding. In Lacuna, the player picks up clues from dialogs, objects, environments, the news, and e-mails (with all sorts of attachments). At the same time, the channels via which the player communicates that solution back to the game are kept to a minimum, namely cloze texts we like to call "Case Sheets" and (to a lesser degree) dialog choices. Having one or two central mechanics for player input makes the experience more coherent and transparent and facilitates designing the mysteries around it.</p>
<p><img alt="Obra Dinn" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-obra-dinn.jpg"><br>
<em>Return of the Obra Dinn by Lucas Pope provides a bunch of different sources of information, but just one central mechanic for the player to communicate back to the game</em></p>
<p><strong>Principle 2: Have the player communicate only the solution.</strong><br>
It is near impossible to create a system through which the player communicates to the game <em>how</em> they arrived at a solution. Luckily, this is not necessary. A well-designed puzzle provides all the information, then moves the entire solution process solely <em>into the player‚Äôs head</em>, and finally prompts the player to input only their answer. The player‚Äôs objective should be stated clearly, but in a very general way at the start of a case (e.g. ‚Äúfind the culprit‚Äù).</p>
<p><strong>Principle 3: Give the player maximum freedom in communicating the solution.</strong><br>
The way in which the player communicates the answer to the game is the most crucial part to get right. One aspect is to give the player many choices (or a large combination of choices) to pick from. Two things should be avoided: 1. Giving the player a high probability to succeed by picking a random answer. 2. Making it easy for the player to guess correctly because only one or a few of the available answers appear plausible. An example for a bad solution like this would be to give the player three dialog choices to solve the puzzle; even worse would be if one of them obviously made the most sense. A better approach would be to give the player a cloze text with a bunch of plausible options for each gap. Another possibility is to have the solution be an unguessable string of characters that the player needs to enter manually. Both ideas utilize combinatorial explosion to make guessing and brute-forcing nearly impossible.</p>
<p><img alt="Detective Grimoire" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-case-sheets.jpg"><br>
<em>Good luck brute-forcing your way through Detective Grimoire's cloze texts</em></p>
<h2>Puzzle example</h2>
<p>Hopefullly all this will become crystal clear when put to concrete use! The following is an early level in Lacuna. It doesn't contain some of the difficulties added later (like a large number of channels communicating potential evidence). In harder cases, the player will need to have paid attention to testimonies, news articles etc. from earlier levels to arrive at the correct conclusion, and some cases span multiple levels. Not this one, though; all the information required to solve it is directly contained in the clues and dialogs of the one level where it starts and ends.</p>
<p>This chapter won't reveal much of importance about the story, but it will spoil the solution to this one puzzle, so consider yourself warned.</p>
<h3>The puzzle</h3>
<p>Here's what happens: Our protagonist Neil is called to a ‚Ä¶</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitales.games/blog/detective-game-design-problems">https://digitales.games/blog/detective-game-design-problems</a></em></p>]]>
            </description>
            <link>https://digitales.games/blog/detective-game-design-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185571</guid>
            <pubDate>Mon, 23 Nov 2020 11:11:43 GMT</pubDate>
        </item>
    </channel>
</rss>
