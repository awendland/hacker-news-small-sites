<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 29 Jul 2020 04:18:02 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 29 Jul 2020 04:18:02 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[GnuTLS audit: passive cleartext recovery attack]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23962840">thread link</a>) | @masklinn
<br/>
July 27, 2020 | https://anarc.at/blog/2020-06-10-gnutls-audit/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-06-10-gnutls-audit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>So <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> came out while I wasn't looking last week. The
GnuTLS advisory (<a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">GNUTLS-SA-2020-06-03</a>) is pretty opaque so I'll
refer instead to <a href="https://twitter.com/FiloSottile/status/1270061316368224256">this tweet</a> from <a href="https://twitter.com/FiloSottile">@FiloSottile</a> (Go team
security lead):</p>

<blockquote><p>PSA: don't rely on GnuTLS, please.</p>

<p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> Whoops, for the past 10 releases most TLS 1.0–1.2
connection could be passively decrypted and most TLS 1.3 connections
intercepted. Trivially.</p>

<p>Also, <a href="https://blog.filippo.io/we-need-to-talk-about-session-tickets/">TLS 1.2–1.0 session tickets are awful</a>.</p></blockquote>

<p>You are reading this correctly: supposedly encrypted TLS connections
made with affected GnuTLS releases are vulnerable to <em>passive</em>
cleartext recovery attack (and active for 1.3, but who uses that
anyways). That is extremely bad. It's pretty close to just switching
everyone to HTTP instead of HTTPS, more or less. I would have a lot
more to say about the security of GnuTLS in particular -- and security
in general -- but I am mostly concerned about patching holes in the
roof right now, so this article is not about that.</p>

<p>This article is about figuring out what, exactly, was exposed in our
infrastructure because of this.</p>






<p>Assuming you're running Debian, this will show a list of packages that
<code>Depends</code> on GnuTLS:</p>

<pre><code>apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u
</code></pre>

<p>This assumes you run this only on hosts running Buster or
above. Otherwise you'll need to figure out a way to pick machines
running GnuTLS 3.6.4 or later.</p>

<p>Note that this list only <em>first level</em> dependencies! It is perfectly
possible that another package uses GnuTLS without being listed
here. For example, in the above list I have <code>libcurl3-gnutls</code>, so the
be really thorough, I would actually need to recurse down the
dependency tree.</p>

<p>On my desktop, this shows an "interesting" list of targets:</p>

<ul>
<li><code>apt</code></li>
<li><code>cadaver</code> - AKA WebDAV</li>
<li><code>curl</code> &amp; <code>wget</code></li>
<li><code>fwupd</code> - another attack on top of <a href="https://github.com/justinsteven/advisories/blob/master/2020_fwupd_dangling_s3_bucket_and_CVE-2020-10759_signature_verification_bypass.md">this one</a></li>
<li><code>git</code> (through the <code>libcurl3-gnutls</code> dependency)</li>
<li><code>mutt</code> - all your emails</li>
<li><code>weechat</code> - your precious private chats</li>
</ul>


<p>Arguably, fetchers like <code>apt</code>, <code>curl</code>, <code>fwupd</code>, and <code>wget</code> rely on HTTPS for
"authentication" more than secrecy, although <code>apt</code> has its own
OpenPGP-based authentication so that wouldn't matter anyways. Still,
this is truly distressing. And I haven't mentioned here things like
<code>gobby</code>, <code>network-manager</code>, <code>systemd</code>, and others - the scope of this is
broad. Hell, even good old <code>lynx</code> links against GnuTLS.</p>

<p>In our infrastructure, the magic command looks something like this:</p>

<pre><code>cumin -o txt -p 0  'F:lsbdistcodename=buster' "apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u" | tee gnutls-rdepds-per-host | awk '{print $NF}' | sort | uniq -c | sort -n
</code></pre>

<p>There, the result is even more worrisome, as those important packages seem to rely on GnuTLS for their transport security:</p>

<ul>
<li><code>mariadb</code> - all MySQL traffic and passwords</li>
<li><code>mandos</code> - full disk encryption</li>
<li><code>slapd</code> - LDAP passwords</li>
</ul>


<p><code>mandos</code> is especially distressing although it's probably not
vulnerable because it seems it doesn't store the cleartext -- it's
encrypted with the client's OpenPGP public key -- so the TLS tunnel
never sees the cleartext either.</p>

<p><a href="https://twitter.com/jedisct1/status/1270078914996682753">Other reports</a> have also mentioned the following servers link
against GnuTLS and could be vulnerable:</p>

<ul>
<li><code>exim</code></li>
<li><code>rsyslog</code></li>
<li><code>samba</code></li>
<li>various <code>VNC</code> implementations</li>
</ul>




<p>Those programs are not affected by this vulnerability:</p>

<ul>
<li><code>apache2</code></li>
<li><code>gnupg</code></li>
<li><code>python</code></li>
<li><code>nginx</code></li>
<li><code>openssh</code></li>
</ul>


<p>This list is not exhaustive, naturally, but serves as an example of
common software you don't need to worry about.</p>

<p>The vulnerability only exists in GnuTLS, as far as we know, so
programs linking against other libraries are not vulnerable.</p>

<p>Because the vulnerability affects session tickets -- and those are set
on the server side of the TLS connection -- only users of GnuTLS as a
server are vulnerable. This means, for example, that while <code>weechat</code>
uses GnuTLS, it will only suffer from the problem when acting as a
server (which it does, in relay mode) or, of course, if the remote IRC
server also uses GnuTLS. Same with apt, curl, wget, or git: it is
unlikely to be a problem because it is only used as a client; the
remote server is usually a webserver -- not git itself -- when using
TLS.</p>



<p>Keep in mind that it's not because a package links against GnuTLS that
it <em>uses</em> it. For example, I have been told that, on Arch Linux, if
both GnuTLS and OpenSSL are available, the <code>mutt</code> package will use the
latter, so it's not affected. I haven't confirmed that myself nor have I
checked on Debian.</p>

<p>Also, because it relies on session tickets, there's a time window
after which the ticket gets cycled and properly initialized. But that
is <a href="https://twitter.com/__agwa/status/1270054740559384576">apparently 6 hours by default</a> so it is going to protect only
really long-lasting TLS sessions, which are uncommon, I would argue.</p>

<p>My audit is limited. For example, it might have been better to walk
the shared library dependencies directly, instead of relying on Debian
package dependencies.</p>



<p>It seems the vulnerability might have been introduced in <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/695">this merge
request</a>, itself following a (entirely reasonable) <a href="https://gitlab.com/gnutls/gnutls/-/issues/184">feature request
to make it easier to rotate session tickets</a>. The merge request was
open for a few months and was thoroughly reviewed by a peer before
being merged. Interestingly, the vulnerable function
(<code>_gnutls_initialize_session_ticket_key_rotation</code>), explicitly says:</p>

<pre><code> * This function will not enable session ticket keys on the server side. That is done
 * with the gnutls_session_ticket_enable_server() function. This function just initializes
 * the internal state to support periodical rotation of the session ticket encryption key.
</code></pre>

<p>In other words, it thinks it is not responsible for session ticket
initialization, yet it is. Indeed, the <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275/">merge request fixing the
problem</a> unconditionally does this:</p>

<pre><code>memcpy(session-&gt;key.initial_stek, key-&gt;data, key-&gt;size);
</code></pre>

<p>I haven't reviewed the code and the vulnerability in detail, so take
the above with a grain of salt.</p>

<p>The <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275.patch">full patch is available here</a>. See also the <a href="https://gitlab.com/gnutls/gnutls/-/issues/1011">upstream issue
1011</a>, the <a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">upstream advisory</a>, the <a href="https://security-tracker.debian.org/tracker/CVE-2020-13777">Debian security
tracker</a>,
and the <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1843723">Redhat Bugzilla</a>.</p>



<p>The impact of this vulnerability depends on the affected packages and
how they are used. It can range from "meh, someone knows I downloaded
that Debian package yesterday" to "holy crap my full disk encryption
passwords are compromised, I need to re-encrypt all my drives",
including "I need to change all LDAP and MySQL passwords".</p>

<p>It promises to be a fun week for some people at least.</p>

<p>Looking ahead, however, one has to wonder whether we should follow
<a href="https://twitter.com/FiloSottile">@FiloSottile</a>'s advice and stop using GnuTLS altogether. There are
at least a few programs that link against GnuTLS because of the
<a href="https://en.wikipedia.org/wiki/OpenSSL#Licensing">OpenSSL licensing oddities</a> but that has been first announced in
2015, then <a href="https://www.openssl.org/blog/blog/2017/03/22/license/">definitely and clearly resolved in 2017</a> -- or <a href="https://opensource.com/article/19/2/top-foss-legal-developments">maybe
that was in 2018</a>? Anyways it's fixed, pinky-promise-I-swear,
except if you're one of those weirdos still using GPL-2, of
course. Even though OpenSSL isn't the simplest and secure TLS
implementation out there, it could preferable to GnuTLS and maybe we
should consider changing Debian packages to use it in the future.</p>

<p>But then again, the last time something like this happened, it was
<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a> and GnuTLS wasn't affected, so who knows... It is
likely that people don't have OpenSSL in mind when they suggest moving
away from GnuTLS and instead think of other TLS libraries like
<a href="https://tls.mbed.org/">mbedtls</a> (previously known as PolarSSL), <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a>, <a href="https://boringssl.googlesource.com/boringssl/">BoringSSL</a>,
<a href="https://www.libressl.org/">LibreSSL</a> and so on. Not that those are totally sinless either...</p>

<p>"This is fine", as they say...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            <div>
            <p><span>Created <time datetime="2020-06-11T15:47:35Z" pubdate="pubdate" title="Thu, 11 Jun 2020 11:47:35 -0400">tard dans la matinée de Thursday, June 11th, 2020</time>.</span>
            <span>
            
            <a href="http://source.anarcat.wiki.orangeseeds.org/?p=source.git;a=history;f=blog/2020-06-10-gnutls-audit.mdwn">Edited <time datetime="2020-06-11T16:18:48Z" title="Thu, 11 Jun 2020 12:18:48 -0400">Thursday, à l'heure du déjeuner, June 11th, 2020</time>.</a>
            
            </span>
            </p></div>

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-06-10-gnutls-audit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962840</guid>
            <pubDate>Mon, 27 Jul 2020 07:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACCC alleges Google misled consumers about expanded use of personal data]]>
            </title>
            <description>
<![CDATA[
Score 265 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23961881">thread link</a>) | @Khaine
<br/>
July 26, 2020 | https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div property="content:encoded"><p><em>Correction: An earlier version of this media release used a hypothetical example that suggested that Google used information about users’ health to personalise or target advertisements. Google says that it does not show personalised ads based on health information. This example has been removed from the media release.</em></p>

<p>The ACCC has launched Federal Court proceedings against Google LLC (Google), alleging Google misled Australian consumers to obtain their consent to expand the scope of personal information that Google could collect and combine about consumers’ internet activity, for use by Google, including for targeted advertising.</p>

<p>The ACCC alleges Google misled consumers when it failed to properly inform consumers, and did not gain their explicit informed consent, about its move in 2016 to start combining personal information in consumers’ Google accounts with information about those individuals’ activities on non-Google sites that used Google technology, formerly DoubleClick technology, to display ads.</p>

<p>This meant this data about users’ non-Google online activity became linked to their names and other identifying information held by Google. Previously, this information had been kept separately from users’ Google accounts, meaning the data was not linked to an individual user.</p>

<p>Google then used this newly combined information to improve the commercial performance of its advertising businesses.</p>

<p>The ACCC also alleges that Google misled consumers about a related change to its privacy policy.</p>

<p>“We are taking this action because we consider Google misled Australian consumers about what it planned to do with large amounts of their personal information, including internet activity on websites not connected to Google,” ACCC Chair Rod Sims said.</p>

<p>“Google significantly increased the scope of information it collected about consumers on a personally identifiable basis. This included potentially very sensitive and private information about their activities on third party websites. It then used this information to serve up highly targeted advertisements without consumers’ express informed consent,” Mr Sims said.</p>

<p>“We allege that Google did not obtain explicit consent from consumers to take this step.”</p>

<p>“The use of this new combined information allowed Google to increase significantly the value of its advertising products, from which it generated much higher profits.”</p>

<p>“The ACCC considers that consumers effectively pay for Google’s services with their data, so this change introduced by Google increased the “price” of Google’s services, without consumers’ knowledge,” Mr Sims said.</p>

<p><strong>“I agree” notification</strong></p>

<p>The conduct is alleged to have impacted millions of Australians with Google accounts.</p>

<p>From 28 June 2016 until at least December 2018, Google account holders were prompted to click “I agree” to a pop-up notification from Google that purported to explain how it planned to combine their data, and sought the consumers’ consent for this.</p>

<blockquote>
	<p><em>Some new features for your Google Account</em></p>

	<p><em>We’ve introduced some optional features for your account, giving you more control over the data Google collects and how it’s used, while allowing Google to show you more relevant ads.</em></p>
</blockquote>

<p>The notification also stated,&nbsp;<em>“More information will be available in your Google Account making it easier for you to review and control”</em>; and&nbsp;<em>“Google will use this information to make ads across the web more relevant for you.”</em></p>

<p>Before June 2016, Google only collected and used, for advertising purposes, personally identifiable information about Google account users’ activities on Google owned services and apps like Google Search and YouTube.</p>

<p>After June 2016, when consumers clicked on the “I agree” notification, Google began to collect and store a much wider range of personally identifiable information about the online activities of Google account holders, including their use of third-party sites and apps not owned by Google.</p>

<p>Previously, this additional data had been stored separately from a user’s Google account.</p>

<p>Combined with the personal data stored in Google accounts, this provided Google with valuable information with which to sell even more targeted advertising, including through its Google Ad Manager and Google Marketing Platform brands.</p>

<p>The ACCC alleges that the “I agree” notification was misleading, because consumers could not have properly understood the changes Google was making nor how their data would be used, and so did not - and could not - give informed consent.</p>

<p>“We believe that many consumers, if given an informed choice, may have refused Google permission to combine and use such a wide array of their personal information for Google’s own financial benefit,” Mr Sims said.</p>

<p><strong>Privacy policy change</strong></p>

<p>Before 28 June 2016, Google stated in its privacy policy that it&nbsp;<em>“will not combine DoubleClick cookie information with personally identifiable information unless we have your opt-in consent.”</em></p>

<p>On 28 June 2016, Google deleted this statement and inserted the following statement:<em>&nbsp;“[d]epending on your account settings, your activity on other sites and apps may be associated with your personal information in order to improve Google’s services and the ads delivered by Google.”</em></p>

<p>Google’s privacy policy also states:&nbsp;<em>“[w]e will not reduce your rights under this Privacy Policy without your explicit consent.”</em></p>

<p>The ACCC alleges that Google did not in fact obtain consumers’ explicit consent for this change to the privacy policy, and that Google’s statement that it would not reduce consumers’ rights without their explicit consent was therefore misleading.</p>

<p>“Google made a clear representation about how it would protect users’ privacy. The ACCC alleges that Google made changes without obtaining the explicit consent it had promised consumers it would obtain before altering how it protected their private information,” Mr Sims said.</p>

<p><strong>DoubleClick</strong></p>

<p>In 2008, Google acquired DoubleClick, a supplier of ad-serving technology services to publishers and advertisers.</p>

<p>Google now supplies DoubleClick’s services through its Google Ad Manager and Google Marketing Platform brands, which are the leading suppliers of ad-tech intermediary services.</p>

<p>These services track users’ internet activity on third-party sites that display ads through the use of DoubleClick’s advertising technology.</p>

<p>Google’s acquisition of DoubleClick required approval by competition authorities including the US Federal Trade Commission and the European Commission. The ACCC also reviewed and cleared this transaction.</p>

<p>FTC and EC cleared the acquisition, and in doing so considered submissions from Google that it would not be able to combine DoubleClick’s data on consumers’ internet activity with its own data about consumers’ activity on Google services because, at the time, DoubleClick’s contracts with its users prevented Google from doing so.</p>

<p>The agencies did not, however, rely on these submissions in clearing the acquisition.</p>

<p>Before 28 June 2016, Google collected and stored this information on a non-personally identifiable basis, as stated in its privacy policy.</p>

<p>On 28 June 2016, it changed its privacy policy by removing the term explaining how it would treat this DoubleClick data.</p>

<p><strong>Images</strong></p>

<p>Depending on the device and Google service being used by the consumer, the notification published by Google from 28 June 2016 was presented in a variety of ways. A copy of the notification in the form published to consumers using desktop devices is provided below for reference.</p>





<p><em>Source: Provided to the ACCC by Google Australia Pty Ltd</em></p>

<p>The relevant changes to Google’s Privacy Policy made on 28 June 2016 are also shown below for reference:</p>



<p>Source: Accessed from https://policies.google.com/privacy/archive?hl=en-US on 24 June 2020</p>

<p><strong>Background</strong></p>

<p>Google LLC (Google) is a multinational company incorporated in the United States with its headquarters in Mountain View, California. It is a subsidiary of Alphabet Inc.</p>

<p>Google supplies a range of services to consumers in Australia including Google Search, Google Maps, Gmail, YouTube, Google Play and Google Chrome.</p>

<p>Google also provides advertising services and analytics services to individuals and businesses. Advertising services are provided on Google services, such as Google Search, Google Maps and YouTube, as well as on websites and mobile device based applications not published or controlled by Google that partner with Google to display advertisements.</p>

<p>Google derives the majority of its revenue from its advertising and analytics services.</p>

<p><strong>Note:</strong> The concise statement has not been attached as it has been filed on a confidential basis pending claims by Google.</p>
</div></div></div></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961881</guid>
            <pubDate>Mon, 27 Jul 2020 02:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Hard-to-Read Gravestones (2014)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 20 (<a href="https://news.ycombinator.com/item?id=23961343">thread link</a>) | @vinnyglennon
<br/>
July 26, 2020 | https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/ | <a href="https://web.archive.org/web/*/https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961343</guid>
            <pubDate>Mon, 27 Jul 2020 00:50:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Warren Buffett 1997 Email Exchange on Microsoft [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23961036">thread link</a>) | @breck
<br/>
July 26, 2020 | http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf | <a href="https://web.archive.org/web/*/http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961036</guid>
            <pubDate>Sun, 26 Jul 2020 23:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Eng, the Master of the “Impossible Bottle”]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 59 (<a href="https://news.ycombinator.com/item?id=23960735">thread link</a>) | @fortran77
<br/>
July 26, 2020 | https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm | <a href="https://web.archive.org/web/*/https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="780">
  <tbody><tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot00.jpg" width="250" height="440"></td>
    <td colspan="2"><div>
      <h3>Harry Eng the Master Bottle Filler.</h3>
      <p>Harry was born in 1932 and died in 1996. He was  a school teacher, educational consultant, inventor, and magician. 
        A web search will tell you a little about his many talents but in summary: </p>
      <p><strong>Everything he did was intended to teach you to think. </strong></p>
      <p>Here are some of his bottles that are in the Puzzle Museum.</p>
      
      <p>This bottle contains his "Trademark" knot. It is, as always, too large to come out of the bottle, but also the stick  plus cord is too wide for the neck of the bottle.</p>
    </div></td>
  </tr>
  <tr>
    <td colspan="2"><p>One evening Harry was in a London hotel and decided to visit the Puzzle Museum the next morning. When he and his friends had finished their bottle of wine, he took the bottle up to his room. He then filled it with a book of matches, menu, and the pack of cards as a gift for us. This is a particular favourite as he assured us that the only tools he had were  a pencil and rubber bands. </p>
    <p>G135(AMB-POBJ) </p></td>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot01.jpg" width="250" height="622"></p></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot02.jpg" width="250" height="529"></p></td>
    <td colspan="2" rowspan="2">This is a "Loaded Deck". The deck is loaded with 6 shots. </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2">This incredible bottle has a bolt through 3 packs of playing cards. It is so tightly packed that there appears to be no room to get the nut on or off . </td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot03.jpg" width="250" height="523"></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot04.jpg" width="250" height="491"></p></td>
    <td colspan="2"><p>Our venerable curator has gone nearly blind with a magnifying glass but has failed to find any sign of breaks or glue in this plank. It is a One Gallon Bottle and the plank measures about 14 cm x 12.5 cm x 1.8 cm thick.</p>
    <p>Even if one could use the key that is loose in the bottom of the bottle, the padlock on the bottom of the plank is too large to fit through the neck of the bottle.</p>
    <p>The plank is engraved with Harry's "Think" Logo. </p></td>
  </tr>
  <tr>
    <td colspan="2"><p>This was Harry's favourite. Made in 1991. The label records how it was made:</p>
    <p>"Find a piece of wood from the High Chaparral (Manginita wood). Drill Deck. Put case in bottle. Put cards in case. Put rope through deck. Tie knot. Put nut, bolt, and lock parts into bottle. Hold bolt with a magnet - screw nut on with dental floss. Assemble and lock padlock. Finally sign the pack of cards". </p></td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot05.jpg" width="250" height="436"></td>
  </tr>
  <tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot06.jpg" width="380" height="444"></td>
    <td colspan="2"><p>This is Harry's ship in a bottle. <br>For details see<br> 
      <a href="https://www.puzzlemuseum.com/month/picm06/200608cutter.htm">Puzzle of the Month for August 2006</a> </p>
    </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></div></div>]]>
            </description>
            <link>https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23960735</guid>
            <pubDate>Sun, 26 Jul 2020 22:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small mail server best current practices]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 133 (<a href="https://news.ycombinator.com/item?id=23958599">thread link</a>) | @ebcase
<br/>
July 26, 2020 | https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/ | <a href="https://web.archive.org/web/*/https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <main>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
        <header>
          
          <time itemprop="datePublished" datetime="2020-07-24">July 24, 2020</time>
        </header>
        <p><em>(This post was originally written as a reply on the mailop mailing-list, but
a friend asked me to turn it into a blog post.  I've edited it, mostly
adding more links to elsewhere, but there are some additions here.)</em></p>
<p><em>Context: someone with a mail-server hosted in a German facility with a
poor reputation for handling abuse reports was asking for help on
sending email to their Gmail-using friends; they had SPF and didn't see
the point of DKIM; they had TLS setup for their mail-server, using a
certificate from CACert.</em></p>
<p>There's a PDF from Google from 2006 which is still worth reading:
<a href="https://research.google.com/pubs/archive/45.pdf">https://research.google.com/pubs/archive/45.pdf</a>, entitled
“Sender Reputation in a Large Webmail Service” by Bradley Taylor.
Anyone running a mail-server today needs to read that document.</p>
<p>If you don't send much email, then the only IP-based reputation which
Google can assess you on is the reputation of your address-block, so
being in a “troublesome” hosting provider will score heavily against
you.  At that point, if not moving away, you need to try to balance out
that negative score with enough positives that any of the large
providers using reputation scoring will accept the mail.</p>
<p>Working forward-and-reverse paired DNS is even more important for IPv6
than for IPv4; for better or worse, some of the large providers have
decided that exemptions in old standards for old behavior should not
apply when folks deploy standards which are far newer.  So you
absolutely need an <code>MX</code> record, you must not just rely upon
address-records (<code>A</code> and <code>AAAA</code>).</p>
<p>With a poor IP-based reputation, you need to see if you can score a
better domain-based reputation.  This is where DKIM comes into play:
once you can provably link a message to really be from a given domain,
then even if you don't send much mail you can benefit from stuff like
“not on day-old-bread domain-lists”.  But having DKIM and then a DMARC
record does help (and <a href="https://bridge.grumpy-troll.org/2014/04/dmarc-stance/">I'm no fan of DMARC</a>).</p>
<p>For the mail-server's TLS: for that to count in your favor instead of
being a wash, I strongly suspect that it needs to be a certificate which
senders can verify.  For those people scoring up for “better TLS”, those
senders using DANE will be happy with a TLSA record in DNSSEC for your
CACert anchor.  But the large webmail providers are Resistant to having
to deploy DNSSEC verification, so instead have pushed out an alternative
called MTA-STS.  With MTA-STS, you're tied into “whichever subset of CAs
all the large senders you care about will trust”, and then using that CA
for the certificates both for the MTA-STS web-server and for your
mail-server.  Note that you don't need to implement the client logic for
MTA-STS (and I think it's antithetical to an open federated platform)
but do need to just publish the static information for those senders who
do use it. At that point, CACert is not going to cut it.  You'd need to
try Let's Encrypt instead.</p>
<p>The ongoing natural tendency from larger providers is to favor
supporting what the majority of their users want the majority of the
time.  With so many people using larger providers, they naturally tilt
towards stuff which works with the larger senders, and requiring more
hoops.  Those additional hoops create more work for smaller providers
and self-hosters doing thing manually.</p>
<p>We need better automation tools around all of this.  The below will make
it clearer why.</p>
<p>So, here is my current understanding of the best current practices here,
in reality not IETF idealism.  This includes making mandatory stuff
which some folks insist must be optional, because realistically to send
to some large providers it's not optional.  This list includes features
to make you compatible with ongoing trends in the EU (particularly
Germany) to strongly disfavor allowing clear-text SMTP.</p>
<p>This assumes that you are <em>not</em> a large sender who should also be
setting up feedback loops, learning how to “warm” IPs, considering BIMI,
postmaster tooling domain verification, etc.</p>
<h3 id="deliverability-fixes">Deliverability fixes</h3>
<ol>
<li>reverse DNS with matching forward DNS; the name used should not
pattern-match anything generic and ideally would include a DNS label
of <code>mail</code> or <code>mx</code> or the like in it.</li>
<li>MX record, always.</li>
<li>Accurate SPF;
<ul>
<li>ideally not too broad; pay attention to SPF's query limits.</li>
<li>avoid <code>-all</code> at the end because, with the sole exception of “this
domain never sends email” records, the larger operators have metrics to
show that using <code>-all</code> <em>tends</em> to be a sign of over-enthusiasm rather
than reality, so it will slightly count against you;</li>
<li>remember to have an SPF record for your <code>HELO</code> hostname, because
when you send a “bounce” rejection, this is the thing which will be
looked up (since there's no domain in <code>&lt;&gt;</code>).</li>
</ul>
</li>
<li>DKIM set up, with thought towards the selector namespace.
<ul>
<li>RSA2048 key is effectively a hard-requirement
<ul>
<li>DNS TXT records consist of one or more DNS strings, each of which
is limited to 255 ASCII characters.  For a key of this size, you
will end up needing two DNS strings in the zonefile.</li>
</ul>
</li>
<li>Ed25519 keys are not yet widely supported, but by now are not
likely to actively break and make things worse for you, if you
dual-sign.  This needs to be a different selector.</li>
<li>Note that for various good reasons you should design this to be
something you routinely rotate.
<ul>
<li>Some folks use yearly, some monthly</li>
<li>I rotate every three months.</li>
</ul>
</li>
</ul>
</li>
<li>DMARC record; see <a href="https://tools.ietf.org/html/rfc7489" title="Domain-based Message Authentication, Reporting, and Conformance (DMARC)">RFC 7489</a>
<ul>
<li>But for domains which humans send from <em>don't</em> use
<code>p=quarantine</code> or <code>p=reject</code>;</li>
<li>Do consider setting up a receiver for reports, just so that you can
see how much of a privacy breach DMARC reporting is when you send
to mailing-lists which don't re-sign. :-/</li>
</ul>
</li>
<li>TLS certificate from a CA in the main trust anchor bundles;
<ul>
<li>Just use Let's Encrypt.</li>
</ul>
</li>
<li>MTA-STS web-server with HTTPS certificate from the same CA, and the
relevant MTA-STS txt file in place; add the DNS record when it's up
and happy.  See <a href="https://tools.ietf.org/html/rfc8461" title="SMTP MTA Strict Transport Security (MTA-STS)">RFC 8461</a>.
<ul>
<li>See <a href="https://esmtp.email/tools/mta-sts/">https://esmtp.email/tools/mta-sts/</a> for a testing validation tool
(with thanks to Luis Muñoz for the pointer).</li>
</ul>
</li>
<li>For the independent mail providers using the stuff broadly supported
in open source MTAs, you should look at DNSSEC, because the patterns
here are less susceptible to rent-seeking pressures:
<ul>
<li>DNSSEC-signed zone for your own domain
<ul>
<li>Use whichever signing algorithm CloudFlare are currently using:
this should be both current for cryptography and widely enough
supported that if it's not supported by someone's resolver, then
they have bigger problems than just your domain.</li>
</ul>
</li>
<li>DNSSEC validating resolver for you to look up records of others
(consider <a href="https://nlnetlabs.nl/projects/unbound/about/">Unbound</a> or <a href="https://www.knot-resolver.cz/">Knot Resolver</a>)</li>
<li>DANE records for your own domain (TLSA records in DNS)
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc7672" title="SMTP Security via Opportunistic DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS)">RFC 7672</a> for the SMTP details.</li>
<li>See <a href="https://tools.ietf.org/html/rfc6698" title="The DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS) Protocol: TLSA">RFC 6698</a> for the base spec with <a href="https://tools.ietf.org/html/rfc7218" title="Adding Acronyms to Simplify Conversations about DNS-Based Authentication of Named Entities (DANE)">RFC 7218</a> for some common
acronyms which make talking about it easier.</li>
<li>See <a href="https://tools.ietf.org/html/rfc7671" title="The DNS-Based Authentication of Named Entities (DANE) Protocol: Updates and Operational Guidance">RFC 7671</a> for the updates and operational guidance.</li>
<li>There are other RFCs, for SRV records and for OpenPGP, etc.</li>
</ul>
</li>
<li>Tell your mail-server to obey DANE stuff, so that if there's a TLSA
record in DNSSEC-verified DNS then the mail-server can disable
fallback to cleartext for delivery to MX (and ideally also then
verify the TLS connection has a cert chain which is anchored in one
of the TLSA records)</li>
<li><a href="https://dnsviz.net/">https://dnsviz.net</a> is your friend</li>
</ul>
</li>
<li><code>_smtp._tls</code> record so you can get reports of TLS failures sending to
you</li>
<li>Seeing if you can get your IP onto one of the open DNS-based
allow-lists (also called “whitelists” but some folks are moving away
from that term), such as <a href="https://www.dnswl.org/">https://www.dnswl.org/</a> or Spamhaus's SWL.</li>
<li>Periodically check if you appear in any DNS-based deny-lists.</li>
<li>Make sure you're not sending from “ISP residential address-space”; if
need be route your mail outbound via a host in better address-space
(and update SPF etc to match)</li>
<li>Don't do sender call-out verification to SMTP servers which aren't
yours.</li>
<li>For your own sanity, do make sure you set up <a href="https://www.fail2ban.org/">fail2ban</a>, or something
like it, scanning your mail-server logs, because SMTP AUTH online
cracking is widespread.  If they ever get in, your deliverability
will be negatively impacted by their spam campaign through your
mail-server.</li>
</ol>
<h3 id="convenience-stuff">Convenience Stuff</h3>
<p>Outside of “Phil's BCP” above, additional non-deliverability but
convenience options include:</p>
<ol>
<li>DNS SRV records for submission(s)/imap(s)/pop3(s)/sieve, even if just
to say with «<code>0 0 0 .</code>» that it's not supported.</li>
<li>If your communications base includes people using OpenPGP with email,
then set up WKD to publish OpenPGP keys for your domain too.
<ul>
<li>This is just a fixed schema for laying out keys for HTTPS retrieval.</li>
<li>See the <a href="https://datatracker.ietf.org/doc/draft-koch-openpgp-webkey-service/?include_text=1" title="OpenPGP Web Key Directory">WKD draft</a> for details.</li>
<li>I wrote <a href="https://github.com/PennockTech/openpgpkey-control">https://github.com/PennockTech/openpgpkey-control</a> as a
management framework for an organization; the
<code>other/standalone-update-website</code> script is designed to be
embeddable into an existing site-building workflow without anything
else from the repository.</li>
<li>The GnuPG project has tooling available which manages the WKD layout as
an email-integrated workflow, for people to update their own keys.</li>
</ul>
</li>
<li>If your communications base includes people using S/MIME then set up
SMIMEA records in your DNSSEC-signed DNS.
<ul>
<li>They look a lot like TLSA records; both are trust anchors in DNS.</li>
<li>See <a href="https://tools.ietf.org/html/rfc8162" title="Using Secure DNS to Associate Certificates with Domain Names for S/MIME">RFC 8162</a> for details.</li>
</ul>
</li>
<li>The moment you start specifying “must be TLS-secured” it's worth
adding <code>CAA</code> records into DNS, so that Certificate Authorities which
are broadly trusted will refuse to issue for your domain unless you
list them.
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc8659" title="DNS Certification Authority Authorization (CAA) Resource Record">RFC 8659</a> for details</li>
<li>The values checked by each Certificate Authority as indicating they
have permission are required to be listed in their Certification
Practice Statement, as part of the CA/Browser forum's Baseline
Requirements.  If it's missing, then browsers are not supposed to
be trusting that CA.</li>
<li>For domain-validation CAs such as Let's Encrypt, consider adding
account information to those records to tie it to your specific
account.  See <a href="https://tools.ietf.org/html/rfc8657" title="Certification Authority Authorization (CAA) Record Extensions for Account URI and Automatic Certificate Management Environment (ACME) Method Binding">RFC 8657</a> for details.</li>
<li>Beware that at time of writing, Let's Encrypt only honors the
<code>accounturi</code> restriction in their staging environment, not their
production setup; this will likely change.</li>
<li>Remember that DNS zonefiles support comments.  You'll want them</li></ul></li></ol></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</a></em></p>]]>
            </description>
            <link>https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23958599</guid>
            <pubDate>Sun, 26 Jul 2020 17:31:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signing .jars is not worth the effort]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 74 (<a href="https://news.ycombinator.com/item?id=23957663">thread link</a>) | @nurettin
<br/>
July 26, 2020 | https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html | <a href="https://web.archive.org/web/*/https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <figure>
<picture>


<source srcset="https://quanttype.net/images/path.jpg.webp" type="image/webp">

<img src="https://quanttype.net/images/path.jpg" alt="Duckboards make a serpentine curve over a marsh.">

</picture>
</figure>

<p>If you try to deploy a new release of Clojure library with
<a href="https://leiningen.org/">Leiningen</a>, it prompts you to sign the .jar file with GPG. This step
often causes confusion and breaks. I believe that it’s not worth the effort to
make it work.</p>
<p>As far as I know, <em>nobody ever verifies the signatures</em> in a systematic way.
There are a bunch of obstacles:</p>
<ul>
<li>It’s unclear if any tools for verifying the signatures actually work. For
example, I just tried to run <code>lein deps :verify</code> against a couple of projects
and it reported every dependency as <code>:unsigned</code>. I know that some of those
dependencies are signed and I verified that the <code>.asc</code> files exist on
repo.clojars.org.</li>
<li>It’s hard to find the public keys for the library maintainers. Sometimes they
upload them on the keyservers, sometimes not.</li>
<li>There’s no established way of communicating that which public keys should be
trusted. If there’s a new release and it has been made with a new key, your
best bet is to e-mail the maintainer and ask what is up.</li>
</ul>
<p>It’s hard to get any security benefits from the signatures in practice. Thus
it’s okay to set <a href="https://github.com/technomancy/leiningen/blob/998d373ae06d17234efffde761fae93242c736fa/sample.project.clj#L111"><code>:sign-releases</code></a> to <code>false</code> in your
project.clj even if Leiningen’s manual does not recommend it.</p>
<hr>
<p>In princple, the systematic checking of signatures could provide security
against a dangerous supply-chain attack: weak or leaked passwords for package
manager accounts. For example, <a href="https://arstechnica.com/information-technology/2019/08/the-year-long-rash-of-supply-chain-attacks-against-open-source-is-getting-worse/">several RubyGems</a> have been attacked
this way. Most likely the signing keys would not be compromised at the same
time.</p>
<p>There are alternative solutions, though, such as disallowing publishing packages
without multi-factor authentication. Using Clojars’s <a href="https://groups.google.com/forum/#!topic/clojure/GmAU4XwnRpw">deploy tokens</a>
helps a bit as well.</p>
<p>Right now we place a lot of trust on Clojars and Maven Central. If either of
them got compromised, we all would be screwed. Package signing could be a part
of a solution to mitigate that risk, but a comprehensive solution would be
something like using <a href="https://theupdateframework.io/">The Update Framework</a>. Go’s <a href="https://blog.golang.org/module-mirror-launch">checksum
database</a> is also worth taking look at.</p>
<p>Finally, if you’re moved to do something about this, please do not build
anything new using PGP. To quote Latacora: <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">PGP is bad and needs to go
away</a>.</p>
<hr>
<p>I’ve written this post in part to be proven wrong. I’m eagerly waiting for posts
from y’all about how you do, in fact, systematically verify the signatures.</p>

    </article></div>]]>
            </description>
            <link>https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957663</guid>
            <pubDate>Sun, 26 Jul 2020 15:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorize Your CLI]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23957325">thread link</a>) | @danyspin97
<br/>
July 26, 2020 | https://danyspin97.org/blog/colorize-your-cli/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/colorize-your-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danyspin97.org/blog/colorize-your-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957325</guid>
            <pubDate>Sun, 26 Jul 2020 14:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote work is not necessarily a good thing for the worker]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 233 (<a href="https://news.ycombinator.com/item?id=23957278">thread link</a>) | @rbanffy
<br/>
July 26, 2020 | https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/ | <a href="https://web.archive.org/web/*/https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.seanblanda.com/content/images/size/w300/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 300w,
                            https://www.seanblanda.com/content/images/size/w600/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 600w,
                            https://www.seanblanda.com/content/images/size/w1000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 1000w,
                            https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg" alt="Our remote work future is going to suck">
            </figure>

            <section>
                <div>
                    <p>As COVID-19 continues to alter the way we live, there is a scramble to predict what our “new normal” will look like. After the virus fades away or, God help us, becomes a constant in our day-to-day life for years to come, which change brought on by the pandemic will stick? </p><p>There is one consensus prediction that is emerging, especially among knowledge workers and those in tech: The distributed workforce is here to stay. And, furthermore, this change is a good thing for workers and welcomed by all.</p><p>To which I say: Um, have you ever worked remotely?</p><p>I have understood and enjoyed the perks of working remotely before. From 2009 to 2016 I wrote about entrepreneurs and creatives, many of whom were early proponents of remote work. And from 2017 to 2019, I worked remotely for a small, privately-owned e-learning company and then a 1000-employee SaaS company. </p><p>While the upsides to remote work are true, for many people remote work is a poison pill — one where you are given “control” in the name of productivity in exchange for some pretty nasty long-term effects.</p><p><strong>In reality, remote work makes you vulnerable to outsourcing, reduces your job to a metric, creates frustrating change-averse bureaucracies, and stifles your career growth.</strong> The lack of scrutiny our remote future faces is going to result in frustrated workers and ineffective companies.</p><p>Let’s tackle these issues one at a time. </p><h2 id="remote-work-democratizes-talent-for-everyone-even-you-">Remote work “democratizes talent” for everyone. Even you.</h2><p>In May 2020, <a href="https://blogs.gartner.com/manjunath-bhat/2020/05/03/remote-work-is-the-next-big-equalizer/" rel="noreferrer nofollow noopener">a Gartner blog post</a> summarized a common argument in favor of remote work: “Democratizing access to resources lowers the barriers to innovation and enables everybody to partake in the ensuing prosperity.” Not everyone can (or wants to) live in an urban commercial hub. Remote work, the thinking goes, allows people to live in whatever environment they’d like — depending on their own circumstances.</p><p>These remote technology jobs don’t just go to a version of you living on a cute farm in the Hudson Valley. Those jobs go to <em>anyone, anywhere.</em> </p><p>This is good for global prosperity and perhaps arguably inevitable. However, if you’re working in technology today as an American, you have tremendous earning potential. This earning potential may not be possible forever. It’s baffling to me that American workers would cheer an acceleration of this trend that would place downward pressure on their wages.</p><p>When you, the American worker, share this belief you are being blinded by an erroneous belief in American exceptionalism. When your company goes all-remote, it is starting a clock that ends in you eventually competing with the global talent market — especially if travel and visas continue to be restricted by the federal government.</p><p>A tech optimist will likely (and correctly) point out that more innovation and new technologies will replace any outsourced jobs. While my academic brain wants that to be true, I can’t help but see the devastating effects globalization had to our manufacturing workers and communities — many of which have never recovered or benefited from new innovations.</p><p>Innovation in the American economy didn’t get transferred one-to-one. Every manufacturing worker did not suddenly receive a tech job. Every technology worker outsourced will not receive the benefit of the next wave of innovation directly. </p><h2 id="remote-enables-you-to-be-forgotten">Remote enables you to be forgotten</h2><p>Remote work advocates often praise the focus that remote work enables. No longer will you be judged by the time you spend at the office, they say, you’ll instead be judged and rewarded on whether you “get things done.” </p><p>These “benefits” are always used to sell remote work to an imagined audience of Dilbert-like cubicle dwellers who are imprisoned and subjected by annoying coworkers and an oppressive boss. The key to freedom, they say, is to work remotely. Basecamp co-founder Jason Fried <a href="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html" rel="noreferrer nofollow noopener">writes in <em>Remote</em></a>:</p><!--kg-card-begin: html--><blockquote darkmode="" data-title="Working%20From%20Home%20Boosts%20The%20Quality%20Of%20The%20Work" data-author="Jason Fried&nbsp;" cite="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html">
                      <p>What you're left with is "what did this person actually do today?" Not "when did they get in?" or "how late did they stay?" Instead it's all about the work produced. So instead of asking a remote worker "what did you do today?" you can now just say, "Show me what you did today." As a manager, you can directly evaluate the work--the thing you're paying this person for--and ignore all the stuff that doesn't actually matter.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>First, being more productive isn’t the only goal of working, but let’s put that to the side. Second, Fried is right, you do gain a bit of freedom from your boss (which doubles as a loss of a mentor, but we’ll get to that). You also gain “freedom” from your colleagues and collaborators. Which means you’re effectively on your own. </p><p>This is empowering to some, but the isolation can mean your contributions are easily overlooked or misunderstood. As a result, I’ve noticed a disturbing trend at (especially larger) remote companies: Some managers often have no clue what their direct reports are doing and how they are doing it. </p><p>Performance reviews are difficult enough under normal circumstances. But how do you judge someone when you can only see their output and never their process? Marketers, project managers, product managers, growth marketers, and others spend their days supporting or maintaining existing things. &nbsp;</p><p>This a difficult problem that predates any shift to remote work. But when applied to remote work, a manager loses several of the inputs needed to judge a direct report’s output — including, yes, who is physically (and mentally) present when actual work is being done. But also: Do the other team members appear to enjoy working with this person? And, if they are struggling, is it due to a lack of effort/focus or something outside of their control? </p><p>Employees who “do the right thing” spending extra time and energy supporting their teammates receive absolutely no recognition for doing the little things needed for a smooth-running, collaborative organization. It’s usually a quantifiable fact whether a sales departments reaches their goals. It’s not as clear that the social media manager had a good quarter.</p><p>With the removed context of a real-life office, your team’s output is difficult to individualize for your manager — especially if work is done in private DMs or one-on-one Zoom calls. The manager sees the end product with no visibility as to who did what, who pulled their weight, who made tough choices, and who made things more difficult. This has a nasty side effect of the leader viewing you less as a person who they have to empathize with and understand — and more as a talking head on a Zoom call or Slack who does things for them. </p><p>This will cause your work to “flatten.” Whatever soft skills you bring to the table will be minimized when working remotely. This will lead to companies and processes relying less on things like creativity and collaboration and more on simple inputs and outputs. Which, again, makes your work easier to outsource.</p><p>We bemoan the loss of empathy and context created by solely getting our news and interacting via social media … and we then turn around and set up our working lives in their image.</p><p>This has a pronounced effect in large organizations.</p><h2 id="remote-work-breaks-large-companies">Remote work breaks large companies</h2><p>Remote work supporters often return to the “interruption culture” at an IRL office as an argument for distributed work. First, clearly people that believe remote work creates an interruption-free zone have never used Slack or email. Second, those interruptions often exist for a reason: They often communicate information that ensures everyone is working on the right thing.</p><p>For companies that have strong product/market fit, have reached scale, and have a clear product roadmap, remote works swimmingly. A distraction-free environment means everyone can focus on “what matters” because “what matters” has been clear and consistent. &nbsp;</p><p>But what happens when “what matters” changes? </p><p>Because it will. Eventually, the market shifts. There’s a competitor or a Black Swan-style event in the industry (like, say, a global pandemic). Suddenly the well-oiled machine needs to adapt and change course. For companies larger than 100 people, this is tremendously difficult in an in-person environment. Working remote, it’s damn near impossible. Twice-a-year in-person meetups are not enough to disseminate brand new strategies. </p><p>And I'd bet that as formerly IRL companies go remote, it will have a negative effect on their ability to iterate and adjust to market conditions making them vulnerable for a smaller, co-located upstart.</p><h2 id="remote-work-can-stifle-your-career-growth">Remote work can stifle your career growth</h2><p>Think back to your first job in your current field. I’d bet there is a person or group of people who were tremendously important in shaping your career. They gave you candid advice and were able to passively observe and critique your behavior.</p><p>When you work remotely, mentorship is stifled because there is no learning via osmosis. You can’t model your behavior on your successful teammates because you only see them on Zoom and in Slack. Whatever process they are using to achieve their results is opaque to you. </p><p>Much of the language used around remote work (and remote events) assumes that one is in the mid-to-late stages of their career. When you’re young, you don’t need “focus” or to “get things done.” You need exposure to new ideas and people. You need the serendipitous fortune of sitting in on the right meeting, attending the right happy hour, or earning the respect of the right observer.</p><p>All of the above is more difficult in a remote environment. As a result, we are in danger of having a generation of new knowledge workers who are never properly onboarded and hastily told to work remotely with nothing but an OKR to chase. They have no context for how to do all of the messy office-ready skills like building consensus, having productive disagreements, and advocating for their ideas.</p><p>Additional…</p></div></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</a></em></p>]]>
            </description>
            <link>https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957278</guid>
            <pubDate>Sun, 26 Jul 2020 14:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Gene Cernan's Missing Moon Camera]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23956771">thread link</a>) | @uptown
<br/>
July 26, 2020 | https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera | <a href="https://web.archive.org/web/*/https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5e5ee63acb9e965b95a34c71" data-item-id="5e5ee63acb9e965b95a34c71">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1583277661007" id="item-5e5ee63acb9e965b95a34c71"><div><div><div data-aspect-ratio="100.80906148867315" data-block-type="5" id="block-yui_3_17_2_1_1583276156349_38578"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image-dimensions="1920x1981" data-image-focal-point="0.5,0.5" alt="Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17." data-load="false" data-image-id="5e5ff5accacd55785de67f35" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594000429895_118575"><div><h2>The mystery of its location</h2><p>It’s often repeated how most of the cameras that landed on the moon stayed on the moon. Astronaut Gene Cernan had been telling the story of how<a href="https://petapixel.com/2012/12/06/the-last-man-to-walk-on-the-moon-left-his-camera-for-a-long-term-gear-test/" target="_blank"> he left his camera</a> on the lunar rover<a href="https://www.telegraph.co.uk/news/science/space/9728289/Apollo-17-commander-left-camera-on-moon-40-years-ago.html" target="_blank"> for years</a>, recounting the tale in interviews:</p><blockquote><p>"I left my Hasselblad camera there with the lens pointing up at the zenith, the idea being someday someone would come back and find out how much deterioration solar cosmic radiation had on the glass. So, going up the ladder, I never took a photo of my last footstep. How dumb! Wouldn’t it have been better to take the camera with me, get the shot, take the film pack off and then (for weight restrictions) throw the camera away?"</p></blockquote><p>It’s easy to accept Cernan at his word - he’s an American hero who flew to space three times, twice to the moon - so as far as everyone was concerned, including the press, the camera was right where he said he left it. Plus, a quick scan of the Apollo 17 stowage list reveals no mention of a lunar surface camera splashing down with the command module. So why the mystery? </p><p>Looking closer, there’s a sprinkling of evidence in photos and transcripts that suggest his camera did in fact return to earth, contradicting both the 1972 NASA inventory and the astronaut. No, don’t cue the dramatic music… there’s no mischief or intentional deception here. I believe Gene Cernan did leave a camera on the lunar rover, just not “his.”&nbsp;Memory can be a fickle thing, even for heroes, and that rings especially true in this case&nbsp;when the story involves not one camera, but three.</p><h2>A tale of three cameras</h2><p>When you’re going to the moon, you’re assigned a camera with a 60mm lens that gets strapped to your chest to document samples, experiments, and the lunar terrain. Both astronauts get their own, clearly labeled with a sticker on the side: “CDR” for commander and “LMP” for lunar module pilot, but they weren’t mutually exclusive, often being swapped throughout the mission based on what film they were shooting with. On Apollo 17, Jack Schmitt - LMP and geologist extraordinaire - was set up with the black &amp; white film. When he needed color, he’d grab Cernan’s camera and vice versa. </p><p>A third Hasselblad camera was also to be used on the mission; it was a bit of a beast really, boasting a 500mm telephoto lens meant to capture distant lunar features for, you know… science. Of the two astronauts, Cernan got stuck looking down the barrel of the 500mm the most, so it’s entirely possible that <em>this</em> is the camera he remembers leaving on the rover. In fact, the post-flight analysis of the transcript pretty much confirms it. But what happened with the other two?</p><h2>The stowage list says they stayed </h2><p>A little background. As each Apollo mission launched, NASA prepared a final stowage list that documented all the equipment aboard, detailing what was to be transferred between each spacecraft before and after landing on the moon. This list was then revised in real time as plans changed due to time or weight restrictions. In the latest revision of the <a href="https://www.hq.nasa.gov/alsj/a17/a17stowage.pdf" target="_blank">Apollo 17 LM Lunar Launch Stowage List</a>, dated December 12th, 1972, the three cameras that went down in the LM are all marked as “offloaded,” meaning they were left on the surface. The problem is, they launched from the moon on December 13th! So if extra items were brought onboard, it’s not recorded. At least not in what’s available online.</p></div></div><div><div><div data-aspect-ratio="55.70987654320988" data-block-type="5" id="block-yui_3_17_2_1_1594649779919_85920"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Two Hasselblad Data Cameras with 60mm lenses marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1594000429895_28896"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>One Lunar Surface Camera with 500 lens marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594649779919_62191"><div><h2>The <a href="https://www.hq.nasa.gov/alsj/a17/a17.clsout3.html#1702716" target="_blank">audio</a> says otherwise</h2><p>The next logical step was to check the transcripts to see if it was possible to follow the cameras by listening to what was happening. As you read the following excerpt, Cernan and Schmitt are both standing by the final resting place of the lunar rover at the end of their last EVA.</p><blockquote><p>169:29:44<strong>&nbsp;Parker [Mission Control]:</strong> ...and, Jack, <strong>we're making plans here, to change the camera usage at the end of EVA here.</strong> And we're going to let you take Commander's camera out to the ALSEP and take a few photos which people think we need. And Gene's going to take your camera out and document the geophone, when he deploys it. We will not deploy it for the long-term experiment, however. <strong>And we'll bring both (cameras) back, and carry them to the ETB when we get done.</strong></p><p>169:30:17&nbsp;<strong>Cernan:</strong> Okay.</p><p><em>[When he said "document the geophone", Bob may have been referring to documentary photos of the seismic charge Gene will deploy near the VIP site. "When he deploys it" probably refers to the charge and the phrase "we will not deploy it for the long-term experiment" refers to a planned deployment of the camera on the Rover seat as indicated on checklist page&nbsp;</em><a href="https://www.hq.nasa.gov/alsj/a17/a17eva3_cdr30.gif" title="image" target="new"><em>CDR-3</em></a><em>2. </em><strong><em>Specifically, the checklist calls out "Pos(ition) LMP cam(era) vert(ically) on seat."</em></strong><em> Gene remembers that he did put the camera on the seat, with the lens pointed at the zenith. Presumably, the intent was to recover the camera at some future date to get information of long-term exposure to the lunar environment.]</em></p><p>[Cernan - "Parker said 'We'll bring them both (that is, both cameras) back,' but I know what I did with that camera. I left it on the Rover pointed straight up. <strong>That's what I planned to do and that's what I did. </strong>I can remember specifically wedging it - I don't remember exactly where - somewhere up between our seats."]</p></blockquote><p><em>&gt;&gt;&gt;&gt; Fast forward to where the astronauts are now back at the LM &gt;&gt;&gt;&gt;</em></p><blockquote><p>170:39:59&nbsp;<strong>Parker [Mission Control]: </strong>Okay, and we gather an ETB coming up with two cameras in it.</p><p>170:40:04&nbsp;<strong>Schmitt:</strong> ETB's next. (Pause) (To Gene) Got an ETB? Yeah. (Pause) ETB has two cameras.</p></blockquote></div></div><div data-aspect-ratio="94.44444444444444" data-block-type="5" id="block-yui_3_17_2_1_1594747724966_190880"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image-dimensions="378x380" data-image-focal-point="0.5,0.5" alt="CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera" data-load="false" data-image-id="5f0f1cf80254b81fb47dba1f" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594747724966_196522"><div><p>Ok, let’s unpack this:</p><ol data-rte-list="default"><li><p>NASA deviates from the flight plant requesting the astronauts swap cameras:<strong> Schmitt is to return to the LM with Cernan’s CDR camera</strong>, and Cernan is to use Schmitt’s LMP camera at the rover.</p></li><li><p>When they’re done, both CDR and LMP cameras<strong> are to be brought back into the LM</strong> using the equipment transfer bag (ETB). </p></li><li><p>On Gene’s cuff checklist was an item to “Position the LMP camera facing up on the seat of the rover,” leaving it behind, but because NASA had just asked for that camera to be returned, Gene, following the checklist, positions the 500mm in its place, returning to the lunar module with the LMP in hand.</p></li><li><p>Two cameras, the CDR and LMP, are then confirmed in the ETB going up to the LM.</p></li></ol><p><em>&gt;&gt;&gt;&gt; Fast forward again to the astronauts inside the LM after a rest period &gt;&gt;&gt;&gt;</em></p><blockquote><p>183:40:17&nbsp;<strong>Fullerton [Mission Control]:</strong> Challenger, Houston. One update for the post-sleep procedure. I understand you brought in the LMP's camera, and we want to be sure you get that into the&nbsp;<a href="https://www.hq.nasa.gov/alsj/alsj-JettBag.html" target="new">jett bag</a>&nbsp;before the final jettison here. And, by the way, you're Stay for that final jettison.</p><p>183:40:39&nbsp;<strong>Schmitt: </strong>Okay, Gordy. It's already in the jett bag, thank you. (Pause)</p><p><em>[</em><strong><em>Cernan </em></strong><em>- "Obviously, I did not leave the LMP's camera on the Rover pointed at the zenith. But I swear I put something there. It's possible it could have been the 500 lens, because we didn't bring it back and I mentioned it was under the seat. I know that I did something with a camera. Now, it could have been a lens. And I stuck it between the seats, sort of wedged it in somewhere, and pointed the lens toward the zenith."]</em></p><p>[<strong>Schmitt </strong>- "Houston wanted us to jettison the camera because they didn't want us to take pictures of Ron Evans' EVA. They had decided it was too cumbersome and too risky. But, we were going to ignore them, and we figured out how we could do it. But we needed a camera. Ron had a camera, but it was not EVA-qualified."]</p><p>[<strong>Cernan</strong> - "We had made up our minds we were going to take pictures of Ron."]</p><p>[<strong>Schmitt </strong>- "And we needed a lunar-surface camera to do it."]</p><p><strong>[Cernan - "Now, we did put the LMP's camera in the jett bag, so we must have had mine."]</strong></p></blockquote><p>*Click*. Finally, we have some clarity. One 500mm camera stays behind, and of the two that go up into the LM, the LMP camera gets jettisoned back to the surface before launch. Cernan’s camera leaves with them as they blasted off live on TV and in color.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1594997167739_70248"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image-dimensions="1721x1721" data-image-focal-point="0.5,0.5" alt="At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover." data-load="false" data-image-id="5f11ba2ee9f8df4e02356918" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594997167739_107441"><div><h2>The photos confirm it</h2><p>Every lunar camera has a unique serial number, usually etched into a piece of glass that’s pressed against the film plane. It’s known as the Réseau plate, used to help scientists both accurately measure objects in view, and identify what camera took what image.&nbsp;By simply <a href="https://tothemoon.ser.asu.edu/gallery/Apollo/17/Hasselblad%20500EL%20Data%20Camera%2070%20mm" target="_blank">looking through the …</a></p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</a></em></p>]]>
            </description>
            <link>https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956771</guid>
            <pubDate>Sun, 26 Jul 2020 13:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why should we all wear face masks?]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23956748">thread link</a>) | @askaboutio
<br/>
July 26, 2020 | https://askabout.io/covid-19/ask/why-should-most-people-wear-masks/ | <a href="https://web.archive.org/web/*/https://askabout.io/covid-19/ask/why-should-most-people-wear-masks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Two hair stylists that were COVID-19 carriers, wore face masks while working with their 139 clients, who also wore face coverings, and subsequently avoided virus transmission.<br>
</p>
<figure><img src="https://www.cdc.gov/mmwr/volumes/69/wr/social-media/mm6928e2_HairSalonCOVID19_IMAGE_14July20_1200x627.jpg" height="auto" width="auto" alt="COVID-19 Carrier Hairstylists wore facemasks along with their 139 clients and avoided transmission."></figure>
<p><br>
Among 139 clients exposed to two symptomatic hair stylists with confirmed COVID-19 while both the stylists and the clients wore face masks, no symptomatic secondary cases were reported; among 67 clients tested for SARS-CoV-2, all test results were negative.</p>
<p>Adherence to the community’s and company’s face-covering policy likely mitigated spread of SARS-CoV-2.</p></div></div>]]>
            </description>
            <link>https://askabout.io/covid-19/ask/why-should-most-people-wear-masks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956748</guid>
            <pubDate>Sun, 26 Jul 2020 12:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Surprise AWS Bill]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 287 (<a href="https://news.ycombinator.com/item?id=23956671">thread link</a>) | @oaf357
<br/>
July 26, 2020 | https://chrisshort.net/the-aws-bill-heard-around-the-world/ | <a href="https://web.archive.org/web/*/https://chrisshort.net/the-aws-bill-heard-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><h2 id="scene">Scene</h2><p>It was a bright, Saturday morning, July 4, 2020. I had just gotten Max all situated with breakfast and cartoons (Mighty Mike, if you’re curious). Julie was sleeping in like she usually does on every day I have off. I’m an early riser and this is a cherished part of our co-parenting. It gives Max and I time to bond (when he’s not stuffing his face and laughing at cartoons). I sat down with my laptop to plow through the week’s personal email.</p><h3 id="the-e-mail">The e-mail</h3><p>“Oh look, the AWS bill, I should have a laugh at that,” I thought to myself. Until recently, it had been pennies a month for some very light SES usage. In February, I moved off Google Cloud back to AWS. The primary motivation was that Google had so intertwined GSuite and GCP IAM that it became overly confusing.</p><p>Along with that migration came the CDN for this web site (cdn.chrisshort.net). I mean <a href="https://chrisshort.net/low-cost-content-delivery-network-cdn/">a Cloudflare fronted S3 bucket that holds assets deemed too big for git</a> when I say CDN. It’s not even <a href="https://chrisshort.net/">chrisshort.net</a> itself, as it is hosted on Netlify’s CDN and every other static site I own or manage. I’ve been a Cloudflare user for a long time. The CDN is less than 300 files and has existed for over five years on various clouds. Moving it back to AWS from GCP bumped the AWS bill to an average of $23/month. Not too bad given the <a href="https://app.usefathom.com/share/suwvjwwc/chrisshort.net">site’s traffic</a>.</p><h3 id="the-shock">The shock</h3><p>Not on this Saturday morning, nope. June 2020’s AWS bill was a heart palpitation causing <strong>$2,657.68</strong> (<a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/invoice498711077_redacted.jpg">JPG</a>). I audibly gasped, “Keep your shit together.” I thought to myself. Max was leaned up against me drinking his milk. I know he could tell something was wrong because he looked at the laptop screen. I only assume when he saw letters and numbers, he thought, “Adult stuff… These cartoons and this Cinnamon Toast Crunch tho.” 2020 being the year that it is and my military history being what it is, I’ve been diagnosed with a panic disorder (on top of the PTSD and physical injuries).</p><h3 id="the-panic">The panic</h3><blockquote data-dnt="true"><div lang="en" dir="ltr"><p>Good morning, $2700 AWS bill!</p><p>Holy shit...</p></div>— Chris Short (@ChrisShort) <a href="https://twitter.com/ChrisShort/status/1279406322837082114?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><p>I immediately began having a panic attack. As I took the mental steps to mitigate the onset of the panic attack, I started forming a battle plan. Yes, I can switch back to emergency mode, like back in the old days, when something would go bang or boom, and I’d run towards it (it’s not helpful overall, trust me).</p><p>First, Max: Maslow’s Hierarchy of Needs? Check.<br>Next, me: As if it was destined, my alert for morning medications went off.</p><p>“Daddy’s gotta grab his meds, bud.” Instinctively, Max leans off me (wow… okay… he’s used to hearing that reminder and statement shortly after that; my brain is now in overdrive). I take everything I need to conquer this while still being able to function cognitively. I refill my coffee and grab a laptop charger.</p><h2 id="incident-response">Incident response</h2><p>Check the source of truth.</p><p>What’s diverged?</p><p>How do we get things back to normal?</p><p>I login to the AWS console, hoping I got some output that was uniquely off this month. Weirder stuff has happened (like <a href="https://aws.amazon.com/message/41926/">S3 going down</a>). This bill couldn’t be more out of the norm than ever. This AWS bill is several hundred dollars more than our mortgage! I hit the AWS Billing page and am deeply saddened by what I see:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/1f2dd17bc5d8e1407c22b84f7f981a7ad9888eba/8e235/the-aws-bill-heard-around-the-world/aws-bill-landing-page.png" alt="AWS Billing landing page showing a $2,657.68 balance"></p><p>There it was. <strong>$2,657.68</strong>, staring at me. “This can’t be legit.” Drilling down even further, it looks like it is indeed legitimate traffic from the cdn.chrisshort.net S3 bucket in us-east-2. In total, <strong>more than 30.6 terabytes of traffic</strong> had moved out of that one S3 bucket. WHEN?!? Did this just happen? Nope.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/3373f05e910b0938aeed4a2975b4b4f48922fdc0/2e223/the-aws-bill-heard-around-the-world/aws-june-2020-data-transfer.png" alt="AWS data transfer billing break down"></p><p><img src="https://d33wubrfki0l68.cloudfront.net/46294144a86a5d64df074d306386b3024b7d882a/af2d6/the-aws-bill-heard-around-the-world/june-23-24-2020-s3-breakdown.png" alt="S3 Activity"></p><p><strong>30.6 TB?!?!</strong> how is that even possible???<br>$1,011.59 on 23 June 2020.<br>$1,639.07 on 24 June 2020.</p><p>I immediately open a ticket with AWS Support frantically wondering what broke? How is this even possible? Did someone bypass Cloudflare? What the hell is Cloudflare saying?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/6cd3322753f262dc51bbca44a07fef6b19b381e9/52aec/the-aws-bill-heard-around-the-world/cloudflare_june_22_2020.png" alt="Cloudflare 22 June 2020"><br>Oh cool, Cloudflare let those 2,700 requests passthrough completely uncached? How is that not anomaly detected as a DDoS??? How is it that barely a fraction of the traffic is cached (more on that later)?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a0f7d1526c44cb74baba13f749f3d5a886bbdadb/6d2b1/the-aws-bill-heard-around-the-world/cloudflare_june_23_2020.png" alt="Cloudflare 23 June 2020"><br>Oh, another 4,400 requests the next day… Sweet, baby Jesus. Oh, but you served 9 GB from cache. Thanks, Cloudflare.</p><h2 id="help-arrives">Help Arrives</h2><p>Apparently, when you tweet something crazy af, like a $2700 AWS bill, it gets a lot of attention on a quiet holiday morning. A quarter-million people saw the tweet and a third of them interacted with it. It was enough attention that the AWS Support Twitter account was on it before, <a href="https://twitter.com/QuinnyPig/status/1186319925901586432">my friend</a> and <a href="https://www.duckbillgroup.com/">cloud economist</a>, Corey Quinn.</p><blockquote data-dnt="true"><p lang="en" dir="ltr">Oh no! 😰 Sorry to hear about this unpleasant Saturday morning surprise, Chris. Please create a support case so our agents can help get to the bottom of this: <a href="https://t.co/weTUnSYLRU">https://t.co/weTUnSYLRU</a>. 🕵️‍♀️ ^HG</p>— AWS Support (@AWSSupport) <a href="https://twitter.com/AWSSupport/status/1279424879566163970?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>Praise Twitter for at least its ability to draw attention to things. I am not sure this would’ve ended up as well as it did without it.<blockquote data-dnt="true"><p lang="und" dir="ltr"><a href="https://t.co/tUrNnXqWMY">pic.twitter.com/tUrNnXqWMY</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1279446759664611329?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>I forwarded the bill to Corey almost immediately after seeing it at pre-dawn west coast time. I am forever thankful to Corey for his analysis. When he was ready, Corey sent me a list of things he needed to do an analysis (instead, I created him a regular IAM account with the proper perms 😉 and yes I cleaned up after).<p>Corey encouraged me to apply a bucket policy that would only allow Cloudflare IP addresses to access anything from the bucket. The theory here is that someone could have been bypassing Cloudflare somehow. But, thankfully, <a href="https://www.cloudflare.com/ips/">Cloudflare publishes their IP blocks</a> and they don’t change all that often. The Cloudflare support article, <a href="https://support.cloudflare.com/hc/en-us/articles/360037983412-Configuring-an-Amazon-Web-Services-static-site-to-use-Cloudflare#77nNxWyQf69T1a78gPlCi9">Configuring an Amazon Web Services static site to use Cloudflare</a> gives you an example bucket policy to do exactly that. This should become a standard practice for folks. However, it wouldn’t have mattered in this case; more on that later.</p><p>Corey Quinn’s thread on the topic covers what happened on the AWS side pretty well:</p><blockquote data-dnt="true"><p lang="en" dir="ltr">That's right--it's threading time!<a href="https://twitter.com/ChrisShort?ref_src=twsrc%5Etfw">@chrisshort</a>'s surprise <a href="https://twitter.com/awscloud?ref_src=twsrc%5Etfw">@awscloud</a> bill of $2700 looks S3 driven... <a href="https://t.co/VnXufn24iA">https://t.co/VnXufn24iA</a> <a href="https://t.co/tKLWv5rHtW">pic.twitter.com/tKLWv5rHtW</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1280280727133642753?ref_src=twsrc%5Etfw">July 6, 2020</a></blockquote><ul><li>”…it’s almost entirely due to us-east-2 data transfer out…”</li><li>“Now, what caused this? Nobody knows!”</li><li>“Chris Short isn’t some random fool…” (Might be the nicest thing Corey’s every said about anyone he’s not related to)</li><li>”‘Surprise jackhole, your mortgage isn’t your most expensive bill this month, guess you shoulda enabled billing alarms!’ is crappy, broken, and WOULD NOT HAVE SOLVED THE PROBLEM!”</li><li><a href="https://twitter.com/QuinnyPig/status/1280289410844471296?s=20">“I want to be explicitly clear here: Chris Short didn’t do anything wrong!”</a></li></ul><h2 id="but-wait-there-s-more">But wait! There’s more!</h2><p>I had tickets in with Cloudflare (1918916) and AWS (7153956931). Cloudflare was the least helpful service I could have imagined given the circumstances. A long term user and on and off customer thinks they were attacked for two days and you don’t lift a finger? If I didn’t have reason enough to move off of Cloudflare, I do now. That’ll be an update for a later blog post. But, if you work for a CDN company and you’re relatively painless to get up and running, I’m interested in hearing from you.</p><p>After a very chaotic morning, I take Corey’s advice, disconnect, and enjoy the holiday weekend.</p><h2 id="more-help-arrives">More Help Arrives</h2><p>On July 8th, an astute AWS employee starts doing some digging around and reaches out to me. Because they see this as bafflingly as Corey and I do. How did so few requests generate so much traffic so quickly and then as soon as it appears, it’s gone again? It doesn’t seem like something intentionally malicious either because Cloudflare and AWS let it right on through.</p><h3 id="here-s-the-theory">Here’s the theory</h3><p>In hindsight, I made a poor decision to distribute a trial Windows 2019 SQL Server virtual machine images (fully patched with all necessary drivers and VM extensions) in the form of a qcow2 file. Someone became aware of the existence of this VM image. They then stood up hundreds, potentially thousands, of copies this VM using the internet accessible URL. This is, in theory, possible, with something like <a href="https://chrisshort.net/tags/kubernetes/">Kubernetes</a> and <a href="https://kubevirt.io/">Kubevirt</a>. Given that the disk image becomes a volume mount in the corresponding VMs pod. Spin up enough copies of the VM, a single YAML file can create infinite copies of a VM. If the YAML definition directly referenced the Cloudflare or S3 URL and not a locally cached copy, you can rack up the number of times you pull down an image real quick. The qcow2 image, in this case, was 13.7 GB. But it’s trickier than that.</p><h3 id="the-sharp-edge-of-the-cloud">The sharp edge of the cloud</h3><p>File this under, “Things I should’ve known but didn’t.” Did you know that “The maximum file size Cloudflare’s CDN caches <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files."><strong>is 512MB</strong></a> for Free, Pro, and Business customers and 5GB for Enterprise customers.” That’s right, Cloudflare saw requests for a 13.7 GB file and sent them straight to origin every time <em>BY DESIGN</em>. <strong>Ouch!</strong></p><p>I suspected these files immediately on July 4 and moved them to an internal work GDrive for the time being. If you need the images, let me know, you’re also a suspect if you ask for them, be warned.</p><p>If you’re sitting at home doing the math, something might not be adding up. The bandwidth cost is off, there was indeed some legitimate traffic to the bucket in June, of course, But, as it turns out the intrepid AWS employee discovered that 3655 partial GETs to the object might have actually been delivered as full file requests and Cloudflare might have ever done anything with them. Yes, this is a bug somewhere and folks are looking into it. I also suggested that object size limits be a tunable S3 bucket policy. This way, I wouldn’t have even been able to upload the files to the bucket, to begin with.</p><h2 id="the-resolution">The Resolution</h2><p>As I mentioned, I’ve removed the multiple gigabyte files from the bucket the day I got the bill (July 4). <a href="https://twitter.com/QuinnyPig/status/1280282363461726208">Corey pointed that out here</a>. That might have hindered the investigation from the AWS side. I won’t be so quick to delete in the future. I will lock files down though. But, let’s face it. Now that I’m aware of the <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files.">512 MB file limit at Cloudflare</a>, I am moving other larger files in that bucket to <a href="https://archive.org/">archive.org</a> for now (and will add them to my supported <a href="https://chrisshort.net/causes/">Causes</a>).</p><p>Long term, I won’t want to store files in …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/">https://chrisshort.net/the-aws-bill-heard-around-the-world/</a></em></p>]]>
            </description>
            <link>https://chrisshort.net/the-aws-bill-heard-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956671</guid>
            <pubDate>Sun, 26 Jul 2020 12:40:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who’s sharing my data, and who the hell is Dave M. Rogenmoser?]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23956388">thread link</a>) | @gingerlime
<br/>
July 26, 2020 | https://blog.gingerlime.com/2020/whos-sharing-my-data-and-who-the-hell-is-dave-m-rogenmoser/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/whos-sharing-my-data-and-who-the-hell-is-dave-m-rogenmoser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2603">
		<!-- .entry-header -->

	
	<div>
		
<p>I’m no longer active on Facebook, but at the moment, oddly, it’s my main goto option to find out at least some of the companies that share my data.</p>



<p>Facebook lets you see who shared your data with them. There are two interesting pages, buried and well-hidden, worth checking: <strong>Off Facebook activity</strong> and <strong>Businesses who uploaded and used a list</strong>.</p>



<p>Want to see which companies are sharing your data? continue reading.</p>



<h2><a href="https://www.facebook.com/off_facebook_activity/activity_list" target="_blank" rel="noreferrer noopener nofollow">Off Facebook activity</a></h2>



<p>This one is very interesting and I recommend visiting the link to check our your own list. I won’t share the screenshot, but from what I gathered, all this information was leaked via apps on my iPhone, before I’ve disabled ad tracking. I’ve written about it before: <a href="https://blog.gingerlime.com/2020/does-apple-care-about-your-privacy/">Does Apple care about your privacy?</a> and I recommend reading it, if only to know how to disable ad tracking on your Apple devices.</p>



<h2><a href="https://www.facebook.com/ads/preferences/?entry_product=information_about_you&amp;section_id=interacted#" target="_blank" rel="noreferrer noopener nofollow">Businesses who uploaded and used a list</a> </h2>



<div><figure><img src="https://blog.gingerlime.com/assets/dave_who-892x1024.png" alt="" srcset="https://blog.gingerlime.com/assets/dave_who-892x1024.png 892w, https://blog.gingerlime.com/assets/dave_who-261x300.png 261w, https://blog.gingerlime.com/assets/dave_who-768x882.png 768w, https://blog.gingerlime.com/assets/dave_who.png 1000w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"></figure></div>



<p>My list can be divided to roughly 3 categories:</p>



<ol><li>Companies I know and use. Amazon, Uber, etc. So whilst they know me and I did give them my details, I <strong>never explicitly gave them consent to share my details</strong>. With Facebook or with anyone… </li><li>Companies I’ve heard of, but never signed-up for, used nor shared any details with. <strong>How the f*** do they even have my details?</strong> not to mention share them with Facebook (or who knows what other companies)</li><li>Companies I’ve never heard of, but <strong>the name alone looks really dodgy</strong>. “Mindshare Biddable Digital” … you can imagine what a company with this name is doing. </li><li>Dave M. Rogenmoser. He probably deserves his own category. I don’t know him, never heard about him, and frankly now want nothing whatsoever to do with him. Dave, if you’re reading this, WTF are you doing sharing people’s personal details with Facebook? especially people who you don’t know and definitely didn’t give you consent to share details of.</li></ol>



<p>Ok, so this was 4 categories I guess… Although Dave might more realistically fall into the 3rd one.</p>



<h2>What does it mean?</h2>



<p>In case you can’t read the text on the image, this is what Facebook tells us about it</p>



<blockquote><p>These businesses uploaded a list to Facebook. Lists can contain contact information, for example an email address or phone number that is <a href="https://www.facebook.com/ads/preferences/?entry_product=information_about_you&amp;section_id=interacted#" target="_blank" rel="noreferrer noopener nofollow">hashed</a> so that Facebook does not learn any new identifying information about you. Lists can also contain advertising identifiers instead of contact information. Information from lists is matched against our existing list of users. The identity of users is not revealed to the business during the matching process.</p><p>Facebook uses these lists only to match the information to your profile and to deliver the ads chosen by the advertiser. Facebook does not keep the information shared in these lists. Advertisers can use lists to show you more relevant ads or to exclude you from ads that may be less relevant to you. For example, if you’re already a member of a gym then the gym could choose to exclude you from ads about becoming a member.</p><p>Facebook doesn’t learn any new identifying information about users when lists are uploaded. <a href="https://www.facebook.com/ads/preferences/?entry_product=information_about_you&amp;section_id=interacted#" target="_blank" rel="noreferrer noopener nofollow">Learn More</a></p></blockquote>



<p>So, let’s decipher things a bit here, shall we?</p>



<h2>Hash data</h2>



<p>Technically, it’s true that Dave and his friends don’t share my personal details directly. i.e. they won’t upload my actual email address to Facebook. They will upload a <em>hash</em> of my email. But then, Facebook obviously holds its own giant list of hashed emails and other personal details, so then when two hashes match, Facebook knows that it’s me. That’s the way they can show me this list of companies.</p>



<p>So is this data sharing? I think every reasonable person would think so. Obviously now Facebook knows more about me. At the very least my (forced) association with those companies. Their claim that “Facebook doesn’t learn <em>any new identifying information</em>…” is technically true, but practically false, because this association is super valuable. Not only for allowing advertising to place ads, but I imagine to increase the richness of the user profile and what Facebook knows about you.</p>



<h2>Lookalike audiences</h2>



<p>I’m not 100% sure about this, but I think that’s another thing to worry about: <a href="https://www.facebook.com/business/help/164749007013531?id=401668390442328" target="_blank" rel="noreferrer noopener nofollow">Lookalike audiences</a>. When companies upload lists of emails to Facebook, they not only do it in order to target those users directly, but rather to also discover <em>similar</em> people. People who are likely to be interested in their ads.</p>



<p>So whilst Facebook doesn’t reveal any extra information about me directly with advertisers who upload my details, these companies get a huge “prize” for sharing my data with them: These companies are then able to <strong>target ads to people with similar interests to mine</strong>.</p>



<p>Add the fact that now Facebook knows more about us, because they not only see how we interact on Facebook or sites that use the Facebook like buttons etc, this practice feeds even more knowledge (and golden opportunity) to Facebook. So if they know X people who (like me) use Amazon, Uber, and Share Now, perhaps they are also likely to be interested in using Grab? So both Facebook and those companies have a <strong>clear interest sharing my data. But are they allowed to?</strong></p>



<h2>Legitimate business and consent</h2>



<p>Let’s leave Facebook out of it for a moment… Are these companies allowed to share information about me with <em>any other company</em> (Facebook or otherwise), without my explicit and informed consent?</p>



<p>I’m not a lawyer, but here’s <a href="https://gdpr.eu/recital-40-lawfulness-of-data-processing/" target="_blank" rel="noreferrer noopener nofollow">recital 40 of the GPDR</a>:</p>



<blockquote><p>In order for processing to be lawful, personal data should be processed on the basis of the consent of the data subject concerned or some other legitimate basis, laid down by law, either in this Regulation or in other Union or Member State law as referred to in this Regulation, including the necessity for compliance with the legal obligation to which the controller is subject or the necessity for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract.</p></blockquote>



<p>The way I understand it, personal data should be processed either based on “some other legitimate basis”, or on the basis consent.</p>



<p><strong>Legitimate basis</strong>, in very simple terms, is when the data is necessary to provide the service. For example, if I sign up to Amazon, they need my email to send me order confirmations. That’s a legitimate basis. But using my email for marketing or advertising stops becoming a legitimate basis. Why? because it is not <em>required</em> to provide the service that Amazon provides me.</p>



<p>So if Amazon wants to send me ads, or share my email for other purposes that aren’t realistically legitimate, they are <strong>required to ask for my informed and explicit consent</strong>.</p>



<h2>“But hey! They didn’t share your personal data! They only shared a hash…”</h2>



<p>Technically they “only shared a hash”, but this hash identifies me clearly. I believe it falls under personal data under the GDPR as well.</p>



<p><a href="https://gdpr.eu/eu-gdpr-personal-data/" target="_blank" rel="noreferrer noopener">According to the GDPR, Personal information</a> is (emphasis mine):</p>



<blockquote><p>… any information relating to an identified or identifiable natural person (‘data subject’); an identifiable natural person is one who <strong>can be identified, directly or indirectly, in particular by reference to an identifier such as</strong> a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.</p></blockquote>



<h2>It gets even stranger</h2>



<p>If I dig a bit deeper into my list of companies, I saw that one of them actually shared my details with Facebook in order <em>not</em> to show me ads. This is actually one of the examples that Facebook gives when they explained about the Gym.</p>



<p>It’s definitely good for the Gym (they will not waste money on advertising someone who is already their member)</p>



<p>It’s definitely good for Facebook (they will sell more targeted ads, increasing the value of their platform to advertisers)</p>



<p>Is it good for me? some might say yes, because I won’t see the Gym ads any more. But at what price? I will still see other ads. And now Facebook knows that I’m a Gym member. I’m sure lots of advertisers would jump on the opportunity to sell me some Gym gear. I think I’m much worse-off here.</p>



<h2>What can we do about it?</h2>



<p>If you have a Facebook account, I highly recommend checking those two pages I linked to and seeing which companies are sharing your data.</p>



<p>The thing I wonder about most though, is what <em>other</em> companies my data is being shared with. Companies I have no way whatsoever to see such a list…</p>



<p>I guess the best thing to do is to contact these companies and ask them to stop it. Or to file a GDPR complaint. I would also recommend checking out <a href="https://noyb.eu/en" target="_blank" rel="noreferrer noopener">NOYB</a> (None Of Your Business). It’s a privacy non-profit organization that does some great work in this area. Sign up and become a member if you want to support their work further.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/whos-sharing-my-data-and-who-the-hell-is-dave-m-rogenmoser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956388</guid>
            <pubDate>Sun, 26 Jul 2020 11:53:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying MLsub – The Simple Essence of Algebraic Subtyping]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23956315">thread link</a>) | @panic
<br/>
July 26, 2020 | https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html | <a href="https://web.archive.org/web/*/https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong><em>Note: this web article is an older version of a paper which has now been published as an ICFP Pearl. You can find a preprint of that paper <a href="https://lptk.github.io/simple-sub-paper">here</a>.</em></strong></p> <p><strong><em>It’s probably better to read the paper rather than this post, as the paper contains more material, is more up to date, and is better explained!</em></strong></p> <p><strong>Algebraic subtyping</strong> is a new approach to global type inference in the presence of subtyping. It extends traditional Hindley-Milner type inference while preserving the principal type property — that is, it can always infer <em>the</em> most general type for any given expression. This approach was developed by <a href="http://stedolan.net/about/">Stephen Dolan</a> as part of his PhD thesis, along with Alan Mycroft.</p> <p>Algebraic subtyping was implemented in <a href="https://www.cl.cam.ac.uk/~sd601/mlsub/">the <strong>MLsub</strong> type inference engine</a>. However, the design of MLsub seems significantly more complex than the simple unification algorithms used for traditional ML languages. MLsub has proven harder to grasp, even for people already familiar with compilers and type systems, such as myself.</p> <p>Dissatisfied with this state of affairs, I wanted to get to the bottom of the algebraic subtyping approach. What really is special about it, beyond the formalism? What are the simple concepts that hide behind the strange notions of <em>biunification</em> and <em>polar types</em>?</p> <p>This article is an answer to those questions. I propose an alternative algorithm for algebraic subtyping, called <strong>Simple-sub</strong>. Simple-sub can be implemented <strong>efficiently</strong> in <strong>under 500 lines of code</strong> (including parsing, simplification, and pretty-printing), and I think it is much more familiar-looking and easier to understand than MLsub.</p> <h4 id="---you-can-try-simple-sub-online-here---"><strong>⇨ ⇨ ⇨ <em><a href="https://lptk.github.io/simple-sub/">You can try Simple-sub online here!</a></em> ⇦ ⇦ ⇦</strong></h4> <p>This article is meant to be light in formalisms and easy to consume for prospective designers of new type systems and programming languages.</p> <p><a href="https://github.com/LPTK/simple-algebraic-subtyping">The complete source code of Simple-sub is available on Github.</a></p>   <h2 id="summary">Summary</h2> <ol> <li> <p><strong><a href="#intro">Introduction</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-mlsub">Algebraic Subtyping in MLsub</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-simple-sub">Algebraic Subtyping in Simple-sub</a></strong></p> </li> <li> <p><strong><a href="#simplifying-types">Simplifying Types</a></strong></p> </li> <li> <p><strong><a href="#conclusions">Conclusions</a></strong></p> </li> </ol> <hr>  <p>The ML family of languages, which encompasses Standard ML, OCaml, and Haskell, have been designed around a powerful “global” approach to type inference, rooted in the work of <a href="https://doi.org/10.2307%2F1995158">Hindley</a> and <a href="https://doi.org/10.1016%2F0022-0000%2878%2990014-4">Milner</a>, later closely formalized by <a href="https://dl.acm.org/doi/10.1145/582153.582176">Damas</a>. In this approach, the type system is designed to be simple enough that types can be unambiguously inferred from terms without the help of any type annotations. That is, for any unannotated term, it is always possible to infer a <em>principal type</em> which subsumes all other types that can be assigned to this term. For instance, the term $\lambda{x}. {x}$ can be assigned types $\mathsf{bool} \to \mathsf{bool}$ and $\mathsf{int} \to \mathsf{int}$, but both of these are subsumed by the polymorphic type $\forall a.\ a \to a$, also written <code>'a -&gt; 'a</code>, which is the principal type of this term.</p> <p><strong><em>Hindley-Milner</em></strong> (HM) type inference contrasts with more restricted “local” approaches to type inference, found in languages like Scala and C#, which often require the types of variables to be annotated explicitly by programmers. On the flip side, abandoning the principal type property allows these type systems to be more expressive and to support features such as object orientation and first-class polymorphism. Note that in practice, even ML languages like OCaml and Haskell have adopted expressive type system features which, when used, break the principal type property.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p> <p><strong><em>Subtyping</em></strong> is an expressive feature allowing types to be structured into hierarchies (usually a subtyping <a href="https://en.wikipedia.org/wiki/Lattice_(order)"><em>lattice</em></a>) with the property that types can be <em>refined</em> or <em>widened</em> transparently following this hierarchy. This lets us express the fact that some types are more precise (contain more information) than others, but still have a compatible runtime representation, so that no coercions between them are needed. For instance, in a system where the type <code>nat</code> is a subtype of <code>int</code>, one can transparently use a <code>nat list</code> in place where an <code>int list</code> is expected, without having to apply a coercion function on all the elements of the list. Subtyping can be emulated using somewhat heavy type system machinery (which both OCaml and Haskell occasionally do<sup id="fnref:2"><a href="#fn:2">2</a></sup>), but first-class support for subtyping gives the benefit of simpler type signatures and better type inference.</p> <p>For a long time, it was widely believed that pervasive implicit subtyping got in the way of satisfactory global type inference. Indeed, previous approaches to inferring subtypes failed to support principal types or resulted in the inference of large, unwieldy typing schemes which included sets of complex constraints, making their understanding by programmers difficult.</p> <p><strong><em>Algebraic subtyping</em></strong> was introduced by Dolan and Mycroft as an ML-style type system supporting subtyping and global type inference, while producing compact principal types. Here, <em>compact</em> refers to the fact that the inferred types are relatively simple type expressions without any visible constraints, making them easy to understand by programmer. This was achieved by carefully designing the syntax and semantics of the underlying subtyping lattice, allowing for simplifying assumptions in to be made the constraint resolution process of the type inference algorithm.</p> <p>However, <em>biunification</em>, the algorithm proposed by Dolan in order to implement algebraic subtyping, has been quite difficult to understand for many experts and non-experts alike. Indeed, on the surface it looks quite different from the usual <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Algorithm_J"><em>Algorithm J</em></a> traditionally used for Hm type systems: it requires several additional concepts, such as bisubstitution and polar types, making it look more complicated.</p> <p>Thankfully, it turns out that algebraic subtyping admits a type inference algorithm, which I called <em>Simple-sub</em>, that is very similar to the familiar Algorithm J, and also much more efficient than biunification (or at least, than the basic syntax-driven form of biunification.<sup id="fnref:3"><a href="#fn:3">3</a></sup> In this article, I show that inferring algebraic subtypes is actually extremely easy, and can be done in under 300 lines of Scala code. Most of the complexity actually comes from simplifying the inferred type representations, which we will get to later.</p> <p>While the implementation we present is written in Scala, it is straightforward to translate into any other functional programming language.</p> <p><strong><em>The goal of this article</em></strong> is to recast algebraic subtyping into a simpler mold, allowing more prospective designers of type systems and programming languages to benefit from the great insights that this approach offers.</p> <hr>  <p>Let’s start by briefly reviewing what algebraic subtyping and MLsub are and what they are not, and by trying to assess their expressiveness.</p> <h2 id="term-language">Term Language</h2> <p>The term syntax of MLsub is given below. I have omitted boolean literals and if-then-else, as they can easily be typed as primitive combinators. I also used only one form of variables $x$, which will be sufficient for our use (Dolan’s MLsub formalism distinguishes lambda-bound variables from let-bound variables for technical reasons).</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>variable</td> <td>$x$</td> <td><code>x</code></td> </tr> <tr> <td>lambda</td> <td>$\lambda{x}. {e}$</td> <td><code>fun x -&gt; e</code></td> </tr> <tr> <td>application</td> <td>$e\ e$</td> <td><code>e e</code></td> </tr> <tr> <td>record creation</td> <td>$\{\ l_0 = e \,;\; … \,;\; l_n = e\ \}$</td> <td><code>{ l_0 = e; ...; l_n = e }</code></td> </tr> <tr> <td>field selection</td> <td>$e.l$</td> <td><code>e.l</code></td> </tr> <tr> <td>let bindings</td> <td>$\mathsf{let}\ x = e\ \mathsf{in}\ e$</td> <td><code>let x = e in e</code></td> </tr> </tbody> </table> <h2 id="type-language">Type Language</h2> <p>The type syntax of MLsub, summarized below, consists in booleans, function types, record types, type variables, top $\top$ (the type of all values — supertype of all types), bottom $\bot$ (the type of no values — subtype of all types), type union $\sqcup$, type intersection $\sqcap$, and recursive types $\mu{\alpha}. {\tau}$.</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>primitives</td> <td>$\mathsf{bool}$, $\mathsf{int}$, …</td> <td><code>bool</code>, <code>int</code>, …</td> </tr> <tr> <td>function</td> <td>$\tau \to \tau$</td> <td><code>t -&gt; t</code></td> </tr> <tr> <td>record</td> <td>$\set{\ l_0: \tau \,,\; … \,,\; l_n: \tau\ }$</td> <td><code>{ l_0: t, ..., t_n: t }</code></td> </tr> <tr> <td>variable</td> <td>$\alpha $</td> <td><code>'a</code></td> </tr> <tr> <td>top</td> <td>$\top$</td> <td><code>⊤</code></td> </tr> <tr> <td>bottom</td> <td>$\bot$</td> <td><code>⊥</code></td> </tr> <tr> <td>union</td> <td>$\tau \sqcup \tau$</td> <td><code>∨</code></td> </tr> <tr> <td>intersection</td> <td>$\tau \sqcap \tau$</td> <td><code>∧</code></td> </tr> <tr> <td>recursive</td> <td>$\mu\alpha. \tau$</td> <td><code>t as 'a</code></td> </tr> </tbody> </table> <h2 id="informal-semantics-of-types">Informal Semantics of Types</h2> <p>While most MLsub type forms are usual and unsurprising, two kinds of types require our special attention: set-theoretic types (more specifically union and intersection types), and recursive types.</p> <h3 id="set-theoretic-types">Set-Theoretic Types</h3> <p>To a first approximation, union and intersection types can be understood in set-theoretic terms: the type term $\tau_0 \sqcup \tau_1$ (resp. $\tau_0 \sqcap \tau_1$) represents the type of values that are <em>either</em> (resp. <em>both</em>) of type $\tau_0 $ <em>or</em> (resp. <em>and</em>) of type $\tau_1$.</p> <p>MLsub uses these types to indirectly constrain inferred type variables; for instance, one type inferred for term $\lambda{x}. {\set{l = x - 1 \,;\; r = x}}$ could be $\alpha \sqcap \mathsf{int} \to \set{l: \mathsf{int} \,,\; r: \alpha}$. This type reflects the fact that the original argument, of type $\alpha$, is returned in the $r$ field of the result record, as the input type $\alpha$ ends up in that position, but also that this argument should be able to be treated as an $\mathsf{int}$, expressed via the type intersection $\alpha \sqcap \mathsf{int}$ on the left-hand side of the function type. Keeping track of the precise argument type $\alpha$ is important: it could be later substituted with a more specific type than $\mathsf{int}$, such as $\alpha = \mathsf{nat}$, which would give us $\mathsf{nat} \to \set{l: \mathsf{int} \,;\; r: \mathsf{nat}}$.</p> <p>On the other hand, there may be type signatures where some $\alpha$ becomes undistinguishable from $\mathsf{int}$. For instance, consider the term $\lambda{x}. {\mathsf{if}\ \mathsf{true}\ \mathsf{then}\ {x - 1}\ \mathsf{else}\ {x}}$, whose simplified inferred type would be just $\mathsf{int} \to \mathsf{int}$, as the seemingly-more precise type $\alpha \sqcap \mathsf{int} \to \alpha \sqcup \mathsf{int}$ does not actually contain more information (see the MLsub paper for details).</p> <p>The beauty of algebraic subtyping is that this sort of reasoning scales to arbitrary flows of variables and higher-order functions; for instance, the previous example can be generalized by passing in a function $f$ to stand for the $\cdot - 1$ operation, as in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</a></em></p>]]>
            </description>
            <link>https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956315</guid>
            <pubDate>Sun, 26 Jul 2020 11:38:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to effectively evade the GDPR and the reach of the DPA]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 186 (<a href="https://news.ycombinator.com/item?id=23955596">thread link</a>) | @thierryzoller
<br/>
July 26, 2020 | https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html | <a href="https://web.archive.org/web/*/https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955596</guid>
            <pubDate>Sun, 26 Jul 2020 09:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebGL Fluid Simulation]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23955527">thread link</a>) | @maxraz
<br/>
July 26, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955527</guid>
            <pubDate>Sun, 26 Jul 2020 08:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The David Peters Problem]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23955152">thread link</a>) | @apsec112
<br/>
July 26, 2020 | http://tetzoo.com/blog/2020/7/23/the-david-peters-problem | <a href="https://web.archive.org/web/*/http://tetzoo.com/blog/2020/7/23/the-david-peters-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div>

			<section id="content" role="main">
			  <article id="article-5f19cf558cefce22cbe45190" data-item-id="5f19cf558cefce22cbe45190">

     

    
    
    <div>
      
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1595527017370" id="item-5f19cf558cefce22cbe45190"><div><div><div data-block-type="2" id="block-012de72923a196aec9ca"><p>And so it is that I must once more write about the great eternal menace of our age: David Peters. </p></div><div data-block-type="5" id="block-yui_3_17_2_1_1595584636582_289616"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595600373129-HJX3Z36QXOKC9M8149YT/ke17ZwdGBToddI8pDm48kHSOih3rf5Yj5FBYwX4qlNAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchB_s_lSPOhlvrAn825I_D_LqasukoLqujV_vQoSb4_jYu2DH4W47kqIJMZhXOfGB/David-Peters-response-July-2020-Pterosaur-Heresies-header-and-Reptile-Evolution-dot-com-1445px-132kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595600373129-HJX3Z36QXOKC9M8149YT/ke17ZwdGBToddI8pDm48kHSOih3rf5Yj5FBYwX4qlNAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchB_s_lSPOhlvrAn825I_D_LqasukoLqujV_vQoSb4_jYu2DH4W47kqIJMZhXOfGB/David-Peters-response-July-2020-Pterosaur-Heresies-header-and-Reptile-Evolution-dot-com-1445px-132kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="1445x392" data-image-focal-point="0.5,0.5" alt="Caption:  the two main repositories of Peters-based observations and proposals." data-load="false" data-image-id="5f1aedf4cdd8054c19f8d777" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> the two main repositories of Peters-based observations and proposals.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595584636582_542216"><div><p>If you’ve ever looked for information online about the evolution or fossil history of vertebrate animals, chances are high that you’ve encountered work by independent researcher David Peters. Peters sees stuff that no-one else can see, reports findings that no-one else finds, perpetually declares everyone else to be wrong, is vastly prolific, and has been very, very good at sharing and disseminating his stuff online. If Peters were reliable, trustworthy, careful, conscientious, and good at doing science, this would be great, and he would be a significant force for good. </p><p>But Peters is not reliable, or careful, or conscientious, or good at doing science. He is the opposite of those things. And yet he’s on a crusade whereby he aims to share his views – proclaimed by him as representing The Truth – as widely and frequently as possible, all the while decrying the mainstream palaeontological world as if it’s part of a conspiratorial cabal of blinkered elites. Peters is a significant source of miseducation, whose work floods the internet, and who aims to bamboozle those unaware that he’s peddling nonsense.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1595584636582_546745"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595670591430-YFK5J0MJO2002K98S6KS/ke17ZwdGBToddI8pDm48kKLVaihEW4yacHCCWGnLIbUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcRe0kuMBz-UQFIAwLXYOXNB8zy_pvvUf3wqj7HRzhcOKI_k7HB34zqlnB1xFeFLrn/David-Peters-response-July-2020-David-Peters-older-work-vs-modern-work-1415px-146kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595670591430-YFK5J0MJO2002K98S6KS/ke17ZwdGBToddI8pDm48kKLVaihEW4yacHCCWGnLIbUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcRe0kuMBz-UQFIAwLXYOXNB8zy_pvvUf3wqj7HRzhcOKI_k7HB34zqlnB1xFeFLrn/David-Peters-response-July-2020-David-Peters-older-work-vs-modern-work-1415px-146kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="1415x531" data-image-focal-point="0.5,0.5" alt="Caption:  David Peters contends that his older attempts to interpret fossil animals (like the pterosaurs shown here) are “old laundry” which should be ignored, and are irrelevant to his modern efforts. What he fails to understand is that he has never changed, and is still producing work of the exact same quality. This is junk science; it might be correct to label it pseudoscience. Images: David Peters." data-load="false" data-image-id="5f1c003ea5b1ab2f72081359" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> David Peters contends that his older attempts to interpret fossil animals (like the pterosaurs shown here) are “old laundry” which should be ignored, and are irrelevant to his modern efforts. What he fails to understand is that he has never changed, and is still producing work of the exact same quality. This is junk science; it might be correct to label it pseudoscience. Images: David Peters.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595584636582_547044"><div><p>In this article, I explain why David Peters, and the two primary repositories of his work (his Pterosaur Heresies blog and his ReptileEvolution.com site), must be ignored. But first, some required background. The following largely repeats <a href="https://web.archive.org/web/20120705194937/http://blogs.scientificamerican.com/tetrapod-zoology/2012/07/03/world-must-ignore-reptileevolution-com/" target="_blank"><span>the review of the Peters problem published at TetZoo back in 2012</span></a> (and then corrupted by its hosters, hence my reliance on a <a href="https://web.archive.org/web/20120705194937/http://blogs.scientificamerican.com/tetrapod-zoology/2012/07/03/world-must-ignore-reptileevolution-com/" target="_blank"><span>version at wayback machine</span></a>).</p><p><strong>Prologue.</strong> David Peters is a published scientist with articles in <em>Journal of Vertebrate Paleontology</em>, <em>Historical Biology</em>, <em>Nature</em> and <em>Science</em> to his name (Peters 1995, 2002, 2005, 2009, 2010). He’s a skilled and proficient artist, and the author and artist of several excellent books from the 1980s and early 90s. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1595526977752_35690"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595538066622-FN0NM8D5PED69U5TT6YF/ke17ZwdGBToddI8pDm48kHjy9aoMnVP3vIMKmFwrQaEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcNLW-VcGsPKSEcVQKHF5o5NAcqgHZaCOhD7aC9KZ0tJ57dfc9Np835Ut2WsJjQ3mU/David-Peters-response-July-2020-Peters-books-1108px-167kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595538066622-FN0NM8D5PED69U5TT6YF/ke17ZwdGBToddI8pDm48kHjy9aoMnVP3vIMKmFwrQaEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcNLW-VcGsPKSEcVQKHF5o5NAcqgHZaCOhD7aC9KZ0tJ57dfc9Np835Ut2WsJjQ3mU/David-Peters-response-July-2020-Peters-books-1108px-167kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="1108x704" data-image-focal-point="0.5,0.5" alt="Caption:  the David Peters of the past produced a fair few very good, beautifully illustrated popular books." data-load="false" data-image-id="5f19fa914a3c2e42bbc0d6d5" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> the David Peters of the past produced a fair few very good, beautifully illustrated popular books.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595526977752_35989"><p>But at some point between the late 1990s and early 2000s, it became clear from his online writings and published articles that Peters had become <em>very strange</em>. Thanks to a unique kind of magic, super-powered vision, he claimed to find hitherto undetected babies, soft-tissue frills, umpteen new anatomical structures <em>and more</em> on pterosaur fossils. These claims were awfully reminiscent of those fringe announcements on the finding of skulls and bits of technology in NASA’s photographs of Mars or the moon, or of Jon-Eric ‘the fruitbat’ Beckjord’s proposals that frames of the Patterson-Gimlin film reveal hidden Bigfoots lurking in the shadows. Today, the Peters of 2020 thinks that at least some of these claims – documented in Peters (2004) and reported at conferences (e.g., the 2003 Society of Vertebrate Paleontology meeting at San Antonio, Texas, the 2006 Flugsaurier meeting at Munich) – should be ignored as “rookie mistakes” or “old laundry”. Making mistakes is part of science, we all do it. But claiming with confidence (in print and at conferences) that you’ve found a ton of incredible stuff that others have not is a red flag, especially when the Peters technique of finding stuff that on-one else can has the vile, distinct stench of pseudoscience about it. And despite arguments that those weird claims of the past were “rookie mistakes” or “old laundry”, the fact is that Peters has never stopped doing whatever it is that he does.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1595526977752_41793"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595538116407-YUFT896QAQH77Y998YZL/ke17ZwdGBToddI8pDm48kG-ZFJPdd7cm2LaajXfqDskUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc2syx4ap2EKRbZVnCpMxIZCLEMiWHxCZ4jIciK0NxZTY961ONlpTSK84GsNDmNG8D/David-Peters-response-July-2020-in-the-past-Peters-thought-pterosaurs-looked-ridiculous-Kosemen-and-Naish-1296px-134kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595538116407-YUFT896QAQH77Y998YZL/ke17ZwdGBToddI8pDm48kG-ZFJPdd7cm2LaajXfqDskUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc2syx4ap2EKRbZVnCpMxIZCLEMiWHxCZ4jIciK0NxZTY961ONlpTSK84GsNDmNG8D/David-Peters-response-July-2020-in-the-past-Peters-thought-pterosaurs-looked-ridiculous-Kosemen-and-Naish-1296px-134kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="1286x605" data-image-focal-point="0.5,0.5" alt="Caption:  Peters dislikes the illustrations you see here, claiming that they were created to “lampoon” him. The fact is that these illustrations (created by C. M. Kösemen and myself) accurately depict what Peters was saying about pterosaurs when the illustrations were made. Dorsal frills, soft tissue head crests, extra-long tails and more. Images: C. M. Kösemen ( Pteranodon  and  Pterodactylus ); Darren Naish ( Campylognathoides )." data-load="false" data-image-id="5f19fac365572e3cfcbbe63e" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> Peters dislikes the illustrations you see here, claiming that they were created to “lampoon” him. The fact is that these illustrations (created by C. M. Kösemen and myself) accurately depict what Peters was saying about pterosaurs when the illustrations were made. Dorsal frills, soft tissue head crests, extra-long tails and more. Images: C. M. Kösemen (<em>Pteranodon</em> and <em>Pterodactylus</em>); Darren Naish (<em>Campylognathoides</em>).</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595526977752_42092"><p>In a 2003 article in the <em>Times Higher</em>, journalist Steve Farrar wrote a piece (‘Experts dismiss vampire reptile claim’) calling out Peters’&nbsp;Society of Vertebrate Paleontology presentation ‘The Chinese vampire and other overlooked pterosaur ptreasures’, and in 2005, pterosaur specialist Chris Bennett produced an effective demolition of Peters’ work (<a href="http://bigcat.fhsu.edu/biology/cbennett/Bennett-PT-article.pdf" target="_blank"><span>Bennett 2005</span></a>). By now, the proverbial cat (a vampire cat, covered in hitherto unseen babies and sporting a <em>Longisquama</em>-like frill of dorsal plumes and with a previously unnoticed long, tassel-tipped tail) was out of the bag, and it became less easy – although not impossible – for Peters to get his stuff into the literature, and presented at conferences. Several of his manuscripts – I believe submitted to such journals as <em>Nature</em> and <em>Journal of Vertebrate Paleontology</em> and mostly aimed at tackling big picture issues of reptile phylogeny – were rejected at around this time (for the record, I have not ever, not once, acted as a reviewer for a Peters paper).</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1595584636582_203035"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595590833877-DWWW7ERO1V04K1DEBHSK/ke17ZwdGBToddI8pDm48kIo5GMNWQRByW6nhUxdVqq1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQARuYaQZ95YKFtrM0Ij5bsGRNCdpk2qEL94Tvrm2TS4KMshLAGzx4R3EDFOm1kBS/David-Peters-response-July-2020-Peters-vampire-and-Times-Higher-piece-2-833px-194kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595590833877-DWWW7ERO1V04K1DEBHSK/ke17ZwdGBToddI8pDm48kIo5GMNWQRByW6nhUxdVqq1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQARuYaQZ95YKFtrM0Ij5bsGRNCdpk2qEL94Tvrm2TS4KMshLAGzx4R3EDFOm1kBS/David-Peters-response-July-2020-Peters-vampire-and-Times-Higher-piece-2-833px-194kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="833x753" data-image-focal-point="0.5,0.5" alt="Caption:  the infamous ‘vampire pterosaur’ Peters abstract from 2003. Some people say that stuff like this makes a mockery of organisations like the Society of Vertebrate Paleontology, others that it doesn’t matter and that it’s inevitable that nonsense will slip through the cracks. At right: part of the  Times Higher  article on Peters and the appearance of his research at the relevant SVP meeting." data-load="false" data-image-id="5f1ac8b159f5c362ebf7d519" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> the infamous ‘vampire pterosaur’ Peters abstract from 2003. Some people say that stuff like this makes a mockery of organisations like the Society of Vertebrate Paleontology, others that it doesn’t matter and that it’s inevitable that nonsense will slip through the cracks. At right: part of the <em>Times Higher</em> article on Peters and the appearance of his research at the relevant SVP meeting.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595584636582_92738"><p>Predictably, these efforts to block or smack Peters down did not cause him to retreat, or revise or reconsider his methods or conclusions, but, instead, to double-down, become more entrenched, and become ever more determined to convert the world to see and accept his results. He stepped up his game online, giving us the outpouring that is ReptileEvolution.com and the updated daily, twice daily, thrice daily, infinity-times daily blog The Pterosaur Heresies. Though starting this grand online project with pterosaurs as his focus, Peters has expanded his interest to include reptiles of all sorts, mammals, all tetrapods and FISH as well. To those mammal, bird and fish experts who didn’t care about Peters when he was just ‘that weird pterosaur guy’, I say… well, now you know what it’s like.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1595584636582_92439"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595585837933-W1W0IKE3JI6B5O46MK16/ke17ZwdGBToddI8pDm48kN48qJhWkxNI2g5mAWhyIs4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcYGnZW2S01ttp7mSQei0CilNEKWHIAcwdKSLRIskJFS62DsFidnWaHffi5Yp0Ha28/Bennet-2005-comp-1168px-284kb-July-2020-Tetrapod-Zoology.JPG" data-image="https://images.squarespace-cdn.com/content/v1/510be2c1e4b0b9ef3923f158/1595585837933-W1W0IKE3JI6B5O46MK16/ke17ZwdGBToddI8pDm48kN48qJhWkxNI2g5mAWhyIs4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcYGnZW2S01ttp7mSQei0CilNEKWHIAcwdKSLRIskJFS62DsFidnWaHffi5Yp0Ha28/Bennet-2005-comp-1168px-284kb-July-2020-Tetrapod-Zoology.JPG" data-image-dimensions="1168x768" data-image-focal-point="0.5,0.5" alt="Caption:  in an influential article of 2005, Chris Bennett showed why Peters’ unique takes on pterosaur anatomy - some of which are depicted in the drawings here - should be regarded as discordant with reality." data-load="false" data-image-id="5f1ab52c169f0b5648ada13a" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p><strong>Caption:</strong> in an influential article of 2005, Chris Bennett showed why Peters’ unique takes on pterosaur anatomy - some of which are depicted in the drawings here - should be regarded as discordant with reality.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1595584636582_248033"><div><p>Why do I care about what Peters says or does, and since when is it my business to tell people what to do? Or, restated: why can’t I just mind my own business and leave Peters alone? I will tell you why. If ‘the published literature’ is regarded as a synonym for ‘the accepted canon of human knowledge’, then efforts to curtail the spread of Peters’ ideas (e.g., <a href="http://bigcat.fhsu.edu/biology/cbennett/Bennett-PT-article.pdf" target="_blank"><span>Bennett 2005</span></a>) have been successful. His efforts to instigate paradigm change (that pterosaurs are lepidosaurs, that mammals are archosauromorph reptiles, that bats are civets, that mysticete whales are desmostylians and so on and on and on and on) have failed and are being ignored by working scientists. </p><p>If, however, you think that material shared online – in blog articles and so on – has some impact on what people think worthy of attention or allocation to memory, Peters is successful. Peters is not, dear reader, just doing his own thing in some quiet corner of the internet, beavering away in earnest, minding his own business. He is instead on some kind of eternal crusade to promote promote promote his ideas CEASELESSLY. I can confirm from working with students, the interested public and even other qualified scientists that his stuff is often assumed to be real science, on equal footing with that of those he criticises. All of which means that his efforts need countering. </p><p>My interest in the dissemination of knowledge and public education, and my respect for the due diligence of those people whose work is criticised, admonished or …</p></div></div></div></div></div></div></article></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tetzoo.com/blog/2020/7/23/the-david-peters-problem">http://tetzoo.com/blog/2020/7/23/the-david-peters-problem</a></em></p>]]>
            </description>
            <link>http://tetzoo.com/blog/2020/7/23/the-david-peters-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955152</guid>
            <pubDate>Sun, 26 Jul 2020 07:29:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Montreal is taxing churches (2017)]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 295 (<a href="https://news.ycombinator.com/item?id=23954846">thread link</a>) | @seesawtron
<br/>
July 25, 2020 | https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
	Churches in Montreal are becoming concerned about hosting community groups after being hit with bills for municipal taxes.</p>
<p>
	Joel Coppetiers, the Minister at the Cote des Neiges Presbyterian church, was shocked when his institution first received a municipal tax bill in early 2015.</p>
<p>
	It was "the first indication that something had changed," said Coppetiers.</p>
<p>
	Provincial law exempts churches and manses from paying municipal taxes but Coppetiers was told that if a manse is vacant for several months between ministers, it's taxable.</p>
<p>
	Following that, city officials arrived for an inspection of every room in the church and how they were used.</p>
<p>
	"The indication is there's not an exemption for the church as a whole, there's only an exemption for those areas used for public worship and things directly related to it," said Coppetiers.</p>
<p>
	As a result, many churches in Montreal that host community groups, such as food banks, or Girl Guides or Boy Scouts, are facing mounting tax bills.</p>
<p>
	Coppetiers says the city has changed how it interprets the law.</p>
<p>
	"We're there to care and serve the community and this is part of it," said Coppetiers.</p>
<p>
	Coppetiers says taxes are due even when services are suspended for renovations.</p>
<p>
	The amount owed in taxes can increase swiftly if a church closes its doors.</p>
<p>
	When <a href="http://montreal.ctvnews.ca/trinity-memorial-church-in-ndg-closes-its-doors-1.3302321">Trinity Memorial Church in NDG </a>closed earlier this year, the city started enacting taxes immediately following the last service.</p>
<p>
	As a result churches feel pressured to sell swiftly, with Trinity Memorial being sold to Stanford Properties Group within two months.</p>
<p>
	The issue of places of worship owing taxes and fighting the city's exemptions office came as a surprise to city politicians, including Councillor Peter McQueen.</p>
<p>
	"Already our churches are in danger, they're having a number of financial problems and this is a further low blow," said McQueen.</p>
<p>
	The NDG councillor said his party, Projet Montreal, will study the exemption issue, but he said Montreal's Executive Committee needs to step up.</p>
<p>
	"If we don't do something you're going to see churches closed, churches possibly torn down, heaven forbid, certainly converted away from community use," said McQueen.</p>
<p>
	Meanwhile churches across the island are praying that the city will cease surprising them with taxes they can't afford.</p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954846</guid>
            <pubDate>Sun, 26 Jul 2020 06:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running DOS Apps on Windows]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 47 (<a href="https://news.ycombinator.com/item?id=23954234">thread link</a>) | @bluedino
<br/>
July 25, 2020 | https://gekk.info/articles/dosapps.html | <a href="https://web.archive.org/web/*/https://gekk.info/articles/dosapps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tr><td>
	<div>
	<p>It's worth discussing <em>how</em> all this works so you understand the 
	challenges that are being overcome here. The ability to run multiple DOS 
	programs at once is a pretty neat trick, given that this software heralds 
	from an era of computing that was <em>just barely</em> ahead of what the 
	Apple ][ was doing in 1978. If you want to skip this, <a href="#Windows_1.0">go ahead</a>.</p>
	<p>The root of the problem is that the IBM PCs basic architecture 
	crystallized a very long time ago, in 1981. In a world where ten kilobytes of RAM counted for 
	about what a gig does now, there was not a lot of room for "overhead" and 
	the idea that you would run two programs simultaneously was generally 
	unrealistic except at the high end of the computing world, which most PC 
	buyers were nowhere near. You needed every bit (<em>ha</em>) of memory you could get, and when 
	memory became more affordable a few years later, it was too late 
	to change anything.</p>
	<p>After just a couple years on the market, MS-DOS had become the 
	unquestioned OS of choice for the PC<a href="#footnote1">*</a> 
	and developed a monumental stable of software, every bit of which<em> </em>
	was essential to someone, somewhere, and could not be easily replaced. Thus 
	began one of the longest tails in technology history, as the PC industry and 
	Microsoft began contorting themselves to try not to 
	break compatibility with old software while still moving forward with advanced 
	functionality.<br>
	<sub><a name="footnote1">*</a>(specifically, since there were MS-DOSes for 
	other architectures, and other OSes for the PC)</sub></p>
	<p>Because DOS was developed under constraints very similar to those 
	in the 
	late '70s that gave us the "bitty boxes" (C64, Apple ][, ZX 
	Spectrum, etc.) it was not built with any kind of "supervision" in mind. In 
	other words, there was no abstraction level above the current running program. 
	DOS was more like a set of tools than what we think 
	of as an operating system now - specifically, it had no "process management"; no concept of "processes" at all, in fact.</p>
	<h2><strong>DOS</strong></h2>
	<p>When the machine booted, the part of DOS that was considered "the OS" - 
	the code for accessing disk drives, writing text to screen, etc. - was copied 
	into memory, and then execution was handed off to the command interpreter, COMMAND.COM, 
	which was an application like any other, at which point you could begin 
	entering commands to use the computer.</p>
		<p>At this point, DOS was no longer "running" in 
	any meaningful way. The code was "resident," meaning it was present in the 
		computer's memory, but 
	the processor wasn't&nbsp; executing any of it. Instead, the CPU was busy executing 
	whatever the current program was - if you were at the command prompt, then 
		all the code the PC was executing was part of COMMAND.COM. When you launched another application, COMMAND.COM was 
	vacated and replaced by that other application.</p>
	<p>In other words, while an application was running, DOS was almost totally out of 
	the picture. The only time execution returned to DOS itself was when the 
	application requested a "service" from DOS, like accessing a disk drive, at 
	which point it would tell the CPU to go execute one of DOS' stored routines 
	for this, and when that routine was done, control would return to the 
	application. This meant that,<em> generally speaking</em>,<em> </em>the current 
	program 
	had absolute control of the PCs execution and it's memory. It could in fact choose to 
	overwrite DOS itself, obliterating it out of memory, and DOS couldn't do a damn thing about it.</p>
	<p>The currently running app also had the option to speak directly to hardware. 
	The 
	whole purpose of DOS was to abstract things like that so programs wouldn't 
	need to know the details of the system they were running on, but since the 
	IBM PC was <em>extremely</em> consistent hardware-wise in its early 
	incarnations, it was entirely 
	optional for developers to take advantage of that, and often 
	there were reasons - of performance, perhaps - to bypass DOS and do things 
	directly.</p>
		<p>DOS provided disk access routines, 
	but the app could blow right by them and shoot commands straight to the 
	floppy drive if it wanted. DOS provided routines for printing text and clearing the 
	screen, but the app could just write directly to video memory. I can't speak to how common this kind of behavior actually was, but it 
	certainly wasn't rare, and it speaks to a larger problem - DOS apps simply 
	expect total control over the system.</p>
		<p>If you run two DOS apps at once, they're 
	going to stomp on each other, because each one thinks it's in charge of the 
		whole machine. The first one would store data in the same spot that the 
		second one stored program code, and thus one would overwrite the other 
		and crash it. So DOS was a single-tasking operating system - you could 
		run one program at a time, and when you wanted to run another, you had 
		to exit, return to the command prompt, and then launch your other app.</p>
		<p>Consequently, if you were working on something 
	in Microsoft Multiplan and wanted to go look up some data in dBase, you had to quit completely 
	out of Multiplan and then start dBase, which would take over the system and totally 
	overwrite the previous app. To get back to where you were you'd have to exit 
		dBase, restart Multiplan, load your document and find your place again - 
		in the process, totally forgetting what you were there to do in the 
		first place, because it's so many steps and takes so long.</p>
	<p>Right from the get-go, PC users wanted to be able to look at one program, then rapidly 
	switch to another. On its face this seems to mean "run two programs at once," 
	which is what we do now, but that's not quite the full story. Let's touch on how 
	that works nowadays, however.</p>
	<h2><strong>Multiprocessing</strong></h2>
	<p>To be clear, you <em>cannot</em> run two programs "at once" on a 
	computer. Some would call this semantics, but it's important in a very real 
	way, <em>especially</em> when talking about 80s-era PCs.</p>
		<p>Modern multicore CPUs get very close to true parallel processing by 
		letting separate programs run on separate cores, but of course, nobody has a CPU so big 
	that they have one core per process. And even if you did, programs still 
		have to share other 
	resources - the system bus, hard drives, and so on. Access to these 
	resources has to be carefully managed so that only one application can use 
		them at a time, and each one has to be cleaned up after before another 
		one can use the same resources. Otherwise, one program could leave the 
		hardware in a state where the commands that the next program sends put 
		it in an unusable state and crash the machine, or corrupt data.</p>
	<p>Even with all our modern pipelined cleverness, you have the 
	fundamental problem that a CPU, and a computer in general, has a limited 
	amount of physical hardware and can't dedicate some to each individual 
	program that's running. When you have more processes running than you have silicon, the only option left is to share 
	resources by dividing up the amount of time that each process gets to use the hardware 
	- this is one of the oldest concepts in computing, and goes back to the late '50s.</p>
	<p>The fundamentals of this process are simple: At 
	any given moment, one program has near-total control of the entire 
	system, to execute its code and use all the resources, and then after it 
	executes for a bit, it goes into a paused state and control is handed off to 
	the next program, which does its work and then hands off to the next. This 
	continues in a round-robin fashion, so that every program gets to use the 
	hardware for a certain portion of every second.</p>
	<p>Modern implementations take this to a fever pitch with all the complex 
	machinations used to make this process efficient, but the fundamentals have 
	never changed; this is how your PC is operating right now.</p>
	<p>One big hurdle to overcome in implementing this is that programs don't just execute 
	instructions in a vacuum. As code is executed, there are side 
	effects. Some are values internal to the CPU, like the&nbsp; status of CPU registers and the current 
	position of the instruction pointer. This is called "CPU state," amd is specific to 
	each running program. When you switch from one program to another, you have to 
	save that information - called "context switching" - and restore it when you 
	come back. Storing this info takes extra time and memory.</p>
		<p>Another hurdle is the state of other hardware. If two programs are 
		talking to the hard drive, you can't let them both just blindly issue 
		commands every time they get control of the CPU. The first process might 
		start a data read that the second process interrupts with a data write, 
		confusing the hard drive controller. So when switching from one process 
		to another, you also have to save the state of these other hardware 
		resources - and possibly even delay switching tasks until those hardware 
		requests are complete.</p>
	<p>If you have enough RAM to store this state, and if your apps don't need too many cycles per second to appear responsive, you can do all this and the user 
	will feel like they're "running multiple programs at 
	once."</p>
	<p>Now, in business applications - the 
	driving force behind the first couple decades of computing - actual 
	"multiprocessing" of this type is not as important as simple usability - users 
	just don't want to have to close one program in order to open another, as they 
	did throughout the DOS days. That, ultimately, is the goal: it 
	doesn't matter if the computer is perfectly speedy, or if programs can run 
	simultaneously, it just matters that 
	users not have to lose all their work in one program simply in order to look 
	at another.</p>
	<h2>Multitasking</h2>
	<p>This desire was of course tremendous right from the start of computing. Who wants to 
	be stuck in one program at a time? So, almost from the 
	earliest days of the IBM PC, software was created to enable task switching 
	with various degrees of success.</p>
		<h3>Early Attempts</h3>
		<p><a data-lity="" href="https://gekk.info/articles/images/doswin/dos4_taskswitch.png">
		<img alt="Multitasking DOS 4" height="177" src="https://gekk.info/articles/images/doswin/dos4_taskswitch_small.png" width="320"><!-- MSComment="autothumbnail" xthumbnail-orig-image="file:///C:/Users/dthom/Documents/My Web Sites/images/doswin/dos4_taskswitch.png" --></a></p>
	<p>Microsoft actually released a version of DOS with true multitasking 
	support, but it …</p></div></td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gekk.info/articles/dosapps.html">https://gekk.info/articles/dosapps.html</a></em></p>]]>
            </description>
            <link>https://gekk.info/articles/dosapps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954234</guid>
            <pubDate>Sun, 26 Jul 2020 03:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[D3js Tree of Wittgenstein's Tractatus]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23953857">thread link</a>) | @motohagiography
<br/>
July 25, 2020 | https://pbellon.github.io/tractatus-tree/#/ | <a href="https://web.archive.org/web/*/https://pbellon.github.io/tractatus-tree/#/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pbellon.github.io/tractatus-tree/#/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23953857</guid>
            <pubDate>Sun, 26 Jul 2020 02:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typometer: A tool to measure and analyze the visual latency of text editors]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 99 (<a href="https://news.ycombinator.com/item?id=23952697">thread link</a>) | @mrzool
<br/>
July 25, 2020 | https://pavelfatin.com/typometer/ | <a href="https://web.archive.org/web/*/https://pavelfatin.com/typometer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>

<span><img src="https://pavelfatin.com/images/typometer.png" alt="Technical drawing of keyboard keys" title="Typometer"></span>Typometer is a tool to measure and analyze visual latency of text / code editors.</p>
<p>Editor latency is delay between an input event and a corresponding screen update, in particular case – delay between keystroke and character appearance. While there are many kinds of delays (caret movement, line editing, etc.), typing latency is a major predictor of editor usability.</p>
<p>Check my article <a href="https://pavelfatin.com/typing-with-pleasure">Typing with pleasure</a> to learn more about editor latency and its effects on typing performance.</p>
<p>Project source code is available as a <a href="https://github.com/pavelfatin/typometer">GitHub repository</a>.</p>
<p>Download: <a href="https://github.com/pavelfatin/typometer/releases/download/v1.0.1/typometer-1.0.1-bin.zip">typometer-1.0.1-bin.zip</a> (0.5 MB)</p>
<p>Java 8 or latter is required to run the program. You can <a href="https://java.com/download">download Java</a> from the official site.<br>
<span id="more-1135"></span></p>
<h3>Features</h3>
<ul>
<li>Cross-platform (Windows, Mac, Linux).</li>
<li>Native API calls for faster screen access.</li>
<li>Synchronous / asynchronous modes.</li>
<li>Import / export of CSV data.</li>
<li>Summary statistics, frequency distribution.</li>
<li>Line / bar charts (including comparative ones).</li>
<li>Chart image export (with legend).</li>
</ul>
<h3>Screenshots</h3>
<p>Main window:</p>
<p><img alt="Typometer, main window" title="Typometer, main window" src="https://pavelfatin.com/images/typometer/typometer-window.png"></p>
<p>Frequency distribution chart:</p>
<p><img src="https://pavelfatin.com/images/typometer/typometer-distribution.png" alt="Typometer, frequency distribution chart" title="Typometer, frequency distribution chart"></p>
<h3>Principle</h3>
<p>The program generates OS input events (key presses) and uses screen capture to fully automate the test process.</p>
<p>At first, a predefined pattern (“<code>.....</code>“) is inserted in editor window in order to detect screen metrics (start position, step, background, etc.).</p>
<p>After that, the program types a predefined number of “<code>.</code>” characters into the editor (with given periodicity), measuring delays between key presses and corresponding character drawings.</p>
<p>To achieve high accuracy of measurement, only a single pixel is queried for each symbol. Moreover, the program can use fast native API (<a href="https://en.wikipedia.org/wiki/Windows_API">WinAPI</a>, <a href="https://en.wikipedia.org/wiki/Xlib">XLib</a>) calls on supported platforms, offering <a href="http://docs.oracle.com/javase/8/docs/api/java/awt/Robot.html">AWT robot</a> as a fallback option.</p>
<p>There are two modes of testing available:</p>
<ul>
<li><strong>Synchronous</strong> – the program always waits for typed character to appear before making a pause and typing the next character. It’s the most accurate method (because there’s no threading overhead).</li>
<li><strong>Asynchronous</strong> – the program types and recognizes characters independently. This method is slightly less accurate, but it’s useful for testing rapid typing, when editor drawing might easily lag by multiple characters.</li>
</ul>
<h3>Usage</h3>
<p>To register only essential editor latency, text must be rendered directly to <a href="https://en.wikipedia.org/wiki/Framebuffer">framebuffer</a>, without intermediate image processing that might introduce additional delay. Prefer <a href="https://en.wikipedia.org/wiki/Stacking_window_manager">stacking window managers</a> to <a href="https://en.wikipedia.org/wiki/Compositing_window_manager">compositing window managers</a> for the testing purposes, particularly:</p>
<ul>
<li>Switch to Classic theme in Windows. <a href="https://en.wikipedia.org/wiki/Windows_Aero">Windows Aero</a> enforces internal <a href="https://en.wikipedia.org/wiki/Analog_television#Vertical_synchronization">vertical synchronization</a>, which leads to minimum 1 frame lag (about 17 ms for 60 Hz monitor refresh rate) and delay discretization. It’s also possible to disable the compositing directly <a href="https://web.archive.org/web/20161021060058/http://www.softwareaudioconsole.com/Tweaking_Windows_7.htm">in Windows 7</a> and <a href="http://www.rlauncher.com/wiki/index.php?title=Input_Lag_Checklist#Disable_Desktop_Composition_in_Windows_8_and_8.1">in Windows 8</a>.</li>
<li>Use Linux distributive with lightweight <a href="https://en.wikipedia.org/wiki/Window_manager">window manager</a>, like <a href="http://lubuntu.net/">Lubuntu</a> (<a href="https://en.wikipedia.org/wiki/Openbox">Openbox</a>). Complex, 3D-based windows managers might substantially increase system rendering latency, for example, on my hardware, Ubuntu’s <a href="https://en.wikipedia.org/wiki/Compiz">Compiz</a>, adds ~10 ms unavoidable lag.</li>
</ul>
<p>Close all programs that add system-wide keyboard <a href="https://en.wikipedia.org/wiki/Hooking">hooks</a>, as they might process the keyboard events synchronously and affect the results (for example, <a href="http://www.workrave.org/">Workrave</a> is known to noticeable increase the typing latency).</p>
<p>You may consider switching your machine in a particular hardware mode (power scheme, integrated / discrete graphics, etc.). In power save mode (and on battery), for example, editor responsiveness is usually much lower, so it’s possible to detect significant performance glitches which are less frequently observable otherwise.</p>
<p>Before you start benchmarking, make sure that other applications are not placing noticeable load on your system. It’s up to you whether to “warm up” <a href="https://en.wikipedia.org/wiki/Virtual_machine#Process_virtual_machines">VM</a>-based editors, so they can pre-compile performance-critical parts of their code before proceeding.</p>
<p>If possible, enable non-block caret (i. e. underline / vertical bar instead of rectangle) in editor. This might increase measurement accuracy.</p>
<p>Typical action sequence is the following:</p>
<ol>
<li>Specify a measurement title, like “HTML in Vim” <em>(optional, can be set later)</em>.</li>
<li>Configure test parameters <em>(optional)</em>.</li>
<li>Launch an editor, maximize its window.</li>
<li>Open some data in the editor, for instance, a large HTML file <em>(optional)</em>.</li>
<li>Place editor caret in desired context (like comment, etc.), at the end of short / empty line.</li>
<li>Start benchmarking process in the program.</li>
<li>After a corresponding prompt, transfer focus to the editor window.</li>
<li>Wait for test completion, don’t interfere with the process.</li>
</ol>
<p>You can always interrupt the testing process simply by transferring focus back to the program window.</p>
<p>After test result is acquired, you may either analyze the singular data by itself or perform additional tests (different editors / conditions) to do comparative analysis.</p>
<p>Both source- and aggregate data is easily accessible, you can:</p>
<ul>
<li>copy table content  as text,</li>
<li>save chart to <a href="https://en.wikipedia.org/wiki/Portable_Network_Graphics">PNG</a> file (with legend and summary stats),</li>
<li>export raw data in <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> format (for <a href="https://en.wikipedia.org/wiki/LibreOffice_Calc">Calc</a> or <a href="https://www.r-project.org/">R</a>, if you fancy).</li>
</ul>
<p>It’s possible to merge results either by inserting data from an existing CSV file, or by appending data to a CSV file on saving.</p>
<h3>Recipes</h3>
<p>Here are a few tips on how you can use the tool to detect performance bottlenecks in text / code editors:</p>
<ul>
<li>Check whether number of lines influences the latency. If so, typing might “lag” inside a large file.</li>
<li>Check whether editor window size influences the latency. If so, the editor probably does excessive repainting instead of drawing only a newly inserted symbol.</li>
<li>Check whether latency depends on horizontal symbol position. Ideally, that correlation should be undetectable.</li>
<li>Try to enable highlighting / autocomplete / folding / spellchecker / etc. Those features should be processed asynchronously, without affecting the typing as such.</li>
<li>Try to run the test in power-saving mode. Ideally, typing should be handled decently even on less powerful hardware.</li>
</ul>
<p>If you’re implementing a text / code editor, take a look at the <a href="https://pavelfatin.com/low-latency-painting-in-awt-and-swing/">programming techniques</a> to significantly reduce the drawing latency.</p>
<h3>Troubleshooting</h3>
<p>To make benchmarking possible, correct screen metrics must be detected at the initial step. The program attempts to recognize a custom pattern (5 new dots) in order to determine the following parameters:</p>
<ul>
<li>starting position,</li>
<li>horizontal step,</li>
<li>background color,</li>
<li>line length,</li>
<li>caret type.</li>
</ul>
<p>Because there are many editors (and multiple versions of each editor), which looks different on different platforms, and there are many possible color schemes and fonts, the metrics recognition algorithm has to be very flexible. While the program sources contain a great deal of test cases, some glitches are still probable.</p>
<p>Here’s a list of typical problems and corresponding solutions:</p>
<ul>
<li>Editor background is non-uniform (gradient, picture) – set solid color background.</li>
<li>Characters are too low-contrast and obscure – use a crisp color scheme.</li>
<li>Dot characters merge with the caret – increase font size.</li>
<li>Editor replaces multiple dots with ellipsis – disable that auto-correction.</li>
<li>Spaces between dots are uneven – use <a href="https://en.wikipedia.org/wiki/Monospaced_font">monospaced font</a> in the editor.</li>
<li>Editor has a left panel that melds with the text area – hide the panel.</li>
</ul>
<p>Feel free to contribute by creating additional test case images (check <code>/src/test/resources</code> directory for examples).</p>
<p>See also:</p>
<ul>
<li><a href="https://pavelfatin.com/typing-with-pleasure/">Typing with pleasure</a> — Human- and machine aspects of typing latency, experimental data on latency of popular text / code editors.</li>
<li><a href="https://pavelfatin.com/low-latency-painting-in-awt-and-swing/">Low-latency painting in AWT and Swing</a> — In-depth analysis of delay sources in AWT / Swing architectures, methods to significantly reduce the drawing latency.</li>
</ul>

								<p>Tags: <a href="https://pavelfatin.com/tag/benchmark/" rel="tag">benchmark</a>, <a href="https://pavelfatin.com/tag/delay/" rel="tag">delay</a>, <a href="https://pavelfatin.com/tag/editor/" rel="tag">editor</a>, <a href="https://pavelfatin.com/tag/lag/" rel="tag">lag</a>, <a href="https://pavelfatin.com/tag/latency/" rel="tag">latency</a>, <a href="https://pavelfatin.com/tag/measure/" rel="tag">measure</a>, <a href="https://pavelfatin.com/tag/typing/" rel="tag">typing</a></p>
				<p>
					<small>
						This entry was posted
												on Sunday, December 20th, 2015 at 11:17 am						and is filed under <a href="https://pavelfatin.com/category/programming/" rel="category tag">Programming</a>, <a href="https://pavelfatin.com/category/software/" rel="category tag">Software</a>.
						You can follow any responses to this entry through the <a href="https://pavelfatin.com/typometer/feed/">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://pavelfatin.com/typometer/trackback/" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div></div>]]>
            </description>
            <link>https://pavelfatin.com/typometer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23952697</guid>
            <pubDate>Sat, 25 Jul 2020 21:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In a GPT-3 World, Anonymity Prevents Free Speech]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 78 (<a href="https://news.ycombinator.com/item?id=23952084">thread link</a>) | @riverlong
<br/>
July 25, 2020 | https://jayriverlong.github.io/2020/07/24/gpt3.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/07/24/gpt3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>What does it mean to have freedom of speech? Naively, it means that you have the right to express ideas without fear of governmental retaliation or censorship. But that’s not worth much in a vacuum. Free speech is valuable when you are communicating with others: abstractly, freedom of speech means the right to distribute information to an audience.</p> <p>If you frame freedom of speech not in terms of what comes out of your mouth, but in terms of the interaction between yourself and another party,<sup id="fnref:1"><a href="#fn:1">1</a></sup> then edge cases rapidly emerge. For example, suppose that you are on the street, lawfully raising a protest sign supporting X. You are hoping to persuade passers-by. The government sends in <em>five hundred</em> counter-protestors, peacefully raising <em>not X</em> signs. Your voice is drowned out in the crowd. You are unable to reach the passers-by; it’s as if you were not there. Is this censorship? I am no constitutional lawyer, but the effect is undeniably censorious – it is practically as if you had been sent home by the police.</p> <p>Historically, I haven’t seen this type of scenario give rise to much concern among constitutional scholars – perhaps for reasons of practicality. Perpetually mobilizing the <a href="https://en.wikipedia.org/wiki/Astroturfing">astroturf</a> brigades to drown out individual voices is hardly practically feasible.</p> <p>However, this has dangerously changed as discourse has moved online. The real-world constraints to astroturfing do not exist online. With <a href="https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/">GPT-3</a>, the marginal cost of distributing astroturfed propaganda online has firmly hit zero. GPT-3 represents the newest generation of text-generating AI, and it is extremely good – perfectly indistinguishable from a human in short form, articulate, detailed, and capable of infinite variety in style and tone. Now it is actually possible for any online group discussion to be brigaded by thousands of automated users – indistinguishable from real humans – twisting the conversation, while drowning out the voices of real humans.</p> <p>This will become common in no time. It’s too effective a weapon for malicious states to pass it up. Manual online astroturfing is already widespread. Both <a href="https://en.wikipedia.org/wiki/Internet_Water_Army">China</a> and <a href="https://en.wikipedia.org/wiki/Internet_Research_Agency">Russia</a> pay thousands of state employees to spread propaganda online. As <a href="https://en.wikipedia.org/wiki/Russian_interference_in_the_2016_United_States_elections">Russiagate</a> and the now widespread conspiracy theories on Antivax, 5G, COVID-19, etc. show, it’s very effective: social media platforms have enabled divide-and-conquer strategies at unprecedented scale and granularity. They have become a battleground for the opinions of people in the West, and these people haven’t realized it yet. Using fully automated, infinitely scalable tools to infect the minds of your opponents with malicious ideas and sow discord offers an unprecedentedly high ROI to the villains of the world.</p> <p>Thus, we are moving into a world where bad actors can interfere with free speech with a new form of censorship: the use of automated voices, indistinguishable from real ones, to overpower genuine voices online, and to shape the appearance of public discourse according to their goals. If you believe, as many scholars do, that democratic societies are critically reliant on your freedom to distribute information, then this poses a severe threat.</p> <p>The abstract problem is that on the internet, we don’t have a good way to tell real humans from fake ones. The current state-of-the-art tests are CAPTCHAs with challenges that “only humans could pass”: read the word, click all the squares with traffic lights, and so forth. Obviously these aren’t going to resist automation for long. They will be useless across the board in a few years, once general image recognition tools are as good as some substantial minority of humans.</p> <p>In the long term, AI will be effectively impossible to distinguish from humans online. The only solution is to use what we have and they don’t – real-world identification. A real-world ID could correspond to some set of private keys, so you could sign your online actions to prove their human authenticity. You could have a large number of private keys, so as to enable ample pseudonymity. However, true anonymity – not leveraging real-world identity in some sense – becomes impossible<sup id="fnref:2"><a href="#fn:2">2</a></sup> without opening up the possibility of mass creation of automated trolls.</p> <p>In conclusion: free speech is not just about freedom from straight-forward censorship, but about your ability to participate in discourse without state interference. GPT-3 marks a new generation of tools enabling states to interfere in online discourse with unprecedented scale and persuasiveness, enabling great damage at low cost. It is clear that on the internet, AI will become indistinguishable from genuine humans in the next few years. To that extent, we have to protect our freedom of speech. It seems like requiring real-world IDs and coupling them with public key cryptography is the only way out, which keeps pseudonymity but loses anonymity.</p> <p>Losing anonymity to protect free speech is counter-intuitive and somewhat repulsive. I believe in individual freedom as the highest ideal. I used to think anonymity was one of the greatest values provided by the internet. And I acknowledge that eliminating anonymity to protect free speech comes with its own issues in the long run: for example, a malicious government could abuse the real-world-ID-to-private-key link to very effectively crack down on free speech. I don’t <em>like</em> the solution I am advocating, but it’s a difficult trade-off.</p>  <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/07/24/gpt3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23952084</guid>
            <pubDate>Sat, 25 Jul 2020 20:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing stupid stuff with GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 43 (<a href="https://news.ycombinator.com/item?id=23952024">thread link</a>) | @spalas
<br/>
July 25, 2020 | https://devopsdirective.com/posts/2020/07/stupid-github-actions/ | <a href="https://web.archive.org/web/*/https://devopsdirective.com/posts/2020/07/stupid-github-actions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<h5>July 25, 2020</h5>
<strong>Categories:</strong>

<strong>Tags:</strong>

<p><strong>TL;DR:</strong> DevOps doesn’t have to be all work and no play. I built 5 stupid (but fun!) GitHub actions… because <em>why not</em>?</p>
<p>The full code for these actions can all be found in this <strong><a href="https://github.com/sidpalas/stupid-actions">GitHub repo</a></strong>. I encourage you to fork and/or add issues/PRs with impractical actions of your own!</p>
<p>I also recorded a video about this project on <strong><a href="https://www.youtube.com/watch?v=w7-ugGAYVCo">YouTube</a></strong>. ← Check out the video and subscribe if you are into this sort of thing 🙏</p>
<p><img src="https://devopsdirective.com/static/images/stupid-actions.png" alt="Whiteboard Screenshot"></p>
<hr>
<p><strong>Table of Contents:</strong></p>
<ul>
<li><a href="#what-is-github-actions">What is GitHub Actions?</a></li>
<li><a href="#the-actions">The Actions</a>
<ul>
<li><a href="#1----holiday-reminder">1 – Holiday Reminder</a></li>
<li><a href="#2----recursive-action">2 – Recursive Action</a></li>
<li><a href="#3----exponential-action">3 – Exponential Action</a></li>
<li><a href="#4----smart-lights">4 – Smart Lights</a></li>
<li><a href="#5----tic-tac-toe">5 – Tic-Tac-Toe</a></li>
</ul>
</li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<h2 id="what-is-github-actions">What is GitHub Actions?</h2>
<p>GitHub Actions is a CI/CD platform built into GitHub. It can be used to automate things such as building, testing, and deploying code and can be triggered by any GitHub event.</p>
<p>There is also a <a href="https://github.com/marketplace?type=actions">marketplace</a> where developers can publish their actions for others to use.</p>
<p>While I have used many CI/CD systems including Jenkins, Google Cloud Build, and CircleCI, prior to this project I hadn’t explored GitHub Actions, so I thought I would try it out and have some fun along the way.</p>
<p>Enough preamble, let’s get to the stupid stuff!</p>
<h2 id="the-actions">The Actions</h2>
<h3 id="1----holiday-reminder">1 – Holiday Reminder</h3>
<p>Starting simple with this first action, I take advantage of the fact that actions can be triggered on a cron schedule to create the following 10 line action:</p>
<div><pre><code data-lang="yaml"><span>name</span>: holiday-reminder-happy-new-year
<span>on</span>:
  <span>schedule</span>:
    - <span>cron</span>: <span>'0 0 1 1 *'</span>
<span>jobs</span>:
  <span>happy-new-year</span>:
    <span>runs-on</span>: ubuntu-latest
    <span>steps</span>:
    - <span>name</span>: throw error
      <span>run</span>: exit <span>1</span>
</code></pre></div><p>The action will run at midnight on New Year’s day and fail every time due to the non-zero exit code. This will cause GitHub to send me an email wishing me a Happy New Year 🎉🎉🎉.</p>
<h3 id="2----recursive-action">2 – Recursive Action</h3>
<p>The next idea was proposed by a friend and former colleague (<a href="https://scotchka.github.io/)">https://scotchka.github.io/)</a>. He suggested that I make an action which triggers itself, thus creating an infinite chain of actions.</p>
<p>Given that the GitHub documentation explicitly states <a href="https://docs.github.com/en/actions/reference/events-that-trigger-workflows#triggering-new-workflows-using-a-personal-access-token">“To minimize your GitHub Actions usage costs, ensure that you don’t create recursive or unintended workflow runs,"</a> this seemed like a sufficiently stupid idea. To achieve this, I created an action triggered by commits that makes and commits a code change of its own.</p>
<p>There are two interesting parts to this action:</p>
<ol>
<li>GitHub helps prevent users from accidentally doing this by not triggering actions based on events associated with the default <code>GITHUB_TOKEN</code>. In order to get around this, I created a <a href="https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token">personal access token</a>. See the <a href="https://github.com/sidpalas/stupid-actions/blob/master/.github/workflows/recursive.yml">action yaml file</a> for how this gets used.</li>
<li>In order to prevent the infinite action chain, I persist a count of the action executions within a file in the repo and increment it with each execution. This allows me to terminate the action chain when I reach a specified limit.</li>
</ol>
<div><pre><code data-lang="bash">COUNTER_FILE<span>=</span>./recursive/counter.txt
MAX_COUNT<span>=</span><span>5</span>

count<span>=</span><span>$(</span>cat <span>"</span>$COUNTER_FILE<span>"</span><span>)</span> 
<span>if</span> <span>(</span><span>(</span> $count &gt; $MAX_COUNT <span>)</span><span>)</span>;
<span>then</span> 
    echo <span>"Count too high... exiting"</span>;
<span>else</span>
    echo <span>"Count okay... continuing"</span>;
    echo <span>$((</span> $count <span>+</span> <span>1</span> <span>))</span> &gt; $COUNTER_FILE
    git config --global user.email <span>"<a href="https://devopsdirective.com/cdn-cgi/l/email-protection" data-cfemail="57243e3317333221382724333e253234233e21327934383a">[email&nbsp;protected]</a>"</span>
    git config --global user.name <span>"sid"</span>
    git add $COUNTER_FILE
    git commit -m <span>"Incremented counter file"</span>
    git push 
<span>fi</span>; 
</code></pre></div><h3 id="3----exponential-action">3 – Exponential Action</h3>
<p>The previous action has the potential to run indefinitely, but only one instance executes at a time, so it could be stopped manually if necessary. What if instead, the action triggered itself multiple times? This way, if it got out of hand there would be no stopping the exponential growth 😰. That sounds dumb… lets do it!</p>
<p>The file counter trick from before no longer works because multiple actions would be executing in parallel, all trying to modify and commit simultaneously causing conflicts. Instead, I stored the state in Git tags!</p>
<p>A random UUID is used as the base for the tag and the current iteration is appended to prevent collisions. The current implementation only support single digits, but if I make it past 9 iterations of exponential growth that means I messed up 💀.</p>
<div><pre><code data-lang="bash"><span>function</span> increment_tag_push <span>{</span>
    uuid<span>=</span><span>$(</span>uuidgen<span>)</span>
    suffix<span>=</span><span>$((</span> $count <span>+</span> <span>1</span> <span>))</span>
    tag<span>=</span>$1.$uuid.$suffix
    git tag -a $tag -m <span>"New UUID tag"</span>
    git push origin $tag
<span>}</span>

count<span>=</span><span>"</span><span>$(</span>echo -n $GITHUB_REF| tail -c 1<span>)</span><span>"</span>

echo $GITHUB_REF
echo $count

sleep <span>10</span> <span># In case something goes wrong (this saved me during development 😳)</span>
MAX_COUNT<span>=</span><span>2</span>

<span>if</span> <span>(</span><span>(</span> $count &gt; $MAX_COUNT <span>)</span><span>)</span>;
<span>then</span> 
    echo <span>"Count too high... exiting"</span>;
<span>else</span>
    echo <span>"Count okay... continuing"</span>;
    git config --global user.email <span>"<a href="https://devopsdirective.com/cdn-cgi/l/email-protection" data-cfemail="493a202d092d2c3f26393a2d203b2c2a3d203f2c672a2624">[email&nbsp;protected]</a>"</span>
    git config --global user.name <span>"sid"</span>
    <span>for</span> <span>(</span><span>(</span>i <span>=</span> 1; i &lt;<span>=</span> $1; i++ <span>)</span><span>)</span>;
    <span>do</span>
    increment_tag_push $i
    <span>done</span>
<span>fi</span>; 
</code></pre></div><p>If you are looking for a quick way to burn through your 2000 free tier minutes… this is definitely the way to go!</p>
<h3 id="4----smart-lights">4 – Smart Lights</h3>
<p>Thus far, these actions have been implemented in small bash scripts. In order to actually explore the capabilities of GitHub actions I decided the next action should utilize <a href="https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action">Docker</a>.</p>
<p>I had a couple of WiFi smart plugs from VeSync that I received as a gift a few years ago and found a <a href="https://pypi.org/project/pyvesync/">python client for their API</a>. This made it simple to create an action which turns the lights on for a short period of time after each commit (what better way to incentivize code velocity?!💡)</p>
<figure>
<img src="https://devopsdirective.com/posts/2020/07/stupid-github-actions/images/lights-off.gif" alt="images/lights-off.gif">
<figcaption>Lights on... Lights off!</figcaption>
</figure>
<p>The code for this one isn’t particularly interesting, but because the action is using more than just bash, it requires an <code>action.yml</code> file in which we can see how inputs get passed into the action:</p>
<div><pre><code data-lang="yaml"><span>name</span>: <span>'Turn on Lights'</span>
<span>description</span>: <span>'Turn on smart home lights for a few seconds'</span>
<span>inputs</span>:
  <span>VESYNC_PASS</span>:  
    <span>description</span>: password for VESYNC_PASS
    <span>required</span>: <span>true</span>
<span>runs</span>:
  <span>using</span>: <span>'docker'</span>
  <span>image</span>: <span>'Dockerfile'</span>
  <span>env</span>:
    <span>VESYNC_PASS</span>: ${{ inputs.VESYNC_PASS }}
</code></pre></div><h3 id="5----tic-tac-toe">5 – Tic-Tac-Toe</h3>
<p>With the team starting to get a bit burnt out having to commit code constantly just to keep the lights on, I decided to implement a game of Tic-tac-toe to let them burn off some steam. The trick is that the computer player for this game executes within an action!</p>
<figure>
<img src="https://devopsdirective.com/posts/2020/07/stupid-github-actions/images/tic-tac-toe.png" alt="images/tic-tac-toe.png">
<figcaption>Command line interface + board state file</figcaption>
</figure>
<p>I wanted to try out the <a href="https://docs.github.com/en/actions/creating-actions/creating-a-javascript-action">Javascript runtime</a>, so I built the game with Node, persisting the board state in a text file. Since the point of this game was to learn about actions the computer’s strategy is random, but this has the added benefit of letting the human win, boosting morale 🤔.</p>
<h2 id="closing-thoughts">Closing Thoughts</h2>
<p>Overall, GitHub Actions turned out to be fairly easy to work with and the option Dockerize the action steps ensures that it should be able to support pretty much any CI/CD need. Also, GitHub has made sharing and reuse of actions a core part of the experience through the Marketplace.</p>
<p>While I’m won’t be rushing off to port existing CI/CD workloads onto GitHub actions, I will certainly consider it for future greenfield projects!</p>
</article></div>]]>
            </description>
            <link>https://devopsdirective.com/posts/2020/07/stupid-github-actions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23952024</guid>
            <pubDate>Sat, 25 Jul 2020 20:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cryptography is not magic]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23949694">thread link</a>) | @loup-vaillant
<br/>
July 25, 2020 | http://loup-vaillant.fr/articles/crypto-is-not-magic | <a href="https://web.archive.org/web/*/http://loup-vaillant.fr/articles/crypto-is-not-magic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://loup-vaillant.fr/articles/crypto-is-not-magic</link>
            <guid isPermaLink="false">hacker-news-small-sites-23949694</guid>
            <pubDate>Sat, 25 Jul 2020 15:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ansible-Defined Homelab]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23949030">thread link</a>) | @0xC45
<br/>
July 25, 2020 | https://0xc45.com/blog/ansible-defined-homelab/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/ansible-defined-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<h2 id="overview">Overview</h2>
<p>Around November of last year, I started a project to wrangle my digital life. Tired of haphazardly increasing my subjectivity by trusting "free" websites to provide various services, I wanted to wrest some control over my internet existence. I made a plan to self-host several "critical" services on my home network and maintain them personally. In short, I made a homelab.</p>
<p>To be frank, the professional websites that I was previously dependent upon are undoubtedly more reliable than my cobbled-together hobby project of a homelab. However, on general principle (and because it seemed like a fun way to learn some sysadmin / devops skills), I made this setup:</p>
<p><img src="https://0xc45.com/blog/ansible-defined-homelab/homelab-network-diagram.svg" alt="Homelab Network Diagram"></p>
<p>As you can see, I have deployed a couple of general-purpose compute platforms: 4 ESXi hypervisors, and a Kubernetes cluster. Additionally, there are several VM-based services: Nextcloud, Gitea, and Harbor. For data storage and backup, I use a Synology NAS. Finally, a custom OpenBSD-based router provides internet connectivity to everything. In order to reduce operational overhead, I crafted <a href="https://github.com/0xC45/homelab-setup">a set of Ansible scripts</a> that deploy and configure all of these components.</p>
<p>Overall, making this setup has been quite a journey. In this blog post, I will describe my uses for each of these services, share my thoughts and experiences so far, and attempt to articulate my future improvement plans.</p>
<h2 id="motivation">Motivation</h2>
<p>Of course, everything you see above already exists as a service on the internet. If my goal were solely the end feature set, it would have been much simpler to pay for each service. In most cases, there are even "free" versions available. For example, if I only cared about having access to a web-based git repository UI, I could have signed up for a Github or Gitlab account rather than bother setting up a Gitea VM on my home network.</p>
<p>However, like most of my hobby projects, this endeavor was more about the journey than the destination. By setting up these services on my home network, I learned a bunch of useful devops and sysadmin skills. Additionally, by running my own services, I have achieved the philosophical goal of reducing my reliance on 3rd party services. Now, if any of the services that I rely upon break, I am empowered to fix them. I am no longer dependent on the "opaque box" that is Google Drive, for example.</p>
<h2 id="components">Components</h2>
<p>So, without further ado, let's dive into each of the components that make up my homelab. For each component, I will describe the main utility it provides me, why I chose it, and any additional commentary that may be helpful.</p>
<h3 id="router">Router</h3>
<p>The first component of my homelab is a custom OpenBSD-based router. It provides internet connectivity and DHCP to everything on my home network. Additionally, the device serves as a caching DNS server and firewall. I could write an entire blog post describing this router in excruciating detail. In fact, I <a href="https://0xc45.com/blog/openbsd-home-router/">already have</a>.</p>
<h3 id="esxi-hosts">ESXi Hosts</h3>
<p>In total, I maintain four physical <a href="https://www.vmware.com/products/esxi-and-esx.html">ESXi</a> hosts to form a platform for running virtual machines on my network.</p>
<p>Three of the ESXi hosts are Intel NUCs (System76 Meerkats). These smaller machines run the VMs that form my Kubernetes cluster.</p>
<p>The other ESXi host is a custom machine built from spare parts. It currently runs three VM-based HTTPS services: Nextcloud, Gitea, and Harbor. Because it only runs three (relatively small) VMs, it has quite a bit of spare compute power leftover for future additions and/or temporary experiments.</p>
<p>I chose ESXi to run my virtual machines because it's enterprise quality and free. There are many hypervisors out there. For my current use case, ESXi is perfect. Also, in the future, I may consider expanding my use of VMware products by running vCenter to programmatically manage virtual machines, setting-up vSAN for shared storage, and potentially installing NSX if my networking requirements become more complicated. So, there is room to grow.</p>
<h3 id="kubernetes-cluster">Kubernetes Cluster</h3>
<p>In addition to the VM-based compute platform provided by ESXi, I run Kubernetes to provide a container-based compute platform. Though I do not currently use my Kubernetes cluster for anything, I have plans to setup <a href="https://argoproj.github.io/">Argo CI/CD</a>, experiment with <a href="https://knative.dev/">kNative</a>, develop some operators, and maybe run a <a href="https://github.com/helm/charts/tree/master/stable/factorio">factorio game server</a>.</p>
<p>The Kubernetes cluster consists of 6 VMs running across 3 Intel NUCs. I chose to install Kubernetes on VMs with the ESXi hypervisor layer for ease of management. At some point, I'm sure to break things, want to reconfigure, etc. With the hypervisor, it's easier to perform these type of adjustments. Furthermore, at some point in the future, I may switch to <a href="https://tanzu.vmware.com/kubernetes-grid">TKG</a>, a vSphere-integrated distribution of Kubernetes.</p>
<h3 id="synology-nas">Synology NAS</h3>
<p>For backups and storing important data, I use a <a href="https://www.synology.com/en-global/products/DS218+">Synology NAS</a>. Though I didn't really shop around and compare NAS products / vendors, I am happy with the Synology so far. That being said, I would like to create my own NAS from scratch at some point in the future. However, the Synology product includes several features "out-of-the-box" that would be potentially difficult to replicate.</p>
<p>First, it has an easy-to-use application called <a href="https://www.synology.com/en-us/dsm/feature/active_backup_business">"Active Backup for Business"</a> that can automatically take backups of ESXi virtual machines following configurable schedules and retention policies.</p>
<p>The VM backup application pairs nicely with the automatic cloud backup application, <a href="https://www.synology.com/en-us/dsm/packages/GlacierBackup">"Glacier Backup"</a>. Every night, after the VMs are backed-up to the NAS, I replicate the backups to Amazon S3 Glacier. Hopefully, this way I won't ever lose data.</p>
<p>Finally, the Synology has built-in UPS integration. If <a href="https://www.apc.com/shop/us/en/products/APC-Power-Saving-Back-UPS-Pro-1500/P-BR1500G">my UPS</a> loses power for more than one minute, the NAS will cleanly shutdown, preventing any data corruption that could be caused by an unexpected power loss.</p>
<h3 id="nextcloud-vm">Nextcloud VM</h3>
<p>I use <a href="https://nextcloud.com/">Nextcloud</a> as my "personal cloud". I use it to store my important files and photos. The desktop / mobile application synchronizes the files across all of my devices, allowing me to edit and view my files from anywhere. </p>
<p>Nextcloud also has the capability to install "apps" that provide additional functionality. Currently, I have only installed one app, <a href="https://apps.nextcloud.com/apps/deck">"Deck"</a>. Deck is a Kanban-style project management and organization tool. I use Deck to plan, organize, and record progress on my hobby projects.</p>
<p>Because it gives me the capability to install (and potentially create) apps, Nextcloud is an extensible platform. It's open source and under active development. Though the recent major version upgrade was a bit rocky (for me, at least), I'm happy with Nextcloud and plan to stick with it.</p>
<h3 id="gitea-vm">Gitea VM</h3>
<p>Of course, I need a place to store my code. For that purpose, I use <a href="https://gitea.io/en-us/">Gitea</a>. I prefer Gitea to Gitlab because it's lighter-weight. Unlike Gitlab, there aren't a million additional features bundled-in that add bloat (in my opinion). Also, I slightly prefer the Gitea UI over the Gitlab UI.</p>
<p>There's really not much else to say about Gitea. It works great for my purposes. I push all of my code to the Gitea VM running on my home network. Whenever I want to "publish" a project or share it with the world, I push my code to a public Github repo.</p>
<h3 id="harbor-vm">Harbor VM</h3>
<p>To make container images available for running on my Kubernetes cluster, I need a container registry. For this purpose, I use <a href="https://goharbor.io/">Harbor</a>, an open source solution that seems to be the current most popular self-hosted container registry. In addition to providing a standard API for pushing/pulling container images, Harbor has the useful capability to scan container images for known vulnerabilities.</p>
<p>Harbor has worked well for me so far, but I haven't really placed it under a serious workload. Soon, I will start using my Kubernetes cluster for various projects, which will require pushing / pulling images from Harbor on a regular basis. Perhaps, at some point in the future, I will have a more nuanced opinion of Harbor.</p>
<h2 id="future-improvements">Future Improvements</h2>
<p>Though I am happy with the current setup, I continually find myself coming up with ideas for potential improvements and additions to the homelab. Here are a couple of the more well-defined ideas.</p>
<p>First, I want to install <a href="https://argoproj.github.io/">Argo</a> on the Kubernetes cluster to run pipeline-based workflows. For example, it could be useful to automatically run tests for every commit that gets pushed to my repositories on Gitea. More generally, I could configure Argo to trigger a job for any arbitrary external event. It could be used to create a notification service. Or, it could be used to manage heavy workloads. There are endless potential uses for a pipeline-based workflow engine such as Argo.</p>
<p>Second, I want to create a dashboard that provides a graphical representation of the status of each of my homelab components using <a href="https://grafana.com/">Grafana</a>. Using various open-source tools, I could collect metrics and aggregate them. Then, using Grafana, I could visualize the data. It would be useful to be able to quickly ascertain the state of my home network services in order to understand workloads, diagnose issues, etc.</p>
<h2 id="conclusion">Conclusion</h2>
<p>With the work spanning several months, creating my homelab has been quite a journey. Along the way, I started to grow weary, concerned that I had signed myself up for the all-consuming task of operating my homelab. With the overhead required to maintain all the various components, how could I ever have time for anything else? However, I'm happy to report that the Ansible script automation has proved worthwhile. Now, upgrades, configuration changes, and various "day 2" operations are quick and simple. At this point, I'm looking forward to shifting gears and working on something else for a while, using my homelab services as helpful tools along the way.</p>
<h2 id="links">Links</h2>
<ol>
<li>Homelab Ansible scripts: <a href="https://github.com/0xC45/homelab-setup">https://github.com/0xC45/homelab-setup</a></li>
<li>"OpenBSD Home Router" blog post: <a href="https://0xc45.com/blog/openbsd-home-router/">https://0xc45.com/blog/openbsd-home-router/</a></li>
</ol>

    </section></div>]]>
            </description>
            <link>https://0xc45.com/blog/ansible-defined-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23949030</guid>
            <pubDate>Sat, 25 Jul 2020 13:30:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Huawei Hacked My Laptop]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 20 (<a href="https://news.ycombinator.com/item?id=23948871">thread link</a>) | @realguybrush
<br/>
July 25, 2020 | https://sunburnt.com.au/huawei-hacked-my-laptop | <a href="https://web.archive.org/web/*/https://sunburnt.com.au/huawei-hacked-my-laptop">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://sunburnt.com.au/huawei-hacked-my-laptop">Huawei Hacked My Laptop?</a></p><p><img alt="" src="https://sunburnt.com.au/ox/webcore/attachments/29436/20200725_180027.huawei-xhost.png?width=500&amp;height=444"></p>

<p>The screenshot above shows a script called "Huawei Autorun" which executes the command "xhost +" when you login. This command makes your Linux desktop remotely accessible to anyone on the network. The "Huawei Autorun" script appeared on my laptop after installing a Huawei E353 HSPA+ 3G USB stick (with serial number CE0682 on the back).</p>

<p>It seems like I dodged a bullet as I don't use the standard Linux GNOME desktop, so the script was not enabled, but the fact remains that Huawei installed malware on my Linux laptop. If they managed to get into my laptop, imagine what is happening inside your phone.</p>

<p>State-sponsored hacking is real.</p>

<p><strong>----UPDATE----</strong></p>

<p>For those people who requested more information. The OS is Debian 8.1 LTS. The script is basically a one-liner embedded in an autostart launcher (see below). It was installed as root, so I must have screwed up big time there. Obviously, I'll&nbsp;have to reinstall my OS.&nbsp;Debian 8 is at end of life&nbsp;now anyway.</p>

<pre>$ cat /etc/xdg/autostart/HuaweiAutoStart.desktop 
[Desktop Entry]
Version=1.0
Encoding=UTF-8
Name=Huawei  AutoRun
Name[en_US]=Huawei AutoRun
<strong>Exec=xhost +</strong>
SwallowExec=
SwallowTitle=
Terminal=false
TerminalOptions=
Type=Application
URL=
X-KDE-SubstituteUID=false
X-GNOME-Autostart-enabled=true
GenericName[en_US]=</pre>

<p><strong>----UPDATE 2----</strong></p>

<p>Okay, I decided to check out this modem. It does include Linux drivers which require root for installation. I reran the installation script as root and sure enough the same autostart script was reinstalled.</p>

<pre>$ ls /etc/xdg/autostart/ -l
total 116
-rw-r--r-- 1 root root  305 Oct 10  2014 at-spi-dbus-bus.desktop
-rw-r--r-- 1 root root 6351 Oct 21  2014 gnome-keyring-gpg.desktop
-rw-r--r-- 1 root root 7777 Oct 21  2014 gnome-keyring-pkcs11.desktop
-rw-r--r-- 1 root root 7339 Oct 21  2014 gnome-keyring-secrets.desktop
-rw-r--r-- 1 root root 5996 Oct 21  2014 gnome-keyring-ssh.desktop
-rw-r--r-- 1 root root 7741 Aug 27  2014 gsettings-data-convert.desktop
<strong>-rwxr-xr-x 1 root root  262 Jul 25 23:59 HuaweiAutoStart.desktop</strong>
<span>....</span>
</pre>

<p>This script is also installed to <span>$HOME/.config/autostart/</span><span>HuaweiAutoStart.desktop</span>. Another script called <span>ReadDisplay</span> is&nbsp;installed in <span>/usr/local/modem</span> which&nbsp;passes the&nbsp;<span>$DISPLAY</span>&nbsp;environment variable to a binary&nbsp;called <span>MobilePartner</span>. The drivers do include a GUI, but if the sole purpose of all this is to fire up a GUI then it is not only exceptionally sloppy code, but also a&nbsp;security risk that needs explaining.</p>

<p>Below is a tarball image of the huawei e353 drivers so you can audit them for yourself. I've included the Windows drivers so you get an image of the disk just as I have it. Heck you could even try it for yourself. The drivers didn't compile the second time I did this, but the autostart script was still installed.</p>

<p><a href="https://sunburnt.com.au/ox/webcore/attachments/29437/huawei-e353-malware.tar.gz">Download huawei e353 drivers (warning, possible malware!)</a></p>

<p><strong>----UPDATE 3----</strong></p>

<p>I'm giving Huawei the benefit of doubt on this one. As a commenter suggested, it is probably a hack to run the GUI as root. Either way, it is still a nasty vulnerability, even if your X server is configured to use local sockets by default. I guess this&nbsp;shows the folly of blindly trusting hardware manufactures. I'll be sticking to open source code from official repositories in the future.</p>

<p>Live and learn, I suppose.</p>
<p><a href="https://sunburnt.com.au/huawei-hacked-my-laptop">Huawei Hacked My Laptop?</a></p><h2>About Sunburnt Technology</h2>

    </div><div>
      <p>Based on the article, I would think it is just a sloppy and lazy implementation, but the title does served as a bait clicker. The comment where avoiding pure chinese company or there is at least American company involved will be pure ignorance&nbsp;or turning a blind eye on what is happening around the world and purely cynical. Every country spying on people when they have the means and ways. So don't even think for a second that&nbsp;&nbsp;an American company involvement will make it any better. That will be pure ignorant.<br>
<a href="https://www.telegraph.co.uk/news/worldnews/northamerica/usa/10403598/35-world-leaders-had-their-phones-monitored-by-US-spies.html">https://www.telegraph.co.uk/news/worldnews/northamerica/usa/10403598/35-world-leaders-had-their-phones-monitored-by-US-spies.html</a></p>

    
  <p>It's more likely the package installed some graphical configuration tool that needs to run as root. Running "xhost +" is a lazy way to enable programs running as root to connect to your non-root user's X11 session.</p>

<p>I don't know what debian's default settings are regarding Xorg and networking, but on my laptop Xorg appears to only be listening on unix sockets, which are obviously not accessible from the whole network.</p>

    
  <blockquote>
<p><span>State-sponsored hacking is real.</span></p>
</blockquote>

<p><span>Yes. It's happening. 14 eyes (US+others) are also doing it. So I don't trust US services and devices either.</span></p>

<p><span>While they're banning each other of different things, open hardware is rising up and welcoming everyone (for example RISC V). We need things like this in this world to bring in peace so that they don't fight over silli things.</span></p>

    
  <p>Clean the system, you most likely found one piece of the drop. Replace the drive, looks to be a long weekend</p>

    
  <p>I avoid any pure Chinese tech, where possible. By law in China, all companies must work with the CCP (which means the military). Obviously, iPhones and such are made in China, although production is starting to move to other countries under Trump's trade policies, but at least there is an American company involved on the HW and SW sides.</p>

    
  <p>Did inserting the Huawei E353 dongle attach a virtual CD-ROM drive that you manually installed drivers from? I know for a fact similar devices (eg, ZTE MF910) offer drivers this way. The generic Linux USB ethernet driver worked fine, so there's no need to install Huawei or ZTE's driver.</p>

<p>It's worth mentioning USB On-The-Go devices (including Android phones and 4G modems) have relatively powerful processors running a wide variety of network services, including an insecure web server (for the end-user web configuration interface), high-precision location, a high bandwidth internet side-channel (the 4G connection itself) while also having the ability to act as any USB client device (including keyboards to send keystrokes). They are an incredibly powerful platform for targeted cyberattacks and I imagine state actors are using them very often.</p>

    </div></div>]]>
            </description>
            <link>https://sunburnt.com.au/huawei-hacked-my-laptop</link>
            <guid isPermaLink="false">hacker-news-small-sites-23948871</guid>
            <pubDate>Sat, 25 Jul 2020 13:03:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio from Scratch with Go: Stereo Panning]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23948661">thread link</a>) | @Insanity
<br/>
July 25, 2020 | https://dylanmeeus.github.io/posts/audio-from-scratch-pt4/ | <a href="https://web.archive.org/web/*/https://dylanmeeus.github.io/posts/audio-from-scratch-pt4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In the <a href="https://dylanmeeus.github.io/posts/audio-from-scratch-pt3/">previous post</a> we have written code to change the amplitude of wave files.</p>
<p>Now we’ll take a look at how we can turn a mono wave file into a stereo wave file with optional
panning, and explore how this is represented internally by the WAVE file format.</p>

<p>The raw audio data inside a WAVE file consists of multiple frames. For now, we have called them
‘samples’ although that is strictly speaking not entirely correct. In fact, single float in the raw
audio data only corresponds to a single sample when we assume a mono audio file.</p>
<p>When you have multiple channels, a single ‘sample’ can consist of multiple frames. As each channel
needs to play a certain ‘frame’ at any given point in time.</p>
<p>In the WAVE file format, the channels are interleaved. For example, a stereo file would be
laid out like this:</p>
<p><img src="https://dylanmeeus.github.io/audio/interleaving.png" alt=""></p>
<p>Here, each sample consists of two frames. Such that frame 1 and 2 make up sample 1, frame 3 and 4
make up sample 2, and so on..</p>
<p>Programs know how to interpret the raw audio data because of the <code>fmt</code> chunk inside the audio file,
which specifies the number of channels that are present in the raw audio data. The maximum number of
channels in a wave file is actually as high as 65,536, which does not actually make sense for audio
data.</p>
<p>Some common ones would be:</p>
<ul>
<li>1-channel: mono</li>
<li>2-channel: stereo</li>
<li>3-channel: stereo + center channel</li>
<li>4-channel: Quadrophonic</li>
<li>5-channel: “Surround sound”</li>
</ul>
<p>For convenience though, we’ll mostly work on mono and stereo files. Not only are they the most
commonly used, this also allows us to test our code without needing a more expensive setup.</p>

<p>So what is a pan? When you pan an audio signal, you essentially make an audio signal ‘louder’ on
either the left or the right side. Typically in a <a href="https://en.wikipedia.org/wiki/Digital_audio_workstation">DAW</a> this would be represented by an ‘automation
track’ between the value of -1 to 1.</p>
<p>The program to apply a pan will take three parameters:</p>
<ul>
<li>input file</li>
<li>output file</li>
<li>pan (-1 to 1)</li>
</ul>
<p>For the input file we will restrict this to mono files, and for the output files we will always
generate a stereo file. The pan variable should be between -1 (left) and 1 (right). Before we can
start applying our pan, we need to read the raw audio data from an input wave file. Remember that to
read the wave file we will use the <a href="https://github.com/DylanMeeus/GoAudio">GoAudio</a> library we made
earlier:</p>
<div><pre><code data-lang="go"><span>import</span> (
        <span>wav</span> <span>"github.com/DylanMeeus/GoAudio/wave"</span>
)
</code></pre></div><p>The set up for this program is rather simple, we will use the build-in <code>flags</code> package to parse the
input from the CLI.</p>
<div><pre><code data-lang="go"><span>var</span> (
	<span>input</span>  = <span>flag</span>.<span>String</span>(<span>"i"</span>, <span>""</span>, <span>"input file"</span>)
	<span>output</span> = <span>flag</span>.<span>String</span>(<span>"o"</span>, <span>""</span>, <span>"output file"</span>)
	<span>pan</span>    = <span>flag</span>.<span>Float64</span>(<span>"p"</span>, <span>0.0</span>, <span>"pan in range of -1 (left) to 1 (right)"</span>)
)
</code></pre></div><p>Once we have our flags set up, we can parse them and read the input file.</p>
<div><pre><code data-lang="go"><span>func</span> <span>main</span>() {
	<span>flag</span>.<span>Parse</span>()
	<span>infile</span> <span>:=</span> <span>*</span><span>input</span>
	<span>outfile</span> <span>:=</span> <span>*</span><span>output</span>
	<span>panfac</span> <span>:=</span> <span>*</span><span>pan</span>
	<span>wave</span>, <span>err</span> <span>:=</span> <span>wav</span>.<span>ReadWaveFile</span>(<span>infile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		panic(<span>"Could not parse wave file"</span>)
	}
        <span>...</span>
}
</code></pre></div><p>So far so good. We have parsed the input so we know which value to use for our pan, and we have read
the raw audio data as well. But how do we go from a value in the range of (-1) to (1) to an actual
change in loudness on the left or right-side? We can imagine that a simple function would look like
this:</p>
<div><pre><code data-lang="go"><span>type</span> <span>panposition</span> <span>struct</span> {
	<span>left</span>, <span>right</span> <span>float64</span>
}

<span>func</span> <span>calculatePosition</span>(<span>position</span> <span>float64</span>) <span>panposition</span> {
	<span>position</span> <span>*=</span> <span>0.5</span>
	<span>return</span> <span>panposition</span>{
		<span>left</span>:  <span>position</span> <span>-</span> <span>0.5</span>,
		<span>right</span>: <span>position</span> <span>+</span> <span>0.5</span>,
	}
}
</code></pre></div><p>Here we are using a struct that can represent the amplitude on a scale of 0 to 1 for both the left
and right channel. Such that we observe the following values:</p>
<table>
<thead>
<tr>
<th>position</th>
<th>left-channel</th>
<th>right-channel</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.5</td>
<td>0.5</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>-1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>In other words, if the position is zero the sound is perfectly balanced between the left and
right-side of your headphones. And in the extreme values, the sound is either only left-sided or
right-sided.</p>
<p>Just like in the previous post, we actually need to alter the frames based on the position data we
found in the <code>calculatePosition</code> function. We can create a function that modifies the frames based
on the <code>panposition</code> returned in the previous function.</p>
<div><pre><code data-lang="go"><span>func</span> <span>applyPan</span>(<span>frames</span> []<span>wav</span>.<span>Frame</span>, <span>p</span> <span>panposition</span>) []<span>wav</span>.<span>Frame</span> {
	<span>out</span> <span>:=</span> []<span>wav</span>.<span>Frame</span>{}
	<span>for</span> <span>_</span>, <span>s</span> <span>:=</span> <span>range</span> <span>frames</span> {
		<span>out</span> = append(<span>out</span>, <span>wav</span>.<span>Frame</span>(float64(<span>s</span>)<span>*</span><span>p</span>.<span>left</span>))
		<span>out</span> = append(<span>out</span>, <span>wav</span>.<span>Frame</span>(float64(<span>s</span>)<span>*</span><span>p</span>.<span>right</span>))
	}
	<span>return</span> <span>out</span>
}
</code></pre></div><p>Notice how for each <code>frame</code> we actually append two <code>frames</code> to the resulting slice! That is how we
are interleaving the left and right audio channel.</p>
<p>Now we can finish up the main method:</p>
<div><pre><code data-lang="go">        <span>...</span>
	<span>pos</span> <span>:=</span> <span>calculatePosition</span>(<span>panfac</span>)
	<span>scaledFrames</span> <span>:=</span> <span>applyPan</span>(<span>wave</span>.<span>Frames</span>, <span>calculatePosition</span>(<span>panfac</span>))
	<span>wave</span>.<span>NumChannels</span> = <span>2</span> <span>// samples are now stereo, so we need dual channels
</span><span></span>	<span>if</span> <span>err</span> <span>:=</span> <span>wav</span>.<span>WriteFrames</span>(<span>scaledFrames</span>, <span>wave</span>.<span>WaveFmt</span>, <span>outfile</span>); <span>err</span> <span>!=</span> <span>nil</span> {
		panic(<span>err</span>)
	}
</code></pre></div><p>A crucial step here is that before writing the samples we have set ran <code>wave.NumChannels=2</code>. Without
this, the wave file would be interpreted as a mono sound file and our panning effect would have been
lost.</p>

<p>To test this, I find it easy to use an input file without a lot of things going on. I’m mainly using
this simple <a href="https://dylanmeeus.github.io/audio/part4/mono.wav">mono file</a>.</p>
<p>If we run <code>go run main.go -i mono.wav -o left-side.wav -p -1</code> we get:</p>
<p><a href="https://dylanmeeus.github.io/audio/part4/left-side.wav">left-side.wav</a></p>
<p>And when we  run <code>go run main.go -i mono.wav -o right-side.wav -p 1</code> we get:</p>
<p><a href="https://dylanmeeus.github.io/audio/part4/right-side.wav">right-side.wav</a></p>

<p>There is actually a flaw with this panning function that we are using. However it is not apparent to
us yet because we can only set a pan for an entire audio source. To see why this panning function is
not perfect we need to first introduce breakpoints as a way to create automation tracks, so the focus for our next few posts will be
breakpoints. :-)</p>
<hr>

<ul>
<li><a href="https://github.com/DylanMeeus/GoAudio">GoAudio</a></li>
<li><a href="https://github.com/DylanMeeus/GoAudio/blob/master/examples/stereopan/main.go">Panning code</a></li>
</ul>
<hr>
<p>If you liked this and want to know when I write new posts, the best way to keep up to date is by <a href="https://twitter.com/DylanMeeus">following me on
twitter</a>. ;-)</p>

  </div></div>]]>
            </description>
            <link>https://dylanmeeus.github.io/posts/audio-from-scratch-pt4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23948661</guid>
            <pubDate>Sat, 25 Jul 2020 12:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Frame: Build web apps in ClojureScript and React]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23948579">thread link</a>) | @tosh
<br/>
July 25, 2020 | http://day8.github.io/re-frame/ | <a href="https://web.archive.org/web/*/http://day8.github.io/re-frame/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Build web apps, in ClojureScript, leveraging React.</p>
          <p>Leverages a data-oriented, functional design.</p>
          <p>Advanced enough to have outlasted three generations of Javascript technical churn.</p>
          <p>Excellent developer productivity. Fewer lines of code. Hot code reloading.  A simple dynamic model. Managed effects, including state. Pure functions. Variously declarative.</p>
          <p>The more sophisticated your app, the better.</p>
        </div></div>]]>
            </description>
            <link>http://day8.github.io/re-frame/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23948579</guid>
            <pubDate>Sat, 25 Jul 2020 12:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need (and don't need) to know about PHP's type system]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23948114">thread link</a>) | @nawarian
<br/>
July 25, 2020 | https://thephp.website/en/issue/php-type-system/ | <a href="https://web.archive.org/web/*/https://thephp.website/en/issue/php-type-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div>
<p><time datetime="2020-07-25">
2020-07-25
</time></p>
<p><strong>PHP is a dynamically typed scripting language</strong> and until the year
of 2015 php had no support for statically declared types at all. One
could cast to scalar types explicitly in the code, but declaring scalar
types in methods and functions signatures wasn't a thing until PHP 7.0
with the <a href="https://wiki.php.net/rfc/scalar_type_hints_v5">Scalar Type Declarations</a>
and <a href="https://wiki.php.net/rfc/return_types">Return Type Declarations</a> rfcs.</p>
<p>This doesn't mean that from version 7.0 PHP became a statically typed
language, though. <strong>It has type hinting that can be analyzed statically</strong>
but <strong>it still supports dynamic types</strong> and even allows them to be mixed.
See the example below:</p>
<pre><code>&lt;?php

function returnsInt(): int
{
  return '100';
}</code></pre>
<p>No doubt that <strong>there's a type mismatch there</strong>. The return type is
supposed to be <em>int</em> and the returned type is in fact a <em>string</em>. Now,
what PHP does there is to automatically transform the token '100'
into an integer in order to return the required type. Even though it
seems to have an extra cost, it doesn't. PHP's type juggling is <em>nearly</em>
cost-free in many cases.</p>
<p>To better clarify how the language deals with types I'll split this article
into the following sections:</p>
<ul>
<li><a href="#kinds-of-types-in-php">Kinds of types in php</a></li>
<li><a href="#type-operations-in-php">Type "operations" in php</a></li>
<li><a href="#union-types">Union Types</a></li>
<li><a href="#php-type-juggling">PHP's type juggling</a></li>
<li><a href="#php-type-modes">PHP type modes</a></li>
</ul>
<p>If you have suggestions on what to add here, feel free to
<a href="https://twitter.com/nawarian">reach out to me on twitter</a> or opening an issue on
github.</p>
<h2 id="kinds-of-types-in-php">Kinds of types in php</h2>
<p>PHP's type system is very simplified when it comes to language features.
For example there's no <em>char</em> type, or <em>unsigned</em> types or even <em>int8</em>,
<em>int16</em>, <em>int32</em>, <em>int64</em>...</p>
<p>The <em>char</em> type is simplified to a string type and all <em>integer</em> variations
are simplified into an <em>integer</em> type. Whether that's a good or bad thing, is
up to you.</p>
<p>One can always inspect a variable's type using the
<a href="https://www.php.net/manual/en/function.gettype">gettype()</a> function or using
the <a href="https://www.php.net/manual/en/function.var-dump">var_dump()</a> function and
checking its output.</p>
<p>PHP comes with three different kinds of types: <strong>scalar types</strong>, <strong>compound types</strong>
and <strong>special types</strong>.</p>
<h3>Scalar types</h3>
<p>Scalar types are the bare bones of the language and they are four:</p>
<ul>
<li>Boolean (<code>bool</code> | <code>boolean</code>)</li>
<li>Integer (<code>int</code> | <code>integer</code>)</li>
<li>Float (<code>float</code> | <code>double</code>)</li>
<li>String (<code>string</code>)</li>
</ul>
<p>By definition scalar types do not carry behaviour or state with themselves.
Expressions like <code>100-&gt;toString()</code> or <code>'thephp.website'::length()</code> are invalid.</p>
<p><strong>Main takeaway: scalar values do not have behaviour or state, they just represent
a value.</strong></p>
<h3>Compound types</h3>
<p>Compound types are much more interesting because even though they are very similar
to the scalar type, <strong>each one of the four compound types carry different syntactic
capabilities.</strong></p>
<p>The four compound types are:</p>
<ul>
<li><a href="#compound-type-array">array</a></li>
<li><a href="#compound-type-object">object</a></li>
<li><a href="#compound-type-callable">callable</a></li>
<li><a href="#compound-type-iterable">iterable</a></li>
</ul>
<h4 id="compound-type-array">The array compound type</h4>
<p>An array is in fact a hashmap, built-in to the language. Meaning that it stores
values in a <strong>key =&gt; value</strong> manner. Even if you use it purely as a vector.</p>
<p>Arrays are very flexible structures when it comes to size, internal types and
key-value mapping. The examples below are all valid arrays:</p>
<pre><code>&lt;?php

$vec = [0, 1, 2];
// $vec[1] is int(1)

$map = ['a' =&gt; 1, 'b' =&gt; 2];
// $map['a'] is int(1)

$map_ish = ['a' =&gt; 1, 0 =&gt; 2];
// $map_ish['a'] is int(1)
// $map_ish[0] =&gt; is int(2)</code></pre>
<p>Unlike C, php won't require you to define an array's size before creating it.
This of course comes with a memory consumption cost: the bigger your array size,
the more memory you'll consume in crazy proportions (in fact, arrays are allocated in powers of two).
How this consumption works is out of the scope of this article,
<a href="https://twitter.com/nawarian">feel free to ping me if you'd like to hear more</a>.</p>
<p>In case you're curious about this statement, the video below presents some charts
and further insights on arrays vs. object memory profiles.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/JBWgvUrb-q8?start=1000" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><iframe style="margin: auto; margin-bottom: 20px;" width="560" height="315" src="https://www.youtube.com/embed/JBWgvUrb-q8?start=1000" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>As you'll see bellow, arrays are also considered to be of type <em>iterable</em>, meaning
that you can iterate over them using a <em>foreach</em> loop. But they also provide
<a href="https://www.php.net/manual/en/ref.array.php">specific functions that can manipulate their internal pointers</a>.</p>
<p><strong>Main takeaway: array is an extremely flexible compound type that can be perceived
as a HashMap and is also considered an iterable type.</strong></p>
<h4 id="compound-type-object">The object compound type</h4>
<p>Due to php's architecture, the <em>object</em> compound type normally has a much lower memory
consumption profile when compared with arrays. That's because <em>normally</em> one would use
the object type by creating instances of classes.</p>
<p>Objects can carry state and behaviour. Meaning that php will offer dereferencing
language structs to access an object's internals. The snippet below illustrates
a php object's derefs:</p>
<pre><code>&lt;?php

class MyClass
{
  private const A = 1;
  public int $property = 0;
  public function method(): void {}
}

$obj = new MyClass();
// $obj is object(MyClass)
// $obj::A is int(1)
// $obj-&gt;property is int(0)
// $obj-&gt;method() is null</code></pre>
<p>An object can also be normally created as a result of a type cast from an array.
Transforming an array's keys into objects property names. Such cast will always
result in an <code>object(stdClass)</code> type.</p>
<pre><code>&lt;?php

$obj = (object) ['a' =&gt; 1];
// $obj is object(stdClass)
// $obj-&gt;a is int(1)</code></pre>
<p>Important to notice that casting an array with numeric keys into an object is valid,
but one can't dereference its value because property names may not start with numbers.</p>
<pre><code>&lt;?php

$obj = (object) [0, 1]; // Legal
$obj-&gt;0; // Illegal</code></pre>
<p><strong>Main takeaway: objects normally have lower memory profiles than arrays, they carry
state and behaviour, they all inherit from stdClass and can be created by casting an
array.</strong></p>
<h4 id="compound-type-callable">The callable compound type</h4>
<p>A callable in php is anything that can be called (oh don't you say!!) with parenthesis
or with the <a href="https://www.php.net/manual/en/function.call-user-func.php">call_user_func()</a>
function. In other words, a callable can fulfil the responsibility of what we know as
functions. Functions and methods are always callables. Objects and classes may also become
callables.</p>
<p>A callable can, by definition, have its reference stored in a variable. Like the following:</p>
<pre><code>&lt;?php

$callable = 'strlen';</code></pre>
<p>What? But that's a string, no?</p>
<p>Well, yes. But it can be coerced into a callable if necessary. Like below:</p>
<pre><code>&lt;?php

function callACallable(
  callable $f
): int {
  return $f('thephp.website');
}

$callable = 'strlen';

var_dump(
  $callable('thephp.website')
);
// int(14)

var_dump(
  callACallable($callable)
);
// int(14)</code></pre>
<p>Callables may also point to object methods:</p>
<pre><code>&lt;?php

class MyClass
{
  public function myMethod(): int
  {
    return 1;
  }
}

$obj = new MyClass();
var_dump([$obj, 'myMethod']());
// int(1)</code></pre>
<p>Looks odd? I know it looks like an array. In fact it is. Unless you name it a callable 👀</p>
<p>This kind of callable above (object-method reference) is very interesting because
<strong>you can call private or protected methods</strong> with it <strong>if you're inside the class' scope.</strong>
Otherwise you may only call public methods with it.</p>
<p>Also classes that implement
<a href="https://www.php.net/manual/en/language.oop5.magic.php#object.invoke">the __invoke() magic method</a>,
automatically transform their instances into callables themselves. Like the following:</p>
<pre><code>&lt;?php

class MyCallableClass
{
  public function __invoke(): int
  {
    return 1;
  }
}

$obj = new MyCallableClass();
var_dump($obj());
// int(1)</code></pre>
<p><strong>Main takeaway: callables hold reference to functions or methods and can be
constructed in different ways.</strong></p>
<h4 id="compound-type-iterable">The iterable compound type</h4>
<p>Iterables are simpler to explain: they are by definition an array or an instance of
the <a href="https://www.php.net/manual/en/class.traversable.php">Traversable interface</a>. The
main thing of an iterable is that it can be used in a
<a href="https://www.php.net/manual/en/control-structures.foreach.php">foreach() loop</a>, with a
<a href="https://www.php.net/manual/en/language.generators.syntax.php#control-structures.yield.from">yield from statement</a>
or with <a href="https://wiki.php.net/rfc/spread_operator_for_array">spread operator</a>.</p>
<p>Examples of iterables are:</p>
<pre><code>&lt;?php

function generator_function(): Generator
{
  // ...
};

// All variables here are iterables
$a = [0, 1, 2];
$b = generator_function();
$c = new ArrayObject();</code></pre>
<p><strong>Main takeaway: if you can fit it in a foreach(), it is an iterable.</strong></p>
<h3>Special Types</h3>
<p>There are two special types. And the biggest reason why they're called special, is that
<strong>you can't cast these types</strong>. The special types are both the <strong>resource</strong> type and
the <strong>NULL</strong> type.</p>
<p><strong>A resource represents a handle to an external resource</strong>. It can be a file handle,
an I/O stream or a database connection handle. You may guess now why you can't convert
a resource to any other type.</p>
<p><strong>The null type represents a null value</strong>. Meaning that a variable holding NULL was not
initialized, assigned to NULL or unset during runtime.</p>
<p><strong>Main takeaway: a special typed value can't be casted to anything.</strong></p>
<h3>What about class instances?</h3>
<p>Class instances have the type <code>object</code> and will always be presented like so. Executing
<a href="https://www.php.net/manual/en/function.gettype">gettype()</a> on an object will always return
a <code>string("object")</code> and calling <a href="https://www.php.net/manual/en/function.var-dump">var_dump()</a>
on an object will always print its value using the <code>object(ClassName)</code> notation. If you need
to fetch an object's class as a string, use the
<a href="https://www.php.net/manual/en/function.get-class">get_class()</a> function.</p>
<pre><code>&lt;?php

$obj = new stdClass();

echo gettype($obj);
// object

var_dump($obj);
// object(stdClass)#1 (0) {
// ...

echo get_class($obj);
// \stdClass</code></pre>
<h2 id="type-operations-in-php">Type "operations" in php</h2>
<p>There are different "operations" one can do with PHP when it comes to types. I believe
it is important to clearly state them here so that we don't mix things up later on.</p>
<h3>Type juggling: type casting and coercion</h3>
<p>Before we dive in, here are three important definitions we need keep in mind:</p>
<ol>
<li><strong>Type conversion</strong> means to transform a type from A to B. For example: from integer to float.</li>
<li><strong>Type cast</strong> means to <strong>manually</strong> or <strong>explicitly</strong> convert a type from A to B. As in <code>$hundred = (int) 100.0</code>. (<code>float(100.0)</code> became <code>int(100)</code>)</li>
<li><strong>Type coercion</strong> means to <strong>implicitly</strong> convert a type from A to B. As in <code>$twenty = 10 + '10 bananas';</code>. (<code>string("10 bananas")</code> became <code>int(10)</code>)</li>
</ol>
<p>Being that said, the following sections explain how it happens in php. Later on you'll find
more information on Type Juggling.</p>
<h4>Type casting</h4>
<p>Similar to what Java does, php allows type casting. Meaning that when a variable points to
a value that can be casted to a different type, it allows manual (explicit) type conversion.</p>
<p>Wait, wait. What!? 🤨</p>
<p>Given a variable <code>$hundred</code> holding a <code>string("100")</code> its value may be manually converted (casted)
to become an <code>int(100)</code> or a <code>float(100.00)</code> - or any other scalar type or one of compound
types <em>array</em> or <em>object</em>.</p>
<p>The following snippet works just fine in PHP and is very similar to Java:</p>
<pre><code>&lt;?php

$hundred = (int) '100';
// $hundred is now int(100)</code></pre>
<p>Now, one thing Java does and is completely illegal on php code, is to …</p></iframe></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephp.website/en/issue/php-type-system/">https://thephp.website/en/issue/php-type-system/</a></em></p>]]>
            </description>
            <link>https://thephp.website/en/issue/php-type-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23948114</guid>
            <pubDate>Sat, 25 Jul 2020 10:36:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wayland and LVGL on PinePhone with Ubuntu Touch]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 46 (<a href="https://news.ycombinator.com/item?id=23947176">thread link</a>) | @lupyuen
<br/>
July 24, 2020 | https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland | <a href="https://web.archive.org/web/*/https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

        <!-- Begin scripts/rustdoc-before.html: Pre-HTML for Custom Markdown files processed by rustdoc, like chip8.md -->

    <!-- Begin Theme Picker -->
    
    
    
    <!-- Theme Picker -->

    <!-- End scripts/rustdoc-before.html -->
    

    
    <nav id="TOC"><ul>
<li><a href="#how-x11-works">1 How X11 works</a><ul></ul></li>
<li><a href="#wayland-on-ubuntu-touch">2 Wayland on Ubuntu Touch</a><ul></ul></li>
<li><a href="#render-opengl-graphics-with-wayland">3 Render OpenGL Graphics with Wayland</a><ul></ul></li>
<li><a href="#get-egl-context-from-wayland">4 Get EGL Context from Wayland</a><ul></ul></li>
<li><a href="#build-and-test-wayland-app-on-linux">5 Build and Test Wayland App on Linux</a><ul></ul></li>
<li><a href="#fetch-wayland-interfaces">6 Fetch Wayland Interfaces</a><ul></ul></li>
<li><a href="#render-opengl-bitmap-texture-with-wayland">7 Render OpenGL Bitmap Texture with Wayland</a><ul></ul></li>
<li><a href="#lvgl-toolkit-for-graphical-user-interfaces">8 LVGL Toolkit for Graphical User Interfaces</a><ul></ul></li>
<li><a href="#port-lvgl-to-wayland">9 Port LVGL to Wayland</a><ul></ul></li>
<li><a href="#build-lvgl-on-pinephone-with-ubuntu-touch">10 Build LVGL on PinePhone with Ubuntu Touch</a><ul></ul></li>
<li><a href="#inject-lvgl-into-file-manager-app">11 Inject LVGL into File Manager App</a><ul></ul></li>
<li><a href="#run-lvgl-on-pinephone-with-ubuntu-touch">12 Run LVGL on PinePhone with Ubuntu Touch</a><ul></ul></li>
<li><a href="#overcome-apparmor-security-on-ubuntu-touch">13 Overcome AppArmor Security on Ubuntu Touch</a><ul></ul></li>
<li><a href="#what-i-like-about-ubuntu-touch-on-pinephone">14 What I like about Ubuntu Touch on PinePhone</a><ul>
<li><a href="#ubports-on-ubuntu-touch-wayland-and-mir">14.1 UBports on Ubuntu Touch, Wayland and Mir</a><ul></ul></li>
<li><a href="#gnome-and-gtk-on-wayland">14.2 GNOME and GTK on Wayland</a><ul></ul></li>
<li><a href="#wayland-on-xfce">14.3 Wayland on Xfce</a><ul></ul></li></ul></li>
<li><a href="#whats-next">15 What's Next?</a><ul></ul></li>
<li><a href="#configure-ssh-on-pinephone">16 Configure SSH on PinePhone</a><ul>
<li><a href="#generate-ssh-keys">16.1 Generate SSH Keys</a><ul></ul></li>
<li><a href="#install-ssh-keys">16.2 Install SSH Keys</a><ul></ul></li>
<li><a href="#start-ssh-service">16.3 Start SSH Service</a><ul></ul></li></ul></li>
<li><a href="#copy-files-from-microsd-card-on-pinephone">17 Copy Files from MicroSD Card on PinePhone</a><ul></ul></li>
<li><a href="#build-and-test-lvgl-app-on-linux">18 Build and Test LVGL App on Linux</a><ul></ul></li></ul></nav><p><img src="https://lupyuen.github.io/images/wayland-title.jpg" alt="Work-in-progress LVGL GUI Framework ported to Wayland EGL on PinePhone with Ubuntu Touch"></p>
<p><em>Work-in-progress LVGL GUI Framework ported to Wayland EGL on PinePhone with Ubuntu Touch</em></p>
<p><strong>We ❤️ &nbsp; Old Underwear...</strong></p>
<p>They feel comfy, they fit our contours. Nevermind the holes and the old stains 🤢</p>
<p><strong>X11 is like Old Underwear.</strong> It's been around for 30 years... Yet we still use it in spite of its feature gaps and wonky quirks.</p>
<p><a href="https://wiki.pine64.org/PinePhone"><strong>PinePhone on Ubuntu Touch feels like... New Underwear.</strong></a></p>
<p>It runs Linux but it has none of the legacy X11 code. Because it's optimised for a great mobile experience with <strong>Wayland.</strong></p>
<p>But New Underwear feels uncomfortable. So today we'll learn Wayland and understand how apps are built with Wayland.</p>
<p>Hopefully someday we'll move on to newer, simpler app frameworks (like <a href="https://lvgl.io/">LVGL</a> and Flutter) as we discard our Old Underwear: X11, SDL, GTK, Qt, ...</p>
<p>The source code for this article may be found here...</p>
<ul>
<li>
<p><a href="https://github.com/lupyuen/lvgl-wayland"><code>github.com/lupyuen/lvgl-wayland</code></a></p>
</li>
<li>
<p><a href="https://github.com/lupyuen/pinephone-mir"><code>github.com/lupyuen/pinephone-mir</code></a></p>
</li>
</ul>

<p><a href="https://en.wikipedia.org/wiki/X_Window_System">X11</a> is the Graphical Display Service that runs on most Linux desktops and notebooks.</p>
<p>Let's hunt for the X11 Service on Pinebook Pro...</p>
<p><img src="https://lupyuen.github.io/images/wayland-pinebook.png" alt="X11 Service on Pinebook Pro"></p>
<p>That's the X11 Service... A <strong>2.2 MB</strong> executable named <strong><code>Xorg</code></strong>. </p>
<p>The X11 Service controls the rendering of Linux apps (as well as the keyboard and mouse input) like this...</p>
<p><img src="https://lupyuen.github.io/images/wayland-x11.png" alt="X11 Architecture"></p>
<p>(Adapted from <a href="https://wayland.freedesktop.org/architecture.html">"Wayland Architecture"</a>)</p>
<ol>
<li>
<p>At the top we have the Linux programs running on our Linux machine: <strong>Terminal, Editor, Web Browser</strong>.</p>
<p>Each program renders its graphical display and transmits the raw graphics to the X11 Service (via a local TCP socket).</p>
</li>
<li>
<p>X11 Service forwards the rendered graphics to the <a href="https://en.wikipedia.org/wiki/Compositing_window_manager"><strong>Window Manager / Compositor</strong></a>.</p>
<p>The Window Manager / Compositor is provided by the <strong>Desktop Environment</strong>: Xfce, KDE, Gnome, ...</p>
</li>
<li>
<p>The Window Manager / Compositor wraps the rendered graphics into Display Windows and <strong>"decorates"</strong> them with scrollbars, title bar and minimise / maximise / close buttons.</p>
<p>The Window Manager / Compositor then draws the Display Windows into a <strong>Screen Buffer</strong> according to their screen coordinates.</p>
</li>
<li>
<p>The Screen Buffer is rendered to our screen by the X11 Service, talking to the <strong>Linux Display Driver</strong>.</p>
</li>
<li>
<p>Any <strong>keyboard and mouse input</strong> is captured by the X11 Service, and forwarded to the programs.</p>
</li>
</ol>
<p><em>Why is X11 so complex? So many hops?</em></p>
<p>Because X11 was designed for Distributed Computing Systems.</p>
<p>Here's how I used (abused?) X11R4 at <a href="http://srg.cs.illinois.edu/">UIUC Systems Research Group</a> way back in 1990 (30 years ago!)...</p>
<p><img src="https://lupyuen.github.io/images/wayland-uiuc.png" alt="Distributed X11 System"></p>
<p>Thankfully things are a lot simpler now, lemme explain...</p>

<p><em>Do we need overlapping or tiled windows on PinePhone?</em></p>
<p><em>Do we need to need to decorate PinePhone windows with a title bar and minimise / maximise / close buttons?</em></p>
<p><em>Do we even need any windows on PinePhone?</em></p>
<p>No! Because each PinePhone app takes control of the entire screen!</p>
<p>PinePhone uses a simpler Graphical Display Service: the <a href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)#Wayland_compositors"><strong>Wayland Compositor</strong></a>.</p>
<p>Let's hunt for the Wayland Compositor on PinePhone...</p>
<p><img src="https://lupyuen.github.io/images/wayland-compositor.png" alt="Wayland Compositor on PinePhone"></p>
<p>That's the Wayland Compositor... A <strong>262 KB</strong> executable named <code>unity-system-compositor</code>. </p>
<p><em>Compare that with the 2.2 MB X11 Server on Pinebook Pro!</em></p>
<p>Here's how the Wayland Compositor controls apps and touchscreen input on PinePhone with Ubuntu Touch...</p>
<p><img src="https://lupyuen.github.io/images/wayland-arch.png" alt="Wayland Architecture"></p>
<p>(Adapted from <a href="https://wayland.freedesktop.org/architecture.html">"Wayland Architecture"</a> and <a href="https://en.wikipedia.org/wiki/EGL_(API)">"EGL API"</a>)</p>
<ol>
<li>
<p>At the top we have the apps running on our phone: <strong>Terminal, Editor, Web Browser</strong>.</p>
<p>Since each app runs fullscreen, only the active app will be rendered.</p>
<p>When then app starts, it queries the <strong>Wayland Compositor</strong> for the graphical display interfaces available. (They talk via a <a href="https://en.wikipedia.org/wiki/Unix_file_types#Socket">Linux socket file</a>: <code>/run/user/32011/wayland-0</code>)</p>
</li>
<li>
<p>Wayland Compositor returns the <a href="https://en.wikipedia.org/wiki/EGL_(API)"><strong>EGL Interface</strong></a> to the app.</p>
</li>
<li>
<p>App calls the EGL Interface to <a href="https://en.wikipedia.org/wiki/OpenGL"><strong>render OpenGL graphics</strong></a> directly to the <strong>Linux Display Driver</strong>.</p>
</li>
<li>
<p>Linux Display Driver forwards the OpenGL rendering commands to the <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit"><strong>GPU to update the screen</strong></a>.</p>
</li>
<li>
<p>Any <strong>touchscreen input</strong> is captured by the Wayland Compositor, and forwarded to the active app.</p>
</li>
</ol>
<p>Wayland looks so much simpler and faster than X11!</p>
<p><em>Wayland is designed for OpenGL and GPUs?</em></p>
<p>Yes! And I lied about Wayland being New Underwear... Wayland is not really that New!</p>
<p>Wayland was first released in 2008 (<a href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)">11 years ago</a>)... Yet it was designed around OpenGL and GPUs, the same tech that powers our beautiful games today. (<a href="https://youtu.be/DNBk9hnPkTY">And websites too</a>)</p>
<p>Read on to learn how to render our own OpenGL graphics with Wayland and Ubuntu Touch on PinePhone...</p>
<p><img src="https://lupyuen.github.io/images/wayland-egl.jpg" alt="Rendering a yellow rectangle with Wayland and OpenGL on PinePhone"></p>
<p><em>Rendering a yellow rectangle with Wayland and OpenGL on PinePhone</em></p>

<p>Here's the function that calls OpenGL to render the yellow box above: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L44-L60"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Render the OpenGL ES2 display
static void render_display() {
    //  Fill the rectangular region with yellow
    glClearColor(
        1.0,  //  Red
        1.0,  //  Green
        0.0,  //  Blue
        1.0   //  Alpha
    );
    glClear(GL_COLOR_BUFFER_BIT);

    // Render now
    glFlush();
}
</code></pre>
<p><code>render_display()</code> looks exactly like normal OpenGL, and it works on PinePhone with Wayland! (Thanks to Ubuntu Touch)</p>
<p>Two things to note...</p>
<ol>
<li>
<p>PinePhone supports a popular subset of OpenGL, known as <a href="https://en.wikipedia.org/wiki/OpenGL_ES"><strong>OpenGL for Embedded Systems</strong></a> Version 2.0.</p>
<p>OpenGL ES is optimised for Embedded Devices. It's used by many mobile and console games today.</p>
</li>
<li>
<p>To render OpenGL ES graphics, we need to get the <strong>OpenGL ES Context</strong> and <strong>Window Surface</strong> from Wayland</p>
</li>
</ol>
<p>Before calling <code>render_display()</code>, we fetch the OpenGL Window Surface from Wayland like so: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L167-L189"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Dimensions of the OpenGL region to be rendered
static int WIDTH  = 480;
static int HEIGHT = 360;

static struct wl_egl_window *egl_window;  //  Wayland EGL Window
static EGLSurface egl_surface;            //  EGL Surface

//  Create the EGL Window and render OpenGL graphics
static void create_window(void) {
    //  Create an EGL Window from a Wayland Surface 
    egl_window = wl_egl_window_create(surface, WIDTH, HEIGHT);
    assert(egl_window != EGL_NO_SURFACE);  //  Failed to create OpenGL Window

    //  Create an OpenGL Window Surface for rendering
    egl_surface = eglCreateWindowSurface(egl_display, egl_conf,
        egl_window, NULL);
    assert(egl_surface != NULL);  //  Failed to create OpenGL Window Surface

    //  Set the current rendering surface
    EGLBoolean madeCurrent = eglMakeCurrent(egl_display, egl_surface,
        egl_surface, egl_context);
    assert(madeCurrent);  //  Failed to set rendering surface

    //  Render the display
    render_display();

    //  Swap the display buffers to make the display visible
    EGLBoolean swappedBuffers = eglSwapBuffers(egl_display, egl_surface);
    assert(swappedBuffers);  //  Failed to swap display buffers
}
</code></pre>
<p>Functions named <code>wl_egl_...</code> are provided by the Wayland EGL Interface.  Functions named <code>egl...</code> come from the cross-platform <a href="https://docs.mesa3d.org/egl.html#:%7E:text=The%20main%20library%20(%20libEGL%20)%20is,directly%20dispatched%20to%20the%20drivers.">Mesa 3D Graphics Library</a>.</p>
<p><em>EGL vs OpenGL... What's the difference?</em></p>
<p>In Wayland, EGL is the Enabler for OpenGL. </p>
<p>Wayland only understands EGL and it will gladly hand us EGL objects... But it's up to us to transform EGL into OpenGL for rendering.</p>
<p>Thus in the code above, we take a Wayland Surface <code>surface</code> and transform it into an EGL Window <code>egl_window</code>...</p>
<pre><code>//  Create an EGL Window from a Wayland Surface 
egl_window = wl_egl_window_create(surface, WIDTH, HEIGHT);
</code></pre>
<p>Then we create an OpenGL Window Surface <code>egl_surface</code> from that EGL Window...</p>
<pre><code>//  Create an OpenGL Window Surface for rendering
egl_surface = eglCreateWindowSurface(egl_display, egl_conf,
    egl_window, NULL);
</code></pre>
<p>And we begin the OpenGL rendering...</p>
<pre><code>//  Set the current rendering surface
eglMakeCurrent(egl_display, egl_surface,
    egl_surface, egl_context);

//  Render the display
render_display();

//  Swap the display buffers to make the display visible
eglSwapBuffers(egl_display, egl_surface);
</code></pre>
<p>Here's how we create a Wayland Region for OpenGL rendering: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L103-L112"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>static struct wl_region *region;  //  Wayland Region

//  Create the Wayland Region for rendering OpenGL graphics
static void create_opaque_region(void) {
    //  Create a Wayland Region
    region = wl_compositor_create_region(compositor);
    assert(region != NULL);  //  Failed to create EGL Region

    //  Set the dimensions of the Wayland Region
    wl_region_add(region, 0, 0, WIDTH, HEIGHT);

    //  Add the Region to the Wayland Surface
    wl_surface_set_opaque_region(surface, region);
}
</code></pre>
<p>To learn more about EGL, check out <a href="https://jan.newmarch.name/Wayland/EGL/">"Programming Wayland Clients"</a></p>
<p>The Wayland EGL code in this article was adapted from that document.</p>

<p>Earlier in <code>create_window()</code> we called an <strong>EGL Context</strong> <code>egl_context</code> to render OpenGL graphics.</p>
<p>Here's how we get the EGL Context: <a href="https://github.com/lupyuen/pinephone-mir/blob/master/egl.c#L113-L165"><code>pinephone-mir/egl.c</code></a></p>
<pre><code>/// Wayland EGL Interfaces for OpenGL Rendering
static EGLDisplay egl_display;  //  EGL Display
static EGLConfig  egl_conf;     //  EGL Configuration
static EGLContext egl_context;  //  EGL Context

//  Create the EGL Context for rendering OpenGL graphics
static void init_egl(void) {
    //  Attributes for our EGL Display
    EGLint config_attribs[] = {
        EGL_SURFACE_TYPE,    EGL_WINDOW_BIT,
        EGL_RED_SIZE,        8,
        EGL_GREEN_SIZE,      8,
        EGL_BLUE_SIZE,       8,
        EGL_RENDERABLE_TYPE, EGL_OPENGL_ES2_BIT,
        EGL_NONE
    };
    static const EGLint context_attribs[] = {
        EGL_CONTEXT_CLIENT_VERSION, 2,
        EGL_NONE
    };

    //  Get the EGL Display
    egl_display = eglGetDisplay((EGLNativeDisplayType) display);
    assert(egl_display != EGL_NO_DISPLAY);  //  Failed to get …</code></pre></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland">https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland</a></em></p>]]>
            </description>
            <link>https://lupyuen.github.io/pinetime-rust-mynewt/articles/wayland</link>
            <guid isPermaLink="false">hacker-news-small-sites-23947176</guid>
            <pubDate>Sat, 25 Jul 2020 06:02:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of the Palace of Axayácatl and a house built by Cortés are discovered]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23946877">thread link</a>) | @Thevet
<br/>
July 24, 2020 | https://www.inah.gob.mx/boletines/9259-remains-of-the-palace-of-axayacatl-and-a-house-built-by-order-of-cortes-are-discovered-in-monte-de-piedad-building | <a href="https://web.archive.org/web/*/https://www.inah.gob.mx/boletines/9259-remains-of-the-palace-of-axayacatl-and-a-house-built-by-order-of-cortes-are-discovered-in-monte-de-piedad-building">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.inah.gob.mx/boletines/9259-remains-of-the-palace-of-axayacatl-and-a-house-built-by-order-of-cortes-are-discovered-in-monte-de-piedad-building</link>
            <guid isPermaLink="false">hacker-news-small-sites-23946877</guid>
            <pubDate>Sat, 25 Jul 2020 04:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom filters debunked: Dispelling 30 Years of bad math with Coq]]>
            </title>
            <description>
<![CDATA[
Score 460 | Comments 125 (<a href="https://news.ycombinator.com/item?id=23946793">thread link</a>) | @gopiandcode
<br/>
July 24, 2020 | https://gopiandcode.uk/logs/log-bloomfilters-debunked.html | <a href="https://web.archive.org/web/*/https://gopiandcode.uk/logs/log-bloomfilters-debunked.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org5efdc67">
<p>
There's this rather nifty feature of modern web browsers (such as
<b>Firefox</b> or <b>Chrome</b>) where the browser will automatically warn the
user if they happen to navigate to a "<i>malicious</i>" URL:
</p>

<p><img src="https://gopiandcode.uk/images/malicious-site.png" alt="malicious-site.png">
</p> 


<p>
While <i>conceptually</i> simple, this feature actually requires more
engineering effort than one would expect - in particular, tracking the
set of known malicious URLs in a practical manner turns out to be
somewhat difficult.
</p>

<p>
This is because, on one hand, trying to store the database of <i>all</i>
known malicious URLs, which, bear in mind, may contain <i>millions and
millions</i> of entries, is something that is just practically
infeasible for most users. </p><p><img src="https://gopiandcode.uk/images/database_local.png" alt="database_local.png"> </p>


<p>
Conversely, sending <i>every</i> URL that a user visits to some external
service, where it could be <i>logged</i> and <i>data-mined</i> by nefarious
third parties, is something that most users should
probably not be comfortable with.
</p>

<p>
As it turns out, browsers actually implement this functionality by
means of a rather interesting <i>compromise</i><sup><a id="fnr.1" href="#fn.1">1</a></sup>.
</p>

<p>
Using a probabilistic data structure known as a <b>Bloom filter</b>,
Browsers maintain a approximate representation of the set of known
malicious URLs locally.  By querying this <i>space-efficient</i> local set,
browsers will only send up a <i>small proportion</i> of the honest URLs.
</p>

<p><b><i>Use a Bloom filter to act as a local proxy for queries to an external database</i>.</b>
</p>


<p>
This proxy technique, which safe-guards the privacy of millions of
users ever day, depends on <b>two key properties</b> of Bloom filters:
</p>

<dl>
<dt>No false negatives</dt><dd>This states that if a query for an URL in the
Bloom filter returns negative, then the queried item can be
guaranteed to not be present in the set of malicious URLs - i.e
<i>the Bloom filter is guaranteed to return a positive result for
all known malicious URLs</i>.</dd>

<dt>Low false positive rate</dt><dd>This property states that for any URL
that is <i>not in the set of malicious</i> URLs, the likelihood of a
Bloom filter query returning a positive result should be <i>fairly
low</i> - thus minimising the number of <i>unnecessary</i> infractions on
user privacy.</dd>
</dl>


<p>
This mechanism works <i>quite</i> well, and the guarantees of a Bloom filter
seem to be perfectly suited for this particular task, however it has
one small problem, and that is:
</p>

<p><b><i>The</i> widely cited expression <i>for the</i> false positive rate <i>of a bloom filter is</i> wrong!</b>
</p>


<p>
In fact, as it turns out, the behaviours of a Bloom filter have
actually been the subject of 30 years of mathematical contention,
requiring <i>multiple</i> corrections and even <i>corrections of these
corrections</i>.
</p>

<p>
<b>Given this history of errors, can we really have any certainty in our
understanding of a Bloom filter at all?</b>
</p>

<p>
Well, <i>never fear</i>, I am writing this post to inform you that we have
just recently used <code>Coq</code> to produce the <i>very first</i> <b>certified</b> proof
of the false positive rate of a Bloom filter, finally putting an end to
this saga of errors and returning certainty (pardon the pun<sup><a id="fnr.2" href="#fn.2">2</a></sup>) to a
mechanism that countless people rely on <i>every single</i> day.
</p>

<p>
In the rest of this post, we'll explore the main highlights of this
research, answering the following questions:
</p>
<ul>
<li>What is a Bloom filter?</li>
<li>Why did these errors initially arise?</li>
<li>What is the true behaviour of a Bloom filter? and how can we be certain?</li>
</ul>


<p>
This research was just recently presented at CAV2020 under the title
"Certifying Certainty and Uncertainty in Approximate Membership Query
Structures", you can find the paper <a href="https://www.springerprofessional.de/en/certifying-certainty-and-uncertainty-in-approximate-membership-q/18186934">here</a>, and a video presentation of
it <a href="https://invidio.us/D80VCsVeCMs?t=4482">here</a>.
</p>

<p>
The code and proofs used in this research project are FOSS, and can be
found on the Ceramist repo: <a href="https://github.com/certichain/ceramist">https://github.com/certichain/ceramist</a>
</p>
</div></div>]]>
            </description>
            <link>https://gopiandcode.uk/logs/log-bloomfilters-debunked.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23946793</guid>
            <pubDate>Sat, 25 Jul 2020 04:15:00 GMT</pubDate>
        </item>
    </channel>
</rss>
