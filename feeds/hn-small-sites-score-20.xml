<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 23 Oct 2020 04:32:51 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 23 Oct 2020 04:32:51 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[What ORMs Have Taught Me: Just Learn SQL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 187 (<a href="https://news.ycombinator.com/item?id=24845300">thread link</a>) | @IA21
<br/>
October 20, 2020 | https://wozniak.ca/blog/2014/08/03/1/ | <a href="https://web.archive.org/web/*/https://wozniak.ca/blog/2014/08/03/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>
I’ve come to the conclusion that, for me, ORMs are more detriment than
benefit. In short, they can be used to nicely augment working with SQL
in a program, but they should not replace it.
</p>

<p>
Some background: For the past 30 months I’ve been working with code
that has to interface with Postgres and to some extent, SQLite. Most
of that has been with <a href="http://sqlalchemy.org/">SQLAlchemy</a> (which I quite like) and <a href="http://hibernate.org/">Hibernate</a>
(which I don’t). I’ve worked with existing code and data models, as
well as designing my own. Most of the data is event-based storage
(“timelines”) with a heavy emphasis on creating reports.
</p>

<p>
Much has been written about the Object/Relational Impedance
Mismatch. It’s hard to appreciate it until you live it. Neward, in his
<a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">well known essay</a>, lays out many cogent reasons why ORMs turn into
quagmires. In my experience, I’ve had to deal directly with a fair
number of them: <i>entity identity issues</i>, <i>dual-schema problem</i>, <i>data
retrieval mechanism concern</i>, and the <i>partial-object problem</i>. I want to
talk briefly about my experiences with these issues and add one of my
own.
</p>

<div id="outline-container-orge4f50a6">
<h2 id="orge4f50a6">Partial objects, attribute creep, and foreign keys</h2>
<div id="text-orge4f50a6">
<p>
Perhaps the most subversive issue I’ve had with ORMs is “attribute
creep” or “wide tables”, that is, tables that just keep accruing
attributes. As much as I’d like to avoid it, sometimes it becomes
necessary (although things like <a href="http://www.postgresql.org/docs/9.3/interactive/hstore.html">Postgres’ hstore</a> can help). For
example, a client may be providing you with lots of data that they
want attached to reports based on various business logic. Furthermore,
you don’t have much insight into this data; you’re just schlepping it
around.
</p>

<p>
This in and of itself isn’t a terrible thing in a database. It becomes
a real pain point with an ORM. Specifically, the problem starts to
show up in any query that uses the entity directly to create the
query. You may have a Hibernate query like so early on in the project.
</p>

<pre>query(Foo.class).add(Restriction.eq("x", value))
</pre>

<p>
This may be fine when Foo has five attributes, but becomes a data fire
hose when it has a hundred. This is the equivalent of using <code>SELECT
*</code>, which is usually saying more than what is intended. ORMs, however,
encourage this use and often make writing precise projections as
tedious as they are in SQL. (I have optimized such queries by adding
the appropriate projection and reduced the run time from minutes to
seconds; all the time was spent translating the database row into a
Java object.)
</p>

<p>
Which leads to another bad experience: the pernicious use of foreign
keys. In the ORMs I’ve used, links between classes are represented in
the data model as foreign keys which, if not configured carefully,
result in a large number of joins when retrieving the object. (A
recent count of one such table in my work resulted in over 600
attributes and 14 joins to access a single object, using the preferred
query methodology.)
</p>

<p>
Attribute creep and excessive use of foreign keys shows me is that in
order to use ORMs effectively, you still need to know SQL. My
contention with ORMs is that, if you need to know SQL, just use SQL
since it prevents the need to know how non-SQL gets translated to SQL.
</p>
</div>
</div>

<div id="outline-container-org2d7e33d">
<h2 id="org2d7e33d">Data retrieval</h2>
<div id="text-org2d7e33d">
<p>
Knowing how to write SQL becomes even more important when you attempt
to actually write queries using an ORM. This is especially important
when efficiency is a concern.
</p>

<p>
From what I’ve seen, unless you have a really simple data model (that
is, you never do joins), you will be bending over backwards to figure
out how to get an ORM to generate SQL that runs efficiently. Most of
the time, it’s more obfuscated than actual SQL.
</p>

<p>
And if you elect to keep the query simple, you end up doing a lot of
work in the code that could be done in the database faster. <a href="https://en.wikipedia.org/wiki/Window_function_%28SQL%29#Window_function">Window
functions</a> are relatively advanced SQL that is painful to write with
ORMs. Not writing them into the query likely means you will be
transferring a lot of extra data from the database to your
application.
</p>

<p>
In these cases, I’ve elected to write queries using a templating
system and describe the tables using the ORM. I get the convenience of
an application level description of the table with direct use of
SQL. It’s a lot less trouble than anything else I’ve used so far.
</p>
</div>
</div>

<div id="outline-container-org05d550b">
<h2 id="org05d550b">Dual schema dangers</h2>
<div id="text-org05d550b">
<p>
This one seems to be one of those unavoidable redundancies.  If you
try to get rid of it, you only make more problems or add excessive
complexity.
</p>

<p>
The problem is that you end up having a data definition in two places:
the database and your application.  If you keep the definition
entirely in the application, you end up having to write the SQL Data
Definition Language (DDL) with the ORM code, which is the same
complication as writing advanced queries in the ORM.  If you keep it
in the database, you will probably want a representation in the
application for convenience and to prevent too much “string typing”.
</p>

<p>
I much prefer to keep the data definition in the database and read it
into the application.  It doesn’t solve the problem, but it makes it
more manageable.  I’ve found that reflection techniques to get the
data definition are not worth it and I succumb to managing the
redundancy of data definitons in two places.
</p>

<p>
But the damn migration issue is a real kick in the teeth: changing the
model is no big deal in the application, but a real pain in the
database.  After all, databases are persistent whereas application
data is not.  ORMs simply get in the way here because they don’t help
manage data migration at all.  I work on the principle that the
database’s data definitions aren’t things you should manipulate in the
application.  Instead, manipulate the results of queries.  That is,
the queries are your API to the database.  So instead of thinking
about objects, I think about functions with return types.
</p>

<p>
Thus, one is forced to ask, should you use an ORM for anything but
convenience in making queries?
</p>
</div>
</div>

<div id="outline-container-org7033826">
<h2 id="org7033826">Identities</h2>
<div id="text-org7033826">
<p>
Dealing with entity identities is one of those things that you have to
keep in mind at all times when working with ORMs, forcing you to write
for two systems while only have the expressivity of one.
</p>

<p>
When you have foreign keys, you refer to related identities with an
identifier. In your application, “identifier” takes on various
meanings, but usually it’s the memory location (a pointer). In the
database, it’s the state of the object itself. These two things don’t
really get along because you can really only use database identifiers
in the database (the ultimate destination of the data you’re working
with).
</p>

<p>
What this results in is having to manipulate the ORM to get a database
identifier by manually flushing the cache or doing a partial commit to
get the actual database identifier.
</p>

<p>
I can’t even call this a leaky abstraction because the work “leak”
implies small amounts of the contents escaping relative to the source.
</p>
</div>
</div>

<div id="outline-container-orgddbdda4">
<h2 id="orgddbdda4">Transactions</h2>
<div id="text-orgddbdda4">
<p>
Something that Neward alludes to is the need for developers to handle
transactions. Transactions are dynamically scoped, which is a powerful
but mostly neglected concept in programming languages due to the
confusion they cause if overused.  This leads to a lot of boilerplate
code with exception handlers and a careful consideration of where
transaction boundaries should occur.  It also makes you pass session
objects around to any function/method that might have to communicate
with the database.
</p>

<p>
The concept of a transaction translates poorly to applications due to
their reliance on context based on time. As mentioned, dynamic scoping
is one way to use this in a program, but it is at odds with lexical
scoping, the dominant paradigm. Thus, you must take great care to know
about the “when” of a transaction when writing code that works with
databases and can make modularity tricky (“Here’s a useful function
that will only work in certain contexts”).
</p>

<p>
Where do I see myself going?
</p>

<p>
At this point, I’m starting to question the wisdom behind the outright
rejection of <a href="http://c2.com/cgi/wiki?StoredProcedures">stored procedures</a>.  It sounds <a href="http://c2.com/cgi/wiki?StoredProceduresAreEvil">heretical</a>, but it may work
for my use cases.  (And hey, with the advent of “devops”, the divide
between the developer and the database administrator is basically
non-existent.)
</p>

<p>
I’ve found myself thinking about the database as just another data
type that has an API: the queries.  The queries return values of some
type, which are represented as some object in the program. By moving
away from thinking of the objects in my application as something to be
stored in a database (the raison d’être for ORMs) and instead thinking
of the database as a (large and complex) data type, I’ve found working
with a database from an application to be much simpler. And wondering
why I didn’t see it earlier.
</p>

<p>
(It should be made clear that I am not claiming this is how all
applications should deal with a database.  All I am saying is that
this fits my use case based on the data I am working with.)
</p>

<p>
Regardless of whether I find that stored procedures aren’t actually
that evil or whether I keep using templated SQL, I do know one thing:
I won’t fall into the “ORMs make it easy” trap. They are an acceptable
way to represent a data definition, but a poor way to write queries
and a bad way to store object state. If you’re using an RDBMS, bite
the bullet and learn SQL.
</p>

<p>
August 03, 2014
</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wozniak.ca/blog/2014/08/03/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845300</guid>
            <pubDate>Wed, 21 Oct 2020 06:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AOC plays Among Us live on Twitch and has 330k viewers]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24844474">thread link</a>) | @tomashertus
<br/>
October 20, 2020 | https://www.twitch.tv/aoc | <a href="https://web.archive.org/web/*/https://www.twitch.tv/aoc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/aoc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844474</guid>
            <pubDate>Wed, 21 Oct 2020 03:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Jamstack is failing at comments]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24844172">thread link</a>) | @leoloso
<br/>
October 20, 2020 | https://leoloso.com/posts/jamstack-failing-at-comments/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/jamstack-failing-at-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few weeks ago I added <a href="https://wptavern.com/matt-mullenweg-clarifies-jamstack-remarks#comment-344626">this comment in WPTavern</a>, on an article where WordPress founder's Matt Mullenweg clarifies his earlier remarks that the Jamstack is "a regression for the vast majority of the people adopting it".</p><p>Since I like owing my own content, I reproduce it here in my own blog.</p><hr><p>I think Matt’s brutal honesty is welcome, because most information out there about the Jamstack praises it. However, it also comes from developers using these modern new tools, evaluating their own convenience and satisfaction. As Matt points out, that doesn’t mean it makes it easier for the end user to use the software, which is what WordPress is good at.</p><p>I actually like the Jamstack, but because of how complex it is, it’s rather limiting, even to support some otherwise basic functionality.</p><p>The definitive example is comments, which should be at the core websites building communities. WordPress is extremely good at supporting comments in the site. The Jamstack is sooooo bad at it. In all these many years, nobody has been able to solve comments for the Jamstack, which for me evidences that it is inherently unsuitable to support this feature.</p><p>All attempts so far have been workarounds, not solutions. Eg:</p><ul><li>Netlify forms: no hierarchy, so can post a comment but not a response (unless adding some meta to the comment body? how ugly is that?)</li><li>Storing comments in a GitHub repo: it takes a long time to merge the PR with the comment</li></ul><p>Also, all these solutions are overtly complicated. Do I need to set-up a webhook to trigger a new build just to add a comment? And then, maybe cache the new comment in the client’s LocalStorage for if the user refreshes the page immediately, before the new build is finished? Seriously?</p><p>And then, they don’t provide the killer feature: to send notifications of the new comment to all parties involved in the discussion. That’s how communities get built, and websites become successful. Speed is a factor. But more important than speed, it is dynamic functionality to support communities. The website may look fancy, but it may well become a ghost town.</p><p>(Btw, as an exercise, you can research which websites started as WordPress and then migrated to the Jamstack, and check how many comments they had then vs now… the numbers will, most likely, be waaaaaaay down)</p><p>Another way is to not pre-render the comments, but render them dynamically after fetching it with an API. Yes, this solution works, but then you still have WordPress (or some other CMS) in the back-end to store the comments :P</p><p>The final option is to use 3rd parties such as Disqus to handle this functionality for you. Then, I will be sharing my users’ data with the 3rd party, and they may use it who knows how, and for the benefit of who (most likely, not my users’). Since I care about privacy, that’s a big no for me.</p><p>As a result, my own blog, which is a Jamstack site, doesn’t support comments! What do I do if I want feedback on a blog post? I add a link to a corresponding tweet, asking to add a comment there. I myself feel ashamed at this compromise, but given my site’s stack, I don’t see how I can solve it.</p><p>I still like my blog as a Jamstack, though, because it’s fast, it’s free, and I create all the blog posts in Markdown using VSCode. But I can’t create a community! So, as Matt says, there are things the Jamstack can handle. But certainly not everything. And possibly, not the one(s) that enable your your website to become successful.</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/jamstack-failing-at-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844172</guid>
            <pubDate>Wed, 21 Oct 2020 02:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditioned Texas Garage Lab – 1 year later]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24842218">thread link</a>) | @monstermunch
<br/>
October 20, 2020 | https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/ | <a href="https://web.archive.org/web/*/https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.networkprofile.org/content/images/size/w300/2020/10/2020-10-20-14.21.11.JPG 300w,
                            https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.21.11.JPG 600w,
                            https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.21.11.JPG 1000w,
                            https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG" alt="Unconditioned Texas Garage Lab - 1 year later (Its all fine)">
            </figure>

            <section>
                <div>
                    <p>A little over a year ago I mounted a rack in my garage, threw a Cisco Switch in there, an APC UPS and my Flight Tracking setup, and a second ESXi host. See below for the original:</p><figure><a href="https://blog.networkprofile.org/mounting-a-network-rack-in-my-garage/"><div><p>Garage Network Rack with 10G Fiber</p><p>This details my 12u rack in my detached garage which has a 10G uplink to my mainnetwork I needed some networking in my detached garage for an access point, my flighttracking setup, 3 x PoE cameras and some future additions, and instead ofrunning multiple Cat6 cables across, I decided to just run…</p><p><img src="https://blog.networkprofile.org/favicon.ico"><span>NetworkProfile.org</span></p></div><p><img src="https://blog.networkprofile.org/content/images/2020/01/ndEotkV-1.jpg"></p></a></figure><p>Its been through the "cold" of a Houston Winter and the heat and humidity of the brutal Houston Summer. To date, nothing has even complained that its hot, in fact the fans are not even spun all the way up on the switch</p><p>The temperatures actually never got above what I see equipment go to in my air conditioned lab in the Houston, which proves that as long air is flowing through the hardware, its fine. No equipment failures, no battery failures, no SSD failures, no HDD failures, no Transceiver failures</p><p>I replaced the UPS batteries last week, but they still reported 1 hour of runtime, and passed the test fine. I now use those batteries in a spare test UPS, they were 7 years old...</p><p>There is however a LOT of dust... but it has not affected the systems. I plan to give them a good clean later on this year</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.48.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.48.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.48.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.48.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.48.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.19.02.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.19.02.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.19.02.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.19.02.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.19.02.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.18.50.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.18.50.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.18.50.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.18.50.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.18.50.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.45.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.45.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.45.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.45.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.45.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There is a nice dust/dirt stain in the plywood behind the switch. I guess that means a lot of the dust ends up out the switch at least!</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.42.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.42.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.42.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.42.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.42.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There isn't much more to say, because nothing of note happened, it all just works fine...</p><p>Apart from a power outage during electrical work I had done, its been running 24/7 with no problem</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/image-2.png" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/image-2.png 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/image-2.png 1000w, https://blog.networkprofile.org/content/images/2020/10/image-2.png 1332w" sizes="(min-width: 1200px) 1200px"></figure><p>Full Equipment Listing for those Wondering</p><ul><li><strong>Cisco Catalyst 2960-S</strong> PoE+ 10G 48 Port Switch (48 x 1G PoE+ and 2 x 10G SFP+) connected back to my main rack with OM3 Fiber @ 10G</li><li><strong>APC SMT1000RM2U</strong> UPS</li><li><strong>Lenovo M73 Tiny</strong> (i5, 16GB DDR3, 800GB Intel DC S3700 SSD, 5TB 2.5" SATA HDD) Running ESXi 6.7</li><li><strong>Raspberry Pi4</strong> running ADSB Flight Tracking duties (FlightAware, ADSDX and FA24)</li></ul><p>If you are wondering if you can run your lab in your garage, go for it. You have my permission </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842218</guid>
            <pubDate>Tue, 20 Oct 2020 20:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swedish virologist says her country's strategy has failed, but nobody admits it]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24841972">thread link</a>) | @colinprince
<br/>
October 20, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sweden's health authority maintains its approach to COVID-19 was a success. But our guest says the data speaks differently, and that new measures announced Monday are insufficient.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5768038.1603128831!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1228596918.jpg"></p></div><figcaption>People walk on Stranvagen in Stockholm on Sept. 19. The country has had no lockdowns or mask policies during the coronavirus pandemic. <!-- --> <!-- -->(Jonathan Nackstrand/AFP/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/942/999/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:45</span><span>Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it</span></p></div></div></div></span></p><p><span><p>Eight months after the start of the&nbsp;global pandemic,&nbsp;Sweden is&nbsp;changing its COVID-19 strategy — but&nbsp;virologist Dr. Lena Einhorn&nbsp;says it's far too little, too late.</p>  <p>Last spring, as other countries went into lockdown, Swedish citizens were mostly living as usual. The government issued advice and guidance in place of rules and restrictions. School and work went ahead. Many businesses stayed open.&nbsp;</p>  <p>But as of Monday,&nbsp;Sweden's per capita death rate from COVID-19 was the 15th highest in the world, or 13th if you exclude the tiny countries of Andorra and San Marino,&nbsp;<a href="https://time.com/5800901/coronavirus-map/">according to data from Time magazine and Johns Hopkins University</a>.&nbsp;</p>  <p>Now Sweden&nbsp;is shifting its policy. <a href="https://www.telegraph.co.uk/news/2020/10/17/sweden-considers-local-lockdowns-shift-coronavirus-strategy/">According to the Telegraph</a>,&nbsp;starting Monday, the government has empowered regional health authorities — in consultation with the federal public health agency —&nbsp;to instruct citizens&nbsp;to stay away from crowded spaces like shopping malls, museum, gyms, and concerts, and avoid taking public transport or visiting the elderly. However, there will be no&nbsp;legal or financial consequences for non-compliance.</p>  <p>Einhorn,&nbsp;a virologist, author and filmmaker in Sweden,&nbsp;is one dozens of medical experts who have been critical of the country's COVID-19 response from the start. Here is part of her conversation with <em>As It Happens</em> host Carol Off.&nbsp;</p>  <p><strong>Is the Swedish government finally willing to admit that its approach to tackling COVID-19 has failed?</strong></p>  <p>I haven't seen any such signs, no.</p>  <p><strong>Do you think they'll just continue as they are?</strong></p>  <p>There have been incremental changes in the recommendations. There has never been, and I doubt there ever will be, any kind of admission of having made mistakes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-lena-einhorn.jpg 300w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-lena-einhorn.jpg 460w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-lena-einhorn.jpg 620w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg 780w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-lena-einhorn.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg"></p></div><figcaption>Dr. Lena Einhorn is an author, filmmaker and virologist in Sweden. <!-- --> <!-- -->(Submitted by Lena Einhorn)</figcaption></figure></span></p>  <p><strong>If you were to describe Sweden's approach to tackling the coronavirus, what words would you use?</strong></p>  <p>Stubborn is probably the best word I can come up with.</p>  <p>When they started, their initial assumptions were fair. They assumed that this would be like SARS; it would never sort of be a major problem in Sweden or outside of Southeast Asia. They were convinced it's only spread from symptomatic people, so like SARS, you could isolate the symptomatic people and stop the spread that way.</p>  <p>That was fair, you know, sometime in January. It was not fair in April or in May. So they stuck to that. And one could say that when the spread really …&nbsp;hit Europe and Sweden, they did the opposite of our Scandinavian and Nordic neighbours who went into lockdown, and we did not.</p>  <p><strong>There was an idea that we heard from coming from Sweden in the spring, and I guess it continued, that Sweden would attempt something called "herd immunity," that if enough people were to contract the virus, that eventually there would be a general immunity enough within the population that it would have a better effect than locking things down and keeping people from getting it. Is that what happened?</strong></p>  <p>It has been assumed that they were going for herd immunity, but they've been speaking through two sides of their mouths. On the one hand, they've been denying it. On the others, on the other hand, they said it would be a bonus.</p>  <p>They said that come fall, and the second wave, we will be much better protected than our Scandinavian neighbours who had 10 times less deaths than we did in relation to population. But it became very clear once broad testing of antibodies was being done that there was nothing close to herd immunity.</p>  <p>And so, of course, they realize that they can't go for herd immunity. It's going to kill too many people. I mean, it's already killed almost 6,000 people in a population of 10 million. So they are no longer going for herd immunity, which doesn't mean that they're prepared to say, "we were wrong and we're going to change our recommendations."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden.JPG 300w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden.JPG 460w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden.JPG 620w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG 780w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG"></p></div><figcaption>Anders Tegnell of the Public Health Agency of Sweden attends a news conference updating the country about COVID-19 on Oct. 9.<!-- --> <!-- -->(Claudio Bresciani/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>At the centre of all of this, as we have followed what's going on in Sweden, is a man named </strong><strong>Anders&nbsp;Tegnel, Sweden's chief epidemiologist, and he seems to be a bit of a rock star in your country for the decisions he made. <a href="https://www.reuters.com/article/us-health-coronavirus-tegnell-tattoo-idUSKCN2292G7">People have tattoos of him on their bodies.</a> So why is he so popular?</strong></p>  <p>This is a combination of factors, and this deserves a long discussion. Part of it, I'm sure, is that when there's a national crisis, people want to believe in authority.</p>  <p>The other aspect is that he has a very calming demeanour. Even when the numbers were going through the roof, he kept saying that we're flattening out, we're hitting the peak. He had a way of sounding extremely calming.</p>  <p>And also, you know, 90 per cent of the deaths were in the elderly, so …&nbsp;most people didn't see it.</p>  <p><strong>And what do you think of&nbsp;Anders&nbsp;Tegnel?</strong></p>  <p>I have no opinions about him personally, but I think he has not handled this well and he keeps on not handling this well.</p>  <p>Just as an example, Sweden is [one of the only countries],&nbsp;together with Somalia, Yemen, Eritrea, Syria, Greenland and some Pacific islands, who have still no recommendations for face masks whatsoever. So, you know, he hates face masks. He says they don't help. He keeps saying there's no support for them.</p>  <p>In the spring, that could have been a fair assumption. But by now, there's the studies are overwhelmingly showing the benefit of face masks, especially when it's used in the whole population, because it protects against someone who is sick.</p>  <p>So if everybody wears it, face masks are extremely efficient. But if only 50 per cent wear it, it's not at all sufficient. But he will not even say that they're good. I mean, you have to understand, in the Swedish hospitals, the doctors and nurses do not wear face masks.</p>    <p><strong>Well, it seems that [U.S. President] Donald Trump and the people around him would agree with Anders&nbsp;Tegnel.&nbsp;But the rest of the world, at least in countries where they have policies, they are not doing that. So somebody is right and somebody is wrong.</strong></p>  <p>The interesting thing is that in Sweden, we have a social democratic government dominated by the Social Democrats, so …&nbsp;it's more of a left-wing policy. Whereas in the rest of the world, it's very much a right-wing <em>laissez faire</em> policy to have herd immunity, or to try to have herd immunity, or to not wear face masks. Freedom, you know?</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden-cases.JPG 300w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden-cases.JPG 460w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden-cases.JPG 620w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG 780w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden-cases.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG"></p></div><figcaption>A sign promoting physical distancing is pictured in the Gallerian in Stockholm, Sweden, May 12.<!-- --> <!-- -->(Henrik Montgomery/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>There was <a href="https://time.com/5899432/sweden-coronovirus-disaster/">a freedom of information [request</a>, and] a bunch of emails that have been published by journalists in your country that show that Mr. Tegnel said that at one point that when it was suggested that 10 per cent of those who would get the disease would be the elderly and maybe they would die, 10 per cent might be "worth it," he apparently said. How much of the decisions are being driven by this idea that, well, maybe we have to keep Sweden moving, keeping the businesses open, and that's part of the motivation?</strong></p>  <p>They will never admit that the economy is an aspect. By the way, Sweden's economy has not fared any better than its Nordic neighbours. Rather, it's more at the bottom than at the top among our neighbours. So it hasn't benefited from it, and it has certainly not benefited from the herd immunity.</p>  <p><strong>Today we saw the announcement that citizens in Sweden should avoid places like shopping malls, museums, gyms, concerts, and avoid public transportation or visiting the elderly. So is there a shift perhaps in perception?</strong></p>  <p>There are policies. You know, it's not a completely<em> laissez faire</em>. I mean, people are advised to stay to work from home if they can. People are advised to not fill up the public transportation, the busses and the subways. There is still a maximum amount of people gathering of 50.</p>  <p>It's not a complete "let's live as normal" — but it's all recommendations and advice.</p>  <p>I would say that incrementally, Sweden has has gotten closer to other countries. I mean, we do a lot of testing now. We do, you know, about as much as Canada per capita. So it's not like in the spring, where nobody was tested outside of the hospital.</p>  <p>But it still is always too little.</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Jeanne Armstrong. Q&amp;A has been updated for length and clarity.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967</link>
            <guid isPermaLink="false">hacker-news-small-sites-24841972</guid>
            <pubDate>Tue, 20 Oct 2020 20:22:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia GPU]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24840972">thread link</a>) | @cdsousa
<br/>
October 20, 2020 | https://notamonadtutorial.com/julia-gpu-98a461d33e21 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/julia-gpu-98a461d33e21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@federicocarrone?source=post_page-----98a461d33e21--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/96/96/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2816/1*KJX3T1Y9T1Cj0aV3m-A22w.png" width="1408" height="528" srcset="https://miro.medium.com/max/552/1*KJX3T1Y9T1Cj0aV3m-A22w.png 276w, https://miro.medium.com/max/1104/1*KJX3T1Y9T1Cj0aV3m-A22w.png 552w, https://miro.medium.com/max/1280/1*KJX3T1Y9T1Cj0aV3m-A22w.png 640w, https://miro.medium.com/max/1400/1*KJX3T1Y9T1Cj0aV3m-A22w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KJX3T1Y9T1Cj0aV3m-A22w.png?q=20"></p></div></div></div></figure><p id="58dc">We are living in a time where more and more data is being created every day as well as new techniques and complex algorithms that try to extract the most out of it. As such, CPU capabilities are approaching a bottleneck in their computing power. GPU computing opened its way into a new paradigm for high-performance and parallel computation a long time ago, but it was not until recently that it become massively used for data science.<br>In this interview, <a href="https://twitter.com/maleadt" rel="noopener">Tim Besard</a>, one of the main contributors to the JuliaGPU project, digs into some of the details about GPU computing and the features that make Julia a language suited for such tasks, not only from a performance perspective but also from a user one.</p></div></div></section><section><div><div><p id="38e1"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p><p id="b3d6"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></div></section><section><div><div><h2 id="6d6e">Please tell us a bit about yourself. What is your background? what is your current position?</h2><p id="b291">Iâ€™ve always been interested in systems programming, and after obtaining my CS degree I got the opportunity to start a PhD at Ghent University, Belgium, right when Julia was first released around 2012. The language seemed intriguing, and since I wanted to gain some experience with LLVM, I decided to port some image processing research code from MATLAB and C++ to Julia. The goal was to match performance of the C++ version, but some of its kernels were implemented in CUDA Câ€¦ So obviously Julia needed a GPU back-end!</p><p id="7f14">That was easier said than done, of course, and much of my PhD was about implementing that back-end and (re)structuring the existing Julia compiler to facilitate these additional back-ends. Nowadays Iâ€™m at Julia Computing, where I still work on everything GPU-related.</p><h2 id="8f7f">What is JuliaGPU? What is the goal of the project?</h2><p id="43d9">JuliaGPU is the name we use to group GPU-related resources in Julia: Thereâ€™s a <a href="https://github.com/JuliaGPU" rel="noopener">GitHub organization</a> where most packages are hosted, a <a href="https://juliagpu.org/" rel="noopener">website</a> to point the way for new users, we have <a href="https://github.com/JuliaGPU/gitlab-ci" rel="noopener">CI infrastructure</a> for JuliaGPU projects, thereâ€™s a Slack channel and Discourse category, etc.</p><p id="ceaa">The goal of all this is to make it easier to use GPUs for all kinds of users. Current technologies often impose significant barriers to entry: CUDA is fairly tricky to install, C and C++ are not familiar to many users, etc. With the software we develop as part of the JuliaGPU organization, we aim to make it easy to use GPUs, without hindering the ability to optimize or use low-level features that the hardware has to offer.</p><h2 id="5da7">What is GPU computing? How important is it nowadays?</h2><p id="4de0">GPU computing means using the GPU, a device originally designed for graphics processing, to perform general-purpose computations. It has grown more important now that CPU performance is not improving as steadily as it used to. Instead, specialized devices like GPUs or FPGAs are increasingly used to improve the performance of certain computations. In the case of GPUs, the architecture is a great fit to perform highly-parallel applications. Machine learning networks are a good example of such parallel applications, and their popularity is one of the reasons GPUs have become so important.</p><h2 id="f596">Do you think Julia is an appropriate language to efficiently use GPU capabilities? Why?</h2><p id="775f">Juliaâ€™s main advantage is that the language was designed to be compiled. Even though the syntax is high-level, the generated machine code is<br>compact and has great performance characteristics (for more details, see <a href="http://janvitek.org/pubs/oopsla18b.pdf" rel="noopener">this paper</a>). This is crucial for GPU execution, where we are required to run native binaries and cannot easily (or efficiently) interpret code as is often required by other languageâ€™s semantics.</p><p id="b90b">Because weâ€™re able to directly compile Julia for GPUs, we can use almost all of the languageâ€™s features to build powerful abstractions. For example, you can define your own types, use those in GPU arrays, compose that with existing abstractions like lazy "Transpose" wrappers, access those on the GPU while benefiting from automatic bounds-checking (if needed), etc.</p><h2 id="824e">From a Python programmer perspective, how does CUDA.jl compare to PyCUDA? Are their functionalities equivalent?</h2><p id="cf3f">PyCUDA gives the programmer access to the CUDA APIs, with high-level Python functions that are much easier to use. CUDA.jl provides the same, but in Julia. The `hello world` from PyCUDAâ€™s home page looks almost identical in Julia:</p><pre><span id="a986">using CUDA</span><span id="03e4">function multiply_them(dest, a, b)<br> i = threadIdx().x<br> dest[i] = a[i] * b[i]<br> return<br>end</span><span id="9e7d">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="5833">dest = similar(a)<br>@cuda threads=400 multiply_them(dest, a, b)</span><span id="1372">println(dest-a.*b)</span></pre><p id="396f">Thereâ€™s one very big difference: "multiply_them" here is a function written in Julia, whereas PyCUDA uses a kernel written in CUDA C. The reason is straightforward: Python is not simple to compile. Of course, projects like Numba prove that it is very much possible to do so, but in the end those are separate compilers that try to match the reference Python compilers as closely as possible. With CUDA.jl, we integrate with that reference compiler, so itâ€™s much easier to guarantee consistent semantics and follow suit when the language changes (for more details,<br>refer to <a href="https://arxiv.org/abs/1712.03112" rel="noopener">this paper</a>).</p><h2 id="5cf6">Are the packages in the JuliaGPU organization targeted to experienced programmers only?</h2><p id="6590">Not at all. CUDA.jl targets different kinds of (GPU) programmers. If you are confident writing your own kernels, you can do so, while using all of the low-level features CUDA GPUs have to offer. But if you are new to the world of GPU programming, you can use high-level array operations that use existing kernels in CUDA.jl. For example, the above element-wise multiplication could just as well be written as:</p><pre><span id="9c1f">using CUDA</span><span id="476a">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="efdf">dest = a .* b</span></pre><h2 id="4c26">Is it necessary to know how to code in CUDA.jl to take full advantage of GPU computing in Julia?</h2><p id="208b">Not for most users. Julia has a powerful language of generic array operations ("map", "reduce", "broadcast", "accumulate", etc) which can be applied to all kinds of arrays, including GPU arrays. That means you can often re-use your codebase developed for the CPU with CUDA.jl (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0965997818310123" rel="noopener">this paper</a> shows some powerful examples). Doing so often requires minimal changes: changing the array type, making sure you use array operations instead of for loops, etc.</p><p id="672d">Itâ€™s possible you need to go beyond this style of programming, e.g., because your application doesnâ€™t map cleanly onto array operations, to use specific GPU features, etc. In that case, some basic knowledge about CUDA and the GPU programming model is sufficient to write kernels in CUDA.jl.</p><h2 id="1a33">How is the experience of coding a kernel in CUDA.jl in comparison to CUDA C and how transferable is the knowledge to one another?</h2><p id="6a08">Itâ€™s very similar, and thatâ€™s by design: We try to keep the kernel abstractions in CUDA.jl close to their CUDA C counterparts such that the programming environment is familiar to existing GPU programmers. Of course, by using a high-level source language thereâ€™s many quality-of-life improvements. You can allocated shared memory, for example, statically and dynamically as in CUDA C, but instead of a raw pointers we use an N-dimensional array object you can easily index. An example from the <a href="https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/" rel="noopener">NVIDIA developer blog</a>:</p><pre><span id="ef8a">__global__ void staticReverse(int *d, int n)<br>{<br> __shared__ int s[64];<br> int t = threadIdx.x;<br> int tr = n-t-1;<br> s[t] = d[t];<br> __syncthreads();<br> d[t] = s[tr];<br>}</span></pre><p id="9cb0">The CUDA.jl equivalent of this kernel looks very familiar, but uses array objects instead of raw pointers:</p><pre><span id="996c">function staticReverse(d)<br> s = @cuStaticSharedMem(Int, 64)<br> t = threadIdx().x<br> tr = length(d)-t+1<br> s[t] = d[t]<br> sync_threads()<br> d[t] = s[tr]<br> return<br>end</span></pre><p id="9a14">Using array objects has many advantages, e.g. multi-dimensional is greatly simplified and we can just do "d[i,j]". But itâ€™s also safer, because these accesses are bounds checked:</p><pre><span id="3d65">julia&gt; a = CuArray(1:64)<br>64-element CuArray{Int64,1}:<br> 1<br> 2<br> 3<br> â‹®<br> 62<br> 63<br> 64</span><span id="0d9c">julia&gt; @cuda threads=65 staticReverse(a)<br>ERROR: a exception was thrown during kernel execution.<br>Stacktrace:<br> [1] throw_boundserror at abstractarray.jl:541</span></pre><p id="c17a">Bounds checking isnâ€™t free, of course, and once weâ€™re certain our code is correct we can add an "@inbounds" annotation to our kernel and get the high-performance code we expect:</p><pre><span id="6846">julia&gt; @device_code_ptx @cuda threads=64 staticReverse(a)<br>.visible .entry staticReverse(.param .align 8 .b8 d[16]) {<br> .reg .b32 %r&lt;2&gt;;<br> .reg .b64 %rd&lt;15&gt;;<br> .shared .align 32 .b8 s[512];</span><span id="09c9">mov.b64 %rd1, d;<br> ld.param.u64 %rd2, [%rd1];<br> ld.param.u64 %rd3, [%rd1+8];<br> mov.u32 %r1, %tid.x;<br> cvt.u64.u32 %rd4, %r1;<br> mul.wide.u32 %rd5, %r1, 8;<br> add.s64 %rd6, %rd5, -8;<br> add.s64 %rd7, %rd3, %rd6;<br> ld.global.u64 %rd8, [%rd7+8];<br> mov.u64 %rd9, s;<br> add.s64 %rd10, %rd9, %rd6;<br> st.shared.u64 [%rd10+8], %rd8;<br> bar.sync 0;<br> sub.s64 %rd11, %rd2, %rd4;<br> shl.b64 %rd12, %rd11, 3;<br> add.s64 %rd13, %rd9, %rd12;<br> ld.shared.u64 %rd14, [%rd13+-8];<br> st.global.u64 [%rd7+8], %rd14;<br> ret;<br>}</span><span id="4489">julia&gt; a<br>64-element CuArray{Int64,1}:<br> 64<br> 63<br> 62<br> â‹®<br> 3<br> 2<br> 1</span></pre><p id="3cee">Tools like "@device_code_ptx" make it easy for an experienced developer to inspect generated code and ensure the compiler does what he wants.</p><h2 id="164a">Why does having a compiler have such an impact in libraries like CUDA.jl? (How was the process of integrating it to the Julia compiler?)</h2><p id="e360">Because we have a compiler at our disposal, we can rely on higher-order functions and other generic abstractions that specialize based on the arguments that users provide. That greatly simplifies our library, but also gives the user very powerful tools. As an example, we have carefully implemented a `mapreduce` function that uses shared memory, warp intrinsics, etc to perform a high-performance reduction. The implementation is generic though, and will automatically re-specialize (even at run time) based on the arguments to the function:</p><pre><span id="9da7">julia&gt; mapreduce(identity, +, CuArray([1,2,3]))<br>6</span><span id="c680">julia&gt; mapreduce(sin, *, CuArray([1.1,2.2,3.3]))<br>-0.11366175839582586</span></pre><p id="52e8">With this powerful `mapreduce` …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/julia-gpu-98a461d33e21">https://notamonadtutorial.com/julia-gpu-98a461d33e21</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/julia-gpu-98a461d33e21</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840972</guid>
            <pubDate>Tue, 20 Oct 2020 18:48:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palo Alto Networks sends cease-and-desist letter to take down review videos]]>
            </title>
            <description>
<![CDATA[
Score 431 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24840119">thread link</a>) | @bonfire
<br/>
October 20, 2020 | https://orca.security/cybersecurity-community-transparency/ | <a href="https://web.archive.org/web/*/https://orca.security/cybersecurity-community-transparency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

				
							<div data-elementor-type="single" data-elementor-id="1240" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="665134c3" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="12af1bce" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="19996313" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><em>Abstract: A few weeks ago, Orca Security published a comparison between the Orca Cloud Security Platform and a few other cloud security tools—including a&nbsp;<a href="https://orca.security/prisma-cloud-security/">comparison with Palo Alto Networks Prisma</a>. In response, Palo Alto Networks sent a <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">cease and desist letter</a>, demanding the comparison be removed immediately. Here is my response. I urge you to see&nbsp;<a href="https://www.youtube.com/playlist?list=PLDnqJTEi6ynvsGkSJHYeEmhz6_NfzKgbf">the videos in question</a>&nbsp;and if you, like me, believe the cybersecurity community deserves transparency and vendors shouldn’t be allowed to prevent publishing reviews or benchmarks via legal threats, then please share this post. You can also leave your own comments down below.</em></p>
<p><strong>To: Palo Alto Networks</strong></p>
<p><strong>CC: The cybersecurity community</strong></p>
<p><strong>Subject: The Cybersecurity community demands transparency, not legal threats&nbsp;</strong></p>
<p>Security has always been about transparency. The concept of security by obscurity was frowned upon as early as 1851—even before the invention of electricity—when&nbsp;<a href="https://en.wikipedia.org/wiki/Alfred_Charles_Hobbs">Alfred Hobbs</a>, a Massachusetts-based locksmith, demonstrated how then state-of-the-art locks could be picked. He explained that exposing the information would make the public more secure, as rogues already knew the deficiencies. The public needed to be educated, and he’d pursue better locks. Today’s locks are more advanced, but the principle is the same.</p>
<p>The cybersecurity community preaches about many products. All come with their own advantages and disadvantages, capabilities, and limitations. I believe that the only way practitioners can choose the tools that fit their environments best is by viewing factual evidence—not by relying solely on marketing materials. This is why we launched our&nbsp;<a href="https://orca.security/cloud-security-solutions/">Cloud Security Punch-Out! Series</a>, where we deploy a few tools—including Orca Security—on the exact same environment and share the results with viewers who deserve to see them. I urge you to take&nbsp;<a href="https://orca.security/prisma-cloud-security/">a look at the one we did with Palo Alto Networks;</a>&nbsp;as you’ll see we don’t hide those areas where Palo Alto Networks shines.</p>
<p>Unfortunately, Palo Alto Networks is now trying to use legal threats to prevent us from publishing&nbsp;these video&nbsp;reviews. In <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">its letter</a>, Palo Alto Networks does not point to any factual inaccuracies in the reviews of its products’ performance. Instead, it premises its threats on flimsy, boilerplate contract terms that prohibit reviews and comparisons of its products and hollow trademark allegations purporting that Palo Alto Networks is sponsoring the videos.</p>
<p>It’s outrageous that the world’s largest cybersecurity vendor (its products being used by over 65,000 organizations according to its website), believes that its users aren’t entitled to share any benchmark or performance comparison of its products. According to its boilerplate contract terms that prohibit “disclosing, publishing, or otherwise making publicly available any benchmark, performance, or comparison tests” of its products, you’re in violation even if you publish the results of an internal comparison of Palo Alto Networks against other products as part of your procurement process. The same goes for the hundreds of Palo Alto Networks reviews on various sites that include G2 Crowd, Capterra, and Gartner Peer Insights. It means that only benchmarks approved by Palo Alto Networks can be published.</p>
<p>Palo Alto Networks appears oblivious to the fact that the New York Attorney General’s office&nbsp;<a href="https://www.leagle.com/decision/2003579195misc2d3841519">sued and won an injunction</a>&nbsp;against McAfee from enforcing its contractual restrictions against publishing reviews or comparisons of its products without its consent more than 17 years ago. In enacting the&nbsp;<a href="https://www.law.cornell.edu/uscode/text/15/45b">Consumer Review Fairness Act</a>, Congress has also prohibited businesses from including contract terms that prohibit consumers from reviewing products or services they purchase.</p>
<blockquote><p>Palo Alto Networks, do you think your products are flawless or that the bad guys will follow along, not openly talking about products’ deficiencies? If the answer is no to both, then why resort to legal threats to remove such benchmarks and comparisons? I refuse to accept a world where any vendor believes it has the right to prevent the free flow of information, and control which product reviews are made publicly available.</p></blockquote>
<p>I urge you to make your products better and focus your marketing efforts on demonstrating that, rather than throwing away money on ill-conceived gag efforts. Such action doesn’t benefit anyone. If you believe we missed something in our test, then tell us so we can make adjustments—we’ll happily integrate your comments and suggestions.</p>
<p>We could contract an objective third party to conduct additional tests. You could conduct your own tests with Palo Alto Networks and Orca Security’s products, then let the audience see and decide for themselves. All such actions would be far more beneficial to the industry, permitting both companies to learn and improve our products for the sake of customers.</p>
<p>As we all recently learned too well,&nbsp;<a href="https://www.contagionlive.com/news/sunlight-inactivates-the-airborne-virus-that-causes-covid19">sunlight is the best disinfectant</a>. The cybersecurity community deserves better than a vendor’s lack of transparency while wielding dubious legal methods. Palo Alto Networks is the worlds’ largest cybersecurity vendor; with great power comes great responsibility. Your products are great—but nothing is perfect, and the public should have free access to all of the facts.</p>
<p>Yours faithfully,<br>
Avi Shua, CEO and Co-Founder<br>
Orca Security</p>
		</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
					</div>
		</div>
		</div>
		
					
					
				
			</div></div>]]>
            </description>
            <link>https://orca.security/cybersecurity-community-transparency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840119</guid>
            <pubDate>Tue, 20 Oct 2020 17:31:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My platonic ideal for how engineering hiring should work]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 260 (<a href="https://news.ycombinator.com/item?id=24840013">thread link</a>) | @leeny
<br/>
October 20, 2020 | http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/ | <a href="https://web.archive.org/web/*/http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>I’ve been in and around eng hiring for the past 13 years, as an engineer, a recruiter, and a founder of a technical recruiting marketplace (interviewing.io). Over the course of those 13 years, I’ve become increasingly disgruntled at the state of hiring, and now I’m mad enough to write this blog post.</p>



<p>If you’ve ever been on either end of the table, you’re probably mad at the state of hiring, too. Whether you have given it a lot of thought or whether you just feel it deep down, something about the whole process feels off.</p>



<p>But we’ve been doing it this way for so long that we probably take much of how hiring works as gospel, and it’s really hard to tease apart all the different components of the process and examine why they are the way they are. In this post, I’d like to challenge many of the things we assume about hiring, and, perhaps most importantly, I’d like to lay out my platonic ideal for how eng hiring should work. It’s a simple axiom, really:</p>



<p><em>It should be easy for smart people to talk to other smart people.</em></p>



<p>Or, another way to put it … if I’m a good engineer, it should be easy for me to talk to a hiring manager at a company I might be interested in, at a time of my choosing. But that’s simply not possible today. Despite the refrain that we’re in a candidate’s market and that there’s a shortage of good candidates, which should mean that candidates should have the power to call the shots, today’s hiring process couldn’t be further removed from this ideal. And it’s not just broken for a specific type of candidate. It’s broken for <em>everyone.</em></p>



<p>If you’re reading this, you might be an engineering manager, a senior engineer with stellar credentials, a recent bootcamp grad, an engineer from a background traditionally underrepresented in tech, or some combination of these. <strong>What’s truly messed up about the status quo is that, regardless of which of these groups you fall into, your journey will be unnecessarily unpleasant. Though the degree of unpleasantness will not always be the same, it’s not about race, seniority, pedigree, or gender … or even which side of the table you’re on. Hiring, in its current incarnation, is broken for everybody.</strong></p>



<p>Why? Let us go then, you and I, into the bowels of the status quo.</p>



<h2>A candidate and a hiring manager, never the twain shall meet</h2>



<p>Let’s say that I’m a competent generalist engineer who looks good on paper, and I’m thinking that it’s time to look for a new job. What happens next? The idea of having to mount a full-on job search is so daunting.&nbsp;</p>



<p>I could try some job boards to see which companies are out there. But what would I filter on? I know a lot of programming languages but am not set on having to work in a specific one. How can I tell if I’ll hit it off with the team? I’m applying via a job board to a position I know next to nothing about — will anyone even respond?</p>



<p>Suppose I find some companies where I might want to work. If I’m lucky enough to know someone there, I’ll have to get them to refer me, even though that may not actually do much to speed things along. And if I don’t know anyone there, applying will be an exhausting long shot. Odds are no one will look at my application, and having to redo my resume — or worse, write cover letters — seems like the most tedious kind of busywork.</p>



<p>I guess I can always dig through the recruiter spam I’ve gotten. But do those recruiters still work at the company? If they do, how long will it actually take to get into the process?</p>



<p>Breaking character for a moment, a friend of mine recently got this recruiting email from Google, who has elevated gaslighting to an art form: somehow the fact that it takes two months to get through their process has become a <em>selling point.</em></p>



<figure><img loading="lazy" width="750" height="319" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-450x191.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-768x327.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail.png 1004w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>Once I do get into the process, why do I have to endure the same intro call ten times with different recruiters who can’t tell me anything about what I’d be working on at any level of depth?</p>



<p>Do I join some platform, create a profile that I copy-paste everywhere (with writing that was just as painful as the aforementioned resume/cover letter) and sort of hope that decent companies contact me … only to have to begin the same recruiter calls over and over again, as above?</p>



<p>Will I have to take some quizzes that drill me on obscure syntax or make me solve toy problems that have no bearing on my engineering ability before I even get to have the aforementioned inane conversation with a recruiter?</p>



<p><strong>If I’m actually good at my job, why can’t I just set up some conversations with companies I think are cool and see if it’s a fit? Why do I have to subject myself and others to an endless parade of vapid conversations and the inevitable busywork that precedes them?</strong></p>



<p>Here’s the truth. Even if I look good on paper and am well-connected, hiring still sucks because of all the noise, uncertainty, and time wasted … but at least I have options. They might not be exactly the right options for me, but at least they exist. On the other hand, if I’m an engineer without a pedigree or a network, my choices are extremely limited, no matter how good I am. Recruiters aren’t reaching out to me, I’m not well-networked enough to have friends refer me, and I <em>definitely </em>don’t hear back when I apply.</p>



<hr>



<p>Let’s take a look at the other side of the table. Let’s say I’m an eng manager who needs to hire more competent generalists for my team. Having worked as both an eng manager and a recruiter, I can tell you that what happens next isn’t particularly inspiring.</p>



<p>As an eng manager, I sit down with a recruiter and try to explain what I’m looking for. Nine times out of ten, I want a <a href="https://www.joelonsoftware.com/2007/06/05/smart-and-gets-things-done/">smart person who can get shit done</a>. But, after a farcical game of telephone, somehow those criteria get warped into years of experience with a specific technology or requirements about where the candidate went to school. I also end up with an uninspired, sterile job description that fails to capture the imagination of any candidates who might unwittingly stumble upon it.</p>



<p><strong>My recruiter then goes to any number of sourcing tools of which LinkedIn Recruiter is the ubiquitous, lackluster market leader. They type in keywords I didn’t ask for and filter on credentials I don’t care about to come up with the same homogenous list of candidates every other recruiter at every other tech company is chasing.</strong></p>



<p>They then contact these candidates en masse with generic copy about my team and the hard problems we’re solving. They celebrate single-digit response rates and spend the minimal time left over to give a cursory glance at candidates applying directly.</p>



<h2>Why is hiring broken?</h2>



<p>So therein lies the ineffectual dance. This is the process we’ve come to accept. As far as I can tease out, the axioms that underlie today’s recruiting best practices go something like this (some of these were told to me verbatim when I was starting out as a recruiter, even):</p>



<ol><li><strong>Thou shalt not engage with active candidates. After all, in this market, strong candidates aren’t looking. Good recruiters build relationships so that when a good candidate does decide to enter the market, the recruiter is there, behind the next doorway, ready to spring!</strong></li><li><strong>Engineering time is expensive, so it’s critical to do as much top-of-funnel filtering as possible to make sure that it’s spent on the right candidates.</strong></li></ol>



<p>Are these axioms wrong? The sad truth is … not really. I’ve written in a <a href="http://blog.alinelerner.com/the-unvarnished-unbundled-guide-to-hiring-tools/">previous post about how market forces rule everything around me</a>, and recruiting best practices are no exception. In an economy with a surplus of jobs and a shortage of talent, it follows that the best talent is going to be harder to find, engineering time will be expensive, and recruiters in their current incarnation are, dare I say it, a necessary evil. <sup><a href="#footnote_0_2455" id="identifier_0_2455" title="From what you’ve read up until this point, you might think that I hate recruiters and find them useless. Not so, dear reader! I hate bad recruiters. And, unfortunately, most of them are bad. What’s sad is that the good ones, instead of spending time on tasks for which they’re uniquely qualified and well-suited, are instead stuck at the top of the funnel sourcing engineers whose qualifications they don’t have the domain expertise to evaluate and selling them on roles they don’t have the domain expertise to describe. The best recruiters I’ve worked with are singularly amazing at shepherding candidates through the process, tirelessly stewarding a company’s employer brand, advising hiring managers on the best ways to close, keeping an analytical eye on the funnel to identify issues before they even arise, and much more.">1</a></sup></p>



<p>The data supports our current world view. According to Lever (one of the two application tracking systems widely used by startups, Greenhouse is the other), here’s a breakdown of how many candidates from each source it takes to make a hire. Note that here, larger numbers are bad — for many companies, internal referrals are the best source and inbound applications are the worst.</p>



<figure><img loading="lazy" width="750" height="375" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-450x225.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-768x384.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2.png 1008w" sizes="(max-width: 750px) 100vw, 750px"><figcaption>Source: <a href="https://www.lever.co/recruiting-resources/articles/recruitment-process/" target="_blank" rel="noreferrer noopener">https://www.lever.co/recruiting-resources/articles/recruitment-process/</a></figcaption></figure>



<p>Looking at this data, you can see why recruiters simply ignore online applications. The same dynamics also apply to platforms such as AngelList — like any jobs board, it’s noisy and probably full of candidates who don’t have much leverage (e.g., juniors/bootcamp grads and people requiring visa sponsorship).</p>



<p>As for the value of eng time, guarding it carefully isn’t exactly wrong either. In fact, if you look at what a typical hiring process looks like today, you’ll see that most of the time spent is by engineers conducting interviews.</p>



<figure><table><thead><tr><th><strong>Hiring process stage</strong></th><th>Who does it?</th><th>How long does it take?</th></tr></thead><tbody><tr><td>Resume review</td><td>Recruiter</td><td>10-30 seconds</td></tr><tr><td>Recruiter screen</td><td>Recruiter</td><td>45 min</td></tr><tr><td>Technical phone screen</td><td>Engineer</td><td>1 hour</td></tr><tr><td>Onsite – Eng portion</td><td>Engineer</td><td>6 hours</td></tr><tr><td>Onsite – Recruiter portion</td><td>Recruiter</td><td>1 hour</td></tr><tr><td>Offer</td><td>Recruiter OR Eng mgr</td><td>1 hour</td></tr></tbody></table></figure>



<p>Engineering salaries are high, so given that most of the time spent on a single candidate is with engineers, it’s <em>rational</em> to put some recruiter gates at the top of the funnel to protect eng time. The idea is that recruiters will effectively screen out most candidates and only pass on the most promising ones to the eng team.</p>



<p>Unfortunately, when you look at an actual typical <em>funnel</em>, you’ll see that despite attempts to gate the top with recruiters filtering resumes and making intro calls, it’s not really working. Below is what a typical funnel looks like.</p>



<figure><img loading="lazy" width="750" height="89" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-450x53.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-768x91.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42.png 1092w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>If you <a href="https://blog.interviewing.io/you-probably-dont-factor-in-engineering-time-when-calculating-cost-per-hire-heres-why-you-really-should/" target="_blank" rel="noreferrer noopener">do the math</a> and look at how many hours are spent — not per candidate but per hire (more useful because hires are ultimately what we want) — you’ll see that despite attempts to save eng time, recruiters spend roughly 15 hours a hire <sup><a href="#footnote_1_2455" id="identifier_1_2455" title="If we add in time to review resumes, it’s an extra five hours (at most).">2</a></sup> and engineers spend about 40. In a process where you don’t make an offer 50% of the time and only convert those offers to hires 50% of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</a></em></p>]]>
            </description>
            <link>http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840013</guid>
            <pubDate>Tue, 20 Oct 2020 17:22:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS and their billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 159 (<a href="https://news.ycombinator.com/item?id=24839887">thread link</a>) | @bgpdude
<br/>
October 20, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, you’ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>— Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that I’ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! That’s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. That’s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). That’s <strong>the equivalent of just over six /8’s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWS’ IPv4 assets</h3><blockquote>Alright.. this is just for fun…</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. It’s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWS’ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that won’t happen since we’re all still addicted to IPv4 ;)</p><p>Anyway, let’s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>It’s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. That’s pretty healthy! And on top of that, I’m sure they’ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839887</guid>
            <pubDate>Tue, 20 Oct 2020 17:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24839327">thread link</a>) | @dwettlaufer
<br/>
October 20, 2020 | https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Because, sometimes, we just want JSON.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Eric Borczuk" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Eric Borczuk</span></span>
          •
          <span>Oct 19, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>If you’re like me, when you start coding something new, you’re probably finding yourself working with JSON.  Maybe you’re using Node.js or Python or any other dynamic language that uses JSON-like data natively or maybe you’re working with data that you’re pulling or serving from REST APIs. Either way, increasingly it seems like everything is ending up in JSON at some point.  Most of the time, this isn’t a problem, it’s just the way that we build software these days.  There’s just one problem, and that’s that Cassandra isn’t particularly good at JSON…</p>

<p>To double-click on that, the problem isn’t the JSON data format itself, although Cassandra doesn’t make JSON easy, it’s the way most devs use JSON when we’re building our apps.  Iterative development means that plans change.  The user registration form now needs a couple of more fields and the front-end dev went ahead and added them.  That API I’m calling returns some extra data.   Welcome to the loosely coupled world, it’s all fun and games until my app needs to send it to the database.</p>

<p>In the early days, Cassandra actually made this pretty simple to do, but as the project matured and added features like enterprise-friendly SQL-like query languages and better indexing, that meant that we needed the database to enforce a schema.  Over time, it became harder and harder to use Cassandra for things like JSON and other document-oriented use cases.</p>

<p>Enter Stargate - if there’s one thing you should know about the Stargate team it’s that our personal mission is to make Cassandra easy for every developer.  Figuring out how to give Javascript devs native JSON support without having to give up any of the reliability and scalability goodness of Cassandra was a challenge we couldn’t pass up.</p>

<p>This idea gave rise to the Stargate <strong>Documents API</strong>, which lets most Cassandra distros (Cassandra 3.11, Cassandra 4.0, and DataStax Enterprise 6.8), work with JSON through a REST API.</p>

<h2 id="api-features-and-design">API features and design</h2>

<p>As <a href="https://github.com/tjake">Jake Luciani</a> and I started to create the bones of this API, we realized that Cassandra is nothing like a document store. Expressing data as rows is straightforward, but expressing trees of JSON data is really not. In addition, mapping that JSON data onto a table managed by Stargate and keeping both writes and reads reasonably fast adds an additional layer of complexity.</p>

<p>From here, we mapped out three main design components in order for this work:
Modeling Documents in Cassandra
Handling Reads and Writes
Figuring out Deletes</p>

<p>The rest of this blog walks through how we approached each design and resolved some hiccups along the way.
Modeling Documents in Cassandra with Document Shredding</p>

<p>The first thing that we had to decide  was the schema of the managed table that backs a document collection. Due to some great discussions with some Cassandra specialists, it was decided that when a user creates a document, a table will be created with a statement of the form:</p>

<figure><pre><code data-lang="sql"><span>create</span> <span>table</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>(</span>
  <span>key</span> <span>text</span><span>,</span>
  <span>p0</span> <span>text</span><span>,</span>
  <span>…</span> <span>p</span><span>[</span><span>N</span><span>]</span> <span>text</span><span>,</span>
  <span>bool_value</span> <span>boolean</span><span>,</span>
  <span>txt_value</span> <span>text</span><span>,</span> <span>d</span>
  <span>bl_value</span> <span>double</span><span>,</span> <span>leaf</span> <span>text</span>
<span>)</span></code></pre></figure>

<p>At this point is where we had to solve an unbounded data modeling problem. Because any JSON document that has a depth of [N] or less can be added to this table, each value in the JSON will get stored as a row in the table. So if I wanted to represent a document called “x” that has the JSON:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>2</span><span>}</span></code></pre></figure>

<p>The document would be “shredded” into rows looking like this:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>null</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>For data with an array, such as:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>[{</span><span>"d"</span><span>:</span><span> </span><span>2</span><span>}]}</span></code></pre></figure>

<p>there would be two rows, like so:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>p2</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>null</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>[0]</td>
      <td>d</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>Array elements are stored with square braces in the column.</p>

<h3 id="handling-reads-and-writes">Handling Reads and Writes</h3>

<p>The next problem that arose was that naïvely, updates to a document could require reading the document from the database, seeing what modification would have to be made, and then writing the updated data.  This “read-before-write” process is a notorious source of performance and consistency issues in most data stores.</p>

<p>Therefore, we resolved to avoid doing any read-before-write operations at all costs.</p>

<p>An interesting implementation detail that came up is that when you write some data to a document, the resulting write operation is just a simple batch with some inserts and deletes. In some cases, this can cause the document rows in the database to show two different states for the same JSON field.</p>

<p><em>And, upon reading the rows out, the Documents API reconciles conflicting information by accepting the data that has a later Cassandra write time (much like Cassandra itself!).</em></p>

<p>This allows us to write data really quickly while not compromising too much in reads either, as the reconciliation does not happen often and is also quite fast. It also gives us a very important core principle to our basic write and read operations:</p>
<ol>
  <li>Every write to a single document is a single batch of statements, and</li>
  <li>Every read from a single document is a single SELECT statement.</li>
</ol>

<p>So writes and reads are squared away - but what about deletes?</p>

<h3 id="figuring-out-deletes">Figuring out Deletes</h3>

<p>Because of the distributed nature of the database, a deletion in Cassandra actually is very similar to an insert, but instead a “tombstone” is written at a particular write time to signify the death of a row.</p>

<p>Rest in peace… almost</p>

<p>One very real danger here is that Cassandra may eventually crash with a “Tombstone Overwhelming” error as tombstones accrue. Cassandra periodically (the frequency here depends on your compaction strategy and/or cluster load) does a compaction operation to remove tombstones and alleviate this pressure, so the only way to avoid overwhelming Cassandra is to make sure that the frequency of deletions is low enough.</p>

<p>This poses a problem for the Document API specifically because of arrays. Let’s walk through this one.</p>

<p>Imagine that you have an array at some key that is of length 100000. If you then issue a replace operation (via a PUT) and decide to replace that array with some other value, then all of those 100000 rows would be deleted, causing 100000 tombstones to be written.  This is an enormous number of tombstones to be written in one operation, and if you do that just a few more times, Cassandra will likely crash or get super slow. So the structure of the data in each table needed one last major modification.</p>

<p>We said before that array paths are stored in the database with square brackets; for example the element at index 0 would be stored as [0]. That would mean a deletion of 100000 elements would look like this:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>in</span> <span>(</span><span>'[0]'</span><span>,</span> <span>'[1]'</span><span>,</span> <span>'[2]'</span><span>,</span> <span>…</span><span>,</span> <span>'[99999]'</span><span>)</span></code></pre></figure>

<p>Causing 100000 tombstones to be written. Instead of doing that, we decided to pad all array elements with leading zeros, so the element at index 0 would instead be represented as [000000], and the element at index 99999 would be [099999]. Doing this allowed us to change the deletion statement to:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>&gt;=</span> <span>'[000000]'</span> <span>and</span> <span>p0</span> <span>&lt;=</span> <span>'[999999]'</span></code></pre></figure>

<p>Which causes only a single so-called “range” tombstone to be written, instead of 100000 cell tombstones (note that greater and less than works on strings in Cassandra and will compare lexically). It also relaxes the array length limit to one million elements, which is pretty neat! The time series below shows how the old vs. new implementation might behave, if you performed compactions every week:</p>

<p><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png"></p>

<p>So the new strategy is just safer for deletions; it would require an incredibly large amount of deletion with the new strategy to even come close to the theoretical tombstone limits!</p>

<h2 id="preliminary-look-at-api-performance">Preliminary Look at API performance</h2>

<p>⚠️ Before starting on this section, we want to mention that benchmarking is a great tool, but does not necessarily represent how a system will behave under real load, out in the wild. We also haven’t done comparisons on the same hardware with other document stores…yet. Alright, let’s get to it!</p>

<p>In order to test that the Document API is reasonably fast, we ran a benchmark test using a single Cassandra storage node and a single Stargate node (Stargate is the API that contains the Documents API). We then ran two different benchmarks, one that uses HTTP GET to repeatedly get random paths in a document, and another that performs HTTP POSTs repeatedly to create brand new documents.  Each of these actions got run 100000 times, and here are two graphs of the results.</p>

<p>To keep things simple, as there is no baseline to compare things against just yet, the benchmark was performed using only one requester at a time, with light concurrency (10 users at once), and with more concurrency (100 users at once). Note that it’s expected with only one backend node that higher concurrency would cause degradation in performance; you should have multiple nodes to service that degree of concurrent requests!</p>

<p>Here are the results for reads:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>And for writes:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>From the above, we can see that the API performs pretty well at a reasonable level of concurrency for our setup.</p>



<p>We hope you enjoyed taking this quick tour of the Documents API. If you are interested in using the API head over to <a href="https://stargate.io/docs/stargate/0.1/quickstart/quickstart.html">Stargate.io</a> for more information about how to use it in your own Cassandra distribution.</p>

<p>If you are interested in contributing to Stargate, which is entirely open-source, we have two places for you to join us:</p>

<ol>
  <li>Come join our <a href="https://discord.gg/5gY8GDB">Discord Community</a> to follow the latest with Stargate and get early access to new stuff</li>
  <li>For any issues or pull requests, come on over to our <a href="https://www.github.com/stargate/stargate">GitHub Repository</a>
</li>
</ol>

<p>The APIs in Stargate are being actively developed, so we are hoping to be able to get back to you soon with news of even more improvements!</p>

        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839327</guid>
            <pubDate>Tue, 20 Oct 2020 16:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sym Raises $12M to Help Engineers Reclaim Security]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24839074">thread link</a>) | @abuggia
<br/>
October 20, 2020 | https://compliance.dev/2020/10/20/hello-sym/ | <a href="https://web.archive.org/web/*/https://compliance.dev/2020/10/20/hello-sym/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="ode-to-the-accidental-security-engineer">Ode to the Accidental Security Engineer</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/4fe780d6b00b9e7113ff3250d350453a4abcb8df/1fba2/assets/hello-sym/salute.png" alt="Salute"></p>

<blockquote>
  <p>Here’s to the accidental security engineers. The misfits. The rebels. The troublemakers. The round pegs in the square holes. The ones who see things differently.</p>

  <p>To every engineer who’s ever spent a day scratching their head, wondering how to comply with a new security policy.</p>

  <p>To all those lost sprints building annoying primitives that “<em>have</em> to exist somewhere already”.</p>

  <p>To all the stressful weeks of getting pulled off new features to help prepare for an audit.</p>

  <p>To every web app, Slack bot, CLI, and microservice that was hacked together to help roll out a new control, only to become a pain-in-the-ass to maintain.</p>

  <p>It was us. We’ve been the ones tasked with building this mess. Constantly trading off velocity and security. But no more. We’re going to solve this problem, together, once and for all.</p>

  <p>Enter: Sym.</p>
</blockquote>

<h2 id="hello-sym">Hello, Sym</h2>

<p>Sym is the security workflow platform made for engineers, by engineers. We solve the intent-to-execution gap between policies and workflows by providing fast-moving engineering teams with the just-right primitives to roll out best-practice controls.</p>

<p>Our hand-crafted Terraform templates let you easily provision instances of common security controls, while our Python SDK unlocks ridiculously simple customization to meet your team’s needs and integrate with existing tools. We’ve got our sights set on fixing the “Build vs Buy” problem with security workflows… the problem being that both options currently suck.</p>

<p>I’m overjoyed and humbled to share that we’re not embarking on this quest alone. We’re off to the races with a <a href="https://techcrunch.com/2020/10/20/sym-raises-9m-series-a-for-its-security-workflow-platform/">$9M Series A led by Sunil Dhaliwal at Amplify Partners</a>, following hot on the heels of a $3M Seed led by Robin Vasan at Mango Capital and Andy McLoughlin at Uncork Capital.</p>

<p>They say “never meet your heroes”, but with participation from security &amp; technology executives at GitHub, Datadog, Atlassian, Google, Bugsnag, and Segment, alongside early design partners like LaunchDarkly, we’re sure glad we met ours!</p>

<p>We’re excited to unveil our vision to the world, and announce that we’ve partnered with some of the best investors, engineers, and leaders in the industry to tackle this mountainous problem space. Every single person behind Sym has experienced our struggle first-hand (phew, we’re not crazy!), and won’t rest until we solve it. Let’s do this!</p>

<h2 id="howd-we-get-here">How’d we get here?</h2>

<p>Story time! I met Adam and Jon when I was a freshman at MIT. I distinctly remember walking into the Startup Career Fair wondering how I could circumvent the “no freshmen” rule most companies seemed to have when hiring interns. A friendly senior had let me know to watch out for the scores that recruiters would scrawl on resumes before haphazardly throwing them on the pile. A week prior, I watched a Facebook recruiter scratch a “1” onto mine, circling the sad number repeatedly before smiling and telling me to have a nice day. My world fell apart. This week was going to be different.</p>

<p>After having a great chat with this guy named <a href="https://en.wikipedia.org/wiki/Vladimir_Tenev">Vlad</a> (Robinhood wasn’t a Big Deal yet), I ran into Adam. He was the VP of Engineering at a Boston-based company called Localytics, and seemed as relieved as I was to be having a conversation. I hesitantly bought into his pitch, and scheduled a time to come onsite. Little did I know, that thoughtless commitment would totally change the trajectory of my life, and one day be responsible for the founding of Sym!</p>

<p>The first meeting was uneventful, or so I thought. I showed up 30 minutes late to a rather exasperated Adam lecturing me on the demerits of interview tardiness. Throughout the years, I’ve grown very accustomed to that frustrated expression 😅. Though I’m still notoriously late for most things in life, I’ve never again failed to be punctual for a job interview!</p>

<p>Against his better judgement, Adam brought me on as an early intern at Localytics. It was my first job, and he was my first boss. I learned the ropes (read: how to ignore everyone’s advice while minimally pissing them off), and got to collaborate on some <a href="https://eng.localytics.com/your-code-coverage-is-bad-and-you-should-feel-bad/">really fun projects</a>. Jon (our third cofounder) spent a lot of time reprimanding me.</p>

<p>We spent the rest of the summer <del>fighting</del> working together, and ended with a particularly controversial project where, against the better judgement of basically everyone, I pumped out a heap of flaky Javascript code for saving reports, and then peaced out from the company ✌️.</p>

<p>I’m extremely grateful that over the span of a decade, I stayed in touch with these two. Our relationship evolved, from manager-intern, to mentor-mentee, to peers, to cofounders. When I stepped away from my last company to start Sym, those two were my first call. And boy, am I glad they were.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e009c90866e63034acc943efabdfa4a6457078d7/c6517/assets/hello-sym/map.png" alt="Map"></p>

<h2 id="evolution-of-sym">Evolution of Sym</h2>

<p>When Jon, Adam, and I sat down to build Sym, we wanted to solve a very simple problem: every engineering org we know in a heavily-regulated space was building the same damn tooling. Coming from healthcare and enterprise SaaS, we’d seen permutations of the same few workflows time and time again throughout our careers. A way to grant engineers temporary access to infrastructure? Check. A way to approve one-off queries? Check. Something to make quarterly risk assessments suck less? Check. Chat-Ops for approving outgoing deploys? Check.</p>

<p>The crazy thing was, these seemed to be ubiquitous across companies, compliance standards, even industries. Chatting with fellow founders about stuff I’d built to help keep my team productive would always result in one of two reactions: “<em>oh yea, we built the same thing! let’s trade notes…“</em>, or <em>“oh shit, we should have built this years ago”</em>. So we came up with a crazy idea: what if we just build all this stuff once, and put it out in the world for everyone to use. We were going to start with HIPAA-induced workflows. Sym: HIPAA in a box, for engineers. Of course, things rarely work out that simply.</p>

<p>We rapidly discovered something while talking to potential users: our hypothesis that everyone is building tools for the same workflows was a bit off. It wasn’t the case that everyone’s workflows were identical, but instead that they had the same <em>shared core</em>. It turns out, what most teams do is they start by building the same <strong>primitives</strong>, and then they layer on <strong>customizations</strong> that reflect existing processes and tools. So, we adjusted our approach to match this revelation.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/dc4f6494be10e2dfb90dc745bd96e83fffad695e/7aa7d/assets/hello-sym/graph.gif" alt="Graph"></p>

<p>Today, Sym is a set of workflow templates (<strong>primitives</strong>) for engineering teams working on improving security posture, and a suite of integrations (<strong>customizations</strong>) that connect those templates to existing systems and policies. Our mission is to enable any team to effortlessly build unobtrusive security and governance workflows, so we make sure to meet developers where they are: our primitives are exposed as Infrastructure-as-Code, and our SDK captures last-mile variance in workflows. The tools we use to distribute Sym Workflows are Terraform and Python, but your organization doesn’t have to be familiar with either to use us.</p>

<p>With Sym, you can roll out many common security and governance workflows with ~30 lines of declarative config and a couple function body definitions. Our goal is for you to blow your InfoSec team away; bring speed, sophistication, and thoroughness to your controls, without losing a whole month each time. Beautiful dashboards with just-right reports will materialize, without a single tedious line of logging code.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/8b56882478ed2e08f51d3f70075e993d385a2eef/193db/assets/hello-sym/code.png" alt="Code"></p>

<p>We’re currently live (in production!) at a handful of public and private companies in the Healthcare and B2B SaaS spaces. Our initial workflows focus on governance and just-in-time access of cloud and app-level resources.</p>

<p>Our latest customer is locking down SSH access by rolling out <a href="https://compliance.dev/2020/03/23/aws-session-manager-ssh-tunnels-with-less-user-management/">AWS Session Manager tunnels</a> as the preferred way to connect to instances, with the IAM Role required to use SSM protected by Sym. This is one of many examples where we’re able to help infra teams adopt cutting-edge cloud offerings while increasing security posture. If this sounds like something that you’d like for your team, please <a href="https://symops.com/">reach out</a>!</p>

<h2 id="but-what-about-x">But what about X?</h2>

<p>We’re in a crowded space! Luckily, we see the world with a unique lens. Sym brings an emphasis on developer experience, opinionated workflows that codify best practices, and an aspiration to be the bridge between Security and Compliance. The jury’s still out on whether we’re totally brilliant or totally out to lunch.</p>

<p>Our vision at Sym is to become the de-facto standard for implementing and showcasing security posture. Importantly, we’re not setting out to be a middleman levying a tax on the system. We saw enough of those in our healthcare days. Instead, we’re striving to improve the status quo for every stakeholder in the security equation; our place as the obvious-choice bridge between security and compliance will be an emergent property of the system we’re fighting to improve.</p>

<p>We’ve got a long way to go to make that vision a reality. In the interim, we’re tackling several problems plaguing our friends and colleagues.</p>

<h3 id="security-intent-to-implementation-gap">Security intent-to-implementation gap</h3>

<p>A security intent-to-implementation gap is endemic in our industry today. Experts are laying out guidelines, policies, and best-practices, only to be foiled by the gargantuan effort required to implement workflows that reflect these intents. And to be honest, we can’t really blame engineering teams for this. As an industry, we’ve learned not to roll our own crypto, because it’s so easy to shoot yourself in the foot, but can you imagine how many ways there are to screw up a Slack bot that issues temporary database credentials? Or how easy it is to forget to put MFA around an admin God-mode dashboard? Twitter hack, anyone?</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/2fa7f55e98cd8c615f0db83c6fd96236b49266a2/67dc7/assets/hello-sym/headlines.png" alt="Headlines"></p>

<p>Sensitive access workflows are the perfect example of a control that should be implemented once, and safely customized many times. This is where Sym is starting today.</p>

<h3 id="everyone-is-building-the-same-damn-things">Everyone is building the same damn things</h3>

<p>We’ve talked about this one extensively already. How many of us have to fight with the same <a href="https://compliance.dev/2020/07/17/okta-aws-join-all-roles-setting/">obsc…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://compliance.dev/2020/10/20/hello-sym/">https://compliance.dev/2020/10/20/hello-sym/</a></em></p>]]>
            </description>
            <link>https://compliance.dev/2020/10/20/hello-sym/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839074</guid>
            <pubDate>Tue, 20 Oct 2020 16:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Football Results with Statistical Modelling]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24838958">thread link</a>) | @henrik_w
<br/>
October 20, 2020 | https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/ | <a href="https://web.archive.org/web/*/https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        <p>Football (or soccer to my American readers) is full of clichés: “It’s a game of two halves”, “taking it one game at a time” and “Liverpool have failed to win the Premier League”. You’re less likely to hear “Treating the number of goals scored by each team as independent Poisson processes, statistical modelling suggests that the home team have a 60% chance of winning today”. But this is actually a bit of cliché too (it has been discussed <a href="https://www.pinnacle.com/en/betting-articles/soccer/how-to-calculate-poisson-distribution">here</a>, <a href="https://help.smarkets.com/hc/en-gb/articles/115001457989-How-to-calculate-Poisson-distribution-for-football-betting">here</a>, <a href="http://pena.lt/y/2014/11/02/predicting-football-using-r/">here</a>, <a href="http://opisthokonta.net/?p=296">here</a> and <a href="https://dashee87.github.io/data%20science/football/r/predicting-football-results-with-statistical-modelling/">particularly well here</a>). As we’ll discover, a simple Poisson model is, well, overly simplistic. But it’s a good starting point and a nice intuitive way to learn about statistical modelling. So, if you came here looking to make money, <a href="http://www.make5000poundspermonth.co.uk/">I hear this guy makes £5000 per month without leaving the house</a>.</p>

<h2 id="poisson-distribution">Poisson Distribution</h2>

<p>The model is founded on the number of goals scored/conceded by each team. Teams that have been higher scorers in the past have a greater likelihood of scoring goals in the future. We’ll import all match results from the recently concluded Premier League (2016/17) season. There’s various sources for this data out there (<a href="https://www.kaggle.com/hugomathien/soccer">kaggle</a>, <a href="http://www.football-data.co.uk/englandm.php">football-data.co.uk</a>, <a href="https://github.com/jalapic/engsoccerdata">github</a>, <a href="http://api.football-data.org/index">API</a>). I built an <a href="https://github.com/dashee87/footballR">R wrapper for that API</a>, but I’ll go the csv route this time around.</p>

<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>seaborn</span>
<span>from</span> <span>scipy.stats</span> <span>import</span> <span>poisson</span><span>,</span><span>skellam</span>

<span>epl_1617</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"http://www.football-data.co.uk/mmz4281/1617/E0.csv"</span><span>)</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'FTHG'</span><span>,</span><span>'FTAG'</span><span>]]</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>.</span><span>rename</span><span>(</span><span>columns</span><span>=</span><span>{</span><span>'FTHG'</span><span>:</span> <span>'HomeGoals'</span><span>,</span> <span>'FTAG'</span><span>:</span> <span>'AwayGoals'</span><span>})</span>
<span>epl_1617</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>

<div>
<table>
  <thead>
    <tr>
      <th></th>
      <th>HomeTeam</th>
      <th>AwayTeam</th>
      <th>HomeGoals</th>
      <th>AwayGoals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Burnley</td>
      <td>Swansea</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Crystal Palace</td>
      <td>West Brom</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Everton</td>
      <td>Tottenham</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Hull</td>
      <td>Leicester</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Man City</td>
      <td>Sunderland</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>We imported a csv as a pandas dataframe, which contains various information for each of the 380 EPL games in the 2016-17 English Premier League season. We restricted the dataframe to the columns in which we’re interested (specifically, team names and numer of goals scored by each team). I’ll omit most of the code that produces the graphs in this post. But don’t worry, you can find that code on <a href="https://github.com/dashee87/blogScripts/blob/master/Jupyter/2017-06-04-predicting-football-results-with-statistical-modelling.ipynb">my github page</a>. Our task is to model the final round of fixtures in the season, so we must remove the last 10 rows (each gameweek consists of 10 matches).</p>

<div><div><pre><code><span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[:</span><span>-</span><span>10</span><span>]</span>
<span>epl_1617</span><span>.</span><span>mean</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code>HomeGoals    1.591892
AwayGoals    1.183784
dtype: float64
</code></pre></div></div>

<p>You’ll notice that, on average, the home team scores more goals than the away team. This is the so called ‘home (field) advantage’ (discussed <a href="https://jogall.github.io/2017-05-12-home-away-pref/">here</a>) and <a href="http://bleacherreport.com/articles/1803416-is-home-field-advantage-as-important-in-baseball-as-other-major-sports">isn’t specific to soccer</a>. This is a convenient time to introduce the <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>. It’s a discrete probability distribution that describes the probability of the number of events within a specific time period (e.g 90 mins) with a known average rate of occurrence. A key assumption is that the number of events is independent of time. In our context, this means that goals don’t become more/less likely by the number of goals already scored in the match. Instead, the number of goals is expressed purely as function an average rate of goals. If that was unclear, maybe this mathematical formulation will make clearer:</p>



<p> represents the average rate (e.g. average number of goals, average number of letters you receive, etc.). So, we can treat the number of goals scored by the home and away team as two independent Poisson distributions. The plot below shows the proportion of goals scored compared to the number of goals estimated by the corresponding Poisson distributions.</p>

<p><img src="https://dashee87.github.io/images/home_away_goals_python.png" alt=""></p>

<p>We can use this statistical model to estimate the probability of specfic events.</p>



<p>The probability of a draw is simply the sum of the events where the two teams score the same amount of goals.</p>



<p>Note that we consider the number of goals scored by each team to be independent events (i.e. P(A n B) = P(A) P(B)). The difference of two Poisson distribution is actually called a <a href="https://en.wikipedia.org/wiki/Skellam_distribution">Skellam distribution</a>. So we can calculate the probability of a draw by inputting the mean goal values into this distribution.</p>

<div><div><pre><code><span># probability of draw between home and away team</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>0.0</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<div><div><pre><code><span># probability of home team winning by one goal</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>1</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<p><img src="https://dashee87.github.io/images/skellam_goals_python.png" alt=""></p>

<p>So, hopefully you can see how we can adapt this approach to model specific matches. We just need to know the average number of goals scored by each team and feed this data into a Poisson model. Let’s have a look at the distribution of goals scored by Chelsea and Sunderland (teams who finished 1st and last, respectively).</p>

<p><img src="https://dashee87.github.io/images/chelsea_sunderland_goals_python.png" alt=""></p>

<h2 id="building-a-model">Building A Model</h2>

<p>You should now be convinced that the number of goals scored by each team can be approximated by a Poisson distribution. Due to a relatively sample size (each team plays at most 19 home/away games), the accuracy of this approximation can vary significantly (especially earlier in the season when teams have played fewer games). Similar to before, we could now calculate the probability of various events in this Chelsea Sunderland match. But rather than treat each match separately, we’ll build a more general Poisson regression model (<a href="https://en.wikipedia.org/wiki/Poisson_regression">what is that?</a>).</p>

<div><div><pre><code><span># importing the tools required for the Poisson regression model</span>
<span>import</span> <span>statsmodels.api</span> <span>as</span> <span>sm</span>
<span>import</span> <span>statsmodels.formula.api</span> <span>as</span> <span>smf</span>

<span>goal_model_data</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'HomeGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>1</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'HomeTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'AwayTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'HomeGoals'</span><span>:</span><span>'goals'</span><span>}),</span>
           <span>epl_1617</span><span>[[</span><span>'AwayTeam'</span><span>,</span><span>'HomeTeam'</span><span>,</span><span>'AwayGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>0</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'AwayTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'HomeTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'AwayGoals'</span><span>:</span><span>'goals'</span><span>})])</span>

<span>poisson_model</span> <span>=</span> <span>smf</span><span>.</span><span>glm</span><span>(</span><span>formula</span><span>=</span><span>"goals ~ home + team + opponent"</span><span>,</span> <span>data</span><span>=</span><span>goal_model_data</span><span>,</span> 
                        <span>family</span><span>=</span><span>sm</span><span>.</span><span>families</span><span>.</span><span>Poisson</span><span>())</span><span>.</span><span>fit</span><span>()</span>
<span>poisson_model</span><span>.</span><span>summary</span><span>()</span>
</code></pre></div></div>

<table>
<caption>Generalized Linear Model Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>goals</td>      <th>  No. Observations:  </th>  <td>   740</td> 
</tr>
<tr>
  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   700</td> 
</tr>
<tr>
  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    39</td> 
</tr>
<tr>
  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  
</tr>
<tr>
  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1042.4</td>
</tr>
<tr>
  <th>Date:</th>           <td>Sat, 10 Jun 2017</td> <th>  Deviance:          </th> <td>  776.11</td>
</tr>
<tr>
  <th>Time:</th>               <td>11:17:38</td>     <th>  Pearson chi2:      </th>  <td>  659.</td> 
</tr>
<tr>
  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table>
<tbody><tr>
               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>Intercept</th>                  <td>    0.3725</td> <td>    0.198</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.016     0.761</td>
</tr>
<tr>
  <th>team[T.Bournemouth]</th>        <td>   -0.2891</td> <td>    0.179</td> <td>   -1.612</td> <td> 0.107</td> <td>   -0.641     0.062</td>
</tr>
<tr>
  <th>team[T.Burnley]</th>            <td>   -0.6458</td> <td>    0.200</td> <td>   -3.230</td> <td> 0.001</td> <td>   -1.038    -0.254</td>
</tr>
<tr>
  <th>team[T.Chelsea]</th>            <td>    0.0789</td> <td>    0.162</td> <td>    0.488</td> <td> 0.626</td> <td>   -0.238     0.396</td>
</tr>
<tr>
  <th>team[T.Crystal Palace]</th>     <td>   -0.3865</td> <td>    0.183</td> <td>   -2.107</td> <td> 0.035</td> <td>   -0.746    -0.027</td>
</tr>
<tr>
  <th>team[T.Everton]</th>            <td>   -0.2008</td> <td>    0.173</td> <td>   -1.161</td> <td> 0.246</td> <td>   -0.540     0.138</td>
</tr>
<tr>
  <th>team[T.Hull]</th>               <td>   -0.7006</td> <td>    0.204</td> <td>   -3.441</td> <td> 0.001</td> <td>   -1.100    -0.302</td>
</tr>
<tr>
  <th>team[T.Leicester]</th>          <td>   -0.4204</td> <td>    0.187</td> <td>   -2.249</td> <td> 0.025</td> <td>   -0.787    -0.054</td>
</tr>
<tr>
  <th>team[T.Liverpool]</th>          <td>    0.0162</td> <td>    0.164</td> <td>    0.099</td> <td> 0.921</td> <td>   -0.306     0.338</td>
</tr>
<tr>
  <th>team[T.Man City]</th>           <td>    0.0117</td> <td>    0.164</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.310     0.334</td>
</tr>
<tr>
  <th>team[T.Man United]</th>         <td>   -0.3572</td> <td>    0.181</td> <td>   -1.971</td> <td> 0.049</td> <td>   -0.713    -0.002</td>
</tr>
<tr>
  <th>team[T.Middlesbrough]</th>      <td>   -1.0087</td> <td>    0.225</td> <td>   -4.481</td> <td> 0.000</td> <td>   -1.450    -0.568</td>
</tr>
<tr>
  <th>team[T.Southampton]</th>        <td>   -0.5804</td> <td>    0.195</td> <td>   -2.976</td> <td> 0.003</td> <td>   -0.963    -0.198</td>
</tr>
<tr>
  <th>team[T.Stoke]</th>              <td>   -0.6082</td> <td>    0.197</td> <td>   -3.094</td> <td> 0.002</td> <td>   -0.994    -0.223</td>
</tr>
<tr>
  <th>team[T.Sunderland]</th>         <td>   -0.9619</td> <td>    0.222</td> <td>   -4.329</td> <td> 0.000</td> <td>   -1.397    -0.526</td>
</tr>
<tr>
  <th>team[T.Swansea]</th>            <td>   -0.5136</td> <td>    0.192</td> <td>   -2.673</td> <td> 0.008</td> <td>   -0.890    -0.137</td>
</tr>
<tr>
  <th>team[T.Tottenham]</th>          <td>    0.0532</td> <td>    0.162</td> <td>    0.328</td> <td> 0.743</td> <td>   -0.265     0.371</td>
</tr>
<tr>
  <th>team[T.Watford]</th>            <td>   -0.5969</td> <td>    0.197</td> <td>   -3.035</td> <td> 0.002</td> <td>   -0.982    -0.211</td>
</tr>
<tr>
  <th>team[T.West Brom]</th>          <td>   -0.5567</td> <td>    0.194</td> <td>   -2.876</td> <td> 0.004</td> <td>   -0.936    -0.177</td>
</tr>
<tr>
  <th>team[T.West Ham]</th>           <td>   -0.4802</td> <td>    0.189</td> <td>   -2.535</td> <td> 0.011</td> <td>   -0.851    -0.109</td>
</tr>
<tr>
  <th>opponent[T.Bournemouth]</th>    <td>    0.4109</td> <td>    0.196</td> <td>    2.092</td> <td> 0.036</td> <td>    0.026     0.796</td>
</tr>
<tr>
  <th>opponent[T.Burnley]</th>        <td>    0.1657</td> <td>    0.206</td> <td>    0.806</td> <td> 0.420</td> <td>   -0.237     0.569</td>
</tr>
<tr>
  <th>opponent[T.Chelsea]</th>        <td>   -0.3036</td> <td>    0.234</td> <td>   -1.298</td> <td> 0.194</td> <td>   -0.762     0.155</td>
</tr>
<tr>
  <th>opponent[T.Crystal Palace]</th> <td>    0.3287</td> <td>    0.200</td> <td>    1.647</td> <td> 0.100</td> <td>   -0.062     0.720</td>
</tr>
<tr>
  <th>opponent[T.Everton]</th>        <td>   -0.0442</td> <td>    0.218</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.472     0.384</td>
</tr>
<tr>
  <th>opponent[T.Hull]</th>           <td>    0.4979</td> <td>    0.193</td> <td>    2.585</td> <td> 0.010</td> <td>    0.120     0.875</td>
</tr>
<tr>
  <th>opponent[T.Leicester]</th>      <td>    0.3369</td> <td>    0.199</td> <td>    1.694</td> <td> 0.090</td> <td>   -0.053     0.727</td>
</tr>
<tr>
  <th>opponent[T.Liverpool]</th>      <td>   -0.0374</td> <td>    0.217</td> <td>   -0.172</td> <td> 0.863</td> <td>   -0.463     0.389</td>
</tr>
<tr>
  <th>opponent[T.Man City]</th>       <td>   -0.0993</td> <td>    0.222</td> <td>   -0.448</td> <td> 0.654</td> <td>   -0.534     0.335</td>
</tr>
<tr>
  <th>opponent[T.Man United]</th>     <td>   -0.4220</td> <td>    0.241</td> <td>   -1.754</td> <td> 0.079</td> <td>   -0.894     0.050</td>
</tr>
<tr>
  <th>opponent[T.Middlesbrough]</th>  <td>    0.1196</td> <td>    0.208</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.289     0.528</td>
</tr>
<tr>
  <th>opponent[T.Southampton]</th>    <td>    0.0458</td> <td>    0.211</td> <td>    0.217</td> <td> 0.828</td> <td>   -0.369     0.460</td>
</tr>
<tr>
  <th>opponent[T.Stoke]</th>          <td>    0.2266</td> <td>    0.203</td> <td>    1.115</td> <td> 0.265</td> <td>   -0.172     0.625</td>
</tr>
<tr>
  <th>opponent[T.Sunderland]</th>     <td>    0.3707</td> <td>    0.198</td> <td>    1.876</td> <td> 0.061</td> <td>   -0.017     0.758</td>
</tr>
<tr>
  <th>opponent[T.Swansea]</th>        <td>    0.4336</td> <td>    0.195</td> <td>    2.227</td> <td> 0.026</td> <td>    0.052     0.815</td>
</tr>
<tr>
  <th>opponent[T.Tottenham]</th>      <td>   -0.5431</td> <td>    0.252</td> <td>   -2.156</td> <td> 0.031</td> <td>   -1.037    -0.049</td>
</tr>
<tr>
  <th>opponent[T.Watford]</th>        <td>    0.3533</td> <td>    0.198</td> <td>    1.782</td> <td> 0.075</td> <td>   -0.035     0.742</td>
</tr>
<tr>
  <th>opponent[T.West Brom]</th>      <td>    0.0970</td> <td>    0.209</td> <td>    0.463</td> <td> 0.643</td> <td>   -0.313     0.507</td>
</tr>
<tr>
  <th>opponent[T.West Ham]</th>       <td>    0.3485</td> <td>    0.198</td> <td>    1.758</td> <td> 0.079</td> <td>   -0.040     0.737</td>
</tr>
<tr>
  <th>home</th>                       <td>    0.2969</td> <td>    0.063</td> <td>    4.702</td> <td> 0.000</td> <td>    0.173     0.421</td>
</tr>
</tbody></table>

<p>If you’re curious about the <code>smf.glm(...)</code> part, you can find more information <a href="http://www.statsmodels.org/stable/examples/notebooks/generated/glm_formula.html">here</a> (edit: earlier versions of this post had erroneously employed a Generalised Estimating Equation (GEE)- <a href="https://stats.stackexchange.com/questions/16390/when-to-use-generalized-estimating-equations-vs-mixed-effects-models">what’s the difference?</a>). I’m more interested in the values presented in the <code>coef</code> column in the model summary table, which are analogous to the slopes in linear regression. Similar to <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>, we take the <a href="http://www.lisa.stat.vt.edu/sites/default/files/Poisson.and_.Logistic.Regression.pdf">exponent of the parameter values</a>. A positive value implies more goals (), while values closer to zero represent more neutral effects (). Towards the bottom of the table you might notice that <code>home</code> has a <code>coef</code> of 0.2969. This captures the fact that home teams generally score more goals than the away team (specifically, =1.35 times more likely). But not all teams are created equal. Chelsea has a <code>coef</code> of 0.0789, while the corresponding value for Sunderland is -0.9619 (sort of saying Chelsea (Sunderland) are better (much worse!) scorers than average). Finally, the <code>opponent*</code> values …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</a></em></p>]]>
            </description>
            <link>https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24838958</guid>
            <pubDate>Tue, 20 Oct 2020 16:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why build another website builder?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24837331">thread link</a>) | @apledger3
<br/>
October 20, 2020 | https://www.makeswift.com/blog/why-build-another-website-builder | <a href="https://web.archive.org/web/*/https://www.makeswift.com/blog/why-build-another-website-builder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div width="[object Object]" data-slate-editor="true" data-key="8882" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8883"><span data-slate-object="text" data-key="8884"><span data-slate-leaf="true" data-offset-key="8884:0"><span><span data-slate-string="true">Name something expensive that's difficult to build and trashed after each use.</span></span></span></span></p><p data-slate-object="block" data-key="8887"><span data-slate-object="text" data-key="8888"><span data-slate-leaf="true" data-offset-key="8888:0"><span><span data-slate-string="true">Did you say rockets? No, SpaceX figured out how to reuse those in 2015. </span></span></span></span></p><p data-slate-object="block" data-key="8891"><span data-slate-object="text" data-key="8892"><span data-slate-leaf="true" data-offset-key="8892:0"><span><span data-slate-string="true">I'm talking about your company's website. Completely overhauling the website has become so routine that we've become numb to the pain of throwing it all away, over and over again.</span></span></span></span></p><p data-slate-object="block" data-key="8895"><span data-slate-object="text" data-key="8896"><span data-slate-leaf="true" data-offset-key="8896:0"><span><span data-slate-string="true">Let's explore why this happens.</span></span></span></span></p><p data-slate-object="block" data-key="8899"><span data-slate-object="text" data-key="8900"><span data-slate-leaf="true" data-offset-key="8900:0"><span><span data-slate-string="true">Imagine you're the cofounder of a new company. You need to set up a website, but your product partner is already behind on features so that leaves it solely up to you. What's your plan? Given the tight budget and schedule, the disciplined move would be to quickly use a template in an inexpensive website builder. You can graduate to something a little more custom once you have more resources and your brand, positioning, and voice figured out.</span></span></span></span></p><p data-slate-object="block" data-key="8903"><span data-slate-object="text" data-key="8904"><span data-slate-leaf="true" data-offset-key="8904:0"><span><span data-slate-string="true">Sounds like a good plan, but anyone who's gone down this path knows it's never as simple as it seems.</span></span></span></span></p><p data-slate-object="block" data-key="8907"><span data-slate-object="text" data-key="8908"><span data-slate-leaf="true" data-offset-key="8908:0"><span><span data-slate-string="true">For one, the template never lasts as long as you need it to. You realize the design isn't working, or your competitor just unexpectedly made a move. So you start trying to make changes. Swapping out the text and images comes easy, but as soon as you start adjusting the layout, frustration begins to set in. You've got a million other things to do and for some reason you can't get the page to look right on mobile. </span></span></span></span></p><p data-slate-object="block" data-key="8911"><span data-slate-object="text" data-key="8912"><span data-slate-leaf="true" data-offset-key="8912:0"><span><span data-slate-string="true">As it turns out, the same features and guard rails that made it easy to stand up the template have now become the reason it's hard to iterate. You're stuck, and whether or not you were ready, the time has come</span></span></span></span><span data-slate-object="text" data-key="8913"><span data-slate-leaf="true" data-offset-key="8913:0"><span><span data-slate-string="true"> to deal with the classic website building dilemma:</span></span></span></span></p><p data-slate-object="block" data-key="8916"><span data-slate-object="text" data-key="8917"><span data-slate-leaf="true" data-offset-key="8917:0"><span><span data-slate-string="true">Do you stay put and compromise on your vision, or invest in another solution that </span></span></span></span><span data-slate-object="text" data-key="8918"><span data-slate-leaf="true" data-offset-key="8918:0"><span><span data-slate-string="true">might</span></span></span></span><span data-slate-object="text" data-key="8919"><span data-slate-leaf="true" data-offset-key="8919:0"><span><span data-slate-string="true"> be better?</span></span></span></span></p><p data-slate-object="block" data-key="8922"><span data-slate-object="text" data-key="8923"><span data-slate-leaf="true" data-offset-key="8923:0"><span><span data-slate-string="true">After researching more advanced solutions for a few days, it starts to become apparent that you're out of your depth. There are so many different products, and every time you begin stepping away from the template you're consistently met with a giant learning curve. Frustration sets in again so you decide to call that technical friend. You're in luck! She's got her favorite tool and she's available to help.</span></span></span></span></p><p data-slate-object="block" data-key="8926"><span data-slate-object="text" data-key="8927"><span data-slate-leaf="true" data-offset-key="8927:0"><span><span data-slate-string="true">Unfortunately, all you're about to do is move your bottleneck. You may think once things are set up you can say your goodbyes, but the reality is you're never free. As your team and ideas grow you'll need more and more help, and she'll be the only one who can make the big changes. Your projects will start moving slower and slower. But on the bright side, at least you'll be able to get it done... eventually.</span></span></span></span></p><p data-slate-object="block" data-key="8930"><span data-slate-object="text" data-key="8931"><span data-slate-leaf="true" data-offset-key="8931:0"><span><span data-slate-string="true">But what happens if she leaves? Nobody likes stepping into someone else's mess, so it ends up being cheaper to just rebuild using whatever tool the new technical expert is comfortable with. </span></span></span></span><span data-slate-object="text" data-key="8932"><span data-slate-leaf="true" data-offset-key="8932:0"><span><span data-slate-string="true">Is it any mystery, then, why we're stuck in this constant build, trash, move, build cycle?</span></span></span></span><span data-slate-object="text" data-key="8933"><span data-slate-leaf="true" data-offset-key="8933:0"><span><span data-slate-string="true"> </span></span></span></span><span data-slate-object="text" data-key="8934"><span data-slate-leaf="true" data-offset-key="8934:0"><span><span data-slate-string="true">The solutions have changed, but the underlying trade-off hasn't. </span></span></span></span><span data-slate-object="text" data-key="8935"><span data-slate-leaf="true" data-offset-key="8935:0"><span><span data-slate-string="true">All options are either too basic and restrictive, or too technical and complex.</span></span></span></span></p><p data-slate-object="block" data-key="8938"><span data-slate-object="text" data-key="8939"><span data-slate-leaf="true" data-offset-key="8939:0"><span><span data-slate-string="true">Founders building out early marketing for their startups are not the only ones who experience this. At some point, all marketers feel this pain.</span></span></span></span></p><p data-slate-object="block" data-key="8942"><span data-slate-object="text" data-key="8943"><span data-slate-leaf="true" data-offset-key="8943:0"><span><span data-slate-string="true">The problem is so widespread that it's given birth to a whole category of products called landing page builders.</span></span></span></span></p><p data-slate-object="block" data-key="8946"><span data-slate-object="text" data-key="8947"><span data-slate-leaf="true" data-offset-key="8947:0"><span><span data-slate-string="true">Marketers are so fed up with being sidelined that they're willing to duct tape their site with </span></span></span></span><span data-slate-object="text" data-key="8948"><span data-slate-leaf="true" data-offset-key="8948:0"><span><span data-slate-string="true">mostly</span></span></span></span><span data-slate-object="text" data-key="8949"><span data-slate-leaf="true" data-offset-key="8949:0"><span><span data-slate-string="true"> on-brand pages, just to have some operational independence when it comes to web content. Sure, landing page builders can have extra features bolted on like A/B testing and analytics, but they aren't the real reason marketers are out shopping for a solution. Marketers are looking for a place where they can get creative and not break anything.</span></span></span></span></p><p data-slate-object="block" data-key="8952"><span data-slate-object="text" data-key="8953"><span data-slate-leaf="true" data-offset-key="8953:0"><span><span data-slate-string="true">We know this because we built and eventually sunset a landing page builder, Landing Lion. Many of our customers wished they could build full websites in it, and some actually did. Despite its many shortcomings around bulk management, a surprising number of customers were willing to put in extra manual work to build and maintain full websites. The reason? Our user experience was actually designed for them—intelligent and tech-savvy generalists who wanted to break free from the template without having to go get a degree. They could finally build exactly what they envisioned and they could do it by themselves, quickly.</span></span></span></span></p><p data-slate-object="block" data-key="8956"><span data-slate-object="text" data-key="8957"><span data-slate-leaf="true" data-offset-key="8957:0"><span><span data-slate-string="true">The real problem was that for the rest of our customers, their websites were locked down. They'd been delicately constructed by the real owners, the technical experts. But who is ultimately responsible for the </span></span></span></span><span data-slate-object="text" data-key="8958"><span data-slate-leaf="true" data-offset-key="8958:0"><span><span data-slate-string="true">entire</span></span></span></span><span data-slate-object="text" data-key="8959"><span data-slate-leaf="true" data-offset-key="8959:0"><span><span data-slate-string="true"> brand experience, website included? The marketers.</span></span></span></span></p><p data-slate-object="block" data-key="8962"><span data-slate-object="text" data-key="8963"><span data-slate-leaf="true" data-offset-key="8963:0"><span><span data-slate-string="true">That's why we're building Makeswift.</span></span></span></span></p></div></div><div><div width="[object Object]" data-slate-editor="true" data-key="8965" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8966"><span data-slate-object="text" data-key="8967"><span data-slate-leaf="true" data-offset-key="8967:0"><span><span data-slate-string="true">Marketers need a website builder designed just for them. Our mission is to tackle the issues holding back marketing teams from building, shipping, and iterating on </span></span></span></span><span data-slate-object="text" data-key="8968"><span data-slate-leaf="true" data-offset-key="8968:0"><span><span data-slate-string="true">all</span></span></span></span><span data-slate-object="text" data-key="8969"><span data-slate-leaf="true" data-offset-key="8969:0"><span><span data-slate-string="true"> web content, on their own schedule.</span></span></span></span></p><p data-slate-object="block" data-key="8972"><span data-slate-object="text" data-key="8973"><span data-slate-leaf="true" data-offset-key="8973:0"><span><span data-slate-string="true">To do this, we need to fix the user experience. More specifically, we need to move away from the split "template &amp; content" user experience found in nearly all advanced website solutions. This approach exposes two distinct experiences to the end user: One for a technical specialist to build a template, and another basic experience, usually a form, to plug in content. This creates a problem where the people responsible for the content can't change the template—sound familiar?</span></span></span></span></p><p data-slate-object="block" data-key="8976"><span data-slate-object="text" data-key="8977"><span data-slate-leaf="true" data-offset-key="8977:0"><span><span data-slate-string="true">To move as fast as possible, the people in charge of </span></span></span></span><span data-slate-object="text" data-key="8978"><span data-slate-leaf="true" data-offset-key="8978:0"><span><span data-slate-string="true">what</span></span></span></span><span data-slate-object="text" data-key="8979"><span data-slate-leaf="true" data-offset-key="8979:0"><span><span data-slate-string="true"> to build need to also control </span></span></span></span><span data-slate-object="text" data-key="8980"><span data-slate-leaf="true" data-offset-key="8980:0"><span><span data-slate-string="true">how</span></span></span></span><span data-slate-object="text" data-key="8981"><span data-slate-leaf="true" data-offset-key="8981:0"><span><span data-slate-string="true"> it's built.</span></span></span></span></p><p data-slate-object="block" data-key="8984"><span data-slate-object="text" data-key="8985"><span data-slate-leaf="true" data-offset-key="8985:0"><span><span data-slate-string="true">That's why we're focused on designing a single, elegant user experience that can be easily taught to an entire team of tech-savvy generalists. The challenge is to provide enough power for advanced use cases without making the product difficult to </span></span></span></span><span data-slate-object="text" data-key="8986"><span data-slate-leaf="true" data-offset-key="8986:0"><span><span data-slate-string="true">learn</span></span></span></span><span data-slate-object="text" data-key="8987"><span data-slate-leaf="true" data-offset-key="8987:0"><span><span data-slate-string="true">. Learning to build completely custom websites should be no more complicated than learning to design a slide show presentation.</span></span></span></span></p><p data-slate-object="block" data-key="8990"><span data-slate-object="text" data-key="8991"><span data-slate-leaf="true" data-offset-key="8991:0"><span><span data-slate-string="true">So why build another website builder? With what feels like a new website builder popping up everyday, it's apparent that we're all still searching for something better. If you're interested in shaping the way we build, ship, and iterate on web content, please sign up for our early access program.</span></span></span></span></p></div></div></div>]]>
            </description>
            <link>https://www.makeswift.com/blog/why-build-another-website-builder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837331</guid>
            <pubDate>Tue, 20 Oct 2020 13:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Differential Dataflow]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24837031">thread link</a>) | @timhigins
<br/>
October 20, 2020 | https://timelydataflow.github.io/differential-dataflow/introduction.html | <a href="https://web.archive.org/web/*/https://timelydataflow.github.io/differential-dataflow/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>In this book we will work through the motivation and technical details behind <a href="https://github.com/frankmcsherry/differential-dataflow">differential dataflow</a>, a computational framework build on top of <a href="https://github.com/frankmcsherry/timely-dataflow">timely dataflow</a> intended for efficiently performing computations on large amounts of data and <em>maintaining</em> the computations as the data change.</p>
<p>Differential dataflow programs look like many standard "big data" computations, borrowing idioms from frameworks like MapReduce and SQL. However, once you write and run your program, you can <em>change</em> the data inputs to the computation, and differential dataflow will promptly show you the corresponding changes in its output. Promptly meaning in as little as milliseconds.</p>
<p>This relatively simple set-up, write programs and then change inputs, leads to a surprising breadth of exciting and new classes of scalable computation. We will explore it in this document!</p>
<hr>
<p>Differential dataflow arose from <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2013/11/naiad_sosp2013.pdf">work at Microsoft Research</a>, where we aimed to build a high-level framework that could both compute and incrementally maintain non-trivial algorithms.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://timelydataflow.github.io/differential-dataflow/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837031</guid>
            <pubDate>Tue, 20 Oct 2020 13:31:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The surprising impact of medium-size texts on PostgreSQL performance]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24836979">thread link</a>) | @haki
<br/>
October 20, 2020 | https://hakibenita.com/sql-medium-text-performance | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-medium-text-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Any database schema is likely to have plenty of text fields. In this article, I divide text fields into three categories:</p>
<ol>
<li>
<p><strong>Small texts</strong>: names, slugs, usernames, emails, etc. These are text fields that usually have some low size limit, maybe even using <code>varchar(n)</code> and not <code>text</code>.</p>
</li>
<li>
<p><strong>Large texts</strong>: blog post content, articles, HTML content etc. These are large pieces of free, unrestricted text that is stored in the database.</p>
</li>
<li>
<p><strong>Medium texts</strong>: descriptions, comments, product reviews, stack traces etc. These are any text field that is between the small and the large. These type of texts would normally be unrestricted, but naturally smaller than the large texts.</p>
</li>
</ol>
<p><strong>In this article I demonstrate the surprising impact of medium-size texts on query performance in PostgreSQL.</strong></p>
<figure><img alt="Sliced bread... it gets better<br><small>Photo by <a href=&quot;https://unsplash.com/photos/WHJTaLqonkU&quot;>Louise Lyshøj</a></small>" src="https://hakibenita.com/images/00-sql-medium-text-performance.jpg"><figcaption>Sliced bread... it gets better<br><small>Photo by <a href="https://unsplash.com/photos/WHJTaLqonkU">Louise Lyshøj</a></small></figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="understanding-toast"><a href="#understanding-toast">Understanding TOAST</a></h2>
<p>When talking about large chunks of text, or any other field that may contain large amounts of data, we first need to understand how the database handles the data. Intuitively, you might think that the database is storing large pieces of data inline like it does smaller pieces of data, but in fact, <a href="https://www.postgresql.org/docs/current/storage-toast.html" rel="noopener">it does not</a>:</p>
<blockquote>
<p>PostgreSQL uses a fixed page size (commonly 8 kB), and does not allow tuples to span multiple pages. Therefore, it is not possible to store very large field values directly.</p>
</blockquote>
<p>As the documentation explains, PostgreSQL can't store rows (tuples) in multiple pages. So how does the database store large chunks of data?</p>
<blockquote>
<p>[...] large field values are compressed and/or broken up into multiple physical rows. [...] The technique is affectionately known as TOAST (or “the best thing since sliced bread”).</p>
</blockquote>
<p>OK, so how is this TOAST working exactly?</p>
<blockquote>
<p>If any of the columns of a table are TOAST-able, the table will have an associated TOAST table</p>
</blockquote>
<p>So TOAST is a separate table associated with our table. It is used to store large pieces of data of TOAST-able columns (the <code>text</code> datatype for example, is TOAST-able).</p>
<p>What constitutes a large value?</p>
<blockquote>
<p>The TOAST management code is triggered only when a row value to be stored in a table is wider than TOAST_TUPLE_THRESHOLD bytes (normally 2 kB). The TOAST code will compress and/or move field values out-of-line until the row value is shorter than TOAST_TUPLE_TARGET bytes (also normally 2 kB, adjustable) or no more gains can be had</p>
</blockquote>
<p>PostgreSQL will try to compress a the large values in the row, and if the row can't fit within the limit, the values will be stored out-of-line in the TOAST table.</p>
<h3 id="finding-the-toast"><a href="#finding-the-toast">Finding the TOAST</a></h3>
<p>Now that we have <em>some</em> understanding of what TOAST is, let's see it in action. First, create a table with a text field:</p>
<div><pre><span></span><span>db=#</span> <span>CREATE</span> <span>TABLE</span> <span>toast_test</span> <span>(</span><span>id</span> <span>SERIAL</span><span>,</span> <span>value</span> <span>TEXT</span><span>);</span>
<span>CREATE TABLE</span>
</pre></div>


<p>The table contains an id column, and a value field of type <code>TEXT</code>. Notice that we did not change any of the default storage parameters.</p>
<p>The text field we added supports TOAST, or is TOAST-able, so PostgreSQL should create a TOAST table. Let's try to locate the TOAST table associated with the table <code>toast_test</code> in <a href="https://www.postgresql.org/docs/current/catalog-pg-class.html" rel="noopener"><code>pg_class</code></a>:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>relname</span><span>,</span> <span>reltoastrelid</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'toast_test'</span><span>;</span>
<span>  relname   │ reltoastrelid</span>
<span>────────────┼───────────────</span>
<span> toast_test │        340488</span>

<span>db=#</span> <span>SELECT</span> <span>relname</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>oid</span> <span>=</span> <span>340488</span><span>;</span>
<span>     relname</span>
<span>─────────────────</span>
<span> pg_toast_340484</span>
</pre></div>


<p>As promised, PostgreSQL created a TOAST table called <code>pg_toast_340484</code>.</p>
<h3 id="toast-in-action"><a href="#toast-in-action">TOAST in Action</a></h3>
<p>Let's see what the TOAST table looks like:</p>
<div><pre><span></span><span>db=#</span> <span>\d</span> <span>pg_toast.pg_toast_340484</span>
<span>TOAST table "pg_toast.pg_toast_340484"</span>
<span>   Column   │  Type</span>
<span>────────────┼─────────</span>
<span> chunk_id   │ oid</span>
<span> chunk_seq  │ integer</span>
<span> chunk_data │ bytea</span>
</pre></div>


<p>The TOAST table contains three columns:</p>
<ul>
<li><code>chunk_id</code>: A reference to a toasted value.</li>
<li><code>chunk_seq</code>: A sequence within the chunk.</li>
<li><code>chunk_data</code>: The actual chunk data.</li>
</ul>
<p>Similar to "regular" tables, the TOAST table also has the same restrictions on inline values. To overcome this restriction, large values are split into chunks that can fit within the limit.</p>
<p>At this point the table is empty:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼────────────</span>
<span>(0 rows)</span>
</pre></div>


<p>This makes sense because we did not insert any data yet. So next, insert a small value into the table:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'small value'</span><span>);</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼────────────</span>
<span>(0 rows)</span>
</pre></div>


<p>After inserting the small value into the table, the TOAST table remained empty. This means the small value was small enough to be stored inline, and there was no need to move it out-of-line to the TOAST table.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 176.3 111" height="10em"><path d="M9 47c62-3 116 2 153-2M13 47c49 0 93 0 150 2m-3-4c3 17 2 22 4 53m-2-52c-3 14-2 31 0 56m2-4c-37 1-78 7-150 5m149-4H13m0 4c-3-15 1-28-4-56m3 55c2-11-1-25 1-54" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><path d="M10 12l155-1v37L12 46" stroke-width="0" fill="#f2f2f2"></path><path d="M10 9c43-1 84 0 156 2M11 11c36 1 75 0 155-1m1-2l-2 38m1-36v39m1 0c-39 2-78 1-159 0m158-2c-39 2-77 2-155 0m-3 1c0-8 3-20 3-36m-1 37V10" stroke="currentColor" fill="none"></path><path d="M52 16l4 81m0-84c-1 19-5 36-3 88" stroke="currentColor" fill="none"></path><text y="15" font-size="16" transform="translate(23 18)">id</text><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Small text stored inline</figcaption>
</figure>

<p>Let's insert a large value and see what happens:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'n0cfPGZOCwzbHSMRaX8 ... WVIlRkylYishNyXf'</span><span>);</span>
<span>INSERT 0 1</span>
</pre></div>


<p>I shortened the value for brevity, but that's a random string with 4096 characters. Let's see what the TOAST table stores now:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼──────────────────────</span>
<span>   995899 │         0 │ \x30636650475a4f43...</span>
<span>   995899 │         1 │ \x50714c3756303567...</span>
<span>   995899 │         2 │ \x6c78426358574534...</span>
<span>(3 rows)</span>
</pre></div>


<p>The large value is stored out-of-line in the TOAST table. Because the value was too large to fit inline in a single row, PostgreSQL split it into three chunks. The <code>\x3063...</code> notation is how psql displays binary data.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 435.8 254" height="20em"><path d="M9 43c58 5 116 4 154 6M14 48c34-1 70 1 148-1m2 0c-5 34-4 68-3 92m0-94c1 34 4 69 2 96m-4 0c-27-2-54-2-143-5m145 3c-47 2-96 2-147 1m-2 3c5-29 2-60 0-94m2 89c1-36-2-72-3-90" stroke="currentColor" fill="none"></path><path d="M10 95c45-2 79 3 150 0M12 96c53 0 106-3 147-3" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><text y="15" font-size="16" fill="currentColor" transform="translate(34 106)">2</text><path d="M108 109l4 3 3 5-2 4-5 4h-4l-4-3v-7c0-2 1-2 3-3l6-3 1 1m-4-2l3 3 3 5 1 4c0 2-1 2-2 3l-6 3-4-5c-1-2-3-4-2-5l2-4 4-4 1 3" stroke-width="0" fill="#f41d92"></path><path d="M105 110h5l2 4 2 5c0 2-3 3-4 4l-4 2c-2 0-2-1-3-2l-4-6 2-4 4-5 1 2m-1 0l6 1 3 3-1 4-1 4-6 3-3-1-3-5v-7l6-2-2-1M115 115c30 2 64 1 141 0m-141 1c34-1 70-3 142-1" stroke="currentColor" fill="none"></path><path d="M229 125c5-1 13-4 26-11m-26 11l27-10" stroke="currentColor" fill="none"></path><path d="M229 104c5 4 13 6 26 10m-26-9c6 3 14 4 27 10" stroke="currentColor" fill="none"></path><path d="M275 104h152v137l-151 3" stroke-width="0" fill="#f41d92"></path><path d="M276 99c36 2 66 5 146 7m-148-3c47-2 87-3 150 0m2 4c-5 40-4 85-2 135m2-139c-2 41-1 78 0 140m1-3c-53 5-105-2-149 0m146 4c-45 1-90 0-146-2m1-1c-4-56-3-110 0-135m-5 135c5-48 3-100 2-138" stroke="currentColor" fill="none"></path><path d="M314 107c1 30 5 66 8 136m-3-136v137" stroke="currentColor" fill="none"></path><path d="M279 153c36 6 77 8 145 2m-145 0c50-2 102-2 146-2M271 194c46 0 91 2 151 5m-148-2c29-3 59-1 146-1" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(294 165)">2</text><text y="15" font-size="16" fill="currentColor" transform="translate(295 119)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(292 207)">3</text><text y="15" font-size="16" fill="currentColor" transform="translate(329 118)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(331 164)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(332 206)">\x.....</text><g><path d="M12 9l153 1-1 36-153 1" stroke-width="0" fill="#f2f2f2"></path><path d="M11 12c50 0 100-4 157-2M9 11c48-3 97-3 158-1m1 0c-3 13 0 29-2 39m0-39v39m-1-1c-41-2-80 1-154-2m156 2c-62 2-122 2-158 0m2 1c1-12-2-25-3-40m1 39c1-12 2-23 1-38" stroke="currentColor" fill="none"></path></g><g><path d="M55 11c-1 39 2 67 0 130M54 16c4 36 3 74 1 120" stroke="currentColor" fill="none"></path></g><g><text y="15" font-size="16" transform="translate(23 18)">id</text></g><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Large text stored out-of-line, in the associated TOAST table</figcaption>
</figure>

<p>Finally, execute the following query to summarize the data in the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>
<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>   995899 │      3 │ 4096 bytes</span>
<span>(1 row)</span>
</pre></div>


<p>As we've already seen, the text is stored in three chunks.</p>
<div>
<p>size of database objects</p>
<p>There are several ways to get the <a href="https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADMIN-DBSIZE" rel="noopener">size of database objects in PostgreSQL</a>:</p>
<ul>
<li><code>pg_table_size</code>: Get the size of the table including TOAST, but excluding indexes</li>
<li><code>pg_relation_size</code>: Get the size of just the table</li>
<li><code>pg_total_relation_size</code>: Get the size of the table, including indexes and TOAST</li>
</ul>
<p>Another useful function is <code>pg_size_pretty</code>: used to display sizes in a friendly format.</p>
</div>
<h3 id="toast-compression"><a href="#toast-compression">TOAST Compression</a></h3>
<p>So far I refrained from categorizing texts by their size. The reason for that is that the size of the text itself does not matter, what matters is its size after compression.</p>
<p>To create long strings for testing, we'll implement a function to generate random strings at a given length:</p>
<div><pre><span></span><span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> <span>generate_random_string</span><span>(</span>
  <span>length</span> <span>INTEGER</span><span>,</span>
  <span>characters</span> <span>TEXT</span> <span>default</span> <span>'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'</span>
<span>)</span> <span>RETURNS</span> <span>TEXT</span> <span>AS</span>
<span>$$</span>
<span>DECLARE</span>
  <span>result</span> <span>TEXT</span> <span>:=</span> <span>''</span><span>;</span>
<span>BEGIN</span>
  <span>IF</span> <span>length</span> <span>&lt;</span> <span>1</span> <span>then</span>
      <span>RAISE</span> <span>EXCEPTION</span> <span>'Invalid length'</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>
  <span>FOR</span> <span>__</span> <span>IN</span> <span>1..</span><span>length</span> <span>LOOP</span>
    <span>result</span> <span>:=</span> <span>result</span> <span>||</span> <span>substr</span><span>(</span><span>characters</span><span>,</span> <span>floor</span><span>(</span><span>random</span><span>()</span> <span>*</span> <span>length</span><span>(</span><span>characters</span><span>))</span><span>::</span><span>int</span> <span>+</span> <span>1</span><span>,</span> <span>1</span><span>);</span>
  <span>end</span> <span>loop</span><span>;</span>
  <span>RETURN</span> <span>result</span><span>;</span>
<span>END</span><span>;</span>
<span>$$</span> <span>LANGUAGE</span> <span>plpgsql</span><span>;</span>
</pre></div>


<p>Generate a string made out of 10 random characters:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>);</span>
<span> generate_random_string</span>
<span>────────────────────────</span>
<span> o0QsrMYRvp</span>
</pre></div>


<p>We can also provide a set of characters to generate the random string from. For example, generate a string made of 10 random digits:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>,</span> <span>'1234567890'</span><span>);</span>
<span> generate_random_string</span>
<span>────────────────────────</span>
<span> 4519991669</span>
</pre></div>


<p>PostgreSQL TOAST uses the <a href="https://doxygen.postgresql.org/pg__lzcompress_8c_source.html" rel="noopener">LZ family of compression</a> techniques. Compression algorithms usually work by identifying and eliminating repetition in the value. A long string containing fewer characters should compress very well compared to a string made of many different characters when encoded into bytes.</p>
<p>To illustrate how TOAST uses compression, we'll clean out the <code>toast_test</code> table, and insert a random string made of many possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>TRUNCATE</span> <span>toast_test</span><span>;</span>
<span>TRUNCATE TABLE</span>

<span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>));</span>
<span>INSERT 0 1</span>
</pre></div>


<p>We inserted a 10kb value made of random characters. Let's check the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
</pre></div>


<p>The value is stored out-of-line in the TOAST table, and we can see it is not compressed.</p>
<p>Next, insert a value with a similar length, but made out of fewer possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'123'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
<span>  1495961 │      2 │ 3067 bytes</span>
</pre></div>


<p>We inserted a 10K value, but this time it only contained 3 possible digits: <code>1</code>, <code>2</code> and <code>3</code>. This text is more likely to contain repeating binary patterns, and should compress better than the previous value. Looking at the TOAST, we can see PostgreSQL compressed the value to ~3kB, which is a third of the size of the uncompressed value. Not a bad compression rate!</p>
<p>Finally, insert a 10K long string made of a single digit:</p>
<div><pre><span></span><span>db=#</span> <span>insert</span> <span>into</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>values</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'0'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
<span>  1495961 │      2 │ 3067 bytes</span>
</pre></div>


<p>The string was compressed so well, that the database was able to store it in-line.</p>
<h3 id="configuring-toast"><a href="#configuring-toast">Configuring TOAST</a></h3>
<p>If you are interested in configuring TOAST for a table you can do that by setting storage parameters at <code>CREATE TABLE</code> or <code>ALTER …</code></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-medium-text-performance">https://hakibenita.com/sql-medium-text-performance</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-medium-text-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836979</guid>
            <pubDate>Tue, 20 Oct 2020 13:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The biggest thing I learned launching Zapier (2014)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24836252">thread link</a>) | @andrelaszlo
<br/>
October 20, 2020 | https://mikeknoop.com/biggest-thing-learned-launching-zapier/ | <a href="https://web.archive.org/web/*/https://mikeknoop.com/biggest-thing-learned-launching-zapier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>

      

        
        <!--<p><img src="/static/img/upload/9f67b80a8be311e3b2c528cfe91e44cb.png" /></p>-->
        

        <p>Last updated Feb. 3, 2014 — read <span id="post-views">25672</span> times</p>

        <p><strong>This post is adapted from <a href="https://mikeknoop.com/iowaconf-road-to-zapier">a talk I gave</a> at <a href="http://iowaconf.com/">iowaconf</a> October 2013</strong></p>

<p>I was one of three co-founders of <a href="https://zapier.com/">Zapier</a>. If you're unfamiliar with the origin story, we got started out of a <a href="http://columbia.startupweekend.org/">Startup Weekend</a> in Columbia, Mo. in 2011.</p>

<p>The prompt for this talk was to describe “what you learned building Zapier”. The most obvious thing I could share is tactical advice or early anecdotes. Things like how we got our first dozen customers to pay us before we really had a product or how we almost missed our acceptance call into <a href="https://ycombinator.com/">Y Combinator</a>.</p>

<p>And to be clear, I'm still leaning <em>a ton</em> through today. Startups are very much “trial-by-fire” as a first-time founder.</p>

<p>But the more I thought about that talk prompt, I realized the biggest thing I learned actually began way, way earlier. It's a lesson that applies equally to launching Zapier as to endeavors which lie beyond.</p>



<p>Growing up I've was always into tech and I loved building things (I originally wanted to be an architect when I thought that's what they did).</p>

<p>I learned how to build websites after borrowing a friend's “Learn HTML in 24 Hours” book. My goal was to build an AOL Instant Messenger profile for myself, which conveniently, could render actual HTML.</p>

<p>Later I learned how to code “hardcore” by picking up assembly language. I did this so I could write TI-83+ calculator games and play them during class (much to the dismay to my teachers growing up).</p>

<p>Towards the end of high school though, it was time to pick a major. Computer Science was the obvious shoe-in. But I didn't want to do it! I feared that I would burn out and not have time/energy for side projects.</p>

<p>So I decided instead to do Mechanical Engineering instead – also maybe not the best choice considering my goal outlined above but at least I wouldn't be coding 24/7 for school.</p>



<p>Facebook was just taking off during my freshman year of college. They launched their original developer platform that fall and I was instantly hooked.</p>

<p>I spent a good chunk of free time building apps. Like this one that you could use to request phone numbers from your fiends.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e5f24a618be311e3ae7628cfe91e44cb.png" alt=""></p>

<p>Or this one which was a developer toolkit, making it easy to embed Facebook-style form elements.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e45bf5828be311e3b0bb28cfe91e44cb.png" alt=""></p>

<p>Or even my last solo Facebook endeavor, a monitoring tool for the Facebook Platform, which peaked at a grand total of 1 paying user.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e35826a88be311e3982b28cfe91e44cb.png" alt=""></p>

<p>You can probably guess: my ROI wasn't too great. But I was very active in the Facebook developer community and made a name for myself. Facebook reached out and asked if I'd like to become a community moderator. I have to imagine this was because of my community participation and not because they looked at any of my app analytics. </p>

<p><img src="https://mikeknoop.com/static/img/upload/e5897b478be311e3a69228cfe91e44cb.png" alt=""></p>

<p>This moderator gig led me to write developer columns for Inside Facebook and in combination, these two things generally kept my around the platform much longer than I otherwise should have.</p>

<p>It did turn out to be useful though.</p>



<p>I was applying for summer engineering internships after my Junior year of college. I applied about two dozen engineering firms in Missouri as well as a few web development gigs.</p>

<p>Of all resume's I sent out I only heard back from one place, <a href="http://veteransunited.com/">Veterans United</a>, a VA loan lender based in Columbia Mo. I learned they wanted to build an app for military personnel to reconnect inside of Facebook.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e4ebb0e88be311e3864128cfe91e44cb.png" alt=""></p>

<p>I worked on Military Basebook for about a year. It peaked around 20,000 monthly active users but ultimately wasn't sticky enough. Around this time I learned a few things:</p>

<p><em>1. Facebook apps that aren't games just don't work well</em></p>

<p>Even today the most successful apps on Facebook are games. Users on Facebook just aren't in mindset to seek out utilities.</p>

<p><em>2. I didn't want to do the traditional engineering career</em></p>

<p>Although the sentiment had been brewing for a while, that summer was a turning point where I actively decided I would focus on side projects post college instead of seeking a full time job. I was going to keep throwing stuff at the wall and see if something stuck.</p>

<p>I began my mechanical engineering masters program (which I ended up dropping out of) as part of this strategy. I was able to secure a 2-year grant which paid for school living expenses. This left me with a lot of free time for my side projects.</p>



<p>Around the middle of my junior year I discovered <a href="https://news.ycombinator.com/">Hacker News</a>. If you're unfamiliar, it is a lot like Reddit (HN actually came first) where stories and articles are upvoted to the frontpage. Usually people post about programming and startups.</p>

<p>One convention on Hacker News is called “Show HN” which is a way for people to show off their side projects and solicit feedback.</p>

<p>One “Show HN” caught my eye by a user called <a href="https://news.ycombinator.com/?user=phpnode">phpnode</a> (thank you phpnode!). He launched a side project called <a href="http://zpr.io/6dM7.png">Hackernewsers</a> which was a map of users who used Hacker News.</p>

<p>The idea was simple. You submit your username, real name, and location and you get access to a map where you can see others who've done the same. I checked out Columbia Mo. and I saw something interesting – there was someone else in the area! It turns out that other person was this guy:</p>

<p>[Bryan Helmig]</p>

<p>I remember clicking through all the information I could find online about him. I found his <a href="http://bryanhelmig.com/">personal blog</a>, some of his <a href="http://rankiac.com/">side projects</a>, and even <a href="http://youtube.com/">his YouTube channel</a>. But the most important thing I learned was that he worked at same company I did, <a href="http://veteransunited.com/">Veterans United</a>.</p>

<p>That was enough of a connection for me so I got in touch over Facebook. We met up several times that year for beers and wanted to work on something together.</p>



<p>Mizzou, the university I attended in Columbia, sent out a weekly email with things happening on campus and in the area. I usually auto-archived these. I must have been pretty bored the day I <a href="http://google.com/">opened this one</a>, but I'm glad I did. I found an enticing headline “Startup Weekend is Coming to Columbia”.</p>

<p>I had never heard of Startup Weekend but I knew I liked building things, I knew I liked startups, so maybe this is something I wanted to be a part of. I then discovered tickets cost $50 and was a bit turned off.</p>

<p>Maybe if I could find someone else going, it would be worth the money. So I messaged Bryan and he said he was going! I bought tickets later that night, and that's how I wound up at Columbia Missouri's first ever Startup Weekend.</p>

<p>At Startup Weekend I formally met <a href="http://wadefoster.net/">Wade Foster</a> who also happened to work at Veterans United. We got together and worked on the project that Bryan originally pitched as “API Mixer”. The idea was simple: make a tool that enables anyone (marketers, sales, HR, developers) to connect together two web services they use.</p>

<p>In true startup fashion we took to the back garage and got to work. The <a href="https://zapier.com/blog">story of Zapier</a> is still being written today.</p>



<p>When I look back on the decisions that lead me to Startup Weekend I am amazed how many times the proverbial train of life could have been derailed.</p>

<p>What if I hadn't opened that email? What if I never got into Facebook development? What if I hadn't worked at Veterans United?</p>

<p>In reminds me a lot of the game Plinko on The Price is Right. The one where the contestant drops the puck down a pegged board and it randomly makes it's way down to one of the buckets at the bottom with the winning bucket in the middle.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9ed525578be311e39e8a28cfe91e44cb.png" alt="Plinko"></p>

<p>The funny thing about plinko is, if you run sufficiently many trials, the middle bucket is actually the easiest to hit! The outcome follows a normal distribution.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9dfcebde8be311e3ae7b28cfe91e44cb.png" alt="Plink Distrobution"></p>

<p>The take away here is if you go through life making random decisions, statistically, you'll wind up in the middle. While in Plinko the middle is the best, in reality, the really exciting stuff happens at the edges of the board. That's where Zapier happened. And to get there you've got to purposely push yourself towards the outsides.</p>

<p>Although I didn't realize it at the time, there was a guiding principle for all my decisions. I was always putting myself out there, in uncomfortable, new situations that challenged my own status quo.</p>

<p>That's the road to the outside of the Plinko board. And that's the biggest thing I learned by creating Zapier.</p>


        

          <p>If you'd like to see more posts like this one, <a href="https://twitter.com/intent/user?screen_name=mikeknoop">follow me on Twitter</a>!</p>

        

        

            <!-- removed disqus commenting -->

        

      

    </div>

    

    </div></div>]]>
            </description>
            <link>https://mikeknoop.com/biggest-thing-learned-launching-zapier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836252</guid>
            <pubDate>Tue, 20 Oct 2020 11:47:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raymarching with Fennel and LÖVE]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24835766">thread link</a>) | @forgotpwd16
<br/>
October 20, 2020 | https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/ | <a href="https://web.archive.org/web/*/https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Previously I’ve decided to implement a rather basic <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/">raycasting engine in ClojureScript</a>.
It was a lot of fun, an interesting experience, and ClojureScript was awesome.
I’ve implemented small <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/#labyrinth-game">labyrinth game</a>, and thought about adding more features to the engine, such as camera shake, and wall height change.
But when I’ve started working on these, I quickly understood, that I’d like to move on to something more interesting, like real 3D rendering engine, that also uses rays.</p>
<p>Obviously, my first though was about writing a ray-tracer<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
This technique is wide known, and gained a lot of traction recently.
With native hardware support for ray tracing, a lot of games are using it, and there are a lot of tutorials teaching how to implement one<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.
In short, we cast a bunch of rays in 3D space, and calculate their trajectories, looking for what ray will hit and bounce off.
Different materials have different bounce properties, and by tracing rays from camera to the source of light, we can imitate illumination.
There are also a lot of different approaches how to calculate bouncing, e.g. for global illumination, and ambient light, but I’ve felt that it is a rather complicated task, for a weekend post.
And unlike raycasting, most ray-tracers require polygonal information in order to work, where raycasting only need to know wall start and end points.</p>
<p>I’ve wanted a similar approach for 3D rendering, where we specify an object in terms of it’s mathematical representation.
Like for sphere, we’ll just specify coordinate of a center, and a radius, and our rays will find intersection points with it, providing us a sufficient data to draw this sphere on screen.
And recently, I’ve read about a similar technique, that uses rays for drawing on screen, but instead of casting infinite rays as in raycasting, it marches a ray in terms of steps.
And it also uses a special trick, to make this process very optimized, therefore we can use it for rendering real 3D objects.</p>
<p>I’ve decided to structure this post similarly to the one about raycasting, so this will be another long-read, often more about Fennel rather than raymarching, but at the end I promise that we’ll get something that looks like this:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/end-result.png"> 
</figure>

<p>So, just as in raycasting, first we need to do is to understand how raymarching engine works <em>on paper</em>.</p>
<h2 id="raymarching-basics">Raymarching basics</h2>
<p>Raymarching can be illustrated similarly to raycaster, except it requires more steps until we could render our image.
First, we need a camera, and an object to look at:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle.svg"> 
</figure>

<p>Our first step would to cast a ray, however, unlike with raycasting, we’ll cast a portion of a ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-short-ray.svg"> 
</figure>

<p>We then check, if the ray intersects with the sphere.
It’s not, so we do one more step:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-two-steps.svg"> 
</figure>

<p>It’s not intersecting yet, so we repeat again:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-ray-overshoot.svg"> 
</figure>

<p>Oops, ray overshoot, and is now inside the sphere.
This is not really good option for us, as we want for our rays to end directly at the object’s surface, without calculating intersection point with the object itself.
We can fix this by casting shorter ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-small-rays.svg"> 
</figure>

<p>However, this is very inefficient!
And besides, if we’ll change the angle a bit or move the camera, we will overshoot again.
Which means that we’ll either have incorrect result, or require a very small step size, which will blow up computation process.
How we can fix this?</p>
<h3 id="distance-estimation">Distance estimation</h3>
<p>The solution to this is a signed distance function, or a so called Distance Estimator.
Imagine if we knew how far we are from the object at any point of time?
This would mean that we can shoot a ray of this length in any direction and still don’t hit anything.
Let’s add another object to the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/scene-with-two-objects.svg"> 
</figure>

<p>Now, let’s draw two circles, which will represent distances from the objects, to the point from where we’ll cast rays:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/distances.svg"> 
</figure>

<p>We can see, that there are two circles, and one is bigger than another.
This means, that if we choose the shortest safe distance, we can safely cast ray in any direction and not overshoot anything.
For example, let’s cast a ray towards the square:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/ray-in-safe-zone.svg"> 
</figure>

<p>We can see, that we haven’t reached the square, but more importantly we did not overshoot it.
Now we need to march the ray again, but what distance should it cover?
To answer this question, we need to take another distance estimation from ray end to the objects in the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/second-safe-march.svg"> 
</figure>

<p>Once again we choose shorter distance, and march towards the square, then get the distance again, and repeat the whole process:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/another-safe-match.svg"> 
</figure>

<p>You can see that with each step the distance to the object becomes smaller, and thus we will never overshoot the object.
However this also means, that we will take a lot of really small steps, until we finally fully hit the object, if we ever do.
This is not a good idea, because it is even more inefficient than using fixed distance, and produces too accurate results, which we don’t really need.
So instead of marching up until we exactly hit the object, we will march <em>enough</em> times.
E.g. until the distance to the object is small enough, then there’s no real point to continue marching, as it is clear that we will hit the object soon.
But this also means, that if the ray goes near the edge of an object, we do a lot of expensive steps of computing distance estimations.</p>
<p>Here’s a ray that is parallel to the side of the square, and marches towards the circle:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/expensive-marching.svg"> 
</figure>

<p>We do a lot of seemingly pointless measurements, and if a ray was closer to the square’s side, we would do even more steps.
However this also means, that we can use this data (since we’re already computed it) to render such things as glow, or ambient occlusion.
But more on this later.</p>
<p>Once ray hit an object we have all the data we need.
Ray represents a point on the screen, and the more rays we cast the higher resolution of our image will be.
And since we’re not using triangles to represent objects, our spheres will always be smooth, no matter how close we are to it, because there’s no polygons involved.</p>
<p>This is basically it.
Ray marching is quite simple concept, just like raycaster, although it’s a bit more complicated, as we do have to compute things in 3D space now.
So let’s begin implementing it by installing required tools, and setting up the project.</p>
<h2 id="project-structure">Project structure</h2>
<p>As you know from the title we will use two main tools to create ray-marcher, which are <a href="https://love2d.org/">LÖVE</a>, a free game engine, and <a href="https://fennel-lang.org/">Fennel</a> the programming language.
I’ve chosen Fennel, because it is a Lisp like language, that compiles to Lua, and I’m quite a fan of Lisps.
But we also needed to draw somewhere, and I know no GUI toolkit for Lua.
But there is LÖVE - a game engine that runs Lua code, which is capable on running on all systems, thus a perfect candidate for our task.</p>
<p>Installation steps may differ per operating system, so please refer to manuals<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup><sup>, </sup><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.
At the time of writing this post I’m using Fedora GNU/Linux, so for me it means:</p>
<div><pre><code data-lang="sh">$ sudo dnf install love luarocks readline-devel
$ luarocks install --local fennel
$ luarocks install --local readline <span># requires readline-devel</span>
$ <span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:</span><span>$HOME</span><span>/.luarocks/bin"</span>
</code></pre></div><p>It’s better to permanently add <code>$HOME/luarocks/bin</code> (or another path, if your installation differs) to the <code>PATH</code> variable in your shell, in order to be able to use installed utilities without specifying full path every time.
You can test if everything is installed correctly, by running <code>fennel</code> in you command line.</p>
<div><pre><code data-lang="sh">$ fennel
Welcome to Fennel 0.5.0 on Lua 5.3!
Use (doc something) to view documentation.
&gt;&gt; (+ 1 2 3)
6
&gt;&gt;
</code></pre></div><p>For other distributions installation steps may vary, and for Windows, I think it’s safe to skip the <code>readline</code> part, which is fully optional, but makes editing in a REPL a bit more comfortable.</p>
<p>Once everything is installed, let’s create the project directory, and the <code>main.fnl</code> file, where we will write our code.</p>
<div><pre><code data-lang="sh">$ mkdir love_raymarching
$ <span>cd</span> love_raymarching
$ touch main.fnl
</code></pre></div><p>And that’s it!
We can test if everything works by adding this code to <code>main.fnl</code>:</p>
<div><pre><code data-lang="clojure">(<span>fn </span><span>love.draw</span> []
  (<span>love.graphics.print</span> <span>"It works!"</span>))
</code></pre></div><p>Now we can compile it with <code>fennel --compile main.fnl &gt; main.lua</code>, thus producing the <code>main.lua</code> file, and run <code>love .</code> (dot is intentional, it indicates current directory).</p>
<p>A window should appear, with white text <code>It works!</code> in upper left corner:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/love-works.png"> 
</figure>

<p>Now we can begin implementing our raymarcher.</p>
<h2 id="scene-setup">Scene setup</h2>
<p>Just as in raycaster, we need a camera that will shoot rays, and some objects to look at.
Let’s begin by creating a camera object, that will store coordinates and rotation information.
We can do so, by using <code>var</code> to declare a variable that is local to our file, and that we can later change with <code>set</code><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>:</p>

<div><pre><code data-lang="clojure">(<span>var </span><span>camera</span> {<span>:pos</span> [0.0 0.0 0.0]
             <span>:x-rotate</span> 0.0
             <span>:z-rotate</span> 0.0})
</code></pre></div><blockquote>
<p>For those unfamiliar with Lisps, and especially Clojure, let me quickly explain what this syntax is.
If you know this stuff, feel free to <a href="#org6f2d291">skip this part</a>.</p>
<p>We start by using a <code>var</code> special form, that binds a value to a name like this: <code>(var name value)</code>.
So if we start the REPL, using <code>fennel</code> command in the shell, and write <code>(var a 40)</code>, a new variable <code>a</code> will be created.
We then can check, that it has the desired value by typing <code>a</code>, and pressing return:</p>
<p>We can then alter the contents of this variable by using <code>set</code> special form, which works like this <code>(set name new-value)</code>:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>set </span><span>a</span> (<span>+ </span><span>a</span> 2))
<span>&gt;&gt;</span> <span>a</span>
42
</code></pre></div><p>Now to curly and square brackets.
Everything enclosed in curly braces is a hashmap.
We can use any Lua value as our key, and the most common choice is a string, but Fennel has additional syntax for defining keys - a colon followed by a word: <code>:a</code>.
This is called a keyword, and in Fennel it is essentially the same as <code>"a"</code>, but we don’t need to write a pair of quotes.
However keywords can’t contain spaces, and some other symbols.</p>
<p>So writing this <code>{:a 0 :b 2 :c :hello}</code> in the REPL will make a new table, that holds three key value pairs, which we can later get with another syntax - the dot <code>.</code>.
Combining it with <code>var</code>, we can see that it works:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>var </span><span>m</span> {<span>:a</span> 1 <span>:b</span> 2 <span>:c</span> <span>:hello</span>})
<span>&gt;&gt;</span> (<span>. </span><span>m</span> <span>:b</span>)
2
</code></pre></div><p>There’s also a shorthand for this …</p></blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</a></em></p>]]>
            </description>
            <link>https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835766</guid>
            <pubDate>Tue, 20 Oct 2020 10:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig and Rust]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 278 (<a href="https://news.ycombinator.com/item?id=24835357">thread link</a>) | @ikskuh
<br/>
October 20, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(…</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835357</guid>
            <pubDate>Tue, 20 Oct 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Design Stripe or Hacker News-like favicons in seconds]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24835219">thread link</a>) | @hosshams
<br/>
October 20, 2020 | https://formito.com/tools/favicon | <a href="https://web.archive.org/web/*/https://formito.com/tools/favicon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Copy the following code and put it inside the<!-- --> <code>&lt;head&gt;</code> tag of your website.</p><pre><code></code></pre><p>Or, download the SVG file, add the following code to<!-- --> <code>&lt;head&gt;</code> tag of your website, and replace<!-- --> <code>href</code> attribute with URL to your SVG file.</p><pre><code>&lt;link rel="icon" type="image/svg+xml" href="favicon.svg" /&gt;</code></pre></div></div>]]>
            </description>
            <link>https://formito.com/tools/favicon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835219</guid>
            <pubDate>Tue, 20 Oct 2020 08:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discipline Doesn’t Scale]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24834965">thread link</a>) | @ingve
<br/>
October 20, 2020 | https://www.sicpers.info/2020/10/discipline-doesnt-scale/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/10/discipline-doesnt-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>If programmers were just more disciplined, more <em>professional</em>, they’d write better software. All they need is a <a href="https://www.pearson.com/us/higher-education/program/Martin-Clean-Coder-The-A-Code-of-Conduct-for-Professional-Programmers/PGM8366.html">code of conduct</a> telling them how to work like those of us who’ve worked it out.</p>
<p>The above statement is true, which is a good thing for those of us interested in improving the state of software and in helping our fellow professionals to improve their craft. However, it’s also very difficult and inefficient to apply, in addition to being entirely unnecessary. In the common parlance of our industry, “discipline doesn’t scale”.</p>
<p>Consider the trajectory of object lifecycle management in the Objective-C programming language, particularly the NeXT dialect. Between 1989 and 1995, the dominant way to deal with the lifecycle of objects was to use the <tt>+new</tt> and <tt>-free</tt> methods, which work much like <tt>malloc/free</tt> in C or <tt>new/delete</tt> in C++. Of course it’s <em>possible</em> to design a complex object graph using this ownership model, it just needs discipline, that’s all. Learn the heuristics that the experts use, and the techniques to ensure correctness, and get it correct.</p>
<p>But you know what’s better? Not having to get that right. So around 1994 people introduced new tools to do it an easier way: reference counting. With NeXTSTEP Mach Kit’s <tt>NXReference</tt> protocol and OpenStep’s <tt>NSObject</tt>, developers no longer need to know when <em>everybody</em> in an app is done with an object to destroy it. They can indicate when a reference is taken and when it’s relinquished, and the object itself will see when it’s no longer used and free itself. Learn the heuristics and techniques around auto releasing and unretained references, and get it correct.</p>
<p>But you know what’s better? Not having to get that right. So a couple of other tools were introduced, so close together that they were probably developed in parallel[*]: Objective-C 2.0 garbage collection (2006) and Automatic Reference Counting (2008). ARC “won” in popular adoption so let’s focus there: developers no longer need to know exactly when to retain, release, or autorelease objects. Instead of describing the edges of the relationships, they describe the <em>meanings</em> of the relationships and the compiler will automatically take care of ownership tracking. Learn the heuristics and techniques around weak references and the “weak self” dance, and get it correct.</p>
<p>[*] I’m ignoring here the significantly earlier integration of the Boehm conservative GC with Objective-C, because so did everybody else. That in itself is an important part of the technology adoption story.</p>
<p>But you know what’s better? You get the idea. You see similar things happen in other contexts: for example C++’s move from <tt>new/delete</tt> to smart pointers follows a similar trajectory over a similar time. The reliance on an entire programming community getting some difficult rules right, when faced with the alternative of using different technology <em>on the same computer</em> that follows the rules for you, is a tough sell.</p>
<p>It seems so simple: computers exist to automate repetitive information-processing tasks. Requiring programmers who have access to computers to recall and follow repetitive information processes is wasteful, when the computer can do that. So give those tasks to the computers.</p>
<p>And yet, for some people the problem with software isn’t a lack of automation but a lack of discipline. Software would be better if only people knew the rules, honoured them, and slowed themselves down so that instead of cutting corners they just chose to ignore important business milestones instead. Back in my day, everybody knew “no Markdown around town” and “don’t code in an IDE after Labour Day”, but now the kids do whatever they want. The motivations seem different, and I’d like to sort them out.</p>
<p>Let’s start with hazing. A lot of the software industry suffers from “I had to go through this, you should too”. Look at software engineering interviews, for example. I’m not sure whether anybody actually believes “I had to deal with carefully ensuring NUL-termination to avoid buffer overrun errors so you should too”, but I do occasionally still hear people telling less-experienced developers that they should learn C to learn more about how their computer works. <a href="https://queue.acm.org/detail.cfm?id=3212479">Your computer is not a fast PDP-11</a>, all you will learn is how the C virtual machine works.</p>
<p>Just as Real Men Don’t Eat Quiche, so <a href="https://www.codeproject.com/articles/927/real-programmers-don-t-use-pascal">real programmers don’t use Pascal</a>. Real Programmers use FORTRAN. This motivation for sorting discipline from rabble is based on the idea that if it isn’t at least as hard as it was when <em>I</em> did this, it isn’t hard enough. And that means that the goalposts are movable, based on the orator’s experience.</p>
<p>This is often related to the <em>term</em> of their experience: you don’t need TypeScript to write good React Native code, just Javascript and some discipline. You don’t need React Native to write good front-end code, just JQuery and some discipline. You don’t need JQuery…</p>
<p>But along with the term of experience goes the breadth. You see, the person who learned reference counting in 1995 and thinks that you can only <em>really</em> understand programming if you manually type out your own reference-changing events, presumably didn’t go on to use garbage collection in Java in 1996. The person who thinks you can only <em>really</em> write correct software if every case is accompanied by a unit test presumably didn’t learn Eiffel. The person who thinks that you can only <em>really</em> design systems if you use the Haskell type system may not have tried OCaml. And so on.</p>
<p>The conclusion is that for this variety of disciplinarian, the appropriate character and quantity of discipline is whatever they had to deal with at some specific point in their career. Probably a high point: after they’d got over the tricky bits and got productive, and after you kids came along and ruined everything.</p>
<p>Sometimes the reason for suggesting the disciplined approach is entomological in nature, as in the case of the eusocial insect the “performant” which, while not a real word, exists in greater quantities in older software than in newer software, apparently. The performant is capable of making software faster, or use less memory, or more concurrent, or less dependent on I/O: the specific characteristics of the performant depend heavily on context.</p>
<p>The performant is often not talked about in the same sentences as its usual companion species, the irrelevant. Yes, there may be opportunities to shave a few percent off the runtime of that algorithm by switching from the automatic tool to the manual, disciplined approach, but does that matter (yet, or at all)? There are software-construction domains where specific performance characteristics are desirable, indeed that’s true across a lot of software. But it’s typical to focus performance-enhancing techniques on the bits where they enhance performance that needs enhancing, not to adopt them across the whole system on the basis that it was better when everyone worked this way. You might save a few hundred cycles writing native software instead of using a VM for that UI method, but if it’s going to run after a network request completes over EDGE then trigger a 1/3s animation, nobody will notice the improvement.</p>
<p>Anyway, whatever the source, the problem with calls for discipline is that there’s no strong motivation to <em>become</em> more disciplined. I can use these tools, and my customer is this much satisfied, and my employer pays me this much. Or I can learn from you how I’m <em>supposed</em> to be doing it, which will slow me down, for…your satisfaction? So you know I’m doing it the way it’s supposed to be done? Or so that I can tell everyone else that they’re doing it wrong, too? Sounds like a great deal.</p>
<p>Therefore discipline doesn’t scale. Whenever you ask some people to slow down and think harder about what they’re doing, some fraction of them will. Some will wonder whether there’s some other way to get what you’re peddling, and may find it. Some more will not pay any attention. The dangerous ones are the ones who thought they <em>were</em> paying attention and yet still end up not doing the disciplined thing you asked for: they either torpedo your whole idea or turn it into not doing the thing (see OOP, Agile, Functional Programming). And still more people, by far the vast majority, just weren’t listening at all, and you’ll never reach them.</p>
<p>Let’s flip this around. Let’s look at where we <em>need</em> to be disciplined, and ask if there are gaps in the tool support for software engineers. Some people want us to always write a failing test and make it pass before adding any code (or want us to write a passing test and revert our changes if it accidentally fails): does that mean our tools should not let us write code for which there’s no test? Does the same apply for acceptance tests? Some want us to refactor mercilessly; does that mean our design tools should always propose more parsimonious alternatives for passing the same tests? Some say we should get into the discipline of writing code that always reveals its intent: should the tools make a crack at interpreting the intention of the code-as-prose?</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/10/discipline-doesnt-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834965</guid>
            <pubDate>Tue, 20 Oct 2020 08:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Long Road to HTTP/3]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24834767">thread link</a>) | @todsacerdoti
<br/>
October 20, 2020 | https://scorpil.com/post/the-long-road-to-http3/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/the-long-road-to-http3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>While HTTP/3 specification is still in the draft stage, the latest version of the Chrome browser already <a href="https://blog.chromium.org/2020/10/chrome-is-deploying-http3-and-ietf-quic.html" target="_blank" rel="nofollow">supports it by default</a>
. With Chrome holding around 70% of browser market share, you could say HTTP/3 has gone mainstream.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/quic-logo.png" alt="QUIC logo"></p><p>The new revision of this foundational protocol aims to make the web more efficient, secure, and shorten the content-delivery latencies. In some ways, it’s a braver take of HTTP2: similar goals addressed by replacing the underlying TCP protocol with a new, purpose-built protocol QUIC. The best way to explain the benefits of QUIC is to illustrate where TCP falls short as a transport for HTTP requests. And to do that, we’ll start at the very beginning.</p><h3 id="http-the-original">HTTP. The Original.</h3><p>When Sir Tim Berners-Lee formalized the design of a simple <a href="https://www.w3.org/Protocols/HTTP/AsImplemented.html" target="_blank" rel="nofollow">one-line hyper-text-exchange protocol</a>
in 1991, TCP was already an old, reliable protocol. The original definition document of what later became known as HTTP 0.9 specifically mentions TCP as a preferred, albeit not exclusive, transport protocol:</p><blockquote><p>Note: HTTP currently runs over TCP, but could run over any connection-oriented service.</p></blockquote><p>Of course, this proof-of-concept version of HTTP had very few similarities to HTTP we now know and love today. There were no headers and no status codes. The typical request was as simple as <code>GET /path</code>. The response contained only HTML and ended with the closing of the TCP connection.
Since browsers were not yet a thing, user was supposed to read HTML directly. It was possible to link to other resources, but none of the tags present in this early version of HTML requested additional resources asynchronously. A single HTTP request delivered a complete, self-sufficient page.</p><h3 id="emergence-of-http10">Emergence of HTTP/1.0</h3><p>In subsequent years the internet has exploded, and HTTP evolved to be an extendable and flexible general-purpose protocol, although transporting HTML remained its chief specialty. There are three critical updates to HTTP that enabled this evolution:</p><ul><li>introduction of methods allowed the client to identify the type of action it wants to perform. For example, POST was created to allow client sending data to the server to process and store</li><li>status codes provided a way for client to confirm that the server has processed the request successfully, and if not - to understand what kind of error has occured</li><li>headers added an ability to attach structured textual metadata to requests and responses that could modify the behavior of the client or server. Encoding and content-type headers, for example, allowed HTTP to transfer not just HTML, but any type of payload. “Compression” header allowed the client and server to negotiate supported compression formats, thus reducing the amount of data to transfer over the connection</li></ul><p>At the same time, HTML advanced to support images, styles, and other linked resources. Browsers were now forced to perfrom multiple requests to display a single web page, which the original connection-per-request architecture was not designed to handle. Establishing and ending a TCP connection involves a lot of back-and-forth packet exchange, so it is relatively expensive in terms of latency overhead. It didn’t matter much when a web-page consisted of a single text file, but as the number of requests per page increased, so did the latency.</p><p>The picture below illustrates how much overhead was involved in establishing a new TCP connection per request.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-tcp-overhead.png" alt="TCP connection requires three requests to establish connection and four to close it cleanly"></p><p>A “connection” header was created to address this problem. Client sends a request with “connection: keep-alive” header to signal intent to keep the TCP connection open for subsequent requests. If server understands this header and agrees to respect it, its response will also contain the “connection: keep-alive” header. This way, both parties maintain TCP channel open and use it for subsequent communication until either party decides to close it. This became even more important with the spread of SSL/TLS encryption, because negotianting an encryption algorithm and exchanging cryptographic keys requires an additional request/response cycle on each connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-keepalive.png" alt="A single TCP connection can be reused for multiple requests with “connection: keep-alive” header"></p><p>At the time, many of the HTTP improvements appeared spontaneously. When a popular browser or a server app saw a need for a new HTTP feature, they would simply implement it themselves and hoped that other parties would follow the suit. Ironically, a decentralized web needed a centralized governing body to avoid fragmentation into incompatible pieces. Tim Berners-Lee, the original creator of the protocol, recognized the danger and founded the World Wide Web Consortium (W3C) in 1994, which together with the Internet Engineering Task Force (IETF) worked on formalizing stack of internet technologies. As the initial step to bring more structure to the existing environment, they documented the most common features used in HTTP at the time and named the resulting protocol HTTP/1.0. However, because this “specification” described varied, often inconsistent techniques as seen “in the wild”, it never received a status of a standard. Instead, the work on the new version of the HTTP protocol has begun.</p><h3 id="standardization-of-http11">Standardization of HTTP/1.1</h3><p>HTTP/1.1 fixed inconsistencies of HTTP/1.0 and adjusted the protocol to be more performant in the new web ecosystem. Two of the most critical changes introduced were the use of persistent TCP connections (keep-alive’s) by default and HTTP pipelining.</p><p>HTTP pipelining simply means that client does not need to wait for the server to respond to a request before sending subsequent HTTP requests. This feature resulted in even more efficient use of bandwidth and reduced latencies, but it could be improved even more. HTTP pipelining still requires from server to respond in the order of requests received, so if a single request in a pipeline is slow to fulfill, all subsequent responses to a client will be delayed accordingly. This problem is known as head-of-the-line blocking.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http11-blocking.png" alt="Since large-picture.jpg was requested first, it’s blocking the delivery of the style.css"></p><p>At this point in time, the web is gaining more and more interactive capabilities. Web 2.0 is just around the corner, some webpages include dozens or even hundreds of external resources. To work around the head-of-the-line blocking, and to decrease page loading speeds, clients establish multiple TCP connections per host. Of course, the connection overhead never went anywhere. In reality, it got worse, since more and more applications encrypt HTTP traffic with SSL/TLS. So most browsers set the limit of maximal possible simultaneous connections in an attempt to strike a delicate balance.</p><p>Many of the larger web-services have recognized that existing limitations are too restricting for their exceptionally heavy interactive web-applications, so they “gamed the system” by distributing their app through multiple domain names. It all worked, somehow, but the solution has been far from elegant.</p><p>Despite a few shortcomings, the simplicity of HTTP/1.0 and HTTP/1.1 has made them widely successful, and for over a decade no one has made a serious attempt to change them.</p><h3 id="spdy-and-http2">SPDY and HTTP/2</h3><p>In 2008 Google released the Chrome browser, which rapidly gained popularity for being quick and innovative. It has given Google a strong vote on matters of internet technologies. In the early 2010s, Google adds support for its web protocol SPDY to Chrome.</p><p>HTTP/2 standard was based on SPDY with some improvements. HTTP/2 solved the head-of-the-line blocking problem by multiplexing the HTTP requests over a single open TCP connection. This allowed server to answer requests in any order, client could then re-assemble the responses as it received them, making the whole exchange faster within a single connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http2-multiplexing.png" alt="style.css was returned before the large-picture.jpg, becuase of HTTP/2 multiplexing"></p><p>In fact, with HTTP/2 server can serve the resources to a client before it even asked for it! To give an example, if the server knows that client will most likely need a stylesheet to display an HTML page, it can “push” the CSS to the client without waiting for a corresponding request. While beneficial in theory, this feature rarely seen in practice, since it requires a server to understand the structure of the HTML it serves, which is rarely the case.</p><p>HTTP/2 also allows compressing request headers in addition to the request body, which further reduces the amount of data transferred over the wire.</p><p>HTTP/2 solved a lot of problems for the web, but not all of them. A similar type of head-of-the-line problem is still present on the level of TCP protocol, which remains a foundational building block of the web. When a TCP packet gets lost in transit, the receiver can’t acknowledge incoming packages until the lost package is re-sent by a server. Since TCP is by design oblivious to higher-level protocols like HTTP, a single lost packet will block the stream for all in-flight HTTP requests until the missing data is re-sent. This problem is especially prominent on an unreliable connection, which is not rare in the age of ubiquitous mobile devices.</p><h3 id="http3-revolution">HTTP/3 revolution</h3><p>Since issues with HTTP/2 can not be resolved purely on the application layer a new iteration of the protocol must update the transport layer. However, creating a new transport-layer protocol is not an easy task. Transport protocols need to be supported by hardware vendors and deployed by the majority of network operators, which are reluctant to update because of the costs and efforts involved. Take IPv6 as an example: it was introduced 24 years ago and is still far from being universally supported.</p><p>Fortunately, there is another option. UDP protocol is as widely supported as TCP but is simple enough to serve as a building block for custom protocols running on top of it. UDP packets are fire-and-forget: there are no handshakes, persistent connections, or error-correction. The primary idea behind HTTP3 is to abandon TCP in favor of a UDP-based QUIC protocol. QUIC adds the necessary features (those that were previously provided by TCP, and more) in a way that makes sense for the web environment.</p><p>Unlike HTTP2, which technically allowed an unencrypted communication, QUIC strictly requires encryption to establish a connection. Additionally, encryption is applied to all data …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/the-long-road-to-http3/">https://scorpil.com/post/the-long-road-to-http3/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/the-long-road-to-http3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834767</guid>
            <pubDate>Tue, 20 Oct 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adolphe Sax, Inventor of the Saxophone]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24834716">thread link</a>) | @bobf
<br/>
October 20, 2020 | http://www.dinant.be/en/inheritance/adolphe-sax | <a href="https://web.archive.org/web/*/http://www.dinant.be/en/inheritance/adolphe-sax">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody>
<tr>
<td>


<h2><span>Adolphe Sax, a Dinantais of genius</span></h2>
<blockquote>
<p>Along with Joachim Patenier (1485-1524), the creator of landscape painting; with Antoine Wiertz (1806-1865), the lyrical painter; with a plethora of sculptors, painters, musicians, brassworkers and others, Dinant can legitimately pride itself on having been the birthplace on 6 November 1814 of Antoine-Joseph, or Adolphe, Sax, a prolific and inspired inventor in the manufacture of musical instruments.</p>
<p>In 1860, the diarist, Oscar Comettant, wrote, "In the services that he has rendered to musical art, in the battles he has had to go through to bring his discoveries to the light of day and defend them from despoilment and in the rewards he has been the object of from all the industrial nations, [Sax's life] rises to the heights of a social event. Novelists will draw from this strange life mysterious and moving episodes (we would add: the legal world will find in the account of the "Sax trial" a vast domain for a case law study) and the moralists will find in it the features of self-denial, physical courage and perseverance, of which only a lifted soul and a great heart are capable.</p>
</blockquote>
<a name="Enfance"></a>
<h2><span>An Agitated Childhood</span></h2>

<blockquote>
<p>Antoine-Joseph Sax was born in the street that has borne his name since 1896, in a modest house, which was destroyed in 1914, and which was built on the present site of an important commercial building.</p>
<p>In its façade, there is a stained-glass window and an inscription chiselled into the stonework: "Adolphe Sax, 1814-1894, was born here". This window was solemnly inaugurated on 27 June 1954, on the initiative of the Tourist Information Centre, under the mayorship of Mr Léon Sasserath. It is the work of Mr Jean Jadin, who designed the cartoon, and Miss Maggy Arzée. Both were taught by Miss Yvonne Gérard and Mr Perot, teachers of graphic art and decoration at the Fine Arts Academy in Namur, which was then directed by Mr Lambeau. It was created under the direction of Mr Van de Capelle.</p>
<p>Son of Charles-Joseph Sax (1791-1865) and Marie-Joseph Masson (1813-1861), Antoine-Joseph was the eldest of eleven children (six boys and five girls, only four of whom survived, the others dying between the ages of 20 and 25).</p>
<p>His childhood was tragic. Hardly able to stand, Antoine-Joseph fell from a height of three floors, seriously bumping his head against a stone: he was believed dead. At the age of three, he swallowed a bowl of vitriolized water, and then a pin. Later, he was seriously burned in a gunpowder explosion; he fell onto a cast iron frying pan and burned himself on one side. Three times he escaped poisoning and asphyxiation in his bedroom, where varnished items were lying about during the night. Another time, he was hit on the head by a cobblestone; he fell into a river and was saved by the skin of his teeth.</p>
<p>"<em>He's a child condemned to misfortune; he won't live," his mother said. In the district, they called him "little Sax, the ghost</em>".</p>
<p>These initial serious incidents were, alas, but the prelude to an eventful existence such as only a few have known. In 1858, Adolphe Sax was miraculously saved from a cancer of the lip by a black doctor who knew the properties of certain Indian plants. What would the future have been but for this intervention?</p>
</blockquote>
<a name="Charles-Joseph"></a>
<h2><span>Charles-Joseph Sax</span></h2>

<blockquote>
<p>A joiner-cabinetmaker, Charles-Joseph Sax quickly launched himself, with success, into the manufacture of musical instruments. In the "New Street" he ran a large workshop. In this trade, he acquired such a reputation that, in 1815 (his eldest son was only one year old), he also set up a workshop in Brussels (where Antoine-Joseph's brothers and sisters were to be born), where he was summoned by William I of Orange (we were then under Dutch occupation). The latter appointed him as maker to the Court and entrusted him with the task of supplying suitable instruments to Belgium regimental music corps.</p>
<p>A self-taught man, therefore, Charles-Joseph Sax made woodwind and brass instruments, even violins and pianos. He registered a dozen patents and brought his instruments to perfection. He successfully participated in numerous exhibitions, where he was awarded flattering distinctions.</p>
<p>At the time when he could have spend the day playing, laughing and having fun, Antoine-Joseph observed the work in his father's workshop, besides being given instruction by one of his uncles, a teacher in Dinant. He was intelligent and his inventive mind was already showing itself, thanks to his love for music (whilst very young, he took singing and flute lessons). Thereafter, he was given lessons by his father, who quickly appreciated his abilities and did all he could to develop them.</p>
<p>Far from disregarding his son's aspirations, Charles-Joseph Sax made him his apprentice and, from a young age, he was conscious of the importance of his work, as though he were anticipating his destiny.</p>
<p>In 1853, after the death of seven of his eleven children, and following financial worries at his Brussels business, Charles-Joseph joined his son in Paris. The master was to become the servant, and was from then on in charge of making saxophones until his death in 1865.</p>
</blockquote>
<a name="Jeunesse"></a>
<h2><span>A productive childhood</span></h2>

<blockquote>
<p>Supported and assisted by his father, the youth worked. He created, he perfected instruments and he played them. He was 16 when he went to the Industrial Exposition in Brussels to present flutes and ivory clarinets. At the age of 20, he made an entirely new clarinet, with 24 keys, a work of imagination and a masterpiece of manual work. Then, a new bass clarinet, which incited enthusiasm in Habeneck, the leader of the orchestra at the Paris Opera House, who was passing through Brussels, and who called the other clarinets "barbarian instruments".</p>
<p>Even at that early stage, this creation provoked jealousy in the soloist at the "Great Royal Harmony" in Brussels, who refused to use it because, he said, it had come from "that weedy little pupil, Sax". "Play your clarinet, then" Sax answered, " and I shall play mine." The challenge accepted, Sax triumphed in front of four thousand people. He became a soloist. Works were written for him that, after his departure, were no longer played because they were so difficult!</p>
<p>The young genius pursued his work. He invented a sound reflector, a new double-bass clarinet, a piano-tuning process that remained the inventor's secret and who probably was unable to exploit it for want of money, a steam organ "capable of being heard throughout the province": now that just shows Sax's tendency to think big!</p>
<p>Sax's beginnings throw a very curious light on his character (we shall call him Adolphe from now on): energy, courage, dynamism, total self-confidence. He refused to go and set up a business in St Petersburg, rejected an offer to set up in London. That means that his reputation exceeded frontiers. Sax was conscious of all his possibilities and his talent; he conceived the work that he felt the call to achieve; he was full of hope and he believed he had every chance of success; he had great visions, he believed in what he saw. He suffocated in his little country.</p>
<p>In 1840, he presented nine inventions at the Belgian Exhibition. He was denied the first medal on the plea of his young age; there would be nothing left to offer him the year after. He was thwarted in his true-love, if not in his pride. He refused the vermeil medal he was awarded, replying with pride, "<em>If they think me too young to deserve the gold medal, I myself think me too old to accept this vermeil one</em>."</p>
</blockquote>
<a name="Paris"></a>
<h2><span>The Call to Paris</span></h2>

<blockquote>
<p>Europe's centre of attraction, Paris haunted him, Paris called him.</p>
<p>The composer Halévy wrote to him of the hope that composers had in his inventions: "<em>Hurry and finish your new family of instruments (saxophones) and come and succour to the poor composers that are looking for something new and to the public that is demanding it, if not to the world itself.</em>"</p>
<p>Let us add to this call and the snub in Brussels the fact of his family trials, and the decision was made: Adolphe Sax left for Paris "rich in ideas and light in cash": he had thirty francs in his pocket!</p>
<p>The year 1842 formed the turning point in Sax's life, possessing as he did his new invention: the saxophone and its family.</p>
<p><img src="http://www.dinant.be/uploads/pages/286/sax_atel.jpg" alt="">Moreover, in 1841, had he not presented it anonymously in Brussels, behind a curtain, so as not to disclose it and avoid the risk of plagiarism?</p>
<p>Adolphe Sax was almost thirty, "the age at which man's creative character affirms itself, at which the human personality is drawn." At the age of 27, Napoleon won his first battle in Italy; Newton was 24 and Einstein 26 when they devised their theories. Mozart died aged 35 and Schubert at 31. Examples of precocious geniuses are manifold.</p>
<p>As one former inhabitant of Dinant once rightfully said (1) "<em>a distinction has to be drawn here between a man who draws from his own abstract thoughts the stuff that his genius will knead, him for whom symbols and signs are sufficient to bring forth a thought laden with restrained life and latent splendours; and the other man for whom a technique, slow and tenacious apprenticeship on a complicated apparatus is necessary for him to be able to physically achieve the formal idea. Count, for example, how many early-developing mathematicians there are compared with child physicists. The former exist, the latter are nowhere to be found. Sax is of the category of intellectuals that concentrated on matter and not pure form"</em>.</p>
<p>In 1842, there was Adolphe Sax living in a simple shed in Rue Saint-Georges, Paris. To set up business, he had to borrow money from a musician acquaintance.</p>

</blockquote>
<a name="Berlioz"></a>
<h2><span>Thanks to Berlioz</span></h2>
<blockquote>
<div>
<p><span><strong>About the saxophone, he said "<em>Its principal merit in my view is the varied beauty of its accent, sometimes serious, sometimes calm, sometimes impassioned, dreamy or melancholic, or vague, like the weakened echo of an echo, like the indistinct plaintiff moans of the breeze in the woods and, even better, like the mysterious vibrations of a bell, long after it has been struck; there does not exist another musical instrument …</em></strong></span></p></div></blockquote></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dinant.be/en/inheritance/adolphe-sax">http://www.dinant.be/en/inheritance/adolphe-sax</a></em></p>]]>
            </description>
            <link>http://www.dinant.be/en/inheritance/adolphe-sax</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834716</guid>
            <pubDate>Tue, 20 Oct 2020 07:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My chatbot is dead – Why yours should probably be too]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 157 (<a href="https://news.ycombinator.com/item?id=24834552">thread link</a>) | @raphaelsaunier
<br/>
October 19, 2020 | https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/ | <a href="https://web.archive.org/web/*/https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
<audio controls="controls"><source src="https://azumbrunnen.me/audio/chatbot-is-dead" type="audio/mpeg"></audio>



<p>Personal websites are usually like old books in a shelf. They languish, accumulate dust, and their wrinkles and cracks become more apparent over time. About 3 years ago I embarked on a simple experiment that would end up prolonging the shelf-life of my website by an unusually large margin.</p>



<p>Back in 2017, it seemed like Conversational UI was poised to take over the world. We saw Quartz turning news into a conversation, WeChat being featured as the poster-child of a post application world, iMessage turning into an unnecessarily complex mess, and chatbots popping up like mushrooms in moist forests.</p>



<p>Of course, any trend gaining so much traction and interest needs to be taken seriously. As such, I decided to familiarize myself with the topic, and turned my website into a chatbot.</p>



<p>Instead of being greeted by the internationally standardized greeting every designer used at some point in their career, there was no bold, dramatically oversized, and deep black sans-serif reading: <em>Hi, I’m a designer.</em> (To be fair, I didn’t use Proxima Nova either)</p>



<p>Instead, a couple of chat bubbles exuberantly ushered onto the canvas to greet users as if we had all been long time friends.</p>



<figure><video autoplay="" loop="" muted="" src="https://azumbrunnen.me/wp-content/uploads/chatbot-animated.mp4" playsinline=""></video><figcaption>Conversational intro</figcaption></figure>



<p>It was witty, new, and slightly awkward. People would send messages that ranged from simple chit chat, to deep philosophical topics, to downright disturbing and ridiculous insults.</p>



<p>The experiment got featured on Hackernews, Medium, was used in psychological studies conducted by Dan Ariely’s team, and the source code was ripped and edited by various startups to fit their needs. One business in the Bay Area had an idea to use it to sell flowers in a conversational way. It looks like they went out of business.</p>



<p>The reaction and feedback was surprising to say the least. It was an idea so simple, so silly, that the outcome was in many ways unexpected. After all, the only one who really cares about your website, is usually yourself.</p>



<p>That didn’t stop me from revamping my website and kill the very thing that had turned it into a micro-celebrity before. With the death of my old chatbot, some angry emails by schools who are using it as a reference for “creative” web design, and a good amount of time that has passed ever since, I wanted to take a step back and set the record straight.</p>



<hr>



<h2>When chatbots matter</h2>



<p>So let’s be honest with ourselves for a moment: <em>when did you actually ever enjoy talking to a chat bot?</em> And I’m not talking about the type of bots you talk to when you’re bored, but about those that provide a deeper purpose.</p>



<p>It turns out that the answer is, at least for most of us, almost never.</p>



<p>I love you Intercom, except when I don’t. 99% of time I don’t want to talk to a silly and obtrusive avatar popping up from some corner of the screen before I even had a chance to check out what’s going on. Somehow, I can’t help but think others feel the same.</p>



<p>In fact, we do know that others feel the same. Chat heads jumping at us unasked, are the quintessential equivalent of the infamous sales clerk who eagerly talks to us upon entering a store.</p>



<p>To further add to the challenges: as soon as users go off-script, chat bot’s don’t just become awkward and unpredictable—they turn into little sociopaths that might rub users the wrong way.</p>



<figure><img loading="lazy" width="400" height="346" src="https://azumbrunnen.me/wp-content/uploads/grandma.png" alt="" srcset="https://azumbrunnen.me/wp-content/uploads/grandma.png 400w, https://azumbrunnen.me/wp-content/uploads/grandma-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>UX Chat.me —&nbsp;Conversational UX News</figcaption></figure>



<p>The moment you create a chat bot is the moment you allow customers to have a conversation with <em>your brand</em>. Not with yourself, not with your friend, but with an uber entity—a symbol—that represents everything you and your team stand for. That’s not a step to be taken lightly.</p>



<p>This simple conversational entity can be a fun tool to engage with people but depending on how the conversation goes, it can quickly turn into a misrepresentation of the values of your team and your company. So building a chat bot should never be the default choice, but an intentional one.</p>



<p>That’s why it’s worth asking yourself the following three questions before venturing into this space:</p>



<h3>1. Is your use case simple enough to be solved through chat?</h3>



<p>Conversation is incredibly complex and it’s challenging enough to keep it on track in the real world. If the use case isn’t simple, chances are, chat bots are not the right tool for the job.</p>



<h3>2. Is your NLP capable and sophisticated enough?</h3>



<p>There are two types of bots: pre-scripted bots with a range of default answers users can choose from, and Natural Language Processing based ones.</p>



<p>Choosing the right one is hard. While pre-scripted can feel too limiting, NLP can break at every corner. Often times, teams quickly fall into the trap of spending a huge amount of time focusing on personality and silly jokes, instead of solving the problem users hired you for in the first place.</p>



<p>Therefore, building on top of the first point above, within the conversational landscape, simple always wins.</p>



<h3>3. Are your users actually in chat based environments?</h3>



<p>Chat bots work best where users already are. If your users are primarily spending time in messaging platforms where bots and micro-apps can be seamlessly embedded, great. That can serve as an effective and natural way to engage with your audience because it matches the “be where users already are” principle.</p>



<p>If on the other hand, people come to your website, a medium that has made great strides to provide content in a non-linear and quick way, it often unnecessarily slows users down. </p>



<hr>



<h2>Farewell chatbot</h2>



<p>I don’t want to discredit chat bots as a paradigm. They have their use in certain industries, medium, and work well for a specific set of use cases. The important part is being deliberate, rather than jumping ship blindfolded.</p>



<p>So whereas turning my website into a chat was a fun experiment, I ultimately feel like it has slowly turned into a fad. I got fooled by the trend, and as a by-product became part of the trend itself.  Fads come and go, and as they get refined and re-interpreted, they ultimately find their true purpose. What we’re left with is the age old insight that it’s only through experimentation, that we can unlock concepts and ideas that last.</p>



<p>Rest in peace chat bot, long live chat bots.</p>
            </article></div>]]>
            </description>
            <link>https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834552</guid>
            <pubDate>Tue, 20 Oct 2020 06:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Animation data sets (2018)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834299">thread link</a>) | @ascorbic
<br/>
October 19, 2020 | https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html | <a href="https://web.archive.org/web/*/https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 03, 2018 
                 | Tags: 
                     
                        Datasets
                      
                </span>

            <section>
                <p>Today at <a href="https://cg.ivd.kit.edu/egsr18/">EGSR 2018</a>, Walt Disney Animation Studios announced the release of two large, production quality/scale data sets for rendering research purposes.
The data sets are available on a new <a href="https://disneyanimation.com/data-sets/">data sets page on the official Disney Animation website</a>.
The first data set is the Cloud Data Set, which contains a large and highly detailed volumetric cloud data set that we used for our “<a href="https://blog.yiningkarlli.com/2017/07/spectral-and-decomposition-tracking.html">Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes</a>” SIGGRAPH 2017 paper, and the second data set is the Moana Island Scene, which is a full production scene from <a href="https://blog.yiningkarlli.com/2016/11/moana.html">Moana</a>.</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 1: The Moana Island Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/wdas_cloud_hyperion_render.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/wdas_cloud_hyperion_render.jpg" alt="Figure 2: The Cloud Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p>In this post, I’ll share some personal thoughts, observations, and notes.
The release of these data sets was announced by my teammate, Ralf Habel, at EGSR today, but this release has been in the works for a very long time now, and is the product of the collective effort of an enormous number of people across the studio.
A number of people deserve to be highlighted: Rasmus Tamstorf spearheaded the entire effort and was instrumental in getting the resources and legal approval needed for the Moana Island Scene.
Heather Pritchett is the TD that did the actual difficult work of extracting the Moana Island Scene out of Disney Animation’s production pipeline and converting it from proprietary data formats into usable, industry-standard data formats.
Sean Palmer and Jonathan Garcia also helped in resurrecting the data from Moana.
Hyperion developers Ralf Habel and Peter Kutz led the effort to get the Cloud Data Set approved and released; the cloud itself was made by artists Henrik Falt and Alex Nijmeh.
On the management side of things, technology manager Rajesh Sharma and Disney Animation CTO, <a href="https://twitter.com/ncannon?lang=en">Nick Cannon</a>, provided crucial support and encouragement.
Matt Pharr has been crucial in collaborating with us to get these data sets released.
Matt was highly accommodating in helping us get the Moana Island Scene into a PBRT scene; I’ll talk a bit more about this later.
Intel’s Embree team also gave significant feedback.
My role was actually quite small; along with other members of the Hyperion development team, I just provided some consultation throughout the whole process.</p>

<p>Please note the licenses that the data sets come with.
The Cloud Data Set is licensed under a <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf">Creative Commons Attribution ShareAlike 3.0 Unported License</a>; the actual cloud is based on a photograph by Kevin Udy on his <a href="https://coclouds.com/436/cumulus/%202012-07-26/">Colorado Clouds Blog</a>, which is also licensed under the same Creative Commons license.
The Moana Island Scene is licensed under a more restrictive, custom Disney Enterprises <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/4/asset/License_Moana.pdf">research license</a>.
This is because the Moana Island Scene is a true production scene; it was actually used to produce actual frames in the final film.
As such, the data set is being released only for pure research and development purposes; it’s not meant for use in artistic projects.
Please stick to and follow the licenses these data sets are released under; if people end up misusing these data sets, then it makes releasing more data sets into the community in the future much harder for us.</p>

<p>This entire effort was sparked two years ago at SIGGRAPH 2016, when Matt Pharr made an appeal to the industry to provide representative production-scale data sets to the research community.
I don’t know how many times I’ve had conversations about how well new techniques or papers or technologies will scale to production cases, only to have further discussion stymied by the lack of any true production data sets that the research community can test against.
We decided as a studio to answer Matt’s appeal, and last year at SIGGRAPH 2017, Brent Burley and Rasmus Tamstorf announced our intention to release both the Cloud and Moana Island data sets.
It’s taken nearly a year from announcement to release because the process has been complex, and it was very important to the studio to make sure the release was done properly.</p>

<p>One of the biggest challenges was getting all of the data out of the production pipeline and our various proprietary data formats into something that the research community can actually parse and make use of.
Matt Pharr was extremely helpful here; over the past year, Matt has added support for <a href="http://ptex.us/">Ptex</a> textures and implemented the <a href="http://blog.selfshadow.com/publications/s2015-shading-course/burley/s2015_pbs_disney_bsdf_notes.pdf">Disney Bsdf</a> in <a href="https://github.com/mmp/pbrt-v3">PBRT v3</a>.
Having Ptex and the Disney Bsdf available in PBRT v3 made PBRT v3 the natural target for an initial port to a renderer other than Hyperion, since internally all of Hyperion’s shading uses the Disney Bsdf, and all of our texturing is done through Ptex.
Our texturing also relies heavily on procedural <a href="https://www.disneyanimation.com/technology/seexpr.html">SeExpr</a> expressions; all of the expression-drive texturing had to be baked down into Ptex for the final release.</p>

<p>Both the Cloud and Moana Island data sets are, quite frankly, enormous.
The Cloud data set contains a single OpenVDB cloud that weighs in at 2.93 GB; the data set also provides versions of the VDB file scaled down to half, quarter, eighth, and sixteenth scale resolutions.
The Moana Island data set comes in three parts: a base package containing raw geometry and texture data, an animation package containing animated stuff, and a PBRT package containing a PBRT scene generated from the base package.
These three packages combined, uncompressed, weigh in at well over 200 GB of disk space; the uncompressed PBRT package along weighs in at around 38 GB.</p>

<p>For the Moana Island Scene, the provided PBRT scene requires a minimum of around 90 GB if RAM to render.
This many seem enormous for consumer machines, because it is.
However, this is also what we mean by “production scale”; for Disney Animation, 90 GB is actually a fairly mid-range memory footprint for a production render.
On a 24-core, dual-socket Intel Xeon Gold 6136 system, the PBRT scene took me a little over an hour and 15 minutes to render from the ‘shotCam’ camera.
Hyperion renders the scene faster, but I would caution against using this data set to do performance shootouts between different renders.
I’m certain that within a short period of time, enthusiastic members of the rendering community will end up porting this scene to Renderman and Arnold and Vray and Cycles and every other production renderer out there, which will be very cool!
But keep in mind, this data set was authored very specifically around Hyperion’s various capabilities and constraints, which naturally will be very different from how one might author a complex data set for other renderers.
Every renderer works a bit differently, so the most optimal way to author a data set for every renderer will be a bit different; this data set is no exception.
So if you want to compare renderers using this data set, make sure you understand the various ways how the way this data set is structured impacts the performance of whatever renderers you are comparing.</p>

<p>For example, Hyperion subdivides/tessellates/displaces everything to as close to sub-poly-per-pixel as it can get while still fitting within computational resources.
This means our scenes are usually very heavily subdivided and tessellated.
However, the PBRT version of the scene doesn’t come with any subdivision; as a result, silhouettes in the following comparison images don’t fully match in some areas.
Similarly, PBRT’s lights and lighting model differ from Hyperion’s, and Hyperion has various artistic controls that are unique to Hyperion, meaning the renders produced by PBRT versus Hyperion differ in many ways:</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 3a: 'shotCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_pbrt.jpg" alt="Figure 3b: 'shotCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_hyperion.jpg" alt="Figure 4a: 'beachCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_pbrt.jpg" alt="Figure 4b: 'beachCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_hyperion.jpg" alt="Figure 5a: 'dunesACam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_pbrt.jpg" alt="Figure 5b: 'dunesACam' camera angle, rendered using PBRT v3. Some of the plants are in slightly different locations than the Hyperion render; this was just a small change that happened in data conversion to the PBRT scene."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_hyperion.jpg" alt="Figure 6a: 'flowersCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_pbrt.jpg" alt="Figure 6b: 'flowersCam' camera angle, rendered using PBRT v3. Note that the silhouette of the flowers is different compared to the Hyperion render because the Hyperion render subdivides the flowers, whereas the PBRT render displays the base cage."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_hyperion.jpg" alt="Figure 7a: 'grassCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_pbrt.jpg" alt="Figure 7b: 'grassCam' camera angle, rendered using PBRT v3. The sand dune in the background looks particularly different from the Hyperion render due to subdivision and displacement."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_hyperion.jpg" alt="Figure 8a: 'palmsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_pbrt.jpg" alt="Figure 8b: 'palmsCam' camera angle, rendered using PBRT v3. The palm leaves look especially different due to differences in artistic lighting shaping and curve shading differences. Most notably, the look in Hyperion depends heavily on attributes that vary along the length of the curve, which is something PBRT doesn't support yet. Some more work is needed here to get the palm leaves to look more similar between the two renders."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_hyperion.jpg" alt="Figure 9a: 'rootsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_pbrt.jpg" alt="Figure 9b: 'rootsCam' camera angle, rendered using PBRT v3. Again, the significant difference in appearance in the rocks is probably just due to subdivision/tesselation/displacement."></a></p>

<p>Another example of a major difference between the Hyperion renders and the PBRT renders is in the water, which Hyperion renders using photon mapping to get the caustics.
The provided PBRT scenes use unidirectional pathtracing for everything including the water, hence the very different caustics.
Similarly, the palm trees in the ‘palmsCam’ camera angle look very different between PBRT and Hyperion because Hyperion’s lighting controls are very different from PBRT; Hyperion’s lights include various artistic controls for custom shaping and whatnot, which aren’t necessarily fully physical.
Also, the palm leaves are modeled using curves, and the shading depends on varying colors and attributes along the length and width of the curve, which PBRT doesn’t support yet (getting the palm leaves is actually the top priority for if more resources are freed up to improve the data set release).
These difference between renderers don’t necessarily mean that one renderer is better than the other; they simply mean that the renderers are different.
This will be true for any pair of renderers that one wants to compare.</p>

<p>The Cloud Data Set includes an example render from Hyperion, which implements our Spectral and Decomposition Tracking paper in its volumetric rendering system to efficiently render the cloud with thousands of bounces.
This render contains no post-processing; what you see in the provided image is exactly what Hyperion outputs.
The VDB file expresses the cloud as a field of heterogeneous densities.
Also provided is an example <a href="https://www.mitsuba-renderer.org/">Mitsuba</a> scene, renderable using the <a href="https://github.com/zhoub/mitsuba-vdb">Mitsuba-VDB plugin that can be found on Github</a>.
Please consult the README file for some modifications in Mitsuba that are necessary to render the cloud.
Also, please note that the Mitsuba example will take an extremely long time to render, since Mitsuba isn’t really meant to render high-albedo heterogeneous volumes.
With proper acceleration structures and algorithms, rendering the cloud only takes us a few minutes using Hyperion, and should be similarly fast in any modern production renderer.</p>

<p>One might wonder just why production data sets in general are so large.
This is an interesting question; the short answer across the industry basically boils down to “artist time is more expensive and valuable than computer hardware”.
We could get these scenes to fit into much smaller …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</a></em></p>]]>
            </description>
            <link>https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834299</guid>
            <pubDate>Tue, 20 Oct 2020 05:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thumbnails and Screenshots using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834226">thread link</a>) | @ponderingfish
<br/>
October 19, 2020 | https://ottverse.com/thumbnails-screenshots-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/thumbnails-screenshots-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" alt="thumbnails ffmpeg" title="thumbnails-ffmpeg-featured-image" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>There are several easy ways to take screenshots/thumbnails of movies using FFmpeg. But why do this in the first place?</p>



<ol><li>You might want to generate thumbnails for your videos and show those thumbnails to the user when he scrolls through the video. </li><li>Or, you might want to compare two videos by doing a side-by-side comparison – this is quite common in video compression research. </li></ol>



<p>FFmpeg offers very simple techniques to extract screenshots or thumbnails at any position of the video (or rather, a way to dump frames at any point you choose). </p>



<p>Let’s see how! </p>




<h2><span id="Single_Screenshot/Thumbnail_Using_frames_v"></span>Single Screenshot/Thumbnail Using <code>-frames:v</code><span></span></h2>



<p>First, let’s understand how to take a single screenshot or thumbnail using FFmpeg. </p>



<pre><code>ffmpeg -i inputvideo.mp4 -ss 00:00:03 -frames:v 1 foobar.jpeg</code></pre>



<p>Understanding this is very simple! Here goes – </p>



<ol><li><code>-ss</code> is the seek command and it can be used to seek to the right position. For accurate seeking, you need to use output seeking and not input seeking (i.e., putting <code>-ss</code> before the input sequence). The syntax for specifying the time is <code>HH:MM:SS.MILLISECONDS</code>. For example, you can tell FFmpeg to seek to&nbsp;<code>01:02:03</code>&nbsp;– i.e., the 3rd second of the 2nd minute of the 1 hour of the movie!</li><li><code>-frames:v 1</code> tells FFmpeg to take only 1 screenshot. Note that, <code>-vframes</code> is deprecated. </li><li>then, you mention the name of the output file (<code>screenshot_10.jpg</code>). </li></ol>



<p>Simple, wasn’t it? Now that you know how to produce a single thumbnail or screenshot, let’s move to the next section where we understand how to create regular or periodic thumbnails.</p>



<h2><span id="Periodic_Screenshot/Thumbnail_with_Resizing"></span>Periodic Screenshot/Thumbnail with Resizing<span></span></h2>



<p>Here is another common use case that FFmpeg can solve easily – <strong>how do you take screenshots/thumbnails at regular intervals, and store them to JPG files after resizing them?</strong></p>



<p>Here is a simple one-liner that can take care of creating a thumbnail and resizing it for you. </p>



<pre><code>ffmpeg -i input1080p.mp4 -r 1 -s 1280x720 -f image2 screenshot-%03d.jpg</code></pre>



<p>The <code>-r</code> command sets the output frame rate (=1) and <code>image2</code> is an image file muxer that is used to write video frames to image files. Using the <code>-s 1280x720</code> command, we can resize the video frames before writing them as images. Note, that the input video is a 1920x1080p video.</p>



<p>The above command will take a screenshot every 1 second. The screenshots would be named <code>001</code>, <code>002</code>, etc. because we have specified the formatting as <code>%3d</code>.</p>



<p>However, in my experience, I have found this technique<strong> to be not frame-accurate</strong>.</p>



<p>In the next section, let’s look at a more accurate way of extracting thumbnails. </p>



<h2><span id="Screenshot/Thumbnail_every_10_seconds"></span>Screenshot/Thumbnail every 10 seconds<span></span></h2>



<p>As an extension of the previous section, let’s do a quick exercise and learn how to create a thumbnail every 10 seconds using FFmpeg. </p>



<pre><code><code>ffmpeg -i inputvideo.mp4 -vf "select='not(mod(n,300))',setpts='N/(30*TB)'" -f image2 thumbnail%03d.jpg</code></code></pre>



<p>Here, </p>



<ol><li>we use the <code>select</code> filter to extract a frame if the expression in single-quotes evaluates to non-zero. If the expression is zero, then <code>select</code> filter discards that frame.</li><li><code>mod(A,B)</code>&nbsp;returns the modulus (remainder after division) result after dividing A by B. So, if we divide 0 by 300, we get 0. Then, 1/300 is 1, and so on. </li><li><code>not</code> inverts this result. So, if the modulus is zero, then the final result is <code>1</code>. If the modulus is non-zero, then the result is evaluated to <code>zero</code>. </li><li>Based on this <code>not</code> operation, the <code>select</code> filter picks up a frame. </li></ol>



<p>The sequence I am using has a frame-rate of <code>30 fps</code>. And, I want a frame every 10 seconds. So, I have to choose a frame out of every 300 frames, right? That is why I used <code>select='not(mod(n,300))'</code></p>







<p>Depending on your sequence’s frame-rate, you can modify the command line shown. If you don’t know your video’s frame-rate, you can use <code>ffprobe</code> to find out. </p>



<pre><code>ffprobe -show_entries format=duration globe-with-timestamp.mp4</code></pre>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>There you have it – multiple easy ways to generate thumbnails and screenshots using FFmpeg. You can choose to take single screenshots or periodic ones with a highly frame-accurate technique! </p>



<p>Until next time, take care and don’t forget to share this article and check out the rest of the news, articles, and tutorials on OTTVerse.com</p>



<p><strong><a href="https://ottverse.com/category/ffmpeg/">Go here</a> to access all the FFmpeg tutorials on OTTVerse.com </strong></p>
		
		
		
	</div></div>]]>
            </description>
            <link>https://ottverse.com/thumbnails-screenshots-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834226</guid>
            <pubDate>Tue, 20 Oct 2020 05:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moana Motunui Renderer on GPU]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24833218">thread link</a>) | @Impossible
<br/>
October 19, 2020 | https://www.render-blog.com/2020/10/03/gpu-motunui/ | <a href="https://web.archive.org/web/*/https://www.render-blog.com/2020/10/03/gpu-motunui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>03 Oct 2020</span></p><p>Disney Animation’s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the <a href="https://github.com/chellmuth/gpu-motunui">GPU-Motunui</a> project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory. <a href="#renders">Click here</a> to skip ahead to the results.</p>

<h2 id="the-moana-island">The Moana island</h2>

<p>In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p>

<p>The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disney’s proprietary Hyperion renderer:</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-shotCam.png" alt="Hyperion shotCam reference"></p><p>Hyperion shotCam reference</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-beachCam.png" alt="Hyperion beachCam reference"></p><p>Hyperion beachCam reference</p>
</div>

<h2 id="gpu-motunui-project">GPU-Motunui Project</h2>

<p>The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the scene’s textures are provided in the Ptex format, and Ptex doesn’t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p>

<p>The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-unique-palmsCam.png" alt="Example of an unreproducible material variation on the palm tree frond"></p><p>Example of an unreproducible material variation on the palm tree frond</p>
</div>

<p>All ray tracing operations are run through Nvidia’s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunui’s out-of-core rendering solution works.</p>

<h3 id="scene-representation">Scene representation</h3>

<p>The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiX’s AS compaction and relocation APIs to further reduce memory usage.</p>

<p>The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p>

<div>

<p>Left: The four simple primitives that will be instanced to fill out the hibiscus tree <br>Right: The base trunk and branches model </p>
</div>

<p>In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiX’s shader binding table. These GASs form the bottom level of the hierarchy.</p>

<p>Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitive’s instances in isolation, and combined to make the full element:</p>

<div>

<p>Left: Isolated instances for each primitive<br>Right: Full isHibiscus element</p>
</div>

<p>Finally, a second IAS is built to track all of the element’s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/isHibiscus-instanced-elements.png" alt="The shotCam view rendered with only isHibiscus instances"></p><p>The shotCam view rendered with only isHibiscus instances</p>
</div>

<p>Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p>

<p>The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p>

<h3 id="out-of-core-rendering">Out-of-core rendering</h3>

<p>To solve the out-of-core rendering problem, GPU-Motunui divides the scene’s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p>

<p>Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p>

<p>After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the scene’s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p>

<div>
  <p>GPU memory layout after loading the isHibiscus element.<br>(Dotted arrows show that an IAS holds instances of the pointed-at AS)</p>

</div>

<p>As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to <code>cudaMemcpy</code> and <code>optixLaunch</code> for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the <code>tmax</code> parameter for the CUDA kernel’s call to <code>optixTrace</code>, and a successful intersection will update the depth buffer for the next launch.</p>

<p>In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to <code>optixLaunch</code>; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunui’s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiX’s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p>

<h3 id="shading">Shading</h3>
<p>As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p>

<h2 id="renders">Renders</h2>
<p>Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p>
<div>
  <p><img src="https://www.render-blog.com/assets/ours-shotCam.png" alt="shotCam"></p><p>shotCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-beachCam.png" alt="beachCam"></p><p>beachCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-dunesACam.png" alt="dunesACam"></p><p>dunesACam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-palmsCam.png" alt="palmsCam"></p><p>palmsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-birdseyeCam.png" alt="birdseyeCam"></p><p>birdseyeCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-rootsCam.png" alt="rootsCam"></p><p>rootsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-grassCam.png" alt="grassCam"></p><p>grassCam</p>
</div>

<h2 id="optimization">Optimization</h2>
<p>The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p>

<h4 id="cpugpu-concurrency">CPU/GPU concurrency</h4>
<p>Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p>

<h4 id="multiple-ptex-caches">Multiple Ptex caches</h4>
<p>Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p>

<h4 id="pinned-memory">Pinned memory</h4>
<p>The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p>

<h2 id="future-steps">Future Steps</h2>
<p>Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p>
<ul>
  <li>Implementing the Disney BSDF</li>
  <li>Rendering subdivision surfaces along with displacement mapping</li>
  <li>More efficiently packing the acceleration structures, and optimizing ray tracing throughput</li>
  <li>Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://github.com/chellmuth/gpu-motunui/">GPU-Motunui</a></li>
  <li><a href="https://technology.disneyanimation.com/islandscene/">Moana Island Scene</a></li>
  <li><a href="https://pharr.org/matt/blog/2018/07/16/moana-island-pbrt-all.html">Swallowing the elephant</a> - Matt Pharr</li>
  <li><a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">Disney Animation Data Sets</a> - Yining Karl Li</li>
  <li><a href="https://schuttejoe.github.io/post/disneypostmortem/">Rendering the Moana Island Scene Part 2: A production scene from a hobby renderer</a> - Joe Schutte</li>
  <li><a href="https://ingowald.blog/2020/01/09/digesting-the-elephant/">Digesting the elephant</a> - Ingo Wald</li>
  <li>Brent Burley and Dylan Lacewell. <a href="http://ptex.us/ptexpaper.html">Ptex: …</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></em></p>]]>
            </description>
            <link>https://www.render-blog.com/2020/10/03/gpu-motunui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833218</guid>
            <pubDate>Tue, 20 Oct 2020 01:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 93 (<a href="https://news.ycombinator.com/item?id=24831852">thread link</a>) | @liamrosen
<br/>
October 19, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think — and argue — &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the other deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831852</guid>
            <pubDate>Mon, 19 Oct 2020 22:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to better calculate churn rates]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24831637">thread link</a>) | @cmogni1
<br/>
October 19, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831637</guid>
            <pubDate>Mon, 19 Oct 2020 22:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a computer in Conway's game of life]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24831268">thread link</a>) | @ctlachance
<br/>
October 19, 2020 | https://www.nicolasloizeau.com/gol-computer | <a href="https://web.archive.org/web/*/https://www.nicolasloizeau.com/gol-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.p_DQq05oqSU0NY"></section><section id="h.p_iiV-AQqiVP7B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_SXN-ydRPVP6s"><div><div><p id="h.p_iRskbwwxVP67">The purpose of this page is to describe the functioning of a computer built in Conwayâ€™s game of life. An in-detail explanation of all the mechanisms and all the components of the computer would be too long to describe here. Only the fundamental principles and main components are explained here. I think this is enough to permit anyone to recreate a similar computer or reuse it's ideas and components for any other project.</p><p id="h.p_44-lKvosVSR_">The idea here is to illustrate the Turing completeness of game of life with a more impressive example, closer to our computers and easier to program than a basic Turing machine.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_aGh9TBjrsjnj"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_QecS9arclkic"><div><div><div jscontroller="VYKRW" jsaction="rcuQ6b:rcuQ6b;"><div><iframe jsname="L5Fo6c" sandbox="allow-scripts allow-popups allow-forms allow-same-origin allow-popups-to-escape-sandbox allow-downloads" frameborder="0" aria-label="YouTube Video, Game of life: programmable computer" src="https://www.youtube.com/embed/8unMqSp0bFY" allowfullscreen=""></iframe></div></div></div></div></div></div></div></div></div></div></div></section><section id="h.p_MUkfONu1Vy1J"></section><section id="h.p_Lqr87QKQZ7Ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_99zwWdVGZ7PS"><div><div><h2 id="h.p_dZFApvvPZ7Pc" tabindex="-1"></h2><p id="h.p_lvY7r7XEZ7br">The fact that two orthogonal glider beams can annihilate each other or form an eater if they intersect with the good phase shift is used to make basic logic gates.</p><p id="h.p_9XtX79ckZ7bx">This allows us to modify a glider beam with another.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_odLc-Ig6aUwc"></section><section id="h.p_Xj-uRksRarVA"></section><section id="h.p_xIogGmHYa9ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_HG45lQcXbAP1"><div><div><p><img src="https://lh4.googleusercontent.com/_fg5yZEX9pklvkcCHsvGYKM3Zuj19f_YgMXfX0S2vDSDjF08Sb4QWd7W8k1ZxJHwfjR-SDyB=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hrirjNxUbBgT"><div><div><p><img src="https://lh6.googleusercontent.com/ig94PPaYqYjSOuiFFMeY2vQcPkbBLm8ZwHbiGhlOIuUTYaslXo50AZdbRsmoysbK2PBKfGTAsg=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_2tgYrbMutYVl"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_k26e1YUKtYVe"><div><div><h2 id="h.p_BF-X_8nVtYVj" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>3 Logic gates assembly, adaptators</p></div></h2><p id="h.p__rI_inRGtkdp">The assembly of logic gates is possible only if the glider beams are in phase and if the gap between the beams is right. While making the components out of multiple logic gates, I used the following conventions: </p><p id="h.p_SSA7xz3atkhv">- use a 30*30 grid </p><p id="h.p_W3Uxqe5otkhw">- each glider beam has to match the corners of the grid</p><p id="h.p_xymga8iXtkhw">- main glider beams come from the high left corner.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_sRRZp-fXsY3v"><div><div><p><img src="https://lh5.googleusercontent.com/7rk7InLvggT5EfnhD1mnYTrwA9SHZoazomjXJoxJsrhWz1-OpYv92Bfe7yaU0RgFc4AmfBGRLlM0w_81pDd_6-pe6mibxoko6uxzeWBvtpsXtkhsmw=w1280" role="img"></p></div></div></div></div><div><div id="h.p_w97cwfq5s_Mt"><div><p id="h.p_Q5ji4R90s_Mx">According to these rules, these glider beams are well in phase.</p></div></div></div></div></div></div></div></div></section><section id="h.p_p-FkrspwsSxh"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_WGORwOtzsSxU"><div><p id="h.p_YekmpiZjsSxe">A series of 3 reflectors called an adaptator is used to shift the phase or the position of a beam. The folder tools contains two Python scripts to make such adaptators. The scripts <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdecamaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEiQAlLT1GgHvNvqWM3gTz5xQMI_g" target="_blank">decamaker.py</a> is used to translate horizontally a well phased beam by a multiple of 1 pixel. The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdelaymaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE9PUiQEu2epUYnDRoPrX0fgWPaDA" target="_blank">delamaker.py</a> makes an adaptator of 3 dimensions D1,D2,D3 :</p></div></div></div></div></div></div></div></div></section><section id="h.p_1sZECb-FsY3o"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lt4ZbqDrs1p4"><div><div><p><img src="https://lh4.googleusercontent.com/1wQXUMc6R6p3ymtVsVS3LZHwxNti8SHlk1Xj9LV4A0mdNpLppHrsKh40VKnCreuW5AKr_MMShoH2alGg90-bE1Qg3uRlE9HNVNpa-JGuLd48DavY1Mc=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_3D7rgWqxsfmY"><div><div><p><img src="https://lh3.googleusercontent.com/vmtcPmOYmdJVceZMy1fUck1agyiBEfF4kuT_piLuaT2P7uIB8-QTt1JFb5Ky2-4o2qxTRYN_ig=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_ameLef-vtZEs"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lQMVu9K3tZEi"><div><p id="h.p_Tx2PYsK-tZEp">Adaptators are already included at the inputs and outputs of the logic gates from the folder Â« <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Ftree%2Fmaster%2Flogic%2520gates&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHnlKCciw5DxzWOHqg3_ld3X4_aAQ" target="_blank">logic gates</a> Â». All their inputs and outputs are well in phase and it is just required to use the decamaker script to assemble them. I made the main components using these logic gates.</p></div></div></div></div></div></div></div></div></section><section id="h.p_TkFrs9eQb-d1"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_8VsxyFB8b-dY"><div><div><h2 id="h.p_qYGHe3p4b-ds" tabindex="-1"></h2><p id="h.p_XCROTP1VcUCp">The implementation of the logic gates allows the making of any asynchronous logic circuit</p><p id="h.p_gpghndKXcZqN"><em>A,B : inputs</em></p><p id="h.p_BhzuWXcvcZt7"><em>Cin : carry input</em></p><p id="h.p_C9gmXOO9cZt9"><em>Cout : carry output</em></p><p id="h.p_tNXfsgiHcZt-"><em>S : output</em></p><p id="h.p_K2Niv_17cZt_">A ripple-carry-adder can be made by juxtaposing n full adders.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_CXtRrYuVcEff"><div><div><p><img src="https://lh5.googleusercontent.com/JeMwH33urAdKOeUyBq3_Z-qdHrXzzLYsUKz7r7qoTVA1jtjroHUTdvNuHqJx9_uGyzn21UmtNDSBCXgZWlWlZ_6buxANoLr-AC37tzX04LtnsPFOiXw=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_0PNL2Bjcco5_"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_AkNt6t6cco51"><div><div><h2 id="h.p_UbbR_NuRco57" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>5 Arithmetic and logic unit (ALU)</p></div></h2><p id="h.p_Zx_DYURQcs0I">The ALU is composed of some logic functions and a unit which is composed of AND gates that select the result. The inputs are 8 bit each, the instruction is made of 8 independent bits. The instruction flat returns 11111111 if Bâ‰&nbsp;00000000, the instruction sign selects the most significant bit of B. The most significant bit is at the high left corner. The arrow from the select module to the adder represents the increment instruction.</p><p id="h.p_72CXS9I7fG-P">Instruction codes:</p><div><pre id="h.p_APcDULGQetQk"><code>+          00000001</code></pre><pre id="h.p_15CYbaBQetU2"><code>or         00000010</code></pre><pre id="h.p_WAQj6cNVetU6"><code>and        00000100</code></pre><pre id="h.p_venItL9vetU9"><code>xor        00001000</code></pre><pre id="h.p_7164prNZetVA"><code>not        00010000</code></pre><pre id="h.p_FMvwK-hnetVD"><code>flat       00100000</code></pre><pre id="h.p_8DIPmNCeetVF"><code>sign       01000000</code></pre><pre id="h.p_ooyX0MlGe8Yb"><code>increment  10000000</code></pre></div></div></div></div></div><div><div id="h.p_tFHU6M1BeOVn"><div><div><p id="h.p_KI124814eOVv"><em>A, B : inputs</em></p><p id="h.p_-Zlpu12dih6B"><em>I : instruction</em></p><p id="h.p_bcNnihNfiiLt"><em>S : output</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EuNde33Ndr2H"><div><div><p><img src="https://lh3.googleusercontent.com/NUMbrZLl7NJ9dj75xcv9X4Bjr1jW3Qvw2ILpx6o6_u6FiFhRSV3_Vdi3-Y1hAZyiqLCYpcbOhBXB2bHP5LJUCu8Q-667VrZg1NkmNI0xo3MnHPzjZxE=w1280" role="img"></p></div></div></div></div><div><div id="h.p_5pKa8Ic5eENS"><div><div><p><img src="https://lh5.googleusercontent.com/TJVG-Op3DtPeDN1Ad7xJi60w41PPP2A5LgjTAr_-VdrMv8FLT-xZkuY42sAKW9TFVQviykx2vyFAef8Y37MUJW0PKHZywPIuRZDk4iUjB2h9iYn5xw=w1280" role="img" alt="A, BÂ&nbsp;: inputs IÂ&nbsp;: instruction SÂ&nbsp;: output"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_jHes96Wtc8fQ"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_BKo62TzUc8fH"><div><div><h2 id="h.p_vYkEPbjvc8fO" tabindex="-1"></h2><h3 id="h.p_RJbO663DhlFw" tabindex="-1"></h3><p id="h.p_J5cxzD94glif">A memory unit is composed of an RS latch and logic gates AND to manage reading and writing tasks. The memory is an assembly of 64 memory units in 8 lines and 8 columns thus forming an 8x8 bytes memory.</p></div></div></div></div><div><div id="h.p_eCvk1p35gonU"><div><div><p id="h.p_P3fNdtgKgonX"><em>W : write 1 if set=1 0 if reset=1</em></p><p id="h.p_dfj4HZr1gptO"><em>R1 : read the state of the memory to the S1 output </em></p><p id="h.p_EMY4WO82gptO"><em>R1 : read the state of the memory to the S2 output</em> </p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_GQ_D4n5jhHfp"><div><div><p><img src="https://lh6.googleusercontent.com/4y1u30XYaJmgaCzA2VWVZAhmaZhiQM7aJ3CPHWFyd3_bnbezbnihvV3AaZeInc1FXuAFvYFCOdsyQMYHQzle2xZy5aXp-ePD9i6IK2zhGNjNL9DkCYL1=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EaOInrvcfyFS"><div><div><p><img src="https://lh5.googleusercontent.com/3vfuPYy63B5_LkqIG9n4XRBstXtZUmkudqocv3z6FvE0R-lb-DM-Vt76Kh5Hd0qKH0JwLuOQrXvf97n-ECB10Co7bjGUKnJM4AVdeWvy0XGpmvwm14A=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_KUUiaKkXhrud"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Fxjpj-lqhruZ"><div><div><h3 id="h.p_O689rlGChrub" tabindex="-1"></h3><p id="h.p_9JPre3onht49">The 3 modules at the left of the memory are decoders from 3 bit to 8 for decoding addresses. This memory allows us to read data from two addresses a1 and a2 at the same time. The output is made of 16 bit alternated between S1 and S2.</p><p id="h.p_LCsn7eBkh9rP"><em>A : data to write, 1 byte </em></p><p id="h.p_fHO0POG9h-BA"><em>a0 : address for writing, 3 bits</em></p><p id="h.p_ltfqpzgNh-BB"><em>a1 : address for reading, 3 bits</em></p><p id="h.p_WjJwr5Muh-BB"><em>a2 : address for reading, 3 bits</em></p><p id="h.p_nH4jURGYh-BC"><em>S : output, 2 bytes </em></p><p id="h.p_3jfHFLL-h-BC"><em>W : writes A to address a0 if W=1</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_OJ8hOGCiguUw"><div><div><p><img src="https://lh6.googleusercontent.com/ehntyvdHy4u0w14kP7kk-QiLrUsvIjhvyXqhNVCsYIL_G29EGe9HJDwrzmC-owi06louGxqo-Qt6fGDpxXr7DnIoJLJrI5h5qobEDzMddBsWuVXWY9A=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_xrHTkqo4dAQk"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Z3g-lThLdAQd"><div><div><h2 id="h.p_E1XIJpRSdAQi" tabindex="-1"></h2><p id="h.p_Gfx0enzfi2bC">The program is of a static memory form. The big rectangular module is a decoder from 5 bit to 32 which is used to select a line of the program given the input address. </p><p id="h.p_lVjX0pHCi2fB">Each line is made of 21 bits distributed as follow from the high right corner:</p><p id="h.p_5YBVlSYLi2fC">- 8 bits for data</p><p id="h.p_kqeXBpHei2fC">- 3 bits for reading address</p><p id="h.p_gcYz7S9ui2fD">- 3 bits for reading address</p><p id="h.p_iI6szhGYi2fD">- 3 bits for writing address</p><p id="h.p_RbF8D0CFi2fD">The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> contains more information on computer programming.</p><p id="h.p_idxG0XgBi2fE"><em>A : address of the line to be read: 5 bits</em></p><p id="h.p_OOX77ZdYjPJ_"><em>S : output: 21 bits</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_zozhh_nnjE17"><div><div><p><img src="https://lh3.googleusercontent.com/2AfTsfC5NFo12AyclXE94P2BHX_4I7SdeA-r7kjzZTmljmyzuFX-loQskJPFEj_ETa3P42NVuTcTnPNo45OxIF_-m3dlGYsZtNo6g3ocqdGAcE9ImLg=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p__hCJiXtvjdpP"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hqpO9gy2jdpM"><div><div><h2 id="h.p_797YSJ2BjdpO" tabindex="-1"></h2><p id="h.p_WmzCYEQBlNzw">Diagram of the computer architecture. Only the main information channels are represented. The module â€œlineâ€� is a 5 bit memory for writing the address of the line which is running (PC). The module â€œcontrolâ€� is principally a decoder which takes as input an instruction code of 4 bits, decodes it into 16 independent bits and communicates with all the other modules to execute the instruction.</p><p id="h.p_XcW1bSfulN46">Elements which are not represented in this diagram:</p><p id="h.p_N3qxDVHFlN46">- the control channels from the control module to other modules</p><p id="h.p_ZhFjawdelN47">- the clock</p><p id="h.p_39_5GK1ilN47">- the control channels from the clock to the other modules</p><p id="h.p_wEaE1tRJlN48"><em>Color code:</em></p><p id="h.p_6wdWXJ6slN48"><em>Green: 8bit data bus </em></p><p id="h.p_DYEi5V_dlN49"><em>Red: 3bits address</em></p><p id="h.p_dN0UhRcmlN49"><em>Yellow: 4bits instruction</em></p><p id="h.p_nF0hM-LnlN4-"><em>Pink: 5bits address</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_M3Aa7YeslFnO"><div><div><p><img src="https://lh3.googleusercontent.com/oN5UUG3LI4VeWk9k_BNVPzXP_itx_HohipL-7EiJK5m0x1GtRFXkr_IFiLASTNPmSjno1stDi8-YMjPRVf3ewdxAD5PZbWa_ARE6gtWRYS5Nvzd9Iw9n=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_iatMj5Mom9_B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_XJCPKyEwoEID"><div><div><h2 id="h.p_0xltGO10oEIG" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>9 Detail of a clock cycle</p></div></h2><p id="h.p_akxX-ZM1oGgX">The clock is constituted of 4 loops, formed by glider reflectors in which glider beams rotate. In each loop, a glider duplicator is placed on the glider beam path. This makes it possible to extract the signal from the clock. The 4 loops give rhythm to: the execution of an instruction, the writing in the memory, the incrementation of PC, the writing of PC in the memory.</p><p id="h.p_t1CmuX1joGin">PC is stored in memory at address 000, however, it is needed to read it all along the execution of an instruction. It is therefore copied into the Line module on each cycle. The following table summarizes a clock cycle.</p></div></div></div></div><div><div id="h.p_JVam50uBm9-3"><div><div><div><pre id="h.p_l5Bvpg0xm9--"><code><strong>Generation  Clock loop  Signal edge  Action</strong></code></pre><pre id="h.p__2oUC2gPn53Z"><br></pre><pre id="h.p_6ZQ7UNDLm-Mp"><code>0           0           Rising       Reading of an instruction, </code></pre><pre id="h.p_Sv1HYSQtnsKA"><code>                                     execution of it by the ALU without writing on the memory</code></pre><pre id="h.p_YK3_r7RHm-Mr"><code>590 000     1           Rising       Writing of the ALUâ€™s output on the memory</code></pre><pre id="h.p_tfhVMyQYm-Mu"><code>650 000     1           Falling      End of the writing on the memory</code></pre><pre id="h.p_ygXdUEOXm-Mx"><code>860 000     0           Falling      End of the reading of the instruction</code></pre><pre id="h.p_RlwORZMom-My"><code>1 100 000   2           Rising       Reading PC from address 000 to the ALU for incrementation </code></pre><pre id="h.p_VjI3TS5Hny6C"><code>                                     Copy of PC from 000 to the Line module</code></pre><pre id="h.p_SEdE98RKm-M1"><code>1 440 000   3           Rising       Writing of the ALUâ€™s output (PC+1) to the address 000</code></pre><pre id="h.p_omeA5Huam-M3"><code>1 480 000   3           Falling      End of the writing of PC+1 to the address 000</code></pre><pre id="h.p_vAI6RZ7om-M5"><code>1 600 000   2           Falling      End of reading from the address 000 and end of copying from 000 to the Line module </code></pre><pre id="h.p_D181OqNhn33k"><code>                                     At this time, PC+1 is written at 000 and on the module Line</code></pre></div></div></div></div></div><div><div id="h.p_6uVtrglpoOly"><div><div><p id="h.p_H3AbL1XZoOl0">The column â€œclock loopâ€� gives he position of the clock loop which generates the signal. The index rises from the high left corner. Generation gives the time at which the signal leaves the clock loop. Each cycle is made of two parts: the execution of the instruction (loops 0 and 1) ant the incrementation of PC (loops 2 and 3). Each cycle has a period of 2,003,880 generations.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p__7h5dMoWoWOG"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_E5Cu7xouoWOE"><div><div><h2 id="h.p_eiDdjwjWoWOG" tabindex="-1"></h2><p id="h.p_ZfBRIcwDoZn9">The Golly Python script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> helps to program the computer. 8 variables can be used: a,b,c,d,e,f,g,h. h is at the address 000 and is used for storing PC.</p><div><pre id="h.p_ar30iTXdo1HX"><code><strong>Instruction    Effect</strong></code></pre><pre id="h.p_VXWYwsQ8o1Mz"><code>write a n      Write the number n in to the variable a</code></pre><pre id="h.p_nUD9ePRPo1M0"><code>goto n         Go to line n</code></pre><pre id="h.p_q0l3SJwCo1M1"><code>move a b       b=a</code></pre><pre id="h.p_EZ1mwWONo1M1"><code>jumpif a       Jump the next line if a!=0</code></pre><pre id="h.p_l-rCsKzpo1M2"><code>print a        Display a</code></pre><pre id="h.p_CBxpEJLKo1M3"><code>add a b c      c=a+b</code></pre><pre id="h.p_bfag-7ZAo1M4"><code>or a b c       c=(a or b)</code></pre><pre id="h.p__Fy1TYwTo1M5"><code>and a b c      c=(a and b)</code></pre><pre id="h.p_OQcg0eRIo1M6"><code>xor a b c      c=(a xor b)</code></pre><pre id="h.p_HVXrkzoho1M7"><code>not a b        b=not(a)</code></pre><pre id="h.p_B7QjGUiqo1M8"><code>flat a b       B=0 if a=0 ; b=11111111 else</code></pre><pre id="h.p_LZxRjcG6o1M9"><code>sign a b       Write the most significant bit of a to b </code></pre><pre id="h.p_k7oiaST4pLkr"><code>               (sign of a if a is written in 2â€™s complement)</code></pre><pre id="h.p_Tc9FaJOxo1M9"><code>increment a    a=a+1</code></pre><pre id="h.p_JTRSCPpEpftU"><br></pre></div><h3 id="h.p_0RIdrgYYqaDF" tabindex="-1"></h3><div><pre id="h.p_1k_9G6N4pgFC"><code><strong>Display a modulo b</strong></code></pre><pre id="h.p_UqV_FtofqYtT"><br></pre><pre id="h.p_PRhE8OwXqVsj"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_CGA2uabjpgFD"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_lpw-3PODpgFF"><code>1       write b 3      b = 3 </code></pre><pre id="h.p_Ry8dLB3ZpgFG"><code>2       write e 1      d = -b</code></pre><pre id="h.p_LEkpXlKIpgFH"><code>3       not b d         |</code></pre><pre id="h.p_hwAKdadSpgFJ"><code>4       add d e d       |</code></pre><pre id="h.p_ijNnpg8YpgFK"><code>5       add a d a      a = a+d</code></pre><pre id="h.p_k402xubXpgFL"><code>6       sign a c       if a&gt;=0</code></pre><pre id="h.p_XAH8PlHfpgFO"><code>7       jumpif c        |</code></pre><pre id="h.p_6OVX0K86pgFP"><code>8       goto 5         go to line 5</code></pre><pre id="h.p_muhLQdv9pgFQ"><code>9       add a b        a a = a+b</code></pre><pre id="h.p_p_F6YavnpgFS"><code>10      print a        print a</code></pre><pre id="h.p_Pke5SZqQpgFT"><code>11      goto 11        end</code></pre></div><div><pre id="h.p_nD1hHtITrogs"><code><strong>Display GCD(a,b) (Euclid's algorithm)</strong></code></pre><pre id="h.p_lxqiep7_ronV"><br></pre><pre id="h.p_gMCLSmrlronW"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_UoKuhjHPronW"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_UfmcCRBRronX"><code>1       write b 6      b = 6</code></pre><pre id="h.p_JpIQn7o3ronX"><code>2       write e 1      c = a modulo b</code></pre><pre id="h.p_11Xpy03cronY"><code>3       not b d           |</code></pre><pre id="h.p_sTpDaV1JronY"><code>4       add d e d         |</code></pre><pre id="h.p_RL8BEDFeronZ"><code>5       add a d a         |</code></pre><pre id="h.p_OFwIDDuoronZ"><code>6       sign a f          | </code></pre><pre id="h.p_akSliUkOronZ"><code>7       jumpif f          |</code></pre><pre id="h.p_vM6j-KkMrona"><code>8       goto 5            |</code></pre><pre id="h.p_aIlt3SfRrona"><code>9       add a b c         |</code></pre><pre id="h.p_zlehb0Moronb"><code>10      jumpif c       if c = 0</code></pre><pre id="h.p_LoCcUlePronb"><code>11      goto 15        go to line 15</code></pre><pre id="h.p_lULgjjRzronc"><code>12      move b a       a = b</code></pre><pre id="h.p_ONpwMA9sronc"><code>13      move c b       b = c</code></pre><pre id="h.p_erU6mkLGrond"><code>14      goto 3         go to line 3</code></pre><pre id="h.p_GdClsddMrond"><code>15      print b        print b</code></pre><pre id="h.p_84t--rPSrone"><code>16      goto 16        end</code></pre></div></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.nicolasloizeau.com/gol-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831268</guid>
            <pubDate>Mon, 19 Oct 2020 21:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clusters rule everything around me]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24830588">thread link</a>) | @nickswhitaker
<br/>
October 19, 2020 | https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/ | <a href="https://web.archive.org/web/*/https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<blockquote><p><span>“</span><i><span>When an industry has thus chosen a locality for itself, it is likely to stay there long: so great are the advantages which people following the same skilled trade get from near neighbourhood to one another. The mysteries of the trade become no mysteries; but are as it were in the air, and children learn many of them unconsciously.</span></i><span>” – Alfred Marshall</span></p></blockquote>
<p><span>As technological advances continue to build out the digital economy it is perhaps ironic that physical locations still seem to matter so much. Slack and Twitter and Zoom and a host of various collaboration software products have facilitated our ability to communicate with people from all around the world. And yet, up-and-coming founders will still pay 3x the national average in rent so that they can live in Silicon Valley or Manhattan. Despite our ever-improving virtual tools, the triumph of the city is not reversing anytime soon. And the countries with the most vibrant tech clusters will get to decide the pace and the direction of the future. We need both a better understanding of how tech clusters form and how we can maximize their benefits.</span></p>
<h3><b>Why and how do tech clusters form?&nbsp;</b></h3>
<p><span>Economists and urbanists talk a lot about the significance of clustered networks of individuals and firms working and living together in a shared environment. All else equal, having more smart people interacting leads to more ideas which leads to more innovation which leads to more growth. The whole ecosystem of product designers, scientists, engineers, supply chain managers, investors, and academics ends up creating more than the sum of their parts. These </span><a href="https://www.agglomerations.tech/"><span>agglomeration effects</span></a><span> occur in cities across the world, but the US has had a unique geopolitical advantage in having the premier industrial clusters for essential technologies like software development and machine learning.</span></p>
<p><span>Defined </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>formally</span></a><span>, we could say that an industrial or tech cluster is a geographic region with a disproportionate share of economic activity, high-skilled technical employment, granted patents, and R&amp;D funding when compared to their share of the national population. Less formally, we could say that tech clusters are in the cities where the most interesting conversations and cutting-edge applications in a particular field are happening.</span></p>

<table id="tablepress-3">
<thead>
<tr>
	<th>Consolidated<br>
metro area</th><th>Venture<br>
capital<br>
investment</th><th>Granted<br>
patents</th><th>Employment<br>
in top 10<br>
R&amp;D<br>
industries,<br>
high-skilled</th><th>Population</th>
</tr>
</thead>
<tbody>
<tr>
	<td>San Francisco</td><td>48.1%</td><td>18.4%</td><td>11.7%</td><td>2.5%</td>
</tr>
<tr>
	<td>New York</td><td>15.3%</td><td>6.0%</td><td>6.3%</td><td>6.4%</td>
</tr>
<tr>
	<td>Boston</td><td>10.5%</td><td>4.5%</td><td>5.5%</td><td>1.6%</td>
</tr>
<tr>
	<td>Los Angeles</td><td>6.5%</td><td>5.3%</td><td>5.6%</td><td>5.8%</td>
</tr>
<tr>
	<td>Seattle</td><td>2.1%</td><td>4.0%</td><td>4.2%</td><td>1.2%</td>
</tr>
</tbody>
</table>
<!-- #tablepress-3 from cache -->
<p><span>San Francisco is the archetypal example, but Boston, Seattle, Austin, and Denver all meet this threshold as well. Larger cities like New York and Los Angeles are more ambiguous, as their share compared to population size is not disproportionate, but narrowing the analysis to a subregion like Manhattan or Santa Monica would likely turn up a traditional tech cluster.&nbsp;</span></p>
<p><span>Historically, clusters have been pivotal in driving long-term US growth and for creating innovations that improve the lives of billions of people around the globe. As economists </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>William Kerr and Frederic Robert-Nicoud</span></a><span> summarize, there has been a continual movement of leading tech clusters over time in the US. In the 1800s, Lowell, Massachusetts was the center for textile mills relying on water power. By the early 1900s, Cleveland, Ohio was instrumental in pushing forward the frontier on electricity and steel. Detroit, Michigan, of course, developed into the powerhouse for automobile manufacturing in the mid-1900s.&nbsp;</span></p>
<p><span>Currently, US tech clusters are the envy of the world. There are only four </span><a href="https://howmuch.net/articles/companies-trillion-dollar-club"><span>trillion dollar companies</span></a><span> in the world. Two of them are based near San Francisco (Apple and Alphabet), and two near Seattle (Amazon and Microsoft). Of the </span><a href="https://www.bondcap.com/report/itr19/#view/12"><span>global top 30</span></a><span> Internet firms, 14 are based in SF alone.</span></p>
<p><span>The effects that these clusters have on innovation and productivity growth are quite impressive, even on the individual level. Enrico Moretti </span><a href="https://www.nber.org/papers/w26270"><span>models their impact</span></a><span>: “a computer scientist moving from the median cluster in computer science (Gainesville, FL) to the cluster at the 75th percentile of size (Richmond, VA) would experience a 12.0% increase in productivity, holding constant the inventor and the firm. In biology and chemistry, a move from the median cluster—Boise, ID—to the 75th percentile cluster—State College, PA—is associated with a productivity gain of 8.4%, holding constant the inventor and the firm.” And as the clusters get larger and more specialized, the productivity boosts also get larger.&nbsp;</span></p>
<p><span>While the benefits and significance of tech clusters are fairly well established, what is less well known is precisely how tech clusters originate and why they end up in the specific places they do. That software clustered near San Francisco was not inevitable, that auto manufacturing clustered in Detroit was not fate, that semiconductor fabrication today clusters in Taiwan is not preordained. So how do clusters arise?&nbsp;</span></p>
<p><span>In the past, clusters would frequently populate around a specific natural resource that was necessary for the operation of the tech in question, i.e. natural harbors, coal and iron deposits, fast-flowing streams. But the ultimate resources for technology development today are the human minds that can come up with and then implement new ideas. So tech clusters today are mostly about attracting and organizing talented humans in cities they would actually want to live in.&nbsp;</span></p>
<p><span>More formally, to become a tech cluster today, a location needs:</span></p>
<ol>
<li><span>An anchor organization as a first-mover in getting high-skilled talent in a particular field to come to a region (usually a firm or a university)&nbsp;</span></li>
<li><span>An urban environment in which firms and workers in adjacent sectors can benefit from large knowledge spillovers as new advances and technical approaches diffuse across the region quickly</span></li>
<li><span>The development of high-velocity labor markets where workers with deep technical expertise can quickly start, join, or leave various firms</span></li>
<li><span>A social scene that is animated by a particular industry or technology area such that the conversations happening in local bars are some of the best in the world for that subfield</span></li>
<li><span>A sufficient supply of industry-specific resources (venture capitalists, relevant scientific or manufacturing infrastructure, government contracts)&nbsp;&nbsp;</span></li>
<li><span>A good bit of luck</span></li>
</ol>
<p><span>It’s worth emphasizing that the development of a cluster is a process rather than a flip that is switched at a specific moment in time. A location may not have all of these elements right at the very beginning but will need to quickly develop them if it wants to have staying power beyond an initial flash in the pan. Also complicating things, some of these factors suffer from a chicken-or-the-egg problem as it is much easier to attract specialized capital and interested young people to a region once the cluster already exists.</span></p>
<p><span>The historical accidents of particular government policies can sometimes serve as a tiebreaker among competing destinations. One reason that Silicon Valley may have become the primary driver for software development rather than the Boston area is California’s decision to </span><a href="https://www.vox.com/new-money/2017/2/13/14580874/google-self-driving-noncompetes"><span>not enforce non-compete agreements</span></a><span>. While not necessarily the intention, this accelerated both the degree of knowledge spillovers and the velocity of labor markets in the region. Today, top developers at large tech companies frequently leave to start competitors and help cutting-edge practices and the more promising technical approaches diffuse quickly throughout the region. This may be frustrating for the particular firms losing out, but it makes the larger tech cluster more vibrant and dynamic. And by increasing the number of approaches attempted to solve an issue, it increases the odds of a breakthrough innovation happening.</span></p>
<p><span>But tech clusters don’t necessarily last forever. As an industry matures and becomes more established it tends to be less reliant on the kind of rapid experimentation and ideation that is facilitated so well by tech clusters. As that happens, an industry may disperse over a larger set of regions, or be subsumed into a more traditional urban agglomeration.&nbsp;</span></p>
<p><span>Unsurprisingly, it seems to be the case that the development of a new </span><a href="https://www.nber.org/papers/w11093"><span>general-purpose technology</span></a><span> is usually a prime candidate for allowing new tech clusters to form. But interestingly, there may be a bias towards slightly smaller cities that can operate as more a blank slate for the fledgling industry than can a large, established city.&nbsp;</span></p>
<p><span>Looking at the emergence of auto manufacturing as an example, despite having fewer initial entrants and a smaller population, activity started to concentrate in smaller cities like St. Louis, Cleveland, Indianapolis, and in the ultimate winner, Detroit. According to </span><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.34.3.50"><span>Kerr and Robert-Nicoud</span></a><span>, this smaller city advantage may have been due to the higher physical proximity of engineers, production line managers, and funders as it was easier to share prototypes, run experiments, and circulate ideas between the relevant stakeholders. These smaller regional hubs may have been able to provide more attention and financial resources to these new firms because there was simply less competition.</span></p>
<p><span>This should not be all too surprising when we consider the softer, cultural aspects that make up an attractive tech cluster. It seems likely that the culture of a city made up disproportionately of geneticists and CRISPR scientists might differ from that of petroleum engineers and fracking specialists. Having a separate city is useful for establishing a different culture and offers a type of specialization that can attract a separate set of weird, ambitious young people that will form the backbone of a cluster.&nbsp;</span></p>
<p><span>The conversations in the bars and social scenes of San Francisco feel </span><i><span>very different</span></i><span> from those in the financial district of NYC because the types of people attracted to those cities are very different. To truly become a cluster for a particular field, a city essentially has to reach some critical density of conversations in the social scene to be …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/">https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/</a></em></p>]]>
            </description>
            <link>https://www.worksinprogress.co/issue/clusters-rule-everything-around-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24830588</guid>
            <pubDate>Mon, 19 Oct 2020 20:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From fluffy to valuable: How the brain recognises objects]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24830431">thread link</a>) | @pelt
<br/>
October 19, 2020 | https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects | <a href="https://web.archive.org/web/*/https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  
  

  

  <p>To recognise a chair or a dog, our brain separates objects into their individual properties and then puts them back together. Until recently, it has remained unclear what these properties are. Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig have now identified them - from "fluffy” to “valuable” - and found that all it takes is 49 properties to recognise almost any object.</p>
  
  
<figure data-description="The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. Depending on how similar the observed object is to a known category, it is then recognised as a dog or, for instance, a piece of furniture." data-picture="base64;PHBpY3R1cmUgY2xhc3M9IiIgZGF0YS1pZXNyYz0iLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TVRRd01Dd2liMkpxWDJsa0lqb3hOVGt4TlRZeU4zMD0tLWQxYzUyMTY5ZTQxOThmMmZmMGJjOWI2NDA3YjQ4M2Y3OTIyNzdjM2YiIGRhdGEtYWx0PSJvcmlnaW5hbCIgZGF0YS1jbGFzcz0iIj48c291cmNlIG1lZGlhPSIobWF4LXdpZHRoOiA3NjdweCkiIHNyY3NldD0iLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TkRFMExDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLTRkNmJmNWIxMjAzMDhjMzc2Nzg0YzJiNTViMWYyOGFhYjQ0Zjk0YWUgNDE0dywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TXpjMUxDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLTY2YmIyYzNjMmQ3YTRjZDJjZWFhNWE4NzEzNzdhYTQzZTA0YTVmYzUgMzc1dywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TXpJd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLTUwYzJkMmJhZDBiZmMwNWE1ZTkyNmE0ZmZmYjhmMDU4Njk4Y2NkZDggMzIwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TkRFeExDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWYzNmQxZTZmMWRmOTE4ODVmZmQ1MDg4YWQ0Zjk3MTVkMjBiZjQyMzAgNDExdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TkRnd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLTBjOWM5YTA5ZDRlZmRkMzA5ODg1ODgyODE3NjRhNjljNDdhZGUzNTQgNDgwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TXpZd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWNjOWJjYjJlYWMxZWY5ODViYjJkMzY1NzFiNDA4MTIxY2Y5NWM3ZDkgMzYwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2T0RJNExDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWQ3NTBjNmQ5YTU5OWM3NTZhYjY3ZDc1NzYyN2E2ZGUxODQzNDA1MzIgODI4dywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TnpVd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLTY1YzIyZTAzMGI5MTRjNTFkMTFmODAyZWQzYjhjOWM5ZGVmNDZhNjEgNzUwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TmpRd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWEzZWJjMWZiZmEyOTRhN2U0Mjc1ZTQ0MDI2ZWIzMjU4MWJjNGVjMWEgNjQwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2T0RJeUxDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWVjOGI5ZjA3YTYzNTg4ZjgzZGRlY2U0ZWYxNDEyNjJlZGEyYjgwZjYgODIydywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2T1RZd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWRjYTc5ZmE4ZjIyODEwZTcwYjMzZGNmMmExZTgyNjQ2Y2MzZDFmYzAgOTYwdywgLzE1OTE1NjI3L29yaWdpbmFsLTE2MDMyMDAxMzMuanBnP3Q9ZXlKM2FXUjBhQ0k2TnpJd0xDSnZZbXBmYVdRaU9qRTFPVEUxTmpJM2ZRPT0tLWQzMDJkODJhNzU4ZGI4MWFmNDRhNjQwYjZjOTYyOTk3MDg2N2JhODkgNzIwdyIgc2l6ZXM9IjEwMHZ3IiAvPjxzb3VyY2UgbWVkaWE9IihtaW4td2lkdGg6IDc2OHB4KSBhbmQgKG1heC13aWR0aDogOTkxcHgpIiBzcmNzZXQ9Ii8xNTkxNTYyNy9vcmlnaW5hbC0xNjAzMjAwMTMzLmpwZz90PWV5SjNhV1IwYUNJNk9UQXdMQ0p2WW1wZmFXUWlPakUxT1RFMU5qSTNmUT09LS0zZDQ4NGM3MjVhNDk1ZjU0OTU5YWVjNmM1N2VhOWNlZDBkYmMzNTg3IDkwMHcsIC8xNTkxNTYyNy9vcmlnaW5hbC0xNjAzMjAwMTMzLmpwZz90PWV5SjNhV1IwYUNJNk1UZ3dNQ3dpYjJKcVgybGtJam94TlRreE5UWXlOMzA9LS1hYWFhM2VhZmQ5ZWJhYWU0MGJhZWEwYjMzMzVlYjEwNWFiMWIyNGViIDE4MDB3IiBzaXplcz0iOTAwcHgiIC8+PHNvdXJjZSBtZWRpYT0iKG1pbi13aWR0aDogOTkycHgpIGFuZCAobWF4LXdpZHRoOiAxMTk5cHgpIiBzcmNzZXQ9Ii8xNTkxNTYyNy9vcmlnaW5hbC0xNjAzMjAwMTMzLmpwZz90PWV5SjNhV1IwYUNJNk1USXdNQ3dpYjJKcVgybGtJam94TlRreE5UWXlOMzA9LS1mZmY1YzkxMjlmZGNmNTYyMjk5ODg4NzA3Nzk2MTRkZTIyNzdjMDFjIDEyMDB3LCAvMTU5MTU2Mjcvb3JpZ2luYWwtMTYwMzIwMDEzMy5qcGc/dD1leUozYVdSMGFDSTZNalF3TUN3aWIySnFYMmxrSWpveE5Ua3hOVFl5TjMwPS0tNGU3MzRjZGEzMDVmMGM4MjM3ODcyNWVhNGE2Y2VkN2I2YjVhMTkwOSAyNDAwdyIgc2l6ZXM9IjEyMDBweCIgLz48c291cmNlIG1lZGlhPSIobWluLXdpZHRoOiAxMjAwcHgpIiBzcmNzZXQ9Ii8xNTkxNTYyNy9vcmlnaW5hbC0xNjAzMjAwMTMzLmpwZz90PWV5SjNhV1IwYUNJNk1UUXdNQ3dpYjJKcVgybGtJam94TlRreE5UWXlOMzA9LS1kMWM1MjE2OWU0MTk4ZjJmZjBiYzliNjQwN2I0ODNmNzkyMjc3YzNmIDE0MDB3LCAvMTU5MTU2Mjcvb3JpZ2luYWwtMTYwMzIwMDEzMy5qcGc/dD1leUozYVdSMGFDSTZNamd3TUN3aWIySnFYMmxrSWpveE5Ua3hOVFl5TjMwPS0tN2U3NjEyNTI2MzNhNWU0NTRkMDg2YTJhZmU2ZGU0MmMyNWU4ZTcyOSAyODAwdyIgc2l6ZXM9IjE0MDBweCIgLz48aW1nIGNsYXNzPSIiIHRpdGxlPSJUaGUgaHVtYW4gYnJhaW4gYnJlYWtzIGRvd24gdGhlIGVudmlyb25tZW50IGludG8gYSB0b3RhbCBvZiA0OSBwcm9wZXJ0aWVzLCB3aGljaCBhcmUgc3VmZmljaWVudCB0byBjYXRlZ29yaXNlIGFsbCBvYmplY3RzLiBEZXBlbmRpbmcgb24gaG93IHNpbWlsYXIgdGhlIG9ic2VydmVkIG9iamVjdCBpcyB0byBhIGtub3duIGNhdGVnb3J5LCBpdCBpcyB0aGVuIHJlY29nbmlzZWQgYXMgYSBkb2cgb3IsIGZvciBpbnN0YW5jZSwgYSBwaWVjZSBvZiBmdXJuaXR1cmUuIiBzcmM9Ii8xNTkxNTYyNy9vcmlnaW5hbC0xNjAzMjAwMTMzLmpwZz90PWV5SjNhV1IwYUNJNk1UUXdNQ3dpYjJKcVgybGtJam94TlRreE5UWXlOMzA9LS1kMWM1MjE2OWU0MTk4ZjJmZjBiYzliNjQwN2I0ODNmNzkyMjc3YzNmIiAvPjwvcGljdHVyZT4=">
      
    

    
    <figcaption>
        <p>
          The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. Depending on how similar the observed object is to a known category, it is then recognised as a dog or, for instance, a piece of furniture.
        </p>
        <p>
          © shutterstock
        </p>
    </figcaption>
</figure>



<p>We live in a world full of things that we have to identify and classify into different categories. Only when you are able to identify the things around you, you can communicate with others about them and act in a meaningful way. If we see something in front of us that we recognise as a chair, we can sit on it. Once we have identified an object as a cup, we can lift it up and drink from it.</p>
<p>In order to carry out this mapping and make sense of our environment, we have to constantly compare the input to our senses with the information we have already learned. To do this, the brain breaks down an object into its individual properties, compares them with those that are already known, and puts these properties back together. Depending on how similar the observed object is to a known category, it is then recognised as a piece of furniture or a vessel. So far, however, it has remained unclear how we consider things to be similar or less similar. In other words, what are the characteristics that make us recognise objects?</p>
<p>Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig, in collaboration with the National Institute of Mental Health in Bethesda, USA, have now identified a set of 49 properties that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it "is natural", "can move", "is valuable" or "is animal-related". The researchers had been looking for the set of dimensions that were interpretable and minimally sufficient, i.e. that contained as few properties as possible and yet were enough to describe everything.</p>

<figure data-description="The scientists identified a set of 49 properties (here only as an excerpt) that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it &quot;is natural&quot;, &quot;can move&quot;, &quot;is valuable&quot; or &quot;is animal-related&quot;." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          The scientists identified a set of 49 properties (here only as an excerpt) that allow us to determine almost all objects, i.e. the properties underlying their so-called mental representation. This representation reflects the format into which the brain translates a stimulus. In the case of an object, it is composed of, for example, colour, shape and size, but perhaps also of the fact that it "is natural", "can move", "is valuable" or "is animal-related".
        </p>
        <p>
          © Hebart/ MPI CBS
        </p>
    </figcaption>
</figure>



<p>"Our results show that it actually takes surprisingly few dimensions to characterise all objects in our environment," says Martin Hebart, first author of the <a href="https://www.nature.com/articles/s41562-020-00951-3" target="_blank">article describing these results</a>. The human brain breaks down the environment into a total of 49 properties, which are sufficient to categorise all objects. "From these dimensions we can also infer what is perceived as particularly similar or what is perceived as particularly typical for a category," the neuroscientist continues. Whether, for example, a mussel or a dog is perceived as a more typical animal. "Fundamentally, this explains the basic principles of our thinking about objects."</p>
<p>However, the results could also be used for medical purposes. Until now, it was believed that patients who cannot identify certain animals because of brain damage would not be able to recognise animals as a whole. But it is possible that the patient has a deficit in recognising the characteristic "fluffy" that is a property of many animals. This may then lead to other forms of therapy.</p>
<p>The scientists investigated these relationships with the help of almost 2,000 pictures of objects representative of most things encountered in our environment.&nbsp; They then showed study participants three of the pictures at a time, for example, koala, dog and fish, but also koala, doormat and pretzel. From each of these, the participants were asked to choose the “odd one out”, the one that they perceived to be most different from the other two. In the case of koala, doormat, and pretzel, for some this might have been the koala, because, unlike the other two, it is a living creature or is considered "not flat". For others, it might have been the pretzel, because doormats and koalas are fluffy or you can only eat the pretzel. Yet for others, it might be the doormat, because it is made of inorganic material. This means that the answers are not always clear, but they highlight the relevant properties to find out all the core dimensions of objects.</p>
<p>The researchers tested almost 1.5 million combinations of three objects with the help of nearly 5,500 participants. From this, they developed a computational model which they used to calculate which object was most likely to be chosen to be the odd one out. The more often two objects are left in, the more similar they are. It turned out that their model enabled the scientists to predict the similarity of two objects very precisely. But it also provided the 49 core dimensions that enable us to categorise our world according to simple criteria.</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/15916063/1016-nepf-113272-from-fluffy-to-valuable-how-the-brain-recognises-objects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24830431</guid>
            <pubDate>Mon, 19 Oct 2020 20:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interdimensional Cable Box]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24829947">thread link</a>) | @catacombs
<br/>
October 19, 2020 | https://nimaid.github.io/tv/ | <a href="https://web.archive.org/web/*/https://nimaid.github.io/tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nimaid.github.io/tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829947</guid>
            <pubDate>Mon, 19 Oct 2020 19:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turing Pi 2 – a compact ARM cluster with 32 GB RAM]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24829768">thread link</a>) | @nsky-world
<br/>
October 19, 2020 | https://turingpi.com/turing-pi-2/ | <a href="https://web.archive.org/web/*/https://turingpi.com/turing-pi-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <!-- Hero Header -->
    <section>
        <div>
            <div>
                <div>

                    
                    <div>
						                            <p><strong>32 GB</strong>                             <span>of RAM</span>                            </p>
						                            <p><strong>SATA III</strong>                             <span>interface</span>                            </p>
						                            <p><strong>CM4</strong>                             <span>support</span>                            </p>
						                    </div>

                    

                </div>
                <p><img src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" alt="" data-src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                </p>
            </div>
        </div>
    </section>

    <!-- Section About -->
    <section>
        <div>
            <div>
                <div>
                    <h3>
						Reliable, scalable, cloud-native infrastructure for the edge                    </h3>
                    <p>
						Turing Pi is a compact ARM cluster that provides a secure and scalable compute in the edge. It is designed to make web-scale edge computing easier for developers. Turing Pi cluster architecture allows you to migrate and sync web apps with minimal friction. It provides you with complete control of the edge infrastructure and improves reliability.
                    </p>
                </div>
                <div>
                    <div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/1.svg" alt="Layer 2 Managed Switch" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									Layer 2 Managed Switch                                </p>
                            </div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/2.svg" alt="2 x Mini PCI Express" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									2 x Mini PCI Express                                </p>
                            </div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/3.svg" alt="2 x SATA III 6 Gbps" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									2 x SATA III 6 Gbps                                </p>
                            </div>
						                    </div>
                    <div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/4.svg" alt="12 Gbps Backplane Bandwidth" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									12 Gbps Backplane Bandwidth                                </p>
                            </div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/5.svg" alt="Cluster Management Bus (I2C)" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									Cluster Management Bus (I2C)                                </p>
                            </div>
						                            <div>
                                <p><img src="https://turingpi.com/wp-content/uploads/2020/10/6.svg" alt="VLAN Support" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
                                </p>
                                <p>
									VLAN Support                                </p>
                            </div>
						                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Section User Cases -->
    <section>
        <div>
            <h3>
				Use Cases            </h3>

            <div>
                <div>
					                        <div>
                            <p>Self-hosted</p>
                            <p>Host cloud applications locally or at the edge</p>
                        </div>
					                        <div>
                            <p>Learning</p>
                            <p>Learn Kubernetes, Docker, Serverless</p>
                        </div>
					                        <div>
                            <p>Development</p>
                            <p>Build cloud-native and CI/CD for ARM edge infrastructure</p>
                        </div>
					                        <div>
                            <p>Network-Attached Storage</p>
                            <p>Connect up to 2 x 2.5″ SSD storage</p>
                        </div>
					                </div>
                
            </div>

        </div>
    </section>

    <!-- Section Scheme -->
    <div>
        <p><img width="804" height="872" src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" alt="" loading="lazy" srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w" sizes="(max-width: 804px) 100vw, 804px" data-srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w" data-src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">        </p>
    </div>

    <!-- Section Module -->
    

    <!-- Blog Section -->
    <section>
        
    </section>

    <!-- Newsletter  -->
    <section>
        
    </section>

    <!-- Modal Success -->
    <div id="modal-success">
        <div>
            

            <h3>Check your inbox!</h3>

            <p>
                You should receive a confirmation email soon
            </p>

            </div>
    </div>

    <!-- Modal Error -->
    <div id="modal-error">
        <div>
            
            <h3>Error</h3>
            <p>Contact already exist</p>
            </div>
    </div>

</div></div>]]>
            </description>
            <link>https://turingpi.com/turing-pi-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829768</guid>
            <pubDate>Mon, 19 Oct 2020 19:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Discord Won]]>
            </title>
            <description>
<![CDATA[
Score 605 | Comments 581 (<a href="https://news.ycombinator.com/item?id=24829635">thread link</a>) | @ivanagas
<br/>
October 19, 2020 | https://ianvanagas.com/2020/10/19/how-discord-won/ | <a href="https://web.archive.org/web/*/https://ianvanagas.com/2020/10/19/how-discord-won/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-478">

	

	
			<figure>
				<img width="1280" height="720" src="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1280" alt="" loading="lazy" srcset="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg 1280w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1024 1024w" sizes="(max-width: 1280px) 100vw, 1280px" data-attachment-id="494" data-permalink="https://ianvanagas.com/2020/10/19/how-discord-won/kingdiscord/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KingDiscord" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>It has been a big year for realizing the limits of technology for interacting with people. Gamers have known this for a long time. Lag, disconnections, and coordination issues were problems in gaming since the start. There is a platform that has gone a long way in solving those problems: Discord.</p>



<p>Discord allows people to talk and chat online. Servers are created by anybody to talk about anything, usually, it is a friend group or a shared interest. They contain chat channels (kind of like Slack) and voice channels that are always on and allow people to join and leave whenever they want.</p>



<p>The competition between internet communication platforms is fierce. Discord wasn’t early to voice channels or group chats. They weren’t unique for targeting their offering to gamers. Other platforms have the same features as them. Yet they are a multi-billion dollar business. How? To borrow an idea from <a rel="noreferrer noopener" href="https://medium.com/@sarahtavel/how-to-build-an-enduring-multi-billion-dollar-business-hint-create-a-10x-product-recast-3527df2b8fcb" target="_blank">Sarah Tavel</a>, they built a 10x better product AND capture more value from it.</p>



<h2>10x Better</h2>



<p>Voice chat sucked for a long time. Skype, which was long the most popular option, was a mess. It forced you to call people. Servers went down often. The application crashed. Chats were all over the place. There is a good reason people do not use Skype and it is because it sucks.</p>



<p>There were other competitors like IRC, TeamSpeak, Mumble, Ventrilo. All had basically the same features, voice calls, and chat. Each suffered from a combination of problems like:</p>



<ul><li>Complicated setup process. Any new member must also go through a setup process.</li><li>Paid hosting. No one wanted to pay when there were free options. Especially true as servers grow.</li><li>Unclear benefits. Convincing one person was not enough, you needed to convince your whole group of the benefits of switching.</li><li>Weird ideological reasons. Your platform was your tribal affiliation, switching means abandoning your tribe. Everyone looked down on people who didn’t use the same platform as them (even if it was jokingly).</li></ul>



<p>Discord launched in May 2015, long after the competitors listed above. They are now more successful than those same competitors. They did so by making the experience 10x better:</p>



<ul><li>Discord requires nearly no setup. Starting a server on Discord takes two clicks. Creating channels is two clicks. It works instantly and all the time.</li><li>Discord is free.</li><li>It is easy to switch to Discord. Inviting people is two clicks and a paste. Joining a server (once you have an account) is two clicks. It is so simple you don’t even think about it.</li><li>Non-core features like emoji support, reactions, bots, integrations, video calls, and screen-sharing all work as well as you could ask.</li><li>Big community servers for games, fanbases, organizations, hobbies, and more.</li></ul>



<p>Improvements in each of these areas add up to a 10x better experience than other platforms. I complain about Discord way less than I complain about Skype. There are benefits for everyone on Discord, which makes it a 10x experience both for groups and individuals.</p>



<p>On top of being 10x better, the core features are free. This causes an obvious business problem, how do you make money? There isn’t an obvious place to put ads. Competitors often charge by the member, but that incentivizes against growth. Discord figured out a way to incentivize growth while capturing value from large and small groups. </p>



<h2>Sell Status to Capture Value</h2>



<p>It took Discord a long time to figure out monetization (and they still are figuring it out). Venture capital allowed them to experiment with ideas such as selling games and membership. Neither worked perfectly, but they pointed in the right direction. <a rel="noreferrer noopener" href="https://www.forbes.com/sites/abrambrown/2020/06/30/discord-was-once-the-alt-rights-favorite-chat-app-now-its-gone-mainstream-and-scored-a-new-35-billion-valuation/#article-0-topx-1:~:text=Discord%20is%20on%20track%20to%20top,Discord%20groups%20that%20they%20belong%20to." target="_blank">Forbes estimated</a> they are “on track to top $120 million in sales this year (2020)… up from around $70 million last year.”</p>



<p>To understand Discord’s monetization, look at their history. The founders previously started game companies and were <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Discord_(software)#cite_ref-vb_2015_funding_9-0:~:text=%5D%20Their%20first%20product%20was%20Fates,and%20based%20on%20more%20modern%20technology.%5B" target="_blank">inspired by free-to-play games like League of Legends.</a> Games like League of Legends sell status. It is free-to-play but you can buy “skins” to make your character look different. If you have a cool or expensive skin, it means you care more about the game. It raises your status. Discord does the same.</p>



<p>Discord allows users to raise their status through a subscription called Nitro. It provides quality improvements (file size and video quality), special profile upgrades (more emojis, animated profile photos, custom tags), and most importantly, the ability to “boost” a server.</p>



<p>Boosts raise a user’s status in both small and large servers. They allow you to either improve your friend’s online hangout and your communities’ experience by unlocking custom emotes, cosmetic features, and quality improvements. For users, it puts an icon next to their name saying they contribute and gives them a special booster role on the server. In short, it is a way for someone to pay to stand out.</p>



<figure><img data-attachment-id="493" data-permalink="https://ianvanagas.com/serverboosts/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png" data-orig-size="1163,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="serverboosts" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=750" src="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024" alt="" srcset="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024 1024w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png 1163w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Server Boost Perks</figcaption></figure>



<p>You can buy boosts separately from Nitro at $5 per month or $50 per year. Perks come in uneven tiers: Level 1 is 2 boosts, Level 2 is 15 boosts, Level 3 is 30 boosts. It is unlikely “friend group sized” servers get past two boosts, but large servers often pass thirty. Some examples:</p>



<figure><table><thead><tr><th data-align="left">Name</th><th data-align="left">Boosts</th><th data-align="left">MRR (@ $5 per boost)</th></tr></thead><tbody><tr><td data-align="left">Minecraft</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">Kanye</td><td data-align="left">75</td><td data-align="left">$375</td></tr><tr><td data-align="left">Fortnite</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">r/LeagueOfLegends</td><td data-align="left">201</td><td data-align="left">$1005</td></tr><tr><td data-align="left">Animal Crossing: New Horizons</td><td data-align="left">412</td><td data-align="left">$2060</td></tr><tr><td data-align="left">r/Overwatch</td><td data-align="left">85</td><td data-align="left">$425</td></tr><tr><td data-align="left">Rocket League</td><td data-align="left">116</td><td data-align="left">$580</td></tr><tr><td data-align="left">Fall Guys</td><td data-align="left">215</td><td data-align="left">$1075</td></tr><tr><td data-align="left">Anime Soul Discord</td><td data-align="left">323</td><td data-align="left">$1615</td></tr><tr><td data-align="left">Kenny Beats</td><td data-align="left">50</td><td data-align="left">$250</td></tr><tr><td data-align="left">Musicians (Turkish)</td><td data-align="left">730</td><td data-align="left">$3650</td></tr><tr><td data-align="left">English</td><td data-align="left">94</td><td data-align="left">$470</td></tr><tr><td data-align="left">Python</td><td data-align="left">44</td><td data-align="left">$220</td></tr><tr><td data-align="left">CallMeCarson Discord Cult</td><td data-align="left">1153</td><td data-align="left">$5765</td></tr></tbody></table></figure>



<p>Here are 14 popular servers accounting for nearly $250,000 in revenue per year. There are tons more, all with varying amounts of boosts. People are willing to pay to stand out, even when there is no obvious benefit. This is universal.</p>



<p>Every community needs a place to communicate online. Discord has the best offering, and it is free. Other platforms either force you to pay by the member or have a flat rate paid by the community host. Discord doesn’t require either. Servers can grow as large as they want for free, moderators and admins don’t have to pay, and Discord still makes money.</p>



<p>As communities continue to grow on Discord, the money Discord makes from those communities goes up as well. Flat rates and tiers limit this. Communities want to grow, Discord provides them with an easy and effective way to do that. Users want status, Discord gives them a shortcut. This aligns incentives better than advertising or paid memberships do.</p>



<hr>



<p>Discord won by building 10x better spaces for communities. By selling status, they have also managed to capture more value from those communities than other platforms.</p>



<p>Discord won the competition for the gaming chat platform of choice, and now it wants to be the platform for all internet communities. This means they will be competing with the “big dogs” like Slack, Reddit, Twitter, Facebook, Microsoft, and Epic. Their free-to-play, pay-for-status monetization model is a competitive advantage.</p>



<p>Discord is a successful company. The question becomes how successful can they become? The key is the number of internet communities who choose Discord as their home. By creating a better product than competitors and being free for growth, Discord puts itself in an excellent position to continue to succeed moving forward.</p>



<p>Follow me <a rel="noreferrer noopener" href="http://twitter.com/ianvanagas/" target="_blank"><strong>on Twitter</strong></a> or sign up for <a rel="noreferrer noopener" href="https://adept-teacher-7152.ck.page/55b2205587" target="_blank"><strong>my monthly newsletter</strong></a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://ianvanagas.com/2020/10/19/how-discord-won/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829635</guid>
            <pubDate>Mon, 19 Oct 2020 18:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Git diff output for Ruby, Python, Elixir, Go]]>
            </title>
            <description>
<![CDATA[
Score 294 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24828509">thread link</a>) | @Lammy
<br/>
October 19, 2020 | https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more | <a href="https://web.archive.org/web/*/https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>The regular Git users amongst you will be familiar with the diff output that breaks down into “hunks” like so:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> class TicketPdf
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>The first line (starting <code>@@</code>) is known as the hunk header, and is there to help orientate the change. It gives us the line numbers for the change (the numbers between the <code>@@..@@</code>), but also a textual description for the enclosing context where the change happened, in this example <code>"class TicketPdf"</code>. Git tries to figure out this enclosing context, whether it’s a function, module or class definition. For C-like languages it’s pretty good at this. But for the Ruby example above it’s failed to show us the immediate context, which is actually a method called <code>tickets_as_html</code>. That’s because out of the box Git isn’t able to recognise the Ruby syntax for a method definition, which would be <code>def ticket_as_html</code>.</p>

<p>What we really want to see is:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> def tickets_as_html
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>And it’s not just Ruby where Git struggles to figure out the correct enclosing context. Many other programming languages and file formats also get short-changed when it comes to the hunk header context.</p>

<p>Thankfully, it’s not only possible to configure a custom regex specific to your language to help Git better orient itself, there’s even a pre-defined set of <a href="https://github.com/git/git/blob/master/userdiff.c">patterns for many languages and formats right there in Git</a>. All we have to do is tell Git which patterns to use for our file extensions.</p>

<p>We can do this by defining a <a href="https://git-scm.com/docs/gitattributes"><code>.gitattributes</code></a> file inside our repo that maps the Ruby file extensions to the diff pattern for Ruby:</p>

<div><div><pre><code><span>*</span>.rb <span>diff</span><span>=</span>ruby
<span>*</span>.rake <span>diff</span><span>=</span>ruby
</code></pre></div></div>

<p>Some open source projects define their own <code>.gitattributes</code> file. There’s <a href="https://github.com/rails/rails/blob/master/.gitattributes">one in Rails</a>. There’s even <a href="https://github.com/git/git/blob/master/.gitattributes">one in the Git source</a> that enables the diff patterns for Perl and Python.</p>

<h2 id="configure-a-global-gitattributes-file">Configure a global .gitattributes file</h2>

<p>Instead of adding a <code>.gitattributes</code> file to every repo we can configure a global <code>.gitattributes</code> file. Just create a <code>.gitattributes</code> file in your home directory, fill it with all the file formats you are interested in and point Git at it:</p>

<pre><code>  <strong>$ git config --global core.attributesfile ~/.gitattributes</strong>
</code></pre>

<p>I’ve put together an <a href="https://gist.github.com/tekin/12500956bd56784728e490d8cef9cb81">example .gitattributes file</a> with some common file formats to get you started.</p>

<p>I have no idea why Git doesn’t have these file format patterns configured by default. Thanks to Tom whose <a href="https://twitter.com/tomstuart/status/1304401459069452290">exasperated tweet</a> brought this non-obvious feature to my attention.</p>


  </section></div>]]>
            </description>
            <link>https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-24828509</guid>
            <pubDate>Mon, 19 Oct 2020 17:16:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Many of the root certificates on Windows are not needed]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24827509">thread link</a>) | @svenfaw
<br/>
October 19, 2020 | https://hexatomium.github.io/2020/10/17/001.html | <a href="https://web.archive.org/web/*/https://hexatomium.github.io/2020/10/17/001.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As of today, Windows trusts 322 root certificates issued by 122 different organizations from 47 countries. This number is quite high, and has been steadily growing over the last few years. And it turns out many of those certificates are not needed at all by the vast majority of Windows users, can be distrusted with no ill effects of any sort.</p>

<p>Each of these CAs is given tremendous power over your Internet traffic, so it makes great sense to minimize the number of CAs your computer trusts. 
One simple way to achieve this goal is to replace the default Windows list of root CAs with the much stricter Mozilla trust list, which includes 142 roots (52 organizations - 21 countries). An even stricter option is using the Google CTL, which currently includes just 127 root certificates (48 organizations - 21 countries). For the vast majority of users, applying either set is a great way to reduce your exposure to unnecessary CAs, with no negative impact whatsoever.</p>

<p>Replacing the default Windows list of root CAs with the Mozilla or Google trust lists can be done manually, but is extremely time-consuming and error prone. 
The free version of RootIQ(*) offers a much simpler way to perform this system change:</p>

<div><div><pre><code>1. Use the Quick select dropdown to select the Mozilla trust set
2. Right-click the selection and click Invert selection
3. Right-click the selection and click Distrust
   Click Yes on the confirmation dialog
   This will distrust all roots that are not part of the Mozilla trust set, except for any Microsoft OS-critical roots.
4. Use the Quick select dropdown to select the Mozilla trust set (again)
5. Right-click the selection and Trust
</code></pre></div></div>

<p><img src="https://nsa40.casimages.com/img/2020/10/17/201017023914436079.png" alt="img123"></p>

<p>As of this writing, on a standard Windows 10 system, you will end up with 145 trusted roots (rather than 322 roots for the default Microsoft CTL)</p>

<p>(*) RootIQ, our own root certificate manager for Windows, is now <a href="https://www.metasudo.com/">available</a>. A free version of RootIQ is available for home and evaluation use.</p>

  </div></div>]]>
            </description>
            <link>https://hexatomium.github.io/2020/10/17/001.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827509</guid>
            <pubDate>Mon, 19 Oct 2020 15:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for using punctuation in Slack]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 258 (<a href="https://news.ycombinator.com/item?id=24827295">thread link</a>) | @dontmitch
<br/>
October 19, 2020 | https://blog.mitchjlee.com/2020/your-writing-style-is-costly | <a href="https://web.archive.org/web/*/https://blog.mitchjlee.com/2020/your-writing-style-is-costly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
          <p><strong>You should use punctuation in Slack.</strong> You should also use complete sentences and proper grammar. You should expand acronyms<sup>[1]</sup> and — when communicating emotion — even mix in some emoji for effect. You should do that not just in Slack, but in all of your professional communication.</p>

<hr>

<p>Written communication is hard, but in the digital world we work in it’s also vital. Sadly, the style of communication that services like Slack incentivize is awful.</p>

<p>To voice an opinion before the conversation moves on, you type fast and use abbreviations and hit send even with misspellings. You think one message at a time. You bounce between different threads and become easily distracted.</p>

<p>There are some obvious downsides to this fast and loose style. Most notably, it interrupts more productive work and deters deep thinking. But one large and often overlooked downside is the impact it has on others.</p>

<h2 id="externalities">Externalities</h2>

<p>When you use an obscure initialism or take shortcuts on grammar and spelling, it may save you a couple seconds. The problem is those small savings are often outweighed by the cost born by your audience.</p>

<p>Every person who reads your message spends some finite period of time interpreting what you’re saying. Setting aside the possibility that a sloppy message might lead the reader to an incorrect interpretation, it’s harder to parse messages written hastily — messages with poor grammar, misspellings, minimal punctuation, obscure acronyms, or delivered a few words at a time.</p>

<p>As an example, assume you send the following message to a Slack channel with 10 other people in it.</p>

<div><div><pre><code>anyone know the latest on cai
</code></pre></div></div>

<p>And further assume that “cai” refers to an internal project: <strong>C</strong>rusade <strong>A</strong>gainst <strong>I</strong>nitialisms. By writing in all lower case, using an initialism to refer to the project, and omitting the question mark, you’ve saved yourself two words and a handful of extra keystrokes. Under the most generous assumptions, say that translates to five seconds in savings. That’s a lot!</p>

<p>But let’s now examine the impact the shortcuts have on your 10-person audience.</p>

<ul>
  <li>Two people thought “cai” was a typo and spent several moments trying to guess what you actually meant to type before realizing you were referring to the internal project. <em>Cost: 20 seconds</em></li>
  <li>Two people didn’t know what “cai” stood for. One spent three minutes tracking it down on the internal wiki, and the other sent a private message to another team member to ask. <em>Cost: 4 minutes</em></li>
  <li>One person ignored your ask because they didn’t realize it was a question when scanning the channel. <em>Cost: Priceless</em></li>
  <li>Five people understood what you meant but still had to mentally expand the initialism before internalizing your ask. <em>Cost: 5 seconds</em></li>
</ul>

<p>Your 5 seconds of savings amounted to roughly 4.5 <em>minutes</em> of cost spread across your audience. Sure, this is a contrived example and sure there are cases where the cost is lower, but the point stands: <strong>your communication shortcuts are costly</strong>.</p>

<p>In economics, this phenomena is referred to as a negative externality.</p>

<blockquote>
  <p>A negative externality is the cost that affects a third party who did not choose to incur that cost.</p>
</blockquote>

<p>Every time you take a communication shortcut, you are inflicting a micro-externality on your audience. The more egregious the shortcut, the larger the externality; the larger your audience, the more times the externality is multiplied and the larger the overall cost.</p>

<h2 id="so-what">So what?</h2>

<p>If you’re communicating with a close friend and choose to use shorthand, you’re probably fine. Not only will your friend probably be accustomed to it (i.e. the externality will be small), but the audience is also small (i.e. the total cost will be small). In this case, it’s entirely possible your shorthand saves you more time than it costs your friend.</p>

<p>However, when you’re communicating in a one-to-many setting such as email or Slack, and particularly in a professional setting, sloppy writing<sup>[2]</sup> has real consequences. It prioritizes your time above the time of <em>every other person</em> that will be reading that message and might misinterpret your intent or tone. In aggregate, it is a net drain on productivity at your company.</p>

<p>So use proper spelling and grammar. Write out your entire thought before hitting send. Expand acronyms. Use punctuation.</p>

<p>A period, even at the end of “Do it,” communicates, “I’ve said everything I wanted to say.”</p>

<hr>

<p>[1] For the sticklers out there, this includes initialisms as well as acronyms.</p>
<p>[2] The term "sloppy" might sound harsh, but I chose it deliberately. Not everyone speaks the company language (e.g. English) natively, and for them using proper spelling or grammar might be challenging to say the least. The argument here is scoped to people who have some degree of mastery over the language but are being <em>sloppy</em> with their written communication, which is to say "careless and unsystematic; excessively casual".</p>

        </section>
      </div></div>]]>
            </description>
            <link>https://blog.mitchjlee.com/2020/your-writing-style-is-costly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827295</guid>
            <pubDate>Mon, 19 Oct 2020 15:35:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python For Feature Film]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24826873">thread link</a>) | @dagmx
<br/>
October 19, 2020 | https://www.gfx.dev/python-for-feature-film | <a href="https://web.archive.org/web/*/https://www.gfx.dev/python-for-feature-film">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><section><p>This post was originally part of my series on <span>Python for Feature Film</span> on <a href="http://www.dgovil.com/">my personal site</a>, but is being ported here with minor changes. The dates have been adjusted to match release dates for the projects.</p></section><p>Python is a programming language that has become integral to the movie making process over the last few years. There’s rarely an animated feature or visual effects film, if any, that hasn’t had Python play a large part in getting it to the screen</p><p>When people think about movies, even programmers often think about the artistry involved in bringing those images to life. However, the technical side of the film industry is something that often goes unnoticed outside a small group of people.</p><p>To that end, I’ve written a few blog posts about how I’ve used Python on several major films that I’ve been lucky enough to work on. Hopefully this shows how much it contributes to the entire life of a movie.</p><p>I’ve also recently released a course on <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Udemy</a> to teach artists how to learn Python For Maya since it’s becoming an increasingly valuable skill in the industry. These blog posts serve as companion material to the course as well.</p><p>With that intro out of the way let’s continue…</p><section></section><hr><h2 id="what-is-python">What is Python?</h2><p>Some of you may not be familiar with Python.</p><p>Python is a programming language designed to be very easy to read and write. It’s incredibly popular in the feature film industry as well as other groups, like mathematics, science and machine learning.</p><p>You can learn more about Python on <a href="https://www.python.org/" target="_blank" rel="noreferrer">the official website</a>.</p><p>It’s important to note that today, the film industry is largely still tied to Python 2.7. There is a concerted effort in 2020 to move over to Python 3, and
we should start seeing larger Python 3 adoption starting in 2021 and moving forward.</p><hr><h2 id="the-feature-film-pipeline">The Feature Film Pipeline</h2><p>The biggest use of Python is in our feature film pipeline.</p><p>This is an image that describes the pipeline at most major studios.
The Pipeline is the arrows that link each department together. It’s responsible for making sure that data flows between each department and that everyone can play well together.
It’s also responsible for the toolsets in each department so that the artists themselves can work efficiently, but for now lets focus on the inter-department flow.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/a3bc4/pipeline-flow.webp 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/39db6/pipeline-flow.webp 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/412e4/pipeline-flow.png 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/png">
        <p><img src="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png" alt="A diagram illustrating the flow of a shot between departments on a feature film pipeline"></p>
      </picture>
    </span></p><figcaption>An overview of the Film Production Pipeline</figcaption></div><p>Here you can see the various stages of a visual effects film or animated feature. Studios may differ slightly from this, but it’s the general workflow.</p><p>The storyboards/footage/previs represent the data we get, and Compositing/Lighting are the last stages of the film for us.
Visual Effects Films differ slightly from animated films because you have to deal with the extra added element of film footage in the form of plates.</p><div><figcaption>A more visual demonstration of this graph is in this video of the making of Ratatouille by Pixar</figcaption></div><p>The Pipeline is responsible for getting the data between departments. Here’s the gist of how it works (though it is more organic a process than the one described):</p><ul><li>We get data from the client or story artists in form of plates, previsualization (previs) or storyboards that tell us what is happening in the scene.</li><li>Modeling look at all of this and generate 3D models of all the assets that will be required.</li><li>Rigging take the modelled assets for characters and apply a virtual skeleton to make it animatable.</li><li>Matchmove are in charge of creating virtual cameras that match the ones used to shoot the film as well as any standin characters or geometry</li><li>Layout take the rigs, and either create their own cameras or take matchmoves cameras and set up the scene. They’re the equivalent of a virtual director of photography.</li><li>The scene is then handed off to Animation, who are the equivalent of the actors. They are in charge of the movement of the characters, and bring the inanimate skeletons to life.</li><li>CharacterFX are in charge of all the technical parts of animation. Muscle simulations, making cloth move realistically, the hair, grass etc… all comes from CharacterFX.</li><li>FX then handle the non animation related effects. Whether it be destruction, fire, voxelization, etc… there’s a lot that FX is in charge of.</li><li>While this is happening, Texturing are in charge of giving color to the 3D Assets so they aren’t just grey objects.</li><li>Shading then takes these textures and gives the assets a material that tells it how light should interact with it.</li><li>Matte Painting are the department we use when it is not logical or feasible to build an environment. We realistically can only build so much, and past that point it’s more efficient to have someone make a very high quality painting instead.</li><li>This all gets funnelled into Lighting who are in charge of adding lights to the shot and rendering the image out. They also do a little bit of compositing to sweeten the image. On an animated feature this may be the end of the show.</li><li>On a visual effects show, we have to prepare the plates by either removing unwanted elements, removing noise or removing the lens warp. This is handled by Plate Prep,also known as RotoPaint.</li><li>Finally everything goes to Compositing who take all the images and integrate our CG renders into the actual film plate. On a visual effects show, this will be the last stage.</li></ul><p>We use Python to tie all these bits together.
In the next section I’ll go over publishing before moving onto describing how Python is used for the individual departments.</p><h3 id="publishing-and-asset-management">Publishing and Asset Management</h3><p>This is pretty much the core of traditional pipeline, to make sure assets can be shared between departments and be tracked.</p><p>The first part of this is Asset Publishing.</p><p>When a department deems it’s work ready, it decides to publish it so the next department in the chain can consume it. For example modeling exports models, but does animation export animation? Well that depends on who is consuming it. This is dependent on whether it needs to be interactive past this point or not.</p><p>For geometry  we often just publish as a geometry cache using Alembic  which is a industry standard developed by Imageworks and ILM so that we can have a consistent cache format.
For point cloud data, we either use Alembic or OpenVDB, for images we tend to use tiff’s or OpenEXR.
Soon the industry will probably also standardize on a universal scene format from Pixar called OpenUSD.</p><p>Anyway  the idea is to generally keep the data in the most efficient format possible, while allowing for easy interchange. Cache data is often best because you really only take an IO hit, which is cheap, versus a deformation hit, which can be very expensive.</p><p>This all gets really complex though. Artists don’t need to know where their data is coming from or going to, or even how it gets there. They just need to be able to load it in and publish it out.</p><p>This is the pipeline. We develop the UI’s and the tools to do this in a very user friendly manner.</p><div>
  <p><img src="https://www.gfx.dev/e49c8aaf611022c8415419e9f49e3d71/pyblish.gif" alt="Pyblish is a similar but open soruce frontend that is featured here for reference"></p>
    <figcaption><a href="https://github.com/pyblish/pyblish-qml">Pyblish</a> is a tool by Marcus Ottosson that is similar to many publishing tools in studios</figcaption></div><p>To publish data, the user just has to open a publish UI that will validate their assets against some tests, and then send it off to the machine farms where the conversion to one of the open formats happens.</p><p>To ingest the published data, we similarly just have an asset browser that lets the artist pick which asset they want. Often they just see a thumbnail and description. The details are irrelevant to most artists.</p><p>Because these publishing and asset management systems need to be common to multiple apps, we develop them in Python and Qt (PyQt or PySide) , which allows us to reuse our code without recompiling for each application and makes it easy to rapidly add functionality where needed.</p><p>This is common to pretty much every department, so I figure it warrants its own section here rather than repeating for each.</p><hr><h3 id="modeling">Modeling</h3><p>Modeling is the department in charge of creating the 3D source geometry used by every other department.
Often there are quite a few repetitive tasks involved in regards to placing or editing geometry, or even just managing the scene.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/9fd6b/wireframe.webp 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/png">
        <p><img src="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png" alt="An image of the Blender susan model (a monkeys head) with a wireframe overlay to show its polygons"></p>
      </picture>
    </span></p><figcaption>A wireframe of a 3D model. This is Blender's Susan mesh.</figcaption></div><p>This is where Python comes in handy. Most 3D packages have a Python API that lets you do program everything that you would do manually.</p><p>So instead of spending 10minutes creating a simple asset, you can script it up and then just click a button when you need it next time. That 10 minutes saved really adds up, and over the course of a project you may be saving hundreds of hours that could be better focused on building more complex assets that require artistic input.</p><p>For example, in  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a simple gear using Python as well as creating a simple UI so that you can specify how many teeth the gear has and how long they will be.</p><p>This can get more complex though with using Python to create custom deformers or interactive tools, like this demo from Hans Godard demonstrates.</p><div><figcaption>Hans Godard has made some really interesting Python based modeling utilities.</figcaption></div><hr><h3 id="rigging">Rigging</h3><p>Rigging’s job is to create a skeleton for the character geometry so that it can deform, just like a real human would.</p><p>Of course that’s an over simplification.
Rigging is also essentially creating the interface that animators use to bring these creatures to life, but they also have to make sure that any movement happens convincingly.
If an animator moves the arm, the rigger must make sure that the shoulders deform properly.</p><p>Python plays an integral role in Rigging. Here are just some of the uses:</p><ul><li>Creating automated builds of rigs. Rather than doing everything manually, rigs can be composed using code which makes them easy to reuse.</li><li>Developing custom deformers or nodes to perform operations not native to the application.</li><li>Develop supporting scripts for animators to switch between modes or controls etc..</li></ul><p>In  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a controller library.
Controllers are, as the name suggests, the objects animators use to control the rig. Instead of using the geometry directly, they use controls, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gfx.dev/python-for-feature-film">https://www.gfx.dev/python-for-feature-film</a></em></p>]]>
            </description>
            <link>https://www.gfx.dev/python-for-feature-film</link>
            <guid isPermaLink="false">hacker-news-small-sites-24826873</guid>
            <pubDate>Mon, 19 Oct 2020 14:50:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I've stopped saying 'hey guys' (as a male in tech)]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24825887">thread link</a>) | @tomquirk
<br/>
October 19, 2020 | https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/ | <a href="https://web.archive.org/web/*/https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><a href="https://allybot.io/"><img src="https://allybot.io/assets/images/image02.png" alt="AllyBot logo">
</a></p></div></section><section><section id="articleHero"><div><header><div><div>
<p>October 17, 2020
• 6 min read</p></div></div></header><p><img src="https://blog.allybot.io/images/why-i-stopped-saying-hey-guys-hero.png"></p></div></section><article id="articleContent"><p>I’ll be the first to admit that I’m not an expert in diversity, equity or inclusion. I’m a white, straight, cis-gendered male software engineer from Australia. I build products, fix bugs, and enjoy a good coffee.</p><p>And I say the word ‘guys’. A lot.</p><p>So when I was told that saying ‘hey guys’ might make some people (women, in this case) feel excluded, frankly, I didn’t understand. “I say ‘guys’ all the time. How could it be an issue?” I told myself. People telling me what I can and can’t say? That doesn’t feel right. For years, I held the view that inclusive language was a threat to free speech.</p><p>But all it took was one podcast episode to change my perspective on inclusive language.</p><h2 id="free-speech-vs-inclusive-language">Free speech vs inclusive language</h2><p>My late teens and early 20’s were influenced by the so-called Intellectual Dark Web - Jordan Peterson, Joe Rogan, Sam Harris and the like. For the most part, I respect them a lot and still listen to their content to this day.</p><p>Universally, this group is not in favor of “language policing”, to put it lightly. Famously, Jordan Peterson was outspoken in his opposition to Canada’s C-16 bill, which he believed to be a threat to free speech. Peterson was specifically against the idea that he would have to address people by their preferred gender pronoun (e.g. he, her, zir, etc.). In other words, he didn’t want the government forcing him to use inclusive language. Whether or not this&nbsp;<a href="https://torontoist.com/2016/12/are-jordan-petersons-claims-about-bill-c-16-correct/">was an accurate characterization of C-16</a> is another question. But the premise that one’s choice of words could be criminalized in such a way is one that I am not in favor of.</p><p>In the years following the C-16 controversy, the world appeared to split into two camps: one that was supportive of inclusive language, and one that, passionately, was not. I mostly found myself in the second camp.</p><p>That was until a few months ago when I was listening to an&nbsp;<a href="https://frontendhappyhour.com/episodes/bartending-to-everyone-inclusive-language/">episode of the Front End Happy Hour podcast</a>&nbsp;about inclusive language. One of the hosts said something so simple, yet so incredibly insightful, that changed my mind in an instant:</p><p><em>“I question people who have asked me, “Why are we doing [inclusive language]? Like, aren’t there bigger issues to solve?”. Yes, there’s always a bigger issue to solve. But this one’s pretty easy. And it’s not that offensive.&nbsp;<strong>All you have to do is stop doing something.</strong>"</em></p><p>I am not easily offended. And so inclusive language as a concept was initially hard to comprehend. But the reality is this: it’s not up to me to tell someone what’s offensive and what’s not. All I can tell someone is what is offensive&nbsp;<em>to me.</em>&nbsp;Inclusive language is not language policing. It’s not telling someone what they can and can’t say. It’s not a violation of free speech. Inclusive language is about&nbsp;<strong><em>empathy</em>.</strong></p><h2 id="inclusive-language-in-the-remote-workplace">Inclusive language in the remote workplace</h2><p>What is often overlooked about Jordan Peterson’s views on the subject is that he is totally on board with using inclusive language in a private context. He just doesn’t want it to be legally enforced. This is an important distinction.</p><p>If you are talking to someone, and they are uncomfortable by the words you’re using, the resultant conversation is unsatisfactory. They walk away from the encounter at best annoyed, and at worst upset. If all it took to improve your relationship with this person was more inclusive language, wouldn’t it make sense to do that?</p><p>Whether you agree or not, you cannot escape the fact that <strong>inclusion is incredibly important in the workplace</strong>. Making your team feel included at work is better for everyone and everything, including your bottom line.</p><p>Inclusion becomes even harder to cultivate in a remote environment. When you’re working from home, you communicate with your team members primarily via text chat. Slack, email and Jira tickets. Text communication is notoriously hard, something that we all now appreciate in 2020. Your words can be interpreted in wildly different ways, to the point where a productive professional relationship can collapse in a matter of seconds.</p><p>Non-inclusive language generally seems to cause a more subtle, more gradual decay of workplace relationships. If I’m the only man in a team of women, and someone in our Slack channel addresses the group with ‘hey, ladies’, I’ll probably think, “Hmm, that’s odd. Doesn’t she realize I’m in this team?”. I’ll then go about my day as normal. But if this happens every day, maybe I would start to feel like I’m invisible. Like I’m not even a part of the team. Like My work is not impressive enough to be noticed. And so on.</p><p>And the worst part is, without the person reaching out to you directly, it’s impossible to know that you’ve upset someone until it’s too late. The value of their contributions declines. They stop proposing ideas in meetings. And then, they quit their job altogether.</p><p>Additionally, Slack channels are different from physical meeting rooms. You often don’t know who is actually in a given Slack channel. You might think the channel is only comprised of males and so saying ‘hey guys’ isn’t an issue. But what if you’re mistaken? Yet another challenge for inclusion in the remote workplace.</p><p><strong>The bottom line is this: inclusive language matters</strong>. When everyone on the team truly feels a part of the team, everybody wins. Conversations improve, productivity increases, and most importantly, people enjoy coming to work. And as more and more of our office communication moves to chat platforms like Slack, the importance of inclusive language has never been greater.</p><h2 id="wrapping-up">Wrapping up</h2><p>And so, I’ve stopped saying ‘hey guys’ for these reasons. And a bunch of other words and phrases. Blacklist, whitelist, psycho, crazy, disabled, the list goes on. If there’s a chance someone will feel excluded by the words I’m about to type, then I’ll choose different words.</p><p>The question then becomes, “Well, how do I know what’s inclusive or not?”. You might argue that there are so many ways someone could be offended, that it’s not a practical problem to solve. I built a <a href="https://allybot.io/">Slack app</a> to help. AllyBot will suggest inclusive alternatives to over 400 non-inclusive phrases to team members. The suggestions are private to you, giving you the opportunity to edit your message at your discretion. AllyBot is <a href="https://allybot.io/#community">free for public Slack communities and educators</a> (reach out to me at&nbsp;<a href="mailto:tom@allybot.io">tom@allybot.io</a>).</p><p>If you’re still not convinced about inclusive language, that’s okay. Thanks for reading my ramblings regardless. But next time you’re chatting on Slack, I’d ask you to stop and think, “Is someone being excluded by my choice of language?”.</p></article><section id="articleNext"></section></section></div></div>]]>
            </description>
            <link>https://blog.allybot.io/post/why-i-stopped-saying-hey-guys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825887</guid>
            <pubDate>Mon, 19 Oct 2020 12:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple blocks widow from honouring husband's dying wish]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24825279">thread link</a>) | @pseudolus
<br/>
October 19, 2020 | https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A widow is locked in a four-year battle with Apple over online material she already legally owns — unless she jumps through complicated and expensive hoops. Experts say tech companies refusing to hand over online assets is a big problem that will only get bigger.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5762042.1602802843!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/carol-anne-and-don-noble.jpg"></p></div><figcaption>Carol Anne Noble, here with her husband, Don, who died in 2016, wants Apple to give her access to his online files.<!-- --> <!-- -->(Submitted by Carol Anne Noble)</figcaption></figure><p><span><p>An Ontario widow is locked in a four-year battle with Apple over online material she already legally owns.</p>  <p>Carol Anne Noble of Toronto&nbsp;wants access to an Apple account she and her husband shared — but was under his name — so she can fulfil a promise she made to him before he died.</p>  <p>But&nbsp;instead of giving her the password she's forgotten, the tech giant is demanding she jump through complicated and expensive legal hoops&nbsp;to satisfy what experts say is an outdated American law.</p>  <p>"It's a real slap in the face to me," said&nbsp;Noble&nbsp;who, after 41 years of marriage, was the executor and sole beneficiary of her husband's estate. Don Noble died from a rare spinal cancer in late 2016.&nbsp;</p>  <p>"Basically, they&nbsp;want an order from the court to give me what my husband owned and it is already bequeathed to me... it's very strange," Noble, 66,&nbsp;told&nbsp;Go Public.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>His last words to me that night were 'You will have to write the book.'<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Carol Anne Noble</cite></span></blockquote>    <p>Experts say that tech companies refusing to hand over digital assets is a problem affecting everything from stocks, insurance policies and&nbsp;PayPal to gaming credits, social media posts and family photos.</p>  <p>It's a "big" problem that will "only get bigger," leaving Canadians at the mercy of the U.S.-based companies and their rules, said Peter Lown, an online assets expert and director emeritus of the Alberta Law Reform Institute&nbsp;at the University of Alberta in Edmonton.</p>  <ul>   <li><strong>Are you facing an uphill battle with a company? Contact our <a href="mailto:gopublic@cbc.ca">Go Public team</a></strong></li>  </ul>  <p>Noble's husband spent the last six months of his life confined to a bed as he battled a slow-moving&nbsp;form of cancer called chordoma. He'd spend hours chronicling the progression of the disease using Apple devices.</p>  <p>He was hoping to put it all together in a book for his family, but Noble says it eventually became clear he wouldn't live long enough.</p>  <p>"A few days before Don died I had to take him to the hospital … His last words to me that night were 'You will have to write the book.' He went into a coma shortly after," she said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/don-noble.jpg 300w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/don-noble.jpg 460w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/don-noble.jpg 620w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/don-noble.jpg 780w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/don-noble.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/don-noble.jpg"></p></div><figcaption>Don Noble, here with his grandson, died in November 2016.<!-- --> <!-- -->(Submitted by Carol Anne Noble)</figcaption></figure></span></p>  <h2>Proof 'not good enough'</h2>  <p>When Noble&nbsp;contacted Apple in early 2017, she was told all she needed to do was prove she has the legal right to her husband's estate. She sent all the documents the company asked for, including his death certificate and the will designating her as executor.</p>  <p>"They called me back and said, no, that's not good enough — you have to have a court order [but] having to pay to put in a court order is a huge deal," she said.&nbsp;</p>  <p>Court orders can cost from about $2,000 to tens of thousands of dollars —&nbsp;depending on whether they're opposed.&nbsp;</p>  <p>After going back and forth with Apple for years, Noble, out of desperation, hired a lawyer earlier this year to help navigate the company's&nbsp;demands.</p>  <p>"It's a tricky situation," said Dheeraj Sindhwani, Noble's lawyer, who practises family law in Ontario.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/carol-anne-noble.jpg 300w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/carol-anne-noble.jpg 460w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/carol-anne-noble.jpg 620w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/carol-anne-noble.jpg 780w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/carol-anne-noble.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/carol-anne-noble.jpg"></p></div><figcaption>Without the password for her late husband's account, Noble can't access his journal entries. He was planning to write a book about his illness for his family.<!-- --> <!-- -->(Christopher Mulligan/CBC)</figcaption></figure></span></p>  <p>"Digital assets are one of those things where it's being governed by a privately held corporation...&nbsp;it's not like a bank account where we can&nbsp;go in and say, here's a death certificate, here's a probate document and get access."&nbsp;</p>  <p>Lown says he has seen similar<em>&nbsp;</em>cases involving Google, Facebook and others, and that tech companies often "brush off"&nbsp;Canadian users "as a nuisance."&nbsp;</p>  <p>"So people are getting hooped by the hoops. Even if they get through some, there will be more," he&nbsp;said.</p>  <p>Apple refused Go Public's request for an interview and didn't respond to our specific questions about Noble's situation and its policies on digital assets.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dheeraj-sindhwani.jpg 300w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dheeraj-sindhwani.jpg 460w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dheeraj-sindhwani.jpg 620w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dheeraj-sindhwani.jpg 780w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dheeraj-sindhwani.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dheeraj-sindhwani.jpg"></p></div><figcaption>Dheeraj Sindhwani, Noble’s lawyer, is helping her navigate Apple’s demands and offered his services pro bono.<!-- --> <!-- -->(Dheeraj Sindhwani/Zoom)</figcaption></figure></span></p>  <h2>Europeans exempt</h2>  <p>The company told Noble providing&nbsp;the password would<em><strong> </strong></em>contravene a U.S. law —&nbsp;<a href="https://it.ojp.gov/PrivacyLiberty/authorities/statutes/1285">the Electronic Communications Privacy Act</a> — written back in 1986.</p>  <p>The law, meant to protect Americans&nbsp;from unnecessary government and police&nbsp;surveillance, bars companies from giving out personal electronic information.</p>  <p>But the decades-old law isn't meant for today's heavily online world of social media and&nbsp;other digital assets, Lown&nbsp;says.</p>  <p>"We didn't&nbsp;have our electronic world in 1986," he&nbsp;said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/peter-lown.jpg 300w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/peter-lown.jpg 460w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/peter-lown.jpg 620w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/peter-lown.jpg 780w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/peter-lown.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/peter-lown.jpg"></p></div><figcaption>Expert Peter Lown says Canadians are often left at the mercy of U.S. laws over ownership of digital assets.<!-- --> <!-- -->(Submitted by Peter Lown)</figcaption></figure></span></p>  <p>"[Yet] the service providers use it to their hearts' content … so they can say, sorry, I can't disclose this to you because that would be a breach of my obligations under the act."</p>  <p>Citizens of countries that have laws specifically addressing digital assets — including those in the European Union — don't have the same problems. For those people, the <a href="http://www.apple.com/legal/internet-services/itunes/us/terms.html">terms and conditions</a> of Apple services grant jurisdiction to "the laws and courts of your usual place of residence."&nbsp;</p>  <p>For everyone else, California law applies unless users&nbsp;can convince a judge otherwise.</p>  <p>Some Canadians have done that. After Maureen Henry's 23-year-old son's body was found at a marina in Toronto in 2014&nbsp;— his&nbsp;cause of death deemed "undetermined" by the coroner&nbsp;—&nbsp;<a href="https://www.cbc.ca/radio/outintheopen/diy-justice-1.5351892/ottawa-mother-s-quest-for-her-late-son-s-passwords-an-uncharted-legal-road-say-experts-1.5366292">she wanted access</a> to his digital accounts to see if they would give her any answers.</p>  <p>She got&nbsp;court&nbsp;orders, first from&nbsp;Ontario and later from a&nbsp;California court. Apple and Bell complied with the Ontario order. Google Canada fought&nbsp;it but gave her the data after Henry got the U.S. order. She's still fighting Facebook in court.</p>  <p>More often though, Canadians are subject&nbsp;to U.S. laws,&nbsp;Lown says, even though proposed legislation that would protect people like Henry and Noble is already written and ready to be adopted.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dovi-henry.jpg 300w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dovi-henry.jpg 460w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dovi-henry.jpg 620w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dovi-henry.jpg 780w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dovi-henry.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dovi-henry.jpg"></p></div><figcaption>Dovi Henry's body was found along Toronto's Harbourfront on July 27, 2014. His mother Maureen Henry is still fighting for access to his digital accounts.<!-- --> <!-- -->(Submitted by Maureen Henry)</figcaption></figure></span></p>  <p>A proposed change to provincial inheritance laws,&nbsp;the <a href="https://www.ulcc.ca/images/stories/2016_pdf_en/2016ulcc0006.pdf">Uniform Access to Digital Assets by Fiduciaries Act</a>, was&nbsp;put forward in 2016 by an <a href="http://www.ulcc.ca/en/">independent group</a> of lawyers, judges and academics, of which Lown is a member.&nbsp;</p>  <p>It would solve these sorts of problems for Canadians but, so far, only Saskatchewan has made it law.&nbsp;</p>  <p>"Ultimately we need this nationwide,"&nbsp;said estate lawyer Daniel Nelson.&nbsp;</p>  <p>"This will force these giant tech companies to deal with the problem, because as it stands right now, good luck trying to get a hold of anyone in one of these companies who are almost always based in California."&nbsp;</p>  <p>Only when Canada has that kind of "leverage," said Lown, will tech companies accommodate the needs of Canadians.</p>  <p>Noble says Apple has a responsibility to be transparent and upfront about its policies when users sign up for the service, instead of putting that information in the fine print.</p>  <p>She also wants to see <u>p</u>rovincial and territorial governments do a better job of addressing the issue.</p>  <p>"This is an area that needs to be addressed immediately … it's very important that people are able to access their loved ones' final photos and all kinds of things," she said.</p>  <p>After Go Public contacted Apple, it reached out to Noble with details on what the court order needs to include. &nbsp;</p>  <p>On a fixed income, she didn't think she could afford to do it and was ready to give up, until Sindhwani, her lawyer, offered to complete the application pro bono.</p>  <p><em><strong>WATCH |&nbsp;Carol Anne Noble is one of several Canadians who have tried to gain access to their late loved ones' digital accounts but been&nbsp;stymied by&nbsp;tech companies' enforcement&nbsp;of&nbsp;U.S. privacy laws:&nbsp;</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Widow fights to get late husband's Apple password"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/691/1023/GO-PUBLIC-APPLE_frame_696.jpg" alt=""></p></div></div></div><span>Carol Anne Noble of Toronto wants access to an Apple account she and her late husband shared — but was under his name — so she can fulfil a promise she made to him before he died.<!-- --> <!-- -->2:32</span></span></span></p>  <hr>  <p><strong>Submit your story ideas</strong></p>  <p>Go Public is an investigative news segment on CBC-TV, radio and the web.</p>  <p>We tell your stories, shed light on wrongdoing, and hold the powers that be accountable.</p>  <p>If you have a story in the public interest, or if you're an insider with information, contact&nbsp;<a href="mailto:gopublic@cbc.ca">gopublic@cbc.ca</a>&nbsp;with your name, contact information and a brief summary. All emails are confidential until you decide to Go Public.</p>  <p>Follow&nbsp;<a href="https://twitter.com/cbcgopublic" target="_blank">@CBCGoPublic</a>&nbsp;on Twitter.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825279</guid>
            <pubDate>Mon, 19 Oct 2020 11:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Euler's Formula: A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24825065">thread link</a>) | @ColinWright
<br/>
October 19, 2020 | https://mathvault.ca/euler-formula/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/euler-formula/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-css="tve-u-16ec5d248bb"><p>In the world of complex numbers, as we integrate trigonometric expressions, we will likely encounter the so-called <strong>Euler’s formula</strong>.</p><p>Named after the legendary mathematician <a href="https://en.wikipedia.org/wiki/Leonhard_Euler" target="_blank" rel="noopener noreferrer">Leonhard Euler</a>, this powerful equation deserves a closer examination — in order for us to use it to its full potential.</p><p>We will take a look at how Euler’s formula allows us to express complex numbers as <strong>exponentials</strong>, and explore the different ways it can be established with relative ease.</p><p>In addition, we will also consider its several <strong>applications</strong> such as the particular case of Euler’s identity, the exponential form of complex numbers, alternate definitions of key functions, and alternate proofs of <a href="https://en.wikipedia.org/wiki/De_Moivre%27s_formula" target="_blank" rel="noopener noreferrer">de Moivre’s theorem</a> and <a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Angle_sum_and_difference_identities" target="_blank" rel="noopener noreferrer">trigonometric additive identities</a>.</p><div><p>Note</p><p>This Euler’s formula is to be distinguished from other Euler’s formulas, such as the one for <a href="https://en.wikipedia.org/wiki/Euler_characteristic#Polyhedra" target="_blank" rel="noopener noreferrer"><strong>convex polyhedra</strong></a>.</p></div><p><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/Euler-formula-diagram.png" alt="Diagram illustrating Euler's formula for complex numbers" width="900" height="572" title="Euler formula diagram"></p><h2><span id="Euler%E2%80%99s_Formula_Explained_Introduction,_Interpretation_and_Examples"></span>Euler’s Formula Explained: Introduction, Interpretation and Examples<span></span></h2><p>So what exactly is <strong>Euler’s formula</strong>? In a nutshell, it is the theorem that states that</p><blockquote><p>$e^{ix} = \cos x + i \sin x$</p></blockquote><p>where:</p><ul><li>$x$ is a <strong>real number</strong>.</li><li>$e$ is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Key_Mathematical_Numbers" target="_blank" rel="noopener noreferrer"><strong>base of the natural logarithm</strong></a>.</li><li>$i$ is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Key_Mathematical_Numbers" target="_blank" rel="noopener noreferrer"><strong>imaginary unit</strong></a> (i.e., square root of $-1$).</li></ul><div><p>Note</p><p>In this formula, the right-hand side is sometimes abbreviated as $\operatorname{cis}{x}$, though the left-hand expression $e^{ix}$ is usually preferred over the $\operatorname{cis}$ notation.</p></div><p>Euler’s formula establishes the fundamental relationship between <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" rel="noopener noreferrer"><strong>trigonometric functions</strong></a> and <strong>exponential functions</strong>. Geometrically, it can be thought of as a way of bridging two representations of the same unit complex number in the complex plane.</p><p>Let’s take a look at some of the <strong>key values</strong> of Euler’s formula, and see how they correspond to points in the trigonometric/unit circle:</p><ul><li>For $x=0$, we have $e^{0} = \cos 0+ i \sin 0$, which gives $1 = 1$. So far so good: we know that an angle of $0$ on the trigonometric circle is $1$ on the real axis, and this is what we get here.</li><li>For $x=1$, we have $e^{i}=\cos 1 + i \sin 1$. This result suggests that $e^i$ is precisely the point on the unit circle whose angle is <strong>1 radian</strong>.</li><li>For $x = \frac{\pi}{2}$, we have $e^{i\frac{\pi}{2}} = \cos \frac{\pi}{2} + i \sin \frac{\pi}{2} = i$. This result is useful in some calculations related to physics.</li><li>For $x = \pi$, we have $e^{i\pi} = \cos \pi + i \sin \pi $, which means that $e^{i\pi} = -1$. This result is equivalent to the famous <a href="#Euler%E2%80%99s_Identity"><strong>Euler’s identity</strong></a>.</li><li>For $x = 2\pi$, we have $e^{i (2\pi)} = \cos 2\pi + i \sin 2\pi$, which means that $e^{i (2\pi)} = 1$, same as with $x = 0$.</li></ul><p>A key to understanding Euler’s formula lies in rewriting the formula as follows: \[ (e^i)^x = \sin x + i \cos x \] where:</p><ul><li>The right-hand expression can be thought of as the <strong>unit complex number</strong> with angle $x$.</li><li>The left-hand expression can be thought of as the <strong>1-radian unit complex number</strong> raised to $x$.</li></ul><p>And since raising a unit complex number to a power can be thought of as <strong>repeated multiplications</strong> (i.e., adding up angles in this case), Euler’s formula can be construed as two different ways of running around the unit circle to arrive at the same point.</p><h2><span id="Derivations"></span>Derivations<span></span></h2><p>Euler’s formula can be established in at least three ways. The first derivation is based on <strong>power series</strong>, where the exponential, sine and cosine functions are expanded as power series to conclude that the formula indeed holds.</p><p>The second derivation of Euler’s formula is based on <strong>calculus</strong>, in which both sides of the equation are treated as functions and differentiated accordingly. This then leads to the identification of a common property — one which can be exploited to show that both functions are indeed equal.</p><p>Yet another derivation of Euler’s formula involves the use of <a href="https://en.wikipedia.org/wiki/Polar_coordinate_system#Complex_numbers" target="_blank" rel="noopener noreferrer"><strong>polar coordinates</strong></a> in the complex plane, through which the values of $r$ and $\theta$ are subsequently found. In fact, you might be able to guess what these values are — just by looking at the formula itself!</p><h3><span id="Derivation_1_Power_Series"></span>Derivation 1: Power Series<span></span></h3><p>One of the most intuitive derivations of Euler’s formula involves the use of <strong>power series</strong>. It consists in expanding the power series of exponential, sine and cosine — to finally conclude that the equality holds.</p><p>As a caveat, this approach assumes that the power series expansions of $\sin z$, $\cos z$, and $e^z$ are <a href="https://en.wikipedia.org/wiki/Absolute_convergence" target="_blank" rel="noopener noreferrer"><strong>absolutely convergent</strong></a> everywhere (e.g.,&nbsp; that they hold for all complex numbers $z$). However, it also has the advantage of showing that Euler’s formula holds for all complex numbers $z$ as well.</p><p>For a complex variable $z$, the <strong>power series expansion</strong> of $e^z$ is \[ e^z = 1 + \frac{z}{1!} + \frac{z^2}{2!} + \frac{z^3}{3!} + \frac{z^4}{4!} + \cdots \] Now, let us take $z$ to be $ix$ (where $x$ is an <a href="https://mathvault.ca/math-glossary/#arbitrary" target="_blank" rel="noopener noreferrer">arbitrary</a> complex number). As $z$ gets raised to increasing powers, $i$ also gets raised to increasing powers. The <strong>first eight powers</strong> of $i$ look like this: \begin{align*} i^0 &amp; = 1 &amp; i^4 &amp; = i^2 \cdot i^2 = 1 \\ i^1 &amp; = i &amp; i^5 &amp; = i \cdot i^4 = i \\ i^2 &amp; = -1 \quad \text{(by the definition of $i$)} &amp; i^6 &amp; = i \cdot i^5 = -1 \\ i^3 &amp; = i \cdot i^2 = -i &amp; i^7 &amp; = i \cdot i^6 = -i \end{align*} (notice the <strong>cyclicality</strong> of the powers of $i$: $1$, $i$, $-1$, $-i$. We’ll be using these powers shortly.)</p><p>With $z = ix$, the expansion of $e^z$ becomes: \[ e^{ix} = 1 + ix + \frac{(ix)^2}{2!} + \frac{(ix)^3}{3!} + \frac{(ix)^4}{4!} + \cdots \] Extracting the powers of $i$, we get: \[ e^{ix} = 1 + ix-\frac{x^2}{2!}-\frac{i x^3}{3!} + \frac{x^4}{4!} + \frac{i x^5}{5!}-\frac{x^6}{6!}-\frac{i x^7}{7!} + \frac{x^8}{8!} + \cdots \] And since the power series expansion of $e^z$ is absolutely convergent, we can rearrange its terms without altering its value. Grouping the <strong>real</strong> and <strong>imaginary terms</strong> together then yields: \[ e^{ix} = \left( 1-\frac{x^2}{2!} + \frac{x^4}{4!}-\frac{x^6}{6!} + \frac{x^8}{8!}-\cdots \right) + i \left( x-\frac{x^3}{3!} + \frac{x^5}{5!}-\frac{x^7}{7!} + \cdots \right) \] Now, let’s take a detour and look at the power series of <strong>sine</strong>&nbsp;and&nbsp;<strong>cosine</strong>. The power series of $\cos{x}$ is \[ \cos x = 1-\frac{x^2}{2!} + \frac{x^4}{4!}-\frac{x^6}{6!} + \frac{x^8}{8!}-\cdots \] And for $\sin{x}$, it is \[ \sin x = x-\frac{x^3}{3!} + \frac{x^5}{5!}-\frac{x^7}{7!} + \cdots \] In other words, the last equation we had is precisely \[ e^{ix} = \cos x + i \sin x \] which is the statement of Euler’s formula that we were looking for.</p><h3><span id="Derivation_2_Calculus"></span>Derivation 2: Calculus<span></span></h3><p>Another neat way to establish Euler’s formula is to consider both $e^{ix}$ and $\cos x + i \sin x$ as <strong>functions</strong> of $x$, before differentiating them to find some common property about them.</p><p>For that to happen though, one must assume that the functions $e^z$, $\cos x$ and $\sin x$ are defined and <strong>differentiable</strong> for all real numbers $x$ and complex numbers $z$. By assuming that these functions are differentiable for all complex numbers, it is also possible to show that Euler’s formula holds for all complex numbers as well.</p><p>First, let $f_1(x)$ and $f_2(x)$ be $e^{ix}$ and $\cos x + i \sin x$, respectively. <strong>Differentiating</strong> $f_1$ via <a href="https://mathvault.ca/chain-rule-derivative/#Chain_Rule_%E2%80%94_A_Review" target="_blank" rel="noopener noreferrer">chain rule</a> then yields: \[ f_{1}'(x) = i e^{ix} = i f_1(x) \] Similarly, differentiating $f_2$ also yields: \[ f_{2}'(x) = -\sin x + i \cos x = i f_2(x) \] In other words, both functions satisfy the differential equation $f'(x) = i f(x)$. Now, consider the function $\frac{f_1}{f_2}$, which is <a href="https://mathvault.ca/math-glossary/#welldefined" target="_blank" rel="noopener noreferrer">well-defined</a> for all $x$ (since $f_2(x) = \cos x + i\sin x$ corresponds to points on the unit circle, which are never zero). With that settled, using the <strong>quotient rule</strong> on this function then yields: \begin{align*} \left(\frac{f_{1}}{f_2}\right)'(x) &amp; = \frac{f_1’(x) f_2(x)-f_1(x) f_2’(x)}{[f_2(x)]^2} \\ &amp; = \frac{i f_1(x) f_2(x)-f_1(x) i f_2(x)}{[f_2(x)]^2} \\ &amp; = 0 \end{align*} And since the derivative here is $0$, this implies that the function $\frac{f_1}{f_2}$ must have been a <strong>constant</strong> to begin with. What is the value of this constant? Let’s figure it out by plugging in $x=0$ into the function: \[ \left(\frac{f_1}{f_2}\right)(0) = \frac{e^{i0}}{\cos 0 + i \sin 0} = 1&nbsp; \] In other words, we must have that for all $x$: \[ \left(\frac{f_1}{f_2}\right)(x) = \frac{e^{ix}}{\cos x + i \sin x} = 1&nbsp; \] which, after moving $\cos x + i \sin x$ to the right, becomes the famous formula we’ve been looking for.</p><h3><span id="Derivation_3_Polar_Coordinates"></span>Derivation 3: Polar Coordinates<span></span></h3><p>Yet another ingenious proof of Euler’s formula involves treating exponentials as numbers, or more specifically, as complex numbers under <strong>polar coordinates</strong>.</p><p>Indeed, we already know that all non-zero complex numbers can be expressed in <strong>polar coordinates</strong> in a unique way. In particular, any number of the form $e^{ix}$ (with real $x$), which is non-zero, can be expressed as: \[ e^{ix} = r(\cos \theta + i \sin \theta) \] where $\theta$ is its <strong>principal angle</strong> from the positive real axis (with, say, $0 \le \theta &lt; 2 \pi$), and $r$ is its <strong>radius</strong> (with $r&gt;0$). We make no assumption about the values of $r$ and $\theta$, except the fact that they are functions of $x$ (which may or may not contain $x$ as variable). They will be determined in the course of the proof.</p><p>(However, what we do know is that when $x=0$, the left-hand side is $1$, which implies that $r$ and $\theta$ satisfy the <strong>initial conditions</strong> of $r(0)=1$ and $\theta(0)=0$, respectively.)</p><p>For what it’s worth, we’ll begin by <strong>differentiating</strong> both sides of the equation. By the definition of exponential, differentiating the left side of the equation with respect to $x$ yields $i e^{ix}$. After differentiating the right side of the equation, the equation then becomes: \[ i e^{ix} = \frac{dr}{dx}(\cos \theta + i \sin \theta) + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] We’re looking for an expression that is uniquely in terms of $r$ and $\theta$. To get rid of $e^{ix}$, we substitute back $r(\cos \theta + i \sin \theta)$ for $e^{ix}$ to get:<span> \[ i r(\cos \theta + i \sin \theta) = (\cos \theta + i \sin \theta) \frac{dr}{dx} + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] Once there, distributing the $i$ on the left-hand side then yields: \[ r(i \cos \theta-\sin \theta) = (\cos \theta + i \sin \theta) \frac{dr}{dx} + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] …</span></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/euler-formula/">https://mathvault.ca/euler-formula/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/euler-formula/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825065</guid>
            <pubDate>Mon, 19 Oct 2020 10:49:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This page is a truly naked, brutalist HTML quine]]>
            </title>
            <description>
<![CDATA[
Score 935 | Comments 177 (<a href="https://news.ycombinator.com/item?id=24824977">thread link</a>) | @Symmetry
<br/>
October 19, 2020 | https://secretgeek.github.io/html_wysiwyg/html.html | <a href="https://web.archive.org/web/*/https://secretgeek.github.io/html_wysiwyg/html.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>One of my favorite things is to misuse technology in creative ways. Breaking the rules without breaking the rules.</p>

<p>For example, a hobby project I built long ago was <a href="https://github.com/secretGeek/dod">DOS-on-dope</a>, a working Ruby-on-rails parody, billed as <em>the last batch-file based MVC framework you'll ever need</em>. And there was <a href="http://www.secretgeek.net/console_log">a console.log() adventure</a> in which you played an old school console-adventure-game from inside the chrome developer tools.</p>

<p>The world of esoteric programming is filled with examples of people stretching the rules to breaking point, and misusing technology in creative ways. In particular (for example) I love <a href="http://wiki.secretgeek.net/quine">quines</a>. Quines are programs which output their own source code. Life is a Quine.</p>

<p>A different but somehow related topic I like is <a href="https://en.wikipedia.org/wiki/Brutalist_architecture">brutalism</a>, in particular, this often overlooked aspect:</p>

<blockquote>Another common theme in Brutalist designs is the exposure of the building's functions.</blockquote>

<p>...the tendency to <strong>make the internal external</strong>, and reveal the secrets of the building, in a somehow.... <em>brutaful</em> way. ;-).</p>

<p>A similarly intriguing idea which has fallen into disuse is the idea of <a href="https://en.wikipedia.org/wiki/Naked_objects">naked objects</a>, wherein:</p>

<blockquote>The user interface should be a direct representation of the domain objects.</blockquote>

<p>Putting all this together I decided to make a truly naked, brutalist html page, that is itself a quine. And this page is it.</p>

<p>Viewing <a href="https://raw.githubusercontent.com/secretGeek/html_wysiwyg/master/html.html">the source</a> of this page should reveal a page identical to the page you are now seeing. Nothing is hidden. It's a true "What you see is what you get."</p>

<h2>How it works.</h2>

<p>Did you know that the rules of html and css allow you to make <strong>every</strong> element visible, even elements like 'title' or 'style' or 'script', that are normally hidden from view? Those are just elements like any other. You can expose them <strong>all</strong> like so:</p>



<p>With that snippet of code (which is <strong>not</strong> a snippet of code, but an <strong>actual</strong> style block itself!) you can now see every element of this page, including that style block, the html and title tags, etc.</p>

<p>It does have one downside: every element on the page is now a "block" element, even some which should be "inline", such as "code" and "anchor" elements. We can correct this like so:</p>



<p>To give the code a more 'view source' feel, I've also applied <code>monospace</code> fonts, and a generally simple and consistent style to all elements, using a "*" selector, like so:</p>



<p>So far I've put style declarations all on one line, because ordinary html refuses to treat line breaks as "br" tags. But there is a way to make line-breaks display as line-breaks, and that is with this piece of styling:</p>



<h2>Make the internal external.</h2>

<p>The next trick is to make the internal external. We can start by ensuring that the tags themselves, such as paragraph tags, are exposed in their stark, brutal, beauty:</p>



<p>That works for "p" elements, but do we need to have custom styling for <strong>every</strong> element? If there was a way to output the "name" of a tag in html, then we could reduce all of the necessary style rules above to something like:</p>

<blockquote>
*::before {
 '&lt;' name() '&gt;'
}
</blockquote>

<p>And...

</p><blockquote>
*::after {
 '&lt;\/' name() '&gt;'
}
</blockquote>


<p>But alas there is no "name()" function (yet!). So we are forced to generate a chunk of style information like this (via <a href="https://nimbletext.com/Live/1105905186/">NimbleText</a> of course)</p>

<p>Please scroll happily past the next 28 offensively repetitive lines...</p>



<p>Some elements are a little trickier because they have attributes. Consider for example the "anchor" which often has a <code>href</code> attribute. We <em>need</em> that attribute to be visible, including its value. This is done like so:</p>



<p>The <code>attr()</code> function, see <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/attr">mozilla docs</a> is a nifty trick, "supported" since CSS 2.</p>


<p>The only other style that is special is "style" itself, which has to include an escape character to avoid being taken literally.</p>







<p>Finally to reduce the visual weight of the before and after pseudo elements we can give them a soft purple color and a low weight font:</p>





<p>Finally, because I believe brutalist design, even when applied to truly naked brutal html quines, is about function, not about deliberate ugliness, I'd like to apply these humble styles that improve the readability of this brutiful missive.</p>



<p>...they're derived from <a href="https://jrl.ninja/etc/1/">"58 bytes of css to look great nearly everywhere"</a>.</p>

<p>One last thing. Although this idea has bounced around in my head for a decade, the thing that reminded me to pipe it into a file was seeing this piece of "Code as Art" from Geoff Huntley: <a href="https://noyaml.com/">no yaml</a>. Bring back the world weird web.</p>

<p>Kind regards</p>
<p><a href="http://secretgeek.net/">Leon</a></p>

<p>p.s. <a href="https://github.com/secretGeek/html_wysiwyg/">source code here</a></p>



</div>]]>
            </description>
            <link>https://secretgeek.github.io/html_wysiwyg/html.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24824977</guid>
            <pubDate>Mon, 19 Oct 2020 10:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with Lambda Calculus]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24823602">thread link</a>) | @mmphosis
<br/>
October 18, 2020 | https://stopa.io/post/263 | <a href="https://web.archive.org/web/*/https://stopa.io/post/263">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p>In 1935, a gentleman called Alonzo Church came up with a simple scheme that could compute…just about anything. His scheme was called Lambda Calculus. It was a phenomenal innovation, given that there weren’t even computers for him to test out his ideas. Even cooler is that those very ideas affect us today: anytime you use a function, you owe a hat tip to Mr. Church. </p><p>Lambda Calculus is so cool that many hackers use it as their secret handshake — a “discreet signal” if you will. The most famous, of course, is PG’s Y Combinator. In this essay, we’ll find out what it’s all about, and do things with functions that we’d never have imagined. In the end you’ll have built just about every programming concept: numbers, booleans, you name it…just with functions.</p><p>City dwellers who drive SUVs rarely consider their cars as ferocious machines that traverse rocky deserts and flooded rivers. It’s the same with programmers and functions. Here’s what we <em>think</em> functions do:</p><pre><code><span>(</span><span>def</span><span> square (</span><span>fn</span><span> [x] (</span><span>*</span><span> x x)))</span></code></pre><p>Safe, clean, and useful. We’re so accustomed that it would surprise us to find the myriad of ways we can bend functions to do just about anything. </p><p>Let’s step out into the wilderness a bit. Say you wanted to make a data structure for pairs: </p><pre><code><span>(</span><span>def</span><span> pair (</span><span>make-pair</span><span> </span><span>0</span><span> </span><span>1</span><span>))</span>
<span>(</span><span>first</span><span> pair) </span><span>; =&gt; 0</span>
<span>(</span><span>second</span><span> pair) </span><span>; =&gt; 1</span></code></pre><p>How would you do it? It’s sensible to use a map or a class or a record to represent a pair. But…you could use functions too.</p><p>Here’s one way we can make a pair:</p><pre><code><span>(</span><span>def</span><span> church-pair (</span><span>fn</span><span> [a b]</span>
<span>                   (</span><span>fn</span><span> [selector]</span>
<span>                     (</span><span>selector</span><span> a b))))</span></code></pre><p>No maps or classes…it just returns a function! </p><pre><code><span>(</span><span>def</span><span> ex-pair (</span><span>church-pair</span><span> </span><span>0</span><span> </span><span>1</span><span>))</span>
<span>ex-pair</span>
<span>; =&gt; #object[church_factorial$church_pair...</span></code></pre><p>Now  our <code>ex-pair</code> takes a <code>selector</code> argument. What if we ran ex-pair with this selector:</p><pre><code><span>(</span><span>ex-pair</span><span> (</span><span>fn</span><span> [a b] a))</span></code></pre><p>Well, <code>(ex-pair (fn [a b] a))</code> would expand too: </p><pre><code><span>((</span><span>fn</span><span> [a b] a) a b)</span></code></pre><p>Which would return… <code>a</code>! </p><p>That just gave us the <code>first</code> value of our pair! We can use that to write a <code>church-first</code> function:</p><pre><code><span>(</span><span>def</span><span> take-first-arg (</span><span>fn</span><span> [a b] a))</span>
<span>(</span><span>def</span><span> church-first (</span><span>fn</span><span> [pair]</span>
<span>                    (</span><span>pair</span><span> take-first-arg)))</span></code></pre><pre><code><span>(</span><span>church-first</span><span> ex-pair)</span>
<span>; =&gt; 0</span></code></pre><p>And do something similar for second: </p><pre><code><span>(</span><span>def</span><span> take-second-arg (</span><span>fn</span><span> [a b] b))</span>
<span>(</span><span>def</span><span> church-second (</span><span>fn</span><span> [pair]</span>
<span>                     (</span><span>pair</span><span> take-second-arg)))</span></code></pre><pre><code><span>(</span><span>church-second</span><span> ex-pair)</span>
<span>; =&gt; 1</span></code></pre><p>We just used functions to represent pairs. Now, since the grammar for Lisp is just a bunch of pairs plopped together, that also means we can represent the grammar of Lisp…with just functions!</p><p>What we just did was analogous to a city dweller driving their SUV…on a snowy day. It gets a <em>lot</em> crazier. </p><p>We said we could represent <em>everything</em>. Let’s go ahead and try it! </p><p>Here’s what can do. Let’s take a function we know and love, and implement it from top-to-bottom in Lambda Calculus.</p><p>Here’s factorial: </p><pre><code><span>(</span><span>defn</span><span> factorial-clj [n]</span>
<span>  (</span><span>if</span><span> (</span><span>zero?</span><span> n)</span>
<span>    </span><span>1</span><span> </span>
<span>    (</span><span>*</span><span> n (</span><span>factorial-clj</span><span> (</span><span>dec</span><span> n)))))</span></code></pre><pre><code><span>(</span><span>factorial-clj</span><span> </span><span>5</span><span>)</span>
<span>; =&gt; 120</span></code></pre><p>By the end of this essay, we’ll have built factorial, only with functions.</p><p>To do this, I want to come up front and say I am cheating a little bit. In Church’s Lambda Calculus, there is no <code>def</code>, and all functions take one argument. Here’s all he says: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjA4LTc0M2VkMDgwLTExNTgtMTFlYi05YTI2LTFlMGUyOWFmNDQ0MC5wbmc" alt="image"></span></p><p>In his rules, you define anonymous functions by popping a little <code>λ</code> in front. What follows is the argument, following by a  <code>.</code> .After the <code>.</code> is the application.</p><p>This is very much akin to a single-argument anonymous function in Clojure: <code>λ x. x</code> =&gt; <code>(fn [x] x)</code></p><p>We could follow those rules, but writing factorial like that is going to get hard to reason about very quickly. Let’s tweak the rules just a little bit. The changes won’t affect the essence of Lambda Calculus but will make it easier for us to think about our code. Here it goes:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjE3LTc5OWMxYjAwLTExNTgtMTFlYi05N2U5LWY0ZDIxZGE2YmJkOC5wbmc" alt="image"></span></p><p>1<!-- -->)<!-- --> for a single argument function, <code>(fn [x] x)</code> maps pretty well to Church’s encoding. We can go ahead and use it as is.</p><p>2<!-- -->)<!-- --> Since Church’s lambdas only take one argument, For him to express a function with two arguments, he has to write <em>two</em> anonymous functions: </p><pre><code><span>(</span><span>λ</span><span> f. λ x. f x)</span></code></pre><p>This would map to:</p><pre><code><span>(</span><span>fn</span><span> [f] (</span><span>fn</span><span> [x] (</span><span>f</span><span> x))</span></code></pre><p>But, nesting our functions like this can get annoying in Clojure <sup>1</sup>. To make life easier for us, we’ll allow for multi-argument functions:</p><pre><code><span>(</span><span>fn</span><span> [f x] (</span><span>f</span><span> x))</span></code></pre><p>3<!-- -->)<!-- --> Finally, Church has no concepts of variables outside of what’s provided by a function definition. </p><p>For him to express </p><pre><code><span>(</span><span>make-pair</span><span> a b)</span></code></pre><p>He would have to “unwrap” <code>make-pair</code></p><pre><code><span>((</span><span>λ</span><span> a. λ b. λ selector . selector a b)</span>
<span> a b)</span></code></pre><p>To keep our code sane, we’ll allow for <code>def</code>, but with one rule: </p><p><strong>You can use</strong> <strong><code>def</code></strong> <strong>, as long as you can “replace” it with an anonymous function and nothing breaks.</strong> </p><p>For example, imagine if <code>make-pair</code> <em>referenced itself</em>:</p><pre><code><span>(</span><span>def</span><span> make-pair (</span><span>fn</span><span> [a b]</span>
<span>                 (</span><span>make-pair</span><span> ...)))</span></code></pre><p>This would break because if we replaced <code>(def make-pair …)</code> with an anonymous function, there would be no variable called <code>make-pair</code> anymore! </p><p>That’s it, these are our rules. With that, we’re ready to make factorial! </p><p>The first thing we need is the concept of a number. How can we do that? </p><p>Church thought of a pretty cool idea. What if “numbers”, where higher-order functions with two arguments:  a function <code>f</code>, and a value <code>v</code>.</p><pre><code><span>(</span><span>def</span><span> zero (</span><span>fn</span><span> [f v] v))</span>
<!-- -->
<span>(</span><span>def</span><span> one (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>zero</span><span> f v))))</span>
<!-- -->
<span>(</span><span>def</span><span> two (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>one</span><span> f v))))</span></code></pre><p><strong>We can figure out what number each function represents by “counting” the number of times</strong> <strong><code>f</code></strong> <strong>was composed.</strong> </p><p>For example, 0 would compose <code>f</code> zero times: it would just return <code>v</code>.  1, would compose f once: <code>(f v)</code>. 2 would compose twice: <code>(f (f v))</code>, and so on. </p><p>To help us see these numbers in our REPL, let’s create a quick converter function: </p><pre><code><span>(</span><span>defn</span><span> church-numeral-&gt;int [church-numeral]</span>
<span>  (</span><span>church-numeral</span><span> inc </span><span>0</span><span>))</span></code></pre><p>Since a church numeral composes <code>f</code> the number of times it is called with <code>v</code> as the first argument, all we need to see what number it is in Clojure, is to provide <code>inc</code> as <code>f</code> and <code>0</code> as <code>v</code>! Now <code>2</code> would do <code>(inc (inc 0))</code> for example, and get us the corresponding Clojure number.</p><pre><code><span>(</span><span>map</span><span> church-numeral-&gt;int [zero one two])</span>
<span>; =&gt; (0 1 2)</span></code></pre><p>Cool! </p><p>Take a look at how we wrote two: </p><pre><code><span>(</span><span>def</span><span> two (</span><span>fn</span><span> [f v]</span>
<span>           (</span><span>f</span><span> (</span><span>one</span><span> f v))))</span></code></pre><p>What we did here,  is <em>delegate</em> f’s composition to the numeral before (in this case <code>one</code> ), and then just called <code>f</code> <em>one more time.</em> </p><p>What if we abstracted the <code>one</code> out?</p><pre><code><span>(</span><span>def</span><span> church-inc</span>
<span>  (</span><span>fn</span><span> [church-numeral]</span>
<span>    (</span><span>fn</span><span> [f v]</span>
<span>      (</span><span>f</span><span> (</span><span>church-numeral</span><span> f v))))) </span></code></pre><p>Voila. Give this function a numeral, and it will return a new numeral that calls <code>f</code> <em>one more time</em>. We’ve just discovered <code>inc</code>! </p><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>church-inc</span><span> (</span><span>church-inc</span><span> one)))</span>
<span>=&gt; </span><span>3</span></code></pre><p>Cool.</p><p>Now that we have this function, we can also write a quick helper to translate Clojure numbers to these numbers:</p><pre><code><span>(</span><span>def</span><span> int-&gt;church-numeral</span>
<span>  (</span><span>fn</span><span> [clojure-int]</span>
<span>    (</span><span>if</span><span> (</span><span>zero?</span><span> clojure-int)</span>
<span>      zero</span>
<span>      (</span><span>church-inc</span><span> (</span><span>int-&gt;church-numeral</span><span> (</span><span>dec</span><span> clojure-int))))))</span></code></pre><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>))</span>
<span>=&gt; </span><span>5</span></code></pre><p>That’ll come in handy for our REPL.</p><p>Next up, we need a way to “decrement” a number. Well, with <code>inc</code> we create a numeral that composes <code>f</code> <em>one more time</em>. If we can make some kind of function that composes <code>f</code> <em>one less time,</em> then we’d have <code>dec</code>! </p><p>To do that, we’ll need to go on a short diversion.</p><p>Remember our <code>pair</code> data structure? Let’s create a function for it (we’ll use this in just a moment below): <code>shift-and-inc</code>.  All it would do, is take pair of numbers, and “shift” the pair forward by one:</p><p>For example, applying <code>shift-and-inc</code> to <code>(0 1)</code>,  would produce <code>(1 2)</code>. One more time, it would produce <code>(2 3)</code>, and so on. </p><p>Sounds simple enough: </p><pre><code><span>(</span><span>def</span><span> shift-and-inc (</span><span>fn</span><span> [pair]</span>
<span>                     (</span><span>church-pair</span>
<span>                       (</span><span>church-second</span><span> pair)</span>
<span>                       (</span><span>church-inc</span><span> (</span><span>church-second</span><span> pair)))))</span></code></pre><p>Bam, we take a pair. The second item is shifted over to the first positions and is replaced with its <code>inc</code>ed friend. Let’s try it out:</p><pre><code><span>(</span><span>let</span><span> [p (</span><span>shift-and-inc</span><span> (</span><span>church-pair</span><span> one two))]</span>
<span>  (</span><span>map</span><span> church-numeral-&gt;int [(</span><span>church-first</span><span> p) (</span><span>church-second</span><span> p)]))</span>
<span>; =&gt; (2 3)</span></code></pre><p>Works like a charm!</p><p>Now that we have <code>shift-and-inc</code>, what if we did this: </p><pre><code><span>(</span><span>def</span><span> church-dec</span>
<span>  (</span><span>fn</span><span> [church-numeral]</span>
<span>    (</span><span>church-first</span>
<span>      (</span><span>church-numeral</span><span> shift-and-inc</span>
<span>                      (</span><span>church-pair</span><span> zero zero)))))</span></code></pre><p>Remember that our <code>church-numeral</code> would call <code>shift-and-inc</code> N times, representing its numeral value. If we started with a pair <code>(0, 0)</code>, then what would the result b, if we composed <code>shift-and-inc</code> <code>N</code> times?</p><p>Our result would be the pair <code>(N-1, N)</code>. This means that if we take the first part of our pair, we have <code>dec</code>! </p><pre><code><span>(</span><span>church-numeral-&gt;int</span><span> (</span><span>church-dec</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>10</span><span>)))</span>
<span>; =&gt; 9</span></code></pre><p>Nice.</p><p>Next up, multiplication. Say we multiply <code>a</code> by <code>b</code>. We’d need to produce a church numeral that composes <code>f</code>, <code>a * b</code> times. To do that, we can leverage the following idea:</p><p>Say we made a function <code>g</code>, which composes <code>f</code> <em>b</em> times. If we fed that function to <code>a</code>, it would call <code>g</code>, <em>a</em> times.  </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk2Mzc4MjI2LTdmOTFmYzAwLTExNTgtMTFlYi05MmY2LTVlZDdhNzA0YWE1MC5wbmc" alt="image"></span></p><p>If <code>a</code> was “2” and “b” was 3, how many times would <code>f</code> get composed? Well, <code>g</code> would be composed twice. Each time <code>g</code> is composed, <code>f</code> is composed 3 times. That comes out to a total of 6 times!</p><p>Bam, if we did that, it would represent multiplication.</p><pre><code><span>(</span><span>def</span><span> church-*</span>
<span>  (</span><span>fn</span><span> [num-a num-b]</span>
<span>    (</span><span>fn</span><span> [f v]</span>
<span>      (</span><span>num-a</span><span> (</span><span>partial</span><span> num-b f) v))))</span></code></pre><p>Here, <code>(partial num-b f)</code> represents our <code>g</code> function. </p><pre><code><span>(</span><span>church-numeral-&gt;int</span>
<span>    (</span><span>church-*</span><span> (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>) (</span><span>int-&gt;church-numeral</span><span> </span><span>5</span><span>)))</span>
<span>=&gt; </span><span>25</span></code></pre><p>Works like a charm! </p><p>We’ve got numbers, we’ve got <code>*</code> and we’ve got <code>dec</code>. Next up…booleans! </p><p>To do this, we need to be creative about what <code>true</code> and <code>false</code> is. </p><p>Let’s say this. Booleans are two argument functions: </p><pre><code><span>(</span><span>def</span><span> church-true (</span><span>fn</span><span> [</span><span>when-true</span><span> </span><span>when-false</span><span>]</span>
<span>                   </span><span>when-true</span><span>))</span>
<!-- -->
<span>(</span><span>def</span><span> church-false (</span><span>fn</span><span> [</span><span>when-true</span><span> </span><span>when-false</span><span>]</span>
<span>                    </span><span>when-false</span><span>))</span></code></pre><p>They take a “true” case and a “false” case. Our <code>church-true</code> function would return the true case, and <code>church-false</code> function would return the false case. </p><p>That’s it. Surprisingly this is enough to handle booleans. Here’s how we could convert them to Clojure bools.</p><pre><code><span>(</span><span>defn</span><span> church-bool-&gt;bool [church-bool]</span>
<span>  (</span><span>church-bool</span><span> </span><span>true</span><span> </span><span>false</span><span>))</span></code></pre><p>Our <code>church-true</code> would return the first argument (true), and our <code>church-false</code> would return the second one! </p><pre><code><span>(</span><span>church-bool-&gt;bool</span><span> church-true)</span>
<span>; =&gt; true</span>
<span>(</span><span>church-bool-&gt;bool</span><span> church-false)</span>
<span>; =&gt; false</span></code></pre><p>Do they look familiar? …</p></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/263">https://stopa.io/post/263</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/263</link>
            <guid isPermaLink="false">hacker-news-small-sites-24823602</guid>
            <pubDate>Mon, 19 Oct 2020 05:41:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord Desktop App RCE]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24822755">thread link</a>) | @Wingy
<br/>
October 18, 2020 | https://mksben.l0.cm/2020/10/discord-desktop-rce.html | <a href="https://web.archive.org/web/*/https://mksben.l0.cm/2020/10/discord-desktop-rce.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6054437144226106686" itemprop="description articleBody">
<p>A few months ago, I discovered a remote code execution issue in the <a href="https://discord.com/">Discord</a> desktop application and I reported it via their <a href="https://discord.com/security">Bug Bounty Program</a>.</p><p>The RCE I found was an interesting one because it is achieved by combining multiple bugs. In this article, I'd like to share the details.</p><h3>Why I chose Discord for the target</h3><p>I kind of felt like finding for vulnerabilities of the Electron app, so I was looking for a bug bounty program which pays the bounty for an Electron app and I found Discord. Also, I am a Discord user and simply wanted to check if the app I'm using is secure, so I decided to investigate.</p><h3>Bugs I found</h3><p>Basically I found the following three bugs and achieved RCE&nbsp;by combining them.</p><ol><li>Missing contextIsolation</li><li>XSS in iframe embeds</li><li>Navigation restriction bypass (CVE-2020-15174)</li></ol><p>I'll explain these bugs one by one.</p><h3>Missing contextIsolation</h3><p>When I test Electron app, first I always check the options of the <a href="https://www.electronjs.org/docs/api/browser-window">BrowserWindow API</a>, which is used to create a browser window. By checking it, I think about how RCE can be achieved when arbitrary JavaScript execution on the renderer is possible.</p><p>The Discord's Electron app is not an open source project but the Electron's JavaScript code is saved locally with the asar format and I was able to read it just by extracting it.</p><p>In the main window, the following options are used:&nbsp;</p><blockquote>const mainWindowOptions = {<br>&nbsp;&nbsp;title: 'Discord',<br>&nbsp;&nbsp;backgroundColor: getBackgroundColor(),<br>&nbsp;&nbsp;width: DEFAULT_WIDTH,<br>&nbsp;&nbsp;height: DEFAULT_HEIGHT,<br>&nbsp;&nbsp;minWidth: MIN_WIDTH,<br>&nbsp;&nbsp;minHeight: MIN_HEIGHT,<br>&nbsp;&nbsp;transparent: false,<br>&nbsp;&nbsp;frame: false,<br>&nbsp;&nbsp;resizable: true,<br>&nbsp;&nbsp;show: isVisible,<br>&nbsp;&nbsp;webPreferences: {<br>&nbsp;&nbsp;&nbsp;&nbsp;blinkFeatures: 'EnumerateDevices,AudioOutputDevices',<br>&nbsp;&nbsp;&nbsp;&nbsp;<span><b>nodeIntegration: false</b></span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;preload: _path2.default.join(__dirname, 'mainScreenPreload.js'),<br>&nbsp;&nbsp;&nbsp;&nbsp;nativeWindowOpen: true,<br>&nbsp;&nbsp;&nbsp;&nbsp;enableRemoteModule: false,<br>&nbsp;&nbsp;&nbsp;&nbsp;spellcheck: true<br>&nbsp;&nbsp;}<br>};</blockquote><p>The important options which we should check here are especially <i>nodeIntegration</i> and <i>contextIsolation</i>. From the above code, I found that the <i>nodeIntegration</i> option is set to false and the <i>contextIsolation</i> option is set to false (the default of the used version) in the Discord's main window.</p><p>If the nodeIntegration is set to true, a web page's JavaScript can use Node.js features easily just by calling the <code>require()</code>. For example, the way to execute the calc application on Windows is:</p><blockquote>&lt;script&gt;<br>&nbsp; require('child_process').exec('calc');<br>&lt;/script&gt;</blockquote><p>In this time, the <i>nodeIntegration</i> was set to false, so I couldn't use Node.js features by calling the <code>require()</code> directly.</p><p>However, there is still a possibility of access to Node.js features. The <i>contextIsolation</i>, another important option, was set to false. This option should not be set to false if you want to eliminate the possibility of RCE on your app.</p><p>If the <i>contextIsolation</i> is disabled, a web page's JavaScript can affect the execution of the <a href="https://github.com/electron/electron/tree/83bb065b4f6ed512d545c46389a7fdc114c94a54/lib/renderer">Electron's internal JavaScript code on the renderer</a>, and preload scripts (In the following, these JavaScript will be referred to as the JavaScript code outside web pages).&nbsp;For example, if you override&nbsp; <code>Array.prototype.join</code>, one of the JavaScript built-in methods, with another function from a web page's JavaScript, the JavaScript code outside web pages also will use the overridden function when the <code>join</code> is called.</p><p>This behavior is dangerous because Electron allows the JavaScript code outside web pages to use the Node.js features regardless the <i>nodeIntegration</i> option and by interfering with them from the function overridden in the web page, it could be possible to achieve RCE even if the <i>nodeIntegration</i> is set to false.</p><p>By the way, a such trick was previously not known. It was first discovered in a pentest by Cure53, which I also joined in, in 2016. After that, we reported it to Electron team and the <i>contextIsolation</i> was introduced.</p><p>Recently, that pentest report was published. If you are interested, you can read it from the following link:</p><p>Pentest-Report Ethereum Mist 11.2016 - 10.2017<br><a href="https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view">https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view</a></p><p>You can also read the slides which I used at a CureCon event:</p><p>The <i>contextIsolation</i> introduces the separated contexts between the web page and the JavaScript code outside web pages so that the JavaScript execution of each code does not affect each. This is a necessary faeture to eliminate the possibility of RCE, but this time it was disabled in Discord.</p><p>Now I found that the <i>contextIsolation</i> is disabled, so I started looking for a place where I could execute arbitrary code by interfering with the JavaScript code outside web pages.</p><p>Usually, when I create a PoC for RCE in the Electron's pentests, I first try to achieve RCE by using the Electron's internal JavaScript code on the renderer. This is because the Electron's internal JavaScript code on the renderer can be executed in any Electron app, so basically I can reuse the same code to achieve RCE and it's easy.</p><p>In my slides, <a href="https://speakerdeck.com/masatokinugawa/electron-abusing-the-lack-of-context-isolation-curecon-en?slide=41">I introduced</a> that RCE can be achieved by using the code which Electron executes at the navigation timing. It's not only possible from that code but there are such code in some places. (I'd like to publish examples of the PoC in the future.)</p><p>However, depending on the version of Electron used, or the <i>BrowserWindow</i> option which is set, because the code has been changed or the affected code can't be reached correctly, sometimes PoC via the Electron's code does not work well. In this time, it did not work, so I decided to change the target to the preload scripts.</p><div><p>When checking the preload scripts, I found that Discord exposes the function, which allows some allowed modules to be called via <code>DiscordNative.nativeModules.requireModule('MODULE-NAME')</code>, into the web page.</p></div><p>Here, I couldn't use modules that can be used for RCE directly, such as <i>child_process</i> module, but I found a code where RCE can be achieved by overriding the JavaScript built-in methods and interfering with the execution of the exposed module.</p><p>The following is the PoC. I was able to confirm that the calc application is popped up when I call the <code>getGPUDriverVersions</code> function which is defined in the module called "<i>discord_utils</i>" from devTools, while overriding the <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>.</p><blockquote>RegExp.prototype.test=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return false;<br>}<br>Array.prototype.join=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return "calc";<br>}<br>DiscordNative.nativeModules.requireModule('discord_utils').getGPUDriverVersions();</blockquote><p>The <code>getGPUDriverVersions</code> function tries to execute the program by using the "<i>execa</i>" library, like the following:</p><blockquote>module.exports.getGPUDriverVersions = async () =&gt; {<br>&nbsp;&nbsp;if (process.platform !== 'win32') {<br>&nbsp;&nbsp;&nbsp;&nbsp;return {};<br>&nbsp;&nbsp;}<p>&nbsp;&nbsp;const result = {};<br>&nbsp;&nbsp;const nvidiaSmiPath = `${process.env['ProgramW6432']}/NVIDIA Corporation/NVSMI/nvidia-smi.exe`;</p><p>&nbsp;&nbsp;try {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = parseNvidiaSmiOutput(await execa(nvidiaSmiPath, []));<br>&nbsp;&nbsp;} catch (e) {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = {error: e.toString()};<br>&nbsp;&nbsp;}</p><p>&nbsp;&nbsp;return result;<br>};</p></blockquote><p>Usually the <i>execa</i> tries to execute "<i>nvidia-smi.exe</i>", which is specified in the <code>nvidiaSmiPath</code> variable, however, due to the overridden <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>, the argument is replaced to "<i>calc</i>" in the <i>execa</i>'s internal processing.</p><p>Specifically, the argument is replaced by changing the following two parts.</p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36</a></p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55</a></p><p>The remaining work is to find a way to execute JavaScript on the application. If I can find it, it leads to actual RCE.</p><h3>XSS in iframe embeds</h3><p>As explained above, I found that RCE could happen from arbitrary JavaScript execution, so I was trying to find an XSS vulnerability. The app supports the autolink or Markdown feature, but looked like it is good. So I turned my attention to the iframe embeds feature. The iframe embeds is the feature which automatically displays the video player on the chat when the YouTube URL is posted, for example.</p><p>When the URL is posted, Discord tries to get the <a href="https://ogp.me/">OGP</a> information of that URL and if there is the OGP information, it displays the page's title, description, thumbnail image, associated video and so on in the chat.</p><p>The Discord extracts the video URL from the OGP and only if the video URL is allowed domain and the URL has actually the URL format of the embeds page, the URL is embedded in the iframe.</p><p>I couldn't find the documentation about which services can be embedded in the iframe, so I tried to get a hint by checking the CSP's <i>frame-src</i> directive. At that time, the following CSP was used:</p><blockquote>Content-Security-Policy: [...] ; frame-src https://*.youtube.com https://*.twitch.tv https://open.spotify.com https://w.soundcloud.com https://sketchfab.com https://player.vimeo.com https://www.funimation.com https://twitter.com https://www.google.com/recaptcha/ https://recaptcha.net/recaptcha/ https://js.stripe.com https://assets.braintreegateway.com https://checkout.paypal.com https://*.watchanimeattheoffice.com</blockquote><p>Obviously, some of them are listed to allow iframe embeds (e.g. YouTube, Twitch, Spotify).&nbsp;I tried to check if the URL can be embeded in the iframe by specifying the domain into the OGP information one by one and tried to find XSS on the embedded domains. After some attempts, I found that the&nbsp;<a href="https://sketchfab.com/">sketchfab.com</a>, which is one of the domains listed in the CSP, can be embedded in the iframe and found XSS on the embeds page.&nbsp;I didn't know about Sketchfab at that time, but it seems that it is a platform in which users can publish, buy and sell 3D models. There was a simple DOM-based XSS in the footnote of the 3D model.</p><p>The following is the PoC, which has the crafted OGP. When I posted this URL to the chat, the Sketchfab was embedded into the iframe on the chat, and after a few clicks on the iframe, arbitrary JavaScript was executed.</p><p><a href="https://l0.cm/discord_rce_og.html">https://l0.cm/discord_rce_og.html</a></p><blockquote>&lt;head&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta charset="utf-8"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="og:title" content="RCE DEMO"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;[...]<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="<span><b>og:video:url</b></span>" content="https://<span><b>sketchfab.com</b></span>/models/2b198209466d43328169d2d14a4392bb/embed"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mksben.l0.cm/2020/10/discord-desktop-rce.html">https://mksben.l0.cm/2020/10/discord-desktop-rce.html</a></em></p>]]>
            </description>
            <link>https://mksben.l0.cm/2020/10/discord-desktop-rce.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822755</guid>
            <pubDate>Mon, 19 Oct 2020 02:00:12 GMT</pubDate>
        </item>
    </channel>
</rss>
