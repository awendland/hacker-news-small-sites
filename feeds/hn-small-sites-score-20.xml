<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Dec 2020 12:35:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Dec 2020 12:35:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[In-Database Machine Learning [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25285983">thread link</a>) | @redwrasse
<br/>
December 2, 2020 | https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf | <a href="https://web.archive.org/web/*/https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25285983</guid>
            <pubDate>Thu, 03 Dec 2020 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the US Banning Crypto Wallets?]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25283610">thread link</a>) | @mkmccarty3
<br/>
December 2, 2020 | https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5fc557916457125654ede725" data-item-id="5fc557916457125654ede725">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1606768551080" id="item-5fc557916457125654ede725"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_4996"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image-dimensions="834x466" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baa31d106d256baa5ca2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-98c39078cd9c52d11cda"><div><p>Just as Bitcoin was guiding cryptocurrency markets skyward with a renewed push for an all-time high valuation, prices came crashing down without warning.</p><p>Wait — <em>was there a warning</em>?</p><p><a href="https://twitter.com/brian_armstrong/status/1331744884856741888">In a tweet</a> with what some deemed suspicious timing, Coinbase CEO Brian Armstrong let loose an alarming rumor. The United States Treasury, with Secretary Mnuchin at the helm, is poised to ban the use of anonymous non-custodial crypto wallets before the year's end.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_22941"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://twitter.com/brian_armstrong/status/1331745659989360640">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image-dimensions="589x256" data-image-focal-point="0.5,0.5" alt="brian armstrong tweet.PNG" data-load="false" data-image-id="5fc6bc78e2dcb1274dd6fb85" data-type="image">
          </p>
        
          </a>
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_23230"><div><p>What is a non-custodial crypto wallet, you ask? Simple — any crypto wallet that is self-hosted (i.e., you own and hold the private keys) fits the description.</p><p>So, if you currently use a cold storage wallet like a Ledger Nano S or a software wallet such as MetaMask, you may soon find yourself running afoul of new regulations.</p><p>While this all seems pretty bad for Bitcoin when you consider the sheer amount of people using non-custodial crypto wallet storage, there are a couple silver linings worth considering.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_25472"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image-dimensions="1306x735" data-image-focal-point="0.5,0.5" alt="wallet guide.PNG"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_25761"><div><p>At the core of the rumored regulations is what appears to be a bank-centric push to force all current and future cryptocurrency users toward intermediary platforms.</p><p>What this means for you is, if the rumors are true, you will need to share KYC information (identification data) with exchanges you use before withdrawing or depositing from your self-hosted wallet. This push will make it so your currently anonymous crypto wallet will be inextricably linked to your real-world identity.</p><p>OK — so there go crypto wallets, right? You might as well delete your Exodus wallet, shut down the MetaMask, and turn everything over to the bankers lying in wait.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_7734"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baf2ad3e6411922cd0a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_8023"><div><p><strong>Wrong.</strong> Try as they might, there is simply <strong>no way</strong> to enforce data collection on the use of non-custodial wallets. Such regulations appear more symbolic than anything else — they might scare newbies looking to enter the market discreetly, but anyone who understands how cryptocurrency storage works, especially when using hardware wallets, knows there are options outside of centralized exchanges.</p><p>Consider the scenario where the US Treasury makes good on their threat to enforce data collection on crypto wallets. Now, Coinbase requires you to KYC your wallet before allowing you to withdraw freshly purchased BTC. What are your options?</p><p>For one thing, you can use a decentralized exchange to trade crypto. Uniswap has already surpassed Coinbase in terms of trading volume — if crypto wallets regulations come into play, expect Uniswap to get much more action.</p><p>Moreover, with the push toward DeFi in the cryptocurrency industry, along with endless options for swapping liquidity, the likelihood that centralized exchanges stay relevant gets slimmer every day.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_15299"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6bbd593ad1a48120388ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_15588"><div><p>Satoshi Nakamoto never envisioned cryptocurrency as a way for governments to collect private data. That's why blockchains are built to enable censorship-free financial access.</p><p>As CoinDesk noted <a href="https://www.coindesk.com/crypto-wallet-regulations-industry-pros">in a recent analysis of the situation</a>, there exists a revealing difference in the language used to refer to crypto wallets by regulators and crypto investors.</p><p>Regulators call crypto wallets <em>unhosted wallets,</em> whereas investors refer to them as <em>self-hosted wallets</em>. The difference here is all about privacy — crypto users believe in financial independence, freedom from oversight, and digital asset autonomy.</p><p>On the other hand, an unhosted wallet points to the view that such wallets lack hosting — a situation that should be remedied by regulation and the cooperation of centralized institutions.</p><p>This seemingly small difference in language does indeed point to a large divide in exactly how each side views the purpose of storing crypto assets.</p><p>As Armstrong noted in his original Twitter thread, the crypto industry has been preparing for this eventuality for at least a few months. In fact, they've known long enough to form a lobby, and have responded to the rumors by sending the US Treasury a plea to leave crypto alone.</p><p>The regulation is expected to come into effect before the year's end, mostly owing to the US election results and the impending changing of the guard. As such, the rush is on for Mnuchin to push through regulations before time is up.</p><p>Does data-collection on self-hosted crypto wallets amount to the US government declaring a ban on cryptocurrency wallets we know them?</p><p><strong>Not really</strong>.</p><p>Moreover, can the government enforce these regulations and push people onto the centralized platforms decentralized blockchains were built to avoid?</p><p>The answer there is clearer: <strong>certainly not.</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_28135"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image-dimensions="1442x669" data-image-focal-point="0.5,0.5" alt="beginners guide to bitcoin cover.png" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>Each of these strategies is simple to implement, even for novice investors, but that doesn’t mean these strategies aren’t used by professions.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>

    

    

    <section id="comments-5fc557916457125654ede725">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://blog.shrimpy.io/blog/coinbase-vs-uniswap">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Coinbase vs. Uniswap — Which Exchange Is Better?</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-12-02">December 2, 2020</time></p><!--

            Tags

            --><p><span>coinbase, uniswap, review, general, notlatest</span></p><!--

            Comments

            --></div>
        </div>
      </a>
    

    
      <a href="https://blog.shrimpy.io/blog/machine-learning-for-crypto-portfolio-management-case-study-week-30">
        <div>
          <p>Next</p>
          <h4>Machine Learning for Crypto Portfolio Management Case Study: Week 30</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-11-30">November 30, 2020</time></p><!--

            Tags

            --><p><span>data, notlatest, topsection</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283610</guid>
            <pubDate>Thu, 03 Dec 2020 00:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Issues as a Hugo Front End with GitHub Actions and Netlify]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25281958">thread link</a>) | @todsacerdoti
<br/>
December 2, 2020 | https://shazow.net/posts/github-issues-as-a-hugo-frontend/ | <a href="https://web.archive.org/web/*/https://shazow.net/posts/github-issues-as-a-hugo-frontend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I got into the habit of dumping quick blog post ideas into issues on my blog’s repo. It’s a convenient place to iterate on them and share with friends for feedback before actually publishing on my blog post.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100761218-a6cb2280-33c0-11eb-92df-1b52d91cc16e.png" alt="image"></p><p>The drafts keep accumulating, how do I trick myself into publishing more? Perhaps by reducing the effort required for the next step? Let’s do it!</p><h2 id="architecture">Architecture</h2><p>My blog is statically generated using <a href="https://github.com/gohugoio/hugo">Hugo</a>, the <a href="https://github.com/shazow/shazow.net">code is hosted on Github</a>, then when a pull request comes in it is built, previewed, and published on merge by <a href="https://netlify.com/">Netlify</a>.</p><p>The blog post drafts are posted as Github issues, so there is a clear gap: How do we convert issues into pull requests for Netlify? Enter Github Actions!</p><h2 id="github-action-issue-to-pull-request">Github Action: Issue to Pull Request</h2><p>My <a href="https://github.com/shazow/shazow.net/blob/master/.github/workflows/publish.yml">full workflow lives here</a> if we want to jump ahead, but let’s break down the broad strokes.</p><p>I decided to trigger the publishing process once an issue is labelled with ‘publish’, so let’s start with that:</p><div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span>Publish<span> </span>post<span> </span>from<span> </span>issue<span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>issues</span><span>:</span><span>
</span><span>    </span><span>types</span><span>:</span><span> </span><span>[</span><span>'labeled'</span><span>]</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>build</span><span>:</span><span>
</span><span>    </span><span>if</span><span>:</span><span> </span>${{<span> </span>github.event.label.name<span> </span>==<span> </span><span>'publish'</span><span> </span>}}<span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>      </span>...<span>
</span></code></pre></div><p>Next up we want to specify the steps, first thing is to check out the repository into the action’s environment:</p><p>Once the source code is available, we want to generate the blog post from the issue metadata. Here is a very basic version of this, though I ended up doing more tweaking in the end:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Generate<span> </span>Post<span>
</span><span>        </span><span>env</span><span>:</span><span>
</span><span>          </span><span>POST_TITLE</span><span>:</span><span> </span>${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>          </span><span>POST_BODY</span><span>:</span><span> </span>${{<span> </span>github.event.issue.body<span> </span>}}<span>
</span><span>        </span><span>run</span><span>:</span><span> </span><span>|
</span><span>          cat &gt; "content/posts/${POST_TITLE}.md" &lt;&lt; EOF</span><span>
</span><span>          </span>${POST_BODY}<span>
</span><span>          </span>EOF<span>
</span></code></pre></div><p>This shoves the body of the issue, which is already markdown, into a markdown file named based on the title of the issue. This is a good place to add frontmatter, or slugify the title, or whatever else your blog setup requires.</p><p>Running the payload through environment variables helps with not needing to escape various characters like `.</p><p>And finally, we make the pull request using Peter Evan’s create-pull-request action which makes this super easy:</p><p>This is the minimum of what we need, but we can specify all kinds of additional options here: like auto-deleting the branch, setting a custom title, body, and whatever else. Here’s an example of what I’m doing:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Create<span> </span>Pull<span> </span>Request<span>
</span><span>        </span><span>uses</span><span>:</span><span> </span>peter-evans/<a href="https://shazow.net/cdn-cgi/l/email-protection" data-cfemail="83e0f1e6e2f7e6aef3f6efefaef1e6f2f6e6f0f7c3f5b0">[email&nbsp;protected]</a><span>
</span><span>        </span><span>with</span><span>:</span><span>
</span><span>          </span><span>delete-branch</span><span>:</span><span> </span><span>true</span><span>
</span><span>          </span><span>title</span><span>:</span><span> </span><span>"publish: ${{ github.event.issue.title}}"</span><span>
</span><span>          </span><span>body</span><span>:</span><span> </span><span>|
</span><span>            Automagically sprouted for publishing.</span><span>
</span><span>            </span><span>Merging will publish to</span><span>:</span><span> </span>https<span>:</span>//shazow.net/posts/${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>            </span>Closes<span> </span><span>#${{ github.event.issue.number }}</span><span>
</span><span>          </span><span>reviewers</span><span>:</span><span> </span>${{<span> </span>github.repository_owner<span> </span>}}<span>
</span><span>          </span><span>commit-message</span><span>:</span><span> </span><span>"post: ${{ github.event.issue.title }}"</span><span>
</span></code></pre></div><h2 id="result">Result</h2><p>When my blog post draft is ready, I add the tag and the Github action takes it away, creating a pull request:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763017-a764b880-33c2-11eb-860f-5bab932ac558.png" alt="image"></p><p>The pull request automatically pings me as a reviewer, and includes a “Closes #X” line which will close the draft issue once the PR is merged. Very convenient!</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763219-ded36500-33c2-11eb-8387-ff28b6561875.png" alt="image"></p><p>Once the pull request is ready, Netlify takes it away, builds everything and generates a handy preview:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763300-fa3e7000-33c2-11eb-9172-206f58556ddd.png" alt="image"></p><p>I can make sure everything looks right, and even apply edits directly inside the pull request. This is another great step to send a long blog post for feedback, using all of the wonderful Pull Request Review features!</p><p>When all is said and done, merging the pull request triggers Netlify to publish my changes to my domain, and merging closes the original issue, and I’m done!</p><h2 id="bonus">Bonus</h2><p>Drag n’ drop images work in Github Issues, so it’s super easy to write a quick post with a bunch of screenshots or what have you.</p><p>It’s important to me that I’m not too tightly coupled to third-party services, so the pull request and code merge flow makes sure that all of the published state continues to live inside of my Git repository.</p><p>I can still make blog posts the way I used to: Pull the latest repo, write some markdown, and push to publish.</p><p>I added a little <a href="https://github.com/shazow/shazow.net/blob/master/frontmatterify">frontmatterify script</a> to process the incoming markdown and convert the remote Github Issue uploaded images into local images that are included in the pull request. The script also generates frontmatter that I use for Hugo. It’s a bit clunky but works for now.</p><p>Alright, let’s do this.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100764184-11ca2880-33c4-11eb-8c84-e992765ace49.png" alt="image"></p></div></div>]]>
            </description>
            <link>https://shazow.net/posts/github-issues-as-a-hugo-frontend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25281958</guid>
            <pubDate>Wed, 02 Dec 2020 21:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Topology to Classify Labelled Graphs]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25279820">thread link</a>) | @Topolomancer
<br/>
December 2, 2020 | https://bastian.rieck.me/blog/posts/2020/topology_graphs/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/topology_graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I have written at lengths about certain aspects of topological data
analysis, but I have neglected to discuss one of its main applications,
i.e. the classification of graphs. In this post, I will therefore take
you on a quick tour of our ICML paper <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">A Persistent Weisfeiler–Lehman Procedure for Graph Classification</a>.</p>
<p>Let us assume that we are given a graph with node label information. The
graph could, for instance, be a molecule, whose nodes are atoms such as
carbon or oxygen, and whose edges indicate chemical bonds. The goal
could now be to classify a given molecule into a set of classes, such as
‘toxic’, ‘carcinogen’, etc. How can we achieve such a classification?
One of the simplest techniques dates back to the 1960s and involves
calculating an <em>iterative fingerprint</em> of the graph! This procedure was
suggested by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler">Boris Weisfeiler</a>
and Andrei Lehman&nbsp;(sometimes also transliterated as ‘Leman’) in
their seminal article <a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">The reduction of a graph to canonical form and the
algebra which appears therein</a>.</p>
<p>At its core, the algorithm is an iteration scheme that works like this:</p>
<ol>
<li>For a node $v$, collect its label and the labels of adjacent nodes in
a multiset.</li>
<li>Assign this multiset a new label by hashing it—with the proviso
that the hashing function is <a href="https://en.wikipedia.org/wiki/Perfect_hash_function"><em>perfect</em></a>, i.e.
it maps distinct labels to distinct values with no collisions.</li>
<li>Replace all node labels by their multiset hashes.</li>
</ol>
<p>Intuitively, each step of the algorithm accumulates more information
from nodes that are further removed from the current node. The hashed
multiset label is thus an expression of the neighbourhood around
a node—and after a sufficiently large number of iterations, the
hashed labels will not change any more.</p>
<p>For example, suppose you are dealing with this simple graph&nbsp;(to
prevent confusion of node labels and node IDs, I used <em>colours</em> to
indicate node labels in this example):</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_graph.svg" alt="Weisfeiler--Lehman example graph" height="128"> 
</figure>

</div>
<p>Tabulating the neighbourhood of each node then results in the following
table:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_1.svg" alt="Weisfeiler--Lehman multiset example (before hashing)" height="128"> 
</figure>

</div>
<p>Now for the hashing step. In this example, <em>perfect hashing</em> means
choosing a set of colours that is distinct for every distinct
combination of neighbourhood labels and vertex labels:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_2.svg" alt="Weisfeiler--Lehman multiset example (after hashing)" height="128"> 
</figure>

</div>
<p>Notice how nodes A, B, and G are hashed to the same colour—because
in the first iteration of the algorithm, they cannot be distinguished.
How can we use the information about the hashed labels in a subsequent
comparison task? The answer is lies in <em>counting</em> them in a histogram
vector, which is indexed by the unique labels—this is where our
requirement of the perfect hashing function is helpful. For the
previously-shown graph, it looks like this:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_feature_vector.svg" alt="Weisfeiler--Lehman subtree feature vector" height="128"> 
</figure>

</div>
<p>The <em>fingerprint</em> of this graph, according to the first iteration of the
Weisfeiler–Lehman scheme is therefore $(3, 1, 2, 1)$. Further iterations
just make the feature vector longer&nbsp;(technically, the initial
labels already give rise to a feature vector of counts). This procedure
can now be repeated for higher-order iterations and the resulting
feature vectors can be compared across graphs by evaluating, for
example, their dot product. More formalisations of this idea have
resulted in the very successful <a href="https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf">Weisfeiler–Lehman Graph
Kernels</a>
publication. This method arguably constitutes the basis for graph neural
networks—in fact, these networks can be seen as a parametrised
version of the Weisfeiler–Lehman iteration scheme. But I digress—if
you are interested in these aspects, please read <a href="https://towardsdatascience.com/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751">Michael Bronstein’s
article on going beyond graph
isomorphism</a>
for more details.</p>
<p>Now, despite its great practical utility, this feature vector is lacking
some <em>structural</em> information about the graph. It does not know whether
a certain label contributes much to the topological structure of
a graph—such as a ring of carbon atoms would in molecule—or not. To
this end, we introduced a notion of topological relevance for each node
label! Briefly put, we first developed a distance metric that would
permit us turn any <em>labelled</em> graph into a <em>weighted</em> graph. We then
calculate a persistence barcode, a topological descriptor of the graph.
This descriptor assesses the relevance of a topological feature created
by some node label. We use the topological relevance of each feature as
an additional <em>weight</em> for the previously-shown feature vector. In
essence, labels that contribute a large amount of topological structure
in a graph are assigned a higher weight than labels that only contribute
a meagre amount!</p>
<p>Here is a graphical depiction of our process:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/p_wl_pipeline.svg" alt="Persistent Weisfeiler--Lehman pipeline" height="128"> 
</figure>

</div>
<p>If you want to brush up your understanding of the barcode calculation,
head on over to <a href="https://christian.bock.ml/">Christian’s website</a>; he has
an <a href="https://christian.bock.ml/posts/persistent_homology">excellent article on persistent
homology</a>.</p>
<p>The neat thing about our approach is that we can easily integrate
information about <em>cycles</em> into the feature vector—this is
a functionality that the original Weisfeiler–Lehman Graph Kernels
Framework lacks. Moreover, these cycles turn out to be crucial in
improving classification performance—we get an increase of more than
3% in classification accuracy by considering them in some data sets!</p>
<p>If this has whet your appetite, I invite you to <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">read our
paper</a> or <a href="https://github.com/BorgwardtLab/P-WL">take
a look at the code</a>. If you want
to learn more about graph classification using graph kernels, take
a look at our <a href="https://arxiv.org/abs/2011.03854">recent survey on graph kernels</a>,
which will hopefully be officially announced in time for NeurIPS 2020.
In the best tradition of Fermat, I would very much like to cover the
content of the survey here, but this blog is too small to contain all of
it—maybe for a subsequent post?</p>
<p>Until next time!</p>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/topology_graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279820</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A founder’s guide to understanding users]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25279814">thread link</a>) | @mgadams3
<br/>
December 2, 2020 | https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44 | <a href="https://web.archive.org/web/*/https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="9bcd">Four steps to ensure your customer discovery &amp; development efforts result in great products that solve real customer problems</h2><div><div><div><p><a href="https://medium.com/@mgadams?source=post_page-----c68feaecac44--------------------------------" rel="noopener"><img alt="Mike Adams" src="https://miro.medium.com/fit/c/96/96/1*Myw6S5WzM6_5PfbkyNAwUQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4ad5">When building any technology product, one of the most common pieces of advice is “talk to your users.”</p><p id="cec4">But the default way most of us talk to customers and prospects is unscientific and fraught with confirmation bias, putting us in danger of being lied to and wasting months building something nobody wants.</p><p id="ee5b">I learned this truth the hard way over the past decade founding multiple companies — but it wasn’t until I was working on my <a href="http://grain.co/utm_source=medium" rel="noopener">third startup</a> that I came to understand a better way to actually understand users.</p><p id="a218">When I first started building start-ups a decade ago, I never anticipated how applicable Yoda’s wisdom about the value of failure would be as a founder.</p><p id="3a5b">When I first started out, we had an idea, turned it into a UI, and hired developers to make it real. After nearly a year and tens of thousands of dollars — we launched it.</p><p id="d4d8">Ghost town. Crickets. Nobody wanted what we’d built.</p><p id="998b">I determined that the missing piece of the puzzle was my <a rel="noopener" href="https://mgadams.com/want-to-learn-to-code-start-with-excel-4f5902fb1b2f?source=collection_home---6------0-----------------------">lack of technical ability</a>, so I enrolled as one of the first dozen students at a now-famous<a href="https://www.hackreactor.com/" rel="noopener"> coding bootcamp</a> and actually got a job as a software engineer at a <a href="http://opentable.com/" rel="noopener">real company</a>.</p><p id="3b53">So surely when I started my <a href="https://twitter.com/missionu?lang=en" rel="noopener">next start-up</a>, this time things would be different. This time we talked to dozens of potential users and industry experts before we built anything. This time it worked. Sort of.</p><p id="d494">Our mission was compelling as we launched to <a href="https://www.inc.com/magazine/201806/leigh-buchanan/missionu-career-training-school.html" rel="noopener">fanfare</a> and raised <a href="https://techcrunch.com/2017/09/14/missionu-raises-8-5m-to-build-an-alternative-one-year-education-program/" rel="noopener">$11.5M</a> within 10 months of founding the company. However, after just two years we were acqui-hired, our investors got their money back, and the product was immediately <a href="https://www.insidehighered.com/digital-learning/article/2018/05/23/missionu-self-styled-alternative-higher-education-closes-after" rel="noopener">shut down</a>.</p><p id="6863">I was gutted, still am TBH.</p><p id="0f28">But with hindsight, I could look back to my original research notes and see I had ignored several fatal warnings. I had listened to what they said — exactly as they said it, but I did not realize until much later that I failed to actually understand what they meant.</p><p id="9305">So if I wanted to avoid failing a third time, I needed to figure out what I was missing about how to <em>really</em> understand users.</p><p id="9c98">Marty Cagan, Silicon Valley Product Group founder and former PM at early eBay, says there are “<a href="https://svpg.com/the-inconvenient-truth-about-product/" rel="noopener">two inconvenient truths about product</a>.”</p><p id="b881">Truth #1: <strong>At least half of our ideas are just not going to work</strong>:</p><p id="ed0c">Truth #2: <strong>Even the good ideas take several iterations to become viable.</strong></p><p id="3d8c">My experience has also been that there’s simply no escaping these inconvenient truths — I only wish I would have learned about them sooner.</p><p id="30d3">It doesn’t matter how smart or experienced we may be, statistically speaking, most of our ideas are simply not going to work. And the successful ones take time and hard work to turn into a real product that gets widely adopted by a market.</p><p id="de93">Your ideas are not nearly as important as your process — and the best process starts with understanding what the customers you wish to serve <em>already</em> do to solve their problems today and even more importantly, understanding why.</p><p id="9883">Yet, even as a 3rd time founder, I fell into the trap of ignoring the two inconvenient truths <em>again.</em></p><p id="87c7">Confirmation bias is a hell of a drug.</p><p id="f8b7">When we started <a href="http://grain.co/?utm_source=medium" rel="noopener">grain.co</a> two years ago, we began with a specific product solution in mind, built prototypes, and got feedback from users. They told us they’d love to use it but after months turning prototypes into a product, few actually did.</p><p id="a400">So we started over from scratch, but this time with a different approach:</p><ol><li id="2be7">Focus on a very specific user type with a very specific job to be done.</li><li id="bb56">Interview dozens of them only to understand how and why they solve their problem today.</li></ol><p id="0128">Our goal was not to validate whether the merit of a specific solution but to observe existing customer behaviors and desires as a means of generating new ideas for potential product solutions.</p><p id="3dec">This is what is known as <strong>generative research</strong>.</p><p id="4699">As you listen to your target market describe what they do today to solve their problems, you can better understand potential customers’ existing incentives, behaviors, and desires in anticipation for how they’d react to a new solution.</p><p id="331b"><a href="https://twitter.com/robfitz" rel="noopener">Rob Fitzpatrick</a> has famously coined this generative research phase “ <a href="http://momtestbook.com/" rel="noopener">The Mom Test</a>,” which is a set of simple rules to ask good questions so that even your Mom can’t lie to you in her answers to protect your ego.</p><p id="7e65">Generative research questions are focused on understanding existing behavior. For example, here are some questions from an interview guide we used at <a href="http://grain.co/" rel="noopener">Grain</a> to understand how our prospective users already document and share information from live meetings:</p><ul><li id="fcb3">What’s your current process to document and share information from a video meeting?</li><li id="fa1f">How important is it that the information you document and share is accurate?</li><li id="6568">What measures do you currently take to ensure accuracy of captured information?</li><li id="33f9">What can happen if your documentation is inaccurate?</li><li id="32f3">How often are you in conversations where you don’t need to document or share anything?</li><li id="cda6">Which types of conversations are the most important for you to document and share?</li></ul><p id="9e72">Be sure to avoid hypothetical questions about what people <em>might</em> do. Don’t try to validate your future product with questions that begin with “would you use this” or “what do you think about the possibility of” — that’s what we call leading the witness, and it will inevitably bias your data and waste your time building the wrong thing. At this stage, you simply need to observe what users are <em>already doing,</em> not what they might theoretically do.</p><figure><div></div></figure><p id="69d3">I recently connected with <a href="https://twitter.com/robfitz" rel="noopener">Rob</a> where he shared an updated model of 3 ways where users will lie to you if you’re not careful:</p><ol><li id="afa0">Asking the wrong questions</li><li id="6697">Remembering the wrong thing</li><li id="6a57">Making the wrong decision “justified” by what you think you heard</li></ol><p id="ecb1">Rob and most other researchers suggest asking for permission from their interviewees to record these interviews and take time-annotated notes that will help them to accurately remember and codify behavioral patterns that could eventually help to define <a href="https://www.uxmatters.com/mt/archives/2019/02/the-pitfalls-of-personas-and-advantages-of-jobs-to-be-done.php" rel="noopener">“jobs to be done”</a> that product, engineering, and design teams can build for with confidence.</p><p id="556d">After gaining insights about the problems your target market faces in generative research, you may be confident enough to test out a specific product solution to see if these users would actually value it.</p><p id="4717">This is the concept behind <strong>evaluative testing</strong>.</p><p id="f326">At this early stage, you want to put an <em>ultra-lightweight implementation </em>of a product solution in front of your target users to see how they react. While the closer to reality your prototype is the better, it doesn’t need to be a fully functional product yet: designs on paper, prototypes, mock-ups-anything like that will work.</p><p id="b1b0">Your goal at this stage is to get clear qualitative signals that users:</p><ol><li id="9f21">understand the proposed product solution</li><li id="fcda">express unmistakable excitement about the prospect of the product as a superior solution to the status quo</li></ol><p id="2033">Unfortunately, all too many product teams speed through this testing or skip it all together and simply march ahead to engineering and delivery. Depending on the complexity of the market and the problem you’re trying to solve, this stage could take months or, in some cases, years.</p><p id="d10d">That might sound discouraging and time-consuming, but I know this for certain: the success of your product will be <strong><em>directly proportiona</em>l</strong> to the quality of work done in this initial customer discovery phase. It’s worth doing it, and it’s certainly worth doing it well.</p><p id="0fd4">Even if your team creates something that people want, if customers can’t figure out how to use it, the product is dead in the water. This is why product teams conduct usability testing throughout the build process.</p><p id="ee09">The traditional approach to usability interviews is to set up a test environment, where we watch as a user navigates the product. An interviewer encourages a user to explain what they see, think, and observe. The interviewer also offers prompts for what the user might consider next if they get stuck using the product. Usability issues in the product become self-evident in most of these cases.</p><p id="8825">My friend <a href="https://medium.com/u/b2d49a9606e3?source=post_page-----c68feaecac44--------------------------------" target="_blank" rel="noopener">Behzod Sirjani</a>, has created a framework for conducting usability testing interviews where he recommends asking the participant about their:</p><ol><li id="084d">Expectation (about what will happen)</li><li id="4d83">Reaction (to what happens)</li><li id="64e1">Reflection (on the difference between 1 and 2)</li></ol><figure><div></div></figure><p id="ec98">A less scientific and more agile approach to identifying lower-hanging usability issues is concierge onboarding. In concierge onboarding, someone from your team guides — via video call is best — new users through setting up the product and answers the questions in real-time. Concierge onboarding helps the team member understand the steps users are asked to take and the ways those steps directly lead to value.</p><figure><div></div></figure><p id="2293">In a recent Zoom call with Behzod, he told me how at Slack it was essential to turn usability interviews into video highlights of moments of user struggle to help his team form a shared understanding of the problem and gain alignment around solutions that will actually work.</p><p id="5379">The best product teams never stop this work of generative and evaluative testing for new features. Even as their initial research and testing turns into a real product, they know the importance of creating a customer discovery and product delivery engine that never stops learning and growing.</p><p id="b7d9">It’s much more common for product teams to continually learn and discover from their existing users than it is for them to gather insights from completely unbiased non-users. But a balance between the two groups — existing and new — is ideal. New users can give you a better understanding of your initial product experience, and existing “power users” can offer you insights that come from living with a product for weeks or months.</p><p id="1af9">Great product teams develop long-standing relationships of trust with their most active users. You’ll often see the people on these teams setting up recurring feedback sessions to gain insight and listen to users’ concerns and ideas. The point of these interviews is to find out what’s delightful and what’s frustrating, what’s there and working well, and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</a></em></p>]]>
            </description>
            <link>https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279814</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop slacking, start rocking: Why we built Rock for a distributed workforce]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25279417">thread link</a>) | @kenzofong
<br/>
December 2, 2020 | http://rock.so/stopslacking | <a href="https://web.archive.org/web/*/http://rock.so/stopslacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <!-- split row one -->
      <div>
        <div>

          <!-- Row one -->
          <div>
            
            <div>
              <p>
                  <br><b>tl;dr</b> <i>Remote work is here to stay and the productivity tools that currently exist are not built for a more distributed workforce. With Rock, we're bringing together both synchronous and asynchronous ways of collaborating, so working with a distributed team becomes easier. <span><a href="#"><i></i> See how Rock works.</a></span></i>
                </p>
            </div>
            
          </div>

          <!-- Row one -->
          <div>
            
            <div>
              <div>
                <p>
                  <br>
                  <b>We are now in more meetings and work longer hours than ever before.</b> With <a href="https://time.com/collection/great-reset/5900753/rethinking-work-covid-19/">62% of people working from home</a> because of the pandemic -- the number of meetings has gone up 12.9%, the volume of emails has increased and workdays have grown 48 ½ minutes longer.
                </p>
                <p>
                  All of these distractions take up 40% of someone’s productive time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row two -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-1.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row three -->
          <div>
            
            <div>
              <div>
                <p>
                  There are different reasons why this has happened, but one of the main reasons is that the way we work hasn't really changed. When companies started shifting their workforce to a remote model, they took the tools they were already using (e.g. Slack, Zoom) and sent their employees home.
                </p>
                <p>
                  These tools are now being used in the same way they were used in the office, where most of the interaction happened in real-time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row four -->
          <div>
            
            <div>
              <div>
                <h3>We're moving towards a more distributed way of working.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row five -->
          <div>
            
            <div>
              <div>
                <p>
                  A quick chat is now another Zoom meeting in a long succession of meetings and a tap on the shoulder is yet another Slack message that pulls you away from what you were doing.
                  This firehose of messages and meetings is not sustainable as it leads to <a href="https://www.cnbc.com/2020/07/28/remote-work-burnout-is-growing-as-coronavirus-pandemic-stretches-on.html">anxiety</a>, <a href="https://www.fastcompany.com/90554935/the-red-flag-signs-you-may-be-burning-out-while-working-from-home">burnout</a> and <a href="https://www.forbes.com/sites/bryanrobinson/2020/09/06/how-remote-workers-can-recognize-burnout-and-6-actions-to-take/?sh=64da6cf14326">pressure</a> to always be connected.
                </p>
                <p>
                  With a <a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/covid-19-driving-lasting-change-for-business-practices-it-spending-8211-451-survey-60716654">majority of companies</a> stating that remote work is here to stay, <a href="https://socketsite.com/archives/2020/10/nearly-12-million-square-feet-of-vacant-office-space-in-s-f.html">office footprints</a> being reduced dramatically and tech companies like Twitter telling their staff that they can <a href="https://www.washingtonpost.com/technology/2020/10/01/twitter-work-from-home/?arc404=true">work from home forever</a> some of these changes will become the new normal. Most people agree that whatever happens, companies will be way more distributed than they were before the pandemic.
                  One thing is for sure -- the communication &amp; collaboration tools that exist today just don't cut it.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row six -->
          <div>
            
            <div>
              <div>
                <h3>We need tools for a distributed workforce.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row seven -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-2.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eight -->
          <div>
            
            <div>
              <div>
                <p>
                  <b>This is where <a href="http://rock.so/">Rock</a> comes in</b>. <a href="https://www.linkedin.com/in/liming/">Ming</a> and I started building Rock about a year ago to make it easier to shift towards a <a href="http://rock.so/about">more asynchronous way of working</a>. This way of working gives you <b>more control</b> over your workday, makes you <b>more productive</b> while <b>reserving face-to-face meetings</b> for the most important things. It's also ideally suited to a workforce that is more distributed.
                </p>
                <p>
                  With the right tools and mindset, working with your team becomes more like a <b>relay race</b>. Everybody knows what's going on, you can pick things up when you're ready, and work happens in a state of flow.
                </p>
              </div>
            </div>
            
          </div>

          

          <div>
            
            <div>
              <div>
                <p>
                  Rock combines real-time messaging and video calls with more asynchronous ways of communicating like <a href="http://rock.so/tasks">tasks</a>, <a href="http://rock.so/notes">notes</a>, and <a href="http://rock.so/files">files</a> and makes this available in <a href="http://rock.so/product">one space</a>. Because we combine these different types of communication, we make it easy for you to pick and choose the best way to interact with your team. We also work with Google Drive (and will work with Zoom and others soon) so it's easier to tap into your existing workflows.
                </p>
                <p>
                  When you <a href="http://rock.so/better-than-slack">compare Rock to Slack</a> you can easily see why we think Rock just works better for how work happens today.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row nine -->
          <div>
            
            <div>
              <p>
                <h3>Rock empowers anyone to work from anywhere</h3>
              </p>
            </div>
            
          </div>

          <!-- Row ten -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-3.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eleven -->
          <div>
            
            <div>
              <div>
                <p>
                  It's our mission to <b>build tools to empower anyone to work from anywhere</b>. When this happens - companies are more diverse, job opportunities are not limited by location and we all meet less, while doing more.
                </p>
                <p>
                  We have a lot more to say and lots more to build. If you want to join us on this journey to bring some much needed balance to the way we work, check out the video below or try out <a href="https://web.rock.so/?utm_source=website&amp;utm_medium=blog&amp;utm_campaign=hello">Rock</a> today.
                </p>
              </div>
            </div>
            
          </div>

          

          

          <section>
            <div>
              
          <!-- box card section -->
          <div>
            <div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/async.svg" alt="async"></p><h4>Product <br> details</h4>
                  <p>
                    Key features and more details about Rock.
                    <a href="http://rock.so/product">Read more</a>
                  </p>
                </div>

              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/recruiting/cross-org.svg" alt="async"></p><h4>How Rock <br> Works</h4>
                  <p>
                    Videos and walkthroughs to get you ready to Rock.
                    <a href="http://rock.so/how-rock-works">Read more</a>
                  </p>
                </div>
              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/zoom.svg" alt="async"></p><h4>Stop slacking, <br> start rocking.</h4>
                  <p>
                    Why Rock is better than Slack
                    <a href="http://rock.so/better-than-slack">Read more</a>
                  </p>
                </div>
              </div>
            </div>
          </div>
          <!-- box card section end -->


        </div>
      </section></div>

      
    </div></section></div>]]>
            </description>
            <link>http://rock.so/stopslacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279417</guid>
            <pubDate>Wed, 02 Dec 2020 18:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PTM – Page Table Manipulation from Usermode]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25279155">thread link</a>) | @DyslexicAtheist
<br/>
December 2, 2020 | https://back.engineering/01/12/2020/ | <a href="https://web.archive.org/web/*/https://back.engineering/01/12/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<div>

<hr>
<p>PDF Version (Best Version) can be downloaded here: <a href="https://githacks.org/_xeroxz/PTM/-/blob/master/PTM.pdf">PDF Download</a>.<br>
You can download the source from the open source repo here: <a href="https://githacks.org/_xeroxz/PTM">VDM Repo</a>.</p>

<hr>
<p>PTM is a Windows 10 C++ library that allows a programmer to manipulate all memory, physical, and virtual from user-mode. The project inherits an interface from VDM allowing the use of a physical memory read-write primitive to fuel this project. VDM is used solely to configure the page tables in such a way that PTM can manage them from user-mode. Once the page tables are configured for PTM VDM is no longer required. However, VDM can inherit an instance of PTM as a means to read and write physical memory. Both VDM and PTM work extremely well together and independently from each other.</p>

<hr>
<p>Page table manipulation is an extremely powerful primitive. One that allows groundbreaking projects to be created such as patching the kernel only in specific process-contexts, or mapping of a source process address space into a target process address space. PTM is a user-mode library that allows a programmer to manipulate page tables from user-mode on 64-bit Windows 10 systems. PTM does this by using VDM; a project designed to abuse vulnerable drivers exposing a physical memory read-write primitive (RWP) to elevate to arbitrary kernel execution. VDM is used to configure the page tables in such a way that they can be managed from user-mode without the need for VDM’s vulnerable driver being loaded into the kernel after initialization. PTM can then be used to get and set all levels of page table entries, translation linear virtual addresses from user-mode, map physical memory into virtual memory, and even create new page tables. PTM can also be used as a means to directly read and write physical memory, thus it can be used with VDM to leverage arbitrary kernel execution without the need of VDM’s vulnerable driver being loaded into the kernel.</p>

<hr>
<p>Paging is the concept of breaking memory into fixed-sized chunks called pages. Pages can be moved in and out of physical memory allowing for memory that is not accessed frequently to be moved to disk. In order for this to work, the CPU cannot directly interface with physical memory instead the CPU interfaces with virtual memory. Virtual addresses are translated to physical addresses using a set of tables called page tables. On a 64-bit system with the CPU in long mode, there are four layers of page tables: PML4(s), PDPT(s), PD(s), and lastly PT(s). All page tables are the same size (1000h bytes) unless configured otherwise. Each page table entry is eight bytes in size. This means that each table contains 512 entries (8 * 512 = 1000h). The last twelve bits of every virtual address is called the page offset and is an offset into a physical page. The page offset of a virtual address can be bigger than 12 bits depending on the paging structure configuration for a given virtual address. The length of the page offset field can be either 12 bits (physical page is 4kB), 21 bits (2MB physical page), or 30 bits (1GB page).</p>
<p><img src="https://imgur.com/IqB4B22.png"></p><p>In order to translate linear virtual addresses to linear physical addresses, the page tables must be traversed. As depicted in figure one, each virtual address space has its own PML4, the physical address of this table is stored in CR3.</p>

<hr>
<p>On Windows, the thread scheduler utilizes KPROCESS.DirectoryTableBase when scheduling threads. The KPROCESS structure is a substructure of the EPROCESS structure and contains DirectoryTableBase at offset 28h. A programmer using VDM can obtain the linear physical address of the PML4 of a process easily by DKOM’ing a desired process KPROCESS structure.</p>
<pre><code>kd&gt; dt !_KPROCESS ffffc38759d9e080
nt!_KPROCESS
   +0x000 Header           : _DISPATCHER_HEADER
   +0x018 ProfileListHead  : _LIST_ENTRY 
   +0x028 DirectoryTableBase : 0x00000001`15684000
   +0x030 ThreadListHead   : _LIST_ENTRY 
   +0x040 ProcessLock      : 0
   +0x044 ProcessTimerDelay : 0
   +0x048 DeepFreezeStartTime : 0
</code></pre><p>Once the physical address of the desired processes PML4 has been obtained the trick is interfacing with the paging structures. Although VDM allows reading and writing of physical memory, be aware that MmMapIoSpace cannot be used to map the paging structures into virtual memory. Drivers that use MmCopyMemory and ZwMapViewOfSection to interface with physical memory can however be used to directly manipulate the page tables. To properly support VDM which PTM inherits as a codebase, the project does not rely on the physical read and write primitive exposed from the driver. Instead PTM allocates its own set of page tables and inserts a PML4E into the current processes PML4 pointing at such tables. This allows a programmer to map physical memory at will into the current virtual memory address space, all from user-mode. In other words, once the tables are allocated and configured, there is no need for VDM anymore since the paging tables can be controlled entirely from user-mode.</p>

<hr>
<p>The translation look-aside buffer is a hardware-based cache that assists in translating linear virtual addresses to linear physical addresses. The TLB caches virtual to physical address translations, as well as other information like page access rights and cache type information. Although extremely important for efficiency, the TLB has made PTM an interesting challenge. For example, when physical memory is mapped into a virtual address space, page table entries will be inserted, or changed. This insertion or alteration of an existing page table entry may be of a cached entry in the TLB. This means that the effects applied to the page table entry will not be seen until the TLB entry for the given virtual page has been invalidated, along with the changes written to main memory. To counteract this, the CPU has an instruction that allows a programmer to invalidate a page table entry in the TLB’s cache. This instruction is called INVLPG and is a privileged instruction. It’s not something PTM can use since the library is designed to operate entirely from user-mode. Directly invalidating TLB is not the only way to invalidate entries. If a page fault occurs, the TLB invalidates entries for the given address that caused the fault (the address in CR2). This is an effective method for invalidating desired virtual addresses from user-mode but is extremely slow. Context switches do not inherently cause the TLB to flush, rather the PCID is changed to another PCID. This allows the TLB to retain entries from multiple address spaces and improve performance. However, yielding execution can invalidate TLB entries because the scheduler will reschedule the logical processor to execute somewhere else for some time, possibly filling the TLB with other entries and removing the ones that were previously cached.</p>
<h3 id="tlb_outrun"><a href="#tlb_outrun">TLB - Outrun</a></h3>
<hr>
<p>Although the TLB is an effective hardware-based cache, it cannot cache linear virtual addresses that have not been accessed before, this simple fact means a programmer can create a new linear virtual address every single time they would want to map a new physical page into virtual memory. This, however, is not a solid solution that works soundly on all modern CPUs. With the industry pushing forward with virtualization technology, the expansion of the TLB continues. Thus solely generating a new linear virtual address every time you would want to interface with a physical page is not a sound solution and is already unstable on most modern AMD chips. Instead combining this technique with other techniques is ideal.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>map_page(<span>void</span><span>*</span> addr) <span>-&gt;</span> <span>void</span><span>*</span>
{
	<span>++</span>pte_index;
	<span>if</span> (pte_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pde_index;
		pte_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pde_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pdpte_index;
		pde_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pdpte_index <span>&gt;</span> <span>511</span>)
		pdpte_index <span>=</span> <span>0</span>;

	<span>// insert paging table entries down here…
</span><span></span>	<span>//... (refer to PTM repo to see that code)...
</span><span></span>	<span>// returns the newly generated virtual address...
</span><span></span>	<span>return</span> <span>get_virtual_address</span>();
}
</code></pre></div><p>The code above generates a new linear virtual address that has not been accessed before. This linear virtual address points to the requests physical page in memory. This allows the programmer to circumvent the TLB by accessing new linear virtual addresses instead of trying to invalidate TLB entry of an existed and already cached page. This however has limitations since the code only provides 512^3 different possible virtual pages.</p>
<h3 id="tlb_benefit_of_the_doubt"><a href="#tlb_benefit_of_the_doubt">TLB - Benefit of The Doubt</a></h3>
<hr>
<p>Although outrunning the TLB is the fastest solution for mapping physical memory into virtual memory without needing to invalidate any TLB entries, it is not the most stable on modern hardware. Instead, a mixture of generating a new virtual address and an SEH try/except loop is preferred. By giving the new virtual address the benefit of the doubt that it has not been cached yet, an attempt to access the newly created page is performed. If the access is successful, the new linear virtual address is returned to the caller of ptm::ptm_ctx::map_page. However, if the access causes a page fault, the TLB invalidates the entries associated with this newly created linear virtual address. The except block then attempts to access the new page in a loop whilst yielding execution at each failure to access the new virtual address. This technique provides the most performant solution to dealing with the TLB from user-mode. This method guarantees that the linear virtual address generated is accessible before returning it to the caller.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>get_virtual_address() <span>const</span> <span>-&gt;</span> <span>void</span><span>*</span>
{
    <span>//...
</span><span></span>    
    <span>// start off by making sure that 
</span><span></span>	<span>// the address is accessible...
</span><span></span>	<span>__try</span>
	{
		<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value <span>=</span> <span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value;
		<span>return</span> new_addr.value;
	}

	<span>// if its not accessible then the
</span><span></span>	<span>// TLB just invalidated its entry...
</span><span></span>	<span>__except</span> (EXCEPTION_EXECUTE_HANDLER)
	{
		<span>// loop until this new address is accessible…
</span><span></span>		<span>// do not return until this new virtual
</span><span></span>		<span>// address is accessible....
</span><span></span>		<span>while</span> (true)
		{
			<span>// try again to access the page again 
</span><span></span>			<span>// and it should return...
</span><span></span>			<span>__try</span>
			{
				<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new…</code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://back.engineering/01/12/2020/">https://back.engineering/01/12/2020/</a></em></p>]]>
            </description>
            <link>https://back.engineering/01/12/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279155</guid>
            <pubDate>Wed, 02 Dec 2020 17:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vector 0.11 Release: K8s, ARC, and metrics collection]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25278771">thread link</a>) | @zhs
<br/>
December 2, 2020 | https://vector.dev/releases/0.11.0/ | <a href="https://web.archive.org/web/*/https://vector.dev/releases/0.11.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><li><div><p><a href="https://github.com/timberio/vector/pull/3099" target="_blank" title="View pull request..."><i></i> 3099</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Cleanup `list` command</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3190" target="_blank" title="View pull request..."><i></i> 3190</a></p></div><h4><span title="Filter to 'buffers' changes only">buffers</span><span title="Filter to 'sinks' changes only">sinks</span>Upgrade all VecBuffer sinks to allow setting `max_bytes`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3236" target="_blank" title="View pull request..."><i></i> 3236</a></p></div><h4><span title="Filter to 'socket source' changes only">socket source</span>Add max_length to UDP</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3151" target="_blank" title="View pull request..."><i></i> 3151</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'stdin source' changes only">stdin source</span>Instrument "stdin" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3241" target="_blank" title="View pull request..."><i></i> 3241</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Add received and invalid line events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3278" target="_blank" title="View pull request..."><i></i> 3278</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Provide error context on parse error</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3187" target="_blank" title="View pull request..."><i></i> 3187</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'kafka source' changes only">kafka source</span>Instrument "kafka" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3300" target="_blank" title="View pull request..."><i></i> 3300</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3317" target="_blank" title="View pull request..."><i></i> 3317</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'prometheus source' changes only">prometheus source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3315" target="_blank" title="View pull request..."><i></i> 3315</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'syslog source' changes only">syslog source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3264" target="_blank" title="View pull request..."><i></i> 3264</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'http source' changes only">http source</span>Add internal events for `http` source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3351" target="_blank" title="View pull request..."><i></i> 3351</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Make sourcetype templatable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3254" target="_blank" title="View pull request..."><i></i> 3254</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'statsd source' changes only">statsd source</span>Add events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3345" target="_blank" title="View pull request..."><i></i> 3345</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'docker source' changes only">docker source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3312" target="_blank" title="View pull request..."><i></i> 3312</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'splunk_hec source' changes only">splunk_hec source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/2913" target="_blank" title="View pull request..."><i></i> 2913</a></p></div><h4><span title="Filter to 'data_dog_metrics sink' changes only">data_dog_metrics sink</span>Add DataDog's `distribution` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3327" target="_blank" title="View pull request..."><i></i> 3327</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Add configuration for source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3337" target="_blank" title="View pull request..."><i></i> 3337</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field (#3300)</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3328" target="_blank" title="View pull request..."><i></i> 3328</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Add source configuration to Humio sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3356" target="_blank" title="View pull request..."><i></i> 3356</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logplex source' changes only">logplex source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3417" target="_blank" title="View pull request..."><i></i> 3417</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Add more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3421" target="_blank" title="View pull request..."><i></i> 3421</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'ansi_stripper transform' changes only">ansi_stripper transform</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3419" target="_blank" title="View pull request..."><i></i> 3419</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3418" target="_blank" title="View pull request..."><i></i> 3418</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3439" target="_blank" title="View pull request..."><i></i> 3439</a></p></div><h4><span title="Filter to 'aws_s3 sink' changes only">aws_s3 sink</span>Add additional canned ACLs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3434" target="_blank" title="View pull request..."><i></i> 3434</a></p></div><h4><span title="Filter to 'codecs' changes only">codecs</span><span title="Filter to 'console sink' changes only">console sink</span>Add "text" encoding for metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3436" target="_blank" title="View pull request..."><i></i> 3436</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Even more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3286" target="_blank" title="View pull request..."><i></i> 3286</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Rewrite parser, improve error handlings </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3476" target="_blank" title="View pull request..."><i></i> 3476</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'startup' changes only">startup</span><span title="Filter to 'shutdown' changes only">shutdown</span>Add events for starting, stopping, and reloading</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3502" target="_blank" title="View pull request..."><i></i> 3502</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add Heartbeat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3373" target="_blank" title="View pull request..."><i></i> 3373</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span><span title="Filter to 'compression' changes only">compression</span>Add support for gzip compression</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3475" target="_blank" title="View pull request..."><i></i> 3475</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span>Sync all data before finishing</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3521" target="_blank" title="View pull request..."><i></i> 3521</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3486" target="_blank" title="View pull request..."><i></i> 3486</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket source' changes only">socket source</span>Add and unify events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3523" target="_blank" title="View pull request..."><i></i> 3523</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'regex_parser transform' changes only">regex_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3553" target="_blank" title="View pull request..."><i></i> 3553</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'grok_parser transform' changes only">grok_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3598" target="_blank" title="View pull request..."><i></i> 3598</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add the ability to store pod labels flat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3602" target="_blank" title="View pull request..."><i></i> 3602</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Store pod labels flat by default, remove the switch</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3586" target="_blank" title="View pull request..."><i></i> 3586</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Add `file` label</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3582" target="_blank" title="View pull request..."><i></i> 3582</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add more `main` events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3593" target="_blank" title="View pull request..."><i></i> 3593</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3490" target="_blank" title="View pull request..."><i></i> 3490</a></p></div><h4><span title="Filter to 'wasm transform' changes only">wasm transform</span>Implement some UX improvements for WASM</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3610" target="_blank" title="View pull request..."><i></i> 3610</a></p></div><h4><span title="Filter to 'kuberentes platform' changes only">kuberentes platform</span>Adds new Helm template variable for podsLabels.</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3607" target="_blank" title="View pull request..."><i></i> 3607</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Multiline support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3577" target="_blank" title="View pull request..."><i></i> 3577</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tag_cardinality_limit transform' changes only">tag_cardinality_limit transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3554" target="_blank" title="View pull request..."><i></i> 3554</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'coercer transform' changes only">coercer transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3655" target="_blank" title="View pull request..."><i></i> 3655</a></p></div><h4><span title="Filter to 'http sink' changes only">http sink</span>Increase rate_limit_num to its maximum</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3690" target="_blank" title="View pull request..."><i></i> 3690</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span>Add a new options to control the auto concurrency limiter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3720" target="_blank" title="View pull request..."><i></i> 3720</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Fix TcpEventSent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3730" target="_blank" title="View pull request..."><i></i> 3730</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'swimlanes transform' changes only">swimlanes transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3699" target="_blank" title="View pull request..."><i></i> 3699</a></p></div><h4><span title="Filter to 'socket sink' changes only">socket sink</span>Add IPv6 supports</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3726" target="_blank" title="View pull request..."><i></i> 3726</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3782" target="_blank" title="View pull request..."><i></i> 3782</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Enhance checkpoint errors with file name</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3812" target="_blank" title="View pull request..."><i></i> 3812</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'reduce transform' changes only">reduce transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3809" target="_blank" title="View pull request..."><i></i> 3809</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'dedupe transform' changes only">dedupe transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3807" target="_blank" title="View pull request..."><i></i> 3807</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tokenizer transform' changes only">tokenizer transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3846" target="_blank" title="View pull request..."><i></i> 3846</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Support `summary` statistic</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3725" target="_blank" title="View pull request..."><i></i> 3725</a></p></div><h4><span title="Filter to 'datadog_metrics sink' changes only">datadog_metrics sink</span>Support datadog `distribution` metric </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3850" target="_blank" title="View pull request..."><i></i> 3850</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Regularize internal event messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3824" target="_blank" title="View pull request..."><i></i> 3824</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'security' changes only">security</span>Enable tls by default  for `papertrail` and `datadog_logs` sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3861" target="_blank" title="View pull request..."><i></i> 3861</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Improve retry error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3989" target="_blank" title="View pull request..."><i></i> 3989</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Accept more timestamp patterns in `to_timestamp`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4018" target="_blank" title="View pull request..."><i></i> 4018</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Include container_name in kubernetes_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3833" target="_blank" title="View pull request..."><i></i> 3833</a></p></div><h4><span title="Filter to 'gcp_stackdriver sink' changes only">gcp_stackdriver sink</span>Insert timestamp into stackdriver message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3778" target="_blank" title="View pull request..."><i></i> 3778</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>GraphQL client</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4075" target="_blank" title="View pull request..."><i></i> 4075</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_timestamp` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4090" target="_blank" title="View pull request..."><i></i> 4090</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `contains` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4092" target="_blank" title="View pull request..."><i></i> 4092</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `slice` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4093" target="_blank" title="View pull request..."><i></i> 4093</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `tokenize` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4020" target="_blank" title="View pull request..."><i></i> 4020</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add container_image and pod_node_name annotations</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4034" target="_blank" title="View pull request..."><i></i> 4034</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Emit warning on incomplete UDP sent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4170" target="_blank" title="View pull request..."><i></i> 4170</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `strip_ansi_escape_codes` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4188" target="_blank" title="View pull request..."><i></i> 4188</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha2` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4198" target="_blank" title="View pull request..."><i></i> 4198</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha3` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4215" target="_blank" title="View pull request..."><i></i> 4215</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>add field's value in warn message when failing to parse</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4236" target="_blank" title="View pull request..."><i></i> 4236</a></p></div><h4><span title="Filter to 'docker platform' changes only">docker platform</span>Added distroless-libc and distroless-static docker container bases</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4186" target="_blank" title="View pull request..."><i></i> 4186</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `parse_duration` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4032" target="_blank" title="View pull request..."><i></i> 4032</a></p></div><h4><span title="Filter to 'prometheus sink' changes only">prometheus sink</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4049" target="_blank" title="View pull request..."><i></i> 4049</a></p></div><h4><span title="Filter to 'auth' changes only">auth</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'aws service' changes only">aws service</span>Add EKS Web Identity Support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4191" target="_blank" title="View pull request..."><i></i> 4191</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Initial GraphQL topology</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4288" target="_blank" title="View pull request..."><i></i> 4288</a></p></div><h4><span title="Filter to 'console sink' changes only">console sink</span>Improve error handling</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4220" target="_blank" title="View pull request..."><i></i> 4220</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_number` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4383" target="_blank" title="View pull request..."><i></i> 4383</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Bidirectional source/transform/sink GraphQL types</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4429" target="_blank" title="View pull request..."><i></i> 4429</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Improve error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4412" target="_blank" title="View pull request..."><i></i> 4412</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span><span title="Filter to 'sinks' changes only">sinks</span>Option to specify `quantiles`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4037" target="_blank" title="View pull request..."><i></i> 4037</a></p></div><h4><span title="Filter to 'security' changes only">security</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>add TLS settings to influxdb_logs and influxdb_metrics sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4068" target="_blank" title="View pull request..."><i></i> 4068</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Add a tags configuration options to add user-defined tags</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4544" target="_blank" title="View pull request..."><i></i> 4544</a></p></div><h4><span title="Filter to 'debian platform' changes only">debian platform</span>Add vector user to adm in debian packaging</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/3557" target="_blank" title="View pull request..."><i></i> 3557</a></p></div><h4><span title="Filter to 'statsd sink' changes only">statsd sink</span>Support all socket types in statsd sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3032" target="_blank" title="View pull request..."><i></i> 3032</a></p></div><h4><span title="Filter to 'sinks' changes only">sinks</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'compression' changes only">compression</span>Add compression level</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4182" target="_blank" title="View pull request..."><i></i> 4182</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Allow using custom selectors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4406" target="_blank" title="View pull request..."><i></i> 4406</a></p></div><h4><span title="Filter to 'aws service' changes only">aws service</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'auth' changes only">auth</span>Support assume_role with EKS web identity</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4580" target="_blank" title="View pull request..."><i></i> 4580</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>Rename "identifier_fields" to "group_by"</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4579" target="_blank" title="View pull request..."><i></i> 4579</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>"concat_newline" strategy merges using newline</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4586" target="_blank" title="View pull request..."><i></i> 4586</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Advanced container filtering</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4428" target="_blank" title="View pull request..."><i></i> 4428</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Add `parse_url` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4164" target="_blank" title="View pull request..."><i></i> 4164</a></p></div><h4><span title="Filter to 'datadog_logs sink' changes only">datadog_logs sink</span><span title="Filter to 'networking' changes only">networking</span>Support datadog logs new HTTPS transport</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4385" target="_blank" title="View pull request..."><i></i> 4385</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span><span title="Filter to 'auth' changes only">auth</span>Basic auth support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4174" target="_blank" title="View pull request..."><i></i> 4174</a></p></div><h4><span title="Filter to 'datadog service' changes only">datadog service</span>Added region configuration parameter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4408" target="_blank" title="View pull request..."><i></i> 4408</a></p></div><h4><span title="Filter to 'windows platform' changes only">windows platform</span>Correctly handle service restart</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4557" target="_blank" title="View pull request..."><i></i> 4557</a></p></div><h4><span title="Filter to 'statsd source' changes only">statsd source</span>Add support for all socket types</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4647" target="_blank" title="View pull request..."><i></i> 4647</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'internal_metrics source' changes only">internal_metrics source</span>Updated internal metrics names to match standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4481" target="_blank" title="View pull request..."><i></i> 4481</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logfmt_parser transform' changes only">logfmt_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4701" target="_blank" title="View pull request..."><i></i> 4701</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span><span title="Filter to 'metrics' changes only">metrics</span>Add `namespace` to `Metric` </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4734" target="_blank" title="View pull request..."><i></i> 4734</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Force daemonset to redeploy when configmap is updated</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4581" target="_blank" title="View pull request..."><i></i> 4581</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Topology added/removed GraphQL subscriptions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4652" target="_blank" title="View pull request..."><i></i> 4652</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API host metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4733" target="_blank" title="View pull request..."><i></i> 4733</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span>annotate logs with query parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4751" target="_blank" title="View pull request..."><i></i> 4751</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Expose the performance related parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4735" target="_blank" title="View pull request..."><i></i> 4735</a></p></div><h4><span title="Filter to 'reload' changes only">reload</span>Resolve port conflict in sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4835" target="_blank" title="View pull request..."><i></i> 4835</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Add the ability to set conatiner ports at vector-agent Helm chart</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4480" target="_blank" title="View pull request..."><i></i> 4480</a></p></div><h4><span title="Filter to 'aws_ec2_metadata transform' changes only">aws_ec2_metadata transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4819" target="_blank" title="View pull request..."><i></i> 4819</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Adds optional file output to generator</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4831" target="_blank" title="View pull request..."><i></i> 4831</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add `namespace` option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4859" target="_blank" title="View pull request..."><i></i> 4859</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>display full error chain</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4884" target="_blank" title="View pull request..."><i></i> 4884</a></p></div><h4><span title="Filter to 'logdna sink' changes only">logdna sink</span>Support template syntax in hostname and tags field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4881" target="_blank" title="View pull request..."><i></i> 4881</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Add TLS and authentication options</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4873" target="_blank" title="View pull request..."><i></i> 4873</a></p></div><h4><span title="Filter to 'gcp_pubsub sink' changes only">gcp_pubsub sink</span>Add configurable endpoint</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4928" target="_blank" title="View pull request..."><i></i> 4928</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Kind/type for `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4836" target="_blank" title="View pull request..."><i></i> 4836</a></p></div><h4><span title="Filter to 'journald source' changes only">journald source</span>Restart journalctl on errors, save checkpoint on shutdown</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4998" target="_blank" title="View pull request..."><i></i> 4998</a></p></div><h4><span title="Filter to 'sources' changes only">sources</span>make scrape interval configurable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4945" target="_blank" title="View pull request..."><i></i> 4945</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Humanized formatting for `vector top` metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4958" target="_blank" title="View pull request..."><i></i> 4958</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Batch events processed total</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5002" target="_blank" title="View pull request..."><i></i> 5002</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Added batch subscriptions for component bytes and errors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5004" target="_blank" title="View pull request..."><i></i> 5004</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API batch support + tests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5018" target="_blank" title="View pull request..."><i></i> 5018</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API version + hostname queries</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4887" target="_blank" title="View pull request..."><i></i> 4887</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add PodIPs into Pod Metadata events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4999" target="_blank" title="View pull request..."><i></i> 4999</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>More debug info on more HTTP requests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5026" target="_blank" title="View pull request..."><i></i> 5026</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>add internal option to ignore missing files</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5034" target="_blank" title="View pull request..."><i></i> 5034</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Edited a few vector top error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4902" target="_blank" title="View pull request..."><i></i> 4902</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>compile-time program result type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5008" target="_blank" title="View pull request..."><i></i> 5008</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>support enum variants for function arguments</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5015" target="_blank" title="View pull request..."><i></i> 5015</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>use path arguments for `del` and `only_field` functions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5039" target="_blank" title="View pull request..."><i></i> 5039</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Renamed docker source to docker_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5053" target="_blank" title="View pull request..."><i></i> 5053</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>expressions no longer return an option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5074" target="_blank" title="View pull request..."><i></i> 5074</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Rename `version` -&gt; `versionString` in GraphQL schema</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5056" target="_blank" title="View pull request..."><i></i> 5056</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>undefined path or variable return null</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5016" target="_blank" title="View pull request..."><i></i> 5016</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add I/O (throughput) columns to `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5146" target="_blank" title="View pull request..."><i></i> 5146</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Expire checkpoints</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5153" target="_blank" title="View pull request..."><i></i> 5153</a></p></div><h4><span title="Filter to 'kafka source' changes only">kafka source</span>Include kafka metadata as optional keys</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4918" target="_blank" title="View pull request..."><i></i> 4918</a></p></div><h4><span title="Filter to 'sampler transform' changes only">sampler transform</span>Add rating by `index`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5095" target="_blank" title="View pull request..."><i></i> 5095</a></p></div><h4><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Support basic-auth credentials in endpoint configuation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5171" target="_blank" title="View pull request..."><i></i> 5171</a></p></div><h4><span title="Filter to 'api' changes only">api</span> Allow querying transform outputs on transform components</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4615" target="_blank" title="View pull request..."><i></i> 4615</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span>Expose internal metrics cardinality as a internal metric counter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5218" target="_blank" title="View pull request..."><i></i> 5218</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add test for component links</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5204" target="_blank" title="View pull request..."><i></i> 5204</a></p></div><h4><span title="Filter to 'loki sink' changes only">loki sink</span>Allow tenant_id to be templatable on loki sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5059" target="_blank" title="View pull request..."><i></i> 5059</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>improve arithmetic type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4699" target="_blank" title="View pull request..."><i></i> 4699</a></p></div><h4><span title="Filter to 'mongodb_metrics source' changes only">mongodb_metrics source</span>Renamed mongo metrics to new naming standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4681" target="_blank" title="View pull request..."><i></i> 4681</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `ConnectionOpen` gauge</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4806" target="_blank" title="View pull request..."><i></i> 4806</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sinks</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4833" target="_blank" title="View pull request..."><i></i> 4833</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sources</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4996" target="_blank" title="View pull request..."><i></i> 4996</a></p></div><h4><span title="Filter to 'shutdown' changes only">shutdown</span>Extend `Resource` to sources </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5048" target="_blank" title="View pull request..."><i></i> 5048</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Beautify reports of conflicting `Resource` usage</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5098" target="_blank" title="View pull request..."><i></i> 5098</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>add _total suffix to events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4922" target="_blank" title="View pull request..."><i></i> 4922</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Emit `FileOpen` in `file` sink and source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5183" target="_blank" title="View pull request..."><i></i> 5183</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Incorrect Log Level Message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5005" target="_blank" title="View pull request..."><i></i> 5005</a></p></div><h4><span title="Filter to 'config' changes only">config</span>Allow JSON and YAML config formats in addition to TOML</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5296" target="_blank" title="View pull request..."><i></i> 5296</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Enable TLS subscription connections in vector top</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5021" target="_blank" title="View pull request..."><i></i> 5021</a></p></div><h4><span title="Filter to 'pulsar sink' changes only">pulsar sink</span>introduce encoding schema and pulsar avro schema</h4></li></div></div>]]>
            </description>
            <link>https://vector.dev/releases/0.11.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278771</guid>
            <pubDate>Wed, 02 Dec 2020 17:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Materialize Raises a $32M Series B]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25277511">thread link</a>) | @austinbirch
<br/>
December 2, 2020 | https://materialize.com/materialize-series-b/ | <a href="https://web.archive.org/web/*/https://materialize.com/materialize-series-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today we <a href="https://www.prnewswire.com/news-releases/materialize-raises-40-million-to-simplify-streaming-data-with-sql-and-speed-up-real-time-analytics-301180777.html">announced</a> that we raised a $32M Series B round of funding led by Kleiner Perkins. This follows a $8.5m Series A last year led by Lightspeed Venture Partners, bringing our total funding to-date to a little over $40 million. With our Series B, <a href="https://www.kleinerperkins.com/people/bucky-moore/" target="_blank" rel="noopener noreferrer">Bucky Moore</a> joins <a href="https://lsvp.com/?team=ravi-mhatre/" target="_blank" rel="noopener noreferrer">Ravi Mhatre</a> on our board of directors.</p>
<p>At Materialize, we believe that at every business it will soon be essential for all information to be always up-to-date. Whether it’s delivering personalized experiences, accurately identifying fraud, building predictive AI, or discovering new business opportunities, the ability to run complex queries on multiple streams of data and keep their answers up to date is critical to making better decisions about the changing world around us.</p>
<p>While the past decade has seen a groundswell in the adoption of streaming platforms, they are still too difficult to use. Current systems require users to make tradeoffs between dumbing down their queries, waiting for hours-long batch ETL pipelines to finish, or building and orchestrating sprawling microservices. We believe users should not have to make these tradeoffs.</p>
<p>Materialize’s mission is to make queries against streaming data simple. We support industry standard SQL: write queries with multi-way joins, correlated subqueries, and complex aggregations, and we’ll keep the answers always up to date for you. In a world where “real-time” has become an empty buzzword, Materialize provides answers that are up to date within milliseconds. All of this comes in <a href="https://materialize.com/docs/install/" target="_blank" rel="noopener noreferrer">a single binary</a> that is easy to install, easy to use, and easy to deploy. With Materialize, users can get interactive and always-up-to-date answers about their changing data using only their existing SQL skills.</p>
<p>While Materialize is a young company, it is built on top of the award winning Timely Dataflow project, spanning almost a decade of cutting-edge research on stream processing led by my co-founder Frank McSherry. Starting from this solid foundation, $40 million dollars of capital gives us the resources to build the no-compromise streaming database that lets every developer build streaming applications.</p>
<p>With this new round of funding, we are well equipped to deliver on <a href="https://materialize.com/blog-roadmap/" target="_blank" rel="noopener noreferrer">an ambitious roadmap</a>, including a fully-managed cloud service with tiered storage and replication. We’re also excited to continue work on broadening the suite of SQL tools that we support, as well as investing in a SQL optimizer, performance and benchmarking work, and in making Materialize more resilient and battle-tested. If you’re interested in working on any of these challenges, Materialize <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">is hiring</a> across the board.</p>
<p>And finally, while it is exciting to build Materialize, it has been even more exciting to see how Materialize is being used to build applications that previously would have required months of development, using just a few simple SQL queries. If you’re as excited about Materialize as we are, we’d love for you to get involved. <a href="https://materialize.com/quickstart/" target="_blank" rel="noopener noreferrer">Download</a> and try Materialize, try <a href="https://materialize.com/docs/katacoda/?intro-wikipedia" target="_blank" rel="noopener noreferrer">a demo</a> in your browser, <a href="https://join.slack.com/t/materializecommunity/shared_invite/zt-jjwe1t45-klG9k7V7xibdtqA6bcFpyQ" target="_blank" rel="noopener noreferrer">join the community</a> and say hello, or <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">apply</a> to join our growing team today!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/materialize-series-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277511</guid>
            <pubDate>Wed, 02 Dec 2020 15:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rga: Ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz]]>
            </title>
            <description>
<![CDATA[
Score 627 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25277280">thread link</a>) | @angrygoat
<br/>
December 2, 2020 | https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/ | <a href="https://web.archive.org/web/*/https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small><time datetime="2019-06-16T00:00:00.000Z">Jun 16, 2019</time> • <a href="https://github.com/phiresky/blog/commits/master/posts/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg.md">Last Update <time datetime="2019-06-16T00:00:00.000Z">Oct 21, 2019</time></a></small></p><p><a href="https://github.com/phiresky/ripgrep-all">rga</a> is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and enables it to search in pdf, docx, sqlite, jpg, zip, tar.*, movie subtitles (mkv, mp4), etc.</p><p><a href="https://github.com/phiresky/ripgrep-all"><img src="https://img.shields.io/badge/repo-github.com%2Fphiresky%2Fripgrep--all-informational.svg" title=""></a>
<a href="https://crates.io/crates/ripgrep-all"><img src="https://img.shields.io/crates/v/ripgrep-all.svg" title=""></a>
<a href="https://www.reddit.com/r/rustjerk/top/?sort=top&amp;t=all"><img src="https://img.shields.io/badge/concurrency-fearless-success.svg" title=""></a></p><h2 id="examples">Examples</h2><h3 id="pdfs">PDFs</h3><p>Say you have a large folder of papers or lecture slides, and you can’t remember which one of them mentioned <code>GRU</code>s. With rga, you can just run this:</p><div><pre>~$ rga "GRU" slides/
<span>slides/2016/winter1516_lecture14.pdf</span>
Page 34:   <span></span><span>GRU</span>                            LSTM
Page 35:   <span></span><span>GRU</span>                            CONV
Page 38:     - Try out <span></span><span>GRU</span>-RCN! (imo best model)

<span>slides/2018/cs231n_2018_ds08.pdf</span>
Page  3: ●   CNNs, GANs, RNNs, LSTMs, <span></span><span>GRU</span>
Page 35: ● 1) temporal pooling 2) RNN (e.g. LSTM, <span></span><span>GRU</span>)

<span>slides/2019/cs231n_2019_lecture10.pdf</span>
Page 103:   <span></span><span>GRU</span> [Learning phrase representations using rnn
Page 105:    - Common to use LSTM or <span></span><span>GRU</span>

</pre></div><p>and it will recursively find a string in pdfs, including if some of them are zipped up.</p><p>You can do mostly the same thing with <a href="https://pdfgrep.org/"><code>pdfgrep -r</code></a>, but you will miss content in other file types and it will be much slower:</p><div><p>Searching in 65 pdfs with 93 slides each</p><div><div><svg width="600" height="200" viewBox="0 0 600 200" version="1.1"><defs><clipPath id="recharts2-clip"><rect x="105" y="5" height="160" width="490"></rect></clipPath></defs><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="165" x2="595" y2="165"></line><g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="171" x2="105" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="105" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="105" dy="0.71em">0</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="227.5" y1="171" x2="227.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="227.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="227.5" dy="0.71em">5</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="350" y1="171" x2="350" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="350" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="350" dy="0.71em">10</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="472.5" y1="171" x2="472.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="472.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="472.5" dy="0.71em">15</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="595" y1="171" x2="595" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="595" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="595" dy="0.71em">20</tspan></text></g></g></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="105" y1="5" x2="105" y2="165"></line><g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="31.666666666666668" x2="105" y2="31.666666666666668"></line><text type="category" width="100" orientation="left" height="160" x="97" y="31.666666666666668" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">pdfgrep</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="85" x2="105" y2="85"></line><text type="category" width="100" orientation="left" height="160" x="97" y="85" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (first run)</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="138.33333333333334" x2="105" y2="138.33333333333334"></line><text type="category" width="100" orientation="left" height="160" x="97" y="138.33333333333334" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (subsequent runs)</tspan></text></g></g></g><g><g><g><path name="pdfgrep" fill="#8884d8" width="469.41999999999996" height="42" x="105" y="10.333333333333334" radius="0" d="M 105,10.333333333333334 h 469.41999999999996 v 42 h -469.41999999999996 Z"></path></g><g><path name="rga (first run)" fill="#8884d8" width="72.27500000000003" height="42" x="105" y="63.66666666666667" radius="0" d="M 105,63.66666666666667 h 72.27500000000003 v 42 h -72.27500000000003 Z"></path></g><g><path name="rga (subsequent runs)" fill="#8884d8" width="2.2539999999999907" height="42" x="105" y="117" radius="0" d="M 105,117 h 2.2539999999999907 v 42 h -2.2539999999999907 Z"></path></g></g></g></svg><div><ul><li><svg width="14" height="14" style="display:inline-block;vertical-align:middle;margin-right:4px" viewBox="0 0 32 32" version="1.1"><path stroke="none" fill="#8884d8" d="M0,4h32v24h-32z"></path></svg><span>run time (seconds, lower is better)</span></li></ul></div></div></div></div><p>On the first run rga is mostly faster because of multithreading, but on subsequent runs (with the same files but any regex query) rga will cache the text extraction, so it becomes almost as fast as searching in plain text files. All runs were done with a warm FS cache.</p><h3 id="other-files">Other files</h3><p>rga will recursively descend into archives and match text in every file type it knows.</p><p>Here is an example directory with different file types:</p><pre><code>demo
├── greeting.mkv
├── hello.odt
├── hello.sqlite3
└── somearchive.zip
    ├── dir
    │&nbsp;&nbsp; ├── greeting.docx
    │&nbsp;&nbsp; └── inner.tar.gz
    │&nbsp;&nbsp;     └── greeting.pdf
    └── greeting.epub</code></pre><p>(see the actual directory <a href="https://github.com/phiresky/ripgrep-all/tree/master/exampledir/demo">here</a>)</p><div><pre>~$ rga "hello" demo/

<span>demo/greeting.mkv</span>
metadata: chapters.chapter.0.tags.title="Chapter 1: <span></span><span>Hello</span>"
00:08.398 --&gt; 00:11.758: <span></span><span>Hello</span> from a movie!

<span>demo/hello.odt</span>
<span></span><span>Hello</span> from an OpenDocument file!

<span>demo/hello.sqlite3</span>
tbl: greeting='<span></span><span>hello</span>', from='sqlite database!'

<span>demo/somearchive.zip</span>
dir/greeting.docx: <span></span><span>Hello</span> from a MS Office document!
dir/inner.tar.gz: greeting.pdf: Page 1: <span></span><span>Hello</span> from a PDF!
greeting.epub: <span></span><span>Hello</span> from an E-Book!
</pre></div><p>It can even search jpg / png images and scanned pdfs using OCR, though this is disabled by default since it is not useful that often and pretty slow.</p><div><pre>~$ # find screenshot of crates.io
~$ rga crates ~/screenshots --rga-adapters=+pdfpages,tesseract
<span>screenshots/2019-06-14-19-01-10.png</span>
<span></span><span>crates</span>.io I Browse All <span></span><span>Crates</span>  Docs v
Documentation Repository Dependent <span></span><span>crates</span>

~$ # there it is!
</pre></div><h2 id="setup">Setup</h2><p>Linux, Windows and OSX binaries are available in GitHub releases. See <a href="https://github.com/phiresky/ripgrep-all#installation">the readme</a> for more information.</p><p>For Arch Linux, I have packaged <code>rga</code> in the AUR: <a href="https://aur.archlinux.org/packages/ripgrep-all/"><code>yay -S ripgrep-all</code></a></p><h2 id="technical-details">Technical details</h2><p>The code and a few more details are here: <a href="https://github.com/phiresky/ripgrep-all">https://github.com/phiresky/ripgrep-all</a></p><p><code>rga</code> simply runs ripgrep (<code>rg</code>) with some options set, especially <code>--pre=rga-preproc</code> and <code>--pre-glob</code>.</p><p><code>rga-preproc [fname]</code> will match an <span>"<!-- -->adapter<!-- -->"</span> to the given file based on either it’s filename or it’s mime type (if <code>--rga-accurate</code> is given). You can see all adapters currently included in <a href="https://github.com/phiresky/ripgrep-all/tree/master/src/adapters">src/adapters</a>.</p><p>Some rga adapters run external binaries to do the actual work (such as pandoc or ffmpeg), usually by writing to stdin and reading from stdout. Others use a Rust library or bindings to achieve the same effect (like sqlite or zip).</p><p>To read archives, the <code>zip</code> and <code>tar</code> libraries are used, which work fully in a streaming fashion - this means that the RAM usage is low and no data is ever actually extracted to disk!</p><p>Most adapters read the files from a <a href="https://doc.rust-lang.org/std/io/trait.Read.html">Read</a>, so they work completely on streamed data (that can come from anywhere including within nested archives).</p><p>During the extraction, rga-preproc will compress the data with ZSTD to a memory cache while simultaneously writing it uncompressed to stdout. After completion, if the memory cache is smaller than 2MByte, it is written to a <a href="https://docs.rs/rkv/0.9.6/rkv/">rkv</a> cache. The cache is keyed by (adapter, filename, mtime), so if a file changes it’s content is extracted again.</p><h2 id="future-work">Future Work</h2><ul><li>I wanted to add a photograph adapter (based on object classification / detection) for fun, so you can grep for <span>"<!-- -->mountain<!-- -->"</span> and it will show pictures of mountains, like in Google Photos. It worked with <a href="https://pjreddie.com/darknet/yolo/">YOLO</a>, but something more useful and state-of-the art <a href="https://github.com/aimagelab/show-control-and-tell">like this</a> proved very hard to integrate.</li><li>7z adapter (couldn’t find a nice to use Rust library with streaming)</li><li>Allow per-adapter configuration options (probably via env (RGA_ADAPTERXYZ_CONF=json))</li><li>Maybe use a different disk kv-store as a cache instead of rkv, because I had some <a href="https://github.com/phiresky/ripgrep-all/blob/05835c1c42bc3575023a81e5494c5530078730fc/src/preproc_cache.rs#L30">weird problems</a> with that. SQLite is great. All other Rust alternatives I could find don’t allow writing from multiple processes.</li><li>Tests!</li><li>There’s some more (mostly technical) todos in the code I don’t know how to fix. Help wanted.</li><li>Other <a href="https://github.com/phiresky/ripgrep-all/issues">open issues</a></li></ul><ul><li><a href="https://pdfgrep.org/">pdfgrep</a></li><li><a href="https://gist.github.com/phiresky/5025490526ba70663ab3b8af6c40a8db">this gist</a> has my proof of concept version of a caching extractor to use ripgrep as a replacement for pdfgrep.</li><li><a href="https://gist.github.com/ColonolBuendia/314826e37ec35c616d70506c38dc65aa">this gist</a> is a more extensive preprocessing script by <a href="https://github.com/ColonolBuendia">@ColonolBuendia</a></li><li><a href="https://github.com/wofr06/lesspipe">lesspipe</a> is a tool to make <code>less</code> work with many different file types. Different usecase, but similar in what it does.</li></ul></div></div>]]>
            </description>
            <link>https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277280</guid>
            <pubDate>Wed, 02 Dec 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Netflix]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25277041">thread link</a>) | @leopold_a
<br/>
December 2, 2020 | https://www.forourposterity.com/against-netflix/ | <a href="https://web.archive.org/web/*/https://www.forourposterity.com/against-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It has become fashionable to lambast big tech corporations and social media sites, the Facebooks and Twitters and Googles, blaming them for a litany of social ills. Seemingly escaping this ire has been the—in my view—most pernicious by far: Netflix.</p><p>Simply put, Netflix (and its imitators) produce too many TV shows that are too good—and too easy to binge. Consequently, too many great minds spend their time watching TV rather than thinking and inventing and creating.</p><h2 id="the-greatness-we-lose">The Greatness We Lose</h2><p>Consider the writer Matthew Yglesias. He just wrote an excellent <a href="https://www.amazon.com/One-Billion-Americans-Thinking-Bigger/dp/0593190211/">book</a>, which partially inspired my <a href="https://www.forourposterity.com/canada-and-mexico-should-join-the-union/">last post</a>. Recently, Yglesias <a href="https://web.archive.org/web/20200912220900/https://twitter.com/mattyglesias/status/1304904789055156225">tweeted</a>:</p><blockquote>Someone asked … “how’d you get this book written without taking time off work?” and the dumb boring answer was basically “didn’t watch much TV for six months.”</blockquote><p>He adds,</p><blockquote>I am perfectly aware that the difference between times when I’m most productive &amp; creative and times when I’m not is how much of the week I waste on watching television, yet tonight I’m almost certainly going to finish season two of Hannibal.</blockquote><p>Yglesias, turn off the TV! Write more books instead! Heck, write more tweets, if you prefer!</p><p>Just think of all the original ideas Yglesias could be contributing if he continued to abstain from watching TV. Of them we are being robbed. That is an epic <a href="https://applieddivinitystudies.com/murder-of-wilbur/">tragedy</a>.</p><h2 id="why-modern-tv-is-different">Why Modern TV Is Different</h2><p>I don’t mean to pick on Yglesias. In fact, I don’t blame him. Modern shows are just too good. As a result, it’s become accepted—even the norm—among elite, educated classes to watch inordinate amounts of TV.</p><p>Modern shows are different from classic TV in two key ways. First, they are much more engrossing. Netflix shows are just on a different level in terms of quality than what TV once offered. Second, they are bingeable. Instead of tuning in for an hour each week, Netflix encourages viewers to enter the dark hole of watching episode after episode after episode. This becomes a vicious cycle. Viewers binge late into the night, lose sleep, and then don’t feel energetic enough to do much in their free time the next day besides…watching more Netflix.</p><p>Movies were always pretty engrossing. But the boundless quantity of content on Netflix—as well as their deliberate addictiveness—puts it on a different level.</p><p>To be sure, the broad America public has always watched <a href="https://www.theatlantic.com/technology/archive/2018/05/when-did-tv-watching-peak/561464/">extraordinary amounts</a> of television, in particular retirees. For them, the improved quality of modern shows is surely an upgrade. But I do think Netflix has distinctly changed the culture around TV among the young and educated.</p><p>As an undergraduate at Columbia, it was extremely common for students to spend much of their free time engorging themselves on Netflix. Many were caught in that maelstrom of bingeing, losing sleep, and then bingeing more. What was most shocking was this practice’s sheer acceptability. Watching dozens of hours of Netflix a week wasn’t something out of the ordinary, something people were embarrassed by. Rather, Netflix bingeing was a core part of the culture, something people would make countless memes about and base their identities on. Amazingly, people’s chief complaint was often that they had exhausted all of Netflix’s content (how do you even do that?!).</p><p>Yglesias got his start blogging in college. Would the next Yglesias be able to do the same? Or would his free time and energy instead be sucked up by the latest, ever-more addictive Netflix show? What a loss for civilization that would be.</p><h2 id="for-a-new-temperance-movement">For a New Temperance Movement</h2><p>Again, I don’t blame the students. I am victim to the same human follies. But I do blame the culture we have created. We don’t tell our bright young minds that it’s alright to waste away your days drinking or abusing drugs. Sure, some end up doing so regardless, but the cultural tabu keeps those impulses in check. Why do we tell them it’s alright to waste away your days watching Netflix?</p><p>Indeed, there has been considerable pushback against video games, which for some are a similar time suck. While many still struggle, this cultural pushback has kept video games in check. At least among the educated classes, Netflix and its imitators have become the far greater time suck.</p><p>For those who can enjoy TV in moderation—great. Modern shows are often meaningful art worth appreciating. The problem with modern TV is that for many, it is closer to alcoholism than a one-off drink. One you watch that first episode—take that first drink—it often doesn’t stay at one episode—as it doesn’t stay at one drink.</p><p>Perhaps it is time for a modern TV-temperance movement. It would be worth encouraging moderation in TV consumption in general. But given that many TV habits resemble alcoholism, it may be appropriate to take a more radical approach: advocating TV-abstinence. Although complete avoidance of TV may be difficult at first, once it becomes a habit, I think most wouldn’t miss much. But they would enjoy an abundance of reclaimed time and energy. And the rest of us would enjoy the wonderful works they create with that newfound time and energy.</p><h2 id="brains-in-vats">Brains in Vats</h2><p>The culture we establish around Netflix matters not just for the present, but for what comes next. As entertainment technology relentlessly advances, are we destined to become brains in vats, nominally pumped full of artificial bliss but doomed to lives of passivity and complacency?</p><p>Look, if that’s what the Europeans want to do, they should go for it. But part of what makes America special is a certain harshness—first embodied in the Puritans and their quest to settle America’s unforgiving wilderness. Great achievements, new ideas, ingenious inventions emerge from a culture that prizes travail and perseverance, not one that prioritizes comfort and ephemeral satisfaction.</p><p>A blithe acceptance of Netflix has insidiously infiltrated our culture. We should push back. Let’s look to the stars, not the next episode.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to For Our Posterity</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
              <h2><span id="cove-count"></span> Comments</h2>

    <p>Sign in or become a For Our Posterity member to join the conversation.<br>
    Just enter your email below to get a log in link.</p>
    

  


  


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.forourposterity.com/against-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277041</guid>
            <pubDate>Wed, 02 Dec 2020 15:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Escape the Modern Rat Race]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25276844">thread link</a>) | @durmonski
<br/>
December 2, 2020 | https://durmonski.com/psychology/escape-the-modern-rat-race/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/escape-the-modern-rat-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2020-11-30T06:06:37+00:00">30/11/2020</time></p>
<p><em>The worst thing about our modern culture is the growing ignorance towards what’s really valuable in the world. From an early age, we join a long-distance rat race where the competition is measured not by who we are, but by what we own. Therefore, the desire for material possessions and attention from our peers become our chief goals. Survival, it seems to us, is based on how well we portray our qualities to the outside world – even if we don’t necessarily possess them.</em></p>



<p>Living a normal life according to our society, even if we don’t always admit it, is tightly connected to the acquisition of funds. One of the most talked-about traits promoted by institutions regardless of our location is the value of money. Of course, this is not directly mentioned by the media outlets or by our neighbors, it’s beautifully camouflaged by what money can buy.</p>



<p>As soon as we understand that all breathing humans worship money and stuff, the sooner we start to desire <a href="https://durmonski.com/psychology/why-we-hate-cheap-things/" target="_blank" aria-label="luxury items (opens in a new tab)" rel="noreferrer noopener">luxury items</a>. Not so much because they are useful, but because these fancy goods make us look like we are more.</p>



<p>And so it happens, that directly after we come into being, these values and principles get embedded in our brains and later influence our decisions. We want better and more beautiful things. But most of all, we want others to <em>see</em> that we actually own these marvelous objects.</p>



<p>This game of competitive signaling has become unbearable only recently. When the number of available choices vastly increased and the way we communicate with others (compare ourselves with them) significantly improved.</p>



<p>In this post, we’ll look at why we’re stuck in this competitive rat race. Why the desire to acquire new things is never tamed and what we can do about it. </p>



<p>By bringing awareness to the problems, I want to liberate more people from the destructive components of this never-ending race to the bottom.</p>







<h2>What is Rat Race Life?</h2>



<p>A modern rat race categorizes as an endless pursuit – often quite exhausting – where you earn small rewards by conspicuous behavior reinforced by acquiring more financial gains or possessions – or both. However, these gains never feel satisfactory enough. As new things constantly appear on the horizon – new products and new competitors who are also part of the race – the only way we can stay ahead of the curve is by constantly investing resources in this rivalry.</p>



<p>In a way, participating in this vain competition is required. After all, our survival is tightly related to the tools, the resources we personally own, plus the relationship we form with others. That’s why we stay devoted to the race – because deep inside, our genes are focused on survival and replication.</p>



<p>That’s the general concept of the modern rat race. Or in the words of Tyler Durden, the protagonist in the masterpiece Fight Club, “We buy things we don’t need with money we don’t have to impress people we don’t like.” But to really grasp the reasons we commit to a life of struggle over resources, we need to go a step deeper.</p>



<p>Let’s unpack the modern rat race ideology further…</p>







<h2>Why and How The Rat Race Was Formed?</h2>



<p>The first reference of the expression rat race was used in the 1930s during aviation training. As stated by Popular Science magazine in 1941, ‘A rat race is … a simple game of “follow the leader.'”<span id="easy-footnote-1-12306"></span><span><a href="#easy-footnote-bottom-1-12306" title="&amp;#8220;<a aria-label=&quot;Rat-race (opens in a new tab)&quot; rel=&quot;noreferrer noopener nofollow&quot; href=&quot;https://www.etymonline.com/search?q=rat+race&quot; target=&quot;_blank&quot; class=&quot;ek-link&quot;>Rat-race</a>&amp;#8220;. Online Etymology Dictionary."><sup>1</sup></a></span> Or in other words, the expression meant that the trainee fighter pilot had to copy all the actions performed by the senior pilot. </p>



<p>A decade later, the term changed its original meaning.</p>



<p>Nowadays, the expression is more closely related to how we live our lives day by day. We don’t simply “follow the leaders”, we compete with them. We want to be like them. To have what they have and to eventually beat them in the game of resources.</p>



<p>This fierce rivalry for wealth is inspired and fueled by three main motivators:</p>







<h3>1. The Genes Want to Survive</h3>



<p>We, our actions, are highly influenced by the desires of the microorganisms that form our bodies – our genes. According to Richard Dawkins, the author of <a aria-label="The Selfish Gene (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/the-selfish-gene/" target="_blank">The Selfish Gene</a>, “the main goal of the body is to propagate copies of the genes which ride inside it.” To achieve this feat, the body is required to strictly follow two commands: survive and replicate.</p>



<p>There is nothing more important for the genes. We live to live another day and to copy ourselves.</p>







<h3>2. Universal Recognition of Money</h3>



<p>Different religions exist in different countries but we are all loyal to one and only lord – the money lord. Or as Yuval Noah Harari writes in his bestseller, <a aria-label="Sapiens (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/sapiens-a-brief-history-of-humankind/" target="_blank">Sapiens</a>, “Money is the most universal and most efficient system of mutual trust ever devised.”</p>



<p>During the years of our existence, we form a love-hate relationship with money. On the one hand, we hate it when we see people who are willing to do whatever it takes to earn more and to gain more power. We have movies, literature, songs, and words that mock the aggressive pursuit of more cash.</p>



<p>On the other hand, however, we adequately recognize the need for this resource. Since money is the currency that can literally save our lives from misery and decay, we have no other choice but to obey some sort of rules to gain more of this finite resource. Even so, while it surely exists, our desire to get more money is usually not directly expressed. Throughout our lives, we learn to successfully decoy our desire for wealth. That’s actually why money is a taboo subject.</p>







<h3>3. Technological Advancements</h3>



<p>High-tech gizmos and the internet greatly exceeded our expectations. These two innovations enabled us to connected like no other species.</p>



<p>At first, we used the Wi-Fi connection to send emails and to communicate better. Now, we use it to showcase our self-worth and to advertise our qualities to the whole world. All of this, done with the underlying desire to feel more desirable by others.</p>







<hr>



<p>The three above-mentioned notes can be portrayed in the following way:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg" alt="the-modern-rat-race" srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg"><figcaption>The cravings for money, survival, being appreciated by others is something we don’t verbally express. We show it by the stuff we obtain and the things we say/do.</figcaption></figure>







<p>Our inner eagerness to survive forces us to obtain money. And cash, supports our existence. But for most, the comfort of holding large chunks of capital in the bank is not enough. We also want to be seen as wealthy.</p>



<p>After all, just owning money is not enough to increase your chances of survival – meeting new friends that will help you along the way and also potential mates. That’s why, we’re also eager to parade with what we have.&nbsp;&nbsp;</p>



<p>Just as the peacock spreads its feathers to show its impeccable genes, we, through our actions and the things we acquire, show the world our features hoping that they’ll pick us. This our way of saying to others, “Look at me, my qualities and traits are so good that I can afford to spend $50,000 on a car. You should want to hang around with me.”</p>



<p>Our possessions are an advertisement, a way of showing off. They reinforce the image we desire to portray. And by going around and talking about ourselves, we want to signal to others – in a non-verbal way in most of the cases – why we are a worthy choice.</p>



<p>This is also called competitive signaling.</p>







<h2>What is Competitive Signaling?</h2>



<p>The way you spend your money can say a lot about how you want to position yourself in modern competition. </p>



<p>If you think carefully about everything before you buy it, and you’re not interested in high-end goods, your income is either average or you’re careless of what others think of you. In contrast, if you focus primarily on obtaining premium goods, you’re probably either rich or you want to be perceived as rich.<span id="easy-footnote-2-12306"></span><span><a href="#easy-footnote-bottom-2-12306" title="The last two are completely different things."><sup>2</sup></a></span></p>



<p>Thorstein Veblen, an American economist and sociologist, argued that the demand for luxury goods is driven largely by a single social motive: “flaunting one’s wealth.”</p>



<p>For example, Nissan is a car. It’s an average, not-flashy, automobile that will help you go from point A to point B, faster. Porsche, on the other hand, is an art museum on wheels. It can also get you from point A to point B, but while driving around town in this beast on wheels you radiate a completely different vibe. You present yourself as a modern, high-paid individual with taste and ambition. Figuratively speaking, the amount of cash that each of them has in the bank – the person owning a Nissan and the person owning a Porsche – can be exactly the same. On the outside though, they appear quite different.&nbsp;&nbsp;</p>



<p>The more interesting thing to consider, if say the individuals in the above example really do have the same amount of cash stashed, is how they approach buying domestic goods – a set of dishes, blankets, or say cleaning products. Since these goods are not to be seen by others, they both, even the person owning a sports car, will most probably end up getting the same cheap things.<span id="easy-footnote-3-12306"></span><span><a href="#easy-footnote-bottom-3-12306" title="This, of course, says a lot more things about their personality. For example, you can have an average income and still get a flashy car. But then, the things that are not visible by others will probably be average to compensate. Conversely, if you&amp;#8217;re <em>really</em> rich, you&amp;#8217;ll probably buy luxury domestic goods, too."><sup>3</sup></a></span></p>



<p>With this, we can conclude that the available products on the market are a mix of personal value and signaling value.</p>



<p>The car you have is simultaneously a way to move faster in the city and also a representation of your hierarchy in the world. Each product on the market, nowadays, comes with these qualities.</p>



<p>And if we can put this in a graph, it will look something like this:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg" alt="luxury-goods-vs-useful-goods" srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg"><figcaption>Above the line the products don’t get more useful, they do something else. Luxury goods help you display, publicly, your wealth. The “scientific term” for this is conspicuous consumption.<span id="easy-footnote-4-12306"></span><span><a href="#easy-footnote-bottom-4-12306" title="<a aria-label=&quot;Conspicuous consumption (opens in a new tab)&quot; href=&quot;https://en.wikipedia.org/wiki/Conspicuous_consumption&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener nofollow&quot; class=&quot;ek-link&quot;>Conspicuous consumption</a>, Thorstein Veblen"><sup>4</sup></a></span></figcaption></figure>







<p>At some point, certain products become a beacon of your self-worth. If you want to signal to others that you have more money, which internally means that you want to show that you’re smarter, slimmer, better than others in a way, you’ll eventually lean towards goods that are considered a luxury.</p>



<p>The extra you’re paying for a Porche, for example, has more to do with the message you want to convey to others, not with the usefulness of the product itself.<span id="easy-footnote-5-12306"></span><span><a href="#easy-footnote-bottom-5-12306" title="We all know that Porche is certainly a great vehicle. But there are still cheaper alternatives that will do the same job in terms of helping you move from point A to point B."><sup>5</sup></a></span></p>



<p>You might be …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/psychology/escape-the-modern-rat-race/">https://durmonski.com/psychology/escape-the-modern-rat-race/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/psychology/escape-the-modern-rat-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276844</guid>
            <pubDate>Wed, 02 Dec 2020 14:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Cybersecurity Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25276033">thread link</a>) | @atum47
<br/>
December 2, 2020 | https://eloeffler.gitlab.io/eloeffler/proto-vcser/ | <a href="https://web.archive.org/web/*/https://eloeffler.gitlab.io/eloeffler/proto-vcser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="indexgreeter">
    
<p>    Marwin Mueller, age 65, owns Spass GmbH. An SME in Luzern which has an annual turnover of close to 1.000.000 CHF and an annual profit of 200.000 CHF.  </p>
<p>    Spass GmbH has been operating in the hospitality industry for the last 30 years and is managing renouned hotels and villas in the Luzern Lake area.  </p>
<p>    Anne Kingston, age 29, is Marwins assistant and accountant. She has joined a year back and during her interactions, she mentioned to Marwin that she is a single mom of a six year old boy named Ryan.  </p>
<p>    Anne is a pleasant and helping personality. She likes plants and playing video games.  </p>
<p>    Marwin is very proud of his business achievements and sometimes acts as an arrogant boss. He is a bit insensitive to kids, due to his experiences. In general, he gets along with Anne and they form a great team at Spass. In the past year, Anne took over most of the office tasks at Spass. She is technology savvy and Marwin likes this quality of Anne's over his other staff.  </p>
<p>    Marwin and Anne worked on important digital initiatives at Spass like listing its properties on booking portals, creating their own website, launching social media accounts and enabling online banking at UBC Bank in Luzern.  </p>
<p>    This gave Marwin an edge over his competitors and Spass has seen a 30% increase in revenues and profits this year.  </p>
<p>    Today, Marwin remembers that two weeks back, Anne came to him and wanted a 1 week vacation to spend time with her son Ryan on occasion of his birthday.  </p>
<p>    Once again, Marwin and Anne had arguments on Anne's vacations in peak season and Marwin blamed Ryan for this.  At the end, Marwin reluctantly agreed to the holidays.</p>
<p>Since then, Anne did not turn up for work. She is not reachable on her mobile and her house is locked.</p>
<p>Marwin has just found that his bank account is debited with 2.000 CHF every day since Anne left.</p>
<p>Marwin has no idea what is happening and he is worried. Therefor, as trusted friends, he has requested that you come here and help him.</p>
<p>Marwin believes it is not a good idea to report the incident immediately to the police or bank as it can damage his reputation.</p>
<p>Now it's Friday. It's 7pm and the UBC Bank is already closed for the weekend.</p>
<p>You need to analyze the gaps Anne might have in her Cybersecurity awareness and secure the Online Banking to stop the money transfers.</p>
<p>Also, try to find out where Anne might be.</p>
<p>All the very best.
  </p></div></div>]]>
            </description>
            <link>https://eloeffler.gitlab.io/eloeffler/proto-vcser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276033</guid>
            <pubDate>Wed, 02 Dec 2020 13:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National parks of New Zealand in 3D]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25275588">thread link</a>) | @pheelicks
<br/>
December 2, 2020 | https://felixpalmer.github.io/new-zealand-3d/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/new-zealand-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/new-zealand-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275588</guid>
            <pubDate>Wed, 02 Dec 2020 12:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK approves Pfizer vaccine for rollout next week]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25275329">thread link</a>) | @williamsharris
<br/>
December 2, 2020 | https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week | <a href="https://web.archive.org/web/*/https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>LONDON –</strong> Britain today became the first Western country to approve a Covid-19 vaccine for general use as it announced a rollout of Pfizer-BioNTech's drug from next week.&nbsp;</p>

<p>"The government has today accepted the recommendation from the independent Medicines and Healthcare products Regulatory Agency (MHRA) to approve Pfizer-BioNTech's Covid-19 vaccine for use," the Health Department said in a statement.</p>

<p>"The vaccine will be made available across the UK from next week," the statement said. Priority groups will include care home residents, health and care staff, the elderly and the clinically extremely vulnerable.</p>

<p>After months of "rigorous" clinical trials and thorough analysis of the data, the MHRA "concluded that the vaccine has met its strict standards of safety, quality and effectiveness", the statement added.</p>

<p>"To aid the success of the vaccination programme, it is vital everyone continues to play their part and abide by the necessary restrictions in their area so we can further suppress the virus and allow the NHS (National Health Service) to do its work without being overwhelmed."</p>

<p>Pfizer chairman Albert Bourla said it was a "historic moment in the fight against Covid-19".&nbsp;</p>

<p>"This authorisation is a goal we have been working toward since we first declared that science will win, and we applaud the MHRA for their ability to conduct a careful assessment and take timely action to help protect the people of the UK," he said.</p>

<p>Pfizer and BioNTech added that they expected further regulatory decisions from other countries "in the coming days and weeks".</p>

<p>The announcement came as England exited a month-long coronavirus lockdown, but most of the country remained under restrictions as a new regional system for cutting infection rates kicked in.</p>

<p>The four-week lockdown, which began last month, was imposed to stop surging rates of infection, ease pressure on health services, and to allow families to gather for Christmas.</p>

<p>Prime Minister Boris Johnson, a Covid survivor, succeeded in winning a vote on the measures in parliament late yesterday, despite significant opposition within his own Conservative ranks.</p>

<p>"All we need to do now is to hold our nerve until these vaccines are indeed in our grasp and indeed being injected into our arms," he told lawmakers before the vote.</p>

<p>Until then "we cannot afford to relax, especially during the cold months of winter", he warned. – AFP, December 2, 2020</p>

                
                

                <div>
                    <div>
                        <h2>Get news, from every side. Subscribe to our newsletter!</h2>
                        


                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275329</guid>
            <pubDate>Wed, 02 Dec 2020 11:06:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux kernel heap quarantine versus use-after-free exploits]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25274928">thread link</a>) | @kmwyard
<br/>
December 2, 2020 | https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html | <a href="https://web.archive.org/web/*/https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It's 2020. Quarantines are everywhere – and here I'm writing about one, too.
But this quarantine is of a different kind.</p>

<p>In this article I'll describe the <strong>Linux Kernel Heap Quarantine</strong> that I developed
for mitigating kernel use-after-free exploitation. I will also summarize
the discussion about the prototype of this security feature on the Linux Kernel
Mailing List (LKML).</p>



<p>Use-after-free (UAF) vulnerabilities in the Linux kernel are very popular for
exploitation. There are many exploit examples, some of them include:</p>
<ul>
  <li><a href="https://seclists.org/oss-sec/2016/q4/607">CVE-2016-8655</a></li>
  <li><a href="https://www.openwall.com/lists/oss-security/2017/02/26/2">CVE-2017-6074</a></li>
  <li><a href="https://a13xp0p0v.github.io/2017/03/24/CVE-2017-2636.html">CVE-2017-2636</a></li>
  <li><a href="https://ssd-disclosure.com/ssd-advisory-linux-kernel-af_packet-use-after-free/">CVE-2017-15649</a></li>
  <li><a href="https://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html">CVE-2019-18683</a></li>
</ul>

<p>UAF exploits usually involve <strong>heap spraying</strong>.
Generally speaking, this technique aims to put attacker-controlled bytes at a defined memory
location on the heap. Heap spraying for exploiting UAF in the
Linux kernel relies on the fact that when <code>kmalloc()</code> is called, the slab
allocator returns the address of memory that was recently freed:</p>

<center><a href="https://a13xp0p0v.github.io/img/no_quarantine.png"><img src="https://a13xp0p0v.github.io/img/no_quarantine.png" width="60%"></a></center>


<p>So allocating a kernel object with the same size and attacker-controlled
contents allows overwriting the vulnerable freed object:</p>

<center><a href="https://a13xp0p0v.github.io/img/uaf.png"><img src="https://a13xp0p0v.github.io/img/uaf.png" width="70%"></a></center>


<p>Note: Heap spraying for out-of-bounds exploitation is a separate technique.</p>



<p>In July 2020, I got an idea of how to break this heap spraying technique for UAF
exploitation. In August I found some time to try it out. I extracted the slab
freelist quarantine from <a href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">KASAN</a> functionality and called it <code>SLAB_QUARANTINE</code>.</p>

<p>If this feature is enabled, freed allocations are stored in the quarantine
queue, where they wait to be actually freed. So there should be no way for them
to be instantly reallocated and overwritten by UAF exploits.
In other words, with <code>SLAB_QUARANTINE</code>, the kernel allocator behaves like so:</p>

<center><a href="https://a13xp0p0v.github.io/img/with_quarantine.png"><img src="https://a13xp0p0v.github.io/img/with_quarantine.png" width="60%"></a></center>


<p>On August 13, <a href="https://www.openwall.com/lists/kernel-hardening/2020/08/13/7">I sent</a> the first early PoC to LKML and started deeper research of
its security properties.</p>



<p>For researching the security properties of the kernel heap quarantine, I developed
two <code>lkdtm</code> tests (<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/7">code is available here</a>).</p>

<p>The first test is called <code>lkdtm_HEAP_SPRAY</code>. It allocates and frees an object
from a separate <code>kmem_cache</code> and then allocates 400,000 similar objects.
In other words, this test attempts an original heap spraying technique for UAF
exploitation:</p>

<div><div><pre><code><span>#define SPRAY_LENGTH 400000
</span>    <span>...</span>
    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>...</span>
    <span>pr_info</span><span>(</span><span>"Original heap spraying: allocate %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>if</span> <span>(</span><span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"FAIL: attempt %lu: freed object is reallocated</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>
    
    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span>
        <span>pr_info</span><span>(</span><span>"OK: original heap spraying hasn't succeeded</span><span>\n</span><span>"</span><span>);</span>
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is disabled, the freed object is instantly
reallocated and overwritten:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000002b5b3ad4 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: FAIL: attempt 0: freed object is reallocated
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is enabled, 400,000 new allocations don't overwrite
the freed object:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000009909e777 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: OK: original heap spraying hasn't succeeded
</code></pre></div></div>

<p>That happens because pushing an object through the quarantine requires <strong>both
allocating and freeing memory</strong>. Objects are released from the quarantine as
new memory is allocated, but only when the quarantine size is over the limit.
And the quarantine size grows when more memory is freed up.</p>

<p>That's why I created the second test, called <code>lkdtm_PUSH_THROUGH_QUARANTINE</code>.
It allocates and frees an object from a separate <code>kmem_cache</code> and then performs
<code>kmem_cache_alloc()+kmem_cache_free()</code> for that cache 400,000 times.</p>

<div><div><pre><code>    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>

    <span>pr_info</span><span>(</span><span>"Push through quarantine: allocate and free %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>push_addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>push_addr</span><span>);</span>

        <span>if</span> <span>(</span><span>push_addr</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"Target object is reallocated at attempt %lu</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span> <span>{</span>
        <span>pr_info</span><span>(</span><span>"Target object is NOT reallocated in %d attempts</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>);</span>
    <span>}</span>
</code></pre></div></div>

<p>This test effectively pushes the object through the heap quarantine and
reallocates it after it returns back to the allocator freelist:</p>

<div><div><pre><code>  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000008fdb15c3 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182994
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000004e223cbe of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 186830
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000007663a058 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182010
</code></pre></div></div>

<p>As you can see, the number of the allocations needed for overwriting
the vulnerable object is almost the same. That would be good for stable
UAF exploitation and should not be allowed.
That's why I developed <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6"><strong>quarantine randomization</strong></a>. This randomization
required very small hackish changes to the heap quarantine mechanism.</p>

<p>The heap quarantine stores objects in batches. On startup, all
quarantine batches are filled by objects. When the quarantine shrinks,
I randomly choose and free half of objects from a randomly chosen batch.
The randomized quarantine then releases the freed object at an unpredictable moment:</p>

<div><div><pre><code>   lkdtm: Target object is reallocated at attempt 107884
   lkdtm: Target object is reallocated at attempt 265641
   lkdtm: Target object is reallocated at attempt 100030
   lkdtm: Target object is NOT reallocated in 400000 attempts
   lkdtm: Target object is reallocated at attempt 204731
   lkdtm: Target object is reallocated at attempt 359333
   lkdtm: Target object is reallocated at attempt 289349
   lkdtm: Target object is reallocated at attempt 119893
   lkdtm: Target object is reallocated at attempt 225202
   lkdtm: Target object is reallocated at attempt 87343
</code></pre></div></div>

<p>However, this randomization alone would not stop the attacker:
the quarantine stores the attacker's data (the payload) in the sprayed objects!
This means the reallocated and overwritten vulnerable object contains the payload
until the next reallocation (very bad!).</p>

<p>This makes it important to <strong>erase heap objects before placing them in the heap quarantine</strong>.
Moreover, filling them with zeros gives a chance to detect UAF
accesses to non-zero data for as long as an object stays in the quarantine (nice!).
That functionality already exists in the kernel, it's called <code>init_on_free</code>.
<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/5">I integrated it</a> with <code>CONFIG_SLAB_QUARANTINE</code> as well.</p>

<p>During that work I found a bug: in <code>CONFIG_SLAB</code>, <code>init_on_free</code> happens too
late. Heap objects go to the KASAN quarantine while still "dirty." I provided the fix
in a <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/4">separate patch</a>.</p>

<p>For a deeper understanding of the heap quarantine's inner workings, I provided an <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/8">additional
patch</a>, which contains verbose debugging (not for merge).
It's very helpful, see the output example:</p>

<div><div><pre><code>   quarantine: PUT 508992 to tail batch 123, whole sz 65118872, batch sz 508854
   quarantine: whole sz exceed max by 494552, REDUCE head batch 0 by 415392, leave 396304
   quarantine: data level in batches:
     0 - 77%
     1 - 108%
     2 - 83%
     3 - 21%
   ...
     125 - 75%
     126 - 12%
     127 - 108%
   quarantine: whole sz exceed max by 79160, REDUCE head batch 12 by 14160, leave 17608
   quarantine: whole sz exceed max by 65000, REDUCE head batch 75 by 218328, leave 195232
   quarantine: PUT 508992 to tail batch 124, whole sz 64979984, batch sz 508854
   ...
</code></pre></div></div>

<p>The heap quarantine <code>PUT</code> operation you see in this output happens during kernel memory freeing.
The heap quarantine <code>REDUCE</code> operation happens during kernel memory allocation, if the quarantine
size limit is exceeded. The kernel objects released from the heap quarantine return to the allocator
freelist – they are actually freed.
In this output, you can also see that on <code>REDUCE</code>, the quarantine releases some part of
a randomly chosen object batch (see the <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6">randomization patch</a> for more details).</p>



<p>I made <a href="https://www.openwall.com/lists/kernel-hardening/2020/10/01/7">brief performance tests</a> of the quarantine PoC on real hardware and in virtual machines:</p>
<ol>
  <li>
    <p>Network throughput test using <code>iperf</code> <br>
server: <code>iperf -s -f K</code> <br>
client: <code>iperf -c 127.0.0.1 -t 60 -f K</code></p>
  </li>
  <li>
    <p>Scheduler stress test <br>
<code>hackbench -s 4000 -l 500 -g 15 -f 25 -P</code></p>
  </li>
  <li>
    <p>Building the defconfig kernel <br>
<code>time make -j2</code></p>
  </li>
</ol>

<p>I compared vanilla Linux kernel in three modes:</p>
<ul>
  <li><code>init_on_free=off</code></li>
  <li><code>init_on_free=on</code> (upstreamed feature)</li>
  <li><code>CONFIG_SLAB_QUARANTINE=y</code> (which enables <code>i…</code></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</a></em></p>]]>
            </description>
            <link>https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274928</guid>
            <pubDate>Wed, 02 Dec 2020 09:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25272533">thread link</a>) | @bdr
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/? | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that—albeit growing more slowly—may have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack—a niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to “back into” $66B worth of vertical markets—CRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate—via chatting with other team members within the context of a personal or shared inbox—and coordinate—via tagging, rules, and 3rd-party integrations—how they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat—based on the cost of switching away to another email product—will become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user—today, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years—a company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front—both because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front’s consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That’s up 40% from Front’s Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front’s last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn’t grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front’s revenue comes from expansion versus bringing on new customers—based on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front’s -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 – 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front’s bear, base, and bull cases hinge largely on whether the company’s growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front’s growth slows even further, with the company reaching a …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/?">https://sacra.com/research/front-inside-the-startup-slackifying-email/?</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272533</guid>
            <pubDate>Wed, 02 Dec 2020 02:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NN-SVG: Generate publication-ready NN-architecture schematics]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25272360">thread link</a>) | @tzm
<br/>
December 1, 2020 | https://alexlenail.me/NN-SVG/AlexNet.html | <a href="https://web.archive.org/web/*/https://alexlenail.me/NN-SVG/AlexNet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <div id="collapsable">
                        <div id="AlexNet" role="tabpanel">


                            <h4>Style:</h4>
                            <div id="rendererType">
                                <p><label for="rendererType">Renderer</label></p><p><label>
                                         webGL
                                    </label>
                                </p>
                                <p><label>
                                         SVG
                                    </label>
                                </p>
                                <p><small>The SVG renderer is required to download SVG, however the WebGL renderer is required to show tensor dimensions.</small>
                            </p></div>

                            
                            <p>
                                <label for="color1">Color 1</label>
                            </p>
                            <p>
                                <label for="color2">Color 2</label>
                            </p>
                            <p>
                                <label for="color3">Color 3</label>
                            </p>
                            <p><label for="rectOpacity">Tensor Opacity</label>
                                
                            </p>
                            <div>
                            <p><label for="strideOpacity">Filter Opacity</label>
                                
                            </p>
<!--                             <div>
                                <label for="borderWidth">Border Width</label>
                                <input type="range" id="borderWidth" name="" min="0.01" max="3" step="0.01" value="1" style="position: relative; top: 3px;">
                            </div> -->
                            <p><label for="betweenLayers">Spacing Between Layers</label>
                                
                            </p>

                            <hr>
                            <p>
                                <label for="logDepth">Log Feature-Map Depth Scaling</label>
                            </p>
                            <p><label for="depthScale">Depth Size Scaling</label>
                                
                                <span id="depthSpan">10</span>
                            </p>
                            <p>
                                <label for="logWidth">Log Feature-Map Width Scaling</label>
                            </p>
                            <p><label for="widthScale">Width Size Scaling</label>
                                
                                <span id="widthSpan">10</span>
                            </p>
                            <p>
                                <label for="logConvSize">Log Convolutional Filter Size Scaling</label>
                            </p>
                            <p><label for="convScale">Convolutional Filter Scaling</label>
                                
                                <span id="convSpan">1</span>
                            </p>

                            <hr>
                            <p>
                                <label for="showDims">Show Tensor Dimensions</label>
                            </p>
                            <p>
                                <label for="showConvDims">Show Conv Dimensions</label>
                            </p>

                            <hr>
                            <h4>Architecture:</h4>
                            <div id="architecture">
                                <p>Height | Width | Depth | filter Height | filter Width</p>
                                
                                
                                
                                
                                
                                
                                
                            </div>

                            <hr>
                            

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexlenail.me/NN-SVG/AlexNet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272360</guid>
            <pubDate>Wed, 02 Dec 2020 01:46:02 GMT</pubDate>
        </item>
    </channel>
</rss>
