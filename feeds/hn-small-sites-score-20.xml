<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Dec 2020 01:06:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Dec 2020 01:06:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[In-Database Machine Learning [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25285983">thread link</a>) | @redwrasse
<br/>
December 2, 2020 | https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf | <a href="https://web.archive.org/web/*/https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25285983</guid>
            <pubDate>Thu, 03 Dec 2020 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the US Banning Crypto Wallets?]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25283610">thread link</a>) | @mkmccarty3
<br/>
December 2, 2020 | https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5fc557916457125654ede725" data-item-id="5fc557916457125654ede725">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1606768551080" id="item-5fc557916457125654ede725"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_4996"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image-dimensions="834x466" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baa31d106d256baa5ca2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-98c39078cd9c52d11cda"><div><p>Just as Bitcoin was guiding cryptocurrency markets skyward with a renewed push for an all-time high valuation, prices came crashing down without warning.</p><p>Wait — <em>was there a warning</em>?</p><p><a href="https://twitter.com/brian_armstrong/status/1331744884856741888">In a tweet</a> with what some deemed suspicious timing, Coinbase CEO Brian Armstrong let loose an alarming rumor. The United States Treasury, with Secretary Mnuchin at the helm, is poised to ban the use of anonymous non-custodial crypto wallets before the year's end.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_22941"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://twitter.com/brian_armstrong/status/1331745659989360640">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image-dimensions="589x256" data-image-focal-point="0.5,0.5" alt="brian armstrong tweet.PNG" data-load="false" data-image-id="5fc6bc78e2dcb1274dd6fb85" data-type="image">
          </p>
        
          </a>
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_23230"><div><p>What is a non-custodial crypto wallet, you ask? Simple — any crypto wallet that is self-hosted (i.e., you own and hold the private keys) fits the description.</p><p>So, if you currently use a cold storage wallet like a Ledger Nano S or a software wallet such as MetaMask, you may soon find yourself running afoul of new regulations.</p><p>While this all seems pretty bad for Bitcoin when you consider the sheer amount of people using non-custodial crypto wallet storage, there are a couple silver linings worth considering.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_25472"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image-dimensions="1306x735" data-image-focal-point="0.5,0.5" alt="wallet guide.PNG"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_25761"><div><p>At the core of the rumored regulations is what appears to be a bank-centric push to force all current and future cryptocurrency users toward intermediary platforms.</p><p>What this means for you is, if the rumors are true, you will need to share KYC information (identification data) with exchanges you use before withdrawing or depositing from your self-hosted wallet. This push will make it so your currently anonymous crypto wallet will be inextricably linked to your real-world identity.</p><p>OK — so there go crypto wallets, right? You might as well delete your Exodus wallet, shut down the MetaMask, and turn everything over to the bankers lying in wait.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_7734"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baf2ad3e6411922cd0a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_8023"><div><p><strong>Wrong.</strong> Try as they might, there is simply <strong>no way</strong> to enforce data collection on the use of non-custodial wallets. Such regulations appear more symbolic than anything else — they might scare newbies looking to enter the market discreetly, but anyone who understands how cryptocurrency storage works, especially when using hardware wallets, knows there are options outside of centralized exchanges.</p><p>Consider the scenario where the US Treasury makes good on their threat to enforce data collection on crypto wallets. Now, Coinbase requires you to KYC your wallet before allowing you to withdraw freshly purchased BTC. What are your options?</p><p>For one thing, you can use a decentralized exchange to trade crypto. Uniswap has already surpassed Coinbase in terms of trading volume — if crypto wallets regulations come into play, expect Uniswap to get much more action.</p><p>Moreover, with the push toward DeFi in the cryptocurrency industry, along with endless options for swapping liquidity, the likelihood that centralized exchanges stay relevant gets slimmer every day.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_15299"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6bbd593ad1a48120388ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_15588"><div><p>Satoshi Nakamoto never envisioned cryptocurrency as a way for governments to collect private data. That's why blockchains are built to enable censorship-free financial access.</p><p>As CoinDesk noted <a href="https://www.coindesk.com/crypto-wallet-regulations-industry-pros">in a recent analysis of the situation</a>, there exists a revealing difference in the language used to refer to crypto wallets by regulators and crypto investors.</p><p>Regulators call crypto wallets <em>unhosted wallets,</em> whereas investors refer to them as <em>self-hosted wallets</em>. The difference here is all about privacy — crypto users believe in financial independence, freedom from oversight, and digital asset autonomy.</p><p>On the other hand, an unhosted wallet points to the view that such wallets lack hosting — a situation that should be remedied by regulation and the cooperation of centralized institutions.</p><p>This seemingly small difference in language does indeed point to a large divide in exactly how each side views the purpose of storing crypto assets.</p><p>As Armstrong noted in his original Twitter thread, the crypto industry has been preparing for this eventuality for at least a few months. In fact, they've known long enough to form a lobby, and have responded to the rumors by sending the US Treasury a plea to leave crypto alone.</p><p>The regulation is expected to come into effect before the year's end, mostly owing to the US election results and the impending changing of the guard. As such, the rush is on for Mnuchin to push through regulations before time is up.</p><p>Does data-collection on self-hosted crypto wallets amount to the US government declaring a ban on cryptocurrency wallets we know them?</p><p><strong>Not really</strong>.</p><p>Moreover, can the government enforce these regulations and push people onto the centralized platforms decentralized blockchains were built to avoid?</p><p>The answer there is clearer: <strong>certainly not.</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_28135"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image-dimensions="1442x669" data-image-focal-point="0.5,0.5" alt="beginners guide to bitcoin cover.png" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>Each of these strategies is simple to implement, even for novice investors, but that doesn’t mean these strategies aren’t used by professions.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>

    

    

    <section id="comments-5fc557916457125654ede725">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://blog.shrimpy.io/blog/coinbase-vs-uniswap">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Coinbase vs. Uniswap — Which Exchange Is Better?</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-12-02">December 2, 2020</time></p><!--

            Tags

            --><p><span>coinbase, uniswap, review, general, notlatest</span></p><!--

            Comments

            --></div>
        </div>
      </a>
    

    
      <a href="https://blog.shrimpy.io/blog/machine-learning-for-crypto-portfolio-management-case-study-week-30">
        <div>
          <p>Next</p>
          <h4>Machine Learning for Crypto Portfolio Management Case Study: Week 30</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-11-30">November 30, 2020</time></p><!--

            Tags

            --><p><span>data, notlatest, topsection</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283610</guid>
            <pubDate>Thu, 03 Dec 2020 00:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Issues as a Hugo Front End with GitHub Actions and Netlify]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25281958">thread link</a>) | @todsacerdoti
<br/>
December 2, 2020 | https://shazow.net/posts/github-issues-as-a-hugo-frontend/ | <a href="https://web.archive.org/web/*/https://shazow.net/posts/github-issues-as-a-hugo-frontend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I got into the habit of dumping quick blog post ideas into issues on my blog’s repo. It’s a convenient place to iterate on them and share with friends for feedback before actually publishing on my blog post.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100761218-a6cb2280-33c0-11eb-92df-1b52d91cc16e.png" alt="image"></p><p>The drafts keep accumulating, how do I trick myself into publishing more? Perhaps by reducing the effort required for the next step? Let’s do it!</p><h2 id="architecture">Architecture</h2><p>My blog is statically generated using <a href="https://github.com/gohugoio/hugo">Hugo</a>, the <a href="https://github.com/shazow/shazow.net">code is hosted on Github</a>, then when a pull request comes in it is built, previewed, and published on merge by <a href="https://netlify.com/">Netlify</a>.</p><p>The blog post drafts are posted as Github issues, so there is a clear gap: How do we convert issues into pull requests for Netlify? Enter Github Actions!</p><h2 id="github-action-issue-to-pull-request">Github Action: Issue to Pull Request</h2><p>My <a href="https://github.com/shazow/shazow.net/blob/master/.github/workflows/publish.yml">full workflow lives here</a> if we want to jump ahead, but let’s break down the broad strokes.</p><p>I decided to trigger the publishing process once an issue is labelled with ‘publish’, so let’s start with that:</p><div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span>Publish<span> </span>post<span> </span>from<span> </span>issue<span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>issues</span><span>:</span><span>
</span><span>    </span><span>types</span><span>:</span><span> </span><span>[</span><span>'labeled'</span><span>]</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>build</span><span>:</span><span>
</span><span>    </span><span>if</span><span>:</span><span> </span>${{<span> </span>github.event.label.name<span> </span>==<span> </span><span>'publish'</span><span> </span>}}<span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>      </span>...<span>
</span></code></pre></div><p>Next up we want to specify the steps, first thing is to check out the repository into the action’s environment:</p><p>Once the source code is available, we want to generate the blog post from the issue metadata. Here is a very basic version of this, though I ended up doing more tweaking in the end:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Generate<span> </span>Post<span>
</span><span>        </span><span>env</span><span>:</span><span>
</span><span>          </span><span>POST_TITLE</span><span>:</span><span> </span>${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>          </span><span>POST_BODY</span><span>:</span><span> </span>${{<span> </span>github.event.issue.body<span> </span>}}<span>
</span><span>        </span><span>run</span><span>:</span><span> </span><span>|
</span><span>          cat &gt; "content/posts/${POST_TITLE}.md" &lt;&lt; EOF</span><span>
</span><span>          </span>${POST_BODY}<span>
</span><span>          </span>EOF<span>
</span></code></pre></div><p>This shoves the body of the issue, which is already markdown, into a markdown file named based on the title of the issue. This is a good place to add frontmatter, or slugify the title, or whatever else your blog setup requires.</p><p>Running the payload through environment variables helps with not needing to escape various characters like `.</p><p>And finally, we make the pull request using Peter Evan’s create-pull-request action which makes this super easy:</p><p>This is the minimum of what we need, but we can specify all kinds of additional options here: like auto-deleting the branch, setting a custom title, body, and whatever else. Here’s an example of what I’m doing:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Create<span> </span>Pull<span> </span>Request<span>
</span><span>        </span><span>uses</span><span>:</span><span> </span>peter-evans/<a href="https://shazow.net/cdn-cgi/l/email-protection" data-cfemail="ed8e9f888c9988c09d988181c09f889c98889e99ad9bde">[email&nbsp;protected]</a><span>
</span><span>        </span><span>with</span><span>:</span><span>
</span><span>          </span><span>delete-branch</span><span>:</span><span> </span><span>true</span><span>
</span><span>          </span><span>title</span><span>:</span><span> </span><span>"publish: ${{ github.event.issue.title}}"</span><span>
</span><span>          </span><span>body</span><span>:</span><span> </span><span>|
</span><span>            Automagically sprouted for publishing.</span><span>
</span><span>            </span><span>Merging will publish to</span><span>:</span><span> </span>https<span>:</span>//shazow.net/posts/${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>            </span>Closes<span> </span><span>#${{ github.event.issue.number }}</span><span>
</span><span>          </span><span>reviewers</span><span>:</span><span> </span>${{<span> </span>github.repository_owner<span> </span>}}<span>
</span><span>          </span><span>commit-message</span><span>:</span><span> </span><span>"post: ${{ github.event.issue.title }}"</span><span>
</span></code></pre></div><h2 id="result">Result</h2><p>When my blog post draft is ready, I add the tag and the Github action takes it away, creating a pull request:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763017-a764b880-33c2-11eb-860f-5bab932ac558.png" alt="image"></p><p>The pull request automatically pings me as a reviewer, and includes a “Closes #X” line which will close the draft issue once the PR is merged. Very convenient!</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763219-ded36500-33c2-11eb-8387-ff28b6561875.png" alt="image"></p><p>Once the pull request is ready, Netlify takes it away, builds everything and generates a handy preview:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763300-fa3e7000-33c2-11eb-9172-206f58556ddd.png" alt="image"></p><p>I can make sure everything looks right, and even apply edits directly inside the pull request. This is another great step to send a long blog post for feedback, using all of the wonderful Pull Request Review features!</p><p>When all is said and done, merging the pull request triggers Netlify to publish my changes to my domain, and merging closes the original issue, and I’m done!</p><h2 id="bonus">Bonus</h2><p>Drag n’ drop images work in Github Issues, so it’s super easy to write a quick post with a bunch of screenshots or what have you.</p><p>It’s important to me that I’m not too tightly coupled to third-party services, so the pull request and code merge flow makes sure that all of the published state continues to live inside of my Git repository.</p><p>I can still make blog posts the way I used to: Pull the latest repo, write some markdown, and push to publish.</p><p>I added a little <a href="https://github.com/shazow/shazow.net/blob/master/frontmatterify">frontmatterify script</a> to process the incoming markdown and convert the remote Github Issue uploaded images into local images that are included in the pull request. The script also generates frontmatter that I use for Hugo. It’s a bit clunky but works for now.</p><p>Alright, let’s do this.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100764184-11ca2880-33c4-11eb-8c84-e992765ace49.png" alt="image"></p></div></div>]]>
            </description>
            <link>https://shazow.net/posts/github-issues-as-a-hugo-frontend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25281958</guid>
            <pubDate>Wed, 02 Dec 2020 21:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Topology to Classify Labelled Graphs]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25279820">thread link</a>) | @Topolomancer
<br/>
December 2, 2020 | https://bastian.rieck.me/blog/posts/2020/topology_graphs/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/topology_graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I have written at lengths about certain aspects of topological data
analysis, but I have neglected to discuss one of its main applications,
i.e. the classification of graphs. In this post, I will therefore take
you on a quick tour of our ICML paper <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">A Persistent Weisfeiler–Lehman Procedure for Graph Classification</a>.</p>
<p>Let us assume that we are given a graph with node label information. The
graph could, for instance, be a molecule, whose nodes are atoms such as
carbon or oxygen, and whose edges indicate chemical bonds. The goal
could now be to classify a given molecule into a set of classes, such as
‘toxic’, ‘carcinogen’, etc. How can we achieve such a classification?
One of the simplest techniques dates back to the 1960s and involves
calculating an <em>iterative fingerprint</em> of the graph! This procedure was
suggested by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler">Boris Weisfeiler</a>
and Andrei Lehman&nbsp;(sometimes also transliterated as ‘Leman’) in
their seminal article <a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">The reduction of a graph to canonical form and the
algebra which appears therein</a>.</p>
<p>At its core, the algorithm is an iteration scheme that works like this:</p>
<ol>
<li>For a node $v$, collect its label and the labels of adjacent nodes in
a multiset.</li>
<li>Assign this multiset a new label by hashing it—with the proviso
that the hashing function is <a href="https://en.wikipedia.org/wiki/Perfect_hash_function"><em>perfect</em></a>, i.e.
it maps distinct labels to distinct values with no collisions.</li>
<li>Replace all node labels by their multiset hashes.</li>
</ol>
<p>Intuitively, each step of the algorithm accumulates more information
from nodes that are further removed from the current node. The hashed
multiset label is thus an expression of the neighbourhood around
a node—and after a sufficiently large number of iterations, the
hashed labels will not change any more.</p>
<p>For example, suppose you are dealing with this simple graph&nbsp;(to
prevent confusion of node labels and node IDs, I used <em>colours</em> to
indicate node labels in this example):</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_graph.svg" alt="Weisfeiler--Lehman example graph" height="128"> 
</figure>

</div>
<p>Tabulating the neighbourhood of each node then results in the following
table:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_1.svg" alt="Weisfeiler--Lehman multiset example (before hashing)" height="128"> 
</figure>

</div>
<p>Now for the hashing step. In this example, <em>perfect hashing</em> means
choosing a set of colours that is distinct for every distinct
combination of neighbourhood labels and vertex labels:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_2.svg" alt="Weisfeiler--Lehman multiset example (after hashing)" height="128"> 
</figure>

</div>
<p>Notice how nodes A, B, and G are hashed to the same colour—because
in the first iteration of the algorithm, they cannot be distinguished.
How can we use the information about the hashed labels in a subsequent
comparison task? The answer is lies in <em>counting</em> them in a histogram
vector, which is indexed by the unique labels—this is where our
requirement of the perfect hashing function is helpful. For the
previously-shown graph, it looks like this:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_feature_vector.svg" alt="Weisfeiler--Lehman subtree feature vector" height="128"> 
</figure>

</div>
<p>The <em>fingerprint</em> of this graph, according to the first iteration of the
Weisfeiler–Lehman scheme is therefore $(3, 1, 2, 1)$. Further iterations
just make the feature vector longer&nbsp;(technically, the initial
labels already give rise to a feature vector of counts). This procedure
can now be repeated for higher-order iterations and the resulting
feature vectors can be compared across graphs by evaluating, for
example, their dot product. More formalisations of this idea have
resulted in the very successful <a href="https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf">Weisfeiler–Lehman Graph
Kernels</a>
publication. This method arguably constitutes the basis for graph neural
networks—in fact, these networks can be seen as a parametrised
version of the Weisfeiler–Lehman iteration scheme. But I digress—if
you are interested in these aspects, please read <a href="https://towardsdatascience.com/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751">Michael Bronstein’s
article on going beyond graph
isomorphism</a>
for more details.</p>
<p>Now, despite its great practical utility, this feature vector is lacking
some <em>structural</em> information about the graph. It does not know whether
a certain label contributes much to the topological structure of
a graph—such as a ring of carbon atoms would in molecule—or not. To
this end, we introduced a notion of topological relevance for each node
label! Briefly put, we first developed a distance metric that would
permit us turn any <em>labelled</em> graph into a <em>weighted</em> graph. We then
calculate a persistence barcode, a topological descriptor of the graph.
This descriptor assesses the relevance of a topological feature created
by some node label. We use the topological relevance of each feature as
an additional <em>weight</em> for the previously-shown feature vector. In
essence, labels that contribute a large amount of topological structure
in a graph are assigned a higher weight than labels that only contribute
a meagre amount!</p>
<p>Here is a graphical depiction of our process:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/p_wl_pipeline.svg" alt="Persistent Weisfeiler--Lehman pipeline" height="128"> 
</figure>

</div>
<p>If you want to brush up your understanding of the barcode calculation,
head on over to <a href="https://christian.bock.ml/">Christian’s website</a>; he has
an <a href="https://christian.bock.ml/posts/persistent_homology">excellent article on persistent
homology</a>.</p>
<p>The neat thing about our approach is that we can easily integrate
information about <em>cycles</em> into the feature vector—this is
a functionality that the original Weisfeiler–Lehman Graph Kernels
Framework lacks. Moreover, these cycles turn out to be crucial in
improving classification performance—we get an increase of more than
3% in classification accuracy by considering them in some data sets!</p>
<p>If this has whet your appetite, I invite you to <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">read our
paper</a> or <a href="https://github.com/BorgwardtLab/P-WL">take
a look at the code</a>. If you want
to learn more about graph classification using graph kernels, take
a look at our <a href="https://arxiv.org/abs/2011.03854">recent survey on graph kernels</a>,
which will hopefully be officially announced in time for NeurIPS 2020.
In the best tradition of Fermat, I would very much like to cover the
content of the survey here, but this blog is too small to contain all of
it—maybe for a subsequent post?</p>
<p>Until next time!</p>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/topology_graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279820</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A founder’s guide to understanding users]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25279814">thread link</a>) | @mgadams3
<br/>
December 2, 2020 | https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44 | <a href="https://web.archive.org/web/*/https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="9bcd">Four steps to ensure your customer discovery &amp; development efforts result in great products that solve real customer problems</h2><div><div><div><p><a href="https://medium.com/@mgadams?source=post_page-----c68feaecac44--------------------------------" rel="noopener"><img alt="Mike Adams" src="https://miro.medium.com/fit/c/96/96/1*Myw6S5WzM6_5PfbkyNAwUQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4ad5">When building any technology product, one of the most common pieces of advice is “talk to your users.”</p><p id="cec4">But the default way most of us talk to customers and prospects is unscientific and fraught with confirmation bias, putting us in danger of being lied to and wasting months building something nobody wants.</p><p id="ee5b">I learned this truth the hard way over the past decade founding multiple companies — but it wasn’t until I was working on my <a href="http://grain.co/utm_source=medium" rel="noopener">third startup</a> that I came to understand a better way to actually understand users.</p><p id="a218">When I first started building start-ups a decade ago, I never anticipated how applicable Yoda’s wisdom about the value of failure would be as a founder.</p><p id="3a5b">When I first started out, we had an idea, turned it into a UI, and hired developers to make it real. After nearly a year and tens of thousands of dollars — we launched it.</p><p id="d4d8">Ghost town. Crickets. Nobody wanted what we’d built.</p><p id="998b">I determined that the missing piece of the puzzle was my <a rel="noopener" href="https://mgadams.com/want-to-learn-to-code-start-with-excel-4f5902fb1b2f?source=collection_home---6------0-----------------------">lack of technical ability</a>, so I enrolled as one of the first dozen students at a now-famous<a href="https://www.hackreactor.com/" rel="noopener"> coding bootcamp</a> and actually got a job as a software engineer at a <a href="http://opentable.com/" rel="noopener">real company</a>.</p><p id="3b53">So surely when I started my <a href="https://twitter.com/missionu?lang=en" rel="noopener">next start-up</a>, this time things would be different. This time we talked to dozens of potential users and industry experts before we built anything. This time it worked. Sort of.</p><p id="d494">Our mission was compelling as we launched to <a href="https://www.inc.com/magazine/201806/leigh-buchanan/missionu-career-training-school.html" rel="noopener">fanfare</a> and raised <a href="https://techcrunch.com/2017/09/14/missionu-raises-8-5m-to-build-an-alternative-one-year-education-program/" rel="noopener">$11.5M</a> within 10 months of founding the company. However, after just two years we were acqui-hired, our investors got their money back, and the product was immediately <a href="https://www.insidehighered.com/digital-learning/article/2018/05/23/missionu-self-styled-alternative-higher-education-closes-after" rel="noopener">shut down</a>.</p><p id="6863">I was gutted, still am TBH.</p><p id="0f28">But with hindsight, I could look back to my original research notes and see I had ignored several fatal warnings. I had listened to what they said — exactly as they said it, but I did not realize until much later that I failed to actually understand what they meant.</p><p id="9305">So if I wanted to avoid failing a third time, I needed to figure out what I was missing about how to <em>really</em> understand users.</p><p id="9c98">Marty Cagan, Silicon Valley Product Group founder and former PM at early eBay, says there are “<a href="https://svpg.com/the-inconvenient-truth-about-product/" rel="noopener">two inconvenient truths about product</a>.”</p><p id="b881">Truth #1: <strong>At least half of our ideas are just not going to work</strong>:</p><p id="ed0c">Truth #2: <strong>Even the good ideas take several iterations to become viable.</strong></p><p id="3d8c">My experience has also been that there’s simply no escaping these inconvenient truths — I only wish I would have learned about them sooner.</p><p id="30d3">It doesn’t matter how smart or experienced we may be, statistically speaking, most of our ideas are simply not going to work. And the successful ones take time and hard work to turn into a real product that gets widely adopted by a market.</p><p id="de93">Your ideas are not nearly as important as your process — and the best process starts with understanding what the customers you wish to serve <em>already</em> do to solve their problems today and even more importantly, understanding why.</p><p id="9883">Yet, even as a 3rd time founder, I fell into the trap of ignoring the two inconvenient truths <em>again.</em></p><p id="87c7">Confirmation bias is a hell of a drug.</p><p id="f8b7">When we started <a href="http://grain.co/?utm_source=medium" rel="noopener">grain.co</a> two years ago, we began with a specific product solution in mind, built prototypes, and got feedback from users. They told us they’d love to use it but after months turning prototypes into a product, few actually did.</p><p id="a400">So we started over from scratch, but this time with a different approach:</p><ol><li id="2be7">Focus on a very specific user type with a very specific job to be done.</li><li id="bb56">Interview dozens of them only to understand how and why they solve their problem today.</li></ol><p id="0128">Our goal was not to validate whether the merit of a specific solution but to observe existing customer behaviors and desires as a means of generating new ideas for potential product solutions.</p><p id="3dec">This is what is known as <strong>generative research</strong>.</p><p id="4699">As you listen to your target market describe what they do today to solve their problems, you can better understand potential customers’ existing incentives, behaviors, and desires in anticipation for how they’d react to a new solution.</p><p id="331b"><a href="https://twitter.com/robfitz" rel="noopener">Rob Fitzpatrick</a> has famously coined this generative research phase “ <a href="http://momtestbook.com/" rel="noopener">The Mom Test</a>,” which is a set of simple rules to ask good questions so that even your Mom can’t lie to you in her answers to protect your ego.</p><p id="7e65">Generative research questions are focused on understanding existing behavior. For example, here are some questions from an interview guide we used at <a href="http://grain.co/" rel="noopener">Grain</a> to understand how our prospective users already document and share information from live meetings:</p><ul><li id="fcb3">What’s your current process to document and share information from a video meeting?</li><li id="fa1f">How important is it that the information you document and share is accurate?</li><li id="6568">What measures do you currently take to ensure accuracy of captured information?</li><li id="33f9">What can happen if your documentation is inaccurate?</li><li id="32f3">How often are you in conversations where you don’t need to document or share anything?</li><li id="cda6">Which types of conversations are the most important for you to document and share?</li></ul><p id="9e72">Be sure to avoid hypothetical questions about what people <em>might</em> do. Don’t try to validate your future product with questions that begin with “would you use this” or “what do you think about the possibility of” — that’s what we call leading the witness, and it will inevitably bias your data and waste your time building the wrong thing. At this stage, you simply need to observe what users are <em>already doing,</em> not what they might theoretically do.</p><figure><div></div></figure><p id="69d3">I recently connected with <a href="https://twitter.com/robfitz" rel="noopener">Rob</a> where he shared an updated model of 3 ways where users will lie to you if you’re not careful:</p><ol><li id="afa0">Asking the wrong questions</li><li id="6697">Remembering the wrong thing</li><li id="6a57">Making the wrong decision “justified” by what you think you heard</li></ol><p id="ecb1">Rob and most other researchers suggest asking for permission from their interviewees to record these interviews and take time-annotated notes that will help them to accurately remember and codify behavioral patterns that could eventually help to define <a href="https://www.uxmatters.com/mt/archives/2019/02/the-pitfalls-of-personas-and-advantages-of-jobs-to-be-done.php" rel="noopener">“jobs to be done”</a> that product, engineering, and design teams can build for with confidence.</p><p id="556d">After gaining insights about the problems your target market faces in generative research, you may be confident enough to test out a specific product solution to see if these users would actually value it.</p><p id="4717">This is the concept behind <strong>evaluative testing</strong>.</p><p id="f326">At this early stage, you want to put an <em>ultra-lightweight implementation </em>of a product solution in front of your target users to see how they react. While the closer to reality your prototype is the better, it doesn’t need to be a fully functional product yet: designs on paper, prototypes, mock-ups-anything like that will work.</p><p id="b1b0">Your goal at this stage is to get clear qualitative signals that users:</p><ol><li id="9f21">understand the proposed product solution</li><li id="fcda">express unmistakable excitement about the prospect of the product as a superior solution to the status quo</li></ol><p id="2033">Unfortunately, all too many product teams speed through this testing or skip it all together and simply march ahead to engineering and delivery. Depending on the complexity of the market and the problem you’re trying to solve, this stage could take months or, in some cases, years.</p><p id="d10d">That might sound discouraging and time-consuming, but I know this for certain: the success of your product will be <strong><em>directly proportiona</em>l</strong> to the quality of work done in this initial customer discovery phase. It’s worth doing it, and it’s certainly worth doing it well.</p><p id="0fd4">Even if your team creates something that people want, if customers can’t figure out how to use it, the product is dead in the water. This is why product teams conduct usability testing throughout the build process.</p><p id="ee09">The traditional approach to usability interviews is to set up a test environment, where we watch as a user navigates the product. An interviewer encourages a user to explain what they see, think, and observe. The interviewer also offers prompts for what the user might consider next if they get stuck using the product. Usability issues in the product become self-evident in most of these cases.</p><p id="8825">My friend <a href="https://medium.com/u/b2d49a9606e3?source=post_page-----c68feaecac44--------------------------------" target="_blank" rel="noopener">Behzod Sirjani</a>, has created a framework for conducting usability testing interviews where he recommends asking the participant about their:</p><ol><li id="084d">Expectation (about what will happen)</li><li id="4d83">Reaction (to what happens)</li><li id="64e1">Reflection (on the difference between 1 and 2)</li></ol><figure><div></div></figure><p id="ec98">A less scientific and more agile approach to identifying lower-hanging usability issues is concierge onboarding. In concierge onboarding, someone from your team guides — via video call is best — new users through setting up the product and answers the questions in real-time. Concierge onboarding helps the team member understand the steps users are asked to take and the ways those steps directly lead to value.</p><figure><div></div></figure><p id="2293">In a recent Zoom call with Behzod, he told me how at Slack it was essential to turn usability interviews into video highlights of moments of user struggle to help his team form a shared understanding of the problem and gain alignment around solutions that will actually work.</p><p id="5379">The best product teams never stop this work of generative and evaluative testing for new features. Even as their initial research and testing turns into a real product, they know the importance of creating a customer discovery and product delivery engine that never stops learning and growing.</p><p id="b7d9">It’s much more common for product teams to continually learn and discover from their existing users than it is for them to gather insights from completely unbiased non-users. But a balance between the two groups — existing and new — is ideal. New users can give you a better understanding of your initial product experience, and existing “power users” can offer you insights that come from living with a product for weeks or months.</p><p id="1af9">Great product teams develop long-standing relationships of trust with their most active users. You’ll often see the people on these teams setting up recurring feedback sessions to gain insight and listen to users’ concerns and ideas. The point of these interviews is to find out what’s delightful and what’s frustrating, what’s there and working well, and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</a></em></p>]]>
            </description>
            <link>https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279814</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop slacking, start rocking: Why we built Rock for a distributed workforce]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25279417">thread link</a>) | @kenzofong
<br/>
December 2, 2020 | http://rock.so/stopslacking | <a href="https://web.archive.org/web/*/http://rock.so/stopslacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <!-- split row one -->
      <div>
        <div>

          <!-- Row one -->
          <div>
            
            <div>
              <p>
                  <br><b>tl;dr</b> <i>Remote work is here to stay and the productivity tools that currently exist are not built for a more distributed workforce. With Rock, we're bringing together both synchronous and asynchronous ways of collaborating, so working with a distributed team becomes easier. <span><a href="#"><i></i> See how Rock works.</a></span></i>
                </p>
            </div>
            
          </div>

          <!-- Row one -->
          <div>
            
            <div>
              <div>
                <p>
                  <br>
                  <b>We are now in more meetings and work longer hours than ever before.</b> With <a href="https://time.com/collection/great-reset/5900753/rethinking-work-covid-19/">62% of people working from home</a> because of the pandemic -- the number of meetings has gone up 12.9%, the volume of emails has increased and workdays have grown 48 ½ minutes longer.
                </p>
                <p>
                  All of these distractions take up 40% of someone’s productive time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row two -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-1.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row three -->
          <div>
            
            <div>
              <div>
                <p>
                  There are different reasons why this has happened, but one of the main reasons is that the way we work hasn't really changed. When companies started shifting their workforce to a remote model, they took the tools they were already using (e.g. Slack, Zoom) and sent their employees home.
                </p>
                <p>
                  These tools are now being used in the same way they were used in the office, where most of the interaction happened in real-time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row four -->
          <div>
            
            <div>
              <div>
                <h3>We're moving towards a more distributed way of working.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row five -->
          <div>
            
            <div>
              <div>
                <p>
                  A quick chat is now another Zoom meeting in a long succession of meetings and a tap on the shoulder is yet another Slack message that pulls you away from what you were doing.
                  This firehose of messages and meetings is not sustainable as it leads to <a href="https://www.cnbc.com/2020/07/28/remote-work-burnout-is-growing-as-coronavirus-pandemic-stretches-on.html">anxiety</a>, <a href="https://www.fastcompany.com/90554935/the-red-flag-signs-you-may-be-burning-out-while-working-from-home">burnout</a> and <a href="https://www.forbes.com/sites/bryanrobinson/2020/09/06/how-remote-workers-can-recognize-burnout-and-6-actions-to-take/?sh=64da6cf14326">pressure</a> to always be connected.
                </p>
                <p>
                  With a <a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/covid-19-driving-lasting-change-for-business-practices-it-spending-8211-451-survey-60716654">majority of companies</a> stating that remote work is here to stay, <a href="https://socketsite.com/archives/2020/10/nearly-12-million-square-feet-of-vacant-office-space-in-s-f.html">office footprints</a> being reduced dramatically and tech companies like Twitter telling their staff that they can <a href="https://www.washingtonpost.com/technology/2020/10/01/twitter-work-from-home/?arc404=true">work from home forever</a> some of these changes will become the new normal. Most people agree that whatever happens, companies will be way more distributed than they were before the pandemic.
                  One thing is for sure -- the communication &amp; collaboration tools that exist today just don't cut it.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row six -->
          <div>
            
            <div>
              <div>
                <h3>We need tools for a distributed workforce.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row seven -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-2.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eight -->
          <div>
            
            <div>
              <div>
                <p>
                  <b>This is where <a href="http://rock.so/">Rock</a> comes in</b>. <a href="https://www.linkedin.com/in/liming/">Ming</a> and I started building Rock about a year ago to make it easier to shift towards a <a href="http://rock.so/about">more asynchronous way of working</a>. This way of working gives you <b>more control</b> over your workday, makes you <b>more productive</b> while <b>reserving face-to-face meetings</b> for the most important things. It's also ideally suited to a workforce that is more distributed.
                </p>
                <p>
                  With the right tools and mindset, working with your team becomes more like a <b>relay race</b>. Everybody knows what's going on, you can pick things up when you're ready, and work happens in a state of flow.
                </p>
              </div>
            </div>
            
          </div>

          

          <div>
            
            <div>
              <div>
                <p>
                  Rock combines real-time messaging and video calls with more asynchronous ways of communicating like <a href="http://rock.so/tasks">tasks</a>, <a href="http://rock.so/notes">notes</a>, and <a href="http://rock.so/files">files</a> and makes this available in <a href="http://rock.so/product">one space</a>. Because we combine these different types of communication, we make it easy for you to pick and choose the best way to interact with your team. We also work with Google Drive (and will work with Zoom and others soon) so it's easier to tap into your existing workflows.
                </p>
                <p>
                  When you <a href="http://rock.so/better-than-slack">compare Rock to Slack</a> you can easily see why we think Rock just works better for how work happens today.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row nine -->
          <div>
            
            <div>
              <p>
                <h3>Rock empowers anyone to work from anywhere</h3>
              </p>
            </div>
            
          </div>

          <!-- Row ten -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-3.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eleven -->
          <div>
            
            <div>
              <div>
                <p>
                  It's our mission to <b>build tools to empower anyone to work from anywhere</b>. When this happens - companies are more diverse, job opportunities are not limited by location and we all meet less, while doing more.
                </p>
                <p>
                  We have a lot more to say and lots more to build. If you want to join us on this journey to bring some much needed balance to the way we work, check out the video below or try out <a href="https://web.rock.so/?utm_source=website&amp;utm_medium=blog&amp;utm_campaign=hello">Rock</a> today.
                </p>
              </div>
            </div>
            
          </div>

          

          

          <section>
            <div>
              
          <!-- box card section -->
          <div>
            <div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/async.svg" alt="async"></p><h4>Product <br> details</h4>
                  <p>
                    Key features and more details about Rock.
                    <a href="http://rock.so/product">Read more</a>
                  </p>
                </div>

              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/recruiting/cross-org.svg" alt="async"></p><h4>How Rock <br> Works</h4>
                  <p>
                    Videos and walkthroughs to get you ready to Rock.
                    <a href="http://rock.so/how-rock-works">Read more</a>
                  </p>
                </div>
              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/zoom.svg" alt="async"></p><h4>Stop slacking, <br> start rocking.</h4>
                  <p>
                    Why Rock is better than Slack
                    <a href="http://rock.so/better-than-slack">Read more</a>
                  </p>
                </div>
              </div>
            </div>
          </div>
          <!-- box card section end -->


        </div>
      </section></div>

      
    </div></section></div>]]>
            </description>
            <link>http://rock.so/stopslacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279417</guid>
            <pubDate>Wed, 02 Dec 2020 18:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PTM – Page Table Manipulation from Usermode]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25279155">thread link</a>) | @DyslexicAtheist
<br/>
December 2, 2020 | https://back.engineering/01/12/2020/ | <a href="https://web.archive.org/web/*/https://back.engineering/01/12/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<div>

<hr>
<p>PDF Version (Best Version) can be downloaded here: <a href="https://githacks.org/_xeroxz/PTM/-/blob/master/PTM.pdf">PDF Download</a>.<br>
You can download the source from the open source repo here: <a href="https://githacks.org/_xeroxz/PTM">VDM Repo</a>.</p>

<hr>
<p>PTM is a Windows 10 C++ library that allows a programmer to manipulate all memory, physical, and virtual from user-mode. The project inherits an interface from VDM allowing the use of a physical memory read-write primitive to fuel this project. VDM is used solely to configure the page tables in such a way that PTM can manage them from user-mode. Once the page tables are configured for PTM VDM is no longer required. However, VDM can inherit an instance of PTM as a means to read and write physical memory. Both VDM and PTM work extremely well together and independently from each other.</p>

<hr>
<p>Page table manipulation is an extremely powerful primitive. One that allows groundbreaking projects to be created such as patching the kernel only in specific process-contexts, or mapping of a source process address space into a target process address space. PTM is a user-mode library that allows a programmer to manipulate page tables from user-mode on 64-bit Windows 10 systems. PTM does this by using VDM; a project designed to abuse vulnerable drivers exposing a physical memory read-write primitive (RWP) to elevate to arbitrary kernel execution. VDM is used to configure the page tables in such a way that they can be managed from user-mode without the need for VDM’s vulnerable driver being loaded into the kernel after initialization. PTM can then be used to get and set all levels of page table entries, translation linear virtual addresses from user-mode, map physical memory into virtual memory, and even create new page tables. PTM can also be used as a means to directly read and write physical memory, thus it can be used with VDM to leverage arbitrary kernel execution without the need of VDM’s vulnerable driver being loaded into the kernel.</p>

<hr>
<p>Paging is the concept of breaking memory into fixed-sized chunks called pages. Pages can be moved in and out of physical memory allowing for memory that is not accessed frequently to be moved to disk. In order for this to work, the CPU cannot directly interface with physical memory instead the CPU interfaces with virtual memory. Virtual addresses are translated to physical addresses using a set of tables called page tables. On a 64-bit system with the CPU in long mode, there are four layers of page tables: PML4(s), PDPT(s), PD(s), and lastly PT(s). All page tables are the same size (1000h bytes) unless configured otherwise. Each page table entry is eight bytes in size. This means that each table contains 512 entries (8 * 512 = 1000h). The last twelve bits of every virtual address is called the page offset and is an offset into a physical page. The page offset of a virtual address can be bigger than 12 bits depending on the paging structure configuration for a given virtual address. The length of the page offset field can be either 12 bits (physical page is 4kB), 21 bits (2MB physical page), or 30 bits (1GB page).</p>
<p><img src="https://imgur.com/IqB4B22.png"></p><p>In order to translate linear virtual addresses to linear physical addresses, the page tables must be traversed. As depicted in figure one, each virtual address space has its own PML4, the physical address of this table is stored in CR3.</p>

<hr>
<p>On Windows, the thread scheduler utilizes KPROCESS.DirectoryTableBase when scheduling threads. The KPROCESS structure is a substructure of the EPROCESS structure and contains DirectoryTableBase at offset 28h. A programmer using VDM can obtain the linear physical address of the PML4 of a process easily by DKOM’ing a desired process KPROCESS structure.</p>
<pre><code>kd&gt; dt !_KPROCESS ffffc38759d9e080
nt!_KPROCESS
   +0x000 Header           : _DISPATCHER_HEADER
   +0x018 ProfileListHead  : _LIST_ENTRY 
   +0x028 DirectoryTableBase : 0x00000001`15684000
   +0x030 ThreadListHead   : _LIST_ENTRY 
   +0x040 ProcessLock      : 0
   +0x044 ProcessTimerDelay : 0
   +0x048 DeepFreezeStartTime : 0
</code></pre><p>Once the physical address of the desired processes PML4 has been obtained the trick is interfacing with the paging structures. Although VDM allows reading and writing of physical memory, be aware that MmMapIoSpace cannot be used to map the paging structures into virtual memory. Drivers that use MmCopyMemory and ZwMapViewOfSection to interface with physical memory can however be used to directly manipulate the page tables. To properly support VDM which PTM inherits as a codebase, the project does not rely on the physical read and write primitive exposed from the driver. Instead PTM allocates its own set of page tables and inserts a PML4E into the current processes PML4 pointing at such tables. This allows a programmer to map physical memory at will into the current virtual memory address space, all from user-mode. In other words, once the tables are allocated and configured, there is no need for VDM anymore since the paging tables can be controlled entirely from user-mode.</p>

<hr>
<p>The translation look-aside buffer is a hardware-based cache that assists in translating linear virtual addresses to linear physical addresses. The TLB caches virtual to physical address translations, as well as other information like page access rights and cache type information. Although extremely important for efficiency, the TLB has made PTM an interesting challenge. For example, when physical memory is mapped into a virtual address space, page table entries will be inserted, or changed. This insertion or alteration of an existing page table entry may be of a cached entry in the TLB. This means that the effects applied to the page table entry will not be seen until the TLB entry for the given virtual page has been invalidated, along with the changes written to main memory. To counteract this, the CPU has an instruction that allows a programmer to invalidate a page table entry in the TLB’s cache. This instruction is called INVLPG and is a privileged instruction. It’s not something PTM can use since the library is designed to operate entirely from user-mode. Directly invalidating TLB is not the only way to invalidate entries. If a page fault occurs, the TLB invalidates entries for the given address that caused the fault (the address in CR2). This is an effective method for invalidating desired virtual addresses from user-mode but is extremely slow. Context switches do not inherently cause the TLB to flush, rather the PCID is changed to another PCID. This allows the TLB to retain entries from multiple address spaces and improve performance. However, yielding execution can invalidate TLB entries because the scheduler will reschedule the logical processor to execute somewhere else for some time, possibly filling the TLB with other entries and removing the ones that were previously cached.</p>
<h3 id="tlb_outrun"><a href="#tlb_outrun">TLB - Outrun</a></h3>
<hr>
<p>Although the TLB is an effective hardware-based cache, it cannot cache linear virtual addresses that have not been accessed before, this simple fact means a programmer can create a new linear virtual address every single time they would want to map a new physical page into virtual memory. This, however, is not a solid solution that works soundly on all modern CPUs. With the industry pushing forward with virtualization technology, the expansion of the TLB continues. Thus solely generating a new linear virtual address every time you would want to interface with a physical page is not a sound solution and is already unstable on most modern AMD chips. Instead combining this technique with other techniques is ideal.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>map_page(<span>void</span><span>*</span> addr) <span>-&gt;</span> <span>void</span><span>*</span>
{
	<span>++</span>pte_index;
	<span>if</span> (pte_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pde_index;
		pte_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pde_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pdpte_index;
		pde_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pdpte_index <span>&gt;</span> <span>511</span>)
		pdpte_index <span>=</span> <span>0</span>;

	<span>// insert paging table entries down here…
</span><span></span>	<span>//... (refer to PTM repo to see that code)...
</span><span></span>	<span>// returns the newly generated virtual address...
</span><span></span>	<span>return</span> <span>get_virtual_address</span>();
}
</code></pre></div><p>The code above generates a new linear virtual address that has not been accessed before. This linear virtual address points to the requests physical page in memory. This allows the programmer to circumvent the TLB by accessing new linear virtual addresses instead of trying to invalidate TLB entry of an existed and already cached page. This however has limitations since the code only provides 512^3 different possible virtual pages.</p>
<h3 id="tlb_benefit_of_the_doubt"><a href="#tlb_benefit_of_the_doubt">TLB - Benefit of The Doubt</a></h3>
<hr>
<p>Although outrunning the TLB is the fastest solution for mapping physical memory into virtual memory without needing to invalidate any TLB entries, it is not the most stable on modern hardware. Instead, a mixture of generating a new virtual address and an SEH try/except loop is preferred. By giving the new virtual address the benefit of the doubt that it has not been cached yet, an attempt to access the newly created page is performed. If the access is successful, the new linear virtual address is returned to the caller of ptm::ptm_ctx::map_page. However, if the access causes a page fault, the TLB invalidates the entries associated with this newly created linear virtual address. The except block then attempts to access the new page in a loop whilst yielding execution at each failure to access the new virtual address. This technique provides the most performant solution to dealing with the TLB from user-mode. This method guarantees that the linear virtual address generated is accessible before returning it to the caller.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>get_virtual_address() <span>const</span> <span>-&gt;</span> <span>void</span><span>*</span>
{
    <span>//...
</span><span></span>    
    <span>// start off by making sure that 
</span><span></span>	<span>// the address is accessible...
</span><span></span>	<span>__try</span>
	{
		<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value <span>=</span> <span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value;
		<span>return</span> new_addr.value;
	}

	<span>// if its not accessible then the
</span><span></span>	<span>// TLB just invalidated its entry...
</span><span></span>	<span>__except</span> (EXCEPTION_EXECUTE_HANDLER)
	{
		<span>// loop until this new address is accessible…
</span><span></span>		<span>// do not return until this new virtual
</span><span></span>		<span>// address is accessible....
</span><span></span>		<span>while</span> (true)
		{
			<span>// try again to access the page again 
</span><span></span>			<span>// and it should return...
</span><span></span>			<span>__try</span>
			{
				<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new…</code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://back.engineering/01/12/2020/">https://back.engineering/01/12/2020/</a></em></p>]]>
            </description>
            <link>https://back.engineering/01/12/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279155</guid>
            <pubDate>Wed, 02 Dec 2020 17:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vector 0.11 Release: K8s, ARC, and metrics collection]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25278771">thread link</a>) | @zhs
<br/>
December 2, 2020 | https://vector.dev/releases/0.11.0/ | <a href="https://web.archive.org/web/*/https://vector.dev/releases/0.11.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><li><div><p><a href="https://github.com/timberio/vector/pull/3099" target="_blank" title="View pull request..."><i></i> 3099</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Cleanup `list` command</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3190" target="_blank" title="View pull request..."><i></i> 3190</a></p></div><h4><span title="Filter to 'buffers' changes only">buffers</span><span title="Filter to 'sinks' changes only">sinks</span>Upgrade all VecBuffer sinks to allow setting `max_bytes`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3236" target="_blank" title="View pull request..."><i></i> 3236</a></p></div><h4><span title="Filter to 'socket source' changes only">socket source</span>Add max_length to UDP</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3151" target="_blank" title="View pull request..."><i></i> 3151</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'stdin source' changes only">stdin source</span>Instrument "stdin" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3241" target="_blank" title="View pull request..."><i></i> 3241</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Add received and invalid line events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3278" target="_blank" title="View pull request..."><i></i> 3278</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Provide error context on parse error</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3187" target="_blank" title="View pull request..."><i></i> 3187</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'kafka source' changes only">kafka source</span>Instrument "kafka" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3300" target="_blank" title="View pull request..."><i></i> 3300</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3317" target="_blank" title="View pull request..."><i></i> 3317</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'prometheus source' changes only">prometheus source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3315" target="_blank" title="View pull request..."><i></i> 3315</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'syslog source' changes only">syslog source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3264" target="_blank" title="View pull request..."><i></i> 3264</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'http source' changes only">http source</span>Add internal events for `http` source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3351" target="_blank" title="View pull request..."><i></i> 3351</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Make sourcetype templatable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3254" target="_blank" title="View pull request..."><i></i> 3254</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'statsd source' changes only">statsd source</span>Add events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3345" target="_blank" title="View pull request..."><i></i> 3345</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'docker source' changes only">docker source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3312" target="_blank" title="View pull request..."><i></i> 3312</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'splunk_hec source' changes only">splunk_hec source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/2913" target="_blank" title="View pull request..."><i></i> 2913</a></p></div><h4><span title="Filter to 'data_dog_metrics sink' changes only">data_dog_metrics sink</span>Add DataDog's `distribution` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3327" target="_blank" title="View pull request..."><i></i> 3327</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Add configuration for source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3337" target="_blank" title="View pull request..."><i></i> 3337</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field (#3300)</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3328" target="_blank" title="View pull request..."><i></i> 3328</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Add source configuration to Humio sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3356" target="_blank" title="View pull request..."><i></i> 3356</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logplex source' changes only">logplex source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3417" target="_blank" title="View pull request..."><i></i> 3417</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Add more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3421" target="_blank" title="View pull request..."><i></i> 3421</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'ansi_stripper transform' changes only">ansi_stripper transform</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3419" target="_blank" title="View pull request..."><i></i> 3419</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3418" target="_blank" title="View pull request..."><i></i> 3418</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3439" target="_blank" title="View pull request..."><i></i> 3439</a></p></div><h4><span title="Filter to 'aws_s3 sink' changes only">aws_s3 sink</span>Add additional canned ACLs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3434" target="_blank" title="View pull request..."><i></i> 3434</a></p></div><h4><span title="Filter to 'codecs' changes only">codecs</span><span title="Filter to 'console sink' changes only">console sink</span>Add "text" encoding for metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3436" target="_blank" title="View pull request..."><i></i> 3436</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Even more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3286" target="_blank" title="View pull request..."><i></i> 3286</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Rewrite parser, improve error handlings </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3476" target="_blank" title="View pull request..."><i></i> 3476</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'startup' changes only">startup</span><span title="Filter to 'shutdown' changes only">shutdown</span>Add events for starting, stopping, and reloading</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3502" target="_blank" title="View pull request..."><i></i> 3502</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add Heartbeat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3373" target="_blank" title="View pull request..."><i></i> 3373</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span><span title="Filter to 'compression' changes only">compression</span>Add support for gzip compression</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3475" target="_blank" title="View pull request..."><i></i> 3475</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span>Sync all data before finishing</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3521" target="_blank" title="View pull request..."><i></i> 3521</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3486" target="_blank" title="View pull request..."><i></i> 3486</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket source' changes only">socket source</span>Add and unify events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3523" target="_blank" title="View pull request..."><i></i> 3523</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'regex_parser transform' changes only">regex_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3553" target="_blank" title="View pull request..."><i></i> 3553</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'grok_parser transform' changes only">grok_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3598" target="_blank" title="View pull request..."><i></i> 3598</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add the ability to store pod labels flat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3602" target="_blank" title="View pull request..."><i></i> 3602</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Store pod labels flat by default, remove the switch</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3586" target="_blank" title="View pull request..."><i></i> 3586</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Add `file` label</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3582" target="_blank" title="View pull request..."><i></i> 3582</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add more `main` events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3593" target="_blank" title="View pull request..."><i></i> 3593</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3490" target="_blank" title="View pull request..."><i></i> 3490</a></p></div><h4><span title="Filter to 'wasm transform' changes only">wasm transform</span>Implement some UX improvements for WASM</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3610" target="_blank" title="View pull request..."><i></i> 3610</a></p></div><h4><span title="Filter to 'kuberentes platform' changes only">kuberentes platform</span>Adds new Helm template variable for podsLabels.</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3607" target="_blank" title="View pull request..."><i></i> 3607</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Multiline support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3577" target="_blank" title="View pull request..."><i></i> 3577</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tag_cardinality_limit transform' changes only">tag_cardinality_limit transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3554" target="_blank" title="View pull request..."><i></i> 3554</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'coercer transform' changes only">coercer transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3655" target="_blank" title="View pull request..."><i></i> 3655</a></p></div><h4><span title="Filter to 'http sink' changes only">http sink</span>Increase rate_limit_num to its maximum</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3690" target="_blank" title="View pull request..."><i></i> 3690</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span>Add a new options to control the auto concurrency limiter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3720" target="_blank" title="View pull request..."><i></i> 3720</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Fix TcpEventSent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3730" target="_blank" title="View pull request..."><i></i> 3730</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'swimlanes transform' changes only">swimlanes transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3699" target="_blank" title="View pull request..."><i></i> 3699</a></p></div><h4><span title="Filter to 'socket sink' changes only">socket sink</span>Add IPv6 supports</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3726" target="_blank" title="View pull request..."><i></i> 3726</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3782" target="_blank" title="View pull request..."><i></i> 3782</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Enhance checkpoint errors with file name</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3812" target="_blank" title="View pull request..."><i></i> 3812</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'reduce transform' changes only">reduce transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3809" target="_blank" title="View pull request..."><i></i> 3809</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'dedupe transform' changes only">dedupe transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3807" target="_blank" title="View pull request..."><i></i> 3807</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tokenizer transform' changes only">tokenizer transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3846" target="_blank" title="View pull request..."><i></i> 3846</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Support `summary` statistic</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3725" target="_blank" title="View pull request..."><i></i> 3725</a></p></div><h4><span title="Filter to 'datadog_metrics sink' changes only">datadog_metrics sink</span>Support datadog `distribution` metric </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3850" target="_blank" title="View pull request..."><i></i> 3850</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Regularize internal event messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3824" target="_blank" title="View pull request..."><i></i> 3824</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'security' changes only">security</span>Enable tls by default  for `papertrail` and `datadog_logs` sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3861" target="_blank" title="View pull request..."><i></i> 3861</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Improve retry error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3989" target="_blank" title="View pull request..."><i></i> 3989</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Accept more timestamp patterns in `to_timestamp`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4018" target="_blank" title="View pull request..."><i></i> 4018</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Include container_name in kubernetes_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3833" target="_blank" title="View pull request..."><i></i> 3833</a></p></div><h4><span title="Filter to 'gcp_stackdriver sink' changes only">gcp_stackdriver sink</span>Insert timestamp into stackdriver message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3778" target="_blank" title="View pull request..."><i></i> 3778</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>GraphQL client</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4075" target="_blank" title="View pull request..."><i></i> 4075</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_timestamp` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4090" target="_blank" title="View pull request..."><i></i> 4090</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `contains` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4092" target="_blank" title="View pull request..."><i></i> 4092</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `slice` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4093" target="_blank" title="View pull request..."><i></i> 4093</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `tokenize` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4020" target="_blank" title="View pull request..."><i></i> 4020</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add container_image and pod_node_name annotations</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4034" target="_blank" title="View pull request..."><i></i> 4034</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Emit warning on incomplete UDP sent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4170" target="_blank" title="View pull request..."><i></i> 4170</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `strip_ansi_escape_codes` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4188" target="_blank" title="View pull request..."><i></i> 4188</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha2` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4198" target="_blank" title="View pull request..."><i></i> 4198</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha3` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4215" target="_blank" title="View pull request..."><i></i> 4215</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>add field's value in warn message when failing to parse</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4236" target="_blank" title="View pull request..."><i></i> 4236</a></p></div><h4><span title="Filter to 'docker platform' changes only">docker platform</span>Added distroless-libc and distroless-static docker container bases</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4186" target="_blank" title="View pull request..."><i></i> 4186</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `parse_duration` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4032" target="_blank" title="View pull request..."><i></i> 4032</a></p></div><h4><span title="Filter to 'prometheus sink' changes only">prometheus sink</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4049" target="_blank" title="View pull request..."><i></i> 4049</a></p></div><h4><span title="Filter to 'auth' changes only">auth</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'aws service' changes only">aws service</span>Add EKS Web Identity Support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4191" target="_blank" title="View pull request..."><i></i> 4191</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Initial GraphQL topology</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4288" target="_blank" title="View pull request..."><i></i> 4288</a></p></div><h4><span title="Filter to 'console sink' changes only">console sink</span>Improve error handling</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4220" target="_blank" title="View pull request..."><i></i> 4220</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_number` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4383" target="_blank" title="View pull request..."><i></i> 4383</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Bidirectional source/transform/sink GraphQL types</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4429" target="_blank" title="View pull request..."><i></i> 4429</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Improve error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4412" target="_blank" title="View pull request..."><i></i> 4412</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span><span title="Filter to 'sinks' changes only">sinks</span>Option to specify `quantiles`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4037" target="_blank" title="View pull request..."><i></i> 4037</a></p></div><h4><span title="Filter to 'security' changes only">security</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>add TLS settings to influxdb_logs and influxdb_metrics sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4068" target="_blank" title="View pull request..."><i></i> 4068</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Add a tags configuration options to add user-defined tags</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4544" target="_blank" title="View pull request..."><i></i> 4544</a></p></div><h4><span title="Filter to 'debian platform' changes only">debian platform</span>Add vector user to adm in debian packaging</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/3557" target="_blank" title="View pull request..."><i></i> 3557</a></p></div><h4><span title="Filter to 'statsd sink' changes only">statsd sink</span>Support all socket types in statsd sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3032" target="_blank" title="View pull request..."><i></i> 3032</a></p></div><h4><span title="Filter to 'sinks' changes only">sinks</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'compression' changes only">compression</span>Add compression level</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4182" target="_blank" title="View pull request..."><i></i> 4182</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Allow using custom selectors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4406" target="_blank" title="View pull request..."><i></i> 4406</a></p></div><h4><span title="Filter to 'aws service' changes only">aws service</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'auth' changes only">auth</span>Support assume_role with EKS web identity</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4580" target="_blank" title="View pull request..."><i></i> 4580</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>Rename "identifier_fields" to "group_by"</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4579" target="_blank" title="View pull request..."><i></i> 4579</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>"concat_newline" strategy merges using newline</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4586" target="_blank" title="View pull request..."><i></i> 4586</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Advanced container filtering</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4428" target="_blank" title="View pull request..."><i></i> 4428</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Add `parse_url` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4164" target="_blank" title="View pull request..."><i></i> 4164</a></p></div><h4><span title="Filter to 'datadog_logs sink' changes only">datadog_logs sink</span><span title="Filter to 'networking' changes only">networking</span>Support datadog logs new HTTPS transport</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4385" target="_blank" title="View pull request..."><i></i> 4385</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span><span title="Filter to 'auth' changes only">auth</span>Basic auth support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4174" target="_blank" title="View pull request..."><i></i> 4174</a></p></div><h4><span title="Filter to 'datadog service' changes only">datadog service</span>Added region configuration parameter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4408" target="_blank" title="View pull request..."><i></i> 4408</a></p></div><h4><span title="Filter to 'windows platform' changes only">windows platform</span>Correctly handle service restart</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4557" target="_blank" title="View pull request..."><i></i> 4557</a></p></div><h4><span title="Filter to 'statsd source' changes only">statsd source</span>Add support for all socket types</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4647" target="_blank" title="View pull request..."><i></i> 4647</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'internal_metrics source' changes only">internal_metrics source</span>Updated internal metrics names to match standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4481" target="_blank" title="View pull request..."><i></i> 4481</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logfmt_parser transform' changes only">logfmt_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4701" target="_blank" title="View pull request..."><i></i> 4701</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span><span title="Filter to 'metrics' changes only">metrics</span>Add `namespace` to `Metric` </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4734" target="_blank" title="View pull request..."><i></i> 4734</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Force daemonset to redeploy when configmap is updated</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4581" target="_blank" title="View pull request..."><i></i> 4581</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Topology added/removed GraphQL subscriptions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4652" target="_blank" title="View pull request..."><i></i> 4652</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API host metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4733" target="_blank" title="View pull request..."><i></i> 4733</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span>annotate logs with query parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4751" target="_blank" title="View pull request..."><i></i> 4751</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Expose the performance related parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4735" target="_blank" title="View pull request..."><i></i> 4735</a></p></div><h4><span title="Filter to 'reload' changes only">reload</span>Resolve port conflict in sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4835" target="_blank" title="View pull request..."><i></i> 4835</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Add the ability to set conatiner ports at vector-agent Helm chart</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4480" target="_blank" title="View pull request..."><i></i> 4480</a></p></div><h4><span title="Filter to 'aws_ec2_metadata transform' changes only">aws_ec2_metadata transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4819" target="_blank" title="View pull request..."><i></i> 4819</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Adds optional file output to generator</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4831" target="_blank" title="View pull request..."><i></i> 4831</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add `namespace` option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4859" target="_blank" title="View pull request..."><i></i> 4859</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>display full error chain</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4884" target="_blank" title="View pull request..."><i></i> 4884</a></p></div><h4><span title="Filter to 'logdna sink' changes only">logdna sink</span>Support template syntax in hostname and tags field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4881" target="_blank" title="View pull request..."><i></i> 4881</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Add TLS and authentication options</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4873" target="_blank" title="View pull request..."><i></i> 4873</a></p></div><h4><span title="Filter to 'gcp_pubsub sink' changes only">gcp_pubsub sink</span>Add configurable endpoint</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4928" target="_blank" title="View pull request..."><i></i> 4928</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Kind/type for `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4836" target="_blank" title="View pull request..."><i></i> 4836</a></p></div><h4><span title="Filter to 'journald source' changes only">journald source</span>Restart journalctl on errors, save checkpoint on shutdown</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4998" target="_blank" title="View pull request..."><i></i> 4998</a></p></div><h4><span title="Filter to 'sources' changes only">sources</span>make scrape interval configurable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4945" target="_blank" title="View pull request..."><i></i> 4945</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Humanized formatting for `vector top` metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4958" target="_blank" title="View pull request..."><i></i> 4958</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Batch events processed total</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5002" target="_blank" title="View pull request..."><i></i> 5002</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Added batch subscriptions for component bytes and errors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5004" target="_blank" title="View pull request..."><i></i> 5004</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API batch support + tests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5018" target="_blank" title="View pull request..."><i></i> 5018</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API version + hostname queries</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4887" target="_blank" title="View pull request..."><i></i> 4887</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add PodIPs into Pod Metadata events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4999" target="_blank" title="View pull request..."><i></i> 4999</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>More debug info on more HTTP requests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5026" target="_blank" title="View pull request..."><i></i> 5026</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>add internal option to ignore missing files</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5034" target="_blank" title="View pull request..."><i></i> 5034</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Edited a few vector top error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4902" target="_blank" title="View pull request..."><i></i> 4902</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>compile-time program result type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5008" target="_blank" title="View pull request..."><i></i> 5008</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>support enum variants for function arguments</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5015" target="_blank" title="View pull request..."><i></i> 5015</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>use path arguments for `del` and `only_field` functions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5039" target="_blank" title="View pull request..."><i></i> 5039</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Renamed docker source to docker_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5053" target="_blank" title="View pull request..."><i></i> 5053</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>expressions no longer return an option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5074" target="_blank" title="View pull request..."><i></i> 5074</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Rename `version` -&gt; `versionString` in GraphQL schema</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5056" target="_blank" title="View pull request..."><i></i> 5056</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>undefined path or variable return null</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5016" target="_blank" title="View pull request..."><i></i> 5016</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add I/O (throughput) columns to `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5146" target="_blank" title="View pull request..."><i></i> 5146</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Expire checkpoints</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5153" target="_blank" title="View pull request..."><i></i> 5153</a></p></div><h4><span title="Filter to 'kafka source' changes only">kafka source</span>Include kafka metadata as optional keys</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4918" target="_blank" title="View pull request..."><i></i> 4918</a></p></div><h4><span title="Filter to 'sampler transform' changes only">sampler transform</span>Add rating by `index`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5095" target="_blank" title="View pull request..."><i></i> 5095</a></p></div><h4><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Support basic-auth credentials in endpoint configuation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5171" target="_blank" title="View pull request..."><i></i> 5171</a></p></div><h4><span title="Filter to 'api' changes only">api</span> Allow querying transform outputs on transform components</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4615" target="_blank" title="View pull request..."><i></i> 4615</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span>Expose internal metrics cardinality as a internal metric counter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5218" target="_blank" title="View pull request..."><i></i> 5218</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add test for component links</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5204" target="_blank" title="View pull request..."><i></i> 5204</a></p></div><h4><span title="Filter to 'loki sink' changes only">loki sink</span>Allow tenant_id to be templatable on loki sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5059" target="_blank" title="View pull request..."><i></i> 5059</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>improve arithmetic type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4699" target="_blank" title="View pull request..."><i></i> 4699</a></p></div><h4><span title="Filter to 'mongodb_metrics source' changes only">mongodb_metrics source</span>Renamed mongo metrics to new naming standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4681" target="_blank" title="View pull request..."><i></i> 4681</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `ConnectionOpen` gauge</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4806" target="_blank" title="View pull request..."><i></i> 4806</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sinks</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4833" target="_blank" title="View pull request..."><i></i> 4833</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sources</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4996" target="_blank" title="View pull request..."><i></i> 4996</a></p></div><h4><span title="Filter to 'shutdown' changes only">shutdown</span>Extend `Resource` to sources </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5048" target="_blank" title="View pull request..."><i></i> 5048</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Beautify reports of conflicting `Resource` usage</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5098" target="_blank" title="View pull request..."><i></i> 5098</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>add _total suffix to events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4922" target="_blank" title="View pull request..."><i></i> 4922</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Emit `FileOpen` in `file` sink and source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5183" target="_blank" title="View pull request..."><i></i> 5183</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Incorrect Log Level Message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5005" target="_blank" title="View pull request..."><i></i> 5005</a></p></div><h4><span title="Filter to 'config' changes only">config</span>Allow JSON and YAML config formats in addition to TOML</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5296" target="_blank" title="View pull request..."><i></i> 5296</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Enable TLS subscription connections in vector top</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5021" target="_blank" title="View pull request..."><i></i> 5021</a></p></div><h4><span title="Filter to 'pulsar sink' changes only">pulsar sink</span>introduce encoding schema and pulsar avro schema</h4></li></div></div>]]>
            </description>
            <link>https://vector.dev/releases/0.11.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278771</guid>
            <pubDate>Wed, 02 Dec 2020 17:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Materialize Raises a $32M Series B]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25277511">thread link</a>) | @austinbirch
<br/>
December 2, 2020 | https://materialize.com/materialize-series-b/ | <a href="https://web.archive.org/web/*/https://materialize.com/materialize-series-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today we <a href="https://www.prnewswire.com/news-releases/materialize-raises-40-million-to-simplify-streaming-data-with-sql-and-speed-up-real-time-analytics-301180777.html">announced</a> that we raised a $32M Series B round of funding led by Kleiner Perkins. This follows a $8.5m Series A last year led by Lightspeed Venture Partners, bringing our total funding to-date to a little over $40 million. With our Series B, <a href="https://www.kleinerperkins.com/people/bucky-moore/" target="_blank" rel="noopener noreferrer">Bucky Moore</a> joins <a href="https://lsvp.com/?team=ravi-mhatre/" target="_blank" rel="noopener noreferrer">Ravi Mhatre</a> on our board of directors.</p>
<p>At Materialize, we believe that at every business it will soon be essential for all information to be always up-to-date. Whether it’s delivering personalized experiences, accurately identifying fraud, building predictive AI, or discovering new business opportunities, the ability to run complex queries on multiple streams of data and keep their answers up to date is critical to making better decisions about the changing world around us.</p>
<p>While the past decade has seen a groundswell in the adoption of streaming platforms, they are still too difficult to use. Current systems require users to make tradeoffs between dumbing down their queries, waiting for hours-long batch ETL pipelines to finish, or building and orchestrating sprawling microservices. We believe users should not have to make these tradeoffs.</p>
<p>Materialize’s mission is to make queries against streaming data simple. We support industry standard SQL: write queries with multi-way joins, correlated subqueries, and complex aggregations, and we’ll keep the answers always up to date for you. In a world where “real-time” has become an empty buzzword, Materialize provides answers that are up to date within milliseconds. All of this comes in <a href="https://materialize.com/docs/install/" target="_blank" rel="noopener noreferrer">a single binary</a> that is easy to install, easy to use, and easy to deploy. With Materialize, users can get interactive and always-up-to-date answers about their changing data using only their existing SQL skills.</p>
<p>While Materialize is a young company, it is built on top of the award winning Timely Dataflow project, spanning almost a decade of cutting-edge research on stream processing led by my co-founder Frank McSherry. Starting from this solid foundation, $40 million dollars of capital gives us the resources to build the no-compromise streaming database that lets every developer build streaming applications.</p>
<p>With this new round of funding, we are well equipped to deliver on <a href="https://materialize.com/blog-roadmap/" target="_blank" rel="noopener noreferrer">an ambitious roadmap</a>, including a fully-managed cloud service with tiered storage and replication. We’re also excited to continue work on broadening the suite of SQL tools that we support, as well as investing in a SQL optimizer, performance and benchmarking work, and in making Materialize more resilient and battle-tested. If you’re interested in working on any of these challenges, Materialize <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">is hiring</a> across the board.</p>
<p>And finally, while it is exciting to build Materialize, it has been even more exciting to see how Materialize is being used to build applications that previously would have required months of development, using just a few simple SQL queries. If you’re as excited about Materialize as we are, we’d love for you to get involved. <a href="https://materialize.com/quickstart/" target="_blank" rel="noopener noreferrer">Download</a> and try Materialize, try <a href="https://materialize.com/docs/katacoda/?intro-wikipedia" target="_blank" rel="noopener noreferrer">a demo</a> in your browser, <a href="https://join.slack.com/t/materializecommunity/shared_invite/zt-jjwe1t45-klG9k7V7xibdtqA6bcFpyQ" target="_blank" rel="noopener noreferrer">join the community</a> and say hello, or <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">apply</a> to join our growing team today!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/materialize-series-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277511</guid>
            <pubDate>Wed, 02 Dec 2020 15:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rga: Ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz]]>
            </title>
            <description>
<![CDATA[
Score 627 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25277280">thread link</a>) | @angrygoat
<br/>
December 2, 2020 | https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/ | <a href="https://web.archive.org/web/*/https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small><time datetime="2019-06-16T00:00:00.000Z">Jun 16, 2019</time> • <a href="https://github.com/phiresky/blog/commits/master/posts/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg.md">Last Update <time datetime="2019-06-16T00:00:00.000Z">Oct 21, 2019</time></a></small></p><p><a href="https://github.com/phiresky/ripgrep-all">rga</a> is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and enables it to search in pdf, docx, sqlite, jpg, zip, tar.*, movie subtitles (mkv, mp4), etc.</p><p><a href="https://github.com/phiresky/ripgrep-all"><img src="https://img.shields.io/badge/repo-github.com%2Fphiresky%2Fripgrep--all-informational.svg" title=""></a>
<a href="https://crates.io/crates/ripgrep-all"><img src="https://img.shields.io/crates/v/ripgrep-all.svg" title=""></a>
<a href="https://www.reddit.com/r/rustjerk/top/?sort=top&amp;t=all"><img src="https://img.shields.io/badge/concurrency-fearless-success.svg" title=""></a></p><h2 id="examples">Examples</h2><h3 id="pdfs">PDFs</h3><p>Say you have a large folder of papers or lecture slides, and you can’t remember which one of them mentioned <code>GRU</code>s. With rga, you can just run this:</p><div><pre>~$ rga "GRU" slides/
<span>slides/2016/winter1516_lecture14.pdf</span>
Page 34:   <span></span><span>GRU</span>                            LSTM
Page 35:   <span></span><span>GRU</span>                            CONV
Page 38:     - Try out <span></span><span>GRU</span>-RCN! (imo best model)

<span>slides/2018/cs231n_2018_ds08.pdf</span>
Page  3: ●   CNNs, GANs, RNNs, LSTMs, <span></span><span>GRU</span>
Page 35: ● 1) temporal pooling 2) RNN (e.g. LSTM, <span></span><span>GRU</span>)

<span>slides/2019/cs231n_2019_lecture10.pdf</span>
Page 103:   <span></span><span>GRU</span> [Learning phrase representations using rnn
Page 105:    - Common to use LSTM or <span></span><span>GRU</span>

</pre></div><p>and it will recursively find a string in pdfs, including if some of them are zipped up.</p><p>You can do mostly the same thing with <a href="https://pdfgrep.org/"><code>pdfgrep -r</code></a>, but you will miss content in other file types and it will be much slower:</p><div><p>Searching in 65 pdfs with 93 slides each</p><div><div><svg width="600" height="200" viewBox="0 0 600 200" version="1.1"><defs><clipPath id="recharts2-clip"><rect x="105" y="5" height="160" width="490"></rect></clipPath></defs><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="165" x2="595" y2="165"></line><g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="171" x2="105" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="105" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="105" dy="0.71em">0</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="227.5" y1="171" x2="227.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="227.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="227.5" dy="0.71em">5</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="350" y1="171" x2="350" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="350" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="350" dy="0.71em">10</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="472.5" y1="171" x2="472.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="472.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="472.5" dy="0.71em">15</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="595" y1="171" x2="595" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="595" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="595" dy="0.71em">20</tspan></text></g></g></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="105" y1="5" x2="105" y2="165"></line><g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="31.666666666666668" x2="105" y2="31.666666666666668"></line><text type="category" width="100" orientation="left" height="160" x="97" y="31.666666666666668" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">pdfgrep</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="85" x2="105" y2="85"></line><text type="category" width="100" orientation="left" height="160" x="97" y="85" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (first run)</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="138.33333333333334" x2="105" y2="138.33333333333334"></line><text type="category" width="100" orientation="left" height="160" x="97" y="138.33333333333334" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (subsequent runs)</tspan></text></g></g></g><g><g><g><path name="pdfgrep" fill="#8884d8" width="469.41999999999996" height="42" x="105" y="10.333333333333334" radius="0" d="M 105,10.333333333333334 h 469.41999999999996 v 42 h -469.41999999999996 Z"></path></g><g><path name="rga (first run)" fill="#8884d8" width="72.27500000000003" height="42" x="105" y="63.66666666666667" radius="0" d="M 105,63.66666666666667 h 72.27500000000003 v 42 h -72.27500000000003 Z"></path></g><g><path name="rga (subsequent runs)" fill="#8884d8" width="2.2539999999999907" height="42" x="105" y="117" radius="0" d="M 105,117 h 2.2539999999999907 v 42 h -2.2539999999999907 Z"></path></g></g></g></svg><div><ul><li><svg width="14" height="14" style="display:inline-block;vertical-align:middle;margin-right:4px" viewBox="0 0 32 32" version="1.1"><path stroke="none" fill="#8884d8" d="M0,4h32v24h-32z"></path></svg><span>run time (seconds, lower is better)</span></li></ul></div></div></div></div><p>On the first run rga is mostly faster because of multithreading, but on subsequent runs (with the same files but any regex query) rga will cache the text extraction, so it becomes almost as fast as searching in plain text files. All runs were done with a warm FS cache.</p><h3 id="other-files">Other files</h3><p>rga will recursively descend into archives and match text in every file type it knows.</p><p>Here is an example directory with different file types:</p><pre><code>demo
├── greeting.mkv
├── hello.odt
├── hello.sqlite3
└── somearchive.zip
    ├── dir
    │&nbsp;&nbsp; ├── greeting.docx
    │&nbsp;&nbsp; └── inner.tar.gz
    │&nbsp;&nbsp;     └── greeting.pdf
    └── greeting.epub</code></pre><p>(see the actual directory <a href="https://github.com/phiresky/ripgrep-all/tree/master/exampledir/demo">here</a>)</p><div><pre>~$ rga "hello" demo/

<span>demo/greeting.mkv</span>
metadata: chapters.chapter.0.tags.title="Chapter 1: <span></span><span>Hello</span>"
00:08.398 --&gt; 00:11.758: <span></span><span>Hello</span> from a movie!

<span>demo/hello.odt</span>
<span></span><span>Hello</span> from an OpenDocument file!

<span>demo/hello.sqlite3</span>
tbl: greeting='<span></span><span>hello</span>', from='sqlite database!'

<span>demo/somearchive.zip</span>
dir/greeting.docx: <span></span><span>Hello</span> from a MS Office document!
dir/inner.tar.gz: greeting.pdf: Page 1: <span></span><span>Hello</span> from a PDF!
greeting.epub: <span></span><span>Hello</span> from an E-Book!
</pre></div><p>It can even search jpg / png images and scanned pdfs using OCR, though this is disabled by default since it is not useful that often and pretty slow.</p><div><pre>~$ # find screenshot of crates.io
~$ rga crates ~/screenshots --rga-adapters=+pdfpages,tesseract
<span>screenshots/2019-06-14-19-01-10.png</span>
<span></span><span>crates</span>.io I Browse All <span></span><span>Crates</span>  Docs v
Documentation Repository Dependent <span></span><span>crates</span>

~$ # there it is!
</pre></div><h2 id="setup">Setup</h2><p>Linux, Windows and OSX binaries are available in GitHub releases. See <a href="https://github.com/phiresky/ripgrep-all#installation">the readme</a> for more information.</p><p>For Arch Linux, I have packaged <code>rga</code> in the AUR: <a href="https://aur.archlinux.org/packages/ripgrep-all/"><code>yay -S ripgrep-all</code></a></p><h2 id="technical-details">Technical details</h2><p>The code and a few more details are here: <a href="https://github.com/phiresky/ripgrep-all">https://github.com/phiresky/ripgrep-all</a></p><p><code>rga</code> simply runs ripgrep (<code>rg</code>) with some options set, especially <code>--pre=rga-preproc</code> and <code>--pre-glob</code>.</p><p><code>rga-preproc [fname]</code> will match an <span>"<!-- -->adapter<!-- -->"</span> to the given file based on either it’s filename or it’s mime type (if <code>--rga-accurate</code> is given). You can see all adapters currently included in <a href="https://github.com/phiresky/ripgrep-all/tree/master/src/adapters">src/adapters</a>.</p><p>Some rga adapters run external binaries to do the actual work (such as pandoc or ffmpeg), usually by writing to stdin and reading from stdout. Others use a Rust library or bindings to achieve the same effect (like sqlite or zip).</p><p>To read archives, the <code>zip</code> and <code>tar</code> libraries are used, which work fully in a streaming fashion - this means that the RAM usage is low and no data is ever actually extracted to disk!</p><p>Most adapters read the files from a <a href="https://doc.rust-lang.org/std/io/trait.Read.html">Read</a>, so they work completely on streamed data (that can come from anywhere including within nested archives).</p><p>During the extraction, rga-preproc will compress the data with ZSTD to a memory cache while simultaneously writing it uncompressed to stdout. After completion, if the memory cache is smaller than 2MByte, it is written to a <a href="https://docs.rs/rkv/0.9.6/rkv/">rkv</a> cache. The cache is keyed by (adapter, filename, mtime), so if a file changes it’s content is extracted again.</p><h2 id="future-work">Future Work</h2><ul><li>I wanted to add a photograph adapter (based on object classification / detection) for fun, so you can grep for <span>"<!-- -->mountain<!-- -->"</span> and it will show pictures of mountains, like in Google Photos. It worked with <a href="https://pjreddie.com/darknet/yolo/">YOLO</a>, but something more useful and state-of-the art <a href="https://github.com/aimagelab/show-control-and-tell">like this</a> proved very hard to integrate.</li><li>7z adapter (couldn’t find a nice to use Rust library with streaming)</li><li>Allow per-adapter configuration options (probably via env (RGA_ADAPTERXYZ_CONF=json))</li><li>Maybe use a different disk kv-store as a cache instead of rkv, because I had some <a href="https://github.com/phiresky/ripgrep-all/blob/05835c1c42bc3575023a81e5494c5530078730fc/src/preproc_cache.rs#L30">weird problems</a> with that. SQLite is great. All other Rust alternatives I could find don’t allow writing from multiple processes.</li><li>Tests!</li><li>There’s some more (mostly technical) todos in the code I don’t know how to fix. Help wanted.</li><li>Other <a href="https://github.com/phiresky/ripgrep-all/issues">open issues</a></li></ul><ul><li><a href="https://pdfgrep.org/">pdfgrep</a></li><li><a href="https://gist.github.com/phiresky/5025490526ba70663ab3b8af6c40a8db">this gist</a> has my proof of concept version of a caching extractor to use ripgrep as a replacement for pdfgrep.</li><li><a href="https://gist.github.com/ColonolBuendia/314826e37ec35c616d70506c38dc65aa">this gist</a> is a more extensive preprocessing script by <a href="https://github.com/ColonolBuendia">@ColonolBuendia</a></li><li><a href="https://github.com/wofr06/lesspipe">lesspipe</a> is a tool to make <code>less</code> work with many different file types. Different usecase, but similar in what it does.</li></ul></div></div>]]>
            </description>
            <link>https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277280</guid>
            <pubDate>Wed, 02 Dec 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Netflix]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25277041">thread link</a>) | @leopold_a
<br/>
December 2, 2020 | https://www.forourposterity.com/against-netflix/ | <a href="https://web.archive.org/web/*/https://www.forourposterity.com/against-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It has become fashionable to lambast big tech corporations and social media sites, the Facebooks and Twitters and Googles, blaming them for a litany of social ills. Seemingly escaping this ire has been the—in my view—most pernicious by far: Netflix.</p><p>Simply put, Netflix (and its imitators) produce too many TV shows that are too good—and too easy to binge. Consequently, too many great minds spend their time watching TV rather than thinking and inventing and creating.</p><h2 id="the-greatness-we-lose">The Greatness We Lose</h2><p>Consider the writer Matthew Yglesias. He just wrote an excellent <a href="https://www.amazon.com/One-Billion-Americans-Thinking-Bigger/dp/0593190211/">book</a>, which partially inspired my <a href="https://www.forourposterity.com/canada-and-mexico-should-join-the-union/">last post</a>. Recently, Yglesias <a href="https://web.archive.org/web/20200912220900/https://twitter.com/mattyglesias/status/1304904789055156225">tweeted</a>:</p><blockquote>Someone asked … “how’d you get this book written without taking time off work?” and the dumb boring answer was basically “didn’t watch much TV for six months.”</blockquote><p>He adds,</p><blockquote>I am perfectly aware that the difference between times when I’m most productive &amp; creative and times when I’m not is how much of the week I waste on watching television, yet tonight I’m almost certainly going to finish season two of Hannibal.</blockquote><p>Yglesias, turn off the TV! Write more books instead! Heck, write more tweets, if you prefer!</p><p>Just think of all the original ideas Yglesias could be contributing if he continued to abstain from watching TV. Of them we are being robbed. That is an epic <a href="https://applieddivinitystudies.com/murder-of-wilbur/">tragedy</a>.</p><h2 id="why-modern-tv-is-different">Why Modern TV Is Different</h2><p>I don’t mean to pick on Yglesias. In fact, I don’t blame him. Modern shows are just too good. As a result, it’s become accepted—even the norm—among elite, educated classes to watch inordinate amounts of TV.</p><p>Modern shows are different from classic TV in two key ways. First, they are much more engrossing. Netflix shows are just on a different level in terms of quality than what TV once offered. Second, they are bingeable. Instead of tuning in for an hour each week, Netflix encourages viewers to enter the dark hole of watching episode after episode after episode. This becomes a vicious cycle. Viewers binge late into the night, lose sleep, and then don’t feel energetic enough to do much in their free time the next day besides…watching more Netflix.</p><p>Movies were always pretty engrossing. But the boundless quantity of content on Netflix—as well as their deliberate addictiveness—puts it on a different level.</p><p>To be sure, the broad America public has always watched <a href="https://www.theatlantic.com/technology/archive/2018/05/when-did-tv-watching-peak/561464/">extraordinary amounts</a> of television, in particular retirees. For them, the improved quality of modern shows is surely an upgrade. But I do think Netflix has distinctly changed the culture around TV among the young and educated.</p><p>As an undergraduate at Columbia, it was extremely common for students to spend much of their free time engorging themselves on Netflix. Many were caught in that maelstrom of bingeing, losing sleep, and then bingeing more. What was most shocking was this practice’s sheer acceptability. Watching dozens of hours of Netflix a week wasn’t something out of the ordinary, something people were embarrassed by. Rather, Netflix bingeing was a core part of the culture, something people would make countless memes about and base their identities on. Amazingly, people’s chief complaint was often that they had exhausted all of Netflix’s content (how do you even do that?!).</p><p>Yglesias got his start blogging in college. Would the next Yglesias be able to do the same? Or would his free time and energy instead be sucked up by the latest, ever-more addictive Netflix show? What a loss for civilization that would be.</p><h2 id="for-a-new-temperance-movement">For a New Temperance Movement</h2><p>Again, I don’t blame the students. I am victim to the same human follies. But I do blame the culture we have created. We don’t tell our bright young minds that it’s alright to waste away your days drinking or abusing drugs. Sure, some end up doing so regardless, but the cultural tabu keeps those impulses in check. Why do we tell them it’s alright to waste away your days watching Netflix?</p><p>Indeed, there has been considerable pushback against video games, which for some are a similar time suck. While many still struggle, this cultural pushback has kept video games in check. At least among the educated classes, Netflix and its imitators have become the far greater time suck.</p><p>For those who can enjoy TV in moderation—great. Modern shows are often meaningful art worth appreciating. The problem with modern TV is that for many, it is closer to alcoholism than a one-off drink. One you watch that first episode—take that first drink—it often doesn’t stay at one episode—as it doesn’t stay at one drink.</p><p>Perhaps it is time for a modern TV-temperance movement. It would be worth encouraging moderation in TV consumption in general. But given that many TV habits resemble alcoholism, it may be appropriate to take a more radical approach: advocating TV-abstinence. Although complete avoidance of TV may be difficult at first, once it becomes a habit, I think most wouldn’t miss much. But they would enjoy an abundance of reclaimed time and energy. And the rest of us would enjoy the wonderful works they create with that newfound time and energy.</p><h2 id="brains-in-vats">Brains in Vats</h2><p>The culture we establish around Netflix matters not just for the present, but for what comes next. As entertainment technology relentlessly advances, are we destined to become brains in vats, nominally pumped full of artificial bliss but doomed to lives of passivity and complacency?</p><p>Look, if that’s what the Europeans want to do, they should go for it. But part of what makes America special is a certain harshness—first embodied in the Puritans and their quest to settle America’s unforgiving wilderness. Great achievements, new ideas, ingenious inventions emerge from a culture that prizes travail and perseverance, not one that prioritizes comfort and ephemeral satisfaction.</p><p>A blithe acceptance of Netflix has insidiously infiltrated our culture. We should push back. Let’s look to the stars, not the next episode.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to For Our Posterity</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
              <h2><span id="cove-count"></span> Comments</h2>

    <p>Sign in or become a For Our Posterity member to join the conversation.<br>
    Just enter your email below to get a log in link.</p>
    

  


  


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.forourposterity.com/against-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277041</guid>
            <pubDate>Wed, 02 Dec 2020 15:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Escape the Modern Rat Race]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25276844">thread link</a>) | @durmonski
<br/>
December 2, 2020 | https://durmonski.com/psychology/escape-the-modern-rat-race/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/escape-the-modern-rat-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://durmonski.com/psychology/escape-the-modern-rat-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276844</guid>
            <pubDate>Wed, 02 Dec 2020 14:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Cybersecurity Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25276033">thread link</a>) | @atum47
<br/>
December 2, 2020 | https://eloeffler.gitlab.io/eloeffler/proto-vcser/ | <a href="https://web.archive.org/web/*/https://eloeffler.gitlab.io/eloeffler/proto-vcser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="indexgreeter">
    
<p>    Marwin Mueller, age 65, owns Spass GmbH. An SME in Luzern which has an annual turnover of close to 1.000.000 CHF and an annual profit of 200.000 CHF.  </p>
<p>    Spass GmbH has been operating in the hospitality industry for the last 30 years and is managing renouned hotels and villas in the Luzern Lake area.  </p>
<p>    Anne Kingston, age 29, is Marwins assistant and accountant. She has joined a year back and during her interactions, she mentioned to Marwin that she is a single mom of a six year old boy named Ryan.  </p>
<p>    Anne is a pleasant and helping personality. She likes plants and playing video games.  </p>
<p>    Marwin is very proud of his business achievements and sometimes acts as an arrogant boss. He is a bit insensitive to kids, due to his experiences. In general, he gets along with Anne and they form a great team at Spass. In the past year, Anne took over most of the office tasks at Spass. She is technology savvy and Marwin likes this quality of Anne's over his other staff.  </p>
<p>    Marwin and Anne worked on important digital initiatives at Spass like listing its properties on booking portals, creating their own website, launching social media accounts and enabling online banking at UBC Bank in Luzern.  </p>
<p>    This gave Marwin an edge over his competitors and Spass has seen a 30% increase in revenues and profits this year.  </p>
<p>    Today, Marwin remembers that two weeks back, Anne came to him and wanted a 1 week vacation to spend time with her son Ryan on occasion of his birthday.  </p>
<p>    Once again, Marwin and Anne had arguments on Anne's vacations in peak season and Marwin blamed Ryan for this.  At the end, Marwin reluctantly agreed to the holidays.</p>
<p>Since then, Anne did not turn up for work. She is not reachable on her mobile and her house is locked.</p>
<p>Marwin has just found that his bank account is debited with 2.000 CHF every day since Anne left.</p>
<p>Marwin has no idea what is happening and he is worried. Therefor, as trusted friends, he has requested that you come here and help him.</p>
<p>Marwin believes it is not a good idea to report the incident immediately to the police or bank as it can damage his reputation.</p>
<p>Now it's Friday. It's 7pm and the UBC Bank is already closed for the weekend.</p>
<p>You need to analyze the gaps Anne might have in her Cybersecurity awareness and secure the Online Banking to stop the money transfers.</p>
<p>Also, try to find out where Anne might be.</p>
<p>All the very best.
  </p></div></div>]]>
            </description>
            <link>https://eloeffler.gitlab.io/eloeffler/proto-vcser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276033</guid>
            <pubDate>Wed, 02 Dec 2020 13:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National parks of New Zealand in 3D]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25275588">thread link</a>) | @pheelicks
<br/>
December 2, 2020 | https://felixpalmer.github.io/new-zealand-3d/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/new-zealand-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/new-zealand-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275588</guid>
            <pubDate>Wed, 02 Dec 2020 12:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK approves Pfizer vaccine for rollout next week]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25275329">thread link</a>) | @williamsharris
<br/>
December 2, 2020 | https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week | <a href="https://web.archive.org/web/*/https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>LONDON –</strong> Britain today became the first Western country to approve a Covid-19 vaccine for general use as it announced a rollout of Pfizer-BioNTech's drug from next week.&nbsp;</p>

<p>"The government has today accepted the recommendation from the independent Medicines and Healthcare products Regulatory Agency (MHRA) to approve Pfizer-BioNTech's Covid-19 vaccine for use," the Health Department said in a statement.</p>

<p>"The vaccine will be made available across the UK from next week," the statement said. Priority groups will include care home residents, health and care staff, the elderly and the clinically extremely vulnerable.</p>

<p>After months of "rigorous" clinical trials and thorough analysis of the data, the MHRA "concluded that the vaccine has met its strict standards of safety, quality and effectiveness", the statement added.</p>

<p>"To aid the success of the vaccination programme, it is vital everyone continues to play their part and abide by the necessary restrictions in their area so we can further suppress the virus and allow the NHS (National Health Service) to do its work without being overwhelmed."</p>

<p>Pfizer chairman Albert Bourla said it was a "historic moment in the fight against Covid-19".&nbsp;</p>

<p>"This authorisation is a goal we have been working toward since we first declared that science will win, and we applaud the MHRA for their ability to conduct a careful assessment and take timely action to help protect the people of the UK," he said.</p>

<p>Pfizer and BioNTech added that they expected further regulatory decisions from other countries "in the coming days and weeks".</p>

<p>The announcement came as England exited a month-long coronavirus lockdown, but most of the country remained under restrictions as a new regional system for cutting infection rates kicked in.</p>

<p>The four-week lockdown, which began last month, was imposed to stop surging rates of infection, ease pressure on health services, and to allow families to gather for Christmas.</p>

<p>Prime Minister Boris Johnson, a Covid survivor, succeeded in winning a vote on the measures in parliament late yesterday, despite significant opposition within his own Conservative ranks.</p>

<p>"All we need to do now is to hold our nerve until these vaccines are indeed in our grasp and indeed being injected into our arms," he told lawmakers before the vote.</p>

<p>Until then "we cannot afford to relax, especially during the cold months of winter", he warned. – AFP, December 2, 2020</p>

                
                

                <div>
                    <div>
                        <h2>Get news, from every side. Subscribe to our newsletter!</h2>
                        


                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275329</guid>
            <pubDate>Wed, 02 Dec 2020 11:06:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux kernel heap quarantine versus use-after-free exploits]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25274928">thread link</a>) | @kmwyard
<br/>
December 2, 2020 | https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html | <a href="https://web.archive.org/web/*/https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It's 2020. Quarantines are everywhere – and here I'm writing about one, too.
But this quarantine is of a different kind.</p>

<p>In this article I'll describe the <strong>Linux Kernel Heap Quarantine</strong> that I developed
for mitigating kernel use-after-free exploitation. I will also summarize
the discussion about the prototype of this security feature on the Linux Kernel
Mailing List (LKML).</p>



<p>Use-after-free (UAF) vulnerabilities in the Linux kernel are very popular for
exploitation. There are many exploit examples, some of them include:</p>
<ul>
  <li><a href="https://seclists.org/oss-sec/2016/q4/607">CVE-2016-8655</a></li>
  <li><a href="https://www.openwall.com/lists/oss-security/2017/02/26/2">CVE-2017-6074</a></li>
  <li><a href="https://a13xp0p0v.github.io/2017/03/24/CVE-2017-2636.html">CVE-2017-2636</a></li>
  <li><a href="https://ssd-disclosure.com/ssd-advisory-linux-kernel-af_packet-use-after-free/">CVE-2017-15649</a></li>
  <li><a href="https://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html">CVE-2019-18683</a></li>
</ul>

<p>UAF exploits usually involve <strong>heap spraying</strong>.
Generally speaking, this technique aims to put attacker-controlled bytes at a defined memory
location on the heap. Heap spraying for exploiting UAF in the
Linux kernel relies on the fact that when <code>kmalloc()</code> is called, the slab
allocator returns the address of memory that was recently freed:</p>

<center><a href="https://a13xp0p0v.github.io/img/no_quarantine.png"><img src="https://a13xp0p0v.github.io/img/no_quarantine.png" width="60%"></a></center>


<p>So allocating a kernel object with the same size and attacker-controlled
contents allows overwriting the vulnerable freed object:</p>

<center><a href="https://a13xp0p0v.github.io/img/uaf.png"><img src="https://a13xp0p0v.github.io/img/uaf.png" width="70%"></a></center>


<p>Note: Heap spraying for out-of-bounds exploitation is a separate technique.</p>



<p>In July 2020, I got an idea of how to break this heap spraying technique for UAF
exploitation. In August I found some time to try it out. I extracted the slab
freelist quarantine from <a href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">KASAN</a> functionality and called it <code>SLAB_QUARANTINE</code>.</p>

<p>If this feature is enabled, freed allocations are stored in the quarantine
queue, where they wait to be actually freed. So there should be no way for them
to be instantly reallocated and overwritten by UAF exploits.
In other words, with <code>SLAB_QUARANTINE</code>, the kernel allocator behaves like so:</p>

<center><a href="https://a13xp0p0v.github.io/img/with_quarantine.png"><img src="https://a13xp0p0v.github.io/img/with_quarantine.png" width="60%"></a></center>


<p>On August 13, <a href="https://www.openwall.com/lists/kernel-hardening/2020/08/13/7">I sent</a> the first early PoC to LKML and started deeper research of
its security properties.</p>



<p>For researching the security properties of the kernel heap quarantine, I developed
two <code>lkdtm</code> tests (<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/7">code is available here</a>).</p>

<p>The first test is called <code>lkdtm_HEAP_SPRAY</code>. It allocates and frees an object
from a separate <code>kmem_cache</code> and then allocates 400,000 similar objects.
In other words, this test attempts an original heap spraying technique for UAF
exploitation:</p>

<div><div><pre><code><span>#define SPRAY_LENGTH 400000
</span>    <span>...</span>
    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>...</span>
    <span>pr_info</span><span>(</span><span>"Original heap spraying: allocate %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>if</span> <span>(</span><span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"FAIL: attempt %lu: freed object is reallocated</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>
    
    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span>
        <span>pr_info</span><span>(</span><span>"OK: original heap spraying hasn't succeeded</span><span>\n</span><span>"</span><span>);</span>
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is disabled, the freed object is instantly
reallocated and overwritten:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000002b5b3ad4 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: FAIL: attempt 0: freed object is reallocated
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is enabled, 400,000 new allocations don't overwrite
the freed object:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000009909e777 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: OK: original heap spraying hasn't succeeded
</code></pre></div></div>

<p>That happens because pushing an object through the quarantine requires <strong>both
allocating and freeing memory</strong>. Objects are released from the quarantine as
new memory is allocated, but only when the quarantine size is over the limit.
And the quarantine size grows when more memory is freed up.</p>

<p>That's why I created the second test, called <code>lkdtm_PUSH_THROUGH_QUARANTINE</code>.
It allocates and frees an object from a separate <code>kmem_cache</code> and then performs
<code>kmem_cache_alloc()+kmem_cache_free()</code> for that cache 400,000 times.</p>

<div><div><pre><code>    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>

    <span>pr_info</span><span>(</span><span>"Push through quarantine: allocate and free %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>push_addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>push_addr</span><span>);</span>

        <span>if</span> <span>(</span><span>push_addr</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"Target object is reallocated at attempt %lu</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span> <span>{</span>
        <span>pr_info</span><span>(</span><span>"Target object is NOT reallocated in %d attempts</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>);</span>
    <span>}</span>
</code></pre></div></div>

<p>This test effectively pushes the object through the heap quarantine and
reallocates it after it returns back to the allocator freelist:</p>

<div><div><pre><code>  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000008fdb15c3 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182994
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000004e223cbe of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 186830
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000007663a058 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182010
</code></pre></div></div>

<p>As you can see, the number of the allocations needed for overwriting
the vulnerable object is almost the same. That would be good for stable
UAF exploitation and should not be allowed.
That's why I developed <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6"><strong>quarantine randomization</strong></a>. This randomization
required very small hackish changes to the heap quarantine mechanism.</p>

<p>The heap quarantine stores objects in batches. On startup, all
quarantine batches are filled by objects. When the quarantine shrinks,
I randomly choose and free half of objects from a randomly chosen batch.
The randomized quarantine then releases the freed object at an unpredictable moment:</p>

<div><div><pre><code>   lkdtm: Target object is reallocated at attempt 107884
   lkdtm: Target object is reallocated at attempt 265641
   lkdtm: Target object is reallocated at attempt 100030
   lkdtm: Target object is NOT reallocated in 400000 attempts
   lkdtm: Target object is reallocated at attempt 204731
   lkdtm: Target object is reallocated at attempt 359333
   lkdtm: Target object is reallocated at attempt 289349
   lkdtm: Target object is reallocated at attempt 119893
   lkdtm: Target object is reallocated at attempt 225202
   lkdtm: Target object is reallocated at attempt 87343
</code></pre></div></div>

<p>However, this randomization alone would not stop the attacker:
the quarantine stores the attacker's data (the payload) in the sprayed objects!
This means the reallocated and overwritten vulnerable object contains the payload
until the next reallocation (very bad!).</p>

<p>This makes it important to <strong>erase heap objects before placing them in the heap quarantine</strong>.
Moreover, filling them with zeros gives a chance to detect UAF
accesses to non-zero data for as long as an object stays in the quarantine (nice!).
That functionality already exists in the kernel, it's called <code>init_on_free</code>.
<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/5">I integrated it</a> with <code>CONFIG_SLAB_QUARANTINE</code> as well.</p>

<p>During that work I found a bug: in <code>CONFIG_SLAB</code>, <code>init_on_free</code> happens too
late. Heap objects go to the KASAN quarantine while still "dirty." I provided the fix
in a <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/4">separate patch</a>.</p>

<p>For a deeper understanding of the heap quarantine's inner workings, I provided an <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/8">additional
patch</a>, which contains verbose debugging (not for merge).
It's very helpful, see the output example:</p>

<div><div><pre><code>   quarantine: PUT 508992 to tail batch 123, whole sz 65118872, batch sz 508854
   quarantine: whole sz exceed max by 494552, REDUCE head batch 0 by 415392, leave 396304
   quarantine: data level in batches:
     0 - 77%
     1 - 108%
     2 - 83%
     3 - 21%
   ...
     125 - 75%
     126 - 12%
     127 - 108%
   quarantine: whole sz exceed max by 79160, REDUCE head batch 12 by 14160, leave 17608
   quarantine: whole sz exceed max by 65000, REDUCE head batch 75 by 218328, leave 195232
   quarantine: PUT 508992 to tail batch 124, whole sz 64979984, batch sz 508854
   ...
</code></pre></div></div>

<p>The heap quarantine <code>PUT</code> operation you see in this output happens during kernel memory freeing.
The heap quarantine <code>REDUCE</code> operation happens during kernel memory allocation, if the quarantine
size limit is exceeded. The kernel objects released from the heap quarantine return to the allocator
freelist – they are actually freed.
In this output, you can also see that on <code>REDUCE</code>, the quarantine releases some part of
a randomly chosen object batch (see the <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6">randomization patch</a> for more details).</p>



<p>I made <a href="https://www.openwall.com/lists/kernel-hardening/2020/10/01/7">brief performance tests</a> of the quarantine PoC on real hardware and in virtual machines:</p>
<ol>
  <li>
    <p>Network throughput test using <code>iperf</code> <br>
server: <code>iperf -s -f K</code> <br>
client: <code>iperf -c 127.0.0.1 -t 60 -f K</code></p>
  </li>
  <li>
    <p>Scheduler stress test <br>
<code>hackbench -s 4000 -l 500 -g 15 -f 25 -P</code></p>
  </li>
  <li>
    <p>Building the defconfig kernel <br>
<code>time make -j2</code></p>
  </li>
</ol>

<p>I compared vanilla Linux kernel in three modes:</p>
<ul>
  <li><code>init_on_free=off</code></li>
  <li><code>init_on_free=on</code> (upstreamed feature)</li>
  <li><code>CONFIG_SLAB_QUARANTINE=y</code> (which enables <code>i…</code></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</a></em></p>]]>
            </description>
            <link>https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274928</guid>
            <pubDate>Wed, 02 Dec 2020 09:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25272533">thread link</a>) | @bdr
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/? | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that—albeit growing more slowly—may have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack—a niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to “back into” $66B worth of vertical markets—CRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate—via chatting with other team members within the context of a personal or shared inbox—and coordinate—via tagging, rules, and 3rd-party integrations—how they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat—based on the cost of switching away to another email product—will become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user—today, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years—a company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front—both because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front’s consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That’s up 40% from Front’s Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front’s last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn’t grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front’s revenue comes from expansion versus bringing on new customers—based on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front’s -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 – 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front’s bear, base, and bull cases hinge largely on whether the company’s growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front’s growth slows even further, with the company reaching a …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/?">https://sacra.com/research/front-inside-the-startup-slackifying-email/?</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272533</guid>
            <pubDate>Wed, 02 Dec 2020 02:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NN-SVG: Generate publication-ready NN-architecture schematics]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25272360">thread link</a>) | @tzm
<br/>
December 1, 2020 | https://alexlenail.me/NN-SVG/AlexNet.html | <a href="https://web.archive.org/web/*/https://alexlenail.me/NN-SVG/AlexNet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <div id="collapsable">
                        <div id="AlexNet" role="tabpanel">


                            <h4>Style:</h4>
                            <div id="rendererType">
                                <p><label for="rendererType">Renderer</label></p><p><label>
                                         webGL
                                    </label>
                                </p>
                                <p><label>
                                         SVG
                                    </label>
                                </p>
                                <p><small>The SVG renderer is required to download SVG, however the WebGL renderer is required to show tensor dimensions.</small>
                            </p></div>

                            
                            <p>
                                <label for="color1">Color 1</label>
                            </p>
                            <p>
                                <label for="color2">Color 2</label>
                            </p>
                            <p>
                                <label for="color3">Color 3</label>
                            </p>
                            <p><label for="rectOpacity">Tensor Opacity</label>
                                
                            </p>
                            <div>
                            <p><label for="strideOpacity">Filter Opacity</label>
                                
                            </p>
<!--                             <div>
                                <label for="borderWidth">Border Width</label>
                                <input type="range" id="borderWidth" name="" min="0.01" max="3" step="0.01" value="1" style="position: relative; top: 3px;">
                            </div> -->
                            <p><label for="betweenLayers">Spacing Between Layers</label>
                                
                            </p>

                            <hr>
                            <p>
                                <label for="logDepth">Log Feature-Map Depth Scaling</label>
                            </p>
                            <p><label for="depthScale">Depth Size Scaling</label>
                                
                                <span id="depthSpan">10</span>
                            </p>
                            <p>
                                <label for="logWidth">Log Feature-Map Width Scaling</label>
                            </p>
                            <p><label for="widthScale">Width Size Scaling</label>
                                
                                <span id="widthSpan">10</span>
                            </p>
                            <p>
                                <label for="logConvSize">Log Convolutional Filter Size Scaling</label>
                            </p>
                            <p><label for="convScale">Convolutional Filter Scaling</label>
                                
                                <span id="convSpan">1</span>
                            </p>

                            <hr>
                            <p>
                                <label for="showDims">Show Tensor Dimensions</label>
                            </p>
                            <p>
                                <label for="showConvDims">Show Conv Dimensions</label>
                            </p>

                            <hr>
                            <h4>Architecture:</h4>
                            <div id="architecture">
                                <p>Height | Width | Depth | filter Height | filter Width</p>
                                
                                
                                
                                
                                
                                
                                
                            </div>

                            <hr>
                            

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexlenail.me/NN-SVG/AlexNet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272360</guid>
            <pubDate>Wed, 02 Dec 2020 01:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking Tools Every Developer Needs to Know]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25271029">thread link</a>) | @pngmangi
<br/>
December 1, 2020 | https://martinheinz.dev/blog/38 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/38">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/38</link>
            <guid isPermaLink="false">hacker-news-small-sites-25271029</guid>
            <pubDate>Tue, 01 Dec 2020 22:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manuscripts.io]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25270775">thread link</a>) | @cw
<br/>
December 1, 2020 | https://www.manuscripts.io/about/ | <a href="https://web.archive.org/web/*/https://www.manuscripts.io/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><header></header><div><div><p>A simple authoring tool for complex documents.</p></div></div><p><img src="https://www.manuscripts.io/about/static/WindowChrome2x-2b58e9e9c86429ab8d2fac5352d89155.png" width="1024" alt=""></p><p><svg width="64" height="70" viewBox="0 0 64 70"><g fill="none" fill-rule="evenodd"><path d="M33.5 5.02a3 3 0 00-3 0L6.787 18.712a3 3 0 00-1.5 2.598v27.382a3 3 0 001.5 2.598L30.5 64.979a3 3 0 003 0l23.713-13.69a3 3 0 001.5-2.598V21.309a3 3 0 00-1.5-2.598L33.5 5.021z" stroke="#5E6F7E" stroke-width="2"></path><path fill="#5E6F7E" d="M29.842 38.738L23.34 40l4.344-5-4.344-5 6.502 1.262L32 25l2.158 6.262L40.66 30l-4.344 5 4.344 5-6.502-1.262L32 45z"></path></g></svg><h2>Research is collaborative and dynamic.</h2></p><p>Word processors are not. Manuscripts is a collaborative authoring tool built specifically to support scientific content and reproducibility, from the moment a project begins.</p><div><p><img src="https://www.manuscripts.io/about/static/BlueBoxScreenshots-6e19c8d8e118427a65f17e8258450083.png" width="585" alt=""></p><div><h2>Plan and organise writing</h2><p>Save time planning and formatting your work by utilizing one of over 1,300 built-in journal submission templates. Or, upload an existing file, start a blank document, or reformat one manuscript into another template automatically. Manuscripts structured documents support scientific work from the start.</p></div></div><div><p><img src="https://www.manuscripts.io/about/static/GreenBoxScreenshots-8b320e138e54a666993aa50479909f68.png" width="585" alt=""></p><div><h2>Collaborate in real time</h2><p>Invite and collaborate with coauthors live within Manuscripts. No more reconciling multiple versions - work alongside each other, leave comments, or work offline and sync your changes later.</p></div></div><div><p><img src="https://www.manuscripts.io/about/static/OrangeBoxScreenshots-c3270d909e222e3b077a2e432d972a24.png" width="585" alt=""></p><div><h2>Execute and verify</h2><p>Include mathematical equations, code, and data and execute figures live with a behind-the-scenes Jupyter computational notebook integration. Make your work reproducible from the very beginning by including all the elements of your research in Manuscripts.</p></div></div><div><svg width="65" height="70" viewBox="0 0 65 70"><g fill="none" fill-rule="evenodd"><path d="M33.492 5.008a3 3 0 00-2.984 0L6.795 18.602a3 3 0 00-1.508 2.603v27.14a3 3 0 001.508 2.602l23.713 13.594a3 3 0 002.984 0l23.713-13.594a3 3 0 001.508-2.603v-27.14a3 3 0 00-1.508-2.602L33.492 5.008z" stroke="#FFF" stroke-width="2"></path><path d="M25.995 35.037a.95.95 0 00-1.38.03l-.906.975a1.052 1.052 0 00.027 1.442l5.558 5.582L42.198 29.94a1.015 1.015 0 00-.002-1.423l-.94-.943a.995.995 0 00-1.414.005L29.21 38.267l-3.215-3.23z" fill="#FFF"></path></g></svg><h2>All the research features you need in one app</h2><p>Write better research with Manuscripts.</p><div><div width="1,0.5"><div><ul><li>Format citations and bibliography automatically.</li><li>Cross-referencing.</li><li>Footnotes and endnotes.</li><li>Multi-panel figures and tables.</li><li>Equations and inline math with LaTeX support.</li><li>Syntax-highlighted code snippets.</li><li>Menu and keyboard shortcuts for most actions.</li></ul></div></div><div width="1,0.5"><div><ul><li>Share document using links (read-write and read-only).</li><li>Invite and manage roles of collaborators.</li><li>Collaboratively format author lists with contributions and affiliations.</li></ul></div></div><div width="1,0.5"><div><ul><li>Manage styles associated with paragraph types, figures, tables, equations.</li><li>Use templates that bundle together a set of styles and content requirements.</li></ul></div></div><div width="1,0.5"><div><ul><li>Import Markdown, Word, and LaTeX.</li><li>Export Markdown, Word, LaTeX, and PDF.</li><li>Directly submit your manuscripts to hundreds of journals in one click.</li><li>Support for JATSXML and HTML-first publishing workflows.</li></ul></div></div><div width="1,0.5"><div><ul><li>Annotate paragraphs, figures, tables, equations, code listings and citations.</li><li>Include quotes in annotation comments.</li><li>Mention keywords with #hashtags in annotation comments.</li><li>Mention contributors with @mentions in annotation comments.</li></ul></div></div><div width="1,0.5"><div><ul><li>Search for and add citations easily from CrossRef, PubMed, Datacite.</li><li>View and share references in a library across documents and projects.</li><li>Format citations and references in over 8,000 styles.</li></ul></div></div><div width="1,0.5"><div><ul><li>Outline: navigate, manipulate document structure using an outline view of it.</li><li>Smart gutter: shortcut actions for fast access to key editor features.</li></ul></div></div></div></div><p><svg width="69" height="70" viewBox="0 0 69 70"><g stroke="#5E6F7E" stroke-width="2" fill="none" fill-rule="evenodd"><path d="M36.492 5.008a3 3 0 00-2.984 0L9.795 18.602a3 3 0 00-1.508 2.603v27.14a3 3 0 001.508 2.602l23.713 13.594a3 3 0 002.984 0l23.713-13.594a3 3 0 001.508-2.603v-27.14a3 3 0 00-1.508-2.602L36.492 5.008z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M24.89 27.44L18 34.823l6.89 7.383M44.578 27.44l6.89 7.383-6.89 7.383m-14.765 5.906l9.843-27.563"></path></g></svg><h2>Free and open</h2></p><p>Research is increasingly free and open to build on – research tools should be, too.</p><p>Manuscripts is modular: it is a product made of a series of separable components that can also be used to extend or create other systems.</p><div><svg width="187" height="39" viewBox="0 0 187 39"><defs><linearGradient x1="3.726%" y1="50%" x2="77.22%" y2="50%" id="svg-connectlogomonochrome-a"><stop stop-color="#D7F3FF" offset="0%"></stop><stop stop-color="#FFF" offset="100%"></stop></linearGradient></defs><g fill="none"><path d="M52.979 29.434c-1.712.022-3.4-.38-4.897-1.168a8.6 8.6 0 01-3.39-3.229 8.973 8.973 0 01-1.226-4.638c0-1.742.411-3.318 1.225-4.689a8.499 8.499 0 013.391-3.211 10.359 10.359 0 014.897-1.15 9.982 9.982 0 014.125.836 7.432 7.432 0 013.022 2.45l.083.116-1.556 1.077-.091-.12a6.108 6.108 0 00-2.405-1.916 7.75 7.75 0 00-3.178-.64 7.956 7.956 0 00-3.806.903 6.643 6.643 0 00-2.635 2.549 7.448 7.448 0 00-.956 3.795 7.448 7.448 0 00.956 3.795 6.63 6.63 0 002.635 2.544 7.947 7.947 0 003.806.905 7.775 7.775 0 003.178-.64 6.121 6.121 0 002.405-1.933l.09-.119 1.557 1.076-.083.117a7.424 7.424 0 01-3.022 2.45 9.981 9.981 0 01-4.125.84zm19.091 0a9.354 9.354 0 01-4.636-1.168 8.477 8.477 0 01-3.252-3.23 9.256 9.256 0 01-1.181-4.642 9.26 9.26 0 011.181-4.656 8.485 8.485 0 013.252-3.23 9.838 9.838 0 019.272 0 8.485 8.485 0 013.251 3.23 9.248 9.248 0 011.182 4.656 9.244 9.244 0 01-1.182 4.656 8.477 8.477 0 01-3.251 3.23 9.354 9.354 0 01-4.636 1.154zm0-16.29a7.087 7.087 0 00-3.6.92 6.694 6.694 0 00-2.508 2.564 7.605 7.605 0 00-.92 3.76 7.595 7.595 0 00.92 3.757 6.688 6.688 0 002.509 2.565 7.5 7.5 0 007.198 0 6.688 6.688 0 002.508-2.565 7.588 7.588 0 00.921-3.758 7.589 7.589 0 00-.921-3.759 6.694 6.694 0 00-2.508-2.564 7.087 7.087 0 00-3.6-.92zm27.94 16.291V19.1c0-1.936-.512-3.427-1.523-4.432-1.01-1.004-2.45-1.51-4.275-1.51-2.107 0-3.788.61-4.996 1.815-1.208 1.204-1.823 2.856-1.823 4.9v9.56h-2.067V11.478h1.99v3.395a7.052 7.052 0 012.603-2.456c1.275-.71 2.799-1.068 4.532-1.068 2.332 0 4.204.663 5.567 1.97 1.363 1.309 2.052 3.21 2.052 5.654v10.463h-2.06zm23.721 0V19.1c0-1.936-.513-3.427-1.53-4.432-1.019-1.004-2.45-1.51-4.274-1.51-2.107 0-3.788.61-4.996 1.815-1.208 1.204-1.817 2.856-1.817 4.9v9.56h-2.067V11.478h1.99v3.395a7.042 7.042 0 012.603-2.456c1.274-.71 2.799-1.068 4.532-1.068 2.332 0 4.204.663 5.565 1.97 1.362 1.309 2.054 3.21 2.054 5.654v10.463h-2.06zm16.013-.001c-1.877 0-3.573-.39-5.04-1.167a8.751 8.751 0 01-3.473-3.21c-.83-1.36-1.253-2.93-1.253-4.67a9.237 9.237 0 011.18-4.65 8.47 8.47 0 013.262-3.228 9.93 9.93 0 019.288-.017 8.43 8.43 0 013.228 3.201 9.149 9.149 0 011.179 4.635l-.047.615h-16.021a6.82 6.82 0 001.078 3.42 6.81 6.81 0 002.743 2.413 8.767 8.767 0 003.912.856 8.894 8.894 0 003.316-.61 6.41 6.41 0 002.529-1.786l.116-.135 1.243 1.332-.085.096a8.131 8.131 0 01-3.107 2.155 10.798 10.798 0 01-4.048.75zm6.302-10.091a6.594 6.594 0 00-1.04-3.135c-1.25-1.952-3.516-3.128-5.94-3.084a7.382 7.382 0 00-3.462.804 6.373 6.373 0 00-2.46 2.261 7.064 7.064 0 00-1.055 3.154h13.957zm14.378 10.091a10.23 10.23 0 01-4.894-1.168 8.598 8.598 0 01-3.39-3.229 8.976 8.976 0 01-1.232-4.653c0-1.741.411-3.318 1.232-4.688a8.496 8.496 0 013.39-3.211 10.353 10.353 0 014.894-1.136 9.973 9.973 0 014.123.837 7.44 7.44 0 013.021 2.449l.083.117-1.556 1.077-.09-.12a6.106 6.106 0 00-2.404-1.916 7.744 7.744 0 00-3.177-.641 7.95 7.95 0 00-3.804.903 6.641 6.641 0 00-2.634 2.549 7.45 7.45 0 00-.955 3.795 7.45 7.45 0 00.955 3.795 6.629 6.629 0 002.634 2.544 7.941 7.941 0 003.804.905 7.769 7.769 0 003.177-.641 6.122 6.122 0 002.403-1.918l.091-.118 1.556 1.076-.083.116a7.432 7.432 0 01-3.021 2.451 9.97 9.97 0 01-4.123.825zm18.59.001c-1.64 0-2.922-.448-3.823-1.333-.901-.884-1.354-2.123-1.354-3.69V12.86h-3.395v-1.774h3.395V7.174h2.077v3.912h5.871v1.774h-5.871v11.381c0 1.124.276 1.983.825 2.557.55.575 1.37.863 2.452.863 1.11 0 2.039-.323 2.768-.957l.138-.122.903 1.46-.09.081a4.667 4.667 0 01-1.737.978 7.016 7.016 0 01-2.16.334z" fill="#FFF"></path><path d="M28.572 12.972a3.428 3.428 0 000-6.855h-.938v-2.69A3.43 3.43 0 0024.208 0H9.938a3.432 3.432 0 00-3.427 3.428v2.688H3.44A3.43 3.43 0 00.017 9.54L0 22.446a3.426 3.426 0 003.428 3.43h22.654a.93.93 0 01.929.927v1.77a.929.929 0 01-.929.927H9.938a.929.929 0 01-.928-.928v-1.436h-2.5v1.436A3.432 3.432 0 009.939 32h16.144a3.432 3.432 0 003.428-3.428v-1.767a3.433 3.433 0 00-3.428-3.428H9.015V9.873H6.511v13.511H3.428a.927.927 0 01-.93-.929L2.515 9.55a.93.93 0 01.928-.927H23.88V6.116H9.01V3.428a.93.93 0 01.928-.93h14.27a.93.93 0 01.927.93v6.115a3.433 3.433 0 003.437 3.43z" fill="url(#svg-connectlogomonochrome-a)" transform="translate(3 3)"></path></g></svg><h2>One account for all your research</h2><p>Manuscripts is part of Connect. By signing up for Manuscripts, you get access to all of Atypon's apps for discovering, organising, writing, and publishing research.</p><div><div width="1"><div width="1,0.5"><div><p>A simple writing tool for complex documents. Built for collaboration and scholarship.<!-- --> </p></div></div><p>To be connected soon</p></div></div></div><p><svg width="60" height="70" viewBox="0 0 60 70"><g fill="#5E6F7E"><path d="M36.857 29h-1.714c-.629 0-1.143.675-1.143 1.5s.514 1.5 1.143 1.5h1.714c.629 0 1.143-.675 1.143-1.5s-.514-1.5-1.143-1.5zm-7.015 0h-8.684C20.52 29 20 29.675 20 30.5s.521 1.5 1.158 1.5h8.684C30.48 32 31 31.325 31 30.5s-.521-1.5-1.158-1.5zm18.021-7H21.137c-.625 0-1.137.675-1.137 1.5s.512 1.5 1.137 1.5h26.726c.625 0 1.137-.675 1.137-1.5s-.512-1.5-1.137-1.5z"></path><path d="M53.423 11H15.5c-3.067 0-5.577 2.506-5.577 5.568v12.25H4.346A3.353 3.353 0 001 32.16v17.818a3.353 3.353 0 003.346 3.341h5.577v5.568c0 .446.279.836.67 1.003.167.055.278.111.445.111.28 0 .558-.111.725-.278l6.916-6.125.056-.056c.167-.167.39-.223.725-.223h7.25a3.353 3.353 0 003.346-3.34v-7.796h1.004c.836 0 1.617.278 2.23.89l10.43 9.634c.222.167.501.278.78.278.167 0 .279-.056.446-.111a1.1 1.1 0 00.67-1.003v-9.688h7.807c3.067 0 5.577-2.506 5.577-5.568V16.568C59 13.506 56.49 11 53.423 11zM27.825 49.977c0 .613-.502 1.114-1.115 1.114h-7.25c-.893 0-1.673.278-2.287.835l-5.02 4.455v-4.176c0-.613-.501-1.114-1.115-1.114H4.346a1.118 1.118 0 01-1.115-1.114V32.16c0-.612.502-1.114 1.115-1.114h5.577v5.569c0 3.062 2.51 5.568 5.577 5.568h12.325v7.795zm28.944-13.363a3.353 3.353 0 01-3.346 3.34h-7.808v-3.34c0-.613-.502-1.114-1.115-1.114s-1.115.501-1.115 1.114v12.695l-8.533-7.907c-1.004-.946-2.342-1.447-3.792-1.447H15.5a3.353 3.353 0 01-3.346-3.341V16.568a3.353 3.353 0 013.346-3.34h37.923a3.353 3.353 0 013.346 3.34v20.046z"></path></g></svg><h2>Have a question?</h2></p><p>Contact us via <a href="mailto:support@manuscripts.io">support@manuscripts.io</a>.</p><main></main><p>2019 © Atypon Systems, LLC, All rights reserved | <a href="https://www.atypon.com/privacy-policy/">Privacy policy</a></p></div></div></div></div>]]>
            </description>
            <link>https://www.manuscripts.io/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25270775</guid>
            <pubDate>Tue, 01 Dec 2020 22:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Things We Need to Know About Technological Change – By Neil Postman, 1998]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25268936">thread link</a>) | @samim
<br/>
December 1, 2020 | https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/ | <a href="https://web.archive.org/web/*/https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><b>"<a href="https://samim.io/dl/Five_Things_We_Need_to_Know_About_Technological_Change_by_Neil_Postman.pdf">Five Things We Need to Know About Technological Change</a>"</b> - by <a href="https://en.wikipedia.org/wiki/Neil_Postman">Neil Postman </a>(1998) <br></p><ul><li><b>Idea 1: </b>Culture always pays a price for technology.</li><li><b>Idea 2:</b> There are always winners and losers in technological change.<br></li><li><b>Idea 3:</b> Every  technology  has  a  philosophy: “The medium is the message.”</li><li><b>Idea 4:</b> Technological change is not additive; it is ecological.</li><li><b>Idea 5:</b> Media tend to become  mythic. </li></ul><blockquote><p><b>"Conclusion:</b> And  so,  these  are  my  five  ideas  about  technological  change. <b> First</b>,  that  we  always  pay  a  price  for technology;  the  greater  the  technology,  the  greater  the  price. <b> Second</b>,  that  there  are  always  winners  and losers, and that the winners always try to persuade the losers that they are really winners. <b>Third</b>, that there is  embedded  in  every  great  technology  an  epistemological,  political  or  social  prejudice.  Sometimes  that bias  is  greatly  to  our  advantage.  Sometimes  it  is  not.  The  printing  press  annihilated  the  oral  tradition; telegraphy  annihilated  space;  television  has  humiliated  the  word;  the  computer,  perhaps,  will  degrade community life.  And so on. <b>Fourth</b>, technological change  is not additive;  it is ecological,  which  means, it changes everything and is, therefore, too important to be left entirely in the hands of Bill Gates. And <b>fifth</b>, technology tends to become  mythic; that is, perceived as  part of the  natural  order of things, and therefore tends to control more of our lives than is good for us.&nbsp;</p><p>I will close  with this thought. <b>In the past,  we experienced technological change  in  the  manner  of  sleep-walkers</b>.  <b>Our  unspoken  slogan  has  been “technology  über  alles,” and  we have been willing to shape our lives to fit the requirements of technology, not the requirements of culture. This is a form of stupidity, especially in an age of vast technological change. We need to proceed with our eyes wide open so that we many use technology rather than be used by it."</b></p></blockquote><p><b>Presentation: <a href="https://prezi.com/p/egoxlf6-bln8/neil-postmans-five-ideas-to-technological-change/">Neil Postman's Five Ideas to Technological Change</a></b></p><p><b>"The Surrender of Culture to Technology" - talk by Neil Postman </b></p><div>
	<figure>
		<div>
			<p><iframe src="https://www.youtube.com/embed/hlrv7DIHllE?rel=0" allowfullscreen="" allow="encrypted-media; accelerometer; gyroscope; picture-in-picture"></iframe></p>
		</div>
	</figure>
	
</div><p><a href="https://samim.io/tag/Technology">#Technology</a> <a href="https://samim.io/tag/Media">#Media</a> <a href="https://samim.io/tag/Politics">#Politics</a> <a href="https://samim.io/tag/Philosophy">#Philosophy</a>  </p>
      </div></div>]]>
            </description>
            <link>https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25268936</guid>
            <pubDate>Tue, 01 Dec 2020 19:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to buy gifts that people actually want]]>
            </title>
            <description>
<![CDATA[
Score 334 | Comments 269 (<a href="https://news.ycombinator.com/item?id=25267847">thread link</a>) | @willpatrick
<br/>
December 1, 2020 | https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want | <a href="https://web.archive.org/web/*/https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>I Love It! (I Hate It.)</h2><p>There's a sound of rustling paper. You crack the wrap at the seam. You look inside, unveiling the item within. It's...</p><p>Crap. It’s crap. It’s a crap present that you don’t want.</p><p>You lift your head and, with a beaming grin, you <em>somehow</em> manage to let out a torrent of thanks and praise for what you have just received. This is wonderful! It's just what I wanted! How did you know? I love it! I'll treasure it forever!</p><p>Within a day, it's stuffed in a drawer. Within a week, it's forgotten. Within a month, it's on eBay or off to the charity shop. Worse, it just ends up in a landfill somewhere.</p><p>If you had to guess, how many times would you say this has happened to you when you've received gifts at Christmas or on birthdays?</p><p>Here comes the even worse part: now think about how many times this might have happened with gifts<em> that you have given to others.</em></p><p><strong>Think you've got a perfect record?</strong> Think again, because you really, honestly, probably don't.</p><h2>A Lot of Gifts Aren't Actually That Good</h2><p>In 1993 - to cries of 'Grinch!' - economist Joel Waldfogel published a now-infamous paper (among certain economist circles, anyway) titled '<a href="https://graphics8.nytimes.com/images/blogs/freakonomics/pdf/WaldfogelDeadweightLossXmas.pdf">The Deadweight Loss of Christmas</a>'.</p><p>In it, Waldfogel argues that huge sums of money are wasted every year on gifts that nobody really wants. More accurately, he reported that many gift recipients valued their gifts at a dollar amount much lower than was actually paid for the item.</p><p>For example, if I bought you a gift for $100 and you thought that it was actually worth about $70 it would mean that, somewhere along the line, <em>you’ve destroyed $30</em>. Pop! It's gone. You might as well have just taken your cash and burnt it.</p><p>Waldfogel found that anywhere between 10% and 33% of all Christmas gifts cause this kind of loss every year. This is stunning, especially when we extrapolate out to the entire population.</p><p>He concludes by saying that many people could do worse than simply giving cash as a gift because it would carry more value than the actual gifts they might otherwise have bought.</p><p>Unless you are absolutely convinced that you are god's gift to... well, gift-giving, then you're probably seeing the same loss of value with your own gifts. Or, to put it another way, <strong>a lot of your gifts probably suck whether you realise it or not</strong>.</p><p>You won't see this, though, because nobody is going to turn around and tell you that your gifts were 'only 70% good'. If anything, the reactions that we get with a good gift and a bad gift are remarkably similar. Nobody wants to make you feel like a bastard at Christmas, even if you did hand out some absolute clangers.</p><p>But is it so bad, really, losing a few dollars every year? In short, yes. And then some. But not just because of the money you're wasting.</p><h2>Good Gift Giving Is Incredibly Important</h2><p>Outside of bland analysis by economists that ordinary people haven’t heard of, gift-giving helps us maintain and preserve social ties at all of life’s most important occasions; birthdays, Christmas, Valentine's day, anniversaries, graduations... you name it.</p><p>In between these occasions there is usually some kind of imbalance between the gifts that we have given to one another. That is, you might knock it out of the park one year and I might give you something that’s nowhere near as good. Next time, I'm going to want to do much better. This imbalance leads, in part, to the continuation of the tradition.</p><p>Giving good gifts help to form and strengthen social bonds. It helps us show people how much we care, how much we love them. It helps us say sorry. It helps us convey meaning. It helps us have fun and take delight in generosity. A life without giving and receiving gifts would be a dull life indeed.</p><p>On the other hand, giving bad gifts can degrade the quality of those same bonds. <strong>At best, it can be annoying to be given a bad gift. At worst, it can drive people apart.</strong> If Waldfogel's research is correct, an awful lot of us are unwittingly dropping the ball every year, without really realising it.</p><p>Luckily, it's not just economists giving their miserable analysis of the situation; a handful of psychologists have waded in and they're here to tell you that you're just <em>thinking</em> <em>about it all wrong</em>.</p><h2>Why Our Gifts Don't Work</h2><p>There's a surprising amount of research literature out there that all points in a similar direction as to why gifts don't work and what we can do about it. To find a way through this gift-giving minefield, I've gone through some of the most widely-cited papers to get to the bottom of it all. (Citations can be found at the end of this article.)</p><h3>Gift-Givers and Gift-Receivers Think Differently</h3><p>Gifts don't always hit the spot because the psychology of <em>giving</em> gifts is totally different to the psychology of <em>getting</em> gifts. Although it all happens during the same event, we unwittingly think about these two things in totally different ways.</p><p>When people <em>give</em> gifts, they typically want to nail one or more of these four different things:</p><ul role="list"><li>Surprise (the wow factor)</li><li>Desirability (the clout factor)</li><li>Materiality (the price tag)</li><li>Social responsibility (that is, looking virtuous)</li></ul><p>Gift <em>receivers</em>, though? <strong>Their priorities are completely different</strong>. They want:</p><ul role="list"><li>Usefulness (can I do something with it?)</li><li>Versatility (can I do a variety of things with it?)</li><li>Quality (is it well made/going to last?)</li><li>Stuff they've asked for (did I actually say I want this?)</li></ul><p>Given the difference between these two lists, is it any wonder that some gifts simply don't hit the mark?</p><h3>We Focus too Much on The Moment of Exchange</h3><p>When we give gifts we are mostly thinking about 'the moment' in which we hand it over, seeing the reaction of our recipients. We narcissistically want the chorus of 'oohs' and 'aahs' that come with nailing a really good gift that somebody loves. Whether or not those reactions last any longer than the moment of exchange, though, is not something that gift givers really care about.</p><p>Research shows that we make greater errors with gift giving when those gifts are being opened in public - perhaps at a party - than when we give them in private - such as wedding presents.</p><p>This is because<strong> we end up optimising for the maximum showboat potential of the gifts we give</strong> because it feels good to do so well in public. Once the event is over, though, we basically forget about it all. Onto the next thing.</p><p>Not so for the gift recipient. After the party is over and everyone's gone home... they've still got the gift. It matters much more to them what comes <em>after</em> the moment of exchange.</p><p>This means that it's better to buy a gift that has greater long term appeal than just the momentary 'wow' factor, even if it doesn't feel as good to us in the moment.</p><h3>We Like to Be Given Experiences... But We Don't Like to Gift Them</h3><p>Research shows that an 'experience' gift - like a night out at the theatre or a wine tasting course - is often preferred instead of the usual variety of material gifts that get doled out every year.&nbsp;</p><p>The only problem is that gift-givers don't really like to give experiences as gifts because the moment of exchange is relatively dull. This is usually because there's some stand-in that gets handed over - a voucher or a certificate - and the response is likely to be bland at best.</p><p>The <em>real</em> excitement comes much later when they cash that voucher in. But, of course, the gift-giver can’t actually be there to see that happen. No good.</p><h3>We Care too Much About the Price</h3><p>Gift-givers tend to believe that the more generous or pricey a gift is, the better it must be. This rarely works. For recipients, the absolute quality of the gift matters much more. This is equally true for something that the giver thinks is really thoughtful, too.</p><p>This happens when we put an enormous amount of thought and money into a gift for a friend or relative, <strong>only to find that they have no interest in it.&nbsp;</strong></p><p>A good example of this might be picking up on someone's love for music and then buying them a beautiful acoustic guitar. There's little guarantee that they have any interest in playing an instrument at all, no matter how expensive it is or how much thought you put into it.</p><p>If they're not regularly playing that thing a year later, you’ve probably goofed.</p><h3>We're Too Distant</h3><p>If you're genuinely quite distant from the gift recipient, it's almost impossible to get a good gift for them that they will genuinely want. This means one of two things:</p><ol role="list"><li>You probably shouldn't bother, or</li><li>You can give them cash (or a cash equivalent)</li></ol><p>Whether or not you <em>should</em> give them cash is another question. If they're your grandchildren this is absolutely fine. If they're your grandparents, perhaps not.</p><p>In the latter instance, a good 'consumable' like a decent bottle of wine or a box of chocolates will do. But don't worry about it much more than that.</p><h3>Be Careful With Charity Gifts</h3><p>Sadly, recipients are less grateful about virtuous charitable gifts than we would hope for. While they're good for the cause, they don't score well against the ways in which we normally value gifts. They make the gift giver look good and they feel good in the moment, but they are not valued as much. </p><p>Of course, if someone tells you that they would value a charitable gift then go for it. But don't assume that anybody will actually like it as a gift unless you have discussed it in advance.</p><h2>How to Buy Gifts People Actually Want</h2><p>All hope is not lost. You <em>shall</em> buy gifts that people will actually want! Here's how.</p><h3>Be Realistic About Your Relationship With The Recipient</h3><p>In Waldfogel's 1993 study, there's a chart of gift effectiveness that more or less screams at aunts, uncles and grandparents to simply not bother with material gifts and to give cash instead:</p><figure id="w-node-9f5a4418121f-c39ae183"><p><img src="https://uploads-ssl.webflow.com/5e8b192239b9b4843e9ae18f/5fbfe9af234e056f30021f18_GTfsGCvFwKV3s1qidXi6Ls7EIYGoOQBVRr8o_3XvvwZ6IHt4QwNvAaje0p8Il8hWv-Yz1jcRU9A98nTmQMijJOrXU6E6gZC5FSi4_f_WOLuJY2XXZtR2CCIEYZsyAMvYo1P60Hr3.jpeg" alt=""></p></figure><p>Are you soulmates, together as a couple for many years? You obviously stand a much higher chance of getting the recipient something they will actually want.</p><p>If you’re anyone else, you will have a harder time and should maybe not worry so much about making sure your gift is as ‘thoughtful’ as possible and just focus on making their gift useful or buying them an experience.</p><h3>...Ask Them What They Want</h3><p>It seems obvious, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want">https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want</a></em></p>]]>
            </description>
            <link>https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267847</guid>
            <pubDate>Tue, 01 Dec 2020 18:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Hosting Still Pays]]>
            </title>
            <description>
<![CDATA[
Score 376 | Comments 328 (<a href="https://news.ycombinator.com/item?id=25267651">thread link</a>) | @emperor_
<br/>
December 1, 2020 | https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image.jpg" data-caption="Colo V AWS 2020 Cover Image"><img width="696" height="392" src="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-696x392.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Colo V AWS 2020 Cover Image" title="Colo V AWS 2020 Cover Image"></a><figcaption>Colo V AWS 2020 Cover Image</figcaption></figure></div>
            <!-- content --><p>Years ago, we had a big decision to make. In 2013, STH had grown to a size that would seem immeasurably small by the traffic we do today. Still, at that point, we made the decision that it made fiscal sense to leave Amazon AWS for colocation. We chronicled the reasoning in <a href="https://www.servethehome.com/falling-sky-sth-leaving-cloud-amazon-aws/">Falling From the Sky Why STH is Leaving the Cloud</a> and then the cost breakdown in&nbsp;<a href="https://www.servethehome.com/falling-sky-part-3-evaluating-amazon-ec2-vps-dedicated-colocation-options/">Falling From the Sky Part 3 – Evaluating Amazon EC2, VPS, Dedicated and Colocation Options</a>. Since 2013, we have been doing some irregular updates that largely correspond to planned upgrades of our infrastructure. Since we are taking a look at a few upgrades again, it is time to go through the exercise again.<span id="more-48850"></span></p>

<p>If you want to hear this instead of just reading, we have a YouTube video with some commentary here:</p>
<p><iframe title="Our Colocation Hosting versus AWS Costs Compared 2020 Edition" width="696" height="392" src="https://www.youtube.com/embed/RqetN_i0BnE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Of course, we can go into a bit more detail below, but some prefer to listen rather than read so we have that option.</p>

<p>In 2018, we looked again at whether it was time to move back to the cloud. In our cost analysis, this is what we found using 1-year estimates:</p>
<figure id="attachment_26722" aria-describedby="caption-attachment-26722"><a href="https://www.servethehome.com/falling-from-the-sky-part-4-leaving-the-cloud-5-years-later/sth-2018-web-hosting-budget-v-aws/" rel="attachment wp-att-26722"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS.jpg" alt="STH 2018 Web Hosting Budget V AWS" width="536" height="156" srcset="https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS.jpg 536w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-400x116.jpg 400w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-533x156.jpg 533w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-534x156.jpg 534w" sizes="(max-width: 536px) 100vw, 536px"></a><figcaption id="caption-attachment-26722">STH 2018 Web Hosting Budget V AWS</figcaption></figure>
<p>Just to give some sense of how that March 2018 estimate has gone in the 32 months since we looked at this, we ended up using:</p>
<ul>
<li>Way more bandwidth. STH has grown a ton since 2018. We also focus more on reviews which tend to use more photos. Even with lazy loading images, our bandwidth usage is significantly higher. This did not incur an incremental cost based on how we buy bandwidth. See: <a href="https://www.servethehome.com/buyers-guide-hosting-bandwidth-data-transfer-billing/">Buyer’s Guide to Hosting: Bandwidth, Data Transfer and Billing</a></li>
<li>Several of our VMs doubled memory requirements and we added slightly more storage. We overprovisioned so this was absorbed with still enough leftover.</li>
<li>We replaced a <a href="https://www.servethehome.com/9-step-calm-and-easy-proxmox-ve-boot-drive-failure-recovery/">SSD</a>, upgraded a firewall, and added another <a href="https://www.servethehome.com/explaining-the-automatic-transfer-switching-ats-pdu/">ATS PDU</a>. We have not done long-term infrastructure upgrades.</li>
<li>We ended up using an upgraded node that we had available, as a “hot spare”. We tend to “self-warranty” hardware, and so we had an extra system/ chassis there.</li>
<li>We are going to say we used four hours of labor. This includes drive time to the primary data center. Since it is far away (18-20 minute drive), we actually did not go there for several quarters. So over 32 months, we had budgeted $640 for remote hands. We effectively either paid $160/ hr or paid less than that even rounding up to four hours.</li>
</ul>
<p>Overall, it looks like we probably over-estimated self-hosting costs again, and underestimated AWS costs with respect to how much we would spend there, even after service discounts.</p>
<h2>The Late 2020 AWS v. Colocation Update</h2>
<p>We wanted to answer the question of what the picture would look like for hosting STH now. A few quick words before we get there on assumptions.</p>
<p>First off, we completely could change the way we run the site. That is a given. Frankly, running in VMs whether on the cloud or in self-hosting is convenient. Indeed, we run containers in VMs as well. We could also overhaul the entire software stack again, but frankly, we want to spend more time creating content then doing that work. Something that we learned was that we had less reliability by increasing complexity than by keeping things as simple as possible.</p>
<p>Second, we are modeling current data transfer, and a minimal set of VMs. We actually have a lot more running, including some services that we run for some of the labs. One could argue that since they are lab services they are part of bringing you STH, but they are not focused on the web hosting aspect so we are going to remove them. Also, we have other VMs that are likely only online because we wanted to try something and had capacity. We may or may not elect to run the VMs if there was the AWS incremental cost. We could model these as on-demand or spot instances, but instead, we are just removing them entirely.</p>
<p>Third, we completely understand spot pricing. We are modeling a basic set instead of adding extras. At some point, we need databases, nginx servers, and so forth.</p>
<p>Fourth, we are going to add a mix of AMD EPYC and Intel Xeon instances roughly about what we use for our hosting. We are heavily weighting the larger instances toward the EPYC instances since that helps bring down the costs and for our workloads, there is no appreciable difference. We could go Arm, but that requires some small lift and shift work.</p>
<p>Finally, we do use some AWS services. Those services we would use regardless so we are excluding them from the analysis. We are also not modeling services such as Mailchimp which handles our weekly newsletter, Teespring that handles our online merch shop, YouTube which hosts our videos, and so forth.</p>
<h3>AWS Cost 1-Year Reserved No Upfront</h3>
<p>Here is the calculator for the absolute base setup for our hosting using 1-year reserved upfront instances:</p>
<figure id="attachment_48851" aria-describedby="caption-attachment-48851"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-1-year-reserved-no-upfront/" rel="attachment wp-att-48851"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront.jpg" alt="2020 AWS Calculator 1 Year Reserved No Upfront" width="1114" height="222" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront.jpg 1114w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-400x80.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-800x159.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-696x139.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-1068x213.jpg 1068w" sizes="(max-width: 1114px) 100vw, 1114px"></a><figcaption id="caption-attachment-48851">2020 AWS Calculator 1 Year Reserved No Upfront</figcaption></figure>
<p>As you can see, our hosting costs are just under $4,300 per month.</p>
<h3>AWS Cost 1-Year Reserved Partial Upfront</h3>
<p>Swapping to 1-year reserved partial up-front on the instances helps bring pricing down a bit albeit with a $19,512 up-front cost.</p>
<figure id="attachment_48853" aria-describedby="caption-attachment-48853"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-1-year-partial-upfront/" rel="attachment wp-att-48853"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront.jpg" alt="2020 AWS Calculator 1 Year Partial Upfront" width="1112" height="242" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront.jpg 1112w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-400x87.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-800x174.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-696x151.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-1068x232.jpg 1068w" sizes="(max-width: 1112px) 100vw, 1112px"></a><figcaption id="caption-attachment-48853">2020 AWS Calculator 1 Year Partial Upfront</figcaption></figure>
<p>When we factor in the up-front we get a $4,137.63 monthly cost along with a $49,651.56 total annual cost for the year. We are not discounting here using future values/ present values. There is a big issue with this. Typically, we tend to see our servers run for years. To model that, we tend to use 3-year reserved partial upfront.</p>
<h3>AWS Cost 3-Year Reserved Partial Upfront</h3>
<p>Using the 3-year reserved partial upfront on the instances gives us a much lower operating cost with a larger up-front payment.</p>
<figure id="attachment_48852" aria-describedby="caption-attachment-48852"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-3-year-partial-upfront/" rel="attachment wp-att-48852"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront.jpg" alt="2020 AWS Calculator 3 Year Partial Upfront" width="1117" height="247" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront.jpg 1117w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-400x88.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-800x177.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-696x154.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-1068x236.jpg 1068w" sizes="(max-width: 1117px) 100vw, 1117px"></a><figcaption id="caption-attachment-48852">2020 AWS Calculator 3 Year Partial Upfront</figcaption></figure>
<p>First off, the $39,020 is more than we have spent in the last three years on hosting hardware. We do not purchase machines with long warranties or high markups, so if you are buying the average Dell/ HPE/ Lenovo server and think that sounds like a single server, you are trading higher upfront costs for service contracts. Given what we have seen on hardware/ remote hands, it is not a model we are pursuing. On the operating side, we get down to $1,968.51 per month which is great.</p>
<h2>STH 2020 Hosting Budget</h2>
<p>Next year, we will likely do two small changes. First, we will upgrade database nodes and instead of using Optane SSDs, we will move to Cascade Lake and Optane PMem DIMMs into the database servers and upgrade a few older nodes to AMD EPYC 7002 “Rome” systems. We are testing the Ampere Altra 80-core server right now, and we are at the point where we might consider using Arm in the hosting cluster this year. We are going to increase our hardware budget to $10,000 this year. Although we did not use most of our hardware budget in 2019 nor 2020, we expect to in 2021.</p>
<p>Making up our monthly cost, we increased a bit for inflation. We used a $895/ mo budget in 2018. Our costs are effectively flat, but we are going to assume a bit more labor to install servers/ upgrade the hardware.</p>
<figure id="attachment_48855" aria-describedby="caption-attachment-48855"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-v-self-hosting/" rel="attachment wp-att-48855"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting.jpg" alt="2020 AWS V Self Hosting" width="685" height="197" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting.jpg 685w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting-400x115.jpg 400w" sizes="(max-width: 685px) 100vw, 685px"></a><figcaption id="caption-attachment-48855">2020 AWS V Self Hosting</figcaption></figure>
<p>We are budgeting $22,000 per year or around $1833.33 per month. This is about the same as we would need for EC2’s 3-year partial upfront reserved instance, albeit without the up-front costs.</p>
<p>The one item that skews this substantially, is that we are not replacing every node every year. We are now in a very different place than we were when we started this journey. We have existing infrastructure that is frankly fine from a performance and node count standpoint even though we have relatively under-invested over the past 32 months. We had budgeted around $1687/ month for the last two months and spent under $1000. Still, at some point, we like to replace equipment before it fails.</p>
<h2>Final Words</h2>
<p>There is clearly a lot going into this. We now have just under 8 years since this 10U colocation spot in Las Vegas was our first setup:</p>
<figure id="attachment_8644" aria-describedby="caption-attachment-8644"><a href="https://www.servethehome.com/colocation-architecture-servethehome-2013/sth-colo-10u-rear-picture-annotated-small/" rel="attachment wp-att-8644"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small.png" alt="STH Colo 10U Rear Picture - Annotated small" width="600" height="394" srcset="https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small.png 600w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-300x197.png 300w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-16x11.png 16w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-32x21.png 32w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-28x18.png 28w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-56x37.png 56w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-64x42.png 64w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-184x120.png 184w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-8644">STH Colo 10U Rear Picture – Annotated small</figcaption></figure>
<p>What is not reflected in our discussion is all of the lessons learned along the way. Also, as hardware has gotten faster, and memory prices have decreased, the cost of self-hosting has gone down significantly for our applications. We are also taking advantage of falling bandwidth prices. While AWS is absolutely the right choice for many applications, and indeed we use them, for our web hosting it is not what we want for a simple and inexpensive setup. This may not be the perfect analysis, but it is a little bit of how we now look at hosting at STH.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267651</guid>
            <pubDate>Tue, 01 Dec 2020 17:50:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Update on PromQL Compatibility Across Vendors]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25267601">thread link</a>) | @jrv
<br/>
December 1, 2020 | https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors | <a href="https://web.archive.org/web/*/https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Prometheus's query language <a href="https://prometheus.io/docs/prometheus/latest/getting_started/">PromQL</a> is one of the cornerstones of the Prometheus ecosystem. Back in our August blog post, <a href="https://promlabs.com/blog/2020/08/06/comparing-promql-correctness-across-vendors">Comparing PromQL Correctness Across Vendors</a>, we looked at several external projects and monitoring vendors that claimed to offer PromQL-compatible APIs. Using an <a href="https://github.com/promlabs/promql-compliance-tester">open-source compliance checker tool</a>, we evaluated each implementation by running a set of test queries against both the native Prometheus server and the vendor implementation. As a result, we found multiple bugs in the tested projects, and mapped out in detail how each deviated from the upstream implementation.</p>
<p>Meanwhile, more vendors have entered the PromQL space, while existing projects have worked on improving their PromQL support as a result of our last blog post. Today, we are presenting an updated set of PromQL test results both for existing projects and a couple of new ones. We tested each of these implementations against the latest Prometheus version, <a href="https://github.com/prometheus/prometheus/releases/tag/v2.23.0">v2.23.0</a>.</p>
<h3 id="before-we-start-a-note-on-interpreting-test-scores"><a href="#before-we-start-a-note-on-interpreting-test-scores" aria-label="before we start a note on interpreting test scores permalink"></a>Before we start: a note on interpreting test scores</h3>
<p>When looking at individual test results, please note that the numeric scores alone paint a limited picture. They don't necessarily tell you how impactful implementation errors are, nor how many distinct behavioral differences there are. Since PromQL expressions naturally compose and build on top of each other, it is infeasible to isolate all possible query errors into fully independent test cases. Many of the test queries will contain the same constructs as other queries, in a nested way. For example: If an implementation selects data incorrectly, then this breaks not only a simple data selection test query, but also all other test query cases that try to run a function, operator, or other transformation based on selected data. The test cases also include a lot of variations of the same type of query, but with different ranges, quantile values, or other parameters. So if e.g. a function is broken in a general way, it may cause multiple test case variants to fail at the same time.</p>
<p>Another matter of more subtle interpretation are vendor extensions and extreme edge-case behavior. For example, a vendor may choose to not raise an error when executing a function with a parameter value that is illegal in native PromQL, but legal and sensical in the extended language. Or a vendor may return a different value for an unusual edge-case behavior, such as running <code>histogram_quantile()</code> with a quantile value larger than <code>1</code>.</p>
<p>We still provide the numeric test scores as a quick way to map out the vendor landscape and to motivate the ecosystem towards achieving a 100% score. But if you need to understand behavioral differences in more depth, please <a href="https://promlabs.com/promql-compliance-tests">take a look at the full test results</a> and read on for the details.</p>
<h3 id="criteria-for-including-a-vendor-in-tests"><a href="#criteria-for-including-a-vendor-in-tests" aria-label="criteria for including a vendor in tests permalink"></a>Criteria for including a vendor in tests</h3>
<p>We are always on the lookout for new PromQL implementations to include in these tests. To include a project or vendor, we look for two criteria:</p>
<ul>
<li>Someone is either advertising full or partial PromQL compatibility of their system, and/or otherwise positioning their solution as a drop-in replacement for an existing PromQL implementation.</li>
<li>For practical purposes, we need to be able to ingest test data into the system and query it back via a PromQL-style HTTP API. Otherwise, we can't run any tests.</li>
</ul>
<p>Unfortunately, some vendors failed the second criterium for now, so we couldn't include them:</p>
<ul>
<li><a href="https://sysdig.com/">Sysdig</a> <a href="https://docs.sysdig.com/en/using-promql.html">advertises PromQL support</a>, but has no <code>remote_write</code> protocol support to ingest arbitrary test data. According to contacts at Sysdig, <code>remote_write</code> may be supported at some point in the future, but we couldn't get a recent update on its availability timeline.</li>
<li><a href="https://www.vmware.com/de/company/acquisitions/wavefront.html">Wavefront</a> <a href="https://docs.wavefront.com/wavefront_prometheus.html">advertises partial PromQL support</a>, but they lack an HTTP endpoint against which to run test queries. Their PromQL support is only available within their own user interface so far, which makes it difficult to test against. However, judging by the various compatibility caveats listed in their documentation, we do not expect that they would reach a high test score if we could test them.</li>
</ul>
<p>We hope to be able to test even more vendors in the future.</p>
<p><strong>UPDATE:</strong> After publishing, we received questions about PromQL support in two more vendors:</p>
<ul>
<li><a href="https://www.influxdata.com/products/influxdb/">InfluxDB</a> once <a href="https://github.com/influxdata/promql">started implementing PromQL support</a> (coincidentally with the help of the author of this blog post), but as far as we are aware, this effort has been paused and PromQL support in InfluxDB is neither currently available nor is it being advertised.</li>
<li><a href="https://www.elastic.co/">Elastic</a> recently <a href="https://www.elastic.co/blog/elastic-metrics-7-7-0-released">advertised PromQL support in Elastic Metrics</a>. However, the announced feature is only about Elastic Metrics being able to run queries against an <em>existing</em> external PromQL endpoint (such as Prometheus) to then ingest the query result as metrics into Elasticsearch. There is no way to run PromQL on the resulting data stored in Elasticsearch itself.</li>
</ul>
<h3 id="minor-updates-to-the-test-query-set"><a href="#minor-updates-to-the-test-query-set" aria-label="minor updates to the test query set permalink"></a>Minor updates to the test query set</h3>
<p>Since the last testing round in August, we made minor changes to the test query set:</p>
<ul>
<li>For queries that looked at the absolute values of counter metrics (e.g. with no <code>rate()</code> or similar counter-related function applied), we changed the selected metrics to be gauges instead. This helps keep test cases somewhat more independent for a vendor like New Relic, which does not support storing or retrieving absolute values for counters.</li>
<li>We added a query selecting an intermittently present series to test whether <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness">staleness handling</a> works.</li>
</ul>
<h3 id="lets-get-started-updated-comparisons"><a href="#lets-get-started-updated-comparisons" aria-label="lets get started updated comparisons permalink"></a>Let's get started: Updated comparisons</h3>
<p>In this round of tests, we tested the following projects and vendors, in alphabetical order:</p>
<ul>
<li><a href="https://chronosphere.io/">Chronosphere</a> - A hosted monitoring and observability platform.</li>
<li><a href="https://cortexmetrics.io/">Cortex</a> - An open-source, horizontally scalable reimplementation of Prometheus.</li>
<li><a href="https://grafana.com/products/cloud/">Grafana Cloud</a> - A hosted monitoring and observability service.</li>
<li><a href="https://m3db.io/">M3</a> - An open-source metrics engine and time series database.</li>
<li><a href="https://www.metricfire.com/">MetricFire</a> - A hosted monitoing and observability service.</li>
<li><a href="https://newrelic.com/">New Relic</a> - A hosted monitoring and observability service.</li>
<li><a href="https://thanos.io/">Thanos</a> - An open-source project to provide query aggregation for long-term storage and HA on top of Prometheus.</li>
<li><a href="https://github.com/timescale/promscale">Promscale</a> (<a href="https://www.timescale.com/">TimescaleDB</a>) - An open-source project to store Prometheus data in TimescaleDB.</li>
<li><a href="https://victoriametrics.com/">VictoriaMetrics</a> - An open-source time-series database and monitoring system.</li>
</ul>
<p>Let's look at the test results for each of these systems:</p>
<h4 id="chronosphere"><a href="#chronosphere" aria-label="chronosphere permalink"></a>Chronosphere</h4>
<p>Chronosphere does not have a self-service account creation system yet, but they helpfully provided us with a test account with <code>remote_write</code> and PromQL HTTP API support. Chronosphere is built on top of M3 (tested below), so we expected similar test results for the two. After an initial test run against an outdated test environment using an older M3 version, Chronosphere updated our test account and we achieved a test score of <strong>100%</strong> against it.</p>
<h4 id="cortex"><a href="#cortex" aria-label="cortex permalink"></a>Cortex</h4>
<p>Last time we tested Cortex we encountered two minor issues: floating-point input timestamps were <a href="https://github.com/cortexproject/cortex/issues/2932">not rounded in the same way</a> as in Prometheus, and the system did not <a href="https://github.com/cortexproject/cortex/issues/416">support executing queries without a metric name</a>. The first issue has been resolved entirely, while the second one is being addressed by a new storage mode in Cortex - the new <a href="https://cortexmetrics.io/docs/blocks-storage/">blocks storage mode</a> vs. the older <a href="https://cortexmetrics.io/docs/chunks-storage/">chunks storage mode</a>.</p>
<p>Let's look at <a href="https://github.com/cortexproject/cortex/releases/tag/v1.5.0">version 1.5.0 of Cortex</a> and see what scores each of these modes received:</p>
<h6 id="cortex-with-chunks-storage"><a href="#cortex-with-chunks-storage" aria-label="cortex with chunks storage permalink"></a>Cortex with chunks storage</h6>
<p>When testing Cortex with the old chunks storage, we can now remove the query tweak to align input timestamps, since that bug has been fixed. Other than that, we still get the same test score of <strong>99.62%</strong> due to the chunks mode not supporting queries without metric names.</p>
<h6 id="cortex-with-blocks-storage"><a href="#cortex-with-blocks-storage" aria-label="cortex with blocks storage permalink"></a>Cortex with blocks storage</h6>
<p>Cortex with blocks storage mode now also does not require any query tweaks anymore and passes with a score of <strong>100%</strong>.</p>
<h4 id="grafana-cloud"><a href="#grafana-cloud" aria-label="grafana cloud permalink"></a>Grafana Cloud</h4>
<p>Grafana Cloud is a new test candidate that <a href="https://grafana.com/docs/grafana-cloud/metrics/prometheus/">advertises full hosted Prometheus functionality</a>. Under the hood, Grafana Cloud uses Cortex to offer this service. According to representatives from Grafana Labs, they are in the process of phasing out the last (shared) chunks-based Cortex cluster, while all new Cortex clusters are already using blocks as their storage mode.</p>
<p>To be able to cache PromQL queries, Grafana Cloud aligns incoming query start and end timestamps to the query resolution step width (10 seconds in our case). This is currently not configurable on the Grafana Cloud side, so we had to apply a cross-cutting query tweak to align input timestamps to our reference Prometheus server in the same way, to get comparable results.</p>
<p>With this in mind, we tested a Grafana Cloud account via <code>remote_write</code> and their Prometheus-style HTTP query API on both the remaining legacy cluster and a new dedicated blocks-storage cluster, and we got the same <strong>99.62%</strong> and <strong>100%</strong> test scores as for Cortex itself. Since the chunks-mode cluster is being retired this month, we count that as an overall <strong>100%</strong> score for Grafana Cloud.</p>
<h4 id="m3"><a href="#m3" aria-label="m3 permalink"></a>M3</h4>
<p>M3 is also a new candidate in this group that states, "M3 can be used as Prometheus Remote Storage and has 100% PromQL compatibility", <a href="https://m3db.io/">on its homepage</a>. Its documentation also mentions <a href="https://m3db.github.io/m3/integrations/prometheus/">Prometheus and PromQL integrations</a> that include <code>remote_write</code> support and a PromQL HTTP API endpoint. Using these with M3 version v1.0.0, we ran our test suite and received a test score of <strong>100%</strong>.</p>
<p><strong>Note:</strong> For PromQL to work 100% the same as in Prometheus, we had to ensure that our test query was only hitting raw, non-aggregated data in M3 (vs. data that has been downsampled into a lower resolution). We did this by not configuring any aggregation in our test M3 database.</p>
<h4 id="metricfire"><a href="#metricfire" aria-label="metricfire permalink"></a>MetricFire</h4>
<p>MetricFire, a hosted service by the people behind <a href="https://www.hostedgraphite.com/">hostedgraphite.com</a>, is still pretty new in the Prometheus space. While MetricFire documents how to write data into the system using the <code>remote_write</code> protocol, there is no officially supported way to run external PromQL queries against the collected data using an HTTP API yet. However, MetricFire representatives kindly explained a way to do this. We won't detail it here, but we expect that there will be a documented public HTTP API soon. In our talks with MetricFire we learned that they also use Cortex to back their service, and we also …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors">https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors</a></em></p>]]>
            </description>
            <link>https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267601</guid>
            <pubDate>Tue, 01 Dec 2020 17:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer Graphics from Scratch (2017)]]>
            </title>
            <description>
<![CDATA[
Score 286 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25266812">thread link</a>) | @fanf2
<br/>
December 1, 2020 | https://www.gabrielgambetta.com/computer-graphics-from-scratch/ | <a href="https://web.archive.org/web/*/https://www.gabrielgambetta.com/computer-graphics-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<header>

</header>
<p>
No Starch Press is publishing a book based on this website in early 2021. Stay tuned!
</p>
<p><strong>TL;DR:</strong> This book will <em>not</em> teach you how to use OpenGL or DirectX; instead, it can teach you how OpenGL and DirectX <em>work</em>. In practice you won’t write a software renderer for production use, but understanding how and why a renderer works will let you use OpenGL and DirectX more effectively.</p>
<p>Computer Graphics is a fascinating topic - how do you make <em>Toy Story</em> out of algorithms and some geometric data? Interestingly enough, it’s a mysterious topic not only for the average cinema fan, but also for world-class engineers who just haven’t been exposed to it.</p>
<p>Computer Graphics is also a frighteningly broad topic. From 3D rendering to photographic image filters, from fonts to particle systems, there’s a multitude of disciplines that can be categorized under CG. This work focuses exclusively on 3D rendering.</p>
<p><strong>Computer Graphics from scratch</strong> is my humble attempt to demystify that slice of Computer Graphics in an accessible way. It can be easily understood by high-school students, while covering the same topics of an university course. It is, in fact, based on my years of teaching the subject at my university.</p>
<p>There’s little pre-requisite knowledge, nor hardware or software dependencies. The only primitive used in the book is a method that lets us set the color of a pixel - hence <strong>“from scratch”</strong>. The algorithms are conceptually simple, and the math is straightforward. There is some high-school level trigonometry. There’s some basic Linear Algebra as well, but I’m including an appendix that can be consulted as necessary.</p>
<p>This work is divided in two main parts, <strong>Raytracing</strong> and <strong>Rasterization</strong>, which focus on the two main ways to make pretty pictures out of data. The <strong>Common concepts</strong> chapter introduces some basic knowledge necessary to understand these two parts.</p>
<p>The focus of this work is not on performance, but on clear conceptual exposition. The sample code is, well, <em>sample code</em>, written in the most <em>clear</em> way possible, which may not be the most <em>efficient</em> way to implement the algorithms. Where there are different ways to do something, I’ve chosen the easiest to understand.</p>
<p>The “end result” of this work is two complete, fully functional renderers: a raytracer and a rasterizer. Although they follow very different approaches, they produce similar results when used to render a simple scene:</p>
<figure>
<img src="https://www.gabrielgambetta.com/computer-graphics-from-scratch/images/comparison-1.png">
</figure>
<p>While their sets of features have considerable overlap, they aren’t identical, so this book covers their specific strengths:</p>
<figure>
<img src="https://www.gabrielgambetta.com/computer-graphics-from-scratch/images/comparison-2.png">
</figure>
<p>The book provides sample code throughout the text, as somewhat informal pseudocode; it also provides fully working implementations written in JavaScript that can run directly on your browser, rendering to a <code>canvas</code> element.</p>
<h2 id="why-read-this">Why read this?</h2>
<p>This work should give you all the knowledge necessary to write software renderers. Although in the age of GPUs few people have good reasons to write a pure software renderer, the experience of writing one is valuable for the following reasons:</p>
<ol type="1">
<li><p><strong>Shaders</strong>. The first GPUs had their algorithms hardcoded in hardware, but in modern ones you’re expected to write your own shaders. In other words, you’re still implementing big chunks of rendering software, except it now runs on the GPU.</p></li>
<li><p><strong>Understanding</strong>. Whether you’re using a fixed pipeline or writing your own shaders, <em>understanding</em> what’s going on behind the scenes lets you use the fixed pipeline better and write better shaders.</p></li>
<li><p><strong>Fun</strong>. Few areas of Computer Science have the kind of immediately visible results offered by Computer Graphics. The sense of accomplishment you get when your SQL query runs just right is <em>nothing</em> compared to what you feel the first time you get ray traced reflections right. I taught Computer Graphics at my university for 5 years. I often wondered why I enjoyed teaching the same thing semester after semester for so long; in the end, what made it worth it was seeing the faces of my students light up and use their first renders as desktop backgrounds.</p></li>
</ol>
<h2 id="work-in-progress">Work in progress</h2>
<p>This is a work in progress. Here’s a non-exhaustive to do list:</p>
<ul>
<li>Texture filtering</li>
<li>Normal mapping</li>
<li>Textures in the raytracer</li>
<li>Shadows in the rasterizer (stencil and shadow maps)</li>
<li>Reflection in the rasterizer</li>
<li>Expand the CSG and Refraction sections into chapters</li>
<li>Linear algebra appendix</li>
<li>Make demos interactive</li>
<li>Clean up demo code</li>
</ul>
<p>Feel free to contribute or to correct mistakes - all the text, diagrams and demos are in <a href="https://github.com/ggambetta/computer-graphics-from-scratch">Github</a>. PRs welcome!</p>

<p>I’m a senior software engineer at Google. In the past I’ve worked at <a href="http://improbable.io/">Improbable</a>, who have a good shot at building the Matrix, for real (or at the very least revolutionizing multiplayer game development), and at <a href="http://mysterystudio.com/">Mystery Studio</a>, a game development company I founded and ran for about a decade, and which released almost 20 games you probably never heard of.</p>
<p>I taught Computer Graphics for five years at university, where it was a semester-long third-year subject. I am grateful to all of my students, who served as unwitting guinea pigs for the materials that inspired this book.</p>
<p>I have other interests besides Computer Graphics, engineering-related and otherwise. See <a href="http://gabrielgambetta.com/">my website</a>, for more details and contact information.</p>


<p><span>Found an error?</span> Everything is in <a href="https://github.com/ggambetta/computer-graphics-from-scratch">Github</a>.
</p>


</div></div>]]>
            </description>
            <link>https://www.gabrielgambetta.com/computer-graphics-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25266812</guid>
            <pubDate>Tue, 01 Dec 2020 16:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS to FreeBSD migration a.k.a. why I left macOS]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 346 (<a href="https://news.ycombinator.com/item?id=25266435">thread link</a>) | @rodrigo975
<br/>
December 1, 2020 | https://antranigv.am/weblog_en/posts/macos_to_freebsd/ | <a href="https://web.archive.org/web/*/https://antranigv.am/weblog_en/posts/macos_to_freebsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>I think the title tells a lot about the story I’m going to tell you.</p>
<p>This is not a technical documentation for how I migrated from macOS to FreeBSD. This is a high-level for <em>why</em> I migrated from macOS to FreeBSD.</p>
<p>Not so long ago, I was using macOS as my daily driver. The main reason why I got a macbook was the underlying BSD Unix and the nice graphics it provides. Also, I have an iPhone. But they were also the same reasons for why I <strong>left</strong> macOS.</p>
<p>I did not want to write this post right after the migration, I wanted to take my time, use FreeBSD daily, see if I will ever miss macOS.</p>
<p>Here’s a tweet of mine from 8 months ago</p>
<blockquote><div lang="en" dir="ltr"><p>Every 4 months I look at my systems (servers, laptops, desktops, embedded) to see if there's anything suspicious, if anything got hacked, etc.</p><p>man, I did not realize that macOS is that complicated. Why is there a "studentd" running? I don't even use Classrooms :/</p></div>— Antranig Vartanian (@antranigv) <a href="https://twitter.com/antranigv/status/1234753346600394752?ref_src=twsrc%5Etfw">March 3, 2020</a></blockquote>


<p>Let’s look at it this way. macOS is becoming less Unix-y every year, <code>date(1)</code> is outdated, there are 100+ Unix processes running by the time the system is booted, most of them are useless for the general user, it has no native package manager (at least MacPorts/homebrew/pkgsrc is out there) and for a power user, there is no proper documentation. Have you ever checked the FreeBSD handbook? Everything is right there!</p>
<p>Okay, the nice graphics part. Have you seen the latest and greatest Big Sur? It feels like eye-candy, it’s not made for power users at all, everything seems to be a distraction now, even the icons. I’m no UI guru, but bringing iOS to the desktop is not for everyone.</p>
<p>So I decided to move to FreeBSD. This is where many people will tell me “Okay but not everything works outside the box”, true! but which OS works outside the box these days anyway? Windows is still a nightmare, setting up macOS took me 3 days the last time, Linux takes way more if you’re building it from scratch. Setting up FreeBSD took me 3 days, however this meant that I will NOT need to change it again for a very, very, VERY long time.</p>
<p>Every time Apple pushed an updated, my <code>pf.conf</code> and <code>automount</code> configs got broken on macOS. They either got deleted or they moved somewhere. Well, the last 2 times it just got deleted.</p>
<p>On FreeBSD, I upgraded from <code>12.1-RELEASE</code> to <code>12.2-RELEASE</code> and nothing broke, and in case there were any changes, FreeBSD just asked me what to do about them.</p>
<p>Let’s come back for a second. Unix is outdated and Apple does not care about it, fancy graphics are too fancy now. Doing forensics is almost impossible. And the hardware is, well, not the best out there (have you ever disassembled a MacBook Pro? it’s takes 2 hours to change a battery while I can reassemble my Dell Latitudes and ThinkPads in 30 minutes).</p>
<p>So there was no reason to stay here anymore. I had to migrate. The question is: where?</p>
<p>Linux has systemd, not my favorite thing out there, Windows is privacy nightmare. That left me with 2 major options: Linuxes without systemd (Gentoo, in my case) or BSDs.</p>
<p>Since I run FreeBSD servers anyway, I just migrated to FreeBSD.</p>
<p>Here’s a short review about running FreeBSD on ThinkPad T480s.</p>
<ul>
<li>WiFi: works. not the fastest, but fast enough.</li>
<li>Graphics: works.</li>
<li>Touchpad: works with multiple fingers AND very configurable via <code>sysctl</code>.</li>
<li>BT does discovery and pairs, I still have to try it with non-Apple headphones.</li>
<li>COVID-19 era: Zoom, Google Hangouts, Jitsi and all other WebRTC-based video conferencing software works via web as well.</li>
<li>Thanks to <a href="https://forums.freebsd.org/threads/linuxulator-how-to-run-google-chrome-linux-binary-on-freebsd.77559/">Linuxulator</a>, I can watch Netflix as well: <a href="https://twitter.com/antranigv/status/1327422687107555329">here’s a screenshot</a>.</li>
</ul>
<p>Most importantly, it’s Free and Open Source.</p>
<p>It’s been 1 month and 1 day since I last touched my MacBook Pro, so, what do I miss?</p>
<ul>
<li>Better BT support</li>
<li>Faster WiFi</li>
</ul>
<p>That’s it, that’s all missing on a FreeBSD laptop these days. WiFi can do 48Mbps according to <code>ifconfig</code> but I usually get 10-20Mbps. BT pairs with my Apple AirPods but I wish it worked till the end.</p>
<p>Having a nice workstation/laptop is not an easy thing, using macOS means living by Apple rules, Windows is the same for Microsoft. The BSDs gave me the power to be as free as possible :)</p>
<p>During the next weeks I’ll try to blog about the actual setup.</p>
<p>P.S. dear Apple employee, in case you’re reading this, please tell your management to update their BSD Unix layer. Some of us still care, some of us are not just Docker people, some of us are not just “modern” web developers. Thanks in advance.</p>
<p>That’s all folks! :)</p>

      </div></div>]]>
            </description>
            <link>https://antranigv.am/weblog_en/posts/macos_to_freebsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25266435</guid>
            <pubDate>Tue, 01 Dec 2020 16:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Busybox-based Linux distro from scratch]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25263398">thread link</a>) | @pfrog
<br/>
December 1, 2020 | https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/ | <a href="https://web.archive.org/web/*/https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1624">
	<!-- .entry-header -->

	<div>
		<p><img width="257" height="303" src="https://re-ws.pl/wp-content/uploads/2020/11/logo.gif" alt="linux logo" loading="lazy"></p><figure id="attachment_1648" aria-describedby="caption-attachment-1648"><a href="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg"><img loading="lazy" src="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg" alt="Canon SD MMC card 16 MiB" width="263" height="300" srcset="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg 263w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-899x1024.jpg 899w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-768x875.jpg 768w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-1348x1536.jpg 1348w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg 1443w" sizes="(max-width: 263px) 100vw, 263px"></a><figcaption id="caption-attachment-1648">16 MiB SD/MMC card. Made in Japan in 2005</figcaption></figure>
<p>Today, I would like to show something different, than usual reverse-engineering, that appears on my blog usually. I needed to prepare a Linux distro for myself to be able to run it on my PC. But not the ordinary operating system that we download from webpage, then use fancy graphical installer to select, what we want and where. My goals were very specific. First was to have it custom-compiled. With that in mind there aren’t many choices left (maybe Gentoo?). Second was to not cross 16 MiB boundary. Why exactly that? That’s simple. I have old (15 years old to be precise) SD/MMC card made for Canon of exactly that size. Quick check showed me that this is possible. I tried buildroot and it failed to fulfill second requirement and I decided not to continue, despite the obvious optimizations on kernel modules, I could do. It’s simply too complex for such a simple task. If not buildroot, then let’s go and see how to do such thing from scratch!</p>

<p>Basically the plan is to have custom Linux distro compiled from scratch. It may sound like something incredibly complex and hard to do. But it’s not. There are just few problems one must learn on how to overcome. The most problematic constraint in my case is, obviously, 16 MiB limit. To not exceed it, I have to use busybox as my userspace. This by the way simplifies distro development significantly. Busybox works the way, that, if linked statically, requires only one, single binary to be able to work correctly. So, to sum up, on software side, we need Linux and busybox. You may wonder, how do I want to boot that system, then? Well. I said I need Linux 🙂 Maybe some people know, some does not, that Linux is itself a boot loader of some kind. At least, when using UEFI and this is what I want to use, it can be loaded directly by UEFI firmware. But that’s another thing to note – I will describe a way to prepare a distro for UEFI – it won’t be as simple as that, for legacy BIOS.</p>
<p>The whole plan will look as follows:</p>
<ol>
<li>Get compiler</li>
<li>Compile Linux kernel</li>
<li>Compile busybox (statically and stripped!)</li>
<li>Prepare initramfs with whole userspace</li>
<li>Format drive as EFI System Partition</li>
<li>Combine kernel and initramfs into single binary</li>
<li>Optionally sign the binary, in case we want Secure Boot to be enabled</li>
<li>Add entry to embedded UEFI boot manager</li>
</ol>
<p>In the meantime, I am going to show few ways to debug the system, in case of any problems.<span id="more-1624"></span></p>

<p>This is maybe not so obvious, but you need new compiler. Most likely, you could use the one that your distro provides, aliased as simply gcc. But this way, you will by the way use glibc as your standard library. For a lightweight system, glibc does not fit well, as this is most heavyweight libc, we have available. Therefore, I will use uClibc. And for that, we need a compiler. Or, to be precise, a toolchain. A toolchain, consisting of kernel headers, uClibc and gcc. Here, I could show, how to build such thing from scratch. But it’s not a tutorial about building a toolchain. This requires knowledge that can fill another tutorial. Instead, I will use the toolchain prepared by my latest project – <a href="https://github.com/v3l0c1r4pt0r/cc-factory" target="_blank" rel="noopener noreferrer">cc-factory</a>. For those, who did not read <a href="https://re-ws.pl/2020/10/meet-cc-factory-a-factory-for-cross-compilers/">my previous post</a>, it is toolchain factory running in Docker container, that provides a recipe for a toolchain that just works. If you tried compiling a toolchain from scratch in the past, then you know that this can fail, even if you use crosstool-ng. With cc-factory, it works as long as Docker can start a service and has Docker Hub working. But enough of that. In cc-factory, I am experimenting with releasing binary distributions of my toolchain. And <a href="https://github.com/v3l0c1r4pt0r/cc-factory/releases/tag/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1">newest one</a> is special-made for this job. You can simply download it to you disk with:</p>
<pre>wget <span>'</span><span>https://github.com/v3l0c1r4pt0r/cc-factory/releases/download/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1.tar.gz</span><span>'</span>
</pre>
<p>After that, you have to install it to your <code>/opt</code> directory with:</p>
<pre>tar <span>-xvf</span> x86_64-gcc10.<span>2</span>.0-linux5.<span>9</span>.13-uclibc1.<span>0</span>.36-1.tar.gz <span>-C</span> /
</pre>
<p>If you prefer another installation path, then head onto cc-factory project to see, how to build one from source. Then, you can choose whatever path, you like for this SDK.</p>
<p>Next step is to export SDK’s bin directory to you PATH for convenience:</p>
<pre><span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:/opt/x86_64-linux-uclibc/bin</span><span>"</span>
</pre>
<p>Now, it’s nice to check, if toolchain works. Let’s write one-liner C hello world program to your temp directory, compile and run:</p>
<pre><span>echo</span><span> -e </span><span>'</span><span>#include &lt;stdio.h&gt;\nint main() {printf("Hello, World!\\n");}</span><span>'</span> <span>&gt;</span>/tmp/main.c
x86_64-linux-uclibc-gcc <span>-static</span> <span>-o</span> /tmp/main /tmp/main.c
/tmp/main
</pre>
<p>And you should see the familiar text on your screen. You are ready to go!</p>

<p>That is, in my opinion, the easiest part. First, we have to download kernel image, that we want to use. For that purpose, we need to go to <a href="https://www.kernel.org/" target="_blank" rel="noopener noreferrer">Kernel Archives</a> and download latest stable tarball. Optionally, we can download PGP signature and verify its correctness. But this is outside the scope of this tutorial. Another option to get kernel is to clone its stable repo with:</p>
<pre>git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
</pre>
<p>This is the path, I chose, because I don’t like leaving multiple copies of kernel sources on my hard drive, so I prefer to have one, central clone of repo and use for any project, I need it to.</p>
<p>In case of tarball, it now has to be unpacked with usual:</p>
<pre>tar <span>-xvf</span> linux-*.tar.gz
</pre>
<p>Then, in case of tarball, you got directory with name dependent on you kernel version, in case of git repo, it is simply linux. So we can cd into it, in any of the above cases:</p>
<pre><span>cd</span> linux*
</pre>
<p>In theory at this point, we could set the compiler, we prepared to be run by kernel buildsystem. But this is optional, as we target <code>x86_64</code> platform, that we run our host on, so default compiler should be as good as uClibc variant. I case, you want to use custom one, you have to export the following:</p>
<pre><span>export</span> <span>CROSS_COMPILE</span>=x86_64-linux-uclibc-
</pre>
<p>Now, we have to configure our kernel.</p>
<p>First step is to choose defconfig. Possible values can be listed in case of x86 with:</p>
<pre><span>ls</span> arch/x86/configs/
</pre>
<p>At the time of writing this returned the following options:</p>
<pre>i386_defconfig tiny.config x86_64_defconfig xen.config
</pre>
<p>As you can see, there are only a few. So, we do:</p>
<pre>make x86_64_defconfig
</pre>
<p>At this point, we are ready to compile. In case, you want to do some modifications, you could do:</p>
<pre>make menuconfig
</pre>
<p>And select (or deselect) some options there. If you think, you are ready, you can type:</p>
<pre>make <span>-j</span>
</pre>
<p>And wait couple of minutes (up to half an hour), depending on speed of your PC. Afterwards, you should see that <code>bzImage</code> has been made and is available at <code>arch/x86/boot/bzImage</code>. We can copy it somewhere in order to not accidentally start its recompilation:</p>
<pre>cp arch/x86/boot/bzImage ../
</pre>
<h2>Testing on hardware</h2>
<p>At this point, it is possible to run the kernel on our system. If you don’t have Secure Boot enabled, then you can try to copy the kernel to you EFI System Partition (wherever it is, I will call this path <code>ESP</code> from now on). But first create new directory for your distro:</p>
<pre><span>mkdir</span> <span>-p</span> ESP/EFI/linux
cp arch/x86/boot/bzImage ESP/EFI/linux/linuxx64.efi
</pre>
<p>I am changing the name in the meantime, as I heard that some systems does not like binaries without <code>.efi</code> extension. Now, we can try to boot.There is more than one way to do it. The one that works always is to utilize EFI firmware directly. But this one differs significantly between manufacturers, so if you prefer that one, please refer to his support pages. The other is to use one of existing tools. For sure KeyTool, that manages Secure Boot keys, is able to start any executable from ESP by browsing the filesystem. But the way I would like to show is, by using so called EFI shell. Why? Because EFI shell allows us to experiment with kernel parameters, by simply typing them, as we would start new user program. And, in fact, from EFI perspective, we simply start a new program.</p>
<p>There are many shells in the wild. I tried EDK2, that is available on Arch as <code>edk2-shell</code> package. It is then available at <code>/usr/share/edk2-shell/x64/Shell.efi</code> You can simply copy it to <code>ESP</code>, just like with kernel, then you have to add it to your EFI boot manager, or use boot manager that is able to autodetect it. You can find a bunch of resources on how to do it, even from inside Linux. But, please do not add the kernel, you copied in such way, to boot manager, as we will play with it a bit, later. Now, in EFI shell, you will be presented with a list of partitions, that the shell has detected. This might be not so obvious at first, but, somehow, you have to identify the one, that is you EFI partition. You should see a similar numbering to the one you see in Linux console, when you list with e.g. <code>lsblk</code>. You can try guessing it by typing its name, in similar way as in Windows, e.g.:</p>
<pre>FS0:
</pre>
<p>to switch to <code>FS0</code> partition. Then you can simply type ls to list its content. Once, you found the right one, it’s worth to remember it, as you might need it couple of times. How many, depends on how many problems, you would have.</p>
<p>Then go to the directory, where you copied your kernel:</p>
<pre><span>cd</span> EFI\linux
</pre>
<p>And ls to make sure, it is there. Now, we are ready to call it:</p>
<pre>linuxx64.efi
</pre>
<p>Yes. It’s as simple as that. But this will fail. We did not provide any root filesystem for our kernel, so it will gonna panic. But don’t worry, as long as reason of the panic is like that:</p>
<pre>not syncing: VFS: Unable to mount root fs on unknown-block(0,0)
</pre>
<p>then it was expected. In case of any other error, act accordingly, as this may be hardware dependent. So, probably, something has to be reconfigured in menuconfig.</p>
<h2>Testing in qemu</h2>
<p>It’s quite a nice option to be able to test your work on real hardware. However, in my opinion, it is much easier to do it in virtualized environment, that you can quickly reset at any time and where you would have latest binaries for testing, all the time, without wasting time for flashing them somewhere. Therefore I recommend to prepare qemu as such environment.</p>
<p>For that, you will need …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</a></em></p>]]>
            </description>
            <link>https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25263398</guid>
            <pubDate>Tue, 01 Dec 2020 08:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Tiny mobile-friendly interactive fiction game]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25262631">thread link</a>) | @memalign
<br/>
November 30, 2020 | https://memalign.github.io/m/dungeon/index.html | <a href="https://web.archive.org/web/*/https://memalign.github.io/m/dungeon/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://memalign.github.io/m/dungeon/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25262631</guid>
            <pubDate>Tue, 01 Dec 2020 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QEMU Advent Calendar 2020]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25262608">thread link</a>) | @todsacerdoti
<br/>
November 30, 2020 | https://www.qemu-advent-calendar.org/2020/ | <a href="https://web.archive.org/web/*/https://www.qemu-advent-calendar.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <div id="myCarousel">
      <div>
        <div>
          <div>
            <div>
              <p><img src="https://www.qemu-advent-calendar.org/2020/images/qemu-winter.png" alt="QEMU"></p>
              <h2>Brightening your days in the winter holiday season.</h2>
              <p>
               This advent calendar is brought to you by the
               <a href="https://www.qemu.org/">QEMU community</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div><!-- /.carousel -->

    <div id="day-1">
     <p>
	<img id="img-day01" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 1" onclick="opendoor('day01', 'Day 1 - Tweetable bootsector game');">
     </p>
     <h2 id="title-day01">Day 1</h2>
     <div id="desc-day01">
      <p>
        This bootloader game can be generated from text that fits in a tweet.
      </p>
      <p>
       Size of download is 893 bytes.
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/day01.tar.gz" role="button">Download</a>
     </p>
    </div>

    <div id="day-2">
     <p>
       <img id="img-day02" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 2" onclick="opendoor('day02', 'Day 2 - QEMU 5.2.0-rc4');">
     </p>
     <h2 id="title-day02">Day 2</h2>
     <div id="desc-day02">
      <p>
       No disk image today, but a new release candidate for QEMU: Version 5.2.0-rc4 has just been published yesterday – please download the package and give it a try! 
      </p>
      <p>
       Size of download is 102 MB
      </p>
      
     </div>
     <p>
       <a href="https://download.qemu.org/qemu-5.2.0-rc4.tar.xz" role="button">Download</a>
     </p>
    </div>

    <div id="day-3">
     <p>
       <img id="img-day03" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 3" onclick="opendoor('day03', 'Day 3 - GW-BASIC');">
     </p>
     <h2 id="title-day03">Day 3</h2>
     <div id="desc-day03">
      <p>
	GW-BASIC is a dialect of the BASIC programming language and it came with MS-DOS. It was open-sourced on May 21st 2020 under the MIT License. The famous BASIC game DONKEY.BAS is included as a demo.
      </p>
      <p>
       Size of download is 10.2 MB
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/gw-basic.tar.xz" role="button">Download</a>
     </p>
    </div>

    <div id="day-4">
     <p>
       <img id="img-day04" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 4" onclick="opendoor('day04', 'Day 4 - bootRogue');">
     </p>
     <h2 id="title-day04">Day 4</h2>
     <div id="desc-day04">
      <p>
	bootRogue, a roguelike game that fits in a boot sector (511 bytes) by Oscar Toledo G.
      </p>
      <p>
       Size of download is 1936 Bytes
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/day04.tar.gz" role="button">Download</a>
     </p>
    </div>

    <div id="day-5">
     <p>
       <img id="img-day05" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 5" onclick="zonk('day05');">
     </p>
     <h2 id="title-day05">Day 5</h2>
     <p>
       Image will be available on December 5th.
      </p>
     
    </div>

    <div id="day-6">
     <p>
       <img id="img-day06" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 6" onclick="zonk('day06');">
     </p>
     <h2 id="title-day06">Day 6</h2>
     <p>
       Image will be available on December 6th.
      </p>
     
    </div>

    <div id="day-7">
     <p>
       <img id="img-day07" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 7" onclick="zonk('day07');">
     </p>
     <h2 id="title-day07">Day 7</h2>
     <p>
       Image will be available on December 7th.
      </p>
     
    </div>

    <div id="day-8">
     <p>
       <img id="img-day08" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 8" onclick="zonk('day08');">
     </p>
     <h2 id="title-day08">Day 8</h2>
     <p>
       Image will be available on December 8th.
      </p>
     
    </div>

    <div id="day-9">
     <p>
       <img id="img-day09" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 9" onclick="zonk('day09');">
     </p>
     <h2 id="title-day09">Day 9</h2>
     <p>
       Image will be available on December 9th.
      </p>
     
    </div>


    <div id="day-10">
     <p>
       <img id="img-day10" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 10" onclick="zonk('day10');">
     </p>
     <h2 id="title-day10">Day 10</h2>
     <p>
       Image will be available on December 10th.
      </p>
     
    </div>

    <div id="day-11">
     <p>
       <img id="img-day11" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 11" onclick="zonk('day11');">
     </p>
     <h2 id="title-day11">Day 11</h2>
     <p>
       Image will be available on December 11th.
      </p>
     
    </div>

    <div id="day-12">
     <p>
       <img id="img-day12" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 12" onclick="zonk('day12');">
     </p>
     <h2 id="title-day12">Day 12</h2>
     <p>
       Image will be available on December 12th.
      </p>
     
    </div>

    <div id="day-12">
     <p>
       <img id="img-day14" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 13" onclick="zonk('day13');">
     </p>
     <h2 id="title-day13">Day 13</h2>
     <p>
       Image will be available on December 13th.
      </p>
     
    </div>

    <div id="day-14">
     <p>
       <img id="img-day14" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 14" onclick="zonk('day14');">
     </p>
     <h2 id="title-day14">Day 14</h2>
     <p>
       Image will be available on December 14th.
      </p>
     
    </div>

    <div id="day-15">
     <p>
       <img id="img-day15" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 15" onclick="zonk('day15');">
     </p>
     <h2 id="title-day15">Day 15</h2>
     <p>
       Image will be available on December 15th.
      </p>
     
    </div>

    <div id="day-16">
     <p>
       <img id="img-day16" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 16" onclick="zonk('day16');">
     </p>
     <h2 id="title-day16">Day 16</h2>
     <p>
       Image will be available on December 16th.
      </p>
     
    </div>

    <div id="day-17">
     <p>
       <img id="img-day17" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 17" onclick="zonk('day17');">
     </p>
     <h2 id="title-day17">Day 17</h2>
     <p>
       Image will be available on December 17th.
      </p>
     
    </div>

    <div id="day-18">
     <p>
       <img id="img-day18" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 18" onclick="zonk('day18');">
     </p>
     <h2 id="title-day18">Day 18</h2>
     <p>
       Image will be available on December 18th.
      </p>
     
    </div>

    <div id="day-19">
     <p>
       <img id="img-day19" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 19" onclick="zonk('day19');">
     </p>
     <h2 id="title-day19">Day 19</h2>
     <p>
       Image will be available on December 19th.
      </p>
     
    </div>

    <div id="day-20">
     <p>
       <img id="img-day20" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 20" onclick="zonk('day20');">
     </p>
     <h2 id="title-day20">Day 20</h2>
     <p>
       Image will be available on December 20th.
      </p>
     
    </div>

    <div id="day-21">
     <p>
       <img id="img-day21" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 21" onclick="zonk('day21');">
     </p>
     <h2 id="title-day21">Day 21</h2>
     <p>
       Image will be available on December 21th.
      </p>
     
    </div>

    <div id="day-22">
     <p>
       <img id="img-day22" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 22" onclick="zonk('day22');">
     </p>
     <h2 id="title-day22">Day 22</h2>
     <p>
       Image will be available on December 22th.
      </p>
     
    </div>

    <div id="day-23">
     <p>
       <img id="img-day23" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 23" onclick="zonk('day23');">
     </p>
     <h2 id="title-day23">Day 23</h2>
     <p>
       Image will be available on December 23th.
      </p>
     
    </div>

    <div id="day-24">
     <p>
       <img id="img-day24" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 24" onclick="zonk('day24');">
     </p>
     <h2 id="title-day24">Day 24</h2>
     <p>
       Image will be available on December 24th.
      </p>
     
    </div>

    <hr>

    <div>

      <div id="about">
        <h2>About</h2>
        <p>
          The QEMU Advent Calendar 2020 features a QEMU disk image each day of
          December until the 24th. Each day a new package becomes available
          for download.
        </p>
        <p>
          Every download contains a little 'run' shell script that starts the
          QEMU emulator with the recommended parameters for the disk image.
          Disk images are either contained directly in the download or are
          downloaded by the 'run' script (you need to have installed 'curl' or
          'wget' in that case).
        </p>
        <p>
          The disk images contain interesting operating systems and software
          that run under the QEMU emulator. Some of them are well-known or
          not-so-well-known operating systems, old and new, others are custom
          demos and neat algorithms.
        </p>
        <p>
          The 'run' scripts (and disk images if included in the download)
          were created by volunteers from the QEMU community to showcase cool
          software that QEMU can run.
        </p>
      </div>

      

      <hr>

      

    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    
    
  

</div>]]>
            </description>
            <link>https://www.qemu-advent-calendar.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25262608</guid>
            <pubDate>Tue, 01 Dec 2020 05:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do I care the open web is dying?]]>
            </title>
            <description>
<![CDATA[
Score 385 | Comments 337 (<a href="https://news.ycombinator.com/item?id=25261132">thread link</a>) | @archajain
<br/>
November 30, 2020 | https://insightbrowser.com/blog/open-web-dying-why-care | <a href="https://web.archive.org/web/*/https://insightbrowser.com/blog/open-web-dying-why-care">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p><em>Part 1: How your user experience changes for the worse as the open web gives way to walled gardens</em></p><p>I hang out in two circles. Open web enthusiasts that are lamenting its demise, and regular users who are happy with their fast snappy apps and couldn't care less. </p><p>These groups have a hard time talking because the "open web" too often comes across as an idealistic abstract notion and most end users just don't tangibly feel the bad consequences. In fact, they're often happier with the snappy, vertically integrated experience of closed app ecosystems. </p><p>My goal here is to make it more palpable how everyday apps, searches and tools get worse when we let big centralized companies take over the web, and explore some paths for reversing it.</p><h2>What is the open web?</h2><p>Most definitions of the "open web" I've seen are either too technical to be accessible or too abstract to be usable and getting gridlocked in this debate often means watching from the sidelines while actual user welfare slowly diminishes.</p><p>Three characteristics that proponents of the open web will agree to in roughly descending order are:</p><ul><li><strong>Ease of publishing</strong>: anyone can publish to it freely or at least very cheaply, and is on the same footing with a globally accessible URL</li><li><strong>Ease of consuming</strong>: Net neutrality — ISP's dont cut deals with corporations to make some websites load faster or cheaper than others.</li><li><strong>Ease of remixing</strong>. You can see the source code. Content licenses and tools are permissive for derived works.</li></ul><h2>Detour: A framework to break down how people use the web</h2><p>I want to focus on the user experience point of view. To do this, I'm going to introduce a framework that divides up all our internet usage into two categories.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/xscGdbWOOPkGjdER.png" alt="Frame 1.png"></p><h3><strong>Unfamiliar problems</strong></h3><p>You have an unfamiliar problem and to solve it you either need to learn something new, or purchase goods or services to solve it</p><ul><li>e.g. taking out a mortgage, a health problem in the family, where to go to college, what skill to acquire next.</li><li>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services.</li><li>These user journeys start with search engines — Google predominantly and **a lot of the time solving them is spent on web pages**.</li><li>When people are looking to solve unfamiliar problems, **revenue is typically higher-margin**, because users can't price the products and services as well.</li><li>These ultimately transition to being familiar problems.</li></ul><h3><strong>Familiar problems</strong></h3><ul><li>e.g. being entertained, keeping the dog food in stock,</li><li>These are best solved with apps like Email, Netflix, Twitter, DTC subscription boxes, etc.</li><li>Solving these needs has a very well defined user interaction journey. You open the app you're familiar with and follow its standard flow.</li><li>Revenue from people solving familiar problems is typically lower-margin and there's more competing products.
</li></ul><h3>How we're spending our time on familiar vs. unfamiliar problems</h3><p>Using time spent in apps vs mobile web on mobile is a way to proxy how we divide up our time.<strong> We spend most of our time on familiar problems but have a constant trickle of unfamiliar problems</strong>.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/cPuXkKFELALeIAkI.png" alt="Untitled (1).png"></p><h2>Unfamiliar problems are better solved with the open web</h2><p>Think about the last time you did some research, e.g. choosing a phone plan. You asked your friends, compared on forums, looked at the official sites, scribbled some notes and made a decision. Even if this journey was quick, you likely traversed a dozen services and products to do this.</p><p>Unfamiliar problems have less constraints, require creativity to solve, and thus are better suited to open solutions. Some other things that work for the open web here</p><ul><li>comparing alternatives is easier.</li><li>changing modalities (e.g. from reading to video) is easier.</li></ul><h2>Familiar problems stand to benefit more from tight vertical integration</h2><p>Take Spotify for example. It solves the very familiar problem of listening to music. Spotify just works better as an app because</p><ul><li>Controlling the user experience end to end makes for smoother flows.</li><li>Having all the user data kept with Spotify allows for better recommendation algorithms.</li><li>Spotify can easily hand off between devices.</li><li>It can run in the background</li></ul><p>Sure, the web can do a bunch of these things, but they're simply not first-class considerations in the open-read-close workflow that the browser was designed for.</p><h2>But the open web can be better for familiar problems too, especially for breaking monopolies</h2><p>Let's look at Amazon. Initially you start buying there because of their "always low prices" and the convenience of 2 day shipping. Over the years you keep shopping there, until you've forgotten that </p><ol><li>free 2 day shipping is now near universal</li><li>amazon isn't often the cheapest place</li></ol><p>On the Amazon app, you see the story around the product that best serves Amazon, not the buyer. Meanwhile, over on Insight you can use the web version and do all these things the app can't.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/ZEblynrLvBsutnlQ.png" alt="Screen Shot 2020-11-17 at 5.42.21 PM.png"></p><p>... and not just that

</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/JVZoTRazmYPZXBQQ.png" alt="Screen Shot 2020-11-17 at 5.59.22 PM.png"></p><h2><strong>How solving unfamiliar problems gets harder too</strong></h2><p>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services. The incentives to freely create knowledge that solves unfamiliar problems is lost as the web closes down.</p><ul><li>Google increasingly takes a larger percent of ad revenue as they <a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/">start extracting answers from pages and showing them on their search result pages.</a><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a></li><li><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a>Publishers have to either a) paywall their content (e.g. NYTimes) or b) subtly sell products (everyone standing a Wirecutter alternative), or c) ask for donations in order to survive.</li><li>Only a few big name publishers survive. Google and Facebook start sending them more of the traffic that's left, and since domain rank plays a big part in Google's ranking, those that survived assimilate more power and rank better.</li><li>and search engines seem more littered with SEO junk and less actually useful information year over year.</li></ul><h2>In conclusion, and where we fit in.</h2><p>And that's how your user experience slowly degrades, and that's why we stand to suffer as users if we give up the ability to remix software that the web brought us and closed apps are now taking away. </p><p>Our goal with Insight is to give the web (in particular on mobile) a fighting chance by exhibiting how it can be more powerful than a closed ecosystem and give more control to the end-user. We do this by showcasing the web's infinite extensibility and customizability for common use cases like <a href="http://insightbrowser.com/collections/search">search</a>, <a href="https://insightbrowser.com/collections/shopping">shopping</a>, <a href="https://insightbrowser.com/collections/reading">reading</a> and <a href="https://insightbrowser.com/collections/cooking">cooking</a>.</p><p>Insight's advanced features will soon only be available to Pro subscription users but for a limited time we're opening up <strong>lifetime free beta access if you download it via TestFlight below.</strong></p><h3>Coming up in part 2</h3><ul><li>What parts of the open web probably should die off?</li><li>A pragmatic path for what's left of the open web to thrive again.</li></ul><p>We'd love to hear from you, feel free to tweet at or DM us at @<a href="https://twitter.com/insightbrowser">insightbrowser</a>, and my personal Twitter is <a href="https://twitter.com/abhinavsharma">@abhinavsharma</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://insightbrowser.com/blog/open-web-dying-why-care</link>
            <guid isPermaLink="false">hacker-news-small-sites-25261132</guid>
            <pubDate>Tue, 01 Dec 2020 01:16:22 GMT</pubDate>
        </item>
    </channel>
</rss>
