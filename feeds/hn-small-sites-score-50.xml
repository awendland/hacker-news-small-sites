<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 07 Mar 2021 16:52:51 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 07 Mar 2021 16:52:51 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[FizzBuzz Mario World: Learning Assembly Language and Having Some Fun]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26362739">thread link</a>) | @vga805
<br/>
March 5, 2021 | https://computebeauty.com/posts/fbmw/index.html | <a href="https://web.archive.org/web/*/https://computebeauty.com/posts/fbmw/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've wanted to learn <a href="https://en.wikipedia.org/wiki/Assembly_language" target="_blank">Assembly language (ASM)</a> programming for a long time. I finally found the perfect project to do it: hacking Super Mario World (SMW). It was a lot of fun so I thought I'd document the process.</p><p>The SMW <a href="https://en.wikipedia.org/wiki/ROM_hacking" target="_blank">ROM hacking</a> community is vibrant. It's an impressively talented and creative community that makes a lot of awesome games with custom graphics, music, level design, and game physics. Stumbling upon <a href="https://www.youtube.com/results?search_query=super+mario+world+rom+hack" target="_blank">these hacks</a> on YouTube started me down this rabbit hole.</p><p>TLDR: the code and a list of the resources mentioned in this post can be found on <a href="https://github.com/thoughtbyte/super-fizzbuzz-world" target="_blank">GitHub</a>.</p><h2>FizzBuzz Mario</h2><p><a href="https://en.wikipedia.org/wiki/Fizz_buzz" target="_blank">FizzBuzz</a> is a common problem that beginner programmers solve for practice. The objective is to loop from 1 to 100 and:</p><ul><li>for every number divisible by 3, print 'fizz'</li><li>for every number divisible by 5, print 'buzz'</li><li>for every number divisible by 3 and 5, print 'fizz buzz'</li><li>otherwise print the number</li></ul><p>The goal of this project is to solve a problem similar to FizzBuzz by writing custom ASM that can be patched, or inserted, into the SMW code. The perfect context for FizzBuzz in SMW is the coin count. At any one time the player can have between 0 and 99 coins. Additionally, Mario can have 1 of 4 power-up statuses: small, big, cape, and fire. Here's the behavior we'll hack into our version of SMW:</p><ul><li>when coin count is divisible by 3, set status to big</li><li>when coin count is divisible by 5, set status to cape</li><li>when coin count is divisible by 3 and 5, set status to fire</li><li>otherwise set status to small</li></ul><p>Here's game-play of the finished product:</p><p><iframe title="FizzBuzz Mario World Demo" src="https://www.youtube.com/embed/APwAE0wiGF8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>Getting Started</h2><p>After a few minutes of searching the web I found the source of most of the information I'll be sharing: <a href="https://www.smwcentral.net/" target="_blank">SWM Central</a>. You can find a full list of resources at the end of this article but the guides I found most helpful were Ersanio's <a href="https://ersanio.gitbook.io/assembly-for-the-snes/" target="_blank">Assembly for the SNES</a> and <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=15073" target="_black">Assembly for Super Mario World</a>. The former assumes no knowledge of ASM. The latter refreshes the ASM information from the former and then goes into how to apply a simple patch similar to the one we'll be writing. Both are quick reads and I recommend them to any programmer that wants to know what ASM programming feels like.</p><h3>Memory</h3><p>ASM is a low-level language with which you deal directly with individual bytes of memory. SNES games are comprised of read-only memory (ROM) and random-access memory (RAM). You can think of the ROM as the game cartridge itself. Instead of an actual cartridge and SNES, the ROM for present purposes is a computer file that you can play on a <a href="http://www.snes9x.com/" target="_blank">SNES emulator</a>. The ROM is where all the code for how the game works is stored. This memory, as the name implies, is usually only ever read from. Our goal is to hack this ROM by overwriting a small part of it thus changing how the game behaves.</p><p>The RAM is on the SNES itself and it's where values are stored that will change while the game is played. The coin counter value needs to live in RAM because it changes often. The same goes for the player's power-up status.</p><p>In both ROM and RAM, memory is a long list of addresses where values can be stored. These addresses are represented in <a href="https://en.wikipedia.org/wiki/Hexadecimal" target="_blank">hexadecimal (hex)</a>. For our purposes we'll need to figure out the memory addresses for three things: the value of the coin count, the value of the power-up status, and where to insert some custom code.</p><p>Fortunately, people have completely disassembled SMW and mapped the RAM and ROM, so finding what we need is a simple web search. The RAM map can be found on <a href="https://www.smwcentral.net/?p=memorymap&amp;game=smw&amp;u=0&amp;address=&amp;sizeOperation=%3D&amp;sizeValue=&amp;region[]=ram&amp;type=*&amp;description=" target="_blank">SMW Central</a>. The RAM begins at address <code>$7E0000</code> and ends at <code>$7FC800</code>. The <code>$</code> indicates hex. By searching a few relevant keywords I found that the coin count is stored at address <code>$7E0019</code> and the power-up status is stored at address <code>$7E0DBF</code>. The entry for power-up status also indicates the 4 possible values for this address and what they mean: 1 for big Mario, 2 for cape Mario, 3 for fire Mario, and 0 for small Mario.</p><p>This gives us a basic idea of what our ASM code will need to do, in pseudocode:</p><pre><code>every time the coin count increases:
  get the value of RAM address $7E0019 (coin count)
  if that value is divisible by 15
    store 3 in RAM address $7E0DBF (power-up status)
  else if that value is divisible by 5
    store 2 in RAM address $7E0DBF
  else if that value is divisible by 3
    store 1 in RAM address $7E0DBF
  else store 0 in RAM address $7E0DBF</code></pre><p>Now we need to figure out where to insert our code. I want this code to run whenever the player gets a coin so I searched for "coin count" within the ROM map and found <code>$008F1D</code>, a 30 byte piece of code that "handles actually increasing the player's coin count and giving a life from 100 coins." This is a good start, but we can't just insert code into 30 bytes of ROM without seeing what it does. We will break everything if we're not careful. Unfortunately the ROM map on SWM Central doesn't have the actual code stored at this address. But then I found <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=21822" target="_blank">All.log++</a>: a complete disassembly of the SMW source code, in ASM, with extensive comments and labels.</p><p>Inspecting the disassembled SMW source code at this coin count code address, I noticed that the address where the coin count is actually increased is <code>$008F25</code>. That is, this is the memory address of ROM that stores the instruction that literally adds 1 to the coin count every single time the player receives 1 coin. But instead of just increasing the coin count by 1, I want to patch the ROM so that when the code at this address gets executed, the SNES <i>also</i> runs my FizzBuzz code.</p><p>Now we have all of the relevant memory addresses that we need, and we have the pseudocode that we need to run at the coin count increase ROM address. Now we assemble.</p><h2>Writing the Code</h2><p>Our first two lines are easy:</p><pre><code>!PowerUpStatus = $0019
!CoinCount = $0DBF</code></pre><p>We simply set the RAM memory addresses that we need for the coin count and power-up status to some labels so they'll be easier to refer to in the code. Notice that we dropped the <code>7E</code> from both addresses. We don't need it. These lines don't actually get patched into the ROM. All occurrences of the labels in the code that we will write will get replaced with the addresses by the assembler. The assembler is the thing that will take our code and insert it into the ROM.</p><h3>Hijacking the Coin Count Increase Code</h3><p>We know where we want to insert our code: the ROM address where the coin count is increased. But we can't insert <i>all</i> of our code into this address, we'll overwrite a lot of stuff and break the game. We can only insert a few bytes, and we have to make sure the bytes that we overwrite are executed by us in our own code so that everything that the original code was supposed to do still happens. So what we'll do is insert one instruction in the ROM at the coin count increase address that tells the processor to <i>jump</i> to the rest of our code. Then we'll tell the assembler to insert our code in some free space so we don't overwrite anything. Here's what that looks like:</p><pre><code>ORG $008F25
JSL FizzBuzz
NOP
NOP

freecode</code></pre><p><code>ORG $008F25</code> instructs the assembler to insert the following instruction, <code>JSL FizzBuzz</code>, into the ROM address where the coin count is increased. What <code>JSL FizzBuzz</code> means is: <b>J</b>ump to the <b>S</b>ubroutine code labeled <code>FizzBuzz</code>. Most ASM operation codes, or opcodes, are menumonic. The J and S are for Jump and Subroutine. We can ignore the L, it's beyond the scope of this.</p><p>What's with the <code>NOP</code>s? As it turns out, the code we've chosen to overwrite, the coin count increase instruction, is 3 bytes long (we know this because All.log++ tells us that). The code we insert, <code>JSL FizzBuzz</code>, is 4 bytes long. So in our attempt to overwrite 1 3 byte long instruction, we overwrote the first byte of a second instruction.</p><p>The fix for this is that we need remember to execute <i>both instructions that we overwrote</i> in the code <i>we</i> write. The second instruction we overwrite, like the first, is 3 bytes long, for a total of 6 bytes. But again, the code we inserted is only 4 bytes: there are still 2 dangling bytes that were previously part of that second instruction. That's not good. Random, partially overwritten bytes in the code will break the game. So, we include 2 <code>NOP</code> instructions. These are <b>N</b>o <b>OP</b>erations. We do nothing for 2 bytes to fill up the space not filled up by the previous 4 bytes of code we inserted. To recap, we overwrote 6 bytes of 2 instructions with 6 bytes of our own instruction that jumps to our custom code.</p><p><code>freecode</code> just means find some free space in the ROM to put the rest of our custom ASM code.</p><h3>The FizzBuzz Subroutine</h3><p>The following code is the beginning of the <code>FizzBuzz</code> subroutine that we referenced above.</p><pre><code>FizzBuzz:
INC !CoinCount
LDA #$0F
STA $00
LDA !CoinCount
JSR Mod</code></pre><p>The first line is the label. The second, <code>INC !CoinCount</code>, means <b>INC</b>rement the value in the memory address for the coin count by 1. This is what the first instruction of the code we overwrote was supposed to do, so we do it here ourselves.</p><p>In ASM, one of the most important things is the <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)" target="_blank">accumulator</a>. Essentially, the accumulator (A) is the memory address where the microprocessor stores its results from math and logic operations. We can also store stuff there for use in math operations. <code>LDA #$0F</code> does just that. It <b>L</b>oa<b>D</b>s into the <b>A</b>ccumulator the value 15. 0F is hex for the decimal value 15, and the # means we want the value 15 itself, not what's stored at the memory address 15.</p><p>We then run <code>STA $00</code>, this <b>ST</b>ores the value of the <b>A</b>ccumulator into memory address <code>$00</code>. This memory address is "scratch" memory that has no assigned purpose other than as a place to store temporary values. We couldn't just store a value directly into <code>$00</code>, instead it was a two-step process: load a value into A, then store the value of A in <code>$00</code>. Next, <code>LDA !CoinCount</code> loads the value of the coin count into A.</p><p>So now we have two values stored in memory: the coin count, stored in A, and 15, stored in <code>$00</code>. To check if something is divisible by 3 and 5, we can divide it by 15 and check if there's a remainder. Many programming languages have a modulo operator that gives you the remainder of 1 number divided by another. For example, 47 modulo 15 is 2. <code>JSR Mod</code> means <b>J</b>ump to the <b>S</b>ub<b>R</b>outine labeled <code>Mod</code>.…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computebeauty.com/posts/fbmw/index.html">https://computebeauty.com/posts/fbmw/index.html</a></em></p>]]>
            </description>
            <link>https://computebeauty.com/posts/fbmw/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26362739</guid>
            <pubDate>Fri, 05 Mar 2021 22:04:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do What Makes the Best Story]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26359378">thread link</a>) | @tosh
<br/>
March 5, 2021 | https://amasad.me/story | <a href="https://web.archive.org/web/*/https://amasad.me/story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Kids are always telling themselves stories. Try to remember yourself as a child lying in bed, anticipating an exciting day tomorrow, and you'll probably remember telling yourself a story about how cool it's going to be, who's going to be there, and how much fun you'll have. Self storytelling might be more pronounced in kids -- they like to say it out loud -- but it never goes away and only subsides to the background in adults. Self storytelling is so essential for people that one of the most effective <a href="https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy">techniques</a> for treating depression and anxiety boils down to "tell yourself better stories." </p>
<p>Life is also a form of self storytelling. We're continually retelling ourselves our life story, but very few people think of themselves as authors of their story, not mere subjects. People with extraordinary high-agency realize this early in life and start maximizing the interestingness of their life story.</p>
<p>Having a fascinating life story is not just an exercise in vanity -- it has a real impact on your success in life. You'll have an easier time attracting friends as well as life and business partners. It'll also make it much easier to sell yourself or your products. It has a kind of compounding <a href="https://en.wikipedia.org/wiki/Halo_effect">halo effect</a>.</p>
<p>Startups also have to be good stories. A good business idea or market is not enough to endure the pain and have the motivation to get a startup off the ground. Without an interesting story about the founding of the company and the vision, you'll have a hard time attracting talent and money. Notice how the most successful startups in the world all have remarkable genesis stories. </p>
<p>So next time you're faced with a tough decision, consider the path that makes a more interesting story. If it turned out to be the wrong decision to have made, you'd at least be fun at dinner parties.</p>

          </div></div>]]>
            </description>
            <link>https://amasad.me/story</link>
            <guid isPermaLink="false">hacker-news-small-sites-26359378</guid>
            <pubDate>Fri, 05 Mar 2021 17:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The reason Okta spent $6.5B on Auth0]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 138 (<a href="https://news.ycombinator.com/item?id=26358309">thread link</a>) | @advaitruia
<br/>
March 5, 2021 | https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0 | <a href="https://web.archive.org/web/*/https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png" loading="lazy" width="680" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" alt="Express session vs SuperTokens" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png 2835w"></p><p>March 05, 2021</p>

<p>Okta acquired <a href="https://www.okta.com/press-room/press-releases/okta-signs-agreement-to-acquire-auth0/">Auth0 for $6.5B</a> in an all stock deal (Okta was valued at ~$35B in the few days preceding the
announcement).<br></p>
<p>In July last year, Auth0 <a href="https://auth0.com/blog/auth0-announces-120m-seriesf-funding/">raised $120M</a> in private financing at a valuation of $1.9B. The round was led by Salesforce
Ventures with participation from DTCP and other existing investors.<br></p>
<p><strong>The acquisition is a ~3.5X jump in Auth0â€™s valuation from last year.Â&nbsp;</strong><br></p>
<h2 id="Security">Why acquire Auth0 for $6.5B?</h2>

<ol role="list">
<li>
<p><span>Complementary product and revenue streamâ€¨<br></span>Oktaâ€™s
core strength is workforce identity and it used to be almost all of their revenue. In the last few years,
revenues from their customer identity product has grown to 25% of total revenues from almost nothing. Auth0
core strength is customer identity. With Auth0, Okta has the best product for both use cases.<br></p>
</li>
<li>
<p><span>Increasing addressable marketâ€¨<br></span>According to Todd,
the founder of Okta, workforce identity is a $30B market and customer identity is $25B. The customer identity
space effectively doubles Oktaâ€™s addressable market. In return, Okta is paying 20% of its market cap for that
opportunity.<br></p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png" loading="lazy" sizes="(max-width: 479px) 280px, (max-width: 767px) 500px, 640px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png 1582w" alt="">
</li>
<li>
<p><span>Competition and pricing power<br></span>Auth0 is the most
prominent alternative that customers consider when evaluating Okta. The acquisition of Auth0 eliminates that
threat and grants Okta pricing power as a result.<br></p>
</li>
<li>
<p><span>Go To Market (GTM) strategy<br></span>Okta is built as a top
down sales organisation whereas Auth0 is built with a developer first bottoms up acquisition strategy. This
allows Okta to get the best of both worlds.<br></p>
<p>In the words of the Founder and CEO of Auth0, â€œWe have a large thriving developer
community, which provides powerful grassroot support for Auth0 within SMB and enterprise that we leverage in
our sales motion. Our developer-led adoption fosters rapid customer growthâ€�<br></p>
</li>
<li>
<p><span>Strategic acquisition<br></span>There were rumours that
Salesforce was interested in acquiring Auth0. Given that Salesforce has made several key acquisitions (Slack,
Mulesoft, and others) and led Auth0â€™s last round, this is a well founded theory. It is possible that Okta had
to make a preemptive move. Weâ€™ve heard anecdotally that Salesforceâ€™s and Oracleâ€™s identity solution were both
performing badly and they were looking to do something about it. Auth0 was the perfect candidate for and was
also supposedly being shopped around.<br></p>
</li>
</ol>
<p>Finally, â€¨there was a Hackernews comment along the lines of: â€œ$6,500,000,000.00 for a company
providing authentication APIs?â€� and the sentiment has been echoed by others too.<br></p>
<p>The thing to note is that Okta isn't just acquiring an API or a product. Itâ€™s acquiring
$200M in recurring revenue thatâ€™s probably growing at 50%. As soon as Okta acquires its largest competitor, it can
also refactor Auth0â€™s (and itâ€™s own) pricing to increase revenue even further. So it's paying a lot upfront
for what it hopes will be even more in the future.Â&nbsp;<br></p>
<p>Now that we have some clarity on the acquisition, weâ€™ll be looking at how the (stock) market,
users and employees reacted to the news (largely drawn from Reddit, Hackernews and some personal
conversations)<br></p>
<h2><strong>Reactions (and what this means)</strong><br></h2>

<p><span>Market<br></span>Oktaâ€™s will acquire Auth0 in an all stock deal
and dilute existing shareholders by 20%. The 10% fall in the stock price (equivalent to a decrease in $3-4B)
immediately post the announcement means that investors are valuing Auth0 at half the price what Okta paid for
it.<br></p>
<p>Okta will issue shares to Auth0 shareholders at share price of $276.21, close to 20% less
than the current share price (at the time of writing).<br></p><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png" loading="lazy" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png 1830w" alt=""></p><p><strong>Users<br>â€�</strong>In general, the developer community has had an unpleasant
experience with Okta. This is perhaps expected given that it is not a â€œdeveloper firstâ€� company. Below are some
excerpts taken from Hackernews.<br></p>
<p>â€œWe moved from Okta a few years ago after we basically received almost no actual real support
for a bunch of issues, even though we were paying a premium cost. Nobody cares about issues on their Githubâ€�. â€œWe
ended up switching to Auth0â€�, â€œshaved a decent amount off our costsâ€�. â€œIn the end we were much happier.â€�<br></p>
<p>â€œOkta requires you to "contact support" to turn on basic features like email
customization, and even though I'm a paying customer, I was given a multi-week estimate (after waiting a week
or two) for how long it would take to enable this featureâ€�<br></p>
<p>â€œWe use Okta for multiple AWS accounts and they "ran a bad migration" that deleted
half our permissions and took a month to resolve. On top of that, nothing appeared in the audit logs.â€�<br></p>
<p>â€œOkta as a business are a pain to deal with, and unless you meet their minimum spend
requirements (which are not told to you up-front) you're screwed.â€�<br></p>
<p><strong>Employees<br>â€�</strong>Similarly, employees were worried about Auth0, given their
experience with Oktaâ€™s culture and hiring process.<br></p>
<p>â€œI interviewed with both, and the process at Auth0 had me walk away with respect, while
contrasted with Okta that left me reminded that tech hiring is broken.â€�<br></p>
<p>â€œThe two companies couldn't be more different, with Auth0 embracing a remote-first-class
culture with creative interview processes, and Okta (pre-covid) being very much the opposite.â€�<br></p>
<p>I used to work on the Okta team.. As far as I could tell, Okta is a sales company. The
salespeople got the fancy events, the high floors with nice views, all the budgetâ€¦ Enterprise customers are the
only ones that mattered.. I got to know some people who came into Okta via acquisitions and letâ€™s just say itâ€™s
not a fun ride.â€�<br></p>
<h2><strong>What next for Auth0?</strong><br></h2>

<p>â€¨Officially the statement is that the â€œCompany will operate as an independent unit inside of
Okta as they look for paths to integration in the coming monthsâ€�.<br></p>
<h2><strong>What is the opportunity for SuperTokens?â€¨</strong><br></h2>

<ol role="list">
<li>
<p>The incumbents in the space are Okta, Auth0, Firebase and AWS Cognito. However, they are all closed source,
proprietary companies. We have a strong belief in our open source approach as it benefits all stakeholders -
customers, the community and us as a company. There are a few others who are taking this approach and there is
a strong possibility for a project like SuperTokens to reach the scale that matches the incumbents.<br></p>
</li>
<li>
<p>Consolidation typically creates small vacuums. It is our job, as the project creators, to understand which
vacuum (niche) is the strongest.Â&nbsp;<br></p>
</li>
<li>
<div><p>We claim to be truly developer friendly. <b>But what does that really mean?</b> How do we demonstrate
that?
</p><ul>
<li>First is <b>our open source approach</b> - we place developers and the community above all else.</li>Â&nbsp;
<li>Second is the <b>modular architecture of SuperTokens</b>. This enables developers to pick features
they need
for their use
case and forget about the complexity associated with everything else (for example, if you do not need SSO,
no
need worry about OAuth flows). It allows you to add authentication functionality as your product and
company
scale.
<strong>We even have different docs based on your feature set and use case.<br>â€�</strong>
</li>
<li>Finally, our
frontend
UI is the most customizable weâ€™ve seen of any of the alternatives. While Auth0 provides a ready made
frontend
or exposes the backend APIs to build your own frontend, we provide ready made frontends and make it far
easier
to build your own theme or customize existing ones.<br></li>
</ul>
</div>
</li>
</ol>
<p>Hope this added some insight into this massive development. Weâ€™re excited about the space and
are here to serve developers everyday.<br></p>
<p>Written by the Folks at <a href="https://supertokens.io/" aria-current="page">SuperTokens</a> â€” hope you enjoyed! We are always available on our Discord server.
Join us if you have any questions or need any help.<br></p>
<p><a rel="noopener" href="https://supertokens.io/discord" target="_blank"><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Image-93x.png" loading="lazy" width="200" alt=""></a>
</p></div></div>]]>
            </description>
            <link>https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358309</guid>
            <pubDate>Fri, 05 Mar 2021 16:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating ePub from LaTeX]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26356903">thread link</a>) | @ivan_ah
<br/>
March 5, 2021 | https://minireference.com/blog/generating-epub-from-latex/ | <a href="https://web.archive.org/web/*/https://minireference.com/blog/generating-epub-from-latex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://minireference.com/blog/generating-epub-from-latex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356903</guid>
            <pubDate>Fri, 05 Mar 2021 13:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure from a Schemer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 62 (<a href="https://news.ycombinator.com/item?id=26356367">thread link</a>) | @todsacerdoti
<br/>
March 5, 2021 | https://www.more-magic.net/posts/thoughts-on-clojure.html | <a href="https://web.archive.org/web/*/https://www.more-magic.net/posts/thoughts-on-clojure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Recently I joined <a href="https://www.bevuta.com/">bevuta IT</a>, where I am now working on a big project written in <a href="https://www.clojure.org/">Clojure</a>.  I'm very fortunate to be working in a Lisp for my day job!</p>
<p>As I've mostly worked with Scheme and have used other Lisps here and there, I would like to share my perspective on the language.</p><a href="#overall-design">
<h2 id="overall-design">Overall design</h2></a>
<p>From a first view, it is pretty clear that Clojure has been designed from scratch by (mostly) one person who is experienced with Lisps and as a language designer.  It is quite clean and has <a href="https://download.clojure.org/papers/clojure-hopl-iv-final.pdf">a clear vision</a>. Most of the standard library has a very consistent API.  It's also nice that it's a <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">Lisp-1</a>, which obviously appeals to me as a Schemer.</p>
<p>My favourite aspect of the language is that everything is designed with a functional-first mindset.  This means I can program in the same functional style as I tend to do in Scheme.  Actually, it's even more functional, because for example its maps (what would be hash tables in Scheme) are much less clunky to deal with.  In Scheme, SRFI-69 hash tables are quite imperative, with <tt>hash-table-set!</tt> and <tt>hash-table-update!</tt> being the ways to insert new entries, which of course mutate the existing object.  Similarly, vectors can easily be extended (on either end!) functionally.</p>
<p>The underlying design of Clojure's data structures must be different. It needs to efficiently support functional updates; you don't want to fully copy a hash table or vector whenever you add a new entry. I am not sure how efficient everything is, because the system I'm working on isn't in production yet.  A quick look <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/PersistentArrayMap.java">at the code</a> implies that various data structures are used under the hood for what looks like one data structure in the language.  That's a lot of complexity!  I'm not sure that's a tradeoff I'd be happy to make.  It makes it harder to reason about performance.  You might just be using a completely different underlying data structure than expected, depending on which operations you've performed.</p><a href="#non-lispiness">
<h2 id="non-lispiness">(non) Lispiness</h2></a>
<p>To a seasoned Lisp or Scheme programmer, Clojure can appear positively <i>bizarre</i>.  For example, while there is a <tt>cons</tt> function, there are no cons cells, and <tt>car</tt> and <tt>cdr</tt> don't exist.  Instead, it has <tt>first</tt> and <tt>rest</tt>, which are definitely saner names for a language designed from scratch.  It has "persistent lists", which are immutable lists, but in most day to day programming you will not even be <b>using</b> lists, as weird as that sounds!</p><a href="#symbols-and-keywords">
<h3 id="symbols-and-keywords">Symbols and keywords</h3></a>
<p>One thing that really surprised me is that symbols are not interned. This means that two symbols which are constructed on the fly, or when read from the same REPL, are not identical (as in <tt>eq</tt> or <tt>eq?</tt>) to one another:</p>
<pre><tt>user&gt; <span>(<span>= 'foo 'foo</span>)</span>
true
user&gt; <span>(<span>identical? 'foo 'foo</span>)</span>
false</tt></pre>
<p>Keywords seem to fulfil most "symbolic programming" use cases.  For example, they're almost always used as "keys" in maps or when specifying options for functions.  Keywords <i>are</i> interned:</p>
<pre><tt>user&gt; <span>(<span>= <span>:foo</span> <span>:foo</span></span>)</span>
true
user&gt; <span>(<span>identical? <span>:foo</span> <span>:foo</span></span>)</span>
true</tt></pre>
<p>Code is still (mostly) expressed as lists of symbols, though.  When you're writing macros you'll deal with them a lot.  But in "regular" code you will deal more with keywords, maps and vectors than lists and symbols.</p><a href="#numeric-tower">
<h3 id="numeric-tower">Numeric tower</h3></a>
<p>A favorite gotcha of mine is that integers <a href="https://clojure.org/reference/data_structures#Numbers">are not automatically promoted to bignums</a> like in most Lisps that support bignums.  If you need bignums, you have to use special-purpose operators like <tt>+'</tt> and <tt>-'</tt>:</p>
<pre><tt>user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
Execution error <span>(<span>ArithmeticException</span>)</span> at user/eval51159 <span>(<span>REPL:263</span>)</span>.
integer overflow
user&gt; <span>(<span>*' <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
9223372036854775808N

user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2N</span>)</span> 9223372036854775808N
user&gt; <span>(<span>* 1N 1</span>)</span> 1N</tt></pre>
<p>This could lead to better performance at the cost of more headaches when dealing with the accidental large numbers in code that was not prepared for them.</p>
<p>What about rationals, you ask?  Well, those are just treated as "the unusual, slow case".  So even though they <i>do</i> normalize to regular integers when simplifying, operations on those always return BigInts:</p>
<pre><tt>user&gt; <span>(<span>+ 1/2 1/4</span>)</span>
3/4
user&gt; <span>(<span>+ 1/2 1/2</span>)</span>
1N
user&gt; <span>(<span>/ 1 2</span>)</span> 1/2
user&gt; <span>(<span>/ 4 2</span>)</span> 2</tt></pre>
<p>The sad part is, bitwise operators do not support bignums, <i>at all</i>:</p>
<pre><tt>user&gt; <span>(<span>bit-shift-right 9223372036854775808N 62</span>)</span>
Execution error <span>(<span>IllegalArgumentException</span>)</span> at user/eval51167 <span>(<span>REPL:273</span>)</span>.
bit operation not supported for: class clojure.lang.BigInt
user&gt; <span>(<span>bit-shift-right' 9223372036854775808N 62</span>)</span> Syntax error compiling at <span>(<span>*cider-repl test:localhost:46543<span>(<span>clj</span>)</span>*:276:7</span>)</span>.
Unable to resolve symbol: bit-shift-right' in this context</tt></pre>
<p>There's one benefit to all of this: if you know the types of something going into numeric operators, you will typically know the type that comes out, because there is no automatic coercion.  Like I mentioned, this may provide a performance benefit, but it also simplifies reasoning about types.  Unfortunately, this does not work as well as you would hope because division may change the type, depending on whether the result divides cleanly or not.</p><a href="#syntax">
<h3 id="syntax">Syntax</h3></a>
<p>For many Lispers, this is the elephant in the room.  Clojure certainly qualifies as a Lisp, but it is much heavier on syntax than most other Lisps.  Let's look at a small contrived example:</p>
<pre><tt><span>(<span><i><span>let</span></i> [foo-value <span>(<span>+ 1 2</span>)</span>
      bar-value <span>(<span>* 3 4</span>)</span>]
  {<span>:foo</span> foo-value
   <span>:bar</span> bar-value}</span>)</span></tt></pre>
<p>This is a <tt>let</tt> just like in Common Lisp or Scheme.  The bindings are put inside square brackets, which is literal syntax for <i>vectors</i>.  Inside this vector, key-value pairs are interleaved, like in a Common Lisp <a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/26_glo_p.htm#property_list">property list</a>.</p>
<p>The lack of extra sets of "grouping" parentheses is a bit jarring at first, but you get used to it rather quickly.  I still mess up occasionally when I accidentally get an odd number of entries in a binding vector.  Now, the <tt>{:foo foo-value :bar bar-value</tt>} syntax is a <i>map</i>, which acts like a hash table (more on that below).</p>
<p>There doesn't seem to be a good rationale about why vectors are used instead of regular lists, though.  What I <i>do</i> really like is that all the binding forms (even function signatures!) support <a href="https://clojure.org/guides/destructuring">destructuring</a>.  The syntax for destructuring maps is a bit ugly, but having it available is super convenient.</p>
<p>What I regard as a design mistake is the fact that Clojure allows for optional commas in lists and function calls.  Commas are just whitespace to the reader.  For example:</p>
<pre><tt><span>(<span>= [1, 2, 3, 4] [1 2 3 4]</span>)</span> =&gt; true
<span>(<span>= '<span>(<span>1, 2, 3, 4</span>)</span> '<span>(<span>1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= {<span>:foo</span> 1, <span>:bar</span> 2, <span>:qux</span> 3} {<span>:foo</span> 1 <span>:bar</span> 2 <span>:qux</span> 3}</span>)</span> =&gt; true
<span>(<span>= <span>(<span>foo 1, 2, 3, 4</span>)</span> <span>(<span>foo 1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= [,,,,,,1,,,2,3,4,,,,,,] [1 2 3 4]</span>)</span> =&gt; true</tt></pre>
<p>Maybe this is to make up for removing the extra grouping parentheses in <tt>let</tt>, <tt>cond</tt> and map literal syntax?  With commas you can add back some clarity about which items belong together.  Rarely anybody uses commas in real code, though.  And since it's optional it doesn't make much sense.</p>
<p>This has an annoying ripple effect on quasiquotation.  Due to this decision, a different character has to be used for <tt>unquote</tt>, because the comma was already taken:</p>
<pre><tt>`<span>(<span>1 2 ~<span>(<span>+ 1 2</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3</span>)</span>
`<span>(<span>1 2 ~@<span>(<span>list 3 4</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3 4</span>)</span></tt></pre>
<p>This might seem like a small issue, but it is an unnecessary and stupid distraction.</p><a href="#minimalism">
<h2 id="minimalism">Minimalism</h2></a>
<p>One of the main reasons I enjoy Scheme so much is its goal of minimalism.  This is achieved through elegant building blocks.  This is embodied by the <a href="https://schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-3.html#%_chap_Temp_3">Prime Clingerism</a>:</p>
<pre><tt>  Programming languages should be designed not by piling feature on
  top of feature, but by removing the weaknesses and restrictions
  that make additional features appear necessary.</tt></pre>
<p>Let's check the size of the <tt>clojure.core</tt> library.  It clocks in at 640 identifiers (v1.10.1), which is a lot more than R5RS Scheme's 218 identifiers.  It's not an entirely fair comparison as Scheme without SRFI-1 or SRFI-43 or an FFI has much less functionality as well. Therefore, I think Clojure's core library is fairly small but not exactly an exercise in minimalism.</p>
<p>Clojure reduces its API size considerably by having a "<a href="https://clojure.org/reference/sequences">sequence</a> abstraction". This is similar to Common Lisp's sequences: you can call <tt>map</tt>, <tt>filter</tt> or <tt>length</tt> on any sequence-type object: lists, vectors, strings and even maps (which are treated as key/value pairs). However, it is less hacky than in Common Lisp because for example with <tt>map</tt> you don't need to specify which kind of sequence you want to get back.  I get the impression that in Common Lisp this abstraction is not very prominent or used often but in Clojure <i>everything</i> uses sequences.  What I also liked is that sequences can be <i>lazy</i>, which removes the need for special operators as well.</p>
<p>If you compare this to Scheme, you have special-purpose procedures for every concrete type: <tt>length</tt>, <tt>vector-length</tt>, <tt>string-length</tt> etc.  And there's no <tt>vector-map</tt> in the standard, so you need <a href="https://srfi.schemers.org/srfi-43/srfi-43.html#vector-map"><tt>vector-map</tt> from SRFI 43</a>.  Lazy lists are a <a href="https://srfi.schemers.org/srfi-41/srfi-41.html">separate type</a> with its own set of specialized operators.  And so on and so forth.  Using concrete types everywhere provides for less abstract and confusing code and the performance characteristics of an algorithm tend to be clearer, but it also leads to a massive growth in library size.</p>
<p>After a while I really started noticing mistakes that make additional features appear necessary: for example, there's a special macro called <tt>loop</tt> to make tail recursive calls.  This uses a keyword <tt>recur</tt> to call back into the loop.  In Scheme, you would do that with a named <tt>let</tt> where you can choose your own identifier to recur.  It's also not possible to nest such Clojure loops, because the identifier is hardcoded.  So, this called for adding <a href="https://archive.clojure.org/design-wiki/display/design/Named%2Bloops%2Bwith%2Brecur-to.html">another feature</a>, which is currently in proposal.  Speaking of <tt>recur</tt>, it is also used for tail recursive self-calls.  It relies on the programmer rather than the compiler to mark calls as tail recursive. I find this a bit of a cop-out, especially in a language that is so heavily functional.  Especially since this doesn't work for mutually tail-recursive functions.  The <a href="https://www.windley.com/archives/2008/11/tail_optimized_mutual_recursion_in_clojure.shtml">official way to do those</a> is even more of a crutch.</p>
<p>I find the special syntax for one-off lambdas <tt>#(foo %)</tt> just as misguided as <a href="https://srfi.schemers.org/srfi-26/srfi-26.html">SRFI 26</a> (<tt>cut</tt> and <tt>cute</tt>).  You often end up needing to tweak the code in such a way that you have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.more-magic.net/posts/thoughts-on-clojure.html">https://www.more-magic.net/posts/thoughts-on-clojure.html</a></em></p>]]>
            </description>
            <link>https://www.more-magic.net/posts/thoughts-on-clojure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356367</guid>
            <pubDate>Fri, 05 Mar 2021 13:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bring Your Own Client]]>
            </title>
            <description>
<![CDATA[
Score 496 | Comments 224 (<a href="https://news.ycombinator.com/item?id=26355779">thread link</a>) | @pcr910303
<br/>
March 5, 2021 | https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just a little note about the main problem I'm pondering these days...</p><div><p>It’s delightful to have the freedom to <strong>Bring Your Own Client (BYOC)</strong>: to choose your favorite application to interact with some data.</p>

<p>For example, I can program with Sublime Text, while my teammate uses vim, and we don’t need to fight to the death to pick one editor between us. There are dozens of text editors to choose from, and no lock-in from proprietary file formats.</p>

<p>Contrast this with Google Docs: in order to live collaborate with each other, we all need to use the same editor. For someone who spends their whole working day in Google Docs, this can be a serious limitation. I personally hate doing substantial writing in Google Docs.</p>

<p>In cloud apps, the live collaboration logic is usually coupled to a specific editor; even if Google wanted to expose an API for editing Google Docs in third-party editors, it would probably be very challenging. The situation is nicer with text editors and git, because editing is decoupled from collaboration logic. Our team only needs to agree on a version control solution, which exposes a simple API (local text files) that many editors can interact with.</p>

<p>To be fair, local vs cloud isn’t the only factor here—even in local software, collaborators are often forced to converge on a single proprietary client (Microsoft Office, Adobe suite); conversely, a cloud service can support a third-party client ecosystem with the right APIs and attitude. Still, cloud apps exacerbate the problem. With local files, there’s some default openness built in; even proprietary file formats can be reverse-engineered. With cloud apps, the default is a single official client, unless the service actively exposes an API (and doesn’t shut it down—looking at you, Twitter).</p>

<p>It seems like local-first software is a good foundation for promoting Bring Your Own Client more broadly. What would it look like to have a thriving ecosystem of third-party clients for Google Docs style word processing, which can all interoperate with each other, even supporting realtime collaboration?</p>

<h2 id="concrete-examples">Concrete examples</h2>

<p>Some successful existing examples of client ecosystems built around open standards:</p>

<ul>
<li>text editors / IDE</li>
<li>RSS readers</li>
<li>email clients</li>
<li>web browsers</li>
</ul>

<p>Places where I want to have BYOC:</p>

<ul>
<li>Google Docs. I wish I could write this very doc in my preferred editor, locally, but have also support for inline comments and live collaboration. Might it be possible to build a VSCode extension that edits Google Docs live? (Tricky, because Google doesn’t have a nice API to integrate with, but maybe doable)</li>
<li>Google Slides</li>
<li>Figma</li>
<li>Notion</li>
<li>Trello / Asana / shared todo lists</li>
<li>multiplayer code editor: live collaboration as in repl.it</li>
</ul>

<h2 id="finer-granularity">Finer granularity</h2>

<p>Today we generally think about BYOC at the “app” level. But can we go finer-grained than that, picking individual interface elements?</p>

<p>Instead of needing to pick a single email client, can I compose my favorite email client out of an inbox, a compose window, and a spam filter?</p>

<h2 id="problems-questions">Problems / questions</h2>

<ul>
<li><strong>Schema compatibility</strong>: do all the editors need to agree on a single rigidly specified format? If there are reconcilable differences between formats, can we build “live converters” that convert between them on every change? (Essentially, imagine collaborating between Pages and Microsoft Word, running a file export in both directions on every keystroke from either app) This problem is closely related to the problem of schema versioning within a single editor, but BYOC can complicate things much further.</li>
<li><strong>Preserving intent</strong>: the decoupling of git + text editors has a downside: the text format fails to capture the intent of edits, so git can’t be very smart about merging conflicts. Is this something fundamental to decoupling editors from collaboration? Or are there ways to design APIs that preserve intent better, while also supporting an open client ecosystem? (It seems like deciding on how you store your data in a CRDT is the key question here?)</li>
<li><strong>Additional editor-specific metadata</strong>: Some editors need to store additional data that isn’t part of the “core data model.” Eg, Sublime Text stores my <code>.sublime-workspace</code> file alongside the code source. How does this work smoothly without polluting the data being used by other editors?</li>
<li><strong>Code distribution</strong>: Traditionally code distribution happens through centralized means, but could code be distributed in a decentralized way alongside documents? If we’re collaborating together in a doc, can I directly share a little editor widget/tool that I’m using, without needing to send you a Github link? This might be overcomplicating things / orthogonal to the general idea here… (This idea inspired by <a href="https://webstrates.net/">Webstrates</a>, linked below)</li>
<li><strong>Innovation</strong>: Unfortunately stable open formats can limit product innovation—eg, email clients are tied down by adherence to the email standard. Can we mitigate that effect? I think web browsers have struck a good balance between progress and openness, despite frustrations in both directions.</li>
</ul>

<h2 id="addendum-faq">Addendum: FAQ</h2>

<p><em>Edited 2020-03-05: This post unexpectedly got popular on HN. As I drink my morning coffee, I’ll briefly respond to a few themes from the comments here.</em></p>

<p><strong>Q: Don’t standards make it harder to innovate?</strong></p>

<p>A: Yes, that’s a major challenge. For example, email and IRC have lagged behind Slack and Reddit, because it’s hard to change standards. We discussed this problem a bit in the <a href="https://www.inkandswitch.com/cambria.html#mastodon-protocol-evolution">Cambria paper, re: Mastodon</a>.</p>

<p>I think the key is to aim for more flexible and extensible standards: a useful 80% compatibility, rather than a perfect 100%.</p>

<p>Of course, once you abandon an exact standard, it’s easy to rack up tons of complexity. (I think the Semantic Web struggled with this problem trying to provide schema flexibility.) So we also need better tools to make partial compatibility easy to reason about, for both developers and users.</p>

<p><strong>Q: Hmm. 80% compatibility sounds like kind of a buggy mess? Word and OpenOffice don’t interop very well.</strong></p>

<p>A: I think with the right foundational tech for helping devs build maximally compatible formats, we can avoid the worst problems of incorrect format conversions. In the Cambria paper we sketched <a href="https://www.inkandswitch.com/cambria.html#lenses-in-action">a few examples</a> of partial compatibility, where Cambria guaranteed type safety and helped us easily avoid bugs.</p>

<p>That does leave a substantial design problem, though: even if everything works correctly, what do you show the <em>user</em> when two pieces of software aren’t fully compatible? How do you tell a user that their actions might show up differently for collaborators using different apps? I’m thinking a lot about these questions…</p>

<p><strong>Q: Cloud business models are so entrenched. Can this actually happen without government intervention?</strong></p>

<p>A:  It’s true that business incentives are a major challenge. Maybe some form of government intervention could help, but ultimately it’ll be fighting a headwind unless users and devs are excited for the change.</p>

<p>I think the most sustainable way to make progress is to make BYOC the most convenient option, for the typical user and the typical developer. On the desktop, it’s convenient for a developer to work with the user’s existing filesystem. On the web today, there’s no user-controlled filesystem, so it’s usually easiest to just put the data in a database, and add a ticket to the backlog for someday building a public-facing API. How would that change if we had a convenient user-controlled place to put data?</p>

<p>See the <a href="https://www.inkandswitch.com/local-first.html">local-first software</a> article by Ink &amp; Switch for some ideas on how new data architectures can make the right thing the easy thing, for both users and devs.</p>

<h2 id="prior-art">Prior Art</h2>

<ul>
<li><a href="https://webstrates.net/">Webstrates</a> has some great demos of this philosophy. It uses a centralized server for the live sync.</li>
<li>Webstrates descends from Michel Beaudouin-Lafon’s work on <a href="https://youtu.be/ntaudUum06E?t=727">instrumental interfaces</a>—"polymorphic" tools that can operate in different applications. For example, a color picker that I can use in any app.</li>
<li>The <a href="https://solidproject.org/">SOLID</a> decentralized web project has some closely related ideas: <a href="https://ruben.verborgh.org/blog/2017/12/20/paradigm-shifts-for-the-decentralized-web/#apps-become-views">“apps become views”</a>, creating a competitive marketplace of clients decoupled from data silos. In turn it’s heavily inspired by ideas from the Semantic Web.</li>
<li><a href="https://mashable.com/2009/05/28/google-wave-guide/">Google Wave</a> had some related ideas… A platform for realtime collaboration, with a rich open <a href="https://youtu.be/v_UyVmITiYQ?t=4207">extension API</a> intended for people to build various collaboration clients on top of. Seems like the common wisdom on why it failed is that it was <a href="https://gizmodo.com/what-in-the-hell-was-google-wave-trying-to-be-anyway-1835038967">too complicated</a> and tried to do too much.</li>
<li><a href="https://braid.news/">Braid</a> is exploring ways to extend HTTP to support collaborative editing across diverse clients.</li>
</ul>



<ul>
<li>I believe one piece of the puzzle here is declarative schema mapping, for example the <a href="https://www.inkandswitch.com/cambria.html">Cambria</a> project I worked on recently.</li>
<li>Granular BYOC starts to look like <a href="https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html">software as curation</a>: assembling software out of smaller “extensions”</li>
<li>Also relates to document-centric computing ideas like OpenDoc. Some <a href="https://twitter.com/geoffreylitt/status/1362779218241855494">recent notes</a> I took on why that failed…</li>
<li>Part of the solution may involve extracting and synchronizing data from cloud services without going through official APIs, as demonstrated in my <a href="https://www.geoffreylitt.com/wildcard">Wildcard</a> project.</li>
</ul>

<h2 id="im-working-on-this">I’m working on this!</h2>

<p>I’m currently pursuing a PhD at MIT doing research on this topic. Lots of challenges and open questions ahead, but I have some ideas for how to make progress. I’m particularly excited about clever ways to incrementally nudge us from the status quo to a BYOC world, rather than reinventing everything.</p>

<p>If you want to follow along with future updates, you can subscribe via the links below.</p>

<p>And if you have ideas about this topic or want to chat, feel free to <a href="mailto:gklitt@gmail.com">get in touch</a>.</p>

<h2 id="ps-idea-incubation">PS: idea incubation</h2>

<p>I actually wrote this note 10 months ago and had totally forgotten about it.</p>

<p>An hour ago, I randomly came across it and was quite amused. It includes some ideas which I <em>thought</em> I had started thinking about only recently. But it turns out they’ve been incubating in my mind for a long time. Funny how that works!</p>
</div></div>]]>
            </description>
            <link>https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355779</guid>
            <pubDate>Fri, 05 Mar 2021 11:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clothing, How Did They Make It? Part I: High Fiber]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26355046">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting the first of a four (?) part look at pre-modern textile production.  As with our series on <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farming </a>and <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">iron</a>, we are going to follow the sequence of production from the growing of fibers all the way to the finished object, with a focus not merely on the methods of production but also <em>on the people doing the producing</em> at each stage of production.  Now while I have titled this series, “Clothing, How Did They Make It?” it is worth noting that textiles were used for a lot more than just clothing.  All sorts of household goods were produced this way.  In addition, of course, clothing was sometimes made out of non-textile materials (although, <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">as we’ve discussed</a>, far less often than is portrayed in popular culture; in Eurasia, by and large, clothing meant textiles).  <strong>But what we are going to focus on here is really <em>textiles</em></strong> and (of course) the people that make them.  Leather working will have to wait for another day.</p>



<p>That said, even within textiles, to try to keep the scope manageable<strong> I am going to narrow things down further, by focusing on just two major fibers: wool and flax</strong> (which makes linen) and thus <strong>mostly focus on how this worked in the Mediterranean</strong>, broadly construed (so the Near East, North Africa and Europe).  I am choosing these two fibers because they dominate in locally produced textiles in the Near East and Europe for much of the pre-modern period.  Cotton, another important fiber, only seems to have been cultivated in Egypt in the Roman period (though, as far as I can tell, at some point Egyptian cotton cultivation seems to have largely dropped off, only to boom again in the Early Modern though this is a point about which I can express little confidence in my knowledge) and for much of Europe remained an expensive import fiber through the Middle Ages, transported from South Asia.  Likewise, silk remained in the pre-modern period almost entirely an expensive import good from far to the East of the Mediterranean.  Of course any import good must be local somewhere, but my expertise in pre-modern textile production does not extend so far into South or East Asia, so the task of laying that out must fall to someone else.  We will talk a <em>bit</em> about these fibers as they arrive in the Mediterranean as trade goods, but mostly stay focused on wool and flax.</p>



<p>The very rarity of these goods in the Near East and Europe confined them to the upper-classes, while wool and linen often remained the everyday fibers (though even the very wealthy used textiles of high quality wool and linen as well) and so saw a lot more use.  More importantly to our investigation here, for the ancient Mediterranean (where my knowledge is best) wool and linen were <em>by far</em> the fibers most involved in the household textile production.  Of course other fibers were used locally in the Mediterranean as well – hemp, nettle and even tree-bast, but the vast majority of<strong> textiles being produced in the broader Mediterranean world were wool and linen and so we are going to focus on that.</strong></p>



<figure><img data-attachment-id="6453" data-permalink="https://acoup.blog/616302001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg" data-orig-size="2218,1817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="616302001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1814-0704-573">From the British Museum</a>, a fourth century bell krater depicting the Judgement of Paris (which in turn leads to the Trojan War).  Paris, at the time, was living in exile as a shepherd – the occupation notable because of its lowly status.  Here he is seen seated with his shepherd’s crook (the standing male figure is Hermes); the animal below Paris is a sheep (you can see the twisted horns; to the right is a dog, presumably assisting in the herding.</figcaption></figure>



<p>Worry not, we will have more than enough to talk about with just those two fibers.  This week, we’re going to focus just on producing the raw fibers – how flax is farmed and how wool is produced from sheep.  Next week, we’ll look at the long process of taking those raw fibers, processing them and spinning them into thread.  The week after that, we’ll look at weaving as well as dying, bleaching and other color treatments treatments.  Then finally in the last week, we’ll look at finally sewing but also at markets and trade. <strong> As always, we’ll try to direct attention not only to the processes, but also to the workers who <em>performed</em> those processes and their place in the broader society.</strong></p>



<p>And that brings us to the second reason to discuss textile production, which is that in the broader pre-modern Mediterranean <strong>much of the textile production</strong> <strong>was done within the household and nearly all of that household production was done by women</strong>.  Now as we’ll see, household spinning, weaving and sewing is by no means the only jobs involved in the production of the clothes that say an Egyptian, Babylonian, Roman or early Medieval European family would wear and some important stages of production here were also generally done by men.  As I have mentioned before, the literary sources for the pre-modern world generally prefer to talk about individuals who are rich, male, and free, but as we will see, the workers involved in each stage of textile production are almost never rich, frequently not male and sometimes not free.  Nevertheless investigating textile production gives us a chance to peer into parts of the lives of some historical subjects that we very rarely hear about: women (rich and poor, slave and free), along with enslaved or poor men doing work that left them well outside of the ‘polite society’ of our literary sources.</p>



<p>I should note at the beginning that while I am going to try to keep this discussion general and at points cover technological or regional variations in how textiles in wool and linen were made, in practice a lot of what I am going to write here is going to reflect in particular practice during the Roman period (especially the period of the Republic) and even more specifically than that in Roman Italy, simply because that is where my own specialist knowledge is best.  Consult your friendly neighborhood primary sources when looking to apply these systems on a wider basis either geographically or chronologically!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(<strong>Bibliography Note:</strong> For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I’m going to include a short selected bibliography here up front for the whole series.  For the beginner looking to get their feet under themselves when it comes to pre-modern textile production, E.W. Barber, <em>Women’s Work: The First 20,000 Years, Women, Cloth and Society in Early Times</em> (1994) is the standard starting point.  Also note E.W. Barber, <em>Prehistoric Textiles: The Development of Cloth in the Neolithic and Bronze Ages with Special Reference to the Aegean</em> (1991).  More specific to the Romans, M. Gleba, <em>Textile Production in Pre-Roman Italy</em> (2008) is an indispensable book which gathers together a lot of the quite technical investigation – often done by archaeologists rather than historians because the literary record on textile production can be quite disappointing – in a fairly easy to read location.  Several of the essays in M. Gleba and J. Pásztókai-Szeöke <em>Making Textiles in Pre-Roman Times and Roman Times: People, Places, Identities</em> (2013), while more technical in nature, were also useful here, especially on the question of who did this sort of thing.  Also on this point, L. L. Lovén, <em>The Imagery of Textile Making: Gender and Status in the Funerary Iconography of Textile Manufacture in Roman Italy and Gaul</em> (2002).  On textile production for soldiers, note in the Greek context G.S. Aldrete, S. Bartel and A. Aldrete, <em>Reconstructing Ancient Linen Body Armor: Unraveling the Linothorax Mystery</em>(2013) which also has some very useful time-labor study data; for Roman soldiers note the essays in M.L. Nosch ed., <em>Wearing the Cloak: Dressing the Soldier in Roman Times</em> (2012) and G. Sumner, <em>Roman Military Dress </em>(2009).  On the cloth trade in medieval Europe, I’ve relied heavily on J.S. Lee, <em>The Medieval Clothier</em> (2018).</p>



<p>If it sounds like pre-modern textile production is one of those fields that is only now, somewhat belatedly receiving the attention it has long deserved, that is by and large correct!  As you can see, compared to the discussion of farming or iron-working, the key references here are often decades younger (one is left to assume that it is something to do with the fact that this work was largely done by women that led to it being so late to receive its due study).  Fortunately, archaeology is giving us a lot of the evidence that our literary sources don’t, especially for the ancient world, which has enabled a lot of this work.  May it continue!)</p>



<h2>Meet the Fibers! Flax and Linen</h2>



<p>Linen fabrics are produced from the fibers of the flax plant, <em>Linum usitatissimum</em>.  This common flax plant is the domesticated version of the wild <em>Linum bienne</em>, domesticated in the northern part of the fertile crescent no later than 7,000 BC, although wild flax fibers were being used to produce textiles even earlier than that. Consequently the use of linen fibers goes <em><strong>way </strong></em>back. In fact, the oldest known textiles are made from flax, including finds of fibers at Nahal Hemar (7th millennium BC), Çayönü (c. 7000 BC), and Çatalhöyük (c. 6000 BC). Evidence for the cultivation of flax goes back even further, with linseed from Tell Asward in Syria dating to the 8th millennium BC. Flax was being cultivated in Central Europe no later than the second half of the 7th millennium BC.</p>



<figure><img data-attachment-id="6451" data-permalink="https://acoup.blog/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg" data-orig-size="439,591" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" src="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg 439w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=111 111w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223 223w" sizes="(max-width: 439px) 100vw, 439px"><figcaption><a href="https://en.wikipedia.org/wiki/Flax">Via Wikipedia</a>, the flax plant, showing the seeds and – more importantly for our purpose – the stalk which, when fully grown contains the bast fibers used to make linen.</figcaption></figure>



<p>Flax is a productive little plant that produces two main …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355046</guid>
            <pubDate>Fri, 05 Mar 2021 10:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stability of Fixed Points of High Dimensional Dynamical Systems]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26352308">thread link</a>) | @adipandas
<br/>
March 4, 2021 | https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/ | <a href="https://web.archive.org/web/*/https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p> 5 minute read</p><p><strong> Published:</strong> <time datetime="2021-03-04T00:00:00-08:00">March 04, 2021</time></p></header><section itemprop="text"><p>In the <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a>, I discussed the basics regarding the stability of fixed points of a dynamical system and explained it with a simple continuous-time one-dimensional example. In this post, I will discuss fixed points for a general case of a continuous-time $n$-dimensional system.</p><h4 id="fixed-point">Fixed point</h4><p>Just to reiterate, if the ordinary differential equation (ODE) in $\eqref{eq:1}$ represents a dynamical system:</p>\[\dot x = f(x) \label{eq:1}\]<p>Fixed points of this system are given by the roots of the equation $\eqref{eq:2}$:</p>\[\begin{equation} \dot x = f(x) = 0 \label{eq:2} \end{equation}\]<h2 id="fixed-points-of-multi-dimensional-system">Fixed points of Multi-dimensional system</h2><p>My <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a> only explained the definition of fixed point and provided an example with a scalar-valued dynamical system. Now, lets discuss a case of multi-dimensional ODE.</p><p>We will start with the system given by equation $\eqref{eq:3}$:</p>\[\mathbf{\dot x} = \mathbf{f(x)} \label{eq:3}\]<p>where $\mathbf{f}$ is a vector-valued function, $\mathbf{x}$ and $\mathbf{\dot x}$ are $n$-dimensional vectors:</p>\[\mathbf{x, \dot x} \in \mathcal{R}^{n} \label{eq:4}\]<p>We find the fixed points (a.k.a. equilibrium states) of the system by following $\eqref{eq:2}$:</p>\[\mathbf{\dot x_{eq}} = \mathbf{f}(\mathbf{x_{eq}}) = \mathbf{0} \label{eq:5}\]<p>The roots of $\eqref{eq:5}$ will give us the value of $\mathbf{x_{eq}}$, i.e., fixed points of our multi-dimensional system.</p><h2 id="stable-and-unstable-fixed-points">Stable and Unstable Fixed Points</h2><p>We analyzed the system in a one-dimensional case (<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">here</a>) using a small perturbation $\delta$ at the equilibrium condition of the system. We will follow the similar procedure here as well.</p><p>We evaluated $\mathbf{f}^{\prime}\mathbf{(x)}$ at $\mathbf{x_{eq}}$ to see if our fixed point is stable or unstable. In case of one-dimensional system, it was easy since $f^{\prime}(x_{eq})&gt;0$ is unstable fixed point $x_{eq}$ while it is stable when $f^{\prime}(x_{eq})&lt;0$. In case of high-dimensional system, we cannot do this.</p><p>To analyze the behavior of our $n$-dimensional system at $\mathbf{x_{eq}}$, we will introduce the perturbation $\mathbf{\delta x}$ at $\mathbf{x_{eq}}$. Thus, we end up with the following:</p>\[\begin{align} \mathbf{\dot x_{eq} + \dot {\delta x}} &amp;= \mathbf{f(x_{eq}+\delta x)} \label{eq:6} \end{align}\]<p>Using Taylor expansion on $\eqref{eq:6}$:</p>\[\begin{align} \mathbf{\dot x_{eq} + \delta \dot x = f(x_{eq}) + f^{\prime}(x_{eq}) \delta x + f^{\prime \prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \label{eq:7} \end{align}\]<p>But, we know at fixed points, equation $\eqref{eq:5}$ holds and thus, $\eqref{eq:7}$ reduces to $\eqref{eq:8}$.</p>\[\begin{align} \mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + f^{\prime\prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \end{align}\] \[\mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + H.O.T. \label{eq:8}}\]<p>We can ignore the higher order terms $\mathbf{H.O.T.}$ for values of $\mathbf{\delta{x}}$ close to $\mathbf{0}$, resulting in equation $\eqref{eq:9}$.</p>\[\begin{align} \mathbf{\delta \dot x = f^{\prime}(x_{eq}) \delta x \label{eq:9}} \end{align}\]<p>$\mathbf{f}^{\prime}\mathbf{(x)}$ is the Jacobian of $\mathbf{f(x)}$ at $\mathbf{x_{eq}}$, i.e., a <strong>linear approximation</strong> of our dynamical system $\mathbf{f(x)}$ near $\mathbf{x_{eq}}$ (you can refer <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/#jacobian-aka-derivative-of-vector-valued-function">this</a> for further details on Jacobian).</p>\[\begin{align} \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \left[ \frac{\partial\mathbf{f}}{\partial x_{1}}, \frac{\partial\mathbf{f}}{\partial x_{2}}, \dots, \frac{\partial\mathbf{f}}{\partial x_{n}} \right] \label{eq:11}\\ \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \begin{bmatrix} \frac{\partial{f_{1}}}{\partial x_{1}} &amp; \frac{\partial{f_{2}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ \frac{\partial{f_{n}}}{\partial x_{1}} &amp; \frac{\partial{f_{n}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \end{bmatrix} \label{eq:12} \end{align}\]<p>Using this Jacobian, equation $\eqref{eq:12}$, at our fixed point $\mathbf{x_{eq}}$ for the dynamical system under consideration, we can calculate its <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"><strong>eigenvalues</strong></a> and interpret the results of the fixed point.</p><p>Therefore, we find the eigenvalues for equation $\eqref{eq:13}$,</p>\[\begin{align} \mathbf{f}^{\prime}(\mathbf{x_{eq}}) \mathbf{x_{eq}} = \lambda \mathbf{x_{eq}} \label{eq:13} \end{align}\]<p>Here, $\lambda$ denotes the eigenvalue of the system. The roots of $\eqref{eq:13}$ are the eigenvalues the dynamical system at the fixed point $\mathbf{x}=\mathbf{x_{eq}}$.</p><h3 id="eigenvalue-interpretation-">Eigenvalue interpretation <a name="eigen_value_interpretation"></a></h3><p>For a continuous-time nonlinear dynamical system given by $\eqref{eq:3}$, the eigenvalues $\lambda$ that are found as roots of equation $\eqref{eq:13}$ can be interpreted as:</p><ul><li>If any of the eigenvalues have a real part $Re(\lambda)&gt;0$: $\mathbf{x_{eq}}$ is an unstable fixed point.</li><li>If all $Re(\lambda)&lt;0$: $\mathbf{x_{eq}}$ is a stable fixed point.</li><li>If $\lambda=0$: $\mathbf{x_{eq}}$ is a neutral fixed point.</li><li>If eigenvalues $\lambda$ are complex conjugates, i.e., $Im(\lambda) \ne 0$: The dynamical system has oscillatory behavior around the fixed point.</li></ul><h3 id="important-points-to-note-regarding-this-article">Important points to note regarding this article</h3><p>In this post, we discussed a general case of interpreting the fixed points of a dynamical system. By general, I mean $\mathbf{f(x)}$ is a non-linear, continuous-time vector-valued function representing a dynamical system. Below are certain points one should note about any non-linear dynamical system:</p><ul><li>We assumed that the system is non-linear and linearized it using Taylor series expansion near its fixed point (a.k.a. equilibrium).</li><li>We evaluated the stability of a fixed point <strong>near</strong> the equilibrium condition by perturbing the system ($\mathbf{x_{eq}}+\mathbf{\delta x}$).</li><li>This approach of interpreting the stability of the system by linearizing it near the equilibrium <strong>does not tell much</strong> about a system’s asymptotic behavior at large.<ul><li>We only understand how the system behaves <strong>locally</strong> or <strong>in the neighborhood of the fixed points</strong>.</li></ul></li><li>In practical or real-world systems, it may not be possible to interpret the global stability characteristics of the system. Thus, the stability analysis around the neighborhood of the fixed point is useful for many practical applications such as sustaining a non-linear system’s state near or at the fixed point.</li><li>In general, global asymptotic behaviors of any non-linear dynamical system can be complex and there are no systematic methods to predict and analyze such behaviors.</li></ul><h3 id="references-and-further-readings">References and Further Readings:</h3><ul><li>Deshpande, A. M. Stablility of Fixed Point of a Dynamical System. [<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">web</a>]</li><li>Strogatz, Steven H. Nonlinear dynamics and chaos with student solutions manual: With applications to physics, biology, chemistry, and engineering. CRC press, 2018.</li><li>Khalil, Hassan K. “Lyapunov stability.” <em>Control Systems, Robotics and AutomatioN–Volume XII: Nonlinear, Distributed, and Time Delay Systems-I</em> (2009): 115.</li><li>Bomze, Immanuel M., and Jörgen W. Weibull. “Does neutral stability imply Lyapunov stability?.” <em>Games and Economic Behavior</em> 11.2 (1995): 173-192.</li><li>Fixed point. [<a href="https://mathworld.wolfram.com/FixedPoint.html">web</a>]</li><li>Jacobian matrix [<a href="https://www.youtube.com/watch?v=bohL918kXQk">video</a>]</li><li>Stability Theory. [<a href="https://en.wikipedia.org/wiki/Stability_theory">web</a>]</li><li>Lyapunov Stability. [<a href="https://en.wikipedia.org/wiki/Lyapunov_stability">web</a>]</li></ul></section><!--<nav class="pagination"> <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/" class="pagination--pager" title="Notes on Vector Calculus ">Previous</a> <a href="https://adipandas.github.io/posts/2021/03/biasvariancetradeoff/" class="pagination--pager" title="Bias, Variance and Trade-off ">Next</a></nav>--></div></div>]]>
            </description>
            <link>https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352308</guid>
            <pubDate>Fri, 05 Mar 2021 03:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compensation as a Reflection of Values]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 91 (<a href="https://news.ycombinator.com/item?id=26348836">thread link</a>) | @timf
<br/>
March 4, 2021 | https://oxide.computer/blog/compensation-as-a-reflection-of-values/ | <a href="https://web.archive.org/web/*/https://oxide.computer/blog/compensation-as-a-reflection-of-values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Compensation: the word alone is enough to trigger a fight-or-flight reaction in many. But we in technology have the good fortune of being in a well-compensated domain, so why does this issue induce such anxiety when our basic needs are clearly covered? If it needs to be said, it's because compensation isn't merely about the currency we redeem in exchange for our labors, but rather it is a proxy for how we are <em>valued</em> in a larger organization. This, in turn, brings us to our largest possible questions for ourselves, around things like meaning and self-worth.</p><p>So when we started Oxide -- as in any new endeavor -- compensation was an issue we had to deal with directly. First, there was the thorny issue of how we founders would compensate ourselves. Then, of course, came the team we wished to hire: hybrid local and remote, largely experienced to start (on account of <a href="https://www.youtube.com/watch?v=vvZA9n3e5pc">Oxide's outrageously ambitious mission</a>), and coming from a diverse set of backgrounds and experiences. How would we pay people in different geographies? How could we responsibly recruit experienced folks, many of whom have families and other financial obligations that can't be addressed with stock options? How could we avoid bringing people's compensation history -- often a reflection of race, gender, class, and other factors rather than capability -- with them?</p><p>We decided to do something outlandishly simple: take the salary that Steve, Jess, and I were going to pay ourselves, and pay that to everyone. The three of us live in the San Francisco Bay Area, and Steve and I each have three kids; we knew that the dollar figure that would allow us to live without financial distress -- which we put at $175,000 a year -- would be at least universally adequate for the team we wanted to build. And we mean everyone literally: as of this writing we have 23 employees, and that's what we all make.</p><p>Now, because compensation is the hottest of all hot buttons, it can be fairly expected that many people will have a reaction to this. Assuming you've made it to this sentence it means you are not already lighting us up in your local comments section (thank you!), and I want to promise in return that we know some likely objections, and we'll address those. But before we do, we want to talk about the benefits of transparent uniform compensation, because they are, in a word, profound.</p><p>Broadly, our compensation model embodies our <a href="https://oxide.computer/about/">mission, principles, and values</a>. First and foremost, we believe that our compensation model reflects our principles of <b>honesty</b>, <b>integrity</b>, and <b>decency</b>. To flip it around: sadly, we have seen extant comp structures in the industry become breeding grounds for dishonesty, deceit, and indecency. Beyond our principles, our comp model is a tangible expression of several of our values in particular:</p><ul><li><p>It has set the tone with respect to <b>teamwork</b>. In my experience, the need to "quantify" one's performance in exchange for justifying changes to individual compensation are at the root of much of what's wrong in the tech industry. Instead of incentivizing people to achieve together as a team, they are incentivized to advance themselves -- usually with sophisticated-sounding jargon like OKRs or MBOs, or perhaps reasonable-sounding (but ultimately misguided) mantras like "measure everything." Even at their very best, these individual incentives represent a drag on a team, as their infrequent calibration can prevent a team from a necessary change in its direction. And at worst, they leave individuals perversely incentivized and operating in direct opposition to the team's best interest. When comp is taken out of the picture, everyone can just focus on what we need to focus on: getting this outlandish thing built, and loving and serving the customers who are taking a chance on it.</p></li><li><p>It is an expression of our <b>empathy</b>. Our approach to compensation reflects our belief in treating other people the way that we ourselves want to be treated. There are several different dimensions for this, but one is particularly visceral: because we have not talked about this publicly, candidates who have applied to Oxide have done so assuming that we have a traditional comp model, and have braced themselves for the combat of a salary negotiation. But we have spoken about it relatively upfront with candidates (before they talk to the team, for example), and (as the one who has often had this discussion) the relief is often palpable. As one recent candidate phrased it to me: "if I had known about this earlier, I wouldn't have wasted time stressing out about it!"</p></li><li><p>It is (obviously?) proof-positive of our <b>transparency</b>. Transparency is essential for building <i>trust</i>, itself one of the most important elements of doing something bold together. One of the interesting pieces of advice we got early on from someone who has had outsized, repeated success: modulo private personnel meetings, make sure that every meeting is open to everyone. For those accustomed to more opaque environments, our level of transparency can be refreshing: for example, new Oxide employees have been pleasantly surprised that we always go through our board decks with everyone -- but we can't imagine doing it any other way. Transparent compensation takes this to an unusual (but not unprecedented) extreme, and we have found it to underscore how seriously we take transparency in general.</p></li><li><p>It has allowed whole new levels of <b>candor</b>. When everyone can talk about their salary, other things become easier to discuss directly. This candor is in all directions; without comp to worry about, we can all be candid with respect to our own struggles -- which in turn allows us to address them directly. And we can be candid too when giving public positive feedback; we don't need to be afraid that by calling attention to someone's progress, someone else will feel shorted.</p></li></ul><p>These are (some of!) the overwhelming positives; what about those objections?</p><ul><li><p>Some will say that this salary is too low. While cash compensation gets exaggerated all of the time, it's unquestionable that salaries in our privileged domain have gotten much higher than our $175,000 (and indeed, many at Oxide have taken a cut in pay to work here). But it's also true that $175,000 per year puts us each in the top 5% of US individual earners -- and it certainly puts a roof over our families' heads and food in their bellies. Put more viscerally: this is enough to not fret when your kids toss the organic raspberries into the shopping cart -- or when they devour them before you've managed to get the grocery bags out of the car! And speaking of those families: nothing is more anxiety-producing than having a healthcare issue compounded by financial distress due to inadequate insurance; Oxide not only offers the best healthcare plans we could find, but we also pay 100% of monthly premiums -- a significant benefit for those with dependents.</p></li><li><p>Some will say that we should be paying people differently based on different geographical locations. I know there are thoughtful people who pay folks differently based on their zip code, but (respectfully), we disagree with this approach. Companies spin this by explaining they are merely paying people based on their cost of living, but this is absurd: do we increase someone's salary when their spouse loses their job or when their kid goes to college? Do we slash it when they inherit money from their deceased parent or move in with someone? The answer to all of these is no, of course not: we pay people based on their work, not their costs. The truth is that companies pay people less in other geographies for a simple reason: because they can. We at Oxide just don't agree with this; we pay people the same regardless of where they pick up their mail.</p></li><li><p>Some will say that this doesn't scale. This is, at some level, surely correct: it's hard to envision a multi-thousand employee Oxide where everyone makes the same salary -- but it has also been (rightly) said that startups should do things that don't scale. And while it seems true that the uniformity won't necessarily scale, we believe that the values behind it very much will!</p></li><li><p>Some will say that this makes us unlikely to hire folks just starting out in their career. There is truth to this too, but the nature of our problem at Oxide (namely, technically very broad and very deep), the size of our team (very small), and the stage of our company (still pretty early!) already means that engineers at the earliest stages of their career are unlikely to be a fit for us right now. That said, we don't think this is impossible; and if we felt that we had someone much earlier in their career who was a fit -- that is, if we saw them contributing to the company as much as anyone else -- why wouldn't we reflect that by paying them the same as everyone else?</p></li><li><p>Some will say that this narrows the kind of roles that we can hire for. In particular, different roles can have very different comp models (sales often has a significant commission component in exchange for a lower base, for example). There is truth to this too -- but for the moment we're going to put this in the "but-this-can't-scale" bucket.</p></li><li><p>Some will say that this doesn't offer a career ladder. Uniform compensation causes us to ask some deeper questions: namely, what <em>is</em> a career ladder, anyway? To me, the true objective for all of us should be to always be taking on new challenges -- to be unafraid to learn and develop. I have found traditional ladders to not serve these ends particularly well, because they focus us on competition rather than collaboration. By eliminating the rung of compensation, we can put the focus on career development where it belongs: on supporting one another in our self-improvement, and working together to do things that are beyond any one of us.</p></li><li><p>Some will say that we should be talking about equity, not cash compensation. While it's true that startup equity is important, it's also true that startup equity doesn't pay the orthodontist's bill or get the basement …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oxide.computer/blog/compensation-as-a-reflection-of-values/">https://oxide.computer/blog/compensation-as-a-reflection-of-values/</a></em></p>]]>
            </description>
            <link>https://oxide.computer/blog/compensation-as-a-reflection-of-values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26348836</guid>
            <pubDate>Thu, 04 Mar 2021 21:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-engineering Rosetta 2 Part 1: Analyzing AoT files and the runtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26346980">thread link</a>) | @my123
<br/>
March 4, 2021 | https://ffri.github.io/ProjectChampollion/part1/ | <a href="https://web.archive.org/web/*/https://ffri.github.io/ProjectChampollion/part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
              
            
            
              
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/FFRI/ProjectChampollion/edit/master/docs/part1.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                
<p>date: 2021/2/19</p>
<p>author: Koh M. Nakagawa</p>
<h2 id="introduction">Introduction</h2>
<p>Apple announced that it would be moving from Intel processors to Arm-based Apple Silicon CPUs for Macs at WWDC 2020.
The Apple Silicon-based Mac Book Air and Pro were released in October 2020 with great fanfare.</p>
<p>One of the issues that arise with the CPU transition is application compatibility.
Since Apple Silicon is an Arm-based processor, applications built for Intel-based Macs will no longer work.
To solve this problem, Apple offers the following two technologies:</p>
<ul>
<li>Universal Binary 2</li>
<li>Rosetta 2</li>
</ul>
<p>Universal Binary 2 is a mechanism to encapsulate binaries built for multiple architectures into a single binary, which is also called Fat Binary.
Apple has been using this technology for a long time to maintain backward compatibility.
A Mach-O loader selects the binary with the best architecture for the machine it is running on, then loads only that binary into memory to run the program.
Most macOS Big Sur system binaries are currently Fat Binaries, containing binaries built for both Arm and Intel architectures.</p>
<p>Rosetta 2 is a technology that translates Intel-based binaries or JIT-generated code into Arm-based binaries or code.
It is the successor to Rosetta, which was also used in the past processor transition.
There is not much information officially released by Apple.
Of course, there is no source code available, unlike the XNU kernel.
Also, at the time of writing this article, there seems to be no article that examines it in detail.</p>
<p>In this article, I introduce some reverse engineering results of Rosetta 2.</p>
<p>Why I take a closer look at Rosetta 2?</p>
<p>The reason is that I'm interested in translated binaries in Rosetta 2 and examining the possibility of exploiting them.
I presented <a href="https://www.blackhat.com/eu-20/briefings/schedule/index.html#jack-in-the-cache-a-new-code-injection-technique-through-modifying-x-to-arm-translation-cache-21324">a new code injection technique in Windows 10 on Arm at Black Hat EU</a> last December.
The code injection is achieved by modifying x86 to Arm (XTA) binary translation cache files.
This research encourages me to examine whether similar code injection techniques can be achieved with Rosetta 2.</p>
<p>In this part, I will cover the following points:</p>
<ul>
<li>The executables associated with Rosetta 2 and their roles</li>
<li>Analysis results of the translated binaries</li>
<li>JIT binary translation capabilities of Rosetta 2 (mainly focusing on x86_64 machine code decoding process)</li>
</ul>
<p>In the following, I will follow Apple's terminology when referring to architecture.</p>
<ul>
<li>arm64: The architecture specified when generating binaries to run on an Apple Silicon Mac</li>
<li>x86_64: The architecture specified when generating binaries to run on an Intel-based Mac</li>
</ul>
<h2 id="setting-up-the-analysis-environment">Setting up the analysis environment</h2>
<p>First, I show you how to set up the analysis environment.</p>
<p>Rosetta 2 is not installed by default on an Apple Silicon Mac.
So, you need to install it following the pop-up that appears when you run an x86_64 code for the first time.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/macos-big-sur-software-update-rosetta-alert.jpg">
    <figcaption>Figure 1 Rosetta 2 installation popup (https://support.apple.com/en-us/HT211861).</figcaption>
</figure>

<p>After the installation, a folder named <code>/Library/Apple/usr/libexec/oah/</code> (hereinafter referred to as the oah folder) is created, and you can see the following binaries installed.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/rosetta_binaries.png">
    <figcaption>Figure 2 Binaries installed after Rosetta 2 installation.</figcaption>
</figure>

<p>The role of each binary will be explained later.</p>
<p>The next step is to disable System Integrity Protection (SIP).
This is because the folder that contains the translated binaries is protected by SIP and cannot be accessed by default even with administrative privileges.</p>
<p>Please follow the steps below to disable SIP.</p>
<ul>
<li>Restart the OS</li>
<li>Press and hold Touch ID to boot in the recovery mode</li>
<li>Select Terminal from "Utilities" at the top of the screen</li>
<li>Type <code>csrutil disable</code> and execute</li>
<li>Restart the OS again</li>
</ul>
<p>In addition to this, please install Xcode and Command Line Tools for Xcode to use Clang and LLDB.</p>
<h2 id="roles-of-oahd-and-oahd-helper">Roles of <code>oahd</code> and <code>oahd-helper</code></h2>
<p>First, let's create a command line application built for x86_64 and monitor system events (e.g., process creation, file-system activities, and memory mapping) when the x86_64 application runs.</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    puts("Hello World");
    return 0;
}
$ clang -arch x86_64 hello.c -o hello.out # specify x86_64 as the target architecture
$ file hello.out
hello.out: Mach-O 64-bit executable x86_64
</code></pre>
<p>To obtain several system events, I used EventMonitor created using the <a href="https://developer.apple.com/documentation/endpointsecurity">Endpoint Security Framework</a>.
I will release EventMonitor as an OSS soon.</p>
<p>Start EventMonitor and run <code>hello.out</code>.
The following jsonl file contains logs obtained by EventMonitor. The only events related to Rosetta 2 are extracted.</p>
<p><a href="https://ffri.github.io/ProjectChampollion/assets/event.jsonl">event.jsonl</a></p>
<p>When you look at the first line of the logs, you can see an event where <code>/bin/zsh</code> executes <code>hello.out</code>.</p>
<pre><code>{"event":{"log":{"args":[".\/hello.out"],"cwd":{"path":"\/Users\/konakagawa.ffri","path_truncated":false},"last_fd":4,"target":{"executable_path":"\/Users\/konakagawa.ffri\/hello.out","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}},"type":"exec"},"target_process":{"executable_path":"\/bin\/zsh","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}}
</code></pre>
<p>After the exec system call, <code>oahd</code> daemon checks for the file <code>/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0/hello.out.aot</code>.</p>
<pre><code>... (the oahd checks for the AOT file)
{"event":{"log":{"relative_target":"var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot","source_dir":{"path":"\/","path_truncated":false}},"type":"lookup"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
</code></pre>
<p>The file with the extension <code>.aot</code> contains the result of the translation from x86_64 to arm64.
We refer to this file as the AOT file.
The name <code>.aot</code> comes from Ahead-Of-Time, which means that the translation is performed before a thread actually starts.
The <code>oahd</code> is the management daemon for the AOT files.</p>
<p>Since this is the first time we run <code>hello.out</code>, the <code>oahd</code> cannot find the corresponding AOT file. So, it creates a new AOT file.
If the same binary in the same path has already been executed and the AOT file has been created, the <code>oahd</code> uses it.</p>
<p>You can see the folder named <code>/var/db/oah</code> in the above logs.
This folder has a <code>Oah.version</code> file at the top, which is supposed to contain the version information for Rosetta 2.
Also, this folder has <code>16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00</code> folder.
We can see that multiple folders are containing AOT files in it.
The names of these folders are SHA-256 hash values that are calculated from both the contents of the file in x86_64 code and the path where it was executed.</p>
<pre><code># /var/db/oah contains the Oah.version file and 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00 folder
$ ls -l /var/db/oah
total 8
drwxr-xr-x  6528 _oahd  _oahd  208896  2 13 22:22 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00
-rw-------     1 _oahd  _oahd      32  1 27 14:44 Oah.version
# show some AOT files
$ ls -l /var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/* | head -n 10
/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00088a4116103832383ae2866e61d745d3d0013c5073ed032dabf6a785611db9:
total 40
-rwxr-xr-x  1 _oahd  _oahd  17656  1 27 14:45 FlashlightModule.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/0008a5059fda4b8aee7110b04a3e65f175a80ea55a64129a7660c7d3ed77a9d5:
total 56
-rwxr-xr-x  1 _oahd  _oahd  25928  1 27 14:47 libswiftAccelerate.dylib.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00091f4ca51a770fa7a398f4320efe920fa8c3fc611247dcf55ca025f22301d4:
total 600
-rwxr-xr-x  1 _oahd  _oahd  304536  1 27 14:45 AirPlayRoutePrediction.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/000a1ab017d7e24b25cd58739ae01120b8a6d3a9cff37235156dced0123f2c3c:
total 24
-rwxr-xr-x  1 _oahd  _oahd  12280  1 27 14:46 NanoNewsComplications.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/001dac33f82e558695268fb4a4285f47e9806766e7398e377d9dff59235399f5:
total 1192
-rwxr-xr-x  1 _oahd  _oahd  606347  1 27 14:46 TSCoreSOS.aot
</code></pre>
<p>Note that the folders and files under <code>/var/db/oah</code> are protected by SIP, so we cannot access even with admin privileges.
After disabling SIP, we can access these folders and files with admin privileges.</p>
<p>Now, back to the analysis of the logs.
<code>oahd</code> checks for the AOT file, and if not found, it runs <code>oahd-helper</code> to create a new AOT file.</p>
<pre><code>... (oahd creates hello.out.aot.in_progress file)
{"event":{"log":{"dest_path":{"path":"\/private\/var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot.in_progress","path_truncated":false},"dest_type":0,"filename":null},"type":"create"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
... (creates a child process)
{"event":{"log":{"child":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":54133,"ppid":426,"session_id":426}},"type":"fork"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}</code></pre></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ffri.github.io/ProjectChampollion/part1/">https://ffri.github.io/ProjectChampollion/part1/</a></em></p>]]>
            </description>
            <link>https://ffri.github.io/ProjectChampollion/part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26346980</guid>
            <pubDate>Thu, 04 Mar 2021 19:27:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Female Founder Secrets: Fertility]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 715 (<a href="https://news.ycombinator.com/item?id=26345226">thread link</a>) | @femfosec
<br/>
March 4, 2021 | https://femfosec.com/fertility/ | <a href="https://web.archive.org/web/*/https://femfosec.com/fertility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Because of our biological clocks, women need to consider the timing of children a lot more urgently than men.</p><p>Startups take much longer than you’d think before they become successful. You should have a 5-10 year horizon, at least.</p><p>And the period between when you start the startup and when you can relax a little is grueling and all-consuming. The focus that’s required at first will probably force you to cut back on almost everything in your life, making a healthy work/life balance nearly impossible.</p><p>Startups are also unpredictable. In the early stages, you can’t plan too far in the future and arrange your life neatly around your plans, as you might with a job as an employee in the corporate world.</p><p>So you are working around the clock—so busy that you can’t focus on much outside of work, not knowing what startup disaster is around the corner, and maybe with no end in sight for years. But you know you want a family someday, either with your current partner or someone you haven’t even had the time to meet yet.</p><p>Because startups can cause you to neglect much of your own life, women founders need to be really proactive about their fertility. Especially if you want to buy more time before the window shuts on your childbearing years.</p><p>My advice: Freeze your eggs/embryos.</p><p>I wish I had. Life with my company whizzed by and it wasn’t until my late 30s when I had a child. After a year, I started working on baby #2. Three miscarriages later, I finally woke up to the urgency of the situation and went to a fertility doctor.</p><p>The next few years were consumed by IVF cycles. My obsession to have another baby grew with each failed cycle. I’d be on an emotional roller coaster waiting for the various results, praying that this time was the magical one. It never was. My eggs were just too old, I think. After 8 rounds with not one viable embryo to transfer, I decided I had to move on, to focus on my kid and all the really great things in my life. But the what-ifs still haunt me, privately.</p><p>Aspects of getting your eggs retrieved and/or frozen can be really awful. It’s extremely expensive if not covered by your medical insurance. The drugs can wreak havoc on moods and emotions. Between all the doctor’s appointments and the various shots (which cause serious bruising) you have to give yourself several times each day, it’s quite time consuming. &nbsp;And it’s stressful. At least it was for me. The stakes feel so high.</p><p>But nothing is as awful as it not working out. It’s a type of depressing that’s difficult to describe concisely.</p><p>It might seem weird or somehow frivolous to freeze your eggs—and especially to freeze embryos if you’re already married. (Though it’s becoming more mainstream as companies offer egg freezing as an employee benefit.) But freezing is worth it simply because it gives you more options as you get older.</p><p>Until they go through it themselves, few people realize how hard Mother Nature can be in the fertility department. The older you are, the tougher the blows. So if you want a biological child, the best thing you can do is prepare. You don’t want to be like me and wake up one day and it’s too late.</p>
			</section></div>]]>
            </description>
            <link>https://femfosec.com/fertility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26345226</guid>
            <pubDate>Thu, 04 Mar 2021 17:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Shipping Data Products Fast]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26341032">thread link</a>) | @oedmarap
<br/>
March 4, 2021 | https://shopify.engineering/shipping-data-products-fast | <a href="https://web.archive.org/web/*/https://shopify.engineering/shipping-data-products-fast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Shipping a new product is hard. Doing so under tight time constraints is even harder. It’s no different for data-centric products. Whether it’s a forecast, a classification tool, or a dashboard, you may find yourself in a situation where you need to ship a new data product in a seemingly impossible timeline.&nbsp;</p>
<p>Shopify’s Data Science team has certainly found itself in this situation more than a few times over the years. Our team focuses on creating data products that support our merchants’ entrepreneurial journeys, from their initial interaction with Shopify, to their first sale, and throughout their growth journey on the platform. Commerce is a fast changing industry, which means we have to build and ship fast to ensure we’re providing our merchants with the best tools to help them succeed.</p>
<p>Along the way, our team learned a few key lessons for shipping data products quickly, while maintaining focus and getting things done efficiently—<em>but also done right.</em> Below are four tips that are proven to help you ship new products fast.&nbsp;</p>

<p>Investing time in a design sprint pays off down the line as you approach deadlines. The design sprint (created by <a href="https://www.gv.com/sprint/" target="_blank" title="Google Ventures" rel="nofollow noopener noreferrer">Google Ventures</a>) is “a process for answering critical business questions through design, prototyping and testing ideas with customers.” Sprints are great for getting a new data product off the ground quickly because they carve out specific time blocks and resources for you and your team to work on a problem. The Shopify Data Science teams make sprints a common practice, especially when we’re under a tight deadline. When setting up new sprints, here are the steps we like to take:</p>
<ol>
<li>
<strong><em>Choose an impactful problem to tackle. </em></strong>We focus on solving problems for our merchants, but in order to do that, we first have to uncover what those problems are by asking questions. <em>What</em> is the problem we’re trying to solve? <em>Why </em>are we solving this problem? Asking questions empowers you to find a problem worth tackling, identify the right technical solution and ultimately drive impact.</li>
<li>
<strong><em>Assemble a small sprint team</em></strong>: Critical to the success of any sprint is assembling a small team (no more than 6 or 7) of highly motivated individuals. Why a small team? It’s easier to stay aligned in a smaller group due to better communication and transparency, which means it’s easier to move fast.</li>
<li>
<strong><em>Choose a sprint Champion:</em></strong> This individual should be responsible for driving the direction of the project and making decisions when needed (should we use solution A or B?). Assigning a Champion helps remove ambiguity and allow the rest of the team to focus their energy on solving the problem in front of them.</li>
<li>
<strong><em>Set your sprint dates:</em></strong> Timeboxing is one of the main reasons why sprints are so effective. By setting fixed dates, you're committing your team to focus on shipping on a precise timeline. Typically, a sprint lasts up to five days. However, the timeline can be shortened based on the size of the project (for example, three days is likely enough time for creating the first version of a dashboard that follows the impact of COVID-19 on the business’s acquisition funnel).</li>
</ol>
<p>With your problem identified, your team set up, and your dates blocked off, it’s now time to sprint. Keep in mind while exploring solutions that solving a data-centric problem with a non-data focused approach can sometimes be simple and time efficient. For instance, asking a user for its preferred location rather than inferring it using a complex heuristic.</p>

<p>Speed is critical! The first iterations of a brand new product often go through many changes. Prototypes allow for quick and cheap learning cycles. They also help prevent the sunk cost fallacy (when a past investment becomes a rationale for continuing).&nbsp;</p>
<p>In the data world, a good rule of thumb is to leverage spreadsheets for building a prototype. Spreadsheets are a versatile tool that help accelerate build times, yet are often underutilized by data scientists and engineers. By design, spreadsheets allow the user to make sense of data in messy contexts, with just a few clicks. The built-in functions cover most basic use cases:&nbsp;</p>
<ul>
<li>cleaning data by hand rapidly</li>
<li>displaying graphs</li>
<li>computing basic ranking indices</li>
<li>formatting output data.</li>
</ul>
<p>While creating a robust system is desirable, it often comes at the expense of longer building times. When releasing a brand new data product under a tight timeline, the focus should be on developing prototypes fast.&nbsp;</p>
<figure><img alt="A sample Google Sheet dashboard evaluating Inbound Leads.  The dashboard consists of 6 charts.  The 3 line charts on the left measure Lead Count, Qualification Rate %, and Time to Qualification in Minutes.  The 3 bar charts on the right  measure Leads by Channel, Leads by Country, and Leads by Last Source Touched." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455" src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455">
<figcaption>An example of a dashboard prototype created within Google Sheets.</figcaption>
</figure>
<p>Despite a strong emphasis on speed, a prototype should still look and feel professional. For example, the first iteration of the <a href="https://www.shopify.my/blog/marketing-attribution" target="_blank" title="Marketing Attribution: Seeing the Customer Journey More Clearly" rel="noopener noreferrer">Marketing attribution tool</a> developed for Shopify’s Revenue team was a collection of SQL queries automated by a bash script. The output was then formatted in a spreadsheet. This allowed us to quickly make changes to the prototype and compare it to out-of-the-box tools. We avoided any wasted effort spinning up dashboards, production code, as well as any sentimental attachment to the work, which made it easier for the best solution to win.</p>

<p>When building a new data product, it’s tempting to spend lots of time on a flashy machine learning algorithm. This is especially true if the product is supposed to be “smart”. Building a machine learning model for your first iteration can cost a lot of time. For example, when sprinting to build a lead scoring system for our Sales Representatives, our team spent 80% of the sprint gathering features and training a model. This left little time to integrate the product with the existing <a href="https://en.wikipedia.org/wiki/Customer_relationship_management" target="_blank" title="Customer Relationship Management on Wikipedia" rel="nofollow noopener noreferrer">customer relationship management</a> (CRM) infrastructure, polish it, and ask for feedback. A simple ranking using a proxy metric would be much faster to implement for the first iteration. The time gained would allow for more conversations with the users about the impact, use and engagement with the tool.&nbsp;</p>
<p>We took that lesson to heart in our next project when we built a sales forecasting tool. We started with a linear regression using only two input variables that allowed us to have a prototype ready in a couple of hours. Using a simple model allowed us to ship fast and quickly learn whether it solved our user’s problem. Knowing we were on the right track, we then built a more complex model using machine learning.</p>
<p>Focus on building models that solve problems and can be shipped quickly. Once you’ve proven that your product is effective and delivers impact, then you can focus your time and resources on building more complex models.&nbsp;</p>

<p>Shipping fast also means shipping the right product. In order to stay on track, gathering feedback from users is invaluable! It allows you to build the right solution for the problem you’re tackling. Take the time to talk to your users, before, during, and after each build iteration. Shadowing them, or even doing the task yourself is a great return on investment.</p>
<p>Gathering feedback is an art. Entire books and research papers are dedicated to it. Here are the two tips we use at Shopify that increased the value of feedback we’ve received:</p>
<ul>
<li>
<em>Ask specific questions.</em> Asking, “Do you have any feedback?” doesn’t help the user direct their thoughts. Questions like, “How do you feel about the speed at which the dashboard loads?” or “Are you able to locate the insights you need on this dashboard to report on top of funnel performance?” are more targeted and will yield richer feedback.</li>
</ul>
<ul>
<li>
<em>Select a diverse group of users for feedback</em>. Let’s suppose that you are building a dashboard that’s going to be used by three regional teams. It’s more effective to send a request for feedback to one person in each team rather than five people in a single team.</li>
</ul>
<figure><img alt="A sample Google Form that measures Prototype A's Scoring.  The form consists of 2 questions. The first question is &quot;Is the score easy to parse and interpret? It is scored using a ranking from 1 - 5 with 1 = Very Hard and 5 = Very Easy. The 2nd question is &quot;Additional Comments&quot; and has a text field for the answer." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664" src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664">
<figcaption>Feedback our team asked for the scoring system we created. When asking for feedback, you want to ask specific questions so you can yield better feedback.</figcaption>
</figure>
<p>We implemented the two tips when requesting feedback from users of the sales forecasting tool highlighted in the previous section. We asked a diverse group specific questions about our product, and learned that displaying a numerical score (0 - 100) was confusing. The difference between scores wasn’t clear to the users. Instead, it was suggested to display grades (A, B, C) which turned out to be much quicker to interpret and led to a better user experience.</p>
<p>At Shopify, following these tips has provided the team with a clearer path for launching brand new data products under tight time constraints. More importantly, it helped us avoid common pitfalls like getting stuck during neverending design phases, overengineering complex machine learning systems, or building data products that users don’t use.&nbsp;</p>
<p>Next time you’re under a tight timeline to ship a new data product, remember to:</p>
<ol>
<li>
<strong><em>Utilize design sprints</em></strong> to help focus your team’s efforts and remove the stress of the ticking clock</li>
<li>
<strong><em>Don’t skip on prototyping,</em></strong> it’s a great way to fail early</li>
<li>
<strong><em>Avoid machine learning</em></strong> (for first iterations) to avoid being slowed down by unnecessary complexity</li>
<li>
<strong><em>Talk to your users</em></strong> so you can get a better sense of what problem they’re facing and what they need in a product</li>
</ol>
<p>If you’d like to read more about shipping new products fast, we recommend checking out <a href="https://www.thesprintbook.com/" target="_blank" title="Sprint (How to Solve Big Problems and Test New Ideas in Just Five Days)" rel="nofollow noopener noreferrer">The Design Sprint</a> book, by Jake Knapp et al. which provides a complete framework for testing new ideas.</p>
<hr>
<p>If you’re interested in helping us ship great data products, quickly, we’re looking for talented data scientists to <a href="https://www.shopify.com/careers/teams/data?itcat=EngBlog&amp;itterm=Post&amp;shpxid=73b80879-3076-43E8-7604-FE14CE1EBEED" target="_blank">join our team</a>.</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/shipping-data-products-fast</link>
            <guid isPermaLink="false">hacker-news-small-sites-26341032</guid>
            <pubDate>Thu, 04 Mar 2021 11:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t blindly prefer emplace_back to push_back]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 140 (<a href="https://news.ycombinator.com/item?id=26339893">thread link</a>) | @todsacerdoti
<br/>
March 4, 2021 | https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In one of my recent training courses, a student informed me that both clang-tidy
and PVS-Studio were complaining about some code of the form</p>

<div><div><pre><code>std::vector&lt;Widget&gt; widgets;
~~~
widgets.push_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>Both tools flagged this line as “bad style.”
clang-tidy even offered a (SARCASM ALERT) helpful fixit:</p>

<div><div><pre><code>warning: use emplace_back instead of push_back [modernize-use-emplace]
    widgets.push_back(Widget(foo, bar, baz));
            ^~~~~~~~~~~~~~~~~             ~
            emplace_back(
</code></pre></div></div>

<p>The student dutifully changed the line, and both tools reported their
satisfaction with the replacement:</p>

<div><div><pre><code>widgets.emplace_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>The original line materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::push_back(Widget&amp;&amp;)</code>, which move-constructs a <code>Widget</code>
into the vector. Then we destroy the temporary.</p>

<p>The student’s replacement materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::emplace_back&lt;Widget&gt;(Widget&amp;&amp;)</code>, which move-constructs
a <code>Widget</code> into the vector. Then we destroy the temporary.</p>

<p><em>Absolutely no difference.</em></p>

<p>The change clang-tidy meant to suggest — and in fact <em>did</em> suggest,
if you pay very close attention to the underlining in the fixit — was actually this:</p>

<div><div><pre><code>widgets.emplace_back(foo, bar, baz);
</code></pre></div></div>

<p>This version does <em>not</em> materialize any <code>Widget</code> temporaries. It simply
passes <code>foo, bar, baz</code> to <code>vector&lt;Widget&gt;::emplace_back&lt;Foo&amp;, Bar&amp;, Baz&amp;&gt;(Foo&amp;, Bar&amp;, Baz&amp;)</code>,
which constructs a <code>Widget</code> into the vector using whatever
constructor of <code>Widget</code> best matches that bunch of arguments.</p>

<h2 id="emplace_back-is-not-magic-c11-pixie-dust"><code>emplace_back</code> is not magic C++11 pixie dust</h2>

<p>Even a decade after C++11 was released, I still sometimes see programmers assume
that <code>emplace_back</code> is somehow related to move semantics. (In the same way that
some programmers assume lambdas are somehow the same thing as <code>std::function</code>,
you know?) For example, they’ll rightly observe that this code makes an
unnecessary copy:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.push_back(w);  // Copy-constructor alert!
}
</code></pre></div></div>

<p>So they’ll change it to this:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.emplace_back(w);  // Fixed? Nope!
}
</code></pre></div></div>

<p>The original line constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::push_back(const Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p>The replacement constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::emplace_back&lt;Widget&amp;&gt;(Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p><em>Absolutely no difference.</em></p>

<p>What the student should have done is ask the compiler to make an
<em>rvalue</em> reference to <code>w</code>, by saying either</p>

<div><div><pre><code>widgets.push_back(std::move(w));
</code></pre></div></div>

<p>or</p>

<div><div><pre><code>widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>It doesn’t matter which verb you use; what matters is the value category of
<code>w</code>. You must explicitly mention <code>std::move</code>, so that the language (and the
human reader) understand that you’re done using <code>w</code> and it’s okay for
<code>widgets</code> to pilfer its guts.</p>

<p><code>emplace_back</code> was added to the language at the same time as <code>std::move</code> — just
like lambdas were added at the same time as <code>std::function</code> — but that doesn’t
make them the same thing. <code>emplace_back</code> may “look more C++11-ish,” but it’s
not magic move-enabling pixie dust and it will never insert a move in a place
you don’t explicitly request one.</p>

<h2 id="when-all-else-is-equal-prefer-push_back-to-emplace_back">When all else is equal, prefer <code>push_back</code> to <code>emplace_back</code></h2>

<p>So, given that these two lines do the same thing and are equally efficient
at runtime, which should I prefer, stylistically?</p>

<div><div><pre><code>widgets.push_back(std::move(w));
widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>I recommend sticking with <code>push_back</code> for day-to-day use. You should definitely
use <code>emplace_back</code> when you need its particular set of skills — for example, <code>emplace_back</code>
is your only option when dealing with a <code>deque&lt;mutex&gt;</code> or other non-movable type —
but <code>push_back</code> is the appropriate default.</p>

<p>One reason is that <code>emplace_back</code> is more work for the compiler.
<code>push_back</code> is an overload set of two non-template member functions.
<code>emplace_back</code> is a single variadic template.</p>

<div><div><pre><code>void push_back(const Widget&amp;);
void push_back(Widget&amp;&amp;);

template&lt;class... Ts&gt;
reference emplace_back(Ts&amp;&amp;...);
</code></pre></div></div>

<p>When you call <code>push_back</code>, the compiler must do overload resolution, but that’s all.
When you call <code>emplace_back</code>, the compiler must do template type deduction, followed
by (easy-peasy) overload resolution, followed by function template instantiation and
code generation. That’s a much larger amount of work for the compiler.</p>

<h2 id="the-benchmark-program">The benchmark program</h2>

<p>I wrote a simple test program to demonstrate the difference in compiler workload.
Of course <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> applies:
my benchmark displays a massive difference because it’s doing <em>nothing but</em>
instantiating <code>emplace_back</code>, whereas any production codebase will be doing vastly
more other stuff relative to the number of times it instantiates <code>emplace_back</code>.
Still, I hope this benchmark gives you a sense of why I recommend “<code>push_back</code> over
<code>emplace_back</code>” and not vice versa.</p>

<p>This Python 3 script generates the benchmark:</p>

<div><div><pre><code>import sys
print('#include &lt;vector&gt;')
print('#include &lt;string&gt;')
print('extern std::vector&lt;std::string&gt; v;')
for i in range(1000):
    print('void test%d() {' % i)
    print('    v.%s_back("%s");' % (sys.argv[1], 'A' * i))
    print('}')
</code></pre></div></div>

<p>Generate like this:</p>

<div><div><pre><code>python generate.py push &gt;push.cpp
python generate.py emplace &gt;emplace.cpp
time g++ -c push.cpp
time g++ -c emplace.cpp
</code></pre></div></div>

<p>With Clang trunk on my laptop, I get consistently about 1.0s for the <code>push</code> version,
and 4.2s for the <code>emplace</code> version. This big difference is due to the fact that the
<code>push</code> version is merely code-generating a thousand <code>test</code> functions, whereas
the <code>emplace</code> version is code-generating that same thousand <code>test</code> functions <em>and</em>
another thousand template instantiations of <code>emplace_back</code> with different parameter
types:</p>

<div><div><pre><code>vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[1]&gt;(const char (&amp;)[1])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[2]&gt;(const char (&amp;)[2])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[3]&gt;(const char (&amp;)[3])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[4]&gt;(const char (&amp;)[4])
~~~
</code></pre></div></div>

<p>See, <code>push_back</code> knows that it expects a <code>string&amp;&amp;</code>, and so it knows to call the
non-explicit constructor <code>string(const char *)</code> on the caller’s side. The same
constructor is called in each case, and the temporary <code>string</code> is passed to
the same overload of <code>push_back</code> in each case. <code>emplace_back</code>, on the other hand,
is a dumb perfect-forwarding template: it doesn’t know that the relevant constructor
overload will end up being <code>string(const char *)</code> in each case. So it takes
an lvalue reference to the specific <em>array type</em> being passed by the caller.
Perfect-forwarding has no special cases for <code>const char *</code>!</p>

<p>If we change <code>vector&lt;string&gt;</code> to <code>vector&lt;const char *&gt;</code>, the compile-time-performance
gap widens: now it’s 0.7s for <code>push</code>, 3.8s for <code>emplace</code>. This is because we’ve cut
out some of the work that was common to both versions (constructing <code>std::string</code> objects)
without affecting the source of the gap (that one version instantiates a
thousand copies of <code>emplace_back</code> and the other doesn’t). Amdahl’s Law in action!</p>

<p>My conclusions:</p>

<blockquote>
  <p>Use <code>push_back</code> by default.</p>
</blockquote>

<blockquote>
  <p>Use <code>emplace_back</code> where it is semantically significant to your algorithm
(such as when the element type’s move-constructor is absent or has been
benchmarked as expensive).</p>
</blockquote>

<blockquote>
  <p>Avoid mixing string literals and perfect-forwarding templates,
especially in repetitive machine-generated code.</p>
</blockquote>

<hr>

<p>Previously on this blog:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2018/06/26/cost-of-static-lifetime-constructors/">“The surprisingly high cost of static-lifetime constructors”</a> (2018-06-26)</li>
</ul>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26339893</guid>
            <pubDate>Thu, 04 Mar 2021 08:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitsquatting Windows.com]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 71 (<a href="https://news.ycombinator.com/item?id=26338244">thread link</a>) | @vikrum
<br/>
March 3, 2021 | https://remyhax.xyz/posts/bitsquatting-windows/ | <a href="https://web.archive.org/web/*/https://remyhax.xyz/posts/bitsquatting-windows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://remyhax.xyz/image/dns.jpg"></figure><p>Earlier this month, I came back around to seriously considering an attempt at <a href="http://dinaburg.org/bitsquatting.html">bitsquatting</a>. While the prior link goes into great depth on the topic, I will attempt to give a <em>very</em> high level overview here:</p><p>If this sort of thing interests you: I tend to do stuff like this weekly. Give me a follow <a href="https://twitter.com/_mattata">@_mattata</a></p><p>When you try to access a site by it’s domain, that domain is stored in the memory of your computer, device, whatever… in a structure that looks something like this.</p><table><thead><tr><th>01110111</th><th>01101001</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td>i</td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Now let’s say that the computer is running too hot, a solar flare is happening, or a cosmic ray (very real thing) flips a bit on the computer.</p><table><thead><tr><th>01110111</th><th>01101000</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td><strong>h</strong></td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Oh no! Now the value stored in memory is w<strong>h</strong>ndows.com instead of windows.com! When the time comes to make a connection to that domain, what happens?</p><blockquote><p>nslookup whndows.com</p></blockquote><blockquote><p>*** can’t find whndows.com: Non-existent domain</p></blockquote><p>The domain doesn’t resolve to an IP!</p><hr><p>In fact, out of the 32 valid domain names that are 1-bitflip away from windows.com 14 were available for purchase! This is a rather odd occurance as usually these are bought up by a company like Microsoft to prevent their use for phishing attempts. So I bought them. All of them. For ~$126.</p><p>(<em>If you’re a verifiably responsible party, I’m more than happy to transfer ownership of the domains. Otherwise, I’ll just hold on to them and continue to sinkhole.</em>)</p><blockquote><p>windnws.com
windo7s.com
windkws.com
windmws.com
winlows.com
windgws.com
wildows.com
wintows.com
wijdows.com
wiodows.com
wifdows.com
whndows.com
wkndows.com
wmndows.com</p></blockquote><p>Now we need to point these domains somewhere. So I rent a VPS and configure IPv4/IPv6, and create wildcard DNS entries to point to them.</p><p>Wildcard DNS works so that if I create a record saying that whndows.com points to 123.123.123.123 and someone requests abs.xyz.whndows.com, they will still get the same 123.123.123.123 DNS record as a reply. Due to the nature of this research dealing with bits being flipped, this allows me to capture any DNS lookup for a subdomain of windows.com where multiple bits have flipped.</p><p>Once we have DNS configured, we use <a href="https://www.wireshark.org/docs/man-pages/tshark.html">tshark</a> to perform a packet capture on the public interface of our VPS and wait for something interesting to happen.</p><p>Below is a short snippet of some interesting things that can be shared without uniquely indentifying any users.</p><p>Usage of <strong><a href="https://greynoise.io/tech">GreyNoise.io</a></strong> was key in helping to differentiate between opportunistic scanning and actual bitflip scenarios. Great product!</p><h2 id="ntp-udp-port-123-timewindowscom">NTP UDP port 123 time.windows.com</h2><p>UDP packets destined for port 123 attempting to set their computer clock using the Network Time Protocol (NTP).
time.windows.com is the default NTP server configured for all Windows machines and they check for the time regularly. If they don’t succeed in getting the time, they try again, and again, and again.</p><p>In total, over the course of 14 days, my server recieved <strong>199,180 NTP Client connections from 626 unique IP addresses.</strong></p><p>The NTP client for windows OS has no inherent verification of authenticity, so there is nothing stopping a malicious person from telling all these computers that it’s after <a href="https://en.wikipedia.org/wiki/Year_2038_problem">03:14:07 on Tuesday, 19 January 2038</a> and wreaking unknown havoc as the memory storing the signed 32-bit integer for time overflows.</p><p>As it turns out though, for ~30% of these computers doing that would make little to no difference at all to those users because their clock is already <em>broken</em>.</p><p>Using the tshark filter “ntp.xmt” we can extract the Transmit Timestamp, which is the time that the computer thinks it is when it asks to update the time.</p><blockquote><p>tshark -r capture.pcap -T fields -e ntp.xmt -2 -R ntp.xmt | sort -u</p></blockquote><pre><code>Sep 28, 1984 19:41:12.638290998 EDT
Sep 28, 2012 11:59:42.976403314 EDT
Sep 28, 2029 21:50:47.552079831 EDT
Sep 28, 2100 18:13:09.180229791 EST
Sep 29, 1975 08:36:52.200231052 EDT
Sep 29, 1980 23:44:14.142299217 EDT
Sep 29, 2036 11:54:11.410350275 EDT
Sep 29, 2038 06:18:34.082394858 EDT
Sep 29, 2046 16:00:00.102963544 EST
Sep 29, 2050 06:39:18.880921186 EST
Sep 29, 2074 07:31:58.701524704 EST
Sep 30, 1999 00:29:32.120677896 EDT
Sep 30, 2009 02:54:33.318870579 EDT
Sep 30, 2049 00:14:59.396552253 EST
Sep 30, 2075 13:56:14.492526678 EST
Sep 30, 2081 01:56:58.477295064 EST
</code></pre><h2 id="http-tcp-port-80-sg2pwswindowscom">HTTP TCP port 80 sg2p.w.s.windows.com</h2><p>No active DNS record exists for the correct domain sg2p.w.s.windows.com</p><p>However, the User-Agent and timing of requests suggest that this activity is directly linked to the same application that generated the traffic shown below for client.wns.windows.com and skydrive.wns.windows.com</p><pre><code>GET / HTTP/1.1
Host: sg2p.w.s.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-clientwnswindowscom">HTTP TCP port 80 client.wns.windows.com</h2><p>These appear to be directly related to <a href="https://docs.microsoft.com/en-us/windows/uwp/design/shell/tiles-and-notifications/windows-push-notification-services--wns--overview">Windows Push Notification Services (WNS)</a> enable third-party developers to send toast, tile, badge, and raw updates from their own cloud service. DNS record is a CNAME to wns.notify.trafficmanager.net</p><p>DNS Records:</p><pre><code>client.wns.windows.com.        IN    CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN    A       52.177.166.224
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: client.wns.wkndows.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-skydrivewnswindowscom">HTTP TCP port 80 skydrive.wns.windows.com</h2><p>Skydrive is what <a href="https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage">OneDrive</a> was called before it’s name change.</p><p>DNS Records:</p><pre><code>skydrive.wns.windows.com.      IN      CNAME   client.wns.windows.com.
client.wns.windows.com.        IN      CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN      A       52.179.224.121
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: skydrive.wns.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-timewindowscom">HTTP TCP port 80 time.windows.com</h2><p>I have no idea where the hell this request came from or why they were fetching HTTP on a server that should be an NTP server. WHOIS for the IP that made this request shown below:</p><pre><code>inetnum:        123.112.0.0 - 123.127.255.255
netname:        UNICOM-BJ
descr:          China Unicom Beijing province network
descr:          China Unicom
country:        CN
admin-c:        CH1302-AP
tech-c:         SY21-AP
mnt-by:         APNIC-HM
mnt-lower:      MAINT-CNCGROUP-BJ
mnt-routes:     MAINT-CNCGROUP-RR
mnt-irt:        IRT-CU-CN

GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><p><strong>Even stranger, shortly after the above request occurred, this happened!</strong> Baidu is one of China’s largest search engines. Keep in mind that I configured my DNS servers to resolve in wildcard mode. There is only a small number of ways Baiduspider could know that time.wiodows.com existed. Especially considering that only a single request had ever been made for this domain previously (seen above).</p><pre><code>GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><h2 id="http-tcp-port-80-windowscomstopcode">HTTP tcp port 80 windows.com/stopcode</h2><p>When you get a blue screen of death on Windows, you are prompted to visit <a href="https://www.windows.com/stopcode">https://www.windows.com/stopcode</a>
Naturally, as the computer has crashed, they can’t just open the link. Most people would probably just scan the QR code, but those who misspell things ended up here.
<img src="https://remyhax.xyz/bitsquatting/bsod.png" alt="stopcode)"></p><pre><code>GET /stopcode HTTP/1.1
Host: wildows.com
Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 5.0.1; ALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.111 Mobile Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9
</code></pre><p>The following request was particularly interesting. Due to the nature of the request, I’m going to be very general with some details or censor entirely because it’s not exactly clear what’s going on.</p><p>An IP from somewhere in the range 113.96.0.0 - 113.111.255.255 (CHINANET-GD) makes a request from an android phone.</p><pre><code>GET /topode HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 7.1.2; M6 Note Build/N2G47H; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/77.0.3865.120 MQQBrowser/6.2 TBS/045223 Mobile Safari/537.36 MMWEBID/9551 MicroMessenger/7.0.14.1660(0x27000E37) Process/tools NetType/4G Language/zh_CN ABI/arm64 WeChat/arm64 wechatdevtools
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US
Host: wintows.com
Via: 1.1 TENCENT64.site (squid/3.5.20)
X-Forwarded-For: &lt;Department of Defence IP&gt;
Cache-Control: max-age=259200
Connection: keep-alive
</code></pre><p>It would appear the some user in China is using <a href="http://www.squid-cache.org/">squid</a> to inject HTTP headers in every request originating in their network, including their mobile phone. Their computer gets a BSOD, so they try to look up the stopcode at windows.com/stopcode on their phone. They mis-type the url and end up at my server where we can see that they’re injecting an HTTP header for <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For">X-Forwarded-For</a> that attempts to make the request appear as if it originated from an IP belonging to the US Department of Defense.</p><p>When I looked up the source IP on <a href="https://greynoise.io/">GreyNoise</a> it showed that “This IP address has been opportunistically scanning the Internet, and has completed a full TCP connection. Reported activity could not be spoofed. This IP address has been observed by GreyNoise scanning the Internet on the following ports: 443 / TCP”</p><p>Seeing as how my traffic was recieved on 80 / TCP, this seems like it may be something they did not intend to do.</p><h2 id="http-tcp-port-80-windowscomfbclid">HTTP TCP port 80 …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://remyhax.xyz/posts/bitsquatting-windows/">https://remyhax.xyz/posts/bitsquatting-windows/</a></em></p>]]>
            </description>
            <link>https://remyhax.xyz/posts/bitsquatting-windows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26338244</guid>
            <pubDate>Thu, 04 Mar 2021 03:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Can Happen to You]]>
            </title>
            <description>
<![CDATA[
Score 1650 | Comments 401 (<a href="https://news.ycombinator.com/item?id=26337046">thread link</a>) | @mooreds
<br/>
March 3, 2021 | https://www.mattkeeter.com/blog/2021-03-01-happen/ | <a href="https://web.archive.org/web/*/https://www.mattkeeter.com/blog/2021-03-01-happen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->



<h2>It Can Happen to You</h2>
<p>A few days ago, a <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">fascinating article</a>
about Grand Theft Auto Online
made the rounds of the tech news ecosystem.</p>
<p>I'd encourage you to read the whole thing, but in short,
GTA Online had <a href="https://accidentallyquadratic.tumblr.com/">accidentally quadratic</a>
performance when parsing a large JSON blob
(due to repeated calls to <code>strlen</code>);
fixing this improved loading time by almost 70%.</p>
<p>This sparked a <a href="https://news.ycombinator.com/item?id=26296339">great deal</a> of discussion:
Was this C's fault?
Perhaps <a href="https://twitter.com/Jonathan_Blow/status/1366452792563359744">"web shit"</a>?
<a href="https://twitter.com/fasterthanlime/status/1366187333507293184">Capitalism and incentives</a>?</p>
<p>Still, folks in the comments section generally agreed:
<em>they</em> wouldn't write anything that silly.</p>
<p>(<em>do you feel the foreshadowing?</em>)</p>
<hr>
<p>One of my side projects is a high-performance 3D viewer named <a href="https://www.mattkeeter.com/projects/erizo">Erizo</a>.</p>
<p><img src="https://www.mattkeeter.com/blog/2021-03-01-happen/porsche.png" alt="Porsche"></p>
<p>Thanks to a lot of careful programming, it will open a 97 MB binary STL
file in about 165 milliseconds flat, on a <em>2013</em> Macbook Pro.
This is <strong>blinding</strong> fast.</p>
<p>In the interest of compatibility, I wrote a small parser for
<a href="https://en.wikipedia.org/wiki/STL_(file_format)#ASCII_STL">ASCII STLs</a> as well.</p>
<p>ASCII STLs are a poorly-specified plain-text format that looks like this:</p>
<pre><code>solid cube_corner
          facet normal 0.0 -1.0 0.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 1.0 0.0 0.0
              vertex 0.0 0.0 1.0
            endloop
          endfacet
          facet normal 0.0 0.0 -1.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 0.0 1.0 0.0
              vertex 1.0 0.0 0.0
            endloop
          endfacet
          ...
endsolid
</code></pre>
<p>I wrote an extremely <a href="https://en.wikipedia.org/wiki/Robustness_principle">robust</a>
parser, described in a comment as</p>
<pre><code>/*  The most liberal ASCII STL parser:  Ignore everything except
 *  the word 'vertex', then read three floats after each one. */
</code></pre>
<p>Loading ASCII STLs always seemed a little slow, but I assumed
that's what you get for using an inefficient textual format.</p>
<p>(<em>foreshadowing intensifies</em>)</p>
<hr>
<p>Over the course of a few days, several things happened:</p>
<ul>
<li>I revisited Erizo for the first time in a few years to fix a <a href="https://github.com/mkeeter/erizo/commit/d4683f94a4aa0b674bdde0fa53fb6f92d6e1979c">focus issue on macOS</a></li>
<li>The GTA Online article was published</li>
<li>In a follow-up discussion, I learned that
<a href="https://news.ycombinator.com/item?id=26302744">parsing could be quadratic due to repeated calls to <code>sscanf</code></a></li>
<li>I noticed that ASCII STL loading was <em>really quite</em> slow.</li>
</ul>
<p>Here's the timestamped logs (in seconds), loading a 1.5 MB ASCII STL:</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.162895) window.c:91    | Created window
[erizo] (0.162900) window.c:95    | Made context current
[erizo] (0.168715) window.c:103   | Initialized GLEW
[erizo] (0.178329) window.c:91    | Created window
[erizo] (0.178333) window.c:95    | Made context current
[erizo] (1.818734) loader.c:109   | Parsed ASCII STL
[erizo] (1.819471) loader.c:227   | Workers have deduplicated vertices
[erizo] (1.819480) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (1.819530) loader.c:240   | Waiting for buffer...
[erizo] (1.819624) loader.c:326   | Allocated buffer
[erizo] (1.819691) loader.c:253   | Sent buffers to worker threads
[erizo] (1.819883) loader.c:258   | Joined worker threads
[erizo] (1.819887) loader.c:279   | Loader thread done
[erizo] (1.821291) instance.c:32  | Showed window
</code></pre>
<p>From startup to showing the window, it took over 1.8 seconds!</p>
<p>Looking at the ASCII parser with fresh eyes, the cause was glaringly obvious:</p>
<pre><code>    /*  The most liberal ASCII STL parser:  Ignore everything except
     *  the word 'vertex', then read three floats after each one. */
    const char VERTEX_STR[] = "vertex ";
    while (1) {
        data = strstr(data, VERTEX_STR);
        if (!data) {
            break;
        }

        /* Skip to the first character after 'vertex' */
        data += strlen(VERTEX_STR);

        for (unsigned i=0; i &lt; 3; ++i) {
            SKIP_WHILE(isspace);
            float f;
            const int r = sscanf(data, "%f", &amp;f);
            ABORT_IF(r == 0 || r == EOF, "Failed to parse float");
            if (buf_size == buf_count) {
                buf_size *= 2;
                buffer = (float*)realloc(buffer, buf_size * sizeof(float));
            }
            buffer[buf_count++] = f;

            SKIP_WHILE(!isspace);
        }
    }
</code></pre>
<p>You may notice <code>sscanf</code>, happily sitting there, reading a single float off
the front of the data stream and <strong>checking the length of the whole string each time</strong>.</p>
<p>Yes, I had made the exact same mistake as the programmers working on GTA Online:
I had an accidentally quadratic parser!</p>
<p>Replacing the <code>sscanf</code> call with <code>strtof</code> improved startup by nearly a factor of
10: from 1.8 seconds to 199 milliseconds.</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.178082) window.c:91    | Created window
[erizo] (0.178086) window.c:95    | Made context current
[erizo] (0.184226) window.c:103   | Initialized GLEW
[erizo] (0.194469) window.c:91    | Created window
[erizo] (0.194472) window.c:95    | Made context current
[erizo] (0.196126) loader.c:109   | Parsed ASCII STL
[erizo] (0.196866) loader.c:227   | Workers have deduplicated vertices
[erizo] (0.196871) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (0.196921) loader.c:240   | Waiting for buffer...
[erizo] (0.197013) loader.c:326   | Allocated buffer
[erizo] (0.197082) loader.c:253   | Sent buffers to worker threads
[erizo] (0.197303) loader.c:258   | Joined worker threads
[erizo] (0.197306) loader.c:279   | Loader thread done
[erizo] (0.199328) instance.c:32  | Showed window
</code></pre>
<p>This is back down in the noise of
"how long does the OS take to give us an OpenGL context",
which is a great place for a high-performance tool.</p>
<hr>
<p>As someone that has been programming for many years,
this was a perfectly-timed reminder that there are <em>always</em> pitfalls out there.
The <a href="https://en.cppreference.com/mwiki/index.php?title=cpp/io/c/fscanf&amp;oldid=125683">documentation for <code>sscanf</code></a>
does not include a time complexity,
so this is particularly tricky <a href="https://en.wiktionary.org/wiki/footgun">footgun</a>,
and I'm sure it's not the only one lurking in the darkness.</p>
<p>You may not get such a perfectly-timed reminder, but it's worth remembering –
next time you read a fascinating story about bad programming –
that it <em>can</em> happen to you!</p>
<p>(Obviously, the moral of the story is to not use <code>sscanf</code> to repeatedly
parse single tokens off the front of a string; I'm sure you'll do <em>fine</em>
if you can just avoid <strong>that</strong>)</p>
<hr>
<h2>Follow-up and related discussions</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=26337046">Hacker News</a> (lots of discussion)</li>
<li><a href="https://lobste.rs/s/0obriy/it_can_happen_you">Lobste.rs</a>, including an <a href="https://lobste.rs/s/0obriy/it_can_happen_you#c_giuxfq">interesting survey</a> across different C libraries</li>
<li><a href="https://reviews.freebsd.org/D29007">Relevant FreeBSD patch</a></li>
<li><a href="https://sourceware.org/bugzilla/show_bug.cgi?id=17577"><code>glibc</code> bug tracker</a></li>
<li>The <a href="https://en.cppreference.com/w/cpp/io/c/fscanf">cppreference.com page for <code>sscanf</code></a> now mentions this pitfall</li>
</ul>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>https://www.mattkeeter.com/blog/2021-03-01-happen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26337046</guid>
            <pubDate>Thu, 04 Mar 2021 00:37:45 GMT</pubDate>
        </item>
    </channel>
</rss>
