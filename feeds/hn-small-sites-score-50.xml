<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 01 Oct 2020 20:25:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 01 Oct 2020 20:25:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here’s all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS – the operating system that powers the Apple T2 security chip.</p>
<p>For what it’s worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here’s what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There’s too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>— Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft’s secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don’t forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you’ll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog’s
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader’s job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let’s build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We’ll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we’ll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit’s <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You’ll notice that the linker script above declares some variables. We’ll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let’s write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or “Main Stack Pointer”.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that’s the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How India Censors the Web]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24633490">thread link</a>) | @srean
<br/>
September 29, 2020 | http://iamkush.me/how-india-censors-the-web/ | <a href="https://web.archive.org/web/*/http://iamkush.me/how-india-censors-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><b>Update (11th April 2020): This paper has been accepted at <a href="https://websci20.webscience.org/">ACM Web Science 2020</a>. A preprint can be accessed on <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">arXiv</a>.</b></p>

<p>Nation states around the world engage in web censorship using a variety of legal and technical methods. India is no different in this regard: the Government of India can legally order internet service providers (ISPs) operating in its jurisdiction to block access to certain websites for its users. This makes the situation different from jurisdictions like Iran and China, where internet censorship is largely centralised. Legal provisions in India, namely Section 69A and Section 79 of the Information Technology (IT) Act, allow the Central Government and the various courts in the country to issue website-blocking orders that ISPs are legally bound to comply with. <strong>Most of these orders are not publically available</strong>.</p>

<p>Recent events and the opaque nature of internet censorship in India motivated us at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a> to study India's censorship mechanism in detail. We spent the last year trying to answer two questions pertaining to how internet users in India experience web censorship:</p>

<ol>  
<li>What are the technical methods of censorship used by ISPs in India?</li>  
<li>Are all ISPs blocking the same websites?</li>  
</ol>

<p><strong>Our work has been so far the largest study of web censorship in India</strong>, both in terms of the number of censorship mechanisms that we test for and the number of potentially-blocked websites (PBWs). </p>

<h3 id="datacuration">Data curation</h3>

<p>We compiled a list of PBWs from three sources:  </p>

<ul>  
<li><b>Government orders</b>: A website/URL blocking order may come from the Government of India (Section 69A, IT Act). These orders are usually not in the public domain, as a confidentiality clause prevents any party from disclosing its contents. We collect published and leaked Government orders.</li>  
<li><b>Court orders</b>: The various courts in India also have the power to issue website blocking orders (Section 79, IT Act). Not all such orders are available in the public domain. However, the Government and BSNL (a public company operating as an ISP) have provided portions of this list when under pressure to respond to Right to Information (RTI) requests.</li>  
<li><b>User reports</b>: <a href="https://internetfreedom.in/" target="_blank">The Internet Freedom Foundation</a> collects and publishes reports from internet users who notice blocked websites.</li>  
</ul>

<p>Collecting data from these sources led to a total of 9673 unique URLs, which yielded 5798 unique websites. To limit ourselves to active websites, we exclude all websites for which we could not resolve via Tor circuits, culminating in a corpus of 4379 PBWs.</p>

<h3 id="networktestsfordetectingcensorship">Network tests for detecting censorship</h3>

<p>We designed four network tests that probe the existence of censorship at the DNS, TCP, HTTP, and TLS level. For the sake of brevity, I'll skip elaborating on the tests in this post; the details can be found in our <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">preprint</a>.</p>

<p>We run these tests for each website in our corpus from connections of six different ISPs (Jio, Airtel, Vodafone, MTNL, BSNL, and ACT), <strong>which together serve more than 98% of Internet users in India</strong>. Our findings not only confirm that ISPs are using different techniques to block websites, but also demonstrate that different ISPs are not blocking the same websites.</p>

<h3 id="results">Results</h3>

<p>In terms of censorship methods, our results confirm that ISPs in India are at liberty to use any technical filtering mechanism they wish: there was, in fact, no single mechanism common across ISPs. </p>

<p>We observe ISPs to be using a melange of techniques for blocking access, such as DNS poisoning and HTTP host header inspection. <b>Our tests also discern the use of SNI inspection being employed by the largest ISP in India (Jio) to block HTTPS communication, the use of which is previously undocumented in the Indian context</b>.</p>

<p><img src="https://i.imgur.com/vDAgGnf.png" alt="img">
</p><center>Censorship techniques employed by Indian ISPs</center>

<p>Further, we notice that all ISPs using multiple censorship mechanisms are not blocking the same websites with each mechanism. For instance, ACT uses only DNS censorship for blocking 233 websites, only HTTP censorship for 1873 websites, and both to block 1615 websites. Such irregularities are illustrated below.</p>

<p><img src="https://i.imgur.com/azWaVJW.png" alt="img">
</p><center>Censorship techniques used by (i) ACT, (ii) Airtel, and (iii) Jio for blocking websites. We notice the same ISP using multiple techniques for blocking different websites.</center>

<h3 id="somealarmingdiscoveries">Some alarming discoveries</h3>

<p>Our study has recorded large inconsistencies in website blocklists of different Indian ISPs. From our list of 4379 PBWs, we find that 4033 are being blocked by at least one ISP’s blocklist. In terms of absolute numbers, we notice that ACT blocks the maximum number of websites (3721). Compared to ACT, Airtel blocks roughly half the number of websites (1892).</p>

<p>Perhaps most surprisingly, we find that only 1115 websites out of the 4033 (just 27.64%) are blocked by all six ISPs. <b>Simply stated, we find conclusive proof that Internet users in India can have wildly different experiences of web censorship.</b></p>

<p><img src="https://i.imgur.com/XXaRpuf.png" alt="img"></p>

<p>Analysing inconsistencies in blocklists also makes it clear that ISPs in India are:</p>

<ol>  
<li>Not properly complying with website blocking (or subsequent unblocking orders), and/or </li>  
<li>Arbitrarily blocking websites without the backing of a legal order.</li>  
</ol>

<p>This has important legal ramifications: <b>India’s <a href="https://bit.ly/netneutralityframework" target="_blank">Net Neutrality regulations</a>, codified in the license agreements that ISPs enter with the Government of India, explicitly prohibit such behaviour</b>.</p>

<p>Our study also points to how the choice of technical methods used by ISPs to censor websites can decrease transparency about state-ordered censorship in India. While some ISPs were serving censorship notices, other ISPs made no such effort. For instance, Airtel responded to DNS queries for websites it wishes to block with <strong>NXDOMAIN</strong>. Jio used <strong>SNI-inspection</strong> to block websites, a choice which makes it <strong>technically impossible for them to serve censorship notices</strong>. Thus, the selection of certain technical methods by ISPs exacerbates the concerns created by the opaque legal process that allows the Government to censor websites.</p>

<h3 id="summingup">Summing up</h3>

<p>Web censorship is a curtailment of the right to freedom of expression guaranteed to all Indians. There is an urgent need to reevaluate the legal and technical mechanisms of web censorship in India to make sure the curtailment is transparent, and the actors accountable. </p>

<p>The whimsical attitude towards web censorship from both ISPs and the Government necessitates the development of a crowdsourced tool to <strong>monitor and measure such censorship from different vantage points in the country</strong>. This will shed further light into the geographical variation of censorship practices by ISPs across India, which is still unclear.</p>

<p>To probe this further we have ported our network tests into an android application, and are looking for volunteers who are willing to run it on their mobile networks. The entire process will be <strong>completely anonymous</strong>; we will not be collecting any user-specific information. If you live in India, please consider running <a href="https://play.google.com/store/apps/details?id=com.censorwatch.netprobesapp">Censorwatch</a>.</p>

<p><strong>Acks</strong> - This study was done in collaboration with <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> and <a href="https://www.linkedin.com/in/bansalvarun96/" target="_blank">Varun Bansal</a> at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a>, graciously supported by the <a href="https://www.macfound.org/" target="_blank">MacArthur Foundation</a>.</p>
			</section></div>]]>
            </description>
            <link>http://iamkush.me/how-india-censors-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633490</guid>
            <pubDate>Tue, 29 Sep 2020 21:55:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request to a YouTube video downloads the title 14 times and displays it twice]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24631698">thread link</a>) | @anderspitman
<br/>
September 29, 2020 | https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice | <a href="https://web.archive.org/web/*/https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
              <p>I have a project idea that could involve doing some scraping of YouTube videos, so I started poking
around the HTML output of curling YT links. These things are a site (sp) to behold. If you curl the following
well-known URL and store it in a file:</p>
<p><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ</code></p>
<p>Just searching for the title yields 14 results, spread throughout random HTML and JS. But it's only actually
displayed to the user once on the page, and probably again in the browser tab. It's not just the title
either, there's a ton of duplicated data and bloat throughout the file. I'm guessing it compresses well. I
checked a few other files and they all had between 10 and 18 copies of the title.</p>
<p>I'm not sure what conclusions to draw from this. A lot of them are obviously intended to be
machine-readable for things like <a href="https://ogp.me/">ogp</a>, but do you really need 14 identical copies?</p>
<p>EDIT:</p>
<p>Since this errant observation somehow made it to the <a href="https://news.ycombinator.com/item?id=24631698">Hacker News front page</a>, and eventually got flagged, I have a few more thoughts:</p>
<ul>
<li><p>Sorry the title ended up more clickbatey than intended. It's not making 14 extra HTTP requests just for the title. It originally started with "An HTTP request" but it was a few characters too long for HN, and I didn't spend much time rethinking it.</p>
</li>
<li><p>I agree the extra text isn't a problem (like I said, that'll compress well). I'm more concerned about the underlying complexity it signals. There is more obvious evidence of this complexity (it makes 70 network requests when you load the page even if you pause the video immediately), this is just a novel one for me.</p>
</li>
<li><p>I appreciate the copies which are intended to interoperate with other systems like Twitter and OGP.</p>
</li>
<li><p>I actually appreciate the fact that a JSON blob of all the video metadata is embedded in the HTML. It'll make my scraping task much simpler.</p>
</li>
</ul>

            </div>
          </div></div>]]>
            </description>
            <link>https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631698</guid>
            <pubDate>Tue, 29 Sep 2020 19:08:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust 2021: GUI]]>
            </title>
            <description>
<![CDATA[
Score 342 | Comments 205 (<a href="https://news.ycombinator.com/item?id=24631611">thread link</a>) | @clarkmoody
<br/>
September 29, 2020 | https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a response to the Rust <a href="https://blog.rust-lang.org/2020/09/03/Planning-2021-Roadmap.html">call for blogs 2021</a> and also a followup to <a href="https://raphlinus.github.io/rust/druid/2019/10/31/rust-2020.html">last year’s entry</a>. It will be entirely focused on GUI.</p>

<p>There is considerable interest in GUI toolkits for Rust. As one data point, it was the 6th highest rated challenge for adoption in the <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look">2019 Rust survey</a>, just behind async I/O. There is also a fair amount of activity towards this goal, though as a community it still feels a bit unfocused. A characteristic sign is that a new GUI toolkit seems to pop up every couple of months or so.</p>

<p>I believe there is great potential for a high-quality GUI toolkit in Rust. At the same time, it’s an incredibly ambitious task. Subtasks within it, for example accelerated GPU drawing and text layout, are in and of themselves incredibly ambitious tasks. I wouldn’t consider a toolkit “ready” for production use until it supported accessibility, and as far as I know there is nothing in the Rust space even starting to work on this.</p>

<p>Yet, perhaps against my better judgment, I find myself devoting most of my time and energy towards building GUI in Rust. In this post I will set out my hopes but also frankly discuss the challenges.</p>

<h2 id="why-gui-in-rust">Why GUI in Rust?</h2>

<p>Simply put, I believe that the strengths of Rust translate well to writing GUI applications, and that the missing piece is the existence of a good toolkit. One strength is Rust’s wide “dynamic range” – the ability to describe application logic in high level terms while still being attentive to low level details. Another is <em>strong</em> cross-platform compatibility. The increasingly rich crate ecosystem is compelling in many domains. And don’t lose sight of the importance of safety. In traditional object-oriented GUI in C++ especially, object lifetimes can be complicated, and it’s not hard to cause crashes, especially on takeoffs and landings.</p>

<p>I do pay attention to the competitive space, and one thing I see is Electron being used more and more, because it solves real problems. But I also believe that the success of Electron creates a real opportunity for a higher performance, lighter weight alternative. And in general for the projects I see in other languages, I find myself <em>wanting</em> to compete against them.</p>

<h2 id="about-druid">About Druid</h2>

<p>The <a href="https://github.com/linebender/druid">Druid</a> toolkit has made impressive progress in the last year, but is still nowhere near stable or complete. If you are looking for a GUI toolkit to develop your application today, Druid is not it.</p>

<p>We are developing the font editor <a href="https://github.com/linebender/runebender">Runebender</a> as the primary motivating application, but, while a lot of pieces are in place, it is sadly not yet usable for day to day font creation work. One of my goals for the rest of the year is to start creating a font in it.</p>

<p>That said, I am very proud of the work that’s been done in the last year. To hit on some of the highlights, we’re just landing basic but capable <a href="https://www.cmyr.net/blog/piet-text-work.html">rich text layout</a>. The keyboard event is close to browser quality (based on <a href="https://crates.io/crates/keyboard-types">keyboard-types</a>). There is incremental painting based on damage regions. Multi-window support is solid, with support for controlling window placement and dynamic hi-dpi. There is tab-focusing between text boxes. All of these are hard problems. Even more so, I am pleased that a lot of the work came from people in the community.</p>

<h2 id="converging-a-vision">Converging a vision</h2>

<p>Imagine a thought experiment for a bit. Obviously Rust is promising for implementing async, but there isn’t a consensus on the best way to do it. Some people feel it should be done with callbacks, and invest considerable effort into overcoming the serious problems with that approach. Others feel it should be done with a polling future trait, but there are multiple versions of that trait: some get the context from thread local storage, others pass it into the poll method. And of course some people feel the syntax should be <code>future.await</code> while others insist on <code>await!(future)</code>. Every couple of months somebody pops up on /r/rust with a new crate that promises to solve “the async problem,” complete with a nice-looking echo server demo.</p>

<p>That’s about where we are today with GUI toolkits. In many ways, I think converging on a single vision in GUI is a harder problem than for async. For one, people have different things they want to do. I’m personally most interested in things that resemble document editors. Others want 3D or video content. In the future, there might be commercial interest in enterprise line-of-business apps or interfaces for medical devices. These all have quite different requirements in the best ways to express UI logic, and how to build them. Not to mention the endless opportunities to bikeshed.</p>

<p>I am not (yet) proposing Druid as the singular vision that the Rust community should converge on. I’m enjoying reading codebases and learning from other Rust GUI projects. In particular, I’m finding lots to like about <a href="https://github.com/hecrj/iced">Iced</a>: it has good solutions to async, 3D graphics (through wgpu), being able to function in a guest window (important for VST plug-ins), among other problems. And I’m getting the sense that it’s easier for developers. The Elm-like reactive architecture maps nicely to Rust, and depending on exactly what you’re trying to do, it’s not hard to figure out how to express your app-specific logic. By contrast, Druid’s reactive model, while efficient and powerful in many ways, has complex concepts such as Haskell-like lenses, and places a burden on the developer to carefully design the “app data” to fit the Druid model. The <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet research prototype</a> is an active exploration into making that simpler. I am thankful to Iced (and other toolkits) for being a model to study.</p>

<p>The work to build consensus is complex and multifaceted, and it cannot be rushed. From my side, I hope to improve the designs and implementations to the point where they are compelling. I also hope to listen to criticisms, many of which are valid. I also think there is more work the community can be doing here. I’d love to see more active effort in trying to learn from the ongoing work and try to synthesize it. The GUI-related threads on /r/rust are sadly not a place where that happens; they most often consist of a statement of requirements (usually presented very informally), followed by a bit of bikeshedding. I don’t have a good answer for how to improve this situation, but put it out there as a problem I’m feeling.</p>

<p>While I think a converged vision is an admirable and ambitious goal, it may not be necessary for a successful GUI ecosystem in Rust. It’s possible that different types of GUI programs will simply require different infrastructure, so even in the long term it makes sense to have ecosystem diversity. Certainly that’s the case in the short and medium term as well, just to explore the space. And even without a grand unifying vision, there is lots of scope to work on infrastructural crates for important pieces of the GUI story, including text layout and related problems.</p>

<h2 id="learning-and-community">Learning and community</h2>

<p>Many Rust projects these days come with what’s basically a marketing pitch: “adopt this codebase, it’s awesome.” I am starting to see the Druid project in a somewhat different light. I consider its primary mission to be <em>teaching and learning</em> the knowledge required to build GUI. To that extent, the community we’re building, hosted on <a href="https://xi.zulipchat.com/">our Zulip instance,</a> is just as important as the code.</p>

<p>The knowledge needed to build GUI has many aspects, and is at all levels. Some of it is at a high level, like the best way to express reactive UI. Some of it is at a low level, like the keyboard event processing. A common thread is that a lot of it is very arcane, not really written down properly anywhere. Fortunately, a lot of it is accessible through reading the code of other open source projects, whether in Rust or in other languages (I’ve found both Chromium and Gecko to be especially useful).</p>

<p>So I consider this a goal, a success criterion, of the Druid project. If somebody wants to know how to solve a problem in GUI, the Druid codebase should be one of the best places to look for answers.</p>

<p>I love research more than most anything, and a lot of my own work has a strong research flavor. That has caused some confusion; some of the things I’m exploring are very speculative and will likely take years to come to fruition. Certainly my research into compute-centric GPU rendering is of that nature; I’m excited about the fact that it promises dramatic performance improvements over the current state of the art, but it’s nowhere near ready to put into production yet. I’m striving for clearer communication so people can have a better idea what is speculative, based on grand futuristic visions, and what is on track to being usable reasonably soon. But both are important aspects of what I consider to be the main mission: fostering learning about how to build GUI.</p>

<h2 id="baby-steps">Baby steps</h2>

<p>While I am driven by a long-term, ambitious vision, the goal of Druid in 2021 is not to deliver a general UI toolkit. Rather, we are deliberately continuing to follow a narrow scope. The primary goal remains the font editor project, and we plan to re-focus attention on that. I do think this is an attainable goal. I also think that what we learn from trying to build a real application with users will be extremely valuable to the more ambitious task.</p>

<p>One project management technique that is proving effective is “cycles.” Instead of trying to solve the most ambitious version of a problem, we choose up front what to push to a future cycle, reducing the scope for the current implementation cycle. An example is the choice to defer BiDi from our recent text work. This is obviously an essential feature for a real GUI toolkit, but we also know it could take weeks or months to get it right. To have any chance of shipping, we have to carefully budget our time and energy on subprojects that easily could expand to absorb our full attention.</p>

<p>A common development pattern for a fledgling GUI toolkit is to have a “hero app” that drives development. It really helps clarify requirements, and also makes it …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631611</guid>
            <pubDate>Tue, 29 Sep 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking TensorFlow on Nvidia GeForce RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24628189">thread link</a>) | @rkwasny
<br/>
September 29, 2020 | https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090 | <a href="https://web.archive.org/web/*/https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>NVIDIA recently released the much-anticipated GeForce RTX 30 Series of Graphics cards, with the largest and most powerful, the RTX 3090, boasting 24GB of memory and 10,500 CUDA cores. This is the natural upgrade to 2018’s 24GB RTX Titan and we were eager to benchmark the training performance performance of the latest GPU against the Titan with modern deep learning workloads.</p><p>Based on the specs alone, the 3090 RTX offers a great improvement in the number of CUDA cores, which should give us a nice speed up on FP32 tasks. However, NVIDIA decided to cut the number of tensor cores in GA102 (compared to GA100 found in A100 cards) which might impact FP16 performance.<br></p><p>‍<br></p><div>
<table>
  <tbody><tr>
    <th></th>
    <th>Titan RTX</th>
    <th>3090 RTX</th>
  </tr>
  <tr>
    <td><i>Architecture</i></td>
    <td>Turing TU102</td>
    <td>Ampere GA102</td>
  </tr>
  <tr>
    <td><i>Cuda cores</i></td>
    <td>4,609</td>
    <td>10,496</td>
  </tr>
  <tr>
    <td><i>Tensor cores</i></td>
    <td>576</td>
    <td>328</td>
  </tr>
  <tr>
    <td><i>Memory</i></td>
    <td>24GB</td>
    <td>24GB</td>
  </tr>
  <tr>
    <td><i>Memory bandwidth</i></td>
    <td>672 GB/sec</td>
    <td>936 GB/sec</td>
  </tr>
  <tr>
    <td><i>TDP (watts)</i></td>
    <td>285</td>
    <td>350</td>
  </tr>
</tbody></table></div><p>System:<br></p><p><em>Ubuntu 18.04.3</em></p><p><em>Driver Version: 455.23.05</em></p><p><em>CUDA Version: 11.1</em></p><p><em>Tensorflow: tf-nightly 2.4.0.dev20200928</em></p><p>It is very important to use the latest version of CUDA (11.1) and latest tensorflow, some features&nbsp;like TensorFloat are not yet available in a stable release at the time of writing.</p><p><br>We use our own fork of the <a href="https://github.com/lambdal/lambda-tensorflow-benchmark/tree/tf2">Lambda Tensorflow Benchmark</a> which measures the training performance for several deep learning models trained on ImageNet.</p><p>‍</p><div>


<table>
	<caption>Training performance in images processed per second</caption>
  <thead>
    <tr>
      <th></th>
      <th colspan="2">FP16</th>
      <th colspan="2">FP32</th>
    </tr>
    <tr>
      <th></th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><i>AlexNet</i></td>
      <td>6634.31</td>
      <td>8255.43</td>
      <td>4448.46</td>
      <td>6493.16</td>
    </tr>
    <tr>
      <td><i>Inception3</i></td>
      <td>656.13</td>
      <td>616.25</td>
      <td>222.95</td>
      <td>337.31</td>
    </tr>
    <tr>
      <td><i>Inception4</i></td>
      <td>298.11</td>
      <td>132.73</td>
      <td>99.74</td>
      <td>143.65</td>
    </tr>
    <tr>
      <td><i>ResNet152</i></td>
      <td>423.92</td>
      <td>484.02</td>
      <td>134.47</td>
      <td>203.58</td>
    </tr>
    <tr>
      <td><i>ResNet150</i></td>
      <td>966.77</td>
      <td>1259.95</td>
      <td>335.96</td>
      <td>525.88</td>
    </tr>
    <tr>
      <td><i>VGG16</i></td>
      <td>339.73</td>
      <td>442.49</td>
      <td>212.06</td>
      <td>325.60</td>
    </tr>
  </tbody>
</table></div><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-81c38bb21f8c-a8a0c0ce"><p><img src="https://assets.website-files.com/5f286b01a607cf5cd1531aa9/5f731993be0980f19dfb79a2_gpu_benchmark.svg" loading="lazy" alt=""></p><figcaption>Speedup of RTX 3090 over Titan RTX</figcaption></figure><p>‍</p><p>We're able to achieve a 1.4-1.6x training speed-up for all the models training with FP32! As expected, the FP16 is not quite as significant, with a 1.0-1.2x speed-up for most models and a drop for Inception.</p><p>‍</p><p>Please get in touch at <a href="mailto:hello@evolution.ai">hello@evolution.ai</a> with any questions or comments!</p></div></div></div></div>]]>
            </description>
            <link>https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628189</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Airtel middleboxes that censor HTTPS traffic]]>
            </title>
            <description>
<![CDATA[
Score 375 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24626388">thread link</a>) | @justDankin
<br/>
September 29, 2020 | http://iamkush.me/sni-airtel/ | <a href="https://web.archive.org/web/*/http://iamkush.me/sni-airtel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Back in November 2019, <a target="blank" href="https://cis-india.org/internet-governance/blog/reliance-jio-is-using-sni-inspection-to-block-websites">we reported</a> that Reliance Jio is able to block HTTPS internet traffic by means of a deep packet inspection (DPI) technique. In response, some readers messaged us saying that they ran our test and were able to reproduce similar behaviour on Airtel mobile networks. According to <a href="https://trai.gov.in/sites/default/files/PIR_08012020_0.pdf" target="_blank">TRAI's Performance Indicators report for Jul-Sep 2019</a>, Reliance Jio and Airtel serve roughly 52% and 23% of internet subscribers in India respectively. <strong>This essentially means that SNI inspection based censorship is now impacting every 3 out of 4 internet connections in India.</strong></p>

<p>Although the previous test was able to detect the presence of SNI inspection based censorship, it was not very insightful. In this post, we delve into a more informative test which not only confirms the presence of SNI inspection based censorship, but also helps us identify the exact mechanism. Furthermore, it also allows us to identify middleboxes which are actively inspecting SNI in TLS handshakes and censoring requests. <strong>Using this method, we were able to discover 25 different middleboxes registered to Airtel, which are actively censoring HTTPS traffic.</strong></p>

<p>Quick links to different sections of this post: <br>
1. <a href="#secTLS">Transport Layer Security</a> <br>
1.1 <a href="#secSNI">Server Name Indication</a> <br>
2. <a href="#secSNICensor">SNI Inspection based censorship</a> <br>
3. <a href="#secINT">Iterative Network Tracing</a> <br>
4. <a href="#secData">Data Preparation</a> <br>
5. <a href="#secMethod">Methodology</a> <br>
6. <a href="#secAirtel">Examining Airtel's behaviour</a> <br>
7. <a href="#secRef">References</a></p>

<p>All the code for replicating this experiment, as well as the logs from our test runs can be found in <a target="_blank" href="https://github.com/kush789/INT-SNI">this repository</a>. Big shout-out to <a href="https://ipinfo.io/" target="_blank">IPinfo</a> for giving us access to their IP address dataset, and <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> for his suggestions while ideating the methodology and for editing this post.</p>





<p>Transport Layer Security (TLS) is a cryptographic protocol for providing communication confidentiality and authenticity, commonly used for encrypting web traffic (as done in HTTPS). Normally TLS is used over TCP, as it requires a reliable in-order data stream. A <a href="https://www.cloudflare.com/learning/ssl/transport-layer-security-tls" target="_blank">quick refresher</a> on TLS by Cloudflare.</p>

<p><img src="https://i.imgur.com/OlMYujg.png" alt="img">
</p><center>A TCP handshake followed by a TLS Handshake. The ClientHello is a message sent by the client, which initiates the TLS handshake. This message can contain extensions such as SNI. Image credits - <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/">Cloudflare</a></center>



<h3 id="servernameindication">Server Name Indication</h3>

<p>Server Name Indication (SNI), defined first in <a href="https://tools.ietf.org/html/rfc4366" target="_blank">RFC4366</a> and then in <a href="https://tools.ietf.org/html/rfc6066" target="_blank">RFC6066</a>, is a TLS extension designed to facilitate the hosting of multiple HTTPS websites on the same IP address. While sending a <code>ClientHello</code> message (which initiates the establishment of a secure connection), the client is expected to fill in the SNI attribute with the hostname of the website it wishes to connect to. SNI, unfortunately, travels on the network in cleartext, i.e. <strong>network operators can not only see the websites you’re visiting, but also filter traffic based on this information.</strong></p>

<hr>





<p>Since the SNI present is in cleartext, anyone in the network can inspect and filter traffic based on its value. As seen in other countries, ISPs can leverage this to deny access to certain websites. We can observe the same by attempting a TLS connection using openssl and monitoring packets to the host.  </p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername fullhd720.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_fullhd720.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code>, with SNI <code>fullhd720.com</code>. We observe a RST packet immediately after the ClientHello message containing the SNI is sent.</center>

<p>For instance, using Airtel, we can see that the client receives a TCP RST packet when it tries to connect to a blocked website "fullhd720.com". The RST packet seems to be originating from the actual host, and is received right after the ClientHello message containing the SNI is sent. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_fullhd720.com.pcap" target="_blank">PCAP</a>.</p>

<p>To confirm that the connection termination was indeed due to the SNI, we can reattempt the connection with a different SNI which we don't expect to be blocked (in this case we use <code>facebook.com</code>).</p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername facebook.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_facebook.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code> with a different SNI, <code>facebook.com</code>. In this case, we observe a successful TLS handshake</center>

<p>This time we notice a successful connection, indicating that the RST in the previous attempt was indeed due to the specified SNI. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_facebook.com.pcap" target="_blank">PCAP</a>.</p>

<p>Although this test does demonstrate the presence of SNI inspection based censorship, the packet dumps are not sufficient to prove that the RST packet was actually forged by a middlebox belonging to the ISP.</p>

<hr>  





<p>For a given host, let's call the minimum Time to Live (<a href="https://packetpushers.net/ip-time-to-live-and-hop-limit-basics/" target="_blank">TTL</a>) required for a packet to reach from the client to the host, <code>min_ttl</code>. Any packet where the TTL set is less than <code>min_ttl</code> would expire in transit, and never reach the host. Ideally, the router at which the TTL of the packet expired should respond with an ICMP Time Exceeded (<a href="http://www.networksorcery.com/enp/protocol/icmp/msg11.htm" target="_blank">ICMP message type 11</a>) message. However, this is not guaranteed, and some routers are even configured to not send them (in order to hide the topology of the network).</p>

<p><img src="https://i.imgur.com/aSrR375.png" alt="img">
</p><center>Iterative Network Tracing; we send ClientHello messages with increasing TTL. In this particular case, the minimum TTL required is 9. A middlebox which censors requests would send back a censored response even when the TTL is less than 9. Image credits - <a href="#cite1">Yadav et al.</a></center>

<p>So if the RST received is forged by a middlebox, we should receive it even when we send the ClientHello message with TTL less than <code>min_ttl</code>. This approach, known as Iterative Network Tracing (INT), has been previously used to ascertain the presence of middleboxes which censor DNS and HTTP traffic in India [<a href="#cite1">Yadav et al.</a>] and China <a href="#cite2">Xu et al.</a> Similar to these studies, we use INT to detect censorship of TLS traffic (explained further in the <a href="#secMethod">methodology</a> section).</p>

<hr>  





<p>We run our tests using a list of potentially blocked websites (PBWs), curated from leaked court and government orders. The list and more information pertaining to it can be found <a href="https://github.com/kush789/How-India-Censors-The-Web-Data" target="_blank">here</a>.</p>

<p>Using Google's DNS over HTTPS (DoH) <a href="https://developers.google.com/speed/public-dns/docs/doh" target="_blank">service</a>, each hostname was resolved to its correct IP address. Using DoH here is important as it ensures that no DNS based censorship intervenes with the test. This resulted in roughly 5000 (hostname, ip) pairs. Next we selected a random subset and checked for TCP connectivity to port 443 to each of those ips (since not all would support HTTPS traffic), filtering our list down to 1370 pairs.</p>

<p>For each of these test points, we establish a TCP connection with the resolved_ip, and send a TLS ClientHello with the SNI set as the correct_hostname. We sniff and save these ClientHello packets (just the SSL layer) for use later. Similarly, we save the ClientHello packet with the SNI set as <code>facebook.com</code>. These sniffed packets can be found <a href="https://github.com/kush789/INT-SNI/tree/master/tls_client_hellos" target="_blank">here</a>.</p>

<hr>  





<p>The input to the test is a 2-tuple, (<code>correct_hostname</code>, <code>resolved_ip</code>). We would like to understand the behaviour of a middlebox when it observes a ClientHello message containing an SNI for a website it wishes to block.</p>

<p>First, we calculate the <code>min_ttl</code> for a given test point. We begin by establishing a TCP connection with <code>resolved_ip</code>.</p>

<pre><code>import socket  
import random  
from scapy.all import *

resolved_ip = "103.224.212.222"  
dport = 443 # TLS connection  
sport = random.randint(1024, 65535) # Random source port

def create_connection(resolved_ip):  
    s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW)
    s.bind(("usb0", 0)) # Was using a tethered mobile connection for the experiment

    IP_PACKET = IP(dst = resolved_ip)

    seq = random.randint(12345, 67890) # Randomise initial seq number
    SYN = TCP(sport = sport, dport = dport, flags = "S", seq = seq)
    SYNACK = sr1(IP_PACKET / SYN)
    ACK = TCP(sport = sport, dport = dport, flags = "A", seq = seq + 1, ack = SYNACK.seq + 1)
    send(IP_PACKET / ACK)
    return IP_PACKET, ACK
</code></pre>

<p><strong>Note</strong>: When the linux kernel feature gets a TCP packet to an unknown socket, it sends a RST back to the originator. Since we'll be creating our own raw sockets, we need to suppress these outbound RSTs from the kernel using iptables before running experiments.</p>

<pre><code>sudo iptables -A OUTPUT -p tcp --tcp-flags RST RST -j DROP  
</code></pre>

<p>Once the TCP connection has been established, we send ClientHello messages (containing <code>facebook.com</code> in SNI) after updating the TTL (<code>probe_ttl</code>) in the underlying IP header. We specify <code>facebook.com</code> in the SNI so that the middlebox doesn't attempt to terminate the connection. <code>min_ttl</code> would be the minimum TTL at which we receive a TLS ServerHello or TLS Alert from the host.</p>

<pre><code># Load ClientHello with garbled hostname in SNI (sniffed earlier, read Data Preparation)
max_ttl = 35

def find_min_ttl(resolved_ip)

    with open("tls_client_hellos/facebook.com", 'rb') as fp:
        tls_client_hello_facebook_com_sni = fp.read()

    for probe_ttl in range(1, max_ttl):
        IP_PACKET, ACK = create_connection(resolved_ip)
        IP_PACKET.ttl = probe_ttl
        del IP_PACKET.chksum # Will force scapy to recalculate checksum after TTL update

        resp, _ = sr(IP_PACKET / ACK / tls_client_hello_facebook_com_sni, timeout = 2, retry = 0, multi = True)

        for _, ans_packet in resp:
            tls_alert = ans_packet.get(tls.TLS, {}).get(tls.TLSAlert)
            tls_server_hello = ans_packet.get(tls.TLS, {}).get(tls.TLSHandshakes, {}).get(tls.TLSServerHello)

            if tls_alert or tls_server_hello:
                return probe_ttl # min_ttl found!
</code></pre>

<p>Next, we send ClientHello messages containing the <code>correct_hostname</code> in the SNI with TTL increasing from 1 to <code>min_ttl</code> - 1. If there is no middlebox interfering with the connection, all such requests should receive either an ICMP Time Exceeded in response or no response at all. If at any point we receive an RST packet which seems to be originating from <code>resolved_ip</code>, we can say with certainty that the packet was forged by a middlebox.</p>

<pre><code>min_ttl = find_min_ttl(resolved_ip, tls_client_hello)

with open("tls_client_hellos/fullhd720.com", 'rb') as fp:  
    tls_client_hello_correct_sni = fp.read()

for probe_ttl in range(1, min_ttl):  
    IP_PACKET, ACK = create_connection(resolved_ip)
    IP_PACKET.ttl …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://iamkush.me/sni-airtel/">http://iamkush.me/sni-airtel/</a></em></p>]]>
            </description>
            <link>http://iamkush.me/sni-airtel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626388</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun Yet Effective Meetings]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24624819">thread link</a>) | @thesnide
<br/>
September 28, 2020 | https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html | <a href="https://web.archive.org/web/*/https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>⚠️ This article is extreme &amp; satirical on the purpose of being thought-provoking. Therefore, please, do take it with some grain of salt.</p>

  <p>This is a followup of my <a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working is a paradigm shift</a>.</p>
</blockquote>



<p>My #1 advice about distributed teams is actually even the case in colocated teams:
<strong>Try as hard as possible to avoid meetings, use textual IM instead</strong> as <a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/">meetings are where work goes to die</a>.
I know it sounds pretty dull, but if you really think about it you’ll see that it’s usually wasted time.
The usual pattern of decision taking is:</p>

<div><div><pre><code>1. if you don’t have a clue, ask someone else.
2. to ask him, schedule a meeting
3. to schedule a meeting, you have to find a slot
4. that usually postpones the decision
</code></pre></div></div>

<p>Postponing the decision is usually what one really wants, even unknowingly: “<em>to be able to have an excuse not to decide at once</em>”.</p>

<p>It’s a very very fair humane reaction, I also fell myself into that trap.</p>

<p><img src="https://blog.pwkf.org/assets/images/out-of-window.jpg" alt="Thrown out of the fence for proposing an textual chat"></p>



<p>I end up having the following workflow:</p>

<ul>
  <li>Avoid email loops. Those have too much overhead, and will divide your audience pretty quickly.</li>
  <li>Create a slack channel instead of the email loop. This will retain the whole conversation in 1 central place.</li>
  <li>Systematically push back on any meetings. Accept them only if you have a clear statement of who will drive it.</li>
  <li>
    <p>Meetings should be a broadcast mode. All the Q&amp;A should go back to the slack channel.</p>

    <ul>
      <li>Having everything searchable makes it super easy for
        <ul>
          <li>newcomers that can simply scroll back</li>
          <li>old timers such as me that forget and can also simply scroll back</li>
        </ul>
      </li>
      <li>
        <p>Even recorded meetings are a vast of time if you need to find an information, as it’s not indexed.</p>
      </li>
      <li>If not recorded, sending the minutes afterwards are usually a loss of information.
        <ul>
          <li>It’s still very important to extract “executive summaries” from those meetings, even only textual. As can be posted on a public place for massive &amp; broad sharing.</li>
          <li>Yet, the real context on those summaries will be kept inside the whole meeting</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Context effectively fights Cargo Cult</strong></p>

  <p>Usually the why of decisions are not provided in a “<a href="https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory">build the sausage</a>” manner. But after a while, the hypothesis of the decision are not true anymore, and therefore another decision has to be taken.</p>

  <p>This is not possible when loss of information occurs and that’s when <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">Cargo cult</a> begins to creep in.</p>
</blockquote>

<p>In a record-everything scenario, context switch is just a matter of reading back some previous messages. Otherwise you’ll spend numerous times “explaining the context” in a meeting to everyone. And then everyone will just move to something else, and you’ll have pitiful engagement, while still spending time on it.</p>

<p><strong>A company that use its time effectively, is a company that moves much faster than its competitors</strong>, no matter the skillsets in that company. Even if you have the brightest minds, if you waste their talents in boring activities, you’ll dry them up. And either they’ll leave, or worse, they <a href="https://www.sbnonline.com/article/the-quit-and-stay-syndrome-a-business-epidemic-thats-a-silent-profit-killer/">quit &amp; stay</a>.</p>

<blockquote>
  <p>💡 This enabled me to scale to a reasonable multitasking ability while curbing its overhead to a manageable level</p>
</blockquote>

<p><strong>That’s why “startups” are so effective</strong> : they are small and therefore very fast. Being fast brings capacity to try &amp; fail, and therefore agility.</p>

<blockquote>
  <p>💡 <strong>time is the only really scarse resource in a company</strong> : you can’t buy it back, no matter the price.</p>
</blockquote>

<h2 id="why-you-should-only-have-fun-ones">Why you should only have fun ones</h2>

<p>That said, I do agree that travelling is necessary. But we should name the real usecase of travelling : having <em>fun</em> <strong>together</strong>.</p>

<p>The nicest part of that purpose is :</p>

<ul>
  <li>you can plan it far in advance</li>
  <li>you can also budget it in advance</li>
  <li>you can mentally map yourself in those fun times, and focus on actual work right now.</li>
</ul>



<p>The most used reason for meetings is “alignments”, but it is very usually wasted as :</p>

<ul>
  <li>There’s always someone missing for that meeting</li>
  <li>No-one really wants to write the minutes out of it</li>
  <li>If written nonetheless, those minutes are only seldom capturing the <em>why</em> the decision is reached. Which is the most important part!</li>
</ul>

<p>The “<em>there’s always someone missing from that meeting</em>” is the worst part, as usually, that is the one that says “what you decided cannot be done”. And you’ll end up with yet another round of thinking at best. At worst you’ll try to shoehorn your precious alignment (that did sink a huge travel budget) into the needs of that missing person.</p>

<blockquote>
  <p>💡 We can draw a parallel to the paradigm shift I mentioned earlier:</p>
</blockquote>

<ul>
  <li><strong>F2F</strong> Meetings are the <strong>monolith</strong> way.</li>
  <li>Informal, dedicated &amp; <strong>textual meetings</strong> are the <strong>micro-services</strong> way.</li>
</ul>

<p>Now, one immediately notices the following:</p>

<ul>
  <li><strong>People are very much at ease with monoliths</strong>. It takes a huge mental leap to go micro-services.</li>
  <li><strong>Micro-services have an overhead</strong>. But no-one will argue that they can scale way better.</li>
  <li>Monoliths can seldomly be distributed the way micro-services can : you’ll quickly end up with that infamous distributed monolith pattern.</li>
</ul>

<blockquote>
  <p>💡 Now, let’s travel only for “team building” purposes.</p>

  <p>You can plan them in advance, and you won’t have over-budget ones. As their outcome is predictable, and if there’s someone missing, it won’t jeopardy the whole travelling.</p>
</blockquote>

<p>A final word of caution, the reference to scaling is <strong>not about runtime performance</strong>. It’s more about <strong>organisation size</strong>. As Martin Fowler said : <em>don’t even consider microservices unless you have a system that’s too complex to manage as a monolith</em>.</p>

<p>So, it usually makes very much sense to start with a small, colocated team, that has traditional meetings. The trick is to recognize the need to change the paradigm when the team grows, as it always done smoothly over the months. Just don’t forget to have good meeting hygiene (written inputs &amp; outputs), as <strong>even monoliths should be nicely modular</strong>.</p>

<blockquote>
  <p>I posted those 2 articles (<a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working</a>, <a href="https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">Effective Meetings</a>) internally to my company some years ago, but I’m republishing those publicly to help others the same way it helped us.</p>
</blockquote>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624819</guid>
            <pubDate>Tue, 29 Sep 2020 06:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[City of Amsterdam’s Algorithm Register]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24623639">thread link</a>) | @cpeterso
<br/>
September 28, 2020 | https://algoritmeregister.amsterdam.nl/en/ai-register/ | <a href="https://web.archive.org/web/*/https://algoritmeregister.amsterdam.nl/en/ai-register/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-pm="normal" data-desktopportraitmargin="5|*|0|*|65|*|0|*|px+" data-tabletportraitmargin="0|*|0|*|0|*|0|*|px+" data-mobileportraitmargin="-20|*|0|*|0|*|0|*|px+" data-desktopportraitheight="0" data-has-maxwidth="1" data-desktopportraitmaxwidth="520" data-tabletportraitmaxwidth="430" data-mobileportraitmaxwidth="295" data-cssselfalign="inherit" data-desktopportraitselfalign="inherit" data-sstype="layer" data-rotation="0" data-desktopportrait="1" data-desktoplandscape="1" data-tabletportrait="1" data-tabletlandscape="1" data-mobileportrait="1" data-mobilelandscape="1" data-adaptivefont="0" data-desktopportraitfontsize="100" data-tabletportraitfontsize="90" data-mobileportraitfontsize="120" data-plugin="rendered"><div><p><br>The Algorithm Register is an overview of the artificial intelligence systems and algorithms used by the City of Amsterdam. Through the register, you can get acquainted with the quick overviews of the city's algorithmic systems or examine their more detailed information based on your own interests. You can also give feedback and thus participate in building human-centered algorithms in Amsterdam. The register is still under development.</p></div></div></div>]]>
            </description>
            <link>https://algoritmeregister.amsterdam.nl/en/ai-register/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623639</guid>
            <pubDate>Tue, 29 Sep 2020 02:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part I)]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24622788">thread link</a>) | @upofadown
<br/>
September 28, 2020 | https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.</p>

<p>First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the <a href="https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs">amd64 miniroot
image</a> (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the <a href="https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256">SHA256
checksums</a> from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:</p>
<pre><code>$ sha256sum -c --ignore-missing SHA256 
miniroot67.fs: OK
$ sudo dd if=miniroot67.fs of=/dev/sda bs=1M
</code></pre>

<p>The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.</p>
<p>I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:</p>
<ul>
<li>I choose the option <code>I</code> to install OpenBSD.</li>
<li>For the keyboard layout, I pick <code>sg</code>, for Swiss German.</li>
<li>As a hostname, I simply pick <code>x270</code>, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.</li>
<li>From the available network options (<code>iwm0</code>: WiFi, <code>em0</code>: Ethernet, and
  <code>vlan0</code>: Virtual LAN), I pick <code>em0</code>.</li>
<li>I try to get an IPv4 address over DHCP, which seems to work very quickly.</li>
<li>Next, I type in my very secret root password twice.</li>
<li>I do <em>not</em> start <code>sshd</code> by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.</li>
<li>The X Window System should not be started by <code>xnodm(1)</code>, so I leave it to
  <code>no</code>.</li>
<li>Neither do I want to change the default to <code>com0</code>.</li>
<li>I set up my user <code>patrick</code> with my proper name <code>Patrick Bucher</code>, and a decent
  password.</li>
<li>The time zone has been detected properly as <code>Europe/Zurich</code>, which I just
  leave the way it is.</li>
<li>The installer detected two disks: <code>sd0</code> and <code>sd1</code>. Since <code>sd0</code> is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick <code>sd0</code> for the root disk, since <code>sd1</code> is my USB dongle.</li>
<li>I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.</li>
<li>An auto-allocated layout for <code>sd0</code> is presented. It looks decent to me, so I
  just go with that auto layout.</li>
<li>I don't want to initialize another disk, so I just press Enter (<code>done</code>).</li>
<li>Since the miniroot image does not come with the file sets, I pick <code>http</code> as
  the location for the sets.</li>
<li>I don't use a proxy, and use the mirror <code>mirrog.ungleich.ch</code> and the server
  directory <code>pub/OpenBSD/6.7/amd64</code> as proposed.</li>
<li>Next, I unselect the game sets by entering <code>-game*</code>. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the <code>x</code>
  sets, which will be required for the GUI later on.</li>
<li>After those sets are installed, I press Enter (<code>done</code>). Now the installer
  performs various tasks, after which I choose to <code>halt</code> the computer. This
  gives me time to remove the USB dongle.</li>
</ul>

<p>I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses <code>systemd</code>, whereas OpenBSD uses <code>rc</code>, which performs the
startup tasks sequentially.</p>
<p>There's a message showing up that various firmware (<code>intel-firmware</code>,
<code>iwm-firmware</code>, <code>inteldrm-firmware</code>, <code>uvideo-firmware</code>, and <code>vmm-firmware</code>) has
been installed automatically. Very nice, indeed.</p>
<h2>WiFi Connection</h2>
<p>Now that the <code>iwm-firmware</code> has been installed, I can connect right away to my
WiFi network <code>frzbxpdb5</code>. I create a file called <code>/etc/hostname.iwm0</code>, wich
<code>hostname</code> being a literal string, and <code>iwm0</code> being the WiFi network card. The
connection to my WiFi network consists of a single line:</p>
<pre><code>dhcp nwid frzbxpdb5 wpakey [my-wpakey]
</code></pre>
<p>Whereas <code>frzbxpdb5</code> is my WiFi network's ESSID, and <code>[my-wpakey]</code> needs to be
replaced by the actual WPA key.</p>
<p>Then the networking can be restarted for that device:</p>
<pre><code># sh /etc/netstart iwm0
</code></pre>
<p>This script is kind enough to set the file permissions of <code>/etc/hostname.iwm0</code>
to <code>640</code>, and then connects to my WiFi network.</p>
<p>I unplug the Ethernet cable and <code>ping openbsd.org</code>, which works fine, even after
a restart.</p>

<p>My GUI on Unix-like systems is based on the Dynamic Window Manager (<code>dwm</code>) and a
couple of other tools, such as <code>dmenu</code>, <code>st</code>, <code>slstatus</code>, <code>slock</code>, all created and
maintained by the <a href="http://suckless.org/">Suckless</a> community.</p>
<p>This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file <code>config.h</code>, and then re-compiled.
Even though OpenBSD offers <code>dwm</code> as a package, customizing and configuring that
window manager requires to build it from source.</p>
<h2>Building <code>dwm</code> and Friends</h2>
<p>First, I need to install <code>git</code> to fetch the source code:</p>
<pre><code># pkg_add git
</code></pre>
<p>Then I fetch the source code for <code>dwm</code>, <code>dmenu</code>, <code>st</code>, and <code>slstatus</code> from <a href="http://suckless.org/">Suckless</a>:</p>
<pre><code>$ git clone https://git.suckless.org/dwm
$ git clone https://git.suckless.org/dmenu
$ git clone https://git.suckless.org/st
$ git clone https://git.suckless.org/slstatus
</code></pre>
<h3>Building <code>dwm</code></h3>
<p>Next, I try to build <code>dwm</code>:</p>
<pre><code>$ cd dwm
$ make
</code></pre>
<p>This fails with an error message (<code>'ft2build.h' file not found</code>), which reminds
me of building <code>dwm</code> on FreeBSD roughly a month before. Since I can finde the
header file at another location:</p>
<pre><code># find / -type f -name ft2build.h
/usr/X11R6/include/freetype2/ft2build.h
</code></pre>
<p>I simply can modify the <code>config.mk</code> accordingly by changing</p>
<pre><code>FREETYPEINC = /usr/include/freetype2
</code></pre>
<p>to</p>
<pre><code>FREETYPEINC = $(X11INC}/freetype2
</code></pre>
<p>Actually, I only need to comment the above line, and uncomment the line below</p>
<pre><code># OpenBSD (uncomment)
</code></pre>
<p>The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).</p>
<p>The next compilation attempt succeeds:</p>
<pre><code>$ make
</code></pre>
<p>So let's install <code>dwm</code>, too:</p>
<pre><code># make install
</code></pre>
<p>By default, and as to be seen in <code>config.h</code>, the keyboard combination
<code>[Alt]+[Shift]+[Enter]</code> (deeply engraved into the muscle memories of many <code>dwm</code>
users) starts the <code>st</code> terminal. This will be built in a while. However, I
prefer to use the <em>Super</em> or <em>Windows</em> key instead of <code>Alt</code>, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the <code>MODKEY</code> from</p>
<pre><code>#define MODKEY Mod1Mask
</code></pre>
<p>to</p>
<pre><code>#define MODKEY Mod4Mask
</code></pre>
<p>Then I rebuild and reinstall <code>dwm</code>:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>st</code></h3>
<p>Let's switch over to the <code>st</code> source directory and just try to compile it:</p>
<pre><code>$ cd ../st
$ make
</code></pre>
<p>Here, we get a warning that the function <code>pledge</code> (an OpenBSD mitigation, which
is built into the <code>master</code> branch, but surrounded by an <code>ifdef</code> preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.</p>
<p>What's worse, the compilation fails with the error message:</p>
<pre><code>ld: error: unable to find library -lrt
</code></pre>
<p>Here, the FAQ comes in handy, stating that</p>
<pre><code>If you want to compile st for OpenBSD you have to remove -lrt from
config.mk, ...
</code></pre>
<p>Having done so in <code>config.mk</code>, <code>st</code> compiles without any further issues, and,
thus, can be rebuilt and installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>dmenu</code></h3>
<p>Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers <code>dmenu</code>.
Let's switch over to it and compile it:</p>
<pre><code>$ cd ../dmenu
$ make
</code></pre>
<p>Again, we have the issue with <code>ft2build.h</code>, which can be resolved as above with
<code>dwm</code>: by using the proper path for <code>FREETYPEINC</code> in <code>config.mk</code>. Afterwards,
the build succeeds, and <code>dmenu</code> can be installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>slstatus</code></h3>
<p><code>dwm</code> has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in <code>.xinitrc</code> to compose such a
status line, and then set it by <code>xset -b</code> once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.</p>
<p><code>slstatus</code> is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to <code>slstatus</code> and see, what is
available in <code>config.def.h</code>:</p>
<pre><code>$ cd ../slstatus
$ less config.def.h
</code></pre>
<p>The comments section lists different functions (<code>battery_perc</code> for the battery
percentage, <code>datetime</code> for date and time information, <code>temp</code> for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.</p>
<p>Before configuring those, let's try to compile <code>slstatus</code>:</p>
<pre><code>$ make
</code></pre>
<p>This worked fine, so let's configure the information to be displayed in
<code>config.h</code>:</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    "%s",     "%F %T" },
};
</code></pre>
<p>This renders the current date as follows:</p>
<pre><code>$ date +"%F %T"
2020-09-05 19:26:38
</code></pre>
<p>I also like to have the weekday included, but not the seconds, so I define a
different argument string:</p>
<pre><code>$ date +"%a %Y-%m-%d %H:%M"
Sat 2020-09-05 19:27
</code></pre>
<p>That's better, so let's use it in <code>config.h</code> (surrounded with some spaces in the
format string):</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    " %s ",   "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with <code>|</code> as a
seperator) for those:</p>
<pre><code>static const struct arg args[] = {
    /* function    format           argument */
    { cpu_perc,     " cpu: %s%% |", NULL },
    { battery_perc, " bat: %s%% |", NULL },
    { ram_used,     " mem: %s |",   NULL },
    { keymap,       " %s |"         NULL },
    { datetime,     " %s ",         "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>This actually compiles, so let's install it:</p>
<pre><code># make install
</code></pre>
<h2>Configuring X Startup</h2>
<p>Now that all software is compiled and installed, let's run X. To do so, a file
<code>.xinitrc</code> in the user's directory is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</a></em></p>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24622788</guid>
            <pubDate>Tue, 29 Sep 2020 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hanging Gardens of Babylon]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24621384">thread link</a>) | @quickfox
<br/>
September 28, 2020 | https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/ | <a href="https://web.archive.org/web/*/https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621384</guid>
            <pubDate>Mon, 28 Sep 2020 21:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nix × IPFS – Milestone 1]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24621276">thread link</a>) | @Fnoord
<br/>
September 28, 2020 | https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by John Ericson on 2020-09-08</p>

      

      

<p><a href="https://obsidian.systems/">Obsidian Systems</a> is adding support for IPFS to Nix so that build products can be persisted to and fetched from IPFS. This adds resiliency and makes it easier for Nix users to reproduce and distribute their work - by caching and distributing source code (and hopefully in the future intermediate build steps) peer to peer by using IPFS content addresses (CIDs).</p>

<h2 id="what-is-nix">What is Nix?</h2>

<p><a href="https://nixos.org/">Nix</a> is usually used as a package manager, but at its heart is a general-purpose build tool, like Make, Ninja, or Bazel.</p>

<p>What distinguishes Nix is its focus on sandboxing build steps and caching build artifacts.
With these features, neither the plans nor the build artifacts can have hidden dependencies, so builds can be reproduced and build artifacts shared robustly.</p>

<p>This makes Nix an ideal build tool to use with a peer-to-peer system like IPFS.
Indeed, the premier project using Nix is Nixpkgs, a package collection (with associated Linux distro) that is one of the largest most widely-contributed projects on GitHub.</p>

<h2 id="why-we-use-nix">Why we use Nix</h2>

<p>Obsidian Systems is an end-to-end software product consultancy serving everyone from recently funded startups to large institutions.
We have made Nix an integral part of both our production deployments and developer workflows since our founding 2014.</p>

<p>Nix is an indispensable tool for us because we frequently need to switch between projects, and Nix makes setting up and sharing per-project development environments trivial.
It has also made it easy to package software that the end user installs on their own machines, such as blockchain wallets.</p>

<h2 id="challenges-that-inspired-our-use-of-ipfs">Challenges that inspired our use of IPFS</h2>

<p>While Nix build plans are reproducible, one limitation that remains is the availability of the initial data—source code.
Nix plans have what are known as “fixed output derivations”.
These are unsandboxed build steps, with network access to download various sources.
They produce data that must match a pre-fixed hash, so the lack of sandboxing cannot be exploited to result in nondeterministic output.</p>

<p>The big problem with this is that if the URL becomes inaccessible or the data downloaded is non-deterministic (e.g. due to some metadata), this build step will fail —
in other words, we are facing the exact same problems around linkrot IPFS is trying to solve with the web in general!
The IPFS solution is the right one —
we shouldn’t be relying on the <em>location</em> at which some source code was originally uploaded.
And we’re already identifying source code by content addresses, so IPFS solution isn’t even a huge leap from our existing tooling and community practices.</p>

<p>Yes, we can already pin and cache the results of those fixed-output build steps just as we do with regular build steps, but we’re stuck with our own cache of source code completely independent from what upstream offers.
It is tedious and inefficient for users of Nix to each maintain their own uncooperative caches of source code, and even more so for the downstream user who would have to manually configure each of the caches individually, when all they want is some source code that is self-authenticating due to the content-address.</p>

<h2 id="value">Value</h2>

<p>For the Nix community at large, we finally have a chance to leverage our hard work on reproducibility and make it a practical reality.
Rather than relying on our centralized <a href="https://cache.nixos.org/">cache.nixos.org</a> to build artifacts before sources rot away, everyone should feel free to use Nixpkgs as a source or binary distro—as was originally intended.</p>

<p>For users of Obsidian’s open-source software specifically, they finally have an easy and robust way to trust neither our own pre-built binaries or <strong>cache.nixos.org</strong>’s, but build everything from source, which makes auditing security-critical code easier.</p>

<p>Ideally, we want to cache and distribute source code in collaboration with the upstream developers themselves and other downstream distributions.
<a href="https://ipld.io/">IPLD</a>, more than any other schema we’ve seen, understands the value of addressing data with its original intended “native” references, rather than some bespoke 3rd-party format that others cannot understand.</p>

<p>We think this is the key to enable that cooperation.
Upstream devs can simply continue working with git repos (or any other version control system with content-addressing that IPLD supports).
Downstream distros consume that data directly, without any conversion steps that obscure the data’s authenticity.
Neither party is faced with doing chores that the other used to handle.</p>

<h2 id="scope">Scope</h2>

<p>We aim to address these problems in two distinct phases.</p>

<h3 id="milestone-1-distribution-with-ipfs">Milestone 1: Distribution with IPFS</h3>

<p>We wanted Nix to be able to use IPFS as a “substituter” or provider of source/build artifacts alongside the other sorts of substituters that exist today.</p>

<p>As part of this, we taught Nix git tree hashing, so it can content-address git repos in a way IPFS will understand —
which helps IPFS, Nix, upstream collaborators, and other parties with an interest in archiving and disseminating source code find a common way to reference these artifacts.
While the git hashing scheme has its limitations, we think it is the best method for multi-party collaboration on git data.</p>

<p>Looking ahead to using IPFS for build products and deployments, we also added support for a metadata format around git tree hashing for IPFS and Nix to also convey data with run-time dependencies between separately-installed file system trees.
Finally, we provide a way for existing Nix build artifacts to be converted to this new data format.</p>

<h3 id="milestone-2-building-with-ipfs">Milestone 2: Building with IPFS</h3>

<p>Nix doesn’t actually content-address data produced by regular build steps (as opposed to the “fixed output” build steps described above).
Instead, it addresses them based on the plan from which they were made.</p>

<p>Situations exist — such as when someone edits a comment — where the plan changes but the results don’t.
Besides causing extra rebuilding downstream, this muddles the separation between the raw data and its provenance.
With peer-to-peer systems, it doesn’t matter who is <em>providing</em> the data (and we want to take advantage of that not mattering), but it absolutely does matter who is <em>claiming</em> what the data represents.</p>

<p>With this core improvement, we can make new improved versions of build plans in IPLD and produce our newly supported IPFS-compatible formats directly from each build step, no manual conversions from legacy input-addressed data needed. This final step brings everything from both milestones together.</p>

<p>For a complete breakdown, visit our <a href="https://github.com/ipfs/devgrants/blob/master/open-grants/open-proposal-nix-ipfs.md">open grant proposal</a>.</p>

<h2 id="what-was-accomplished">What was accomplished</h2>

<p>We’re happy to announce completion of Milestone 1! In response to community feedback, we were also able to do some extra work to get the Nix community started on using IPFS before migrating to the ideal git tree hashing.</p>

<p>This neatly lays the groundwork for some of our Milestone 2 objectives.
We hope this step can help everyone transition to using IPFS more gracefully.</p>

<p>Get started using our <a href="https://github.com/obsidiansystems/ipfs-nix-guide/">guide repo</a> and, in particular, our <a href="https://github.com/obsidiansystems/ipfs-nix-guide/blob/master/tutorial.md">tutorial</a>.</p>

<p>Finally, we recently did an interview on the <a href="https://zimbatm.com/NixFriday/">Nix Friday</a> stream going over all our work, and also discussing more broadly how we see the IPFS and Nix ecosystems fitting together.
You can watch a recording <a href="https://www.youtube.com/watch?v=FievtzvDbs82">here</a>:</p>


<p>
  <iframe src="//www.youtube.com/embed/FievtzvDbs8" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h2 id="what-s-next">What’s Next?</h2>

<p>We’ve begun implementing Milestone 2, including the improved build steps that produce content-addressed data.
We expect this to be the bulk of the work, with the final IPFS integration being relatively smooth, as by that point the concepts of Nix and IPFS will align so neatly!</p>

<p>We’ve been fastidious about juggling many branches to separate feature work from general improvements of the internals, and thus have been able to upstream many of those improvements.</p>

<p>We like this approach because it allows us to continuously engage with the community, and leaves much more readable diffs for the features themselves.</p>

<p>We hope you can give the demo a spin and like what you see.
Stay tuned for milestone 2!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621276</guid>
            <pubDate>Mon, 28 Sep 2020 21:13:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The SaaS website content you need to close sales]]>
            </title>
            <description>
<![CDATA[
Score 364 | Comments 53 (<a href="https://news.ycombinator.com/item?id=24621132">thread link</a>) | @franciscassel
<br/>
September 28, 2020 | https://www.mikesonders.com/saas-website-content/ | <a href="https://web.archive.org/web/*/https://www.mikesonders.com/saas-website-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>The beauty of using keyword research to do market research is that we can literally uncover and quantify <em>exactly</em>&nbsp;what information a specific audience is looking for.</p>



<p>In this case, <strong>I’ve analyzed the online searches of thousands of B2B SaaS buyers to uncover exactly&nbsp;what information they want when considering a SaaS purchase.</strong></p>



<p>Based on the results, I can confidently say your SaaS website probably isn’t delivering everything SaaS buyers need. </p>



<p>I’m going to share the results of my analysis, and then show you how to translate the results into SaaS website content that answers prospect questions, addresses their objections, and gives them the confidence to purchase.</p>



<p>So if you’re ready to pave the way for more leads and revenue, let’s get started.</p>



<h3><strong>Contents</strong></h3>



<ul><li><a href="#quick">A quick note on methodology</a></li><li><a href="#results">The results: What SaaS buyers are searching for</a></li><li><a href="#best">Best practices: Creating the website content SaaS buyers want</a></li><li><a href="#method">Methodology &amp; raw data</a></li></ul>



<p>The recommendations in this post assume you’ve found product-market fit. Otherwise, building out your website content perhaps shouldn’t be at the top of your list of concerns.</p>



<h2 id="quick">A quick note on methodology</h2>



<p>If you’d like to see my full research methodology, you can <a href="#method">jump to the Methodology section</a> at the end of the post.</p>



<p>In short: I selected ten well-known B2B SaaS brands from among the <a href="https://www.mikesonders.com/largest-saas-companies/">largest SaaS companies</a> in the world. I then identified the ~16K branded searches (e.g., “hubspot pricing”, “servicenow login”, “zendesk support”, etc.) that people enter into Google to search for information on these brands.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image1-1024x248.png" alt="Branded keyword modifiers" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image1.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image1-300x73.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image1-768x186.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Among those ~16K branded search terms, I analyzed their modifiers to find the ones common to most of the ten SaaS brands. Of those common modifiers, I identified the ones that searchers use when considering a potential SaaS purchase.</p>



<p>E.g., “hubspot pricing” is a search that a potential buyer would use when considering a purchase; “hubspot investor relations” and “hubspot login” are not.</p>



<p>That is, <strong>I uncovered the search terms SaaS buyers use most commonly in the “consideration” phase of the buyer journey</strong>&nbsp;— when they’re gathering the information they need to decide (1) whether to make a purchase (i.e., convert) and (2) which vendor will get their money.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image11.png" alt="SaaS conversion funnel" width="550" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image11.png 788w, https://www.mikesonders.com/wp-content/uploads/2020/09/image11-300x236.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image11-768x604.png 768w" sizes="(max-width: 788px) 100vw, 788px"></figure></div>



<p>Using median search volumes, I indexed the relative demand for the information implied by each “consideration” modifier.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image6.png" alt="Branded search terms for SaaS reviews" width="550" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image6.png 804w, https://www.mikesonders.com/wp-content/uploads/2020/09/image6-300x193.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image6-768x495.png 768w" sizes="(max-width: 804px) 100vw, 804px"><figcaption><em>The median search volume for “reviews” keywords is 225.</em></figcaption></figure></div>



<h2 id="results">The results: What SaaS buyers are searching for </h2>



<h3>Pre-sale</h3>



<p>Search volumes for SaaS pricing information are so high–more than nine times higher than searches for “alternatives”–that including&nbsp;pricing data would have blown out the scale of a consolidated chart.</p>



<p>So, I show here the results across two charts, indexing to the demand for “alternatives” information in both:</p>



<figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info.png 994w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info-300x93.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info-768x238.png 768w" sizes="(max-width: 994px) 100vw, 994px"></figure>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1.png 1020w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1-300x296.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1-768x757.png 768w" sizes="(max-width: 1020px) 100vw, 1020px"></figure></div>



<p>It’s no coincidence that this chart looks like a bisected funnel.</p>



<p>Generally speaking, most buyers start their journey at the top of this list (with pricing) and proceed downward. As buyers fail to find satisfactory information that matches up with their needs, they fall out of the funnel.</p>



<p>For example:</p>



<ul><li>If the price is out of budget range, they’re going to be much less interested in getting a demo.</li><li>If the demo goes poorly (or simply shows that the solution doesn’t their your requirements), there’s not much reason to explore integrations.</li><li>If the solution doesn’t offer the specific integrations they need, getting a free trial is likely moot.</li></ul>



<p>The path of the B2B buyer journey certainly varies. Still, this chart paints a clear picture regarding the relative importance of different features, resources, and information SaaS buyers are seeking.</p>



<p>Correspondingly, <strong>you can use these data to prioritize the content (and features!) you create to keep buyers in your funnel and convince them that you’re the best solution</strong>.</p>



<p>Please note: it’s not that lower relative demand for certain information (e.g. “free trial) means that the information isn’t important. (Offering a free trial, if possible, is very important!) To some degree, it simply means there are fewer prospects left in the funnel at that stage seeking that information.</p>











<h3 id="post">Pre- and post-sale</h3>



<p>There’s a set of your resources–like your API documentation or support site–that your existing customers will Google instead of trying to find on your site.</p>



<p>So, it’s not <em>just</em>&nbsp;potential buyers creating the search demand for the following terms.</p>



<p>But I know from <a href="https://www.mikesonders.com/about/">my experience</a>&nbsp;that SaaS buyers oftentimes want to make sure these resources are available before they’ll pull the trigger on any purchase. &nbsp;&nbsp;</p>



<p>And (robustly) <strong>providing these resources is not only an excellent way to close more sales — it sets your customers up to succeed with your product, thereby improving your retention rates</strong>.</p>



<figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post.png 876w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post-300x292.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post-768x747.png 768w" sizes="(max-width: 876px) 100vw, 876px"></figure>



<p>In the next sections, I’ll show you best practices for putting these data into action as compelling content on your website.</p>



<h2 id="best">Best practices: Creating the website content SaaS buyers want</h2>



<h3 id="h.eaif2yj0bxlo">Pricing</h3>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image17-1024x647.png" alt="Help Scout pricing page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image17.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-300x190.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-768x486.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-1536x971.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>It makes sense that there’s a steep drop-off in demand for pricing information versus any other purchase-consideration information.</p>



<p>Pricing information is among the easiest to find on a SaaS website, and it’s a very straightforward litmus test that kicks off (or puts an abrupt stop to) the buying process:</p>



<p><em>Is the price low enough for me to consider, or is it so expensive that I shouldn’t even bother continuing to look into this solution?</em></p>



<p>Pricing can also put off potential buyers when it’s too confusing or when it’s simply missing from the website.</p>



<h4 id="h.fv29gmntzagy">Confusing pricing</h4>



<p>Do your pricing plans <a href="https://twitter.com/mikesonders/status/1285643715554549760" target="_blank" rel="noopener noreferrer">compare apples to apples</a>? Your mileage will vary, but I’ve helped clients <a href="https://twitter.com/mikesonders/status/1257751045729595394" target="_blank" rel="noopener noreferrer">double conversion rates</a>&nbsp;by simply clarifying their pricing pages. (Those links point to threads of mine on Twitter where I provide more details.)</p>



<h4 id="h.tgobcgqit9vl">Missing pricing</h4>



<p>You might (or might not) have good reasons for not providing pricing information on your website.</p>



<p>To avoid unnecessarily driving away prospective customers, <a href="https://businesscasualcopywriting.com/show-pricing-on-website/" target="_blank" rel="noopener noreferrer">consider these alternative approaches</a>&nbsp;formulated by <a href="https://twitter.com/JoelKlettke" target="_blank" rel="noopener noreferrer">Joel Klettke</a>.</p>



<h3 id="h.xvesd4pfueqe">Alternatives</h3>



<p>It makes logical sense that someone considering a meaningful purchase would want to uncover and evaluate all the appropriate alternatives.</p>



<p>That’s why a lot of people in the beginning of the SaaS buyer journey Google things like “[brand] alternative”, “[brand] competitors”, and “alternatives to [brand]”.</p>



<p>In the SaaS world, the search results for these queries tend to be dominated by listicles from the software comparison sites like Capterra, G2, and TrustRadius.</p>



<p>So your most important step is to <strong>make sure your app has a profile on the comparison sites that appear when someone searches on “[your_brand] alternatives”</strong>. And, of course, populate those profiles with positive reviews from customers — which I’ll discuss in a section below.</p>



<p>You should also consider or experiment with paying for better surfacing of your app on those comparison sites. It’s not uncommon for paid campaigns like these to be a top source of leads for SaaS startups.</p>



<p><strong>You can (and should) rank a page from your own site for these “alternatives” queries</strong>, <strong>whether someone is searching for alternatives to your brand, or to one of your competitors.</strong></p>



<p>I recommend following both of these methods:</p>



<h4 id="h.x05igpe9c7lt">The Best [Competitor] Alternative</h4>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image22-1024x512.png" alt="Plivo best alternative page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image22.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-300x150.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-768x384.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-1536x768.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Create a page on your marketing site or blog that positions your solution as the “Best [Competitor] Alternative”, where [Competitor] is a well-known brand in your vertical against whom you can position yourself effectively. &nbsp;</p>



<p>Start with the most well-known of your competitors, as more people will be searching for alternatives for them.</p>



<p>Here are a few examples of pages that follow this method and rank among the top search results for their respective “[competitor] alternatives” searches:</p>



<ul><li><a href="https://www.plivo.com/twilio-alternative/" target="_blank" rel="noopener noreferrer">Twilio Alternative | The best alternative to Twilio API | Plivo</a></li><li><a href="https://www.salesmate.io/pipedrive-crm-alternative/" target="_blank" rel="noopener noreferrer">One Of The Best Pipedrive Alternatives | Salesmate CRM</a></li><li><a href="https://supportbee.com/zendesk-alternative" target="_blank" rel="noopener noreferrer">A simpler, and smarter Zendesk alternative – SupportBee</a></li></ul>



<h4 id="h.z4bgyoba3kj">[Your_brand] Alternatives</h4>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image26-1024x742.png" alt="Jira alternatives page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image26.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-300x218.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-768x557.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-1536x1114.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Yes, <a href="https://www.atlassian.com/software/jira/comparison" target="_blank" rel="noopener noreferrer">like JIRA</a>, you can have a page on your site that lists your competitors.</p>



<p>Why?</p>



<p>One, prospective buyers are going to discover your competitors, anyway.</p>



<p>Two, when someone is searching for alternatives to your solution, appearing in the search results at least gives you a chance&nbsp;to position yourself relative to your competition. To present your relative strengths and clarify your best-fit customer.</p>



<p>Otherwise, you’re letting your competitors or a 3rd-party site like Capterra define your positioning for you.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image4-1024x433.png" alt="JIRA alternatives search results" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image4.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-300x127.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-768x325.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-1536x650.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Atlassian has the fourth organic result when people search for alternatives to their product, JIRA.</em></figcaption></figure></div>



<p>Surprisingly, not many of the big SaaS brands–other than JIRA and <a href="https://www.salesforce.com/in/hub/crm/viable-salesforce-alternatives/" target="_blank" rel="noopener noreferrer">Salesforce</a>–have implemented this defensive strategy. &nbsp;</p>



<h3 id="h.r797chgho5xp">Demo</h3>



<p>Prospects want to see your solution in action. There’s a reason “Schedule a Demo” and similar are such common calls to action (CTAs) on SaaS websites–especially for sales-driven (vs. self-service) products.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image5-1024x609.png" alt="Churn Buster request a demo page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image5.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-300x178.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-768x457.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-1536x914.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>But maybe you’ve got a relatively low-priced solution and it doesn’t make sense to schedule live demos with every prospect.</p>



<p>In that case, consider recording a demo and posting the video to a “demo” page on your website.</p>



<p>And I’d recommend uploading that demo to YouTube and giving the video a straightforward title.</p>



<p>Search results for “[brand] demo” typically feature video packs, and those video packs sometimes appear even before the brand’s own, relevant website content.</p>



<p><strong>Having demo content on your website <em>and</em>&nbsp;on YouTube gives you a chance to own more real estate in search results</strong>, thereby giving you a better chance to own the narrative.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image23-1024x832.png" alt="Shartsheet demo in search results" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image23.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image23-300x244.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image23-768x624.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Smartsheet created demo content on both its website and on YouTube, allowing it to dominate the first search results for “smartsheet demo”.</em></figcaption></figure></div>



<h3 id="h.toefavd2jjr">Reviews</h3>



<p>In competitive industries, search results for “[brand] reviews” are dominated by the big review-aggregation sites like G2, Capterra, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikesonders.com/saas-website-content/">https://www.mikesonders.com/saas-website-content/</a></em></p>]]>
            </description>
            <link>https://www.mikesonders.com/saas-website-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621132</guid>
            <pubDate>Mon, 28 Sep 2020 20:56:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Field Guide to Genetic Programming (2008) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24620614">thread link</a>) | @optimalsolver
<br/>
September 28, 2020 | http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf | <a href="https://web.archive.org/web/*/http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620614</guid>
            <pubDate>Mon, 28 Sep 2020 19:53:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All DuckDuckGo bang operators on one page]]>
            </title>
            <description>
<![CDATA[
Score 403 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24618447">thread link</a>) | @MichaelMoser123
<br/>
September 28, 2020 | https://mosermichael.github.io/duckduckbang/html/main.html | <a href="https://web.archive.org/web/*/https://mosermichael.github.io/duckduckbang/html/main.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mosermichael.github.io/duckduckbang/html/main.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618447</guid>
            <pubDate>Mon, 28 Sep 2020 16:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repurposing my old Chromebook to a low power home server]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24617661">thread link</a>) | @boros2me
<br/>
September 28, 2020 | https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html | <a href="https://web.archive.org/web/*/https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="cant-sell-it-repurpose-it">Can’t sell it? Repurpose it!</h2>
<p>It was around 4 years ago when I bought a used, slightly beat up Asus C300 Chromebook from a friend of mine for £50. It served me well, I installed Linux on it and used it to work on some side projects while commuting. However as time passed by, I slowly forgot about it and it ended up in a box, being put away. I always thought it’s a shame to just let it sit there, but I don’t wanted to sell it for pennies and neither I wanted to throw it out as it is a perfectly fine machine for some lightweight tasks. I always had the idea to convert it to a home server (yes, with a 7W TDP Celeron N2830 CPU), but couldn’t really find a guide online that explains how to do it and neither I had the urge to do the experimenting myself, up until now.</p>

<h2 id="the-setup">The setup</h2>

<p><a href="https://tamas.dev/static/2020-09-28/chromebook.jpg" target="_blank"><img src="https://tamas.dev/static/2020-09-28/chromebook.jpg" alt="Chromebook home server"></a></p>

<ul>
  <li>1x Asus C300 Chromebook</li>
  <li>1x 128GB USB drive</li>
  <li>1x vertical stand</li>
  <li>1x GalliumOS installed</li>
</ul>

<p>In order to run a generic home server, I knew ChromeOS will just not cut it, it has to be proper Linux. The distribution didn’t really matter as I was going to use Docker anyways (and docker-compose) to run all server applications in containers. Fortunately I already had experience installing GalliumOS, therefore it became my distribution of choice. GalliumOS is an Ubuntu based distro, specifically created to be running on ChromeOS devices. I had to update the firmware on my Chromebook (it’s a very simple, less than 10 steps process) then install the OS using a tool called chrx (another 2-3 steps). Once done, I was able to dual boot my Chromebook and got a fully operational Linux laptop.</p>

<h2 id="software-configuration">Software configuration</h2>

<p>Once I had the OS up and running, I wanted to configure it so I can use it in closed-display (clamshell) mode as leaving it running with the display open wouldn’t be too practical. I knew MacBooks had these option, but I also knew you had to have an external display and keyboard/mouse connected to it in order to make it work. Luckily with Linux, the only limit is your imagination (and your coding/Google-ing skills)! Since GalliumOS is Ubuntu based as mentioned before, I was certain there are people using Ubuntu who want their system to stay awake even after they shut the display. And I was not wrong. Simply editing <code>logind.conf</code> and turning off all power savings and auto-sleep functions through the GUI did the job.</p>

<p>The next thing I had to install was sshd, but thanks to this Reddit post I found out it was as simple as <code>apt install</code>-ing it (again, it’s basically a skinny version of Ubuntu). Left all settings to default, then I SSH-ed from another box. All went smooth, I logged in from the remote machine, started <code>htop</code> and closed the lid to see that the configuration actually works! I left the connection open for about an hour, just to be 100% sure no sleep mode will kick in, then I considered the project a success. Was much smoother than I anticipated.</p>

<h2 id="servers-n-containers">Servers ‘n containers</h2>

<p>Although I would <strong><em>not recommend</em></strong> running any production workload on a <em>Chromebook</em> via <em>Wifi</em> connection, it’ll serve perfectly fine as my home cron/CI server, especially knowing it can run on batteries for 10 hours (allegedly), without having a UPS. Following the documentation I installed Docker with no problem whatsoever and docker-compose as well. I also plugged in a tiny 128GB USB thumb drive I found laying around on my desk, as the built in eMMC is not the most spacious storage ever made. I re-formatted the drive to ext4, then mounted and finally updated Docker to use the partition on the USB device for data storage, which includes all containers, volumes, etc.
In case you’re curious, please see the list of the containerised servers I used with some explanation to the whys below.</p>

<h3 id="portainer">Portainer</h3>

<p>Website: <a href="https://www.portainer.io/">https://www.portainer.io/</a></p>

<p>Portainer provides a very user-friendly way to manage containers on remote boxes. Via a web interface, it provides information about resource utilisation, logs, etc. for each container.</p>

<h3 id="grafana--influxdb--telegraph">Grafana + InfluxDB + Telegraph</h3>
<p>Grafana website: <a href="https://grafana.com/">https://grafana.com/</a></p>

<p>InfluxDB website: <a href="https://www.influxdata.com/">https://www.influxdata.com/</a></p>

<p>Telegraf website: <a href="https://www.influxdata.com/time-series-platform/telegraf/">https://www.influxdata.com/time-series-platform/telegraf/</a></p>

<p>I use this combo to monitor average packet loss, ping, DNS query time, CPU temperature and CPU/Memory/Disk utilisation.</p>

<h3 id="jenkins-ci">Jenkins CI</h3>
<p>Website: <a href="https://www.jenkins.io/">https://www.jenkins.io/</a></p>

<p>I use Jenkins for all the cron/CI jobs I have, to build/deploy and run automated tests on some of my side projects.</p>

<h3 id="sonatype-nexus">Sonatype Nexus</h3>
<p>Website: <a href="https://www.sonatype.com/nexus/repository-oss">https://www.sonatype.com/nexus/repository-oss</a></p>

<p>To cut back on network utilisation, I’ve set Nexus up as well as a local docker/npm/pypi cache.</p>

<h3 id="future-improvements">Future improvements</h3>
<p>I’ll stop at this point as I reached my goal with this project (as always, the journey was more important than the result itself), this little device has loads of potential with it’s 2x USB ports, a full size HDMI port and even an audio jack. At the end of the day, I feel much better to put this neat little tech in use, and convinced myself I don’t need to buy <em>yet another</em> RaspberryPI for a future project that’ll never come.</p>

<hr>

<p>Resources used:</p>

<p><a href="https://uk.store.asus.com/asus-chromebook-c300ma-13-3-light-weight-laptop-intel-dual-core-2gb-32gb-emmc.html">ASUS Chromebook C300</a></p>

<p><a href="https://ark.intel.com/content/www/us/en/ark/products/81071/intel-celeron-processor-n2830-1m-cache-up-to-2-41-ghz.html">Intel Celeron N2830</a></p>

<p><a href="https://galliumos.org/">GalliumOS</a></p>

<p><a href="https://wiki.galliumos.org/Installing">Installing GalliumOS</a></p>

<p><a href="https://chrx.org/">chrx</a></p>

<p><a href="https://askubuntu.com/a/372616">How can I tell Ubuntu to do nothing when I close my laptop lid?</a></p>

<p><a href="https://www.reddit.com/r/GalliumOS/comments/5b7vwi/does_galliumos_not_come_with_ssh_abilities/d9mx0ie/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">Does GalliumOS not come with ssh abilities installed?</a></p>

<p><a href="https://stackoverflow.com/a/52018760">How to change the default location for “docker create volume” command?</a></p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617661</guid>
            <pubDate>Mon, 28 Sep 2020 15:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Y Combinator worth it?]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24616649">thread link</a>) | @gk1
<br/>
September 28, 2020 | https://drodio.com/our-ycombinator-experience/ | <a href="https://web.archive.org/web/*/https://drodio.com/our-ycombinator-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://drodio.com/content/images/size/w300/2020/09/IMG_1431.jpg 300w,
                            https://drodio.com/content/images/size/w600/2020/09/IMG_1431.jpg 600w,
                            https://drodio.com/content/images/size/w1000/2020/09/IMG_1431.jpg 1000w,
                            https://drodio.com/content/images/size/w2000/2020/09/IMG_1431.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://drodio.com/content/images/size/w2000/2020/09/IMG_1431.jpg" alt="Is Y Combinator worth it?">
            </figure>

            <section>
                <div>
                    <p>Back in late 2016, I started <a href="http://www.armory.io/">Armory </a>in my garage (pictured above) with my two co-founders. We also applied to Y Combinator. I often have founders ask me if YC is worth it right around now, during YC application season. </p><p>The short answer is <code>Yes, you should at least apply to see if you get in.</code> The longer answer is <code>It depends a lot more on <em>you </em>than YC (kind of like asking "is exercise worth it?").</code> Armory participated in the Winter 2017 batch, as well as the Fall 2019 Growth program.</p><p>YC is not just one thing. It's a series of people, experiences and resources that scale with your company as it grows. Here's a detailed look into what's been valuable, and what you can do to get full value from YC:</p><h2 id="optimizing-our-initial-w17-yc-batch-experience-">Optimizing our initial W17 YC &nbsp;batch experience:</h2><ul><li>YC's biggest initial benefit is that it creates intense focus in a short period of time, and at the end of the program, YC has nailed product-market-fit to help you pick up a good sized initial investment via Demo Day. If you hit it hard, you won't have any problem raising money. That alone is very valuable in the early stages of a startup's life, and it's a self-reinforcing cycle: The more initial traction you have, the more investment you can quickly pick up (and vice versa).</li><li>We secured several million dollars in SAFE notes in the span of a couple of days after demo day – and we could have picked up more if we'd wanted to. More on that below. It helps to be organized because you'll have to prioritize and manage a lot of investor interest in a short period of time. </li></ul><blockquote>I'd recommend using a Trello board like the one below to manage investor interest (you can <strong><a href="https://trello.com/b/jsHJLVMB/ycombinator-demo-day/drodio/recommend">make a copy of it here</a></strong>). This board is also valuable for future rounds; I used a variation of it for Armory's Series A and B as well <em>(that's a whole other blog post; LMK if you'd like me to write it).</em></blockquote><!--kg-card-begin: html--><p><img src="https://p-qkfvwn.b3.n0.cdn.getcloudapp.com/items/xQuL5Bz9/Screen%20Recording%202020-09-11%20at%2003.41.17%20PM.mp4" width="800"></p><!--kg-card-end: html--><ul><li>If you decide to apply to YC, the #1 piece of advice I can provide is <code>Show, Don't Tell.</code> The more you can show YC that you've already got early traction, the more likely it is that your application will be accepted for an interview, and that you'll get in (or at least invited back for a 2nd interview.) And it's good practice to focus on getting early, external validation, because that's what you'll be doing non-stop once you get into YC. Nicolae has <a href="https://medium.com/@nicolaerusan/modeling-what-startup-growth-actually-looks-like-73cc4720230e">a good breakdown here</a> of the 5% to 6% <em>weekly</em> growth that you should be targeting. The YC batch experience is an intense experience where you identify your top growth metric, focus on optimizing it, measure your results, and then do <em>whatever it takes </em>to unblock that growth. Rinse and repeat each week with all the founders around you doing the same thing. &nbsp;</li><li>You're more likely to be accepted if you are not a solo founder. I personally like the "hacker and hustler" combo for the fastest growth iterations &amp; unblocking. If you're afraid of getting strong external signals of validation for an MVP product, you won't do well in YC. One of my favorite sayings is <code>perfectionists are <em>imperfect </em>with their time.</code> And time is in short supply, with the Demo Day clock looming from the very first day of the program. A few other very appropriate sayings: <code>Build the right thing fast, instead of the wrong thing right,</code> and <code>There's <em>always </em>one more thing you can do [to increase growth]. And after that, there's <em>one more thing</em>.</code> I find that often, people are their own enemies when it comes to the headspace you need to be in to be a successful YC founder. Don't doubt yourself. Believe in your ability to create value. And don't be shy about being relentless in pursuing that external validation to prove it.</li></ul><p>Below is Armory's Demo Day video from 2017. I've blurred out some of our early customer names, but other than that, it's the full video. This is the first time it's been shown publicly. We spent the YC batch program getting our first customers to sign contracts (the "hustler" piece) while we built out the first version of Armory's platform (the "hacker" piece), which is built using an open source continuous software delivery project called <a href="http://www.spinnaker.io/">Spinnaker</a>. By the time Demo Day rolled around, we had multiple paid customer commitments and could articulate a long-term vision for Armory<em> (which has remained largely unchanged since our early days in the garage – that's also a whole other blog post!).</em> I've heard people say there's $100 Billion worth of VC funds in the room for YC Demo Day. I can believe that, and I wouldn't be surprised if it's well over that. </p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/IvZjbN2kil0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><ul><li><strong>Other things we did well: </strong>YC has guest speakers come speak once weekly at dinner during the program, and there are really valuable nuggets of wisdom shared during those dinners. For example, Lyle Fong, the founding CEO of Lithium, gave a talk at a dinner about how he had to educate CMOs on the kind of social media platform Lithium was, so he made a maturity model diagram. That sparked Armory's creation of this "<a href="http://go.armory.io/stages">Stages of Software Delivery</a>" diagram, which we've used extensively to help Global 2,000 enterprises understand what their future pain points will be as they adopt the cloud, as well as the benefits they can expect to garner.</li><li><strong>Things we could have done better: </strong>We've never utilized YC Office Hours as effectively as we could have. There are YC partners and domain experts that make themselves available to talk through challenges a business is having. I recommend leaning into that more than we did.</li></ul><h2 id="optimizing-yc-s-growth-program-ycg-f19-">Optimizing YC's Growth Program (YCG F19):</h2><figure><img src="https://drodio.com/content/images/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg" alt="" srcset="https://drodio.com/content/images/size/w600/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 600w, https://drodio.com/content/images/size/w1000/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 1000w, https://drodio.com/content/images/size/w1600/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 1600w, https://drodio.com/content/images/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 2388w" sizes="(min-width: 720px) 720px"></figure><p>In the fall of 2019, I participated in the "graduate" YC program, for YC companies that are scaling. I consider this program to be even more valuable than the initial YC batch experience. It's more intimate – our group was about 15 CEOs – and everyone is dealing with (or has just dealt with) the same types of issues. If the first YC batch experience is about figuring how to drive relentless early traction and growth, the YC growth program is about figuring out how to scale that growth, in every sense of the word – how to scale your functions, your executives, your culture, your size, your<em>self</em>. And the vibe is entirely different: In the early YC batch days, you're just trying to make your startup <em>become relevant and survive.</em> But in the Growth program, it's clear that all the startups who have made it this far are solving a real problem for the world, and have a lot of growth in front of them. And the problems are much more abstract – more about how to align <em>people and processes </em>to scale the magic that's made the business get this far. I've made some incredible, true friendships from this group, and we continue to help each other via WhatsApp and meet on a regular basis. </p><ul><li>My #1 tip is to capture as much of the content as you can to share in permissioned ways with your executive team and managers. By the time you participate in this program, your company will have grown well beyond just the founders. Many of the great tips you'll hear will come from the dinners you attend, as well as how your fellow CEOs have managed similar issues. I highly recommend <a href="http://go.armory.io/Otter">installing Otter.ai on your phone</a> so you can ask the person sharing pro-tips if you can record it and make an auto-transcript to share with your execs. I did this a bunch during the program <em>(Oleg, I'm looking at you, buddy!).</em></li></ul><p>If you have the chance to do the YC Growth program, you should absolutely do it. <em>(I'll invite the CEOs from our batch to leave more thoughts in the comments below).</em></p><h2 id="the-big-thing-to-understand-about-yc-before-you-join-">The big thing to understand about YC <em>before </em>you join:</h2><p>So yes, YC is very much worthwhile. What you get out of YC will very much be dependent on what you put into it. I haven't even mentioned the internal YC forum (cheekily called "BookFace") where several thousand YC alums serve as a resource for each other, as well as YC's <a href="https://www.workatastartup.com/">Work at a Startup</a> recruiting tool, the private VC resource rating directory, YC's <a href="https://blog.ycombinator.com/ycs-series-a-guide/">Series A program</a>, and other similar resources. &nbsp;</p><p>Here's the main thing you need to understand before you apply: YC has <a href="https://www.ycombinator.com/deal/">a "standard deal"</a> where they take a 7% stake in your company. YC also gets pro-rata rights in future funding rounds. If your company is really successful, you may find yourself in a position where you need to negotiate some of those pro-rata rights in order to make the round work (i.e., make enough room to accomodate new new investor demand). While YC will do its best to work with you based on your specific situation, you need to understand that you're signing up for a standard deal up-front, and that early seed-stage commitment may upset other investors. Other angel/seed/Series A investors can become unhappy when having to live on a cap table alongside YC.</p><p>Hope that helps! Feel free to ask any questions in the comments – and if you're also a YC alum, please share your pro-tips as well!</p>
                </div>
            </section>


            

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://drodio.com/our-ycombinator-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616649</guid>
            <pubDate>Mon, 28 Sep 2020 13:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zig's New Relationship with LLVM]]>
            </title>
            <description>
<![CDATA[
Score 442 | Comments 283 (<a href="https://news.ycombinator.com/item?id=24615916">thread link</a>) | @todsacerdoti
<br/>
September 28, 2020 | https://kristoff.it/blog/zig-new-relationship-llvm/ | <a href="https://web.archive.org/web/*/https://kristoff.it/blog/zig-new-relationship-llvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>While not yet at version 1.0, Zig is about to reach a new level of maturity and stability.</p><div><p>In the early days, Zig was but a thin frontend in front of LLVM. This was instrumental for getting started quickly and filling in gaps of Andrew’s knowledge as a compiler developer. Now, the training wheels of the bicycle are coming off, and LLVM is transitioning into an optional component.</p>
<p><span>
      <a href="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/98017/protty1.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/f5e3c/protty1.webp 100w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/f2fbe/protty1.webp 200w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/e227a/protty1.webp 400w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/efddf/protty1.webp 441w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c0399/protty1.png 100w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/9ec3c/protty1.png 200w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c7805/protty1.png 400w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/98017/protty1.png 441w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c7805/protty1.png" alt="protty1" title="protty1">
      </picture>
  </a>
    </span></p>
<p>The work to replace the current C++ compiler implementation with a new pure Zig version has begun. Moving to a self-hosted implementation is usually considered a step towards maturity, with most benefits being felt by developers of the language itself. As an example, <a href="https://www.youtube.com/watch?v=cF1zJYkBW4A" target="_blank" rel="nofollow noopener noreferrer">Go lost</a> some speed of compilation by switching to the self-hosted compiler but, in exchange, it streamlined the toolchain, removed dependencies, and improved the whole development experience.</p>
<p>The move to a self-hosted compiler for Zig has similar advantages for the core contributors, but it also <strong>makes LLVM an optional dependency</strong>, <strong>increases compilation speed</strong> (instead of losing it), and adds an amazing feature for debug builds of your code: <strong>incremental compilation with in-place binary patching</strong>, <a href="https://kristoff.it/blog/what-is-zig-comptime/">another</a> <a href="https://kristoff.it/blog/zig-colorblind-async-await/">unique</a> Zig feature.</p>
<h2 id="speeding-up-compilation"><a href="#speeding-up-compilation" aria-label="speeding up compilation permalink"></a>Speeding up compilation</h2>
<p>Most languages offer some form of caching to speed up compilation, starting from C’s compilation units, up to modules, packages, and other comparable boundaries in more modern languages.</p>
<p>Zig also implements a caching system that comes particularly handy when building a project that mixes C and Zig source code, or when using Zig as a C compiler with the <code>zig cc</code> command. Zig keeps track of all the files involved in the compilation, so it can very easily know when an object file can be reused, and this is <a href="https://andrewkelley.me/post/zig-cc-powerful-drop-in-replacement-gcc-clang.html" target="_blank" rel="nofollow noopener noreferrer">only one of the advantages</a> of using Zig to compile C code.</p>
<p>Zig sources always get bundled into a single compilation unit, so the caching system in its current form doesn’t provide any speedup when editing and recompiling a pure Zig project. The upside is that, not only compiling Zig code is very fast, but also that incremental compilation will provide smart caching for Zig code, more than making up for what we can’t get from simple caching.</p>
<h2 id="incremental-compilation"><a href="#incremental-compilation" aria-label="incremental compilation permalink"></a>Incremental compilation</h2>
<p>Incremental compilation is a form of caching that acts at a higher granularity level than normal “compilation unit”-level caching. The Rust blog has a <a href="https://blog.rust-lang.org/2016/09/08/incremental.html" target="_blank" rel="nofollow noopener noreferrer">great post</a> that explains how it works.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/d4d70/rust.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/f5e3c/rust.webp 100w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/f2fbe/rust.webp 200w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/e227a/rust.webp 400w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/965c5/rust.webp 600w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/0cbce/rust.webp 800w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/16e88/rust.webp 964w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c0399/rust.png 100w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/9ec3c/rust.png 200w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c7805/rust.png 400w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/34e8a/rust.png 600w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/8ff1e/rust.png 800w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/d4d70/rust.png 964w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c7805/rust.png" alt="rust" title="Taken from the Rust blog post linked above.">
      </picture>
  </a>
    </span>
    <figcaption>Taken from the Rust blog post linked above.</figcaption>
  </figure>
<p>In the case of Rust, the compiler builds a dependency graph at the AST level and then saves it to disk alongside the cached intermediate results (object files). When a new compilation is requested, the compiler will be able to easily notice which parts of the AST have changed and thus invalidate all the intermediate results that depend on it.</p>
<p>One important detail about this graph is the fact that the right-most box is always invalidated. In other words, the final executable is always re-linked from scratch starting from a mix of old and newly generated object files. It’s clear that this has to be the case, since the final executable depends on everything else and so any meaningful change to the code will invalidate it, but this is where the Zig self-hosted compiler brings a new ingenious idea to the table.</p>
<h2 id="in-place-binary-patching"><a href="#in-place-binary-patching" aria-label="in place binary patching permalink"></a>In-Place Binary Patching</h2>
<p>As of Zig version 0.6.0, regardless of the type of release (debug, release-safe, release-fast), there is always a final step delegated to <strong>LLVM, which takes at least 70% of the total compilation time</strong> including when compiling a debug build, where optimizations aren’t even enabled.</p>
<p><strong>The self-hosted compiler will not depend on LLVM for debug builds</strong> and will be able to cut compilation time considerably, <strong>basically reducing that 70% to almost zero</strong>, just by virtue of being a simpler piece of software compared to LLVM. </p>
<p>On top of that, since the compiler will have full control over the whole process, it will generate machine code using an ad-hoc strategy optimized for incremental compilation, allowing the compiler to patch the final executable in-place with the new changes. </p>
<p>In-place binary patching is based on a granularity of top-level declarations. Each global variable and function can be independently patched because the final binary is structured as a sequence of loosely coupled blocks. Another important characteristic is that all this information is kept in memory, so the compiler will stay open between compilations.</p>
<p> If you want to see the self-hosted compiler in action, here’s a 5 minute demo by Andrew:</p>

          <p>
            <iframe src="https://www.youtube-nocookie.com/embed/R5FKgi9BYyU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          </p>
          
<h2 id="designing-machine-code-for-incremental-compilation"><a href="#designing-machine-code-for-incremental-compilation" aria-label="designing machine code for incremental compilation permalink"></a>Designing machine code for incremental compilation</h2>
<p>Efficient in-place binary patching is something that can only be accomplished by tightly coupling the compiler frontend and backend. Part of the reason this feature is so rarely seen in the wild is that it goes against our better sense of abstraction and clean code organization. But we must never forget: abstraction is just a tool to reach a practical outcome, and not always the most appropriate one.</p>
<p>In order to perform in-place binary patching, we need code to be <a href="https://en.wikipedia.org/wiki/Position-independent_code" target="_blank" rel="nofollow noopener noreferrer">position independent</a>. This allows us to move it around in virtual memory when a function grows outside its allocated boundary. We also need to be able to reference virtual addresses indirectly, so that N callsites do not need to be updated when a function is moved to a new virtual address.</p>
<p>To accomplish this Zig uses a Global Offset Table for all function calls.</p>
<p>However, that only solves functions. There are more components to consider here, such as debug information. When we add new lines to a function, that modifies the debug information, which is used to print stack traces! Solving this involves creatively organizing an allocation scheme for debug line information, and figuring out how to do NOPs. Andrew’s journey here involved creating a <a href="http://dwarfstd.org/ShowIssue.php?issue=200803.1" target="_blank" rel="nofollow noopener noreferrer">proposal for a new DWARF line number opcode</a>.</p>
<p>This problem must be solved repeatedly for each kind of linking backend - ELF, DWARF, PE, PDB, MachO, and WebAssembly. Special thanks for the contributors who have stepped up and taken on the added challenge of supporting in-place binary patching: <a href="https://github.com/alexnask" target="_blank" rel="nofollow noopener noreferrer">Alexandros Naskos</a>, <a href="http://www.jakubkonka.com/" target="_blank" rel="nofollow noopener noreferrer">Jakub Konka</a>, and <a href="https://ifreund.xyz/" target="_blank" rel="nofollow noopener noreferrer">Isaac Freund</a>.</p>
<p>Be on the lookout for a more technical post on <a href="https://andrewkelley.me/" target="_blank" rel="nofollow noopener noreferrer">Andrew’s blog</a>, where he’ll dive into some of these fascinating details — <strong>including how this design gets us 90% of the way to hot code swapping!</strong></p>
<h2 id="when-is-it-going-to-be-ready"><a href="#when-is-it-going-to-be-ready" aria-label="when is it going to be ready permalink"></a>When is it going to be ready?</h2>
<p>The self-hosted backend is <a href="https://github.com/ziglang/zig/projects/2" target="_blank" rel="nofollow noopener noreferrer">still a work in progress</a>, but all the functionalities presented in this post have been designed and prototyped to the point where it’s just a matter of doing the methodical part of the work.</p>
<p>The self-hosted backend will ship in Zig 0.7.0 behind a flag, supporting only a subset of the Zig language. In the meantime, the core development team and a few other contributors are sprinting forward with more language support and additional targets. The current aim is to fully replace the C++ implementation with the self-hosted backend for Zig 0.8.0, roughly 7 months from now.</p>
<p>If you like where Zig is going, there’s no better time <a href="https://github.com/ziglang/zig/wiki/Community" target="_blank" rel="nofollow noopener noreferrer">to join the Zig community</a> than now, and if you want to help speed the development up, please <a href="https://ziglang.org/zsf/" target="_blank" rel="nofollow noopener noreferrer">consider donating to the Zig Software Foundation</a> to allow core developers to spend more time working on Zig.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/8eeed/protty2.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/f5e3c/protty2.webp 100w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/f2fbe/protty2.webp 200w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/e227a/protty2.webp 400w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/44d87/protty2.webp 407w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c0399/protty2.png 100w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/9ec3c/protty2.png 200w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c7805/protty2.png 400w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/8eeed/protty2.png 407w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c7805/protty2.png" alt="protty2" title="Thanks to kprotty for the cute doodles!">
      </picture>
  </a>
    </span>
    <figcaption>Thanks to kprotty for the cute doodles!</figcaption>
  </figure></div></div>]]>
            </description>
            <link>https://kristoff.it/blog/zig-new-relationship-llvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615916</guid>
            <pubDate>Mon, 28 Sep 2020 12:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alar: The making of an open-source dictionary]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24615530">thread link</a>) | @ronakjain90
<br/>
September 28, 2020 | https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>ನಮಸ್ಕಾರ (Namaskāra)! This is not a post on fintech, or even technology for that matter. This is the story of a product of tenacity, selflessness, and passion; a product that will transcend and outlive most technology we know of. This is the story of a massive dictionary that will become the window to a language spoken by tens of millions of people for generations to come, a resource its author has donated to posterity. This is the story of V. Krishna, <a href="https://alar.ink/"><em>Alar</em></a>, his Kannada-English dictionary, and its accidental discovery and open sourcing at an unlikely place, a stock brokerage, Zerodha. This post is also a personal note, something I have not attempted in a long time.</p><h3 id="prologue">Prologue</h3><p>I have been running <a href="https://olam.in/">Olam</a>, an English-Malayalam and Malayalam-Malayalam dictionary, since 2010. It was built out of the frustration of not having an easily accessible online Malayalam dictionary, of the frustration at dictionary websites that insulted the reader’s intelligence with poor usability, terrible ad-ridden spamminess, and no respect for language. Olam’s website has stayed exactly the same for 10 years. It has an input box that responds to dictionary lookups in under ~50ms, exactly as it did in 2010. It is actively used by millions of Malayalam speakers.</p><p>The first version of the Olam corpus was seeded with unattributed word lists I scraped together from random parts of the web, and several thousand entries I entered myself. Since then, the English-Malayalam dictionary has been expanding slowly with crowdsourced entries.</p><p>The entire Olam corpus is <a href="https://olam.in/open">open source</a> (licensed under <a href="https://opendatacommons.org/licenses/odbl/summary/">OdBL</a>), or open data, rather. While the English-Malayalam corpus is crowdsourced, the Malayalam-Malayalam corpus (now known as the <em>Datuk Corpus</em>) was created out of the mammoth digitisation project the late <a href="https://www.asianetnews.com/pravasam/datuk-kj-joseph-passes-away-pm1xdr">“Datuk” K. J. Joseph</a> undertook in the late 90s, when he single-handledly digitised an out-of-copyright Malayalam-Malayalam dictionary along with many other books and posted them online at the expense of copious amounts of time out of his retirement. He was a Malayali settled in Malaysia, a prominent active social worker and educator. The Malaysian government conferred the title “Datuk” upon him in recognition of his exemplary services in the country, which then ended up being his nickname too. I do not know of the origin of the dictionary Datuk digtised, but it is poignant to think that the original author’s work lives on after a century.</p><p>I discovered the RTF file Datuk had posted a decade prior on an inactive Yahoo groups page around the time I was working on Olam. Needless to say, I was stumped by the scope of this project, and immediately started working on integrating it into Olam. It took more than two years of on and off work to convert the text from the original ASCII input to Unicode, and to clean, structure, and correct close to 200,000 entries. The dataset was named <em>Datuk Corpus</em>, and was published on Olam in 2013. I wrote to the Swathanthra Malayalam Computing (SMC) mailing list <a href="http://lists.smc.org.in/pipermail/discuss-smc.org.in/2013-May/015592.html">announcing it</a>, and we launched it with some fanfare at the SMC conference held in Thrissur, Kerala, that year. Datuk’s story was covered by the press, and his work was now open and available to everyone.</p><p>Shortly thereafter, I was connected to Datuk by an old friend of his I had met at the conference, and we spoke briefly on the phone. He had seen the news clip of the dictionary’s release, and was thrilled to know that his work was now accessible as he had originally intended. Open data lives on. He found it amusing that a random stranger had somehow unearthed a relic he had lost to the annals of internet history. Life is absurd like that, shaped in infinite ways by tiny, random events.</p><p>Datuk <a href="https://www.facebook.com/amma.org.my/posts/tribute-to-the-late-datuk-k-j-josephthe-late-datuk-k-j-joseph-was-a-prominent-ed/2157527197640248/">passed away in January 2019</a>. He was 89 years old. RIP Datuk. Your work’s utility will span generations. The data you created will proliferate and continue to be useful to humanity in ways we never imagined. Such is the beauty of open data. I consider it a privilege to have been able to speak to you just that one time.</p><h3 id="open-data">Open data</h3><blockquote><p><a href="https://en.wikipedia.org/wiki/Open_data">Open data</a> is the idea that some data should be freely available to everyone to use and republish as they wish, without restrictions from copyright, patents or other mechanisms of control.</p></blockquote><p>I shudder to think of a world without Wikipedia. The open data movement shares strong parallels with the Free and Open Source Software (FOSS) movement. The gist is that certain knowledge should be freely available to everyone with no restrictions and with one goal—collective advancement of humanity.</p><p>I consider dictionaries to be on top of that list. The stepping stone to language, the underpinning of civilisation. Dictionaries should be open, free, and easily accessible to everyone, everywhere. If we cannot share something as fundamental as language without motives of profit, we ought to do some serious introspection as members of an advanced civilisation.</p><p>An open data dictionary for every Indian language, the largest collection of open source dictionaries in the world, would be an immense resource for not only India but for humanity in general. Ideally, this is the kind of project governments should do. State governments could very easily partner with local universities and undertake the creation and maintenance of open data dictionaries.</p><p>That said, at Zerodha, we would be happy to fund projects to create high quality open data dictionaries if there are scholars out there working on them.</p><h3 id="a-kannada-dictionary">A Kannada dictionary</h3><p>I moved from Kerala to Bengaluru in early 2012 to get access to fast internet. Bengaluru is a melting pot of people from all over India, and English is the glue that holds the “IT sector” together. I can comprehend Kannada speech reasonably well and speak rather poorly, but cannot read the script, thanks to the lack of opportunities to learn over the many years spent between home, where we speak Malayalam, and work, an English speaking environment. With the guilt of not being able to learn Kannada, and the great satisfaction of having Olam as an open data corpus, I had been looking for ways to build a Kannada dictionary right after I had moved to Bengaluru.</p><p>Sometime in 2016, I presented the idea of having an open source Kannada dictionary created from scratch to Nithin. He was immediately on board to commission the project. A perk I enjoy, the privilege of having a resourceful backer who believes in public good. Not knowing where to start, I asked around a few places but nothing materialised for the next two years, and as always, I continued to bring up this conversation once in a while.</p><p>Then, sometime in October 2018, I randomly brought up the conversation again, and Srihari, who had just joined the tech team, happened to overhear it. He vaguely remembered that someone in his family had been associated with a dictionary for a long time. This would be one of those minuscule, random events that would significantly change the timeline; the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">Butterfly effect</a> in action. I crossed my fingers and he soon setup a meeting with V. Krishna, the relative of his. Shortly thereafter, Srihari, Sharath (also from the tech team), and I went to <a href="http://www.kagapa.in/">KaGaPa’s</a> office to meet V. Krishna and to find out what exactly it was that Srihari remembered about him and a dictionary. KaGaPa (Kannada Ganaka Parishat) created the popular Nudi font and input method for Kannada, an important early innovation for digital Kannada, and V. Krishna had worked with them on several projects.</p><p>V. Krishna and Narasimhamurthy, KaGaPa’s proprietor, spoke passionately about Kannada literature and digitisation projects in the quaint little office room, surrounded by stacks of old Kannada books and literature. It was the perfect setting. Then, the extremely soft-spoken and mild-mannered V. Krishna fired up a computer and showed us his lifelong side project, his Kannada-English dictionary. Researched and written over a period of more than 40 years, 150,000+ Kannada words and 240,000+ English definitions, all neatly typed up in a Word document, complete with parts of speech tags and phonetic notations with diacritics for Kannada words. The ambition of the project, its scholarly quality, the depth of the data, the culmination of one man’s passion, perseverance, and tenacity over a lifetime, all lying in obscurity, stumbled upon by sheer coincidence. Absolutely mind blowing.</p><h3 id="v-krishna">V. Krishna</h3><figure><img src="https://zerodha.tech/static/images/vkrishna-alar.png" alt="V. Krishna's photo" height="150"></figure><p>V. Krishna was born in 1950 in the Malanayakana Halli village in Mysore district in Karnataka. He studied in a Kannada medium school, followed by a year at a pre-university college that he was forced to drop out of before moving to Bengaluru with his family in 1968.</p><p>He found a job at the Indian Agricultural Research Institute (IARI) in 1970. At IARI, around this time, noticing him struggle with the English language, his boss casually suggested that he procure a dictionary to learn English. This conversation would turn out to be pivotal, and would set V. Krishna on a lifelong journey of language research and scholarship, an amazing case of autodidacticism.</p><p>So, he took his boss’s advice and got himself an English dictionary and started studying it. Then he got himself another dictionary, and another, until he had five of them. At the same time, he took an interest in Kannada literature and started studying Kannada and English together. To help with this, he started jotting down notes, and at some point, began structuring them. A dictionary was being born. In the meanwhile, he took evening classes and obtained a commerce degree in 1976 from MES college, Malleshwaram.</p><p>Around 1980, <a href="https://en.wikipedia.org/wiki/Kannada_Sahitya_Parishat">Kannada Sahitya Parishattu</a> published a Kannada - English dictionary, and unsurprisingly, V. Krishna got himself a copy. He was surprised by the sheer number of errors he spotted—more than 200 in the first 50 pages. He wrote to the editor with his findings, and impressed by it, the editor met him in person in Bengaluru, where V. Krishna presented his manuscripts to him. Surprised by its quality, he suggested that V. Krishna continue his work and turn it into a full-fledged dictionary. This was the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615530</guid>
            <pubDate>Mon, 28 Sep 2020 11:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scorpion Transforming Computer Chair]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24615351">thread link</a>) | @jacquesm
<br/>
September 28, 2020 | https://www.cluvens.net/news/this-villainous-scorpion-can-transform | <a href="https://web.archive.org/web/*/https://www.cluvens.net/news/this-villainous-scorpion-can-transform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.cluvens.net/news/this-villainous-scorpion-can-transform</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615351</guid>
            <pubDate>Mon, 28 Sep 2020 11:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Durability: NVMe Disks]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24614893">thread link</a>) | @ingve
<br/>
September 28, 2020 | https://www.evanjones.ca/durability-nvme.html | <a href="https://web.archive.org/web/*/https://www.evanjones.ca/durability-nvme.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>[ 2020-September-27 10:26 ]</h3>
<p>Durability is the guarantee that data can be accessed after a failure. It seems like this should be very simple: either your system provides durable data storage, or it does not. However, durability is not a binary yes/no property, and instead should be defined as the <em>kinds</em> of failures you want your data to survive. Since there is usually some performance penalty for durability, many systems provide a way for only "important" writes to be durable, while "normal" writes will eventually be durable, with no specific guarantee about when. Finally, durability is rarely tested, since <em>really</em> testing it involves cutting the power to computer systems, which is disruptive and hard to automate. Production environments are designed to avoid these failures, so bugs are rarely triggered and hard to reproduce.</p>

<p>I've recently been investigating the durability guarantees in cloud platforms. I decided to start at the beginning: what guarantees are provided by the disks we connect to computers? To find out, I read the relevant sections of the Non-Volatile Memory Express (NVMe) specification (version 1.4a), since it is the newest standard for high-performance SSDs. It also has an <a href="https://nvmexpress.org/developers/nvme-specification/">easy to find, freely available specification</a>, unlike the older SATA or SCSI standards that were originally designed for magnetic disks. In the rest of this article, I will attempt to summarize the durability NVMe devices provide. I believe that most of this should also apply to SATA and SCSI. NVMe was designed as a higher performance replacement for those protocols, so the semantics can't be too different.</p>


<h2>Ordering and atomicity</h2>

<p>Before we can discuss durability, we should discuss some basic semantics of NVMe writes. Commands are submitted to devices using a set of queues. At some time later, the device acknowledges that the commands have completed. There is no ordering guaranteed between commands. From Section 6.3: "each command is processed as an independent entity without reference to other commands [...]. If there are ordering requirements between these commands, host software or the associated application is required to enforce that ordering". This means if the order matters, the software needs to wait for commands to complete before issuing the next commands. However, read commands are guaranteed to return the most completed write (Section 6.4.2.1), although they may also return data from uncompleted writes that have been queued.</p>

<p>A related issue with concurrent updates is atomicity. If there are concurrent writes to overlapping ranges, what are the permitted results? The answer is there are no guarantees. Specifically, "After execution of command A and command B, there may be an arbitrary mix of data from command A and command B in the LBA [logical block address] range specified" (Section 6.4.2). This seems to permit literally any result in the case of concurrent writes, such as alternating bytes from command A and command B.</p>

<p>NVMe includes <em>optional</em> support for atomic writes, with different values for "normal operation" and after power failure. The couple of NVMe devices I looked at don't support atomic writes, but apparently some higher-end devices do. The device exposes the size of atomic writes so software can configure itself to use it. For example, <a href="https://mariadb.com/kb/en/atomic-write-support/">see the MariaDB documentation about atomic writes</a>. This can replace MySQL's "doublewrite buffer," which is a mechanism that provides atomic writes on devices that don't natively support them (nearly all disks).</p>

<p>Basically, NVMe provides "weak" semantics similar to shared memory in multi-threaded programs. There are no guarantees if there are concurrent operations. This means if the order of writes matters, the software needs to submit the commands and wait for them to complete, and never have concurrent writes to overlapping ranges.</p>


<h2>The Flush command</h2>

<p>Without special commands, NVMe provides no guarantees about what data will survive a power failure (Section 5.15.2.2, Figure 249 in the documentation about the Atomic Write Unit Power Fail (AWUPF) field and Section 6.4.2.1). My reading of this means devices are permitted to return an error for all ranges where writes were "in flight" at the time of failure. If you want to be completely safe, you should avoid overwriting critical data by using write-ahead logging. This matches the semantics I found during <a href="https://www.evanjones.ca/intel-ssd-durability.html">power fail testing of SATA magnetic hard drives and SSDs in 2010</a>.</p>

<p>The first NVMe mechanism that can be used to ensure data is durably written is the Flush command (Section 6.8). It writes everything in the write cache to non-volatile memory. More specifically, "The flush applies to all commands [...] completed by the controller prior to the submission of the Flush command" (Section 6.8). This means if you want a durable write, you need to submit the write, wait for it to complete, submit the flush, and wait for that to complete. If you submit writes after submitting the flush, but before it completes, they might also be flushed ("The controller may also flush additional data and/or metadata", section 6.8). Most importantly, if you issue a flush, and it fails in the middle, there is no guarantee about what writes might exist on disk. The disk could have any of the writes, with no relation to the order they were submitted or completed. It could also choose to return an error for all the ranges.</p>


<h2>Force Unit Access (FUA)</h2>

<p>The second mechanism to ensure durability is to set the Force Unit Access option on Write commands. This means that "the controller shall write that data and metadata, if any, to non-volatile media before indicating command completion" (Section 6.15 Figure 404). In other words, data written with a FUA write should survive power failures, and the write will not complete until that is true. Interestingly, you can also specify FUA on a Read command, which is a bit surprising. It forces the referenced data to be flushed to non-volatile media, before reading it (Section 6.9, Figure 374). This mean you can do a set of normal writes, then selectively flush a small portion of it by executing a FUA read of the data you want committed.</p>


<h2>Disabling write caching</h2>

<p>The last mechanism that may ensure durability is to explicitly disable the write cache. If an NVMe device has a volatile write cache, it must be controllable. This means you can disable it (Section 5.21.1.6). It appears to me that if the cache is disabled, then every write must not complete until it is written to non-volatile media, which should be equivalent to setting the FUA bit on every write. However, this is not clearly described in the specification, and I suspect this is rarely used.</p>


<h2>Devices with power loss protection</h2>

<p>Finally, it is worth pointing out that some disks provide "power loss protection." This means the device has been designed to complete any in-flight writes when power is lost. This can be implemented by providing backup power with a supercapacitor or battery that is used to flush the cache. In theory, these devices should show that they do not have volatile write cache, so software could detect that and just use normal writes. However, these devices should ideally also treat FUA writes the same as non-FUA writes, and ignore cache flushes. As a result, I think it is best to design software for disks that have caches, since it can then work with any storage device. If you are using a device with power loss protection, you should still get better performance and some additional protection from failures.</p>

</div></div>]]>
            </description>
            <link>https://www.evanjones.ca/durability-nvme.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614893</guid>
            <pubDate>Mon, 28 Sep 2020 09:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type Systems Explained with Examples]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24614788">thread link</a>) | @thanato0s
<br/>
September 28, 2020 | https://thevaluable.dev/type-system-explained/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/type-system-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/type_system/type_psycho.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/type_system/type_psycho.jpg" alt="The Joker is just a type of psychopath">
                </picture>
            

            <p>“My language is better because it has a strong type system!” screams Dave, your colleague developer, trying to push the programming language Cobol for the next micro-service of your company.</p>
<p>Among developers, discussions about programming languages and their type systems can get quickly emotional. During these discussions, we often hear the words “type systems”, “data type”, “type inference”, “static typing”, “weak typing”, “coercion”, and more.</p>
<p>The goal of this article is to see the meaning of all these words with examples, for you to have good foundations and understand the type system of your favorite programming language. More precisely, we’ll see:</p>
<ul>
<li>What are types and why we need them.</li>
<li>When type checking occurs.</li>
<li>What are primitive types, composite types, and Abstract Data Types (ADT).</li>
<li>Type declaration and changing types can be implicit or explicit.</li>
<li>Types and functions.</li>
<li>What is type strength.</li>
<li>What is type safety.</li>
</ul>
<p>I’ll use two different languages to illustrate the ideas, Golang and PHP. If you don’t know them, don’t worry! The examples are straightforward and easy to understand.</p>
<p>I encourage you to use some <a href="https://repl.it/languages/php_cli" target="_blank" rel="noopener">PHP interpreter online</a> and the <a href="https://play.golang.org/" target="_blank" rel="noopener">Go playground</a> while reading, to play and experiment by yourself. This will help you understand the different concepts.</p>
<p>I won’t go into the gory details here. As you’ll see, it’s difficult to generalize something which is specific to a programming language. Yet, this article will give you a good overview of the usual properties of most type systems.</p>
<p>We’ll go progressively from clear waters to the muddy ideas, so take your rubber boots, get ready for the swamp, and let’s go!</p>
<h2 id="whats-a-type">What’s a Type?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/type_system/state_not_type.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/type_system/state_not_type.jpg" alt="State and types are different">
</picture>



<p>A type system is made of types. I know, it’s mind-blowing. These types are also called <em>data types</em>. What are they?</p>
<h3 id="syntax-and-semantics">Syntax and Semantics</h3>
<p>First, let’s clarify the difference between the <em>syntax</em> and the <em>semantics</em> of a programming language.</p>
<p>For example. the syntax of your mother tongue is the set of rules dictating the structure of the sentences. For many spoken languages, you’ll need a subject and a verb for your sentence to be correct. Programming languages have instead different constructs like <em>expressions</em>, <em>control structures</em>, or <em>statements</em>.</p>
<p>For example, for a <em>if</em> statement to be syntactically correct in PHP, you’ll need:</p>
<ul>
<li>A condition.</li>
<li>Some parenthesis.</li>
<li>Some curly brackets.</li>
</ul>
<p>Something like that: <code>if (1 == 1) { echo "I knew it!"; }</code>.</p>
<p>The semantics, on the other hand, is the meaning behind the constructs. For example, the semantics of an <em>if</em> statement can be explained as follows:</p>
<ol>
<li>The condition is executed.</li>
<li>If the condition is true, the body of the statement is executed.</li>
<li>If the condition is false, the body of the statement is not executed.</li>
<li>The execution continues.</li>
</ol>
<p>Why do we need syntax and semantics? It’s meant to communicate with two different kinds of entities:</p>
<ul>
<li>Your colleagues developers need to understand what the heck you did.</li>
<li>The computer needs to “understand” the instructions to execute them.</li>
</ul>
<h3 id="definition-of-a-type">Definition of a Type</h3>
<p>To come back to our subject, a type can attach semantics to data. For example, in PHP:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>
<span>$integer</span><span>;</span>

<span>echo</span> <span>gettype</span><span>(</span><span>65</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>;</span>
<span>// =&gt; integer
</span><span></span>
<span>$integer</span> <span>=</span> <span>65</span><span>;</span>
<span>echo</span> <span>gettype</span><span>(</span><span>$integer</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>;</span>
<span>// =&gt; integer
</span></code></pre></div><p>In Mathematics, 65 is part of the set of integers, so PHP consider the value 65 as type integer. Your variable <code>$integer</code> has the value 65 too, so it’s an integer, too.</p>
<p>When you assign 65 to the variable <code>$integer</code>, you give it a semantics it didn’t have when we declared it, on the second line. This semantics will let you know what you can do with the variable.</p>
<p>We can conclude that:</p>
<ul>
<li>A type gives semantics to a piece of data.</li>
<li>A type is a set of value. For the type integer, it will be a range of decimals. For the type string, it will be a range of possible strings.</li>
</ul>
<h2 id="why-do-we-need-types">Why Do We Need Types?</h2>
<h3 id="representation-and-semantics">Representation and Semantics</h3>
<p>When you declare a variable and assign it a value, the memory hold this value in <em>binary</em>. Our counting system is <em>decimal</em>, which means that the numbers we know and use everyday are very different in binary:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integer</span> <span>=</span> <span>65</span><span>;</span> <span>// Decimal notation
</span><span></span>
<span>printf</span><span>(</span><span>"Binary notation of %d: %b </span><span>\n</span><span>"</span><span>,</span> <span>$integer</span><span>,</span> <span>$integer</span><span>);</span>
<span>// =&gt; Binary notation of 65: 1000001 
</span></code></pre></div><p>Binary is just another way to represent numbers, <em>and only numbers</em>.</p>
<p>Dave, your colleague developer, is full of questions while reading these lines. “How does a character, such as ‘A’, is saved in memory?”, he wonders. “It’s not a number! It can’t be represented in binary!”.</p>
<p>Dave is right. The character has to be converted first into a decimal number, following the <a href="https://en.wikipedia.org/wiki/ASCII" target="_blank" rel="noopener">ASCII standards</a>. Then, this <em>ASCII code</em> is saved in memory.</p>
<p>Now, let’s try this:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integer</span> <span>=</span> <span>65</span><span>;</span>
<span>printf</span><span>(</span><span>"Binary representation: %b </span><span>\n</span><span>"</span><span>,</span> <span>$integer</span><span>);</span>
<span>// =&gt; Binary representation: 1000001
</span><span></span>
<span>$character</span> <span>=</span> <span>'A'</span><span>;</span>
<span>$ascii</span> <span>=</span> <span>ord</span><span>(</span><span>'A'</span><span>);</span> <span>// Ascii code of 'A'.
</span><span></span><span>printf</span><span>(</span><span>"Ascii code: %d </span><span>\n</span><span>"</span><span>,</span> <span>$ascii</span><span>);</span>
<span>// =&gt; Ascii code: 65
</span><span></span>
<span>printf</span><span>(</span><span>"Binary representation: %b </span><span>\n</span><span>"</span><span>,</span> <span>$ascii</span><span>);</span>
<span>// =&gt; Binary representation: 1000001 
</span></code></pre></div><p>The integer 65 and the string ‘A’ have the same binary representation in memory!</p>
<p>Dave is confused. In despair, he asks the sky: “How the hell our program knows that <code>$integer</code> is equal to 65, and <code>$character</code> is equal to <code>'A</code>’? How?”. Indeed, in memory, the two values of <code>$character</code> and <code>$integer</code> are exactly the same: <code>1000001</code>. When we use these two variables in our code, the type system of our language will <em>interpret</em> the two values in memory, and it will decide what is a character and what is an integer.</p>
<p>This is important to understand, since this interpretation is not always accurate for some types, like floating point numbers.</p>
<p>A type will determine as well how you store a value in memory. For a character and an integer, we saw that they are stored the same way. The way to store floating point numbers, for example, is quite different.</p>
<p>The memory storage is nicely abstracted by the type system for us, developers, not to think about these confusing 0 and 1. You can then focus on more important problems, at least when the abstraction doesn’t leak. If you’re not sure what’s an abstraction, I wrote <a href="https://thevaluable.dev/abstraction-software-development/">a detailed article about it</a>.</p>
<h3 id="a-set-of-rules">A Set of Rules</h3>
<p>A type system is as well a set of rule, more or less strict. You can’t do everything you want with some types.</p>
<p>Let’s take another example:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>printf</span><span>((</span><span>3</span> <span>+</span> <span>"Hello World!"</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>);</span>
<span>// =&gt; PHP Warning:  A non-numeric value encountered in /home/myusername/phpgoodies/test.php on line 3
</span><span>// =&gt; 3
</span><span></span>
<span>printf</span><span>(</span><span>"The execution continue!"</span><span>);</span>
<span>// =&gt; The execution continue!
</span></code></pre></div><p>This code makes little sense. I try to reinvent Mathematics by adding the integer 3 to a string. PHP will throw a warning, but it will still give a result, <code>3</code>. When you violate the rules of a type system, the outcome can range between these two extremes:</p>
<ol>
<li>The interpreter or compiler will silently try to fix the problem and continue.</li>
<li>The interpreter or compiler will throw an error and stop.</li>
</ol>
<p>In the case of our example, PHP will throw a warning, but the execution will still continue. You can even get rid of the warning in the infamous <code>php.ini</code>.</p>
<p>To compare with another language, let’s take the exact same thing in Golang:</p>
<div><pre><code data-lang="golang"><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>3</span> <span>+</span> <span>"Hello World"</span><span>)</span>
    <span>// =&gt; invalid operation: 3 + "Hello World" (mismatched types untyped int and untyped string)
</span><span></span>    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"The execution continue!"</span><span>)</span>
<span>}</span>
</code></pre></div><p><em><a href="https://play.golang.org/p/2JEY0GmHnYF" target="_blank" rel="noopener">Playground</a></em></p>
<p>The compiler will grant you with an error and your program won’t even be compiled.</p>
<h2 id="built-in-types-vs-our-own-abstractions">Built-in Types vs Our Own Abstractions</h2>
<p>Programming languages, more often than not, have a whole set of types you can use, out of the box. These types are called <em>primitive types</em>. For example: <code>integer</code>, <code>boolean</code>, <code>float</code>, and more.</p>
<p>Often, you’ll be able to use as well <em>composite types</em>, a type containing multiple values, and possibly multiple primitive types. It’s what we call more commonly <em>data structures</em>.</p>
<p>For example, an array is a composite type:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integerArray</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>];</span>
<span>$multipleTypeArray</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>5.4</span><span>];</span>

</code></pre></div><p>The rules attached to these data types are imposed by the compiler (or the interpreter) of your language of choice.</p>
<p>Since the raise of the <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.3043&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Abstract Data Types</a> (ADT), you have the power, in high level programming languages, to create your own types. For example, in PHP:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>class</span> <span>Shipment</span>
<span>{</span>
    <span>public</span> <span>function</span> <span>send</span><span>()</span>
    <span>{</span>
        <span>echo</span> <span>"Send powerful shipment!"</span><span>;</span>
    <span>}</span>
<span>}</span>

<span>$shipment</span> <span>=</span> <span>new</span> <span>Shipment</span><span>();</span>
<span>$shipment</span><span>-&gt;</span><span>send</span><span>();</span>
</code></pre></div><p>When you write <code>$shipment = new Shipment()</code>, you create an instance of the class <code>Shipment</code>. The object <code>$shipment</code> can be considered as well of type <code>Shipment</code>.</p>
<p>When you think about it, a type can be seen as a set of possible values, a category, or a group. A class has the <a href="https://www.merriam-webster.com/dictionary/class" target="_blank" rel="noopener">same definition (see entry 3)</a>.</p>
<p>We can say as well that the object <code>$shipment</code> is an abstraction of its class, and its interface (the way you interact with the abstraction) is the method <code>send()</code>.</p>
<p>We created some rules for our new type:</p>
<ul>
<li>The only interface available is the method <code>send()</code>.</li>
<li>The method <code>send()</code> return a string, not an integer.</li>
</ul>
<p>In Golang, you don’t have classes, but you can create custom types, too:</p>
<div><pre><code data-lang="golang"><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
<span>)</span>

<span>type</span> <span>minute</span> <span>int</span>

<span>func</span> <span>(</span><span>m</span> <span>minute</span><span>)</span> <span>second</span><span>()</span> <span>int</span>  <span>{</span>
    <span>return</span> <span>int</span><span>(</span><span>m</span><span>)</span> <span>*</span> <span>60</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>var</span> <span>min</span> <span>minute</span>
	<span>min</span> <span>=</span> <span>2</span>
	<span>fmt</span><span>.</span><span>Printf</span><span>(</span><span>"%d minutes are %d seconds"</span><span>,</span> <span>min</span><span>,</span> <span>min</span><span>.</span><span>second</span><span>())</span>
    <span>// 2 minutes are 120 seconds
</span><span></span><span>}</span>
</code></pre></div><p><em><a href="https://play.golang.org/p/rm1aRW2vZip" target="_blank" rel="noopener">Playground</a></em></p>
<p>In that case, the new type <code>minute</code> gets the same set of rules as the type <code>int</code>. Then, you can attach methods to this new type <code>minute</code>, like the method <code>second()</code>.</p>
<h2 id="type-checking">Type Checking</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/type_system/type_wizard.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/type_system/type_wizard.jpg" alt="Some types are obvious">
</picture>



<p>If types push us to respect some rules, a programming language need an algorithm to check if we respect them. This is called <em>type checking</em>.</p>
<p>Even if type systems can be very similar or very different, depending on the programming language, we are humans, so we need to group these disparate things in categories to understand them.</p>
<p>There are two important categories of type checking: <em>static type …</em></p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/type-system-explained/">https://thevaluable.dev/type-system-explained/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/type-system-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614788</guid>
            <pubDate>Mon, 28 Sep 2020 09:38:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do things that don't require scale]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24614691">thread link</a>) | @davnicwil
<br/>
September 28, 2020 | https://davnicwil.com/do-things-that-dont-require-scale/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/do-things-that-dont-require-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="41"><div data-reactid="42"><div data-reactid="43"><p data-reactid="45">If you're interested in startups, "Do things that don't scale" is something you've likely heard. To me it's execution advice - in the beginning use your relatively small size as a strength by doing things that have outsized short term impact but are infeasible in the long run at scale.</p><p data-reactid="46"><!-- react-text: 47 -->Here's a corollary for the business idea itself: also make sure you start by doing things that don't <!-- /react-text --><span data-reactid="48">require</span><!-- react-text: 49 --> scale.<!-- /react-text --></p><p data-reactid="51">If your small size is the only advantage you have for execution, you'd better make sure the actual business idea works when it's all you have, too, because execution doesn't matter if the idea fundamentally won't work.</p><p data-reactid="52">It sounds obvious, but it's a mistake many people make - I've made it myself repeatedly - and it's especially hard to spot when you're caught up in how great you think an idea is. It might indeed be great, but you're just not in a position to make it work when you're starting from scatch.</p><p data-reactid="53"><!-- react-text: 54 -->You can do things that don't scale to accelerate a good idea, but by definition you actually can't do that if the idea itself<!-- /react-text --><!-- react-text: 55 --> <!-- /react-text --><span data-reactid="56">requires</span><!-- react-text: 57 --> scale. The idea has to work on day 1, for customer 1.<!-- /react-text --></p><p data-reactid="59">A common root of the issue, I believe, is looking at already successful products and imagining how they could be iterated upon or diverged from in new and interesting ways. Such divergent ideas are often very reasonable, good even, the problem is that they require the same scale to work as the products they are based upon.</p><p data-reactid="60"><!-- react-text: 61 -->It's all too easy to ignore that part, or convince yourself that the huge scale is somehow a positive since it proves there's a strong market for this product. It's the other way round: often the strong market &amp; huge scale <!-- /react-text --><span data-reactid="62">are</span><!-- react-text: 63 --> the product.<!-- /react-text --></p><p data-reactid="65">Here's a few good ways to think about whether your idea is one that requires scale or not. Of course every product is different, and there are many more, but following the 80% rule I think most ideas can be caught with the following:</p><p data-reactid="66">First, look at the history of the product it's based upon or one it's similar to. Did it come out of an already huge company? If not, how did it evolve as it scaled? Did it keep roughly the same manifestation and business model, or did these change substantially? Be skeptical if so.</p><p data-reactid="67">Second, does it have network effects? These are obvious in B2C, less so in B2B. Be skeptical if you have a per-seat pricing model and your strategy is bottom-up expansion within organisations starting from a few accounts. Be extra skeptical if these accounts are free.</p><p data-reactid="68">Third, how synchronous and mission critical is it? Be skeptical if it going down would cause interruption to workflows that couldn't be worked around or deferred. Be incredibly skeptical if this is true round the clock and on weekends. That kind of service level implies significant and robust automation and support, which require scale.</p><p data-reactid="69">Fourth, how much does the business model depend on volume? Losing a bit of money on first customers as you bootstrap and learn is not an issue. Be skeptical, though, if this would need to be sustained to bootstrap your way to some required volume which is quite a way beyond those first few customers.</p></div></div></div></div>]]>
            </description>
            <link>https://davnicwil.com/do-things-that-dont-require-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614691</guid>
            <pubDate>Mon, 28 Sep 2020 09:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of XML]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 239 (<a href="https://news.ycombinator.com/item?id=24614404">thread link</a>) | @tannhaeuser
<br/>
September 28, 2020 | https://blog.frankel.ch/defense-xml/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/defense-xml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//defense-xml/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/defense-xml/XML_icon.svg"> </figure> <section> <div itemprop="articleBody"> <p>When I started my career, XML was ubiquitous. The meta-information in a Java JAR file - the manifest - follows a proprietary format. But Java EE designers built it from the ground up on XML: meta-information of all artifacts is in XML format <em>e.g.</em> <code>web.xml</code>, <code>ejb-jar.xml</code>, <code>application.xml</code>, etc.</p> <p>Java EE is one example I experienced personally. But XML was everywhere in the enterprise world at the time. Its prevalence manifested itself in two areas: configuration and data transfer.</p> <p>Ever since then, it would be an euphemism to say XML has been losing in popularity. Other formats, such as JSON and YAML, have replaced it in the hearts of developers. In this post, I’d like to:</p> <ul><li><span>Explore some of the reasons why the mighty XML has fallen</span></li><li><span>Raise some downsides of the popular alternatives</span></li><li><span>And describe how XML already solved those problems</span></li></ul> <div> <h2 id="the-downfall-of-xml">The downfall of XML</h2> <div> <p>I think there are several reasons that led to the downfall of XML. It’s not a single one, but the conjunction of them that led to the current state.</p> <div> <h3 id="associated-with-enterprise">Associated with "Enterprise"</h3> <p>I’m afraid the worst flaw of XML is its close association with the enterprise world. As everybody knows, Enterprise is notoriously bad - by definition: bloated, heavy, not nimble, etc. And yes, that’s sarcasm if you wondered.</p> <p>In general, perception trumps truth. Developers are no different in that regard. In the end, that’s how Hype-Driven Developers - and most developers, perceive XML nowadays.</p> </div> <div> <h3 id="lack-of-integration-with-front-end">Lack of integration with front-end</h3> <p>One of the main usages of XML was in the realm <a href="https://en.wikipedia.org/wiki/SOAP" target="_blank" rel="noopener">SOAP web services</a>. Let’s be frank about it: the ease of consuming those web services from JavaScript and/or the browser is not spectacular.</p> <p>It' no wonder that JavaScript Object Notation, <em>aka</em> JSON became a <em>de facto</em> standard. JSON brought <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">REST</a> along with it. As its name implies, JSON is JavaScript native, while XML is not.</p> </div> <div> <h3 id="steep-first-steps">Steep first steps</h3> <p>JSON is quite easy to start with, YAML even more so. Even with bare XML, one has the concept of namespaces, which are not beginner-friendly. XML allows one document to use elements from different namespaces. On the flip side, it makes designing simple documents more complicated.</p> <p>XML has a lot of powerful features, but all this power can be confusing to beginners. I willingly admit that they make easy things more complex than they should.</p> </div> <div> <h3 id="performance">Performance</h3> <p>I’ve stumbled upon the performance "argument" a couple of time. This is usually "proven" by using a sample describing the same in XML, JSON and YAML. Because of its opening <strong>and</strong> closing tags, the writer shows that XML is quite noisy compared to the other two.</p> <p>IMHO, this argument is shallow, as all 3 formats are text-based. Thus, you can - and should - compress files. Parsing might be a bit slower, but it depends a lot on the exact parser (and the associated technology stack). In the end, the overhead of transmitting and parsing in XML - if any - is negligible compared to the total time in the whole use-case.</p> <p>People who favor YAML over JSON use the same reasoning: less characters.</p> </div> <div> <h3 id="abuse">Abuse</h3> <p>The above reasons are more or less congruent with XML. Yet, I’m more than willing to admit architects have been abusing XML. I’ve personally seen SOAP webservices with payload in the order of several megabytes. At that time, you might imagine the performance of such design was not stellar.</p> </div> </div> </div> <div> <h2 id="failings-of-alternatives">Failings of alternatives</h2> <div> <p>JSON, YAML &amp; al. all have their own failings. Here’s a sample of them:</p> <ul><li><span>JSON has no comments. The most usual fallback is to use the <code>"_comment"</code> property.</span><div> <div> <pre><code data-lang="json"><span>{</span><span>
  </span><span>"foo"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"_comment"</span><span> </span><span>:</span><span> </span><span>"My important comment"</span><span>,</span><span>
    </span><span>"bar"</span><span>:</span><span> </span><span>true</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre> </div> </div></li><li><span>YAML has no governing body. Individuals manage the specification.</span></li><li><span>YAML has <strong>22 ways to write booleans</strong> - no less!</span></li></ul> <div> <div> <div> <blockquote> <p>Anyone who uses YAML long enough will eventually get burned when attempting to abbreviate Norway.</p> </blockquote>  </div> </div> </div> <div> <div><blockquote><div lang="en" dir="ltr"><p>YAML is to config syntaxes what Python is to programming languages. Seriously, significant whitespaces?</p><p>Have fun with a 500 lines of YAML to configure your Kubernetes deployment, and come back to explain why *you* hate it.</p></div>— Nicolas Frankel (@Home for a long time I believe) (@nicolas_frankel) <a href="https://twitter.com/nicolas_frankel/status/1273888063463325697?ref_src=twsrc%5Etfw">June 19, 2020</a></blockquote>  </div> </div> <p>To cope with the above, other formats have poped-up:</p> <ul><li><span><a href="https://github.com/toml-lang/toml" target="_blank" rel="noopener"><abbr title="Tom’s Obvious, Minimal Language">TOML</abbr></a> draws its inspiration from the <a href="https://en.wikipedia.org/wiki/INI_file" target="_blank" rel="noopener"><code>.ini</code></a> format. It allows nested hierarchies of properties</span></li><li><span>Lightbend pushes the <abbr title="Human-Optimized Config Object Notation">HOCON</abbr> format:</span></li></ul> <div> <div> <div> <blockquote> <p>This is an informal spec, but hopefully it’s clear.</p> </blockquote>  </div> <p>This one statement doesn’t fill me confidence.</p> </div> </div> </div> </div> <div> <h2 id="the-original-sin-the-lack-of-grammar">The original sin: the lack of grammar</h2> <div> <p>Whatever the format, regardless of their own specific downsides, one of the most important issue is for clients to decide if the read data is <em>correct</em> or not.</p> <p>When using JSON and YAML, the different clients need to provide <em>ad hoc</em> validation. Issues arise when the provider changes the data format:</p> <ol><li><span>How to make clients aware that the format changed?</span></li><li><span>What information to communicate to the client about the format change?</span></li><li><span>How to keep validation synchronized across clients?</span></li></ol> <p>XML has this issue solved since the beginning by providing a <strong>grammar</strong>. A grammar plays the same role for a XML document as constraints and types in a SQL database. The most important difference is that you can externalize the grammar.</p> <p>Several XML grammar implementations are available: <a href="https://www.w3.org/XML/1998/06/xmlspec-report-19980910.htm" target="_blank" rel="noopener">Document Type Definition</a>, <a href="https://www.w3.org/XML/Schema" target="_blank" rel="noopener">XML Schema</a>, <a href="https://relaxng.org/" target="_blank" rel="noopener">Relax NG</a>, etc. The most widespread one is XML Schema. Since a XML Schema is also written in XML format, a web server can host it. Then you can reference it by a publicly-accessible URL.</p> <p>This approach solves the above issues: when a client receives an XML document, the former looks at the XML Schema URL. It can then fetch it, and check that the data conforms to the schema.</p> <p>Changing the data format is as simple as versioning the XML Schema file, and publishing it under a new URL.</p> </div> </div> <div> <h2 id="other-benefits-of-xml">Other benefits of XML</h2> <div> <p>In this section, I’d like to list a couple of benefits of using XML.</p> <div> <dl> <dt>Public open stewardship</dt> <dd> <p>XML is not under the stewardship of a single person or a company, but of a <abbr title="Non-Governmental Organization">NGO</abbr>, namely the <a href="https://www.w3.org/" target="_blank" rel="noopener">W3C</a>. A W3C specification has a <a href="https://www.w3.org/2019/Process-20190301/" target="_blank" rel="noopener">publicly documented process and defined lifecycle</a>.</p> </dd> <dt>Battle-proven</dt> <dd> <p>XML is not hype, but benefits from plenty of documentation, blog posts, and <a href="https://stackoverflow.com/questions/tagged/xml" target="_blank" rel="noopener">FAQs</a> available</p> </dd> <dt>Composable</dt> <dd> <p>While XML doesn’t strictly enforces namespaces, it’s considered a good practice. This way, similarly-named entities defined in different namespaces can co-exist in the same document without confusion about semantics.</p> </dd> <dt>Different flavors</dt> <dd> <p>XML parsing comes into two flavors:</p> <ol><li><span>Tree-based parsing <em>i.e.</em> <a href="https://dom.spec.whatwg.org/" target="_blank" rel="noopener">Document Object Model</a>. It loads the whole document in memory</span></li><li><span>Event-based parsing <em>i.e.</em> <a href="http://www.saxproject.org/" target="_blank" rel="noopener">Simple API for XML</a>. It makes possible the parsing of large documents. Note that SAX is <strong>not</strong> a W3C specification.</span></li></ol> </dd> <dt>Implementation in different languages</dt> <dd> <p>Every commonly-used language in the industry offers at least one XML parsing implementation. This is either baked in the standard library that comes along the language, or available in a third-party one. Here are a couple of them:</p> </dd> </dl> </div>  <div> <dl> <dt>Document transformation</dt> <dd> <p><abbr title="eXtensible Stylesheet Language Transformation">XSLT</abbr> is <a href="https://www.w3.org/TR/1999/REC-xslt-19991116" target="_blank" rel="noopener">a W3C specification</a>. It allows to transform one XML document into another document in a declarative way. Target documents can be either XML themselves, or not.</p> </dd> <dt>Document querying</dt> <dd> <p><abbr title="XML Path Language">XPath</abbr> is <a href="https://www.w3.org/TR/2017/REC-xpath-31-20170321/" target="_blank" rel="noopener">another W3C specification</a>. It defines how to query XML documents, similar to CSS selectors.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>XML has a lot of advantages compared to other more alternative technologies. In addition to what I described above, it benefits from a <a href="https://www.w3.org/standards/xml/" target="_blank" rel="noopener">rich ecosystem</a>.</p> <p>It’s not considered hype by a lot of young (and not so young) developers. I believe would be beneficial if our industry would value more battle-proven technologies than new shiny ones.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/defense-xml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614404</guid>
            <pubDate>Mon, 28 Sep 2020 08:40:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stupid solutions: Live server push without JS]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24613610">thread link</a>) | @lawik
<br/>
September 27, 2020 | https://underjord.io/live-server-push-without-js.html | <a href="https://web.archive.org/web/*/https://underjord.io/live-server-push-without-js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-09-25</small><!-- RSS:2020-09-25T17:00:00Z -->
<p>
    So in my post <a href="https://underjord.io/is-this-evil.html">Is this evil?</a> I covered a way of tracking users with CSS. While
    thinking about those weird ways of using the web I also started thinking about pushing live data to clients
    without JS. Or at least maintaining a connection.
    So WebSockets requires JS. WebRTC requires JS. Even HLS (video streaming), which would otherwise
    be super cool, with captions for accessibility. But no. Or rather, maybe on Apple platforms. Eh. Not good enough.
</p>
<p>And then it hit me. From some old Nerves projects I'd seen, that there is a standard for just sending a stream of
    JPEG frames as a video. MJPEG. Did you know about MJPEG? Lots of people don't. It is used by lots of webcams and
    security cameras. Common option for Raspberry Pi hacks as well. MJPEG is super simple which is its big advantage.
</p>
<p>But video is what we expect. I was going for something else. So this could be used for a CI status light, showing
    any amount of visual status information. I use it for this:</p>
<p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>
<p>That's live. Or dead if my server falls over.</p>
<p>So how does MJPEG work. Well, you take an <code>&lt;img&gt;</code> tag and you shove an MJPEG URL into it. Done.</p>
<p>Okay, that's how you use it. Not how it works. I implemented it in Elixir, Elixir is quite good at keeping state and
    serving updates. Links are below. But basically the browser opens the connection, receives some headers and some
    chunks of data and then realizes it is dealing with MJPEG. It wil then just expect the chunks to keep coming.
    Indefinitely. Because this is live video. Frame by frame of JPEG.</p>
<p>The basic code for the MJPEG headers and chunking was lifted from a pi camera repo made by the Nerves team. It had a
    lot of Frank Hunleth and Connor Rigby in it so kudos to those guys as always. This is what I did with it: <a href="https://github.com/lawik/mjpeg/blob/master/lib/mjpeg.ex">lawik/mjpeg</a></p>
<p>My server implementation is here and uses the above code: <a href="https://github.com/lawik/mjpeg_example/blob/master/lib/mjpeg_example.ex">lawik/mjpeg_example</a></p>
<p>So I receive the connection and then that calls my MjpegExample GenServer to persist the connection and keep track of
    how to notify that connection about new data. It also triggers an update to notify everyone already connected.</p>
<p>This is not polished, it is hammered together and I'm curious to see if it falls over the next time I get a decent
    amount of traffic.</p>
<p>I really like this approach because it is a fun hack that simply happens to work across browsers and quite well at
    that. I like how it is just an img element and no frills. I added lazy loading because that works more nicely with
    things like Google Lighthouse scores and the loading experience (your browser doesn't spend a few seconds thinking
    about loading the image).</p>
<p>Unfortunately it is absolutely a poor choice to actually use aside from fun and hacky stuff. There is no good way of
    doing accessibility with it. You can update the pixels and that is it. Unless you can chunk-stream a txt-file in an
    iframe.
    Haven't tried that yet...</p>
<p>So, don't use it. But isn't it pretty neat?</p>
<p>Of course, much like the CSS tracking, this can be used for evilish things. You can absolutely keep track of how long
    someone keeps receiving your frames and use that for your analytics. I also find it neat that it lets me know
    concurrent users. I just log the number along with sending it out because I want to know at what number it breaks
    and out of curiosity but you can probably do some mildly untoward things with this. Oh.. Wait. You could serve
    rotating ads with this. You know what the last frame you sent was so if you get a click on it you can direct that
    particular user to the right thing. New title: Ad placement entirely without JS, ugh, no thanks. Moving on.</p>
<p>If you know how to make this more dirty, hacky and fun or even more useful or accessible feel free to get in touch at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on
    Twitter where I'm <a href="https://twitter.com/lawik">@lawik</a>.</p><p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>

</div></div>]]>
            </description>
            <link>https://underjord.io/live-server-push-without-js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24613610</guid>
            <pubDate>Mon, 28 Sep 2020 06:36:16 GMT</pubDate>
        </item>
    </channel>
</rss>
