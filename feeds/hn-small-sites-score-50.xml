<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 27 Jun 2020 04:16:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 27 Jun 2020 04:16:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 183 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 283 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div p="">&gt; 
endobj
379 0 obj
&lt;&lt; /S 964 /O 1045 /Filter /FlateDecode /Length 380 0 R &gt;&gt; 
stream
ì+ªýc„-ÌéEÎØµ«°L½÷Ëÿé;ÄÛxÃ¼to•F$ˆ¡)•ãz§%u­ÌP¬5,‚|)äìº„H”˜Ïk‚Æ&nbsp;s˜Z‡}8kxgF¼�Ew�‰	ÕìC¸‡2÷¨ÿ&gt;JùwãÏ@ãù«z‰7s¹vëëœEªœ:Øy±cˆ[°ÅÄ§ÁôCEb´.&gt;øõ½ó¶B�š:DØ´×¸æ¢¬aqäÁ"Õ&gt;(¿ìøzF|ñlçJ´W‘~|‹§	|hÓwÎ�&gt;|³¹Žö™&amp;¬frË�/^@¦Šà°GM4mejD›ê²õ`X–Þrm¯ð²ÝUdñØ"LjÝÁ{um]4tÈj»­)6qbÕ<v%aÁ£œps1�l`Ôbä2[›;� qhu'…„+~€úmÿÓ‚Ámïx="£ËÝfÊÙÁš¨Ìâ|â3É5¸æ£gøÕû‘jªãt" Øl4ï="ù2Jd·”õ" ŠÖö*uxi«Áx4ãõ€�´�+otx‰³ö÷ö,¼Þ1¢fçÐ¾›ûødÝ^h¸ÚdÎÌ4bÅs×Çê†~k%’î¦—¦¨éå6xª+§qÔÒ„†hÐ[s¹="ˆžµ—QäyÀ½fî¤u*�su$ØÐwrg" endstream="" endobj="" 380="" 0="" obj="" 488="" 352="" <<="" type="" page="" parent="" 336="" r="" resources="" 366="" contents="" 371="" mediabox="" [="" 432="" 648="" ]="" cropbox="" rotate="">&gt; 
endobj
353 0 obj
&lt;&lt; 
/Count 1 
/First 354 0 R 
/Last 354 0 R 
&gt;&gt; 
endobj
354 0 obj
&lt;&lt; 
/Title (T¬Þô¯ø1n)
/Dest [ 4 0 R /Fit ] 
/Parent 353 0 R 
/First 355 0 R 
/Last 356 0 R 
/Count -11 
&gt;&gt; 
endobj
355 0 obj
&lt;&lt; 
/Title (š[ÌBe°†à0úg)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Next 365 0 R 
&gt;&gt; 
endobj
356 0 obj
&lt;&lt; 
/Title (‘'G`iŸ)
/Dest [ 320 0 R /Fit ] 
/Parent 354 0 R 
/Prev 357 0 R 
&gt;&gt; 
endobj
357 0 obj
&lt;&lt; 
/Title (°DÞ—9³Ùí+ Šk¹)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 358 0 R 
/Next 356 0 R 
&gt;&gt; 
endobj
358 0 obj
&lt;&lt; 
/Title (ø“€·+Š*—ÜI)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 359 0 R 
/Next 357 0 R 
&gt;&gt; 
endobj
359 0 obj
&lt;&lt; 
/Title (*I“KP8iÃ]3¨ŒÎÙÝÊÜ®%zÙ3k&gt;g’Bn~|‹Û°.¦7Z#Ð\(Ü²ÄÃhÿ"SÀv7�K/J\()
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 360 0 R 
/Next 358 0 R 
&gt;&gt; 
endobj
360 0 obj
&lt;&lt; 
/Title (D7A­­*!P])
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 361 0 R 
/Next 359 0 R 
&gt;&gt; 
endobj
361 0 obj
&lt;&lt; 
/Title (õËÃª5tT±ZOJR¨�»[¿5&lt;¿j+æN*œ§h4èÉÄo	É»W'±WßK¥ÞZ_š¦&amp;-M)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 362 0 R 
/Next 360 0 R 
&gt;&gt; 
endobj
362 0 obj
&lt;&lt; 
/Title (’›­öëQ“uö)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 363 0 R 
/Next 361 0 R 
&gt;&gt; 
endobj
363 0 obj
&lt;&lt; 
/Title (-hs~FD»M„íM±VleÁŸï!Å¤Ÿpnt­ô6qñ‡-Œí*üKª©)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 364 0 R 
/Next 362 0 R 
&gt;&gt; 
endobj
364 0 obj
&lt;&lt; 
/Title (:Gû¹ÀS ˜&nbsp;2)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 365 0 R 
/Next 363 0 R 
&gt;&gt; 
endobj
365 0 obj
&lt;&lt; 
/Title (²ú"0P“ºSf÷–wn&lt;)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Prev 355 0 R 
/Next 364 0 R 
&gt;&gt; 
endobj
366 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F5 368 0 R /F6 372 0 R /F7 375 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 378 0 R /GS2 377 0 R &gt;&gt; 
&gt;&gt; 
endobj
367 0 obj
&lt;&lt; 
/Type /FontDescriptor 
/Ascent 0 
/CapHeight 0 
/Descent 0 
/Flags 4 
/FontBBox [ -146 -274 1207 909 ] 
/FontName /HDDGLC+MSTT31c6b7 
/ItalicAngle 0 
/StemV 0 
/CharSet (ì»µ”±ßhZ\)0UŠ	wå*‹*Àá&nbsp;|B¬=ŠÉš¬b_Øö1ÈÖ2a¼-Sè�bœ”¿r«áÞ„’nòj"<tøþ˜Ì\ ¬ØtrùÇ;f[û<="" {²h[r)="" fontfile="" 369="" 0="" r="">&gt; 
endobj
368 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Name /F5 
/FirstChar 31 
/LastChar 255 
/Widths [ 750 260 320 380 520 520 900 740 220 440 440 500 520 260 333 260 580 
556 556 556 556 556 556 556 556 556 556 260 260 520 520 520 400 
820 660 640 680 740 620 540 740 820 360 340 660 620 880 760 820 
580 800 660 520 660 780 640 900 740 520 600 440 260 440 520 500 
360 556 556 556 611 500 444 611 667 333 333 556 500 722 611 611 
500 611 556 444 556 611 556 778 611 556 500 280 260 280 520 750 
750 750 300 520 400 1000 500 500 420 1300 520 320 1000 750 750 750 
750 300 300 400 400 460 556 1000 420 980 444 320 833 880 750 520 
750 320 520 520 611 520 260 500 380 740 340 480 520 750 740 400 
400 520 312 312 360 580 600 320 300 312 360 480 780 780 780 400 
660 660 660 660 660 660 880 680 620 620 620 620 360 360 390 370 
740 760 820 820 820 820 820 520 820 780 780 780 780 520 580 888 
556 556 556 556 556 556 722 556 500 500 500 500 347 347 377 357 
611 611 611 611 611 611 611 520 611 611 611 611 611 556 500 556 
] 
/Encoding 370 0 R 
/BaseFont /HDDGLC+MSTT31c6b7 
/FontDescriptor 367 0 R 
&gt;&gt; 
endobj
369 0 obj
&lt;&lt; /Length 10526 /Length1 4144 /Length2 6380 /Length3 0 &gt;&gt; 
stream
zv¥gjQkÜuùxúõüó½�ÕñQÇ9;Õê¡ƒÀÉd¾Ñ®ôQÛçFeœ5íNRAžW!evÔ=Ë½ý™îžÍ8g(XmØpJe*åº0bÝæÆ¡]ó�úqÐÁÊ©OíiÂåt/x�Ò¿ÖUÑS3P¸43G`œŽZŽBª„zïùÖ§¶«X™Åe3?»¹ÏébÃè¦sQŒ–«;îWßê¾ý„ÆaçXOˆn&amp;7¸}ÃŠÈ�Æ³ed½‚$/´ñ?þ2ÿÓ#øKˆÖl%Ù“—0ñ‡ €Eê„†4áN-.‚ÑJHÊr	Ž×+«2¦wDqV/{±gp“™|Mú:4µ$�”yC¿¹
•ÞžœN:sâ-Ú¹(}4,O™�Ù€¡í½MMùcƒÂ–¯­.N¥UwîÈ#G‹©šÕÜ­Š�)~D<a€â-ÑÔší³’È¯=¬Éky÷Ãßm~•‚ 7µl¥”÷á’dï*§yc="" $="">�»‰NHÞVý×ÙpW{5 ÞCžYìg6´Ì�9BUÐñ1Ë^t^8ûªøo#žÞv“–†mEK["ˆ03IBè3F÷Éº ŒB°È:ô•\ˆ÷Gñx?½(Å’=c×ø†Ÿ$h‡ò0KÄqÛÍ°·Ú‘<a}×¨¦’mÑ2uýúsþã¶µf”�[g` dØhhœmí×¹Ä”Žýçfç’Ž’“g›‹%†�ËiÓí="" f{¹õûâð*¾o¶¡e�u©o‚‰Ïß="" %hÌ8ìr1³1<ÁÑ_?dqï½×°˜âÞ%»bb="" œll4beb="A§#Æ‘ìŠá°Fr×i1€" l‰²[r½$ï¨ð*lîn(0vq„Ý="" Ý�="" 5ºð²¢¤m}_‡pü&8r¡äÿu©)›r“boÏ%¶tÀpkÇr$e!óp¾éj”��.\˜þÏÎÌdå$«båý+��'b…wvÎØ.ºõ b£jt3mñ»-}ø¹¤é–Ývoàéƒg¡ìiõ*h0-n¬býá*cÀÍá›®á\="">ÔÅ¨
‚°ôæ‰Ä¦Š¬‡ìäóËp¯;tPÿúÿ$	ÿrëK[Õeœ15X&nbsp;Ñ—åûê	‘3º(uÕ•ÙÛ¯.W6¤Å3r®êÞí´&nbsp;MQtêã}ñ|µ²ÔSùòP^°êéËuÿi•”‚ï¼�Ë‘Ý[Í_Ký@¾Onj³ûö
Ç	âƒ
`IRùÁY…µlt‰¼õ;�(QAr­èz¹LÇœµ.:Ô�#@+‰71.�pU¤ØÄy
D|ÕˆÝ)ÛŸ¸ýáv»ƒo´{œs^áœ,:ïË£óéqžËJ4t¯Dp³ÐzzÑ8þ›+Vpó‘lºÓ±#Q¾Ø¬ªC©ºƒÉ«€{³¶&nbsp;c\tÇ6�OÍ¸A�ÇbXöÃ&amp;4¢­3)³1Ëì\hçÃ|£:’G?£¡¬:zrL{µ¹zÕ÷|b}Oƒ`(uš7êø0s!Ñø ¼Ne�8Ìütr|LYtc”ü†‡}Ñÿ$'Í?XÓœ&nbsp;f/¨•39
PÃál²®sY”0—�2xøZ*úÝÏêt°S?ê2•=¦bAPMóïtØÀªÁìµ¼™à}ZyÙ@	ÕD°—ÚhÄ©Í÷µÇ&gt;9²”0¼çáãB»Ûzû�‹L¾&amp;ãæjÂ¥L–1»#²=çsv)érÁb8A(jóO�o1L‹*Ì*âÃ
¨Ñý—ô”õq7™Ã�Q‰Â`“6Ù-óû/w¯-meèL�´\]
‹c’"øGÇw[®†#úr¯7 ŸFÂ·§°ŸCÀç´§
X¢+F£ŒKôxœŒcye�æÖÖÛ€õ&nbsp;Ã–˜š®[ø
}¿
N5åù?wúmÔ&amp;UZvfc¼“d¼š´ÖÁÕyÝ¥#b¥ôhÑéöÖš]�&amp;QóÞ¸tÄ�*Vù\ÿ~#BÿÛñeóÙuˆ/gÃØ2báwP¿,mÙ¦¥«õ)ã™‰™}°YWó¨ÞP`rÝN½¡ÎVè¸c}'œUà­&gt;?2G�±HÎh¸º¬x’6»î9ÏºÉÐØÓê=ø=ØR'ý‚7¨°}s;mÀ:ÿïp°6…!¬np‰·»Â¼7_ê»-ær?]«tí%I¡8òWÇðf¯?Zö++vÇo#Ò2¼±3Ùú×UP_XkÊGæ¨]8„ÈÞDTœý&amp;˜ðï³{Ô[_²�”‰Å%Z4Y†òvÛØãWááá„¿Œ‡kß(–×\�&nbsp;Ó&lt;¢c.æUp	YíÄª4æ¤g»¥�º%ö?UžÖ´Iõ§7²ø«{xÓóõˆxQ8L†™ÝÑìˆF~•TbÈÚf¥TGKoc	1Q$¯¾iÄFXÏ½¡øiÆÃZMÊ™õõh`3‰Ã}~}&nbsp;)â‡Žáåg¿ƒ«“ÁËÏÊŸ,«“–Ô&nbsp;5$Øe„w‚)î©'Íq‡WÌœìæLÒÅ8Î…6±¾¥6{f¾C&amp;l€@'´%LºJëº&lt;Ç8{;ÏÌ¶à5�\„_öotÝœNxí9NŒTNøÓ‚YVqN¥‰Â³'÷‹‘	€f¸Cù­¸‰Î{)À­ªã^vO/=0”º÷Å£VòŒÜ½þÇv4µÒO9Ôž„Qaœ%0t|'³]±Ý¥
åîSÛÞ9W^ì|�KwAKôpZ—ÚŽÒç.Ÿ@®[;œªc{e]`·h;ïý(¼ËTpÏí¾”éÉ.ïlŒšÖî3%@ö¥n¡Niƒ¦rg\¿°&lt;¥&gt;\î‚RðÆ?ÒO’×ôm“Å‚Þ»ûxæFX·áÛþ0ØË¬ûu5îîlPÁp:�ÖòsŽ#€¹žgv»ÞR—â¯”{È�	ÿ„O˜òþñŒ+i“Ú&nbsp;aJÙ¢aæ@¯ì-zØ ¬”`Úû˜Ã»§vñª¼ ;p9ý”¾!æ¡«Þ”9²&gt;&lt;Nž²Dc^Ìç7òÒý B€³§'×Ýš¬±�5Ã}I©ö¸gWªe´ÀÔââBùˆôç•o¾‘¸åw,TJlY¶�ŠS†×§ÄS/çÇµ-»PÏó¬T¥ÜäåÐÚômüçd›}_öû`$N;_l;Í�€ COH(WÃˆÙ»
¯ºzÒö/¦ç¦P®ð"z#oÈÅŒuà-K—AøXÁ�¿®SàB˜YÅDmŒþƒCÅ/‹Áp¶vø€qã¹ÔPsš3(‹Pïñ+LÒv7W¦&lt;Ô!¶²á+Áw{ml°Pç®r@nsuuTg°ÅHì0ÞG¸¬E/:|Ì�ûÀgGEl=²ìÑQÇF5_ô`Ct˜L&amp;r×ŠàÛãN¨çßIôÙ¯ÎÑÔrDì·³ütr6H›W³©á5Py†¸)´ FFdúøµê¤ö¿¼Ís&amp;XAÖÖ±\Ì6æ¬Ub:iÈ_1œ·´mb;½Šq•ñîË¯Í»8Í9ÊfKÅ³×[u&amp;âÛnª¦&amp;Ë"é¢õB·�˜ïuŸø©EîŸaà8qëÊ	ãíø*¿&lt;Ï *‹´fS15÷î¨©:â©Å¦-3öÈù´�ñEãÓ�A½}šd
Î™Òü= RGW?ÖUì˜U¿»²áŠÊNÇ…�(á­}b¢/WnT	Ï_DgòÝûnÌ¡”/EŒaç¢êÆV`�rø„BšOî|ŠÚ­TàìšÜyá‰»PPáûË £?T’Í¡CÊðs¡µì5x†y×�ñæáÜÏ_'§L´Ãx-(§�U&nbsp;bû[ír&gt;Co™»†j²	Býúç†íO,ô×‰²¬Œ•‰È�—T&nbsp;SæÂÖý²'‘|ã[0}&gt;vE&nbsp;âÐÚa†7LÉtàù0ÒÄH6nx×”ŒÚ¦E…è„žßÍC�³ˆ#”lÇ4ç&nbsp;}ÏG=x=í'´æ#árýÕtƒ,‚ÔÃŸp;¹ïÚrf¶Å[Î¡ÕH?”‚-ê'Ì¦ÜX¶Á-é‡dìõžIV
[�±	ƒ5Úñ¾d&lt;ÆŽž·L/î9þSGæOŒq;«T^�…œå�@¶x•ââñäïŸxœ0ë³­'ƒXòOaÐð‰³´+š“
®ˆ[ˆø;igV`Ôz}á±„n&gt;Éõ&gt;â¬@‚ù‡ç(ÏNwSF~›¨H¶;P’ñˆî´Õç)b½øG–�—ÂU–ÀQ/§Ð^Û¼d„vÚË–N?7½ùj¤‰Îï¼Y
kG–ˆ½À“ÊBÆç€EC`ÙîŸ?.„þù5âêEÉé&lt;¦Hªþ^øÔ!µÎÛe19ü,âlÝœITw sPÇFí�=µœÍ?Rn'Ds‡vK‹7m^„Ù¿p–ŒÑX
ÉÎb§R&nbsp;%ì))åðà gF©_¿Ðþ9ÌCÖúWGÂ@¹!~Ýã}rÂK÷¢Öµs5e[þIBn-É3ú*AUIž­±Š]�#l81nfŸc)ôLß¡g�
ˆ¼£¯FŠ\¸Ç^ïÒ¬�wÌ—0;öÑêä§GEóÓ"Ë³fó
øX*`‰{ˆÌB«3ÝŠmX¨&amp;ñþ·mÕŠ²©š]ºì�Ëó üˆqXi’“çñ(†aÜ
@0ö�.Díz«+êŒœ'µqX]&gt;�8óšª¤r(¤�ßW(¢eã‹‡‚YA,±õ/É–�hizjGž�,m.×Üˆ¯.Y+„nÈT‚7þp¯:|Goª‡­
‹X°¨‡Zø6&amp;L²×ú#Ÿ­Ÿí §sØ&nbsp;žä½×ùÃ
ÕJW$ç
8aY&nbsp;”†êkÿ²X=­ïIrd¯€ÃËÊ¤ž˜.•ÿä¶‹g™$Š^«&lt;Þø¥Ÿ•*ˆÐxEødèriR5YÖÏi‘+âÔ«x‰¶\®ÓÅ{
ŸîVå?B‡�&lt;ë] ëËî:Xå$÷SBáKN[F�¬ê¬è=C…‚³NƒO(ÞåÐPW&amp;ƒÃâ}Ã8wž¸3éJI”×9G#8NmW„ª±iI‰ûœÏ¤$ÍïNgr11§8‘É
îÐ–ÿ¹lžG­ƒÚËÔ3\x—HSâx˜ð"S…�á4@Wâ’•Ì@Õ(jE„ª
dã{8·2œŒþVŒÍð9q¬�ÏOtÅfyš%ÜpL\Öb±Õ„¥Ú™Žzåmí~þí¡Ö78R�âªË‹ÐÉúýÊ¨%&gt;L²È¶Õ™Žl–ý~ö
Ž\Å“#SöläQáù@z9ÒvÃ°�FZÕâU†“ç†c%†=þEdµ;¨£ÚCó•¥sf7OŒC�‹Û€€¾rqÁ([ü±‡X\•[Z›õmUõŸæîwk4³†	]?ÿY_áŠÀéj&amp;¬UáÃ(dW‡f¿%V†G"{ÏÛUdÑ×„W¿À„¡c&lt;•ˆUW.ùÂ<wemj%º‹Ü#‡øÚ\þf�Ïbàn…Ìçzq.hÚaŠš¸Ž+‚¦«Ú%¯ˆ¿’�i*‘¸ïžÇßrß†í£Ê²¦>#OZy?ªD½qÝfK¼cŸlÔ'åGÑºýõ‚Å-x²´ÎZGr—ôé‚÷óÄé+?XÝ#_[¤ì½	Å„6üsl5
ð‰Œ÷±ÌÑ~ù»ñàvÂ3ûÕï�HT¹OöMùˆƒ¹eL¤Âl™Y«(ê‘3mðbBO)Ï˜ø
æÍYb–&lt;î~óÖ¿x¡°S�ƒ
2âQÛTM±áÂæð¸¢Õÿ_:nºðÜ9ÒVŽA¨6¸&gt;ó½�h�H6¹™Ô±A²7NÕ¥žäæ|�Ìû.€rlêMsÐ•�läÛ(f0Û0Œ^€ªö·�¥áûsnÁ\._àñløÈ.�Qò¬à=e‘i¯Ä$Û½ÞN‘wIKÛ³”“ä›|iŽ1?ÆØÂ!n…øú¬ƒÁ(Iè ¶IÞ�'ÓîýêàCãþÜY€VÔ(œ,JV°ý�ÙYšWbÅé§»3?!äà”Òè5…ÕÍ…z?ï,GÀ°]úä±®+¨gùFÙ¿€qÝÐg¯Xç`ñý‘H|žZóëNGòŒ@×nù�ë!(Bå‚{XÊ(!‡ŽXó§ï$c[P$ßb¨Û/!lyîH�âi€1˜´NAbËåt;êN‘§éÐö`ô
Îj•ÓŽŠ¬SüËÜŸŽur!!«�)Sß£¹y¢¾i±iŽG³ŸÐwW×CµˆSc¬;ð–7íB-™“¢^ÂÈ ‚«O
{wã½„J§×üøŒó¤9�ZæÉb8£\‡Ï±™—¼^kO;YU,‚/ª°Xå¼ÌD‰+¼˜Àý¥&amp;q™&lt;1V&nbsp;Bhû3Ê… EùI®¨�±’gÐxeÚƒxK‡Ž^�«Cé¸q9WËñ§X["(ÓbQ·bÐs€4ûZ…º±Þžì»ëûU%*�nºi½&lt;Á®†·Gô»W†öõP‹³^¡9È¤K¯œ˜FCÒÏgó*s²ÁFç+ÒÍ°Pôe#÷a8›1òêOöë=ÕZÂ›Žw?¿Ò"™´f¤¼¿ƒÙ&nbsp;…â&gt;¾–Ly¨›¥˜Úýœ§sh¨?’9Þ×¤ƒ(ÕúfB�¬S×ùÉÏÍÞ„‚$Á�)Ø:&amp;…‰1oÛXÑÖ±òÜÂÇNï
œ±�þµðaØŽ`öâôãLò›Ñ�i„täj?Â�RBUF7+à%žÕ	î@š­ÌãBºšæ‚&amp;"À‹f&amp;ýµlÀ²MÓd-)nÐÅïWèùf[¨Ëä¤„…K!ê›Î =›s(æäæ¢ŽhZ?°àê,ˆOè]Ìé_YÝùäÙÉôÏ«X#«=Ãig‘Â8U³Èg~¸Y’þ•hx1Q6P!§}âj³)ÿÀzÐwÒÛG
&gt;\oÔ$
S�€´¾^ÔMmPÍjqË|QoÄ°áÒp£¡ÑVqAÑ—Ü)

˜eù)­€5¯£€�zè\^…ìýš3ãì*Á¹îí!]Oó„3Š9Ó^àø55È„È“—×¶t™R@„¯Ä®¦uŒéÖwÈV4,ª£Éœlïá)U[J¤Ù;aÑn�H‰Ž
y&lt;£«¹rÜû2ø�k4z®‚¢+¶¿&nbsp;èØñX×žÏ—Kÿe“zvIU­›»ÓaÕ&lt;Ô3®ÜÞæŸ|ÏvE€e&nbsp;]Ö1ú¨HÆÄ^êÄÐ\¥v™E=üPM&lt;Æé’ÉÅi¯„êœ1Ù,t‘rê0iìIø}âsI¦¤N|÷2˜è]€T½3;Ùã`{amPcÞád€ÏT˜N%&amp;Ô×G	¿ýHÍU~=@‚vœ0”9qØ@ˆ}ÆÐ­H°õfÞ—º‰ç½µúIiKØf�mOW¿“�ãì,lÁ¦¡S.C"bx*ú¥j}º–å›Vj¶´Ô§G@–]˜•5â£,³ü&nbsp;ºPÖ�GÉè"Ê�Àxó¯_d`�Á�Vtý¶&lt;ÛYýø,µ80ÖÔ§yœÓE5“v©4Œˆ_©—Œž¬ü¨÷l±2&lt;‡˜ÛÔ•Á„�&amp;�àÏ²‡u'ÖÍ\ü¥Ü.?àðšñ}ølá©¼#�·S‹enê2õo­Û«ïå`é—‡°,ËMµ�
¢T�ŽS“Ä9œæ¥£ôÐÎ–ÂMøèßb�6üú”fr3Á ÓYc�d£b¥•à±LŽ$«Æ†ˆ7ôQ³à�OU–uÕó7Neÿ*ókâØÅÿ`×©¿‘öÇxñtøpfã+Ýv'“^¥œ�èµìF
»~È9Þguq`ø™ü9î-BÉè³qâ¡Ì%h-Ûn…JF_¦[£Èw¥`&lt;\U.lÞZ´!(‡€âÙ²ÛDZ0®´*§ë›&nbsp;ÞÚ–še¡Õ"ÁÐy¥§~§TÒÅlÇ0SüxÄsG�8®�SS*5çó;†2JT»Ø‘UB&amp;f|î<púß¶¿93žg”tÏö|nº•×4|¨zx+vÖ]‰´)c‘¼ât¬› ðuÒ¥ãlà×‡j<¤îh="" ·^káqµt€èb}+lÑ©_="" ÍÃÈx‚¥þ£2üo0¦hc0«Ëô·z£="" e3©nt±”ÀÄlsq ¾l3§›š6k^Ü:ƒûìi…É"ü6ù×'¯c×Í®<p4Žêxspez1@¼¿²ÑÓ‚°âdàØiÐe¾À«»ˆlå†)–~ÛhgËf›@ºÏ°fãp†f="" %Ä2µk5aùÔi9nÀ"~ŸÄ­9}gqçz]%Çô±!15zvŸô-ezr)Æóiè:•còñ¾j3Ô%h="" ã�\à8îv¼›¦©“v§òñ‘“•~="" Ê6Ð="" mtft03="" i:¡‹ÿh¬akêt*& ="" {�ÕªÚôùù="" ·£Æ(ìÖ9üük#ðïŠwobi±l�(Ðœ?ñêˆ—Ôsq¡-r˜xÃ‹px%÷‰v}¼5‹•¡‹ùû„¸Ûho-¤ï„¢ÿŒÙuáe©øþ‰¤a`,a€m7ªi–rÛ÷�fez¬Ð…k.}sñÁ’¥8²�Óo'é?]?,¥-áºaÕ´vòfj�¼žÆÆ6_Ãé(u!ù3guùåólücr)3žzø59à�°6$øâ’ïÕ©§4ñÆhsñ‰�oµ»noÆ2="�ŒiêR‡#ÆµYª+hQJwCçBy/A´H&nbsp;Â" q¥u"„‹øé:c�ÆÑwòqx1p°?Ð+©™æx²�b|Üf="ŽªÄ²,q`”Õba}n•ñ|yŸYó;íÆÔEB­¿á�é¶L§’’8HÑÜÑµò‘jÎ�g­µLŒ&nbsp;¾`™Mºªhw™õò•·šÅæwT—†³Î�»R]3ºî�²Îúè/|‰°ˆ§vr1û£6ÎB¸´<<™»°ãLˆöˆ�×çS1·6ø!¼ñ—›" šv="">Í€½±1¨T5w¤Ò4öªV¶-_;­_÷üÀ¢càCò9V8äÈ‹Éw�àµ¦u1ÐCÒÍªþ3N†Üoˆ@#�ÙÈªÖ%ÎO¥ˆ¹
c?ÿOl2t¨»(–˜°1#*«QqÈ&gt;ä«ÇJø¸ƒJ¦SÝþùcåpÿ–Ãà�•ÓÎ-ÀŽ¢Ê”ÓF¥0Båò0¬ì&nbsp;/‡U�d"žŸéPebFX)ÞXx&amp;¢¤Ñh›ç&gt;PÌƒž³))ŒÚ÷`R&gt;†j=çtQå~Â;b£Ò{îyÊUÆ­+:mLbzi8…‘°AÙ~‰“OñËÿV½ooB•cQ­¾ÆRÞöÊ°/tI�­ü¹¹³ü
ç:Â;)û§{¡€RsÙ÷aß"Õ+¹I¼O#…Eº&nbsp;¯€*¦rudêdI/ÁÿØ†¿ößuÏ�!w†U2×Ì—`§ëgúÑv¿]¢&lt;+ÑrCË}É{‹	&gt;‚ýT¾I)¦E9Å®Tvý�ëÙ‰øÃó§¸@Yþù!¨Ø:n~H~ÜÖ3-£ýOL.-‡@}f„* ¹b2J6HyŠGHOª}É½«±à¬œ¤8RB°"úâ6zµNÖiu%eœM×uGŒåÅôµ‹p=£j²ö»_È°/_Œé oGªßFo_–HÑR1Ò€yNlê÷•[úûk€‡KÓdÏèvuSÉØïâ^®À‰Akü‰"y£9ÃJ+ÚLùòóË.ú»ÐMèŸvŒû¾Ëö7zOKvròF½Š#PF:ñ[k"ˆ°_/¡ÅîÇßþþ-ò+u�®�F•sMa•	òVëØ¨úúB+WÛFšÙ;(Ô&amp;4"Hë4'uÃ4C&amp;hfqÎ½&gt;k†ŒÕ"áÃ^†W_o	—·Äñ.OÓ&amp;ƒáº–g-éHvs8CÖñfµB$�âÛ:H=OþãJ¹¦Éú,Òœ?=™SëélË†;ðFÁ’ªàì†µ 5(hN„;™™;;³Û•SJN”þêd²kõM[Dq=p‹Æ©Á‚�
,Nò�ùœÝ!m|´y}QƒLX¼V 
#Aµ½)7•&gt;˜Ý+xÀó:4&gt;ªìÜçå=Mãt~LIÓJ‡´’„M|›’¤*0±	ñCË»–†éFç4ÕˆPüâ¤(…7Õ›Ð«qäá~ìA‹“´÷8ƒôUê`P&gt;</púß¶¿93žg”tïö|nº•×4|¨zx+vö]‰´)c‘¼ât¬›></wemj%º‹ü#‡øú\þf�ïbàn…ìçzq.húašš¸ž+‚¦«ú%¯ˆ¿’�i*‘¸ïžçßrß†í£ê²¦></a}×¨¦’mñ2uýúsþã¶µf”�[g`></a€â-ñôší³’è¯=¬éky÷ãßm~•‚></tøþ˜ì\></v%aá£œps1�l`ôbä2[›;�></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</a></em></p>]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I deleted my Facebook, WhatsApp, and Instagram accounts, and felt great since]]>
            </title>
            <description>
<![CDATA[
Score 414 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23634788">thread link</a>) | @shog_hn
<br/>
June 24, 2020 | https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/ | <a href="https://web.archive.org/web/*/https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2503">
	<!-- .entry-header -->

	<div>
		
<blockquote><p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content.</p></blockquote>



<h2>The human problem</h2>



<p>It started with an urge to delete Facebook around 3 years ago.</p>



<p>I had noticed how Facebook was mostly just a highly filtered stream of content. Everyone’s happy thoughts and high moments in life, delivered to me in an algorithmically curated form.</p>



<p>I was part of the problem too. I posted things I was proud of, or the happy moments in my life. Very rarely anything else.</p>



<p>Facebook is for the most part, just a small, narrowly defined window into people’s lives.</p>



<p>We see the full picture of our own lives, but end up comparing what we have to this small, ‘happy’ slither of other people’s lives.</p>



<p>For those who don’t notice this unfair comparison, it can lead to moments of envy, anger, or even depression.</p>



<p>Don’t forget about the fake news, agendas, and other drivel that is posted around Facebook either. Scrolling through this kind of stuff on a daily basis will numb the mind and lead to one becoming complacant and perhaps even completely mislead.</p>



<p>One only has to look at how entire countries have been divided and swayed by lies posted to social media platforms to see how poisonous they can be.</p>



<p>The poison runs broad and deep on these platforms. There are many bad actors that wreak havoc, from state sponsored, to criminals and scam artists. They all have agendas to propagate, or nefarious goals to accomplish.</p>



<h2>The data problem</h2>



<p>The number one question to ask yourself whenever signing up for a ‘free’ account of any type is “<strong>Why is this free?</strong>“</p>



<p>A free product, is <a href="https://fee.org/articles/the-hidden-costs-of-free-social-media/" target="_blank" rel="noreferrer noopener" aria-label="not really free (opens in a new tab)">not really free</a>. There is always a catch. In the case of Facebook, you are paying with your own data.</p>



<p>Your own private life, details, habits, information and more is being collected in the background and used to make money for Facebook. They sell your data, and you pay with your privacy.</p>



<h2>Deleting Facebook</h2>



<p>As I mentioned at the start of this post, the urge to delete Facebook began around 3 years ago. It took me year of thinking about it before I took the plunge.</p>



<p>I exported all of my data as a .zip file, and uploaded it to some encrypted cloud storage for safe keeping.</p>



<p>Then I logged in, went to my account settings and requested that my account and data be deleted.</p>



<p>Facebook leaves your account in a ‘to be deleted’ state. They say that if you login again in the next week or so, it’ll automatically be re-enabled. This is a sneaky attempt at catching people out who have a habit of using Facebook on a daily basis.</p>



<p>I was diligent, and after a week or so my account was permanently deleted. Good riddance.</p>



<h2>Instagram purge</h2>



<p>Next up was <strong>Instagram</strong>. Facebook owns a bunch of products of course, Instagram being one of them. My Instagram account had been up and running from when the product had first launched, and was not a part of the Facebook group, but now that it was owned by Facebook, it had to go too.</p>



<p>The same reasons apply as I listed them above for Facebook.</p>



<p>Instagram was the easy one to delete, I didn’t really interact on the platform, and had just kept a bunch of interesting photos on my account. On a rare occasion I would browse through photos that others posted and that was about it.</p>



<p>The account was purged from my life with little fuss or care. More time cumulated over years to come for me to use on more <a href="https://www.shogan.co.uk/kubernetes/building-a-raspberry-pi-kubernetes-cluster-part-1-routing/" target="_blank" rel="noreferrer noopener" aria-label="useful endeavours (opens in a new tab)">useful endeavours</a>!</p>



<h2>Killing WhatsApp with fire</h2>



<p>WhatsApp hung around for a long time. This one was more difficult to get rid of. I had my family contacts and many friends on WhatsApp, and it had become my primary messaging platform.</p>



<p>I started using Telegram alongside WhatsApp and convinced quite a few friends to join.</p>



<p>Telegram is by far a superior product to WhatsApp. I’m not convinced it’s perfect, (hey it’s free too). But at least it’s not in the hands of a massive entity like Facebook. Less power to monopolies is a good thing.</p>



<p>About 9 months or so ago, I sent out a message to most of my WhatsApp contacts telling them I was deleting my account and telling them where to find me on Telegram if they joined there.</p>



<p>Shortly afterwards I deleted my WhatsApp account and have not looked back since.</p>



<p>Telegram offers far superior group chat options, more chat features, bots, and more. I’ve been very happy with it as a replacement for WhatsApp.</p>



<h2>Post Facebook, WhatsApp and Instagram</h2>



<p>I really feel happier without these three apps in my life. Facebook was a time sink, where I wasted time that could have been better used directly interacting with family and friends, or working on hobbies.</p>



<p>Instagram wasn’t too much of an issue, but there was (as with the others) the problem with my data being sold off.</p>



<p>WhatsApp was useful for messaging, but Telegram replaced that and gave me way more useful features.</p>



<p>I feel happier knowing that my data from WhatsApp is no longer up for sale, even though it was of course just a blip in a massive ocean of data.</p>



<p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content. Simply as a result of me having deleted my Facebook, WhatsApp and Instagram accounts.</p>



<p>That’s 121 days of my life I have had available to use on better things already.</p>



<p>So that is the story of how I deleted my Facebook, WhatsApp, and Instagram accounts.</p>



<p>I encourage everyone reading this to take the plunge and delete your social media accounts wherever possible. Whether it be to save time in your lives, or to stop allowing your private data to be sold, you’ll be happier for it.</p>



<p>This is post #3 in my effort towards <a rel="noreferrer noopener" href="https://twitter.com/hashtag/100DaysToOffload" target="_blank">100DaysToOffload</a>.</p>
			</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</article></div>]]>
            </description>
            <link>https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634788</guid>
            <pubDate>Wed, 24 Jun 2020 22:55:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Harm of Studying Abroad]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 109 (<a href="https://news.ycombinator.com/item?id=23631503">thread link</a>) | @jeffreyrogers
<br/>
June 24, 2020 | https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html | <a href="https://web.archive.org/web/*/https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631503</guid>
            <pubDate>Wed, 24 Jun 2020 17:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 311 (<a href="https://news.ycombinator.com/item?id=23630201">thread link</a>) | @kickout
<br/>
June 24, 2020 | http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630201</guid>
            <pubDate>Wed, 24 Jun 2020 16:36:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New technology for aluminum production promises zero CO2 emission]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23629859">thread link</a>) | @dagurp
<br/>
June 24, 2020 | https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/ | <a href="https://web.archive.org/web/*/https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
    

        
          <p>
 A new Icelandic technology intended for aluminum production offers hopes of eliminating CO2 emissions from the production,
 <em>
  <a href="https://www.mbl.is/frettir/innlent/2020/06/22/gaeti_minnkad_losun_co2_um_thridjung/" target="_blank">
   mbl.is
  </a>
 </em>
 reports.
</p>

        
          <p>
 The company Arctus Metals, in cooperation with Innovation Center Iceland, reached a milestone recently, when it successfully produced aluminum with this new method in a large pot. Instead of creating CO2 emissions, the process emits oxygen.
</p>

        
          <p>
 The main part of the innovation consists of using multiple,&nbsp;vertical inert metal-alloy anodes and ceramic cathodes, instead of using electrodes made of carbon.
</p>

        
          <p>
 This innovation could potentially eliminate CO2 emissions from aluminum smelters in Iceland and elsewhere.
</p>

        
          
  
  

  



        
          <p>
 “Iceland’s three aluminum smelters produce more than 800,000 tons of aluminum a year and emit more than 1.6 million tons of CO2 a year,” states Arctus Metals CEO Jón Hjaltalín Magnússon. “Their emissions make up 30 percent of Iceland’s total CO2 emissions.”
</p>

        
          <p>
 “If all our aluminum smelters adopted this new technology, Iceland’s CO2 emissions would be reduced by 30 percent,
 <span>
  ”
 </span>
 he adds,
 <span>
  “
 </span>
 enabling us to fulfill our international obligations and more. Using the new Arctus Metals method, an aluminum smelter, the size of [Rio Tinto’s] in Straumsvík [Southwest Iceland] would produce as much oxygen as a forest covering 500 square kilometers.”
</p>

        
          <p>
 Jón reports that a cooperation agreement has been signed between the German company Trimet Aluminum, one of the world’s largest producers of aluminum, which will continue the development process by starting production in larger pots, and planning to eventually convert production in their four smelters to this method.
</p>

        
          <p>
 The project was presented to Icelandic President Guðni Th. Jóhannesson yesterday at the offices of Innovation Center Iceland.
</p>

        
          <p>
 In the video above, you can see the first chunk of aluminum processed in this new way, presented by CEO Jón Hjaltalín Magnússon.
</p>

        
          <p>
 You can read more about the company and the project
 <a href="http://www.sustainordic.com/portfolio/items/arctus-metals/" target="_blank">
  here
 </a>
 .
</p>

    

  

  

      </div></div>]]>
            </description>
            <link>https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629859</guid>
            <pubDate>Wed, 24 Jun 2020 16:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Blew a Ten-Year Lead]]>
            </title>
            <description>
<![CDATA[
Score 834 | Comments 542 (<a href="https://news.ycombinator.com/item?id=23628761">thread link</a>) | @secondbreakfast
<br/>
June 24, 2020 | https://secondbreakfast.co/google-blew-a-ten-year-lead | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/google-blew-a-ten-year-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        
          



<p>Back when there were rumors of Google building an operating system, I thought<span></span> <span>“</span>Lol.”</p>
<p>Then I watched then-PM Sundar Pichai <a href="https://www.youtube.com/watch?v=0QRO3gKj3qw">announce Chrome <span>OS</span></a>. My heart raced. It was perfect.</p>
<p>I got my email through Gmail, I wrote documents on Docs, I listened to Pandora, I viewed photos on TheFacebook. Why did I need all of Windows Vista?</p>
<p>In 2010, I predicted that by 2020 Chrome <span>OS</span> would be the most popular desktop <span>OS</span> in the world. It was fast, lightweight, and $0.</p>
<p><span>“</span>Every Windows and <span>OS</span> X app will be re-built for the browser!” I thought. Outlook-&gt;Gmail. Excel-&gt;Sheets. Finder-&gt;Dropbox. Photoshop-&gt;Figma. Terminal-&gt;Repl.it.</p>
<p>All of your files would be accessible by whoever you wanted, wherever you wanted, all the time. It was obvious. Revolutionary.</p>
<p>I haven’t installed <span>MSFT</span> Office on a machine since 2009. Sheets and Docs have been good enough for me. The theoretical unlimited computing power and collaboration features meant Google Docs was better than Office (and free!).</p>
<p>Then something happened at Google. I’m not sure what. But they stopped innovating on cloud software.</p>
<p>Docs and Sheets haven’t changed in a decade. Google Drive remains impossible to navigate. Sharing is complicated. Sheets freezes up. I can’t easily interact with a Sheets <span>API</span> (I’ve tried!). Docs still shows page breaks by default! <span>WTF</span>!</p>
<p>Even though I have an iPhone and a MacBook, I’ve been married to Google services. I browse Chrome. I use Gmail. I get directions and lookup restaurants on Maps. I’m a YouTube addict.</p>
<p>Yet I’ve been ungluing myself from Google so far this year. Not because of Google-is-reading-my-emails-and-tracking-every-keystroke reasons, but because I like other software so much more that it’s worth switching.</p>
<p>At <span>WWDC</span>, Apple shared Safari stats for macOS Big Sur. It reminded me how much Chrome makes my machine go <span>WHURRRRRR</span>. Yesterday, I made Safari my default browser again.</p>
<p>My Gmail inbox has become a mailbox stuffed with clothing flyers, SaaS mailers, and Rollbar alerts. I love when people respond to Second Breakfast, but their responses get lost amid a sea of plastic bottles. I started using <span>HEY</span> last week. My new email is <a href="mailto:billy@hey.com">billy@hey.com</a>. I love it so far.</p>
<p>I’ve given up on Google Docs. I can never find the documents Andy shares with me. The formatting is tired and stuck in the you-might-print-this-out paradigm. Notion is a much better place to write and brainstorm with people.</p>
<p>The mobile Google results page is so cluttered that I switched my iPhone’s default search to DuckDuckGo. The results are a tad worse, but I’m never doing heavy-duty searches on the go. And now I don’t have to scroll past 6 ads to get the first result. DuckDuckGo’s privacy is an added bonus.</p>
<p>I still use Google Sheets heavily. But wow, Airtable makes Sheets feel decrepit. Where’s the easy API? New ways of formatting? Better collaboration? Simple sheet-as-a-database?</p>
<p>My new usage patterns:</p>
<ul>
<li>Email: <del>Gmail</del> <span>HEY</span></li>
<li>Search: <del>Google</del> DuckDuckGo (mobile) and Google (desktop)</li>
<li>Maps: Google</li>
<li>Docs: <del>Google</del> Notion</li>
<li>Sheets: Google</li>
<li>Video: YouTube (but increasingly I’m noticing other people use Twitch, Instagram, and TikTok)</li>
<li>Video Calls: <del>Google Meet</del> Zoom</li>
</ul>
<p>I’m a long shareholder of Google. It’s amazing how they have four monopolies and only monetize one of them. I’m confident they have a bright future ahead.</p>
<p>But the lack of innovation is frustrating. The product goals are all over the place. Microsoft has a new clear mission: The Cloud. What’s Google’s clear mission?</p>
<p>It feels like they blew a 10 year lead.</p>

          
          
          
          <div>
            <div>
              <p>
                I write almost every day. Subscribe to get new posts as you sip your coffee each morning.
                <span>When you join I'll also send you the posts that've made the front page of HN.</span>
              </p>
            </div>
            
          </div>
                
          
      

      </div>
    </div></div>]]>
            </description>
            <link>https://secondbreakfast.co/google-blew-a-ten-year-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628761</guid>
            <pubDate>Wed, 24 Jun 2020 15:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Websites]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 113 (<a href="https://news.ycombinator.com/item?id=23626929">thread link</a>) | @lcnmrn
<br/>
June 24, 2020 | https://sjmulder.nl/en/textonly.html | <a href="https://web.archive.org/web/*/https://sjmulder.nl/en/textonly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>By <a href="https://sjmulder.nl/en/">Sijmen J. Mulder</a></p>

<p>This is a directory of websites that <strong>primarily stick with
simple, marked up, hyperlinked text</strong>. I appreciate these sites
because they load quickly, scroll smoothly, spare my battery, are more
compact, and lack the usual nonsense that infects many websites.</p>

<p><small><sup>*</sup> not <em>quite</em> text-only, see preceding
parapgraph. See <a href="#notquite">Honorable mentions</a> below
for sites that aren't quite ‘text-only’ but lightweight
and worth visiting nonetheless.</small></p>

<h3>News</h3>

<ul>
  <li><a href="http://thin.npr.org/">NPR</a></li>
  <li><a href="http://lite.cnn.io/en">CNN</a></li>
  <li>
    <a href="https://www.csmonitor.com/layout/set/text/textedition">
      The Christian Science Monitor
    </a>
  </li>
  <li><a href="https://noslite.nl/">NOS</a> (Dutch)</li>
  <li><a href="https://legiblenews.com/">Legible News</a></li>
  <li><a href="https://lite.poandpo.com/">POST Online Media</a></li>
  <li><a href="https://www.ard-text.de/mobil/">ARD Teletext</a></li>
</ul>

<h3>Social</h3>

<ul>
  <li><a href="https://lobste.rs/">Lobsters</a></li>
  <li>
    <a href="https://rawtext.club/">rawtext.club</a>
    – “<em>Resist</em> the dazzling spectacle”
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li><a href="https://news.ycombinator.com/">Hacker News</a></li>
  <li>
    <a href="https://www.rfc-editor.org/rfc-index-100a.html">
      RFC index
    </a>
  </li>
  <li>
    <a href="https://www.freesoft.org/CIE/Topics/index.htm">Connected</a>,
    an internet encyclopedia.
  </li>
  <li>
    <a href="https://bearblog.dev/">Bear Blog</a>,
    text-first blogging platform
  </li>
  <li>
    <a href="https://mataroa.blog/">Mataroa blog</a>,
    another text-first blogging platform
  </li>
  <li>
    <a href="http://manpages.bsd.lv/index.html">Practical UNIX Manuals</a>,
    on <em>mdoc</em> and history
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="http://idlewords.com/talks/">Maciej Cegłowski</a>
    (talks on various topics, not quite text only)
  </li>
  <li>
    <a href="http://sommarskog.se/">Erland Sommarskog</a> (mostly SQL)
  </li>
  <li>
    <a href="http://bactra.org/">Cosma's Home Page</a>
  </li>
  <li>
    <a href="http://blog.fefe.de/" hreflang="de">Fefes Blog</a>
    (German)
  </li>
  <li>
    <a href="https://gir.st/">Tobias Girstmair</a>,
    <a href="https://gir.st/blog">blog</a>
    (hardware &amp; software hacker)
  </li>
  <li>
    <a href="http://verisimilitudes.net/">verisimilitudes.net</a>
  </li>
  <li><a href="https://lukesmith.xyz/blogindex">Luke Smith</a></li>
  <li><a href="http://www.tomcooks.com/">Tom Cooks</a></li>
  <li><a href="http://danluu.com/">Dan Luu</a></li>
  <li>
    <a href="https://www.artemix.org/">Artemix</a>
    (back end and UX)
  </li>
  <li>
    <a href="https://idle.nprescott.com/">Nolan Prescott</a>,
    or “Idle Thoughts” (tech &amp; thinking)
  </li>
  <li>
    <a href="https://prog21.dadgum.com/">Programming in the Twenty-First Century</a>
  </li>
  <li>
     <a href="https://nullprogram.com/">null program</a>
     by Chris Wellons
  </li>
  <li>
    <a href="https://greghendershott.com/">Greg Hendershott</a>
    (mostly Racket)
  </li>
  <li><a href="https://terkel.com/">Terkel</a></li>
  <li><a href="https://brokensandals.net/">Jacob Williams</a></li>
  <li>
    <a href="http://www.jaruzel.com/">Jaruzel’s Home</a>
    of Retro and Other Curios
  </li>
  <li><a href="https://allstead.dev/">Willis Allstead</a></li>
  <li><a href="https://www.thomasjost.com/">Thomas Jost</a></li>
  <li><a href="https://wildauer.io/">Manuel Wildauer</a></li>
  <li>
    <a href="https://rgz.ee/">Roman Zolotarev</a>
    (<a href="https://www.openbsd.org/">OpenBSD</a> enthousiast)
  </li>
  <li>
    <a href="https://drewdevault.com/">Drew DeVault</a>,
    creator of <a href="https://sourcehut.org/">SourceHut</a>
  </li>
  <li>
    <a href="http://jrm4.com/">John R. Marks, IV</a>
    (created with <a href="http://zim-wiki.org/">Zim</a>)
  </li>
  <li>
    <a href="https://creativegood.com/">Creative Good</a>
    <span>– Since 1997</span>
  </li>
  <li><a href="https://patrickcollison.com/">Patrick Collison</a></li>
  <li><a href="http://eradman.com/">Eric Radman</a> (BSD &amp; SQL)</li>
</ul>

<h3>Music &amp; Podcasts</h3>

<ul>
  <li>
    <a href="https://vulfpeck.com/">Vulfpeck</a>,
    an American funk band
  </li>
  <li><a href="https://techtonic.fm/">Techtonic</a></li>
  <li><a href="https://19hz.info/">Electronic Music Calendars</a></li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://gopherpedia.com/">Gopherpedia</a>
    (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">Gopher</a> interface to Wikipedia)
  </li>
  <li><a href="http://wttr.in/">wttr</a> (weather)</li>
  <li>
    <a href="http://rate.sx/">rate.sx</a>
    (crypto rates, same author)
  </li>
  <li>
    <a href="https://yarchive.net/">Usenet Archives</a>
    by Norman Yarvin
  </li>
  <li>
    <a href="https://every.sdf.org/">every.sdf.org</a>,
    a collection of plain-text files
  </li>
  <li><a href="https://www.craigslist.org/">Craigslist</a>
</li></ul>

<p>Please send me suggestions on <a href="mailto:ik@sjmulder.nl">ik@sjmulder.nl</a>.</p>

<p><a href="#top">Back to top</a></p>

<hr>

<h2 id="notquite">Honorable mentions</h2>

<p>Note quite as ‘text-only’ but lightweight and worth
visiting nonetheless!</p>

<h3>News</h3>

<ul>
  <li>
    <a href="https://readspike.com/">Readspike</a>
    "Simple news aggregator"
  </li>
  <li><a href="https://spidr.today/">Spidr</a> (aggregator)</li>
  <li>
    <a href="https://www.svt.se/svttext/web/pages/100.html">SVT Text</a>
    (Swedish teletext service)
  </li>
  <li><a href="https://radfi.com/">Radio Fidelity</a> (aggregator)</li>
</ul>

<h3>Social</h3>

<ul>
  <li>
    <a href="https://subreply.com/">Subreply</a>
    (social network)
  </li>
  <li>
    <a href="https://needgap.com/">Needgap</a>
    (“problem validation”)
  </li>
  <li>
    <a href="https://midnight.pub/">midnight</a>
    (“networked writing” platform)
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li>
    <a href="https://sourcehut.org/">SourceHut</a>
    (git, mailing lists, etc)
  </li>
  <li>
    <a href="https://archive.vn/">archive.today</a>
    (web archiving)
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="https://engineeringblogs.xyz/">Engineering Blogs</a>,
    a curated collection
  </li>
  <li>
    <a href="http://lucumr.pocoo.org/">Armin Ronacher</a> (mostly Rust)
  </li>
  <li>
    <a href="https://www.gwern.net/">Gwern Branwen</a> (various topics)
  </li>
  <li>
    <a href="https://hugotunius.se/">Hugo Tunius</a> (programming)
  </li>
  <li><a href="https://usmanity.com/">Muhammad Usman</a></li>
  <li>
    <a href="https://sgolem.com/">Stjepan Golemac</a>
    (JS, React, Node, Rust)
  </li>
  <li>
    <a href="http://maddox.xmission.com/">”The Best Page in the Universe”</a>
  </li>
  <li><a href="https://lawzava.com/">Law Zava</a></li>
  <li><a href="https://hitstartup.com/">hitstartup</a></li>
  <li><a href="https://jvns.ca/">Julia Evans</a> (tech)</li>
  <li>
    <a href="https://wingolog.org/">Wingolog</a>
    (mostly functional programming)
  </li>
  <li>
    <a href="http://matt.might.net/">Matt Might</a>
    (medicine and computer science)
  </li>
  <li><a href="https://mnmlist.com/">mnmlist</a></li>
  <li>
    <a href="https://neil.computer/">Neil Panchal</a>
    – “quantum integrated circuits”!
  </li>
  <li>
    <a href="https://www.imperialviolet.org/">ImperialViolet</a>
    by adam Langley (mostly crypto)
  </li>
  <li><a href="https://sirodoht.com/">sirodoht</a></li>
  <li><a href="https://sheep.horse/">Andrew Stephens</a></li>
  <li><a href="https://fnune.com/">Fausto</a></li>
  <li>
    <a href="https://noncombatant.org/">Noncombatant</a>
    (tech, music, more)
  </li>
  <li>
    <a href="https://daringfireball.net/">Daring Fireball</a>
    (predominantly Apple)
  </li>
  <li>
    <a href="https://inessential.com/">Inessential</a>
    by Brent Simmons, author of NetNewsWire
  </li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://wiby.me/">Wiby</a>,
    a search engine for these kinds of sites
  </li>
  <li><a href="http://www.jimmyr.com/">JimmyR</a> (aggregator)</li>
  <li>
    <a href="http://amasci.com/">Science Hobbyist</a>
    (90s design warning!)
  </li>
  <li>
    <a href="https://tilde.pt/~fimdomeio/index2.html">Web 0.5</a>
    (only for text browsers!)
  </li>
  <li>
    <a href="http://gutenberg.net.au/">Project Gutenberg Australia</a>
  </li>
  <li>
    <a href="http://www.rowlingindex.org/">The J.K. Rowling Index</a>
  </li>
  <li><a href="https://copypastelist.com/">Copy Paste List</a></li>
</ul>

<p><a href="#top">Back to top</a></p>
</div>]]>
            </description>
            <link>https://sjmulder.nl/en/textonly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626929</guid>
            <pubDate>Wed, 24 Jun 2020 12:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Fly During Ramadan (2013)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23625215">thread link</a>) | @luu
<br/>
June 24, 2020 | https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/ | <a href="https://web.archive.org/web/*/https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A couple of weeks ago, I was scheduled to take a trip from New York (JFK) to Los Angeles on JetBlue. Every year, my family goes on a one-week pilgrimage, where we put our work on hold and spend time visiting temples, praying, and spending time with family and friends. To my Jewish friends, I often explain this trip as vaguely similar to the <a href="https://en.wikipedia.org/wiki/Sabbath" target="_blank" rel="noopener">Sabbath</a>, except we take one week of rest per year, rather than one day per week.</p>
<p>Our family is not Muslim, but by coincidence, this year, our trip happened to be during the last week of <a href="https://en.wikipedia.org/wiki/Ramadan" target="_blank" rel="noopener">Ramadan</a>.</p>
<p>By further coincidence, this was <em>also</em> the same week that I was moving out of my employer-provided temporary housing (at NYU) and moving into my new apartment. The night before my trip, I enlisted the help of two friends and we took most of my belongings, in a couple of suitcases, to my new apartment. The apartment was almost completely unfurnished – I planned on getting new furniture upon my return – so I dropped my few bags (one containing an air mattress) in the corner. Even though I hadn’t decorated the apartment yet, in accordance with Hindu custom, I taped a single photograph to the wall in my bedroom — a long-haired saint with his hands outstretched in <em><a href="https://www.google.com/search?q=pronam&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ei=fR8WUre0GIG28wSH94DwCw&amp;ved=0CAcQ_AUoAQ&amp;biw=1046&amp;bih=733" target="_blank" rel="noopener">pronam</a></em> (a sign of reverence and respect).</p>
<p>The next morning, I packed the rest of my clothes into a suitcase and took a cab to the airport. I didn’t bother to eat breakfast, figuring I would grab some yogurt in the terminal while waiting to board.</p>
<p>I got in line for security at the airport and handed the agent my ID. Another agent came over and handed me a paper slip, which he said was being used to track the length of the security lines. He said, “just hand this to someone when your stuff goes through the x-ray machines, and we’ll know how long you were in line.’ I looked at the timestamp on the paper: 10:40.</p>
<p>When going through the security line, I opted out (as I always used to) of the millimeter wave detectors. I fly often enough, and have opted out often enough, that I was prepared for what comes next: a firm pat-down by a TSA employee wearing non-latex gloves, who uses the back of his hand when patting down the inside of the thighs.</p>
<p>After the pat-down, the TSA agent swabbed his hands with some cotton-like material and put the swab in the machine that supposedly checks for explosive residue. The machine beeped. “We’re going to need to pat you down again, this time in private,” the agent said.</p>
<p>Having been selected before for so-called “random” checks, I assumed that this was another such check.</p>
<p>“What do you mean, ‘in private’? Can’t we just do this out here?”</p>
<p>“No, this is a different kind of pat-down, and we can’t do that in public.” When I asked him why this pat-down was different, he wouldn’t tell me. When I asked him specifically why he couldn’t do it in public, he said “Because it would be obscene.”</p>
<p>Naturally, I balked at the thought of going somewhere behind closed doors where a person I just met was going to touch me in “obscene” ways. I didn’t know at the time (and the agent never bothered to tell me) that the TSA has a policy that requires two agents to be present during every private pat-down. I’m not sure if that would make me feel more or less comfortable.</p>
<p>Noticing my hesitation, the agent offered to have his supervisor explain the procedure in more detail. He brought over his supervisor, a rather harried man who, instead of explaining the pat-down to me, rather rudely explained to me that I could either submit immediately to a pat-down behind closed-doors, or he could call the police.</p>
<p>At this point, I didn’t mind having to leave the secure area and go back through security again (this time not opting out of the machines), but I didn’t particularly want to get the cops involved. I told him, “Okay, fine, I’ll leave”.</p>
<p>“You can’t leave here.”</p>
<p>“Are you detaining me, then?” I’ve been through enough “<a href="https://www.flexyourrights.org/" target="_blank" rel="noopener">know your rights</a>” training to know how to handle police searches; however, TSA agents are not law enforcement officials. Technically, they don’t even have the right to detain you against your will.</p>
<p>“We’re not detaining you. You just can’t leave.” My jaw dropped.</p>
<p>“Either you’re detaining me, or I’m free to go. Which one is it?” I asked.</p>
<p>He glanced for a moment at my backpack, then snatched it out of the conveyor belt. “Okay,” he said. “You can leave, but I’m keeping your bag.”</p>
<p>I was speechless. My bag had both my work computer and my personal computer in it. The only way for me to get it back from him would be to snatch it back, at which point he could simply claim that I had assaulted him. I was trapped.</p>
<p>While we waited for the police to arrive, I took my phone and quickly tried to call my parents to let them know what was happening. Unfortunately, my mom’s voicemail was full, and my dad had never even set his up.</p>
<p>“Hey, what’s he doing?” One of the TSA agents had noticed I was touching my phone.<br>
“It’s probably fine; he’s leaving anyway,” another said.</p>
<p>The cops arrived a few minutes later, spoke with the TSA agents for a moment, and then came over and gave me one last chance to submit to the private examination. “Otherwise, we have to escort you out of the building.” I asked him if he could be present while the TSA agent was patting me down.</p>
<p>“No,” he explained, “because when we pat people down, it’s to lock them up.”</p>
<p>I only realized the significance of that explanation later. At this point, I didn’t particularly want to miss my flight. Foolishly, I said, “Fine, I’ll do it.”</p>
<p>The TSA agents and police escorted me to a holding room, where they patted me down again – this time using the front of their hands as they passed down the front of my pants. While they patted me down, they asked me some basic questions.</p>
<p>“What’s the purpose of your travel?”</p>
<p>“Personal,” I responded, (as opposed to business).</p>
<p>“Are you traveling with anybody?”</p>
<p>“My parents are on their way to LA right now; I’m meeting them there.”</p>
<p>“How long is your trip?”</p>
<p>“Ten days.”</p>
<p>“What will you be doing?”</p>
<p>Mentally, I sighed. There wasn’t any other way I could answer this next question.</p>
<p>“We’ll be visiting some temples.” He raised his eyebrow, and I explained that the next week was a religious holiday, and that I was traveling to LA to observe it with my family.</p>
<p>After patting me down, they swabbed not only their hands, but also my backpack, shoes, wallet, and belongings, and then walked out of the room to put it through the machine again. After more than five minutes, I started to wonder why they hadn’t said anything, so I asked the police officer who was guarding the door. He called over the TSA agent, who told me,</p>
<p>“You’re still setting off the alarm. We need to call the explosives specialist”.</p>
<p>I waited for about ten minutes before the specialist showed up. He walked in without a word, grabbed the bins with my possessions, and started to leave. Unlike the other agents I’d seen, he wasn’t wearing a uniform, so I was a bit taken aback.</p>
<p>“What’s happening?” I asked.</p>
<p>“I’m running it through the x-ray again,” he snapped. “Because I can. And I’m going to do it again, and again, until I decide I’m done”. He then asked the TSA agents whether they had patted me down. They said they had, and he just said, “Well, try again”, and left the room. Again I was told to stand with my legs apart and my hands extended horizontally while they patted me down all over before stepping outside.</p>
<p>The explosives specialist walked back into the room and asked me why my clothes were testing positive for explosives. I told him, quite truthfully, “I don’t know.” He asked me what I had done earlier in the day.</p>
<p>“Well, I had to pack my suitcase, and also clean my apartment.”</p>
<p>“And yesterday?”</p>
<p>“I moved my stuff from my old apartment to my new one”.</p>
<p>“What did you eat this morning?”</p>
<p>“Nothing,” I said. Only later did I realize that this made it sound like I was fasting, when in reality, I just hadn’t had breakfast yet.</p>
<p>“Are you taking any medications?”</p>
<p>The other TSA agents stood and listened while the explosives specialist and asked every medication I had taken “recently”, both prescription and over-the-counter, and asked me to explain any medical conditions for which any prescription medicine had been prescribed. Even though I wasn’t carrying any medication on me, he still asked for my complete “recent” medical history.</p>
<p>“What have you touched that would cause you to test positive for certain explosives?”</p>
<p>“I can’t think of anything. What does it say is triggering the alarm?” I asked.</p>
<p>“I’m not going to tell you! It’s right here on my sheet, but I don’t have to tell you what it is!” he exclaimed, pointing at his clipboard.</p>
<p>I was at a loss for words. The first thing that came to my mind was, “Well, I haven’t touched any explosives, but if I don’t even know what chemical we’re talking about, I don’t know how to figure out why the tests are picking it up.”</p>
<p>He didn’t like this answer, so he told them to run my belongings through the x-ray machine and pat me down again, then left the room.</p>
<p>I glanced at my watch. Boarding would start in fifteen minutes, and I hadn’t even had anything to eat. A TSA officer in the room noticed me craning my neck to look at my watch on the table, and he said, “Don’t worry, they’ll hold the flight.”</p>
<p>As they patted me down for the fourth time, a female TSA agent asked me for my baggage claim ticket. I handed it to her, and she told me that a woman from JetBlue corporate security needed to ask me some questions as well. I was a bit surprised, but agreed. After the pat-down, the JetBlue representative walked in and cooly introduced herself by name.</p>
<p>She explained, “We have some questions for you to determine whether or not you’re permitted to fly today. Have you flown on JetBlue before?”</p>
<p>“Yes”</p>
<p>“How often?”</p>
<p>“Maybe about ten times,” I guessed.</p>
<p>“Ten what? Per month?”</p>
<p>“No, ten times total.”</p>
<p>She paused, then asked,</p>
<p>“Will you have any trouble following the instructions of the crew and flight attendants on board the flight?”</p>
<p>“No.” I had no idea why this would even be in doubt.</p>
<p>“We have some female …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</a></em></p>]]>
            </description>
            <link>https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625215</guid>
            <pubDate>Wed, 24 Jun 2020 07:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Staring into the COM Abyss]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23623994">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://cmpct.info/~calvin/Articles/COMAbyss/ | <a href="https://web.archive.org/web/*/https://cmpct.info/~calvin/Articles/COMAbyss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		
		<p>
			If you're aware of how software is developed on Windows, chances are you're eventually going to run into COM. While Windows exposes some simple C APIs (and these APIs were much better than its contemporaries like Toolbox, X, or Intuition), pretty much anything more complex than USER32 is exposed through COM interfaces, from Internet Explorer to DirectX. COM is also used to <em>extend</em> applications too: Office, Visual Studio, even the Windows shell provide COM interfaces to applications to hook into. Microsoft loves using COM for everything in Windows, even if third-parties don't like it as much (Usually, out of portability/complexity reasons.). Using COM to its full extent can <a href="https://www.joelonsoftware.com/2009/09/23/the-duct-tape-programmer/">make your application 34% sparklier</a>, but it's a lot of work to properly use those interfaces (and there's a lot of them!).
		</p>
		<p>
			Unfortunately not many were able to take advantage of COM, let alone in more obscure scenarios such as extending the shell. The people who could do so were quite rare, as Spolsky pointed out. Naturally, I was <a href="https://xkcd.com/356/">nerd sniped</a> by a friend to write a <a href="https://docs.microsoft.com/en-us/windows/win32/shell/nse-works">shell namespace extension</a>, one of the more obscure (little documentation, few did it, few know they exist) categories of COM extension. A shell namespace extension adds a "namespace" (basically virtual folder) to the shell, which has further objects represented in it. Common use cases for them include MTP for phones, inline ZIP file viewing, etc.
		</p>
		<p>
			My extension was simple enough I thought I could implement it (and I did... with difficulty, as you'll see) myself. It would enumerate all the open Windows Explorer windows, and put links to them in a namespace. The point of this is that this was accessible from the stock system file dialogs, which is useful if you have a bunch of Explorer windows open, but want to save to one of them quickly. This was inspired by an OS/2 Workplace Shell feature (the one good feature of OS/2!). The challenge was going from a bare minimum knowledge of COM to knowing just enough to be <del>dangerous</del> able to make a shell namespace extension that works.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/os2-version.jpg" alt="The OS/2 feature" title="The OS/2 feature">
		<h2>A Brief Primer on COM</h2>
		<p>
			For something with a near-legendary reputation of complexity, it turns out COM is actually based on some very simple primitives. COM is based on interfaces (in the C++ manner) that implement vtables (a structure full of functions). These interfaces have a fixed shape, so they can be used from C. Every COM class implements the interface <code>IUnknown</code>, which implements three functions:
		</p>
		<ul>
			<li><code>AddRef</code>, which increments the reference count. Every COM object is reference counted, so you'll use this when you make a copy of a held-on reference.</li>
			<li><code>Release</code>, which decrements the reference count. The object frees itself when the count hits zero.</li>
			<li><code>QueryInterface</code>, which gives you the vtable of another interface if the object implements it (casting). The interfaces are identified by a GUID.</li>
		</ul>
		<p>
			This isn't so bad. Of course, objects can implement a <em>lot</em> of interfaces, and because interfaces have a fixed shape, to extend an interface later, you have to create another interface. Microsoft ends up numbering them, so you get into situations where you have an <a href="https://docs.microsoft.com/en-us/windows/win32/api/shobjidl_core/nn-shobjidl_core-ishellfolder2"><code>IShellFolder2</code></a>. And as Microsoft implements more features that require more interfaces, a class can get unwieldy if you're not careful. And then you have to assume the interfaces are well documented! And for extensibility, debugging isn't (as far as I'm aware) very great beyond printf macros.
		</p>
		<p>
			COM classes are registered (that's what REGSVR32 is for), where they become known by other applications. A <a href="https://docs.microsoft.com/en-us/windows/win32/midl/com-dcom-and-type-libraries">type library</a> provides metadata, and is usually generated by an IDL file.
		</p>
		<p>
			While you can use COM from C, it can get a bit unwieldy, because COM benefits from an environment of RAII and scoped destructors. ATL provides a template-based wrapper around COM for C++, and is what Microsoft recommends for COM development. Visual Studio greatly assists in terms of generating the boilerplate for categories of COM classes.
		</p>
		<h2>Do You Eat Your Burgers With or Without the Shell?</h2>
		<p>
			The beautiful part of Windows is how extensible it is. The ugly part of Windows is how no one can extend it properly. Trying to write a shell namespace extension from scratch is a Sisyphean endeavour. I don't think anyone's done it. Instead, you have to do things like your average Windows programmer in 2002 would have done - read someone much smarter than you's <a href="https://www.codeproject.com/Articles/1649/The-Complete-Idiot-s-Guide-to-Writing-Namespace-Ex">article on CodeProject</a>, the site people copied and pasted from <em>before</em> Stack Overflow. His examples are helpful, but they have a critical flaw - they implement the list view on their own, instead of delegating out to the interface which handles using the stock one and its default behaviours for you. (For example, the example will crash on XP and newer because it doesn't handle the new ListView views.) Insightful, but back to the drawing board.
		</p>
		<p>
			Round two. The <a href="https://www.codeproject.com/Articles/7973/An-almost-complete-Namespace-Extension-Sample">example by Pascal Hurni</a> is while slightly rougher, closer to what we want. His example uses the system ShellView, which gives you default behaviours and the ability to use it from a stock file dialog, which is what we want. The example enumerates through the registry (specifically, favourites for the file manager <a href="https://www.gpsoft.com.au/">Directory Opus</a>) and represents real filesystem entities, which is close to what we want - just swap out the enumerator.
		</p>
		<p>
			I took some code I wrote for experimenting with actually listing Explorer windows. First I thought I'd have to enumerate all visible windows and filter on <code>CabinetWClass</code>, then figure out what messages to send to it in order to get useful information out, but it turns out an easier way was possible through COM. You create an instance of <code>IShellWindows</code>, then call <code>get_Count</code> and <code>Item</code>, which returns an <code>IDispatch</code> representing your window. <code>IDispatch</code> is essentially <code>IUnknown</code> with reflection, intended for situations like VBA where you want to enumerate methods and properties. We can cast it to an <code>IWebBrowser</code> (a remnant of when Internet Explorer and Windows Explorer were welded together), and get the location from there. Grafting it onto Pascal's example (and ripping out what code I didn't need for clarity), I had a working MVP (with bugs, of course)
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/explorer-windows.png" alt="Windows XP, opened Explorer windows" title="Windows XP, opened Explorer windows">
		<h2>PIDLy Details</h2>
		<p>
			I <del>cargo-culted (first step of learning)</del> learned some things about the shell, and there's still a lot more I don't know about. Tip of the iceberg as follows:
		</p>
		<ul>
			<li>A PIDL is basically an ID used by Explorer to represent items, since entities may not have real FS representation. A PIDL is basically a free-form struct that has what you want tagged with its size, and what your NSE will use to identify items. They can be absolute or relative (where it only matters to you), like a path.</li>
			<li>It likes to request wrapped PIDLs in the form of <code>IDataObject</code>, one of those can-contain-anything OLE structures usually used for the clipboard.</li>
			<li>Namespaces can be registered at a <em>junction point</em>, which makes it accessible from places other than making a shortcut to its CLSID (GUID). There's also some ceremony in registering the namespace at all; there's a registry resource script that gets called whenever the DLL is registered to make it easier. Some information on creating namespaces (but from a customizer's perspective, so pointing it at existing locations) and making it known in places is available <a href="http://virtualplastic.net/html/ui_shell.html">here</a>.</li>
			<li>Some software (cough, Office) requires an NSE represent a real location before it'll show it. The example works around this by using the temporary directory as a physical manifestation. This can result in weird behaviour, but it's the price to pay to have it work.</li>
			<li>Late in XP's lifecycle and especially Vista, Microsoft extended the column scheme to have property keys. These represent metadata more faithfully, can be extended, and is actively used for search. Namespace extensions can of course, implement these. However, it's not clear on what's the bare minimum you implement to get things like tile view subtitles working. You're almost led to believe you need an <code>IPropertyStore</code> and XML file representing custom metadata columns, but I was seemingly lucky enough I could just use built-in property keys and (I believe) the real filesystem entities have their metadata fill in. I just had to map the (most; I didn't notice anything bad from not mapping everything) column IDs I was using to the system included property keys and handle the property keys that resolve to other property keys for what to display on tiles and such.</li>
		</ul>
		<p>
			The real sad part is for things like this, because the documentation is so lacking/missing, is that you may run into issues where not even Stack Overflow can help you. Experimentation or blind trust in ancient Usenet posts may be required. Or maybe you can be lucky enough to know someone who was there, remembers, and still cares. Remember, not many at the time knew how to use these effectively, and the number of people who do dwindles, to a point of extinction, another point to the <a href="https://www.devever.net/~hl/windowsdefeat">cultural defeat of Windows</a>.
		</p>
		<p>
			I also found <a href="https://www.viksoe.dk/code/regfolder.htm">someone who implemented a wrapper class library and a bunch of samples around them</a>, which probably would be handy if I didn't discover it <em>after</em> actually managing to make it. It might have been useful, but it does a lot for you, so perhaps it was for the best to understand how the shell/COM works at a lower level.
		</p>
		<h2>IActuallyDidIt2</h2>
		<p>
			I managed to actually write the extension. It's available <a href="https://github.com/NattyNarwhal/OpenWindows">on GitHub</a>, and I hope it provides a clearer example of a shell namespace extension (since you're likely not going to find many, let alone many who know it) as well as be useful to Explorer freaks. I had also contacted Pascal about the licensing ambiguities (since people just did open source in Windows circles by the edge of their seats back then) - it's MIT licensed for sure. Now you know how the ISausage is made, and it is delicious - if only people could figure out the best way to eat it.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/save-dialog.png" alt="Windows Vista, save dialog" title="Windows Vista, save dialog">
	

</div>]]>
            </description>
            <link>https://cmpct.info/~calvin/Articles/COMAbyss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623994</guid>
            <pubDate>Wed, 24 Jun 2020 04:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from looking at every AI/ML tool I could find]]>
            </title>
            <description>
<![CDATA[
Score 451 | Comments 106 (<a href="https://news.ycombinator.com/item?id=23620757">thread link</a>) | @amrrs
<br/>
June 23, 2020 | https://huyenchip.com/2020/06/22/mlops.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/06/22/mlops.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>To better understand the landscape of available tools for machine learning production, I decided to look up every AI/ML tool I could find. The resources I used include:</p>

<ul>
  <li><a href="https://github.com/alirezadir/Production-Level-Deep-Learning">Full stack deep learning</a></li>
  <li><a href="https://landscape.lfai.foundation/">LF AI Foundation landscape</a></li>
  <li><a href="http://dfkoz.com/ai-data-landscape/">AI Data Landscape</a></li>
  <li>Various lists of top AI startups by the media</li>
  <li>Responses to my <a href="https://twitter.com/chipro/status/1202815757593108480">tweet</a> and <a href="https://www.linkedin.com/posts/chiphuyen_machinelearning-machinelearningproduction-activity-6608605129010753536-bdZ7">LinkedIn post</a></li>
  <li>People (friends, strangers, VCs) share with me their lists</li>
</ul>

<p>After filtering out applications companies (e.g. companies that use ML to provide business analytics), tools that aren’t being actively developed, and tools that nobody uses, I got 202 tools. See <a href="https://docs.google.com/spreadsheets/d/1OV0cMh2lmXMU9bK8qv1Kk0oWdc_Odmu2K5sOULS9hHQ/edit?usp=sharing">the full list</a>. Please let me know if there are tools you think I should include but aren’t on the list yet!</p>

<p><strong>Disclaimer</strong></p>

<ol>
  <li>This list was made in November 2019, and the market must have changed in the last 6 months.</li>
  <li>Some tech companies just have a set of tools so large that I can’t enumerate them all. For example, Amazon Web Services offer over 165 fully featured services.</li>
  <li>There are many stealth startups that I’m not aware of, and many that died before I heard of them.</li>
</ol>

<p>This post consists of 6 parts:</p>

<p>I. Overview<br>
II. The landscape over time<br>
III. The landscape is under-developed<br>
IV. Problems facing MLOps<br>
V. Open source and open-core<br>
VI. Conclusion<br></p>

<h2>I. Overview</h2>
<p><a href="https://github.com/chiphuyen/machine-learning-systems-design">In one way to generalize the ML production flow that I agreed with</a>, it consists of 4 steps:</p>

<ol>
  <li>Project setup</li>
  <li>Data pipeline</li>
  <li>Modeling &amp; training</li>
  <li>Serving</li>
</ol>

<p>I categorize the tools based on which step of the workflow that it supports. I don’t include <strong>Project setup</strong> since it requires project management tools, not ML tools. This isn’t always straightforward since one tool might help with more than one step. Their ambiguous descriptions don’t make it any easier: “we push the limits of data science”, “transforming AI projects into real-world business outcomes”, “allows data to move freely, like the air you breathe”, and my personal favorite: “we lived and breathed data science”.</p>

<p>I put the tools that cover more than one step of the pipeline into the category that they are best known for. If they’re known for multiple categories, I put them in the <strong>All-in-one</strong> category. I also include the <strong>Infrastructure</strong> category to include companies that provide infrastructure for training and storage. Most of these are Cloud providers.</p>

<h2>II. The landscape over time</h2>
<p>I tracked the year each tool was launched. If it’s an open-source project, I looked at the first commit to see when the project began its public appearance. If it’s a company, I looked at the year it started on Crunchbase. Then I plotted the number of tools in each category over time.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_1.png">
</figure>
</center>

<p>As expected, this data shows that the space only started exploding in 2012 with the renewed interest in deep learning.</p>

<h3>Pre-AlexNet (pre-2012)</h3>
<p>Up until 2011, the space is dominated by tools for modeling and training, with some frameworks that either are still very popular (e.g. scikit-learn) or left influence on current frameworks (Theano). A few ML tools that started pre-2012 and survived until today have either had their IPOs (Cloudera, Datadog, Alteryx), been acquired (Figure Eight), or become popular open-source projects actively developed by the community (Spark, Flink, Kafka).</p>

<h3>Development phase (2012-2015)</h3>
<p>As the machine learning community took the “let’s throw data at it” approach, the ML space became the data space. This is even more clear when we look into the number of tools started each year in each category. In 2015, 57% (47 out of 82 tools) are data pipeline tools.</p>

<center>
<figure>
<img alt="Number of tools started each year" src="https://huyenchip.com/assets/pics/mlops/mlops_2.png">
</figure>
</center>

<h3>Production phase (2016-now)</h3>
<p>While it’s important to pursue pure research, most companies can’t afford it unless it leads to short-term business applications. As ML research, data, and off-the-shelf models become more accessible, more people and organizations would want to find applications for them, which increases the demand for tools to help productionize machine learning.</p>

<p>In 2016, Google announced <a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">its use of neural machine translation to improve Google Translate</a>, marking the one of the first major applications of deep learning in the real world. Since then, many tools have been developed to facilitate serving ML applications.</p>

<h2>III. The landscape is under-developed</h2>
<p>While there are many AI startups, most of them are application startups (providing applications such as business analytics or customer support) instead of tooling startups (creating tools to help other companies build their own applications). Or in VC terms, most startups are vertical AI. Among <a href="https://www.forbes.com/sites/jilliandonfro/2019/09/17/ai-50-americas-most-promising-artificial-intelligence-companies/#2ecf64d9565c">Forbes 50 AI startups in 2019</a>, only 7 companies are tooling companies.</p>

<p>Applications are easier to sell, since you can go to a company and say: “We can automate half of your customer support effort.” Tools take longer to sell but can have a larger impact since you’re not targeting a single application but a part of the ecosystem. Many companies can coexist providing the same application, but for a part of the process, usually a selected few tools can coexist.</p>

<p>After extensive search, I could only find ~200 AI tools, which is puny compared to the number of traditional software engineering tools. If you want testing for traditional Python application development, you can find at least 20 tools within 2 minutes of googling. If you want testing for machine learning models, there’s none.</p>

<h2>IV. Problems facing MLOps</h2>
<p>Many traditional software engineering tools can be used to develop and serve machine learning applications. However, many challenges are unique to ML applications and require their own tools.</p>

<p>In traditional SWE, coding is the hard part, whereas in ML, coding is a small part of the battle. Developing a new model that can provide significant performance improvements in real world tasks is very hard and very costly. Most companies won’t focus on developing ML models but will use an off-the-shelf model, e.g. “if you want it put a BERT on it.”</p>

<p>For ML, applications developed with the most/best data win. Instead of focusing on improving deep learning algorithms, most companies will focus on improving their data. Because data can change quickly, ML applications need faster development and deployment cycles. In many cases, you might have to deploy a new model every night.</p>

<p>The size of ML algorithms is also a problem. The pretrained large BERT model has 340M parameters and is 1.35GB. Even if it can fit on a consumer device (e.g. your phone), the time it takes for BERT to run inference on a new sample makes it useless for many real world applications. For example, an autocompletion model is useless if the time it takes to suggest the next character is longer than the time it takes for you to type.</p>

<p>Git does versioning by comparing differences line by line and therefore works well for most traditional software engineering programs. However, it’s not suitable for versioning datasets or model checkpoints. Pandas works well for most traditional dataframe manipulation, but doesn’t work on GPUs.</p>

<p>Row-based data formats like CSV work well for applications using less data. However, if your samples have many features and you only want to use a subset of them, using row-based data formats still requires you to load all features. Columnar file formats like PARQUET and OCR are optimized for that use case.</p>

<p>Some of the problems facing ML applications development:</p>

<ul>
  <li><strong>Monitoring</strong>: How to know that your data distribution has shifted and you need to retrain your model? Example: <a href="https://www.dessa.com/">Dessa</a>, supported by Alex Krizhevsky from AlexNet and acquired by Square in Feb 2020.</li>
  <li><strong>Data labeling</strong>: How to quickly label the new data or re-label the existing data for the new model? Example: <a href="https://www.snorkel.org/">Snorkel</a>.</li>
  <li><strong>CI/CD test</strong>: How to run tests to make sure your model still works as expected after each change, since you can’t spend days waiting for it to train and converge? Example: <a href="https://argoproj.github.io/">Argo</a>.</li>
  <li><strong>Deployment</strong>: How to package and deploy a new model or replace an existing model? Example: <a href="https://octoml.ai/">OctoML</a>.</li>
  <li><strong>Model compression</strong>: How to compress an ML model to fit in consumer devices? Example: Xnor.ai, a startup spun out of Allen Institute to focus on model compression, raised $14.6M at the valuation of $62M in May 2018. In January 2020, Apple bought it for ~$200M and shut down its website.</li>
  <li><strong>Inference Optimization</strong>: How to speed up inference time for your models? Can we fuse operations together? Can we use lower precision? Making a model smaller might make its inference faster. Example: <a href="https://developer.nvidia.com/tensorrt">TensorRT</a>.</li>
  <li><strong>Edge device</strong>: Hardware designed to run ML algorithms fast and cheap. Example: <a href="https://coral.ai/products/som/">Coral SOM</a>.</li>
  <li><strong>Privacy</strong>: How to use user data to train your models while preserving their privacy? How to make your process GDPR-compliant? Example: <a href="https://github.com/OpenMined/PySyft">PySyft</a>.</li>
</ul>

<p>I plotted the number of tools by the main problems they address.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_3.png">
</figure>
</center>

<p>A large portion focuses on the data pipeline: data management, labeling, database/query, data processing, data generation. Data pipeline tools are also likely to aim to be all-in-one platforms. Because data handling is the most resource-intensive phase of a project, once you’ve had people put their data on your platform, it’s tempting to provide them with a couple of pre-built/pre-trained models.</p>

<p>Tools for modeling &amp; training are mostly frameworks. The deep learning frameworks competition cooled down to be mostly between PyTorch and TensorFlow, and higher-level frameworks that wrap around these two for specific families of tasks such as NLP, NLU, and multimodal problems. There are frameworks for distributed training. There’s also this new framework coming out of Google that every Googler who hates TensorFlow has been raving about: <a href="https://github.com/google/jax">JAX</a>.</p>

<p>There are standalone tools for experiment tracking, and popular frameworks also have their own experiment tracking features built-in. Hyperparameter tuning is important and it’s not surprising to find several that focus on it, but none seems to catch on because the bottleneck for hyperparameter tuning is not the setup, but the computing power needed to run it.</p>

<p>The most exciting problems yet to be solved are in the deployment and serving space. One reason for the lack of serving solutions is the lack of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/06/22/mlops.html">https://huyenchip.com/2020/06/22/mlops.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/06/22/mlops.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23620757</guid>
            <pubDate>Tue, 23 Jun 2020 21:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lossless compression of English messages using GPT-2]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23618465">thread link</a>) | @kleiba
<br/>
June 23, 2020 | http://textsynth.org/sms.html | <a href="https://web.archive.org/web/*/http://textsynth.org/sms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      
      
      

      <div>
        <p>
          This lossless compressor achieves a much higher compression
          rate on English texts than general purpose compressors. Its
          typical compression ratio is 15% (number of output bits
          divided by the number of input bits).
        </p>
        <p>
        The compression is achieved by using the probability of the
        next word computed by
        the <a href="https://openai.com/blog/better-language-models/">GPT-2
        language model</a> released by OpenAI. It is a neural network
        of 1.5 billion parameters based on the Transformer
        architecture. An arithmetic coder generates the bit
        stream. For this demo, each compressed character holds 15 data
        bits by using the CJK and the Hangul Syllables unicode ranges.
        </p>
        <p>
        It is implemented using the
        <a href="https://bellard.org/nncp">LibNC library</a> and runs
        on a standard PC. The Linux standalone command line
        version (<code>gpt2tc</code>) can be downloaded
        <a href="https://bellard.org/nncp/gpt2tc.html">here</a>. Compression
        ratios on several text compression benchmarks is listed in
        the <a href="https://bellard.org/nncp/readme-gpt2tc.txt"><code>gpt2tc</code>
        documentation</a>.
        </p>
        <p>
        The same model can be used to <a href="http://textsynth.org/index.html">complete text messages</a>.
        </p>
        <p>[2020-06-23: Temporary switch to a smaller model (345M) to
        reduce the server load]</p>
        
      </div>
      
      
    </div></div>]]>
            </description>
            <link>http://textsynth.org/sms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23618465</guid>
            <pubDate>Tue, 23 Jun 2020 18:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can't tell people anything (2004)]]>
            </title>
            <description>
<![CDATA[
Score 404 | Comments 187 (<a href="https://news.ycombinator.com/item?id=23617188">thread link</a>) | @memexy
<br/>
June 23, 2020 | http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/ | <a href="https://web.archive.org/web/*/http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-5">
                <h3>You can't tell people anything</h3> 
                <p>This is sort of Morningstar’s version of Murphy’s Law.</p>
<p>When we were assembling our catalog of the things we had learned over the past decade and a half in this business, we almost didn’t include this one because it seems so banal.  But I keep finding that it’s often the first thing I say when people ask me what about my experiences (and another thing I’ve learned is to pay attention to things I find myself saying; that way I’ll know what I really think).  And, upon reflection, I think it’s actually one of the more important lessons that we’ve learned.</p>
<p>We all spend a lot of our time talking to bosses or investors or marketing people or press or friends or other developers. I’m totally convinced that a new idea or a new plan or a new technique is never really understood when you just explain it. People will often think they understand, and they’ll say they understand, but then their actions show that it just ain’t so.</p>
<p>Years ago, before Lucasfilm, I worked for <a href="http://xanadu.com/">Project Xanadu</a> (the original hypertext project, way before this newfangled World Wide Web thing). One of the things I did was travel around the country trying to evangelize the idea of hypertext. People loved it, but nobody <i>got</i> it. Nobody. We provided lots of explanation.  We had pictures.  We had scenarios, little stories that told what it would be like. People would ask astonishing questions, like “who’s going to pay to make all those links?” or “why would anyone want to put documents online?”  Alas, many things really must be experienced to be understood.  We didn’t have much of an experience to deliver to them though — after all, the whole point of all this evangelizing was to get people to give us money to pay for developing the software in the first place!  But someone who’s spent even 10 minutes using the Web would never think to ask some of the questions we got asked.</p>
<p>In 1988 we began consulting to Fujitsu, when they licensed Habitat from Lucasfilm to create Fujitsu Habitat in Japan. We started out with a week long seminar at Skywalker Ranch for their team, explaining everything we knew about Habitat. We gave them copious documentation and complete source code listings. Following that, for the next couple of years they had unlimited access to us via fax, phone and email to answer any questions they might have. We made several visits to Japan to advise them. On our visits they often asked questions that seemed a little, well, odd. We chalked it up to the language barrier, but still, there were clearly things they weren’t getting. For example, their server ran on five (not four, not six, five) Fujitsu A60 minicomputers, and became hopelessly bogged down after about 80 concurrent users. We were never able to get a clear picture of why. We asked lots of questions and they’d try to answer them, but none of the explanations made any sense that we could puzzle out.  They were trying to tell us, you see, but you can’t tell people anything.</p>
<p>The mystery was solved a few years later when we began the WorldsAway project, still consulting to Fujitsu but in a role that was much more hands-on. Our initial plan had been to work from the Fujitsu Habitat code, back porting the client to Macs and Windows, and cleaning up their server (80 users, yeesh). When we took apart their code, we finally figured out what had been puzzling us all that time: <i>they had lost the architecture.</i> In spite of all the information we gave them, we had completely failed to communicate how things worked.  Their guys hadn’t understood the whole client-server concept, which for that day and place was somewhat exotic, so they just implemented what they knew, which was a terminal-mainframe architecture. Their “client” was basically a fancy, highly specialized graphics terminal; all the real work was done on the server.  For example, when you issued a command to an object, instead of sending a command message to the object on the server, the client would send the X-Y coordinates of your mouse click. The server would then render its own copy of the scene into an internal buffer to figure out what object you had clicked on. Not only was this extremely inefficient, but the race conditions inherent a multi-user environment meant that it also sometimes just got the wrong answer. It was amazing…</p>
<p>What’s going on is that without some kind of direct experience to use as a touchstone, people don’t have the context that gives them a place in their minds to put the things you are telling them. The things you say often don’t stick, and the few things that do stick are often distorted.  Also, most people aren’t very good at visualizing hypotheticals, at imagining what something they haven’t experienced might be like, or even what something they <i>have</i> experienced might be like if it were somewhat different. One of the things I really miss from my days at Lucasfilm is having artists on staff, being able to run down the hall and say, “hey Gary, draw me this picture.”</p>
<p>Eventually people can be educated, but what you have to do is find a way give them the experience, to put them in the situation. Sometimes this can only happen by making real the thing you are describing, but sometimes by dint of clever artifice you can simulate it.</p>
<p>With luck, eventually there will be an “Aha!”.  If you’re really good, the “Aha!” will followed by “Oh, so <i>that’s</i> what you meant”.  But don’t be too surprised or upset if the “Aha!” is instead followed by “Why didn’t you <i>tell</i> me that?”.  At Communities.com we developed a system called Passport (I’ll save the astonishing trademark story for a later posting) that let us do some pretty amazing things with web browsers.  For example, with just a few magic HTML tags we could stick avatars on a web page — pretty much any web page.  For months Randy kept getting up at management meetings and saying, “We’ll be able to put avatars on web pages.  Start thinking about what you might do with that.”  Mostly, nobody reacted much.  After a couple of months of this we had things working, and so he got up and presented a demo of avatars walking around on top of our company home page. People were amazed, joyful, and enthusiastic.  But they also pretty much all said the same thing: “why didn’t you <i>tell</i> us that we could put avatars on web pages?”  You can’t tell people anything.</p>
<p>When people ask me about my life’s ambitions, I often joke that my goal is to become independently wealthy so that I can afford to get some work done. Mainly that’s about being able to do things without having to explain them first, so that the finished product can be the explanation.  I think this will be a major labor saving improvement.</p>
<p>One final point: I expect none of you to really get what I’m talking about here, because this principle also applies to itself. But I fully expect I’ll get the occasional email saying “Oh! so <i>that’s</i> what you meant.” or “Why didn’t you <i>tell</i> me that?”  I did, but you can’t tell people anything.</p>

            </div></div>]]>
            </description>
            <link>http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617188</guid>
            <pubDate>Tue, 23 Jun 2020 17:26:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Query 1.6B rows in milliseconds, live]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 92 (<a href="https://news.ycombinator.com/item?id=23616878">thread link</a>) | @bluestreak
<br/>
June 23, 2020 | http://try.questdb.io:9000/index.html | <a href="https://web.archive.org/web/*/http://try.questdb.io:9000/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://try.questdb.io:9000/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23616878</guid>
            <pubDate>Tue, 23 Jun 2020 17:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Crystal Performance]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 160 (<a href="https://news.ycombinator.com/item?id=23615303">thread link</a>) | @open-source-ux
<br/>
June 23, 2020 | https://ptimofeev.com/go-vs-crystal-perfomance/ | <a href="https://web.archive.org/web/*/https://ptimofeev.com/go-vs-crystal-perfomance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://ptimofeev.com/go-vs-crystal-perfomance/"><img src="https://ptimofeev.com/images/go-vs-crystal.png" alt="Go vs Crystal"></a></p>

<p>Itâ€™s a follow up post to the previous <a href="https://ptimofeev.com/ruby-vs-crystal-performance/">Ruby vs Crystal Performance</a>.</p>

<p>I guess this time it will be a fair performance comparison as both languages are compiled and statically typed.</p>

<p>We will perform a couple of tests:</p>
<ul>
  <li>Finding a number in the Fibonacci sequence as in the previous post</li>
  <li>Running an HTTP server locally and performing benchmarks with wrk</li>
</ul>

<p>Language versions installed my machine are:</p>
<ul>
  <li>go version go1.14.3 darwin/amd64</li>
  <li>Crystal 0.34.0 (2020-04-07)</li>
</ul>

<p>Iâ€™m curious to find out how Go and Crystal perform in comparison to each other.</p>

<!-- more -->

<h3 id="compilation">Compilation</h3>

<p>For the tests we will be running previously compiled programs. We will use the release flag to enable optimizations in Crystal:</p>
<div><div><pre><code>crystal build <span>--release</span> program.cr
</code></pre></div></div>

<p>Go binaries donâ€™t have a release version and we wonâ€™t be using any flags. So, itâ€™s just:</p>


<h2 id="fibonacci">Fibonacci</h2>

<p>Alright, first we will write code to generate a Fibonacci sequence for a given number. Letâ€™s find the 47th number which is 2,971,215,073.</p>

<p>Go version:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>"fmt"</span>

<span>func</span> <span>fibonacci</span><span>(</span><span>n</span> <span>uint32</span><span>)</span> <span>uint32</span> <span>{</span>
  <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span> <span>{</span>
    <span>return</span> <span>n</span>
  <span>}</span>
  <span>return</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>fibonacci</span><span>(</span><span>47</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>

<div><div><pre><code><span>def</span> <span>fibonacci</span><span>(</span><span>n</span> <span>:</span> <span>UInt32</span><span>)</span>
  <span>return</span> <span>n</span> <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span>
  <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
  <span>end</span>

<span>puts</span> <span>fibonacci</span><span>(</span><span>47</span><span>)</span>
</code></pre></div></div>

<p>Results on my machine (MacBook Pro 2.2 GHz Intel Core i7):</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Run time</strong></td>
      <td><strong>Memory usage</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>2.1M</td>
      <td>21.28s</td>
      <td>2.01M</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>418k</td>
      <td>19.69s</td>
      <td>1.72M</td>
    </tr>
  </tbody>
</table>

<p>Crystal is slightly winning here.</p>

<p>A few observations here:</p>

<p>Crystalâ€™s binary size is 5 times smaller than Goâ€™s. Though, they can be slightly reduced in size when we omit the debug information:</p>
<div><div><pre><code>go build <span>-ldflags</span><span>=</span><span>"-w"</span> fibonacci_golang.go
</code></pre></div></div>
<p>This way the binary size goes down from 2.1M to 1.7M.</p>

<p>Also, not in this particular example, but generally Goâ€™s compilation time is much much faster than Crystalâ€™s.</p>

<h2 id="http-server">HTTP Server</h2>

<p>Now, letâ€™s create a simple HTTP server using standard libraries. Both Goâ€™s <em>net/http</em> and Crystalâ€™s <em>http/server</em> employ concurrency: Go uses goroutines and Crystal uses fibers.</p>

<p>Go version:</p>
<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>HelloServer</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>

<span>func</span> <span>HelloServer</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"Hello from %s!"</span><span>,</span> <span>r</span><span>.</span><span>URL</span><span>.</span><span>Path</span><span>[</span><span>1</span><span>:</span><span>])</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>
<div><div><pre><code><span>require</span> <span>"http/server"</span>

<span>server</span> <span>=</span> <span>HTTP</span><span>::</span><span>Server</span><span>.</span><span>new</span> <span>do</span> <span>|</span><span>context</span><span>|</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>content_type</span> <span>=</span> <span>"text/plain"</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>print</span> <span>"Hello from </span><span>#{</span><span>context</span><span>.</span><span>request</span><span>.</span><span>path</span><span>}</span><span>!"</span>
<span>end</span>

<span>puts</span> <span>"Listening on http://127.0.0.1:8080"</span>
<span>server</span><span>.</span><span>listen</span><span>(</span><span>8080</span><span>)</span>
</code></pre></div></div>

<p>For benchmarking we will be using <a href="https://github.com/wg/wrk" target="_blank" rel="noopener noreferrer">wrk</a>. If youâ€™re not familiar with this tool itâ€™s like a pretty well known ApacheBench (ab) but a modern version.</p>

<p>Here is how we can run a benchmark for 60 seconds, using 8 threads, and keeping 400 HTTP connections open:</p>

<div><div><pre><code>wrk <span>-t8</span> <span>-c400</span> <span>-d60s</span> http://localhost:8080/hello
</code></pre></div></div>

<p>Results for the Go server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.56ms    2.26ms  95.31ms   92.00%
    Req/Sec     8.77k     2.24k   15.75k    64.66%
  4190457 requests in 1.00m, 535.51MB read
  Socket errors: connect 157, read 100, write 0, timeout 0
Requests/sec:  69757.81
Transfer/sec:      8.91MB
</code></pre></div></div>

<p>Results for the Crystal server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.89ms    0.97ms  19.01ms   80.34%
    Req/Sec    10.54k     3.41k   18.14k    60.85%
  5035284 requests in 1.00m, 513.82MB read
  Socket errors: connect 157, read 85, write 0, timeout 0
Requests/sec:  83917.26
Transfer/sec:      8.56MB
</code></pre></div></div>

<p>Results:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Memory usage</strong></td>
      <td><strong>CPU usage</strong></td>
      <td><strong>Throughput</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>7.4M</td>
      <td>20.2M</td>
      <td>300%</td>
      <td>69,757</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>966kb</td>
      <td>19.1M</td>
      <td>99%</td>
      <td>83,917</td>
    </tr>
  </tbody>
</table>

<p>Crystal again shows better results.</p>

<p>CPU utilization over 100% in the table might seem confusing. But it simply means the system uses multiple cores. One core at max is 100%.</p>

<p>My machine has 8 cores as it can be seen with the following command on macOs:</p>


<h2 id="conclusion">Conclusion</h2>

<p>Frankly speaking, we have only performed a couple of small tests to make any conclusions but Iâ€™m still excited for Crystal as a young language but showing great results.</p>


  </div></div>]]>
            </description>
            <link>https://ptimofeev.com/go-vs-crystal-perfomance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615303</guid>
            <pubDate>Tue, 23 Jun 2020 15:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Touchpad Like a MacBook update: progress on multitouch]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 126 (<a href="https://news.ycombinator.com/item?id=23615218">thread link</a>) | @wbharding
<br/>
June 23, 2020 | https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615218</guid>
            <pubDate>Tue, 23 Jun 2020 15:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome killed my extension and won’t tell me why]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23614601">thread link</a>) | @mikob
<br/>
June 23, 2020 | https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/ | <a href="https://web.archive.org/web/*/https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <hr><!--kg-card-begin: markdown--><p><em>(Part I is <a href="https://blog.lipsurf.com/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">here</a> or <a href="https://medium.com/@miko_89964/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why-83a3f8d65cbc">here</a>)</em></p>
<!--kg-card-end: markdown--><p>We won the battle but not the war.</p><p>I got lucky. If I didn’t win the <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/" rel="noopener">internet attention lottery that day</a>, we may have shutdown and left our users stranded with an unmaintained tool that their daily lives depend on. The fate of web accessibility for thousands of people with disabilities, and our business lie in the hands of a single faceless gatekeeper who made a mistake.</p><p>The story may sound familiar. In short: our Chrome Extension was taken down because it supposedly didn't meet policy. After lots of development work, numerous failed resubmissions, and a week delisted from the store without communication – we complained loudly on <a href="https://www.reddit.com/r/programming" rel="noopener">Reddit</a>. Noticing our post, someone with internal access to the Chrome Webstore reached out to us on <a href="https://twitter.com/DotProto/status/1273845280668966912" rel="noopener">Twitter</a>, they said that it was a mistake and apologized. We resubmitted and were restored later that day.</p><p>Complaining on the internet should not be a support channel. Developers should not have to rely on the internet attention lottery. The Chrome Webstore has been around 10 years and needs to get its act together. We, at <a href="https://www.lipsurf.com/" rel="noopener">LipSurf</a>, want to use our temporary position of attention privilege to improve the system and help other extension developers.</p><p>Firstly, we are very thankful to the unequivocal hero, <a href="https://twitter.com/DotProto">@DotProto</a>. He not only saved <a href="https://www.lipsurf.com/" rel="noopener">us</a>, but has saved <a href="https://blog.pushbullet.com/2020/05/15/our-extension-is-safe/" rel="noopener">PushBullet recently</a>, among others. Furthermore, he does it in <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">his free time</a>.</p><p>Although <a href="https://twitter.com/DotProto">@DotProto</a> says CWS is working to <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">improve internally</a>, it would be foolish for us to stand on the sidelines, just waiting ,  hoping. The issues are clearly systemic, as cries for help <a href="https://groups.google.com/a/chromium.org/forum/#!forum/chromium-extensions" rel="noopener">litter the CWS forums</a>, and our Reddit post was <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9haxs?utm_source=share&amp;utm_medium=web2x" rel="noopener">full</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvaosgv?utm_source=share&amp;utm_medium=web2x" rel="noopener">of</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9to0o?utm_source=share&amp;utm_medium=web2x" rel="noopener">“me too”</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9pkca?utm_source=share&amp;utm_medium=web2x" rel="noopener">stories</a>. </p><p>This can and will happen again.</p><p>Therefore, we are starting a group today for Chrome Extension developers to work together in check with CWS. It's not a technical support channel, nor a platform to get attention when CWS is unresponsive. It's a place for Chrome Extension developers to rally together and discuss improving the foundation we stand on (it also won't be hosted nor managed by Google).</p><p>United, we can have a stronger, common voice to:</p><ol><li><strong>Pressure Google Chrome to allow for 3rd party extension stores.</strong></li></ol><p>This would break down the walled garden of extensions, give extension developers a leveler playing field, and lower the risk of getting wiped out on CWS's whim.</p><p>2. <strong>Pressure CWS to be more fair and communicative with extension publishers.</strong></p><p>Canned emails about rejections with only general policy information are “lose-lose” for publishers and CWS alike. Both parties waste time because of all the guesswork involved currently — especially when CWS makes a mistake.</p><hr><p>We need to start building our defenses and forging relationships today. If we don’t unite and speak together, we will forever be powerless and at the mercy of our gatekeeper. We also open our forum to CWS staff, and extension advocates like <a href="https://twitter.com/DotProto">@DotProto</a>. We don’t want to work against each other, after all – a good platform should &nbsp;work &nbsp;<em>with us</em> &nbsp;not &nbsp;<em>against us</em>.</p><p><strong>If you are a extension developer, or know any extension developers, please share or start by joining us by filling out the form below.</strong> We plan to open the forum once we know that there's enough interest.</p><h3 id="faqs">FAQs</h3><p><em>What power will we have together?</em></p><p>Building awareness to start. We will rally support from other developers and end users alike. One extreme example could be a coordinated a Chrome Extension blackout date. A less extreme example would be proposing ideas as a group, instead of as individuals to Google Chrome that would improve the experience for extensions (eg. improved permissions).</p><p><em>What about adware, or privacy intruding extensions?</em></p><p>If 3rd party extension stores were possible, they would be free to setup their own barriers – monetary or otherwise. It's very possible for a 3rd party extension store to do a <a href="https://www.reddit.com/r/IAmA/comments/dwfbmf/im_brendan_eich_inventor_of_javascript_and/f7mhhay?utm_source=share&amp;utm_medium=web2x">better job</a> <a href="https://forklog.media/google-chrome-extension-with-32m-downloads-has-malicious-add-ons-that-steal-data-report/">than Google</a> at blocking malicious extensions. </p><!--kg-card-begin: html--><!--kg-card-end: html-->
    </div></div>]]>
            </description>
            <link>https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614601</guid>
            <pubDate>Tue, 23 Jun 2020 14:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is WebP really better than JPEG?]]>
            </title>
            <description>
<![CDATA[
Score 422 | Comments 304 (<a href="https://news.ycombinator.com/item?id=23614305">thread link</a>) | @kasabali
<br/>
June 23, 2020 | https://siipo.la/blog/is-webp-really-better-than-jpeg | <a href="https://web.archive.org/web/*/https://siipo.la/blog/is-webp-really-better-than-jpeg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<section id="content" role="main">
					<div>
												<div>
									<article id="post-214">
			<section>
				
				
				<div>
					                                                                                    <p>If you have used tools like Google’s PageSpeed Insights, you probably have run into a suggestion to use “next-gen image formats”, namely Google’s <a href="https://developers.google.com/speed/webp">WebP image format</a>. Google <a href="https://developers.google.com/speed/webp/docs/webp_study">claims that</a> their WebP format is 25 – 34% smaller than JPEG at equivalent quality.</p>
<p>When testing out WebP using a <a href="https://github.com/siiptuo/pio">perceptual image optimizer</a>, I ran into a peculiar issue: the WebP files were of very similar size compared to compressed JPEGs, in many cases larger. I’m not only one who noticed this, but Mozilla also noted in <a href="https://research.mozilla.org/2013/10/17/studying-lossy-image-compression-efficiency/">their 2013 study</a> that WebP doesn’t generally have much better compression efficiency when compared to JPEG. (Note that Mozilla somewhat walked back from this and implemented <a href="https://hacks.mozilla.org/2019/01/firefox-65-webp-flexbox-inspector-new-tooling/">WebP support</a> for Firefox in 2019)</p>
<p>I think Google’s result of 25-34% smaller files is mostly caused by the fact that they compared their WebP encoder to the JPEG reference implementation, Independent JPEG Group’s <a href="https://linux.die.net/man/1/cjpeg">cjpeg</a>, not Mozilla’s improved <a href="https://calendar.perfplanet.com/2014/mozjpeg-3-0/">MozJPEG</a> encoder. I decided to run some tests to see how cjpeg, MozJPEG and WebP compare. I also tested the new AVIF format, based on the open AV1 video codec. AVIF support is already in Firefox behind a flag and should be coming soon to Chrome if <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=960620">this ticket</a> is to be believed.</p>
<h2>Images and Tools</h2>
<p>For the testing I used the <a href="http://r0k.us/graphics/kodak/">Kodak image dataset</a> in 3 different sizes: 500 px, 1000px and 1500px.</p>
<ul>
<li>For JPEG conversion I used cjpeg with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling.</li>
<li>For MozJPEG conversion I used MozJPEG with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling</li>
<li>For WebP  I used cwebp with <code>-m 6</code> flag for maximum compression and <code>-af</code> for auto filter which presumably trades encoding time for increased quality. WebP only supports 4:2:0 subsampling so this doesn’t need to be specified separately.</li>
<li>For AVIF I used <a href="https://github.com/joedrago/colorist">colorist</a> with flags <code>--tonemap off</code>, <code>--yuv 420</code> and <code>--speed 0</code> which is the slowest but highest quality encoding</li>
</ul>
<p>In addition to these, ImageMagick was used to scale down the images from the originals and converting between PNG, WebP and TGA (cwebp only supports TGA input). All conversions were done in sRGB color space.</p>
<p>For comparing the quality I used kornelski’s <a href="https://github.com/kornelski/dssim">dssim utility</a> which calculates <a href="https://en.wikipedia.org/wiki/Structural_similarity">structural similarity</a> index between images. My target SSIM is 0.0044 which <a href="https://gist.github.com/joppuyo/12fe6fb5e5fa532b21e2c8098634c7c9">roughly corresponds</a> to JPEG quality of 85.</p>
<h2>Results for 500px images</h2>

<p><a href="https://webp-test-500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541" srcset="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1400w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1080w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is 18% smaller compared and AVIF is 31% smaller at the equivalent SSIM index.</p>
<h2>Results for 1000px images</h2>

<p><a href="https://webp-test-1000.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6" srcset="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1400w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1080w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is also 11% smaller compared and avif is 28% smaller at the equivalent SSIM index.</p>
<h2>Results for 1500px images</h2>

<p><a href="https://webp-test-1500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0" srcset="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1400w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1080w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 9% smaller, WebP is the same size as cjpeg and AVIF is 28% smaller at the equivalent SSIM index.</p>
<h2>Average for all image sizes</h2>
<p>Just for fun, I graphed the averages of all image sizes. I know this might not be a fair comparison but still, here you go:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/all-sizes-target-quality-85-average-file-size.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697" srcset="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1400x950.png?ver=4c2aa46286fabb012d9e6339114fb697 1400w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1080x733.png?ver=4c2aa46286fabb012d9e6339114fb697 1080w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>As you can see, when compared to cjpeg, MozJPEG is about 9% smaller, WebP is 6% smaller and AVIF is 30% smaller.</p>
<p>If you are interested, you can view the raw data for all the images as a spreadsheet <a href="https://docs.google.com/spreadsheets/d/1j-5ZqbSnIt0qtxh1T83sVjfR7YZIhfdgtWG28F3I8U8/edit?usp=sharing">here</a>. Source code for the comparison app and raw images are available on GitHub: <a href="https://github.com/joppuyo/compare-app-webp-500">500px</a>, <a href="https://github.com/joppuyo/compare-app-webp-1000">1000px</a> and <a href="https://github.com/joppuyo/compare-app-webp-1500">1500px</a>. Check the originals directory for the raw images.</p>
<h2>Conclusions</h2>
<h3>Is WebP better than JPEG?</h3>
<p>So, is WebP better than JPEG? It depends if you are using the reference libjpeg library or the improved MozJPEG encoder.</p>
<p>WebP seems to have about 10% better compression compared to libjpeg in most cases, except with 1500px images where the compression is about equal.</p>
<p>However, when compared to MozJPEG, WebP only performs better with small 500px images. With other image sizes the compression is equal or worse.</p>
<p>I think MozJPEG is the clear winner here with consistently about 10% better compression than libjpeg.</p>
<p>Since most of the time WebP is used alongside JPEG fallback, by using WebP you will essentially double your storage costs with little benefit. So, in the end, I would recommend using WebP in only the following cases:</p>
<ul>
<li>You have a lot of small images in the 500 px range.</li>
<li>You can’t use MozJPEG.</li>
<li>You pick an arbitrary fixed quality instead of using a metric like SSIM.</li>
</ul>
<p>In any case, when converting images to WebP, check that they are actually smaller than the JPEG equivalent. There’s no need to serve larger images to your users than needed.</p>
<h3>How do image formats derived from video codecs differ from JPEG?</h3>
<p>One notable difference between JPEG encoders compared to WebP (based on VP8) and AVIF (based on AV1) is that it’s pretty easy to see how the latter were derived from video codecs. JPEG compression uses the same quantization factor for each 16x16 “macroblock” so the compression is consistent throughout the image.</p>
<p>WebP and AVIF on the other hand use different compression factors for different parts of the image so while the detailed parts of the image retain their quality, surfaces like skin or the sky which have low detail are “smoothed out”. This is especially noticeable with the red window shutters in this image.</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/jpeg-vs-webp-vs-avif.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f" srcset="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1440x399.png?ver=63b1240368ae03d4ad9fa923e352b44f 1440w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1400x388.png?ver=63b1240368ae03d4ad9fa923e352b44f 1400w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1080x300.png?ver=63b1240368ae03d4ad9fa923e352b44f 1080w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>While the bricks in the image look sharp, the doors look almost like they have a “Smart blur” Photoshop filter applied to them.</p>
<p>I think this kind of adaptive compression is a valuable thing to have. Think about a photo with a forest and the sky. A traditional image encoder would have to decide a single compression ratio for the whole image. While it’s good to use a lot of bits for the forest trees with high-frequency detail, they are wasted for the sky with low-frequency detail.</p>
<p>A smarter encoder like WebP or AVIF will be able to process these areas separately to use the available bits efficiently.</p>
<h3>Is AVIF the future of image formats?</h3>
<p>I think AVIF is a really exciting development and compared to WebP it seems like a true next-generation codec with about 30% better compression ratio compared to libjpeg. Only concern I have is the excessive blurring of low detail areas. It remains to be seen if this can be improved when more advanced tooling becomes available.</p>
<p>Right now the tooling is a bit spotty. <a href="https://github.com/joedrago/colorist">Colorist</a> was the only program I found which can reliably encode AVIF files. Encoding AVIF files is also really slow! A big image can take several minutes to encode. I’m using the AOM encoder but <a href="https://github.com/xiph/rav1e">rav1e</a> might be faster. Browser support also still in progress. Firefox has AVIF support but it’s behind a flag and it doesn’t seem to <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1634741">read ICC profiles correctly</a>. Still, it’s more browser support than Apple’s "next-gen" HEIF which <a href="https://caniuse.com/heif">isn’t even supported in Safari</a>.</p>
<p>I think in the next year or so we might see a radically different landscape. With Chrome on board, we could see supported browsers jump to something like 70% of all browsers which means AVIF would be a pragmatic thing to support in web projects.</p>
<h2>Caveats</h2>
<p>In this test, I only used photographic images. WebP may be better when compressing graphics, for example, since it supports lossy compression for the alpha channel which PNG and JPEG do not.</p>
<p>I also tested the images in “Web quality” target of 85 so WebP may perform differently in very high or very low-quality settings.</p>
<p>Also, Google’s study used <a href="http://mehdi.rabah.free.fr/SSIM/">a different program</a> to compute the SSIM values. In my tests, I used the <a href="https://github.com/kornelski/dssim">dssim</a> utility which computes multi-scale SSIM in …</p></div></section></article></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://siipo.la/blog/is-webp-really-better-than-jpeg">https://siipo.la/blog/is-webp-really-better-than-jpeg</a></em></p>]]>
            </description>
            <link>https://siipo.la/blog/is-webp-really-better-than-jpeg</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614305</guid>
            <pubDate>Tue, 23 Jun 2020 14:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Just Hit $100k/year On GitHub Sponsors]]>
            </title>
            <description>
<![CDATA[
Score 1457 | Comments 488 (<a href="https://news.ycombinator.com/item?id=23613719">thread link</a>) | @calebporzio
<br/>
June 23, 2020 | https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it | <a href="https://web.archive.org/web/*/https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                
    <span>Jun 2020</span>

    

    <p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3735079629.png"></a></p>
<p>I have a story to tell.</p>
<p>My last year as a full-time developer (at <a href="https://tighten.com/">Tighten</a>) was 2018. (Read <a href="https://calebporzio.com/n-leaving-my-day-job">â€œOn Leaving My Day Jobâ€�</a> for that story)</p>
<p>My income for that year was ~$90k:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.53.07%20AM.png" alt="90k in income on a W2"></p>
<p>Developer salaries vary like crazy, but $90k was pretty solid for me. Combined with my wifeâ€™s income and some <a href="https://www.mrmoneymustache.com/blog/">Mustachianism</a> it was plenty to save up a chunk of cash for a rainy day. (Or for a few months of working un-paid on open source lol - SPOILER ALERT ðŸ˜¬)</p>
<p>After needing a change of scenery, I left Tighten on January 11th, 2019 to go on a â€œsabbaticalâ€� (fancy word for â€œtake a break and do whatever the hell I wantâ€œ ðŸ˜›) and then start freelancing or something after a couple of months.</p>
<p>4 days into my Sabbatical, I read <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">this post</a> and hastily made a proof of concept for <a href="https://laravel.com/">Laravel</a>.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.07.30%20AM.png" alt="Original Livewire tweet"></p>
<p>This day marked the abrupt end of my sabbatical. I was completely enamored with the project (now called <a href="https://laravel-livewire.com/">Livewire</a>) and couldnâ€™t stop working on it full-time. (Iâ€™ve never stopped. Iâ€™m STILL enamored with it full-time.)</p>
<p>(I also created a pretty popular JS framework along the way called <a href="https://github.com/alpinejs/alpine">AlpineJS</a> that I work on too, but thatâ€™s a story for another timeâ€¦)</p>
<p>Believe it or not, open-source software doesnâ€™t quite pay the bills, so I took on some small code mentorship clients to stay above the water for the entire year of 2019.</p>
<p>Here was my income for 2019 from that freelance work:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.51.34%20AM.png" alt="$21k in self employed income for 2018"></p>
<p>I reduced my salary by ~$70k so I could pursue my passion. It seemed risky, but I knew it would only get harder to make this kind of move in life.</p>
<p>Lots of kind folks reached out to me along the way asking how they could help support the project. Sending me messages like this:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.13.29%20AM.png" alt="Email from a Livewire user asking to support on Patreon"></p>
<p>I avoided creating a Patreon for a long time because I kept picturing a world where a handful of people give me five bucks a month. Which would be nice, but never seemed worth it to me.</p>
<p>Then I saw <a href="https://github.com/sponsors">GitHub Sponsors</a>. ðŸ˜�</p>
<p>It seemed perfect. Hosted directly on GitHub and new enough that thereâ€™s some excitement around it.</p>
<p>I was accepted into GitHub Sponsors on Dec. 12th of 2019.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.17.23%20AM.png" alt="@faustbrian github user sponsoring at $24/mo on Dec 12th">
(Thanks for being my first sponsor, Brian! â�¤ï¸�)</p>
<p>Iâ€™ve since received ~$25k in cash from GitHub sponsorsâ€¦
(They match the first $5k, and they take a ZERO percent cut. You keep EVERYTHING ðŸ™ŒðŸ�»â�¤ï¸�)</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-14%20at%201.36.58%20PM.png" alt="A payout statement from GH sponsors showing $25k in payouts"></p>
<p>â€¦and as of this writing, Iâ€™ve grown my annual GitHub sponsors revenue to $112,680/yr. ðŸŽ‰</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-17%20at%205.23.46%20PM.png" alt="A screenshot of github sponsors dashboard showing $112680 in yearly revenue"></p>
<p>Wow.</p>
<p>I am now making more money than Iâ€™ve ever made while developing open-source software for a community that I adore. Pinch me, Iâ€™m dreaming.</p>
<p>Was it luck? thereâ€™s certainly been a lot of that.</p>
<p>Was it fate? Letâ€™s leave religion out of this mmkay?â€¦</p>
<p>Was it that the software I built was so incredibly compelling that it forced 535 people to give me at least $14/mo. to keep working on it? â€¦I wish.
Itâ€™s more than that though. There were some key things I did along the way to get here. Let me tell you all about them.</p>
<p>Here we go!</p>
<h2>Phase 1: Good-Hearted Folks</h2>
<p>At first, GitHub Sponsors was a place to send loyal/generous followers that wanted to support the project. </p>
<p>However saintly these people are, there arenâ€™t that many of them compared to the number of people actually using the software (and often making money on it).</p>
<p>Because of the nature of open-source, people are already getting the software for free, so without ADDING any value to their lives, this strategy is seriously limiting.</p>
<p>The first section of this income graph is solely from kind folks who just wanted to pitch in.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3023657946.png"></a></p>
<p>Huge thank you to all those people.</p>
<p>Now letâ€™s talk about that first spike. </p>
<h2>Phase 2: Sponsorware</h2>
<p>Hereâ€™s where things started to get wild.</p>
<p>I had a cool idea for a small little Laravel package.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/7B10BCF2-60A7-421D-ACAC-EF1679BE70A2.png" alt="Sushi Laravel package tweet"></p>
<p>While recording an episode of <a href="https://noplanstomerge.com/">No Plans To Merge</a> with my buddy <a href="https://twitter.com/DCoulbourne">Daniel</a> on how to monetize it, we cooked up a novel idea called: â€œSponsorwareâ€�</p>
<iframe src="https://player.vimeo.com/video/394690352" width="640" height="480" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
<p>(<a href="https://noplanstomerge.simplecast.com/episodes/funding-opensource-software-aka-sponsorware">Listen To Full Episode</a>)</p>
<p>Hereâ€™s how Sponsorware works:</p>
<ul>
<li>Create a cool piece of software</li>
<li>Make it exclusive to people who sponsor you until you reach a certain number of sponsors</li>
<li>Then open source the project to the world</li>
</ul>
<p>Itâ€™s a win-win.</p>
<p>It worked incredibly well and I increased my yearly revenue by $11k in a matter of days.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/1455106854.png"></a></p>
<p>I did an entire writeup on â€œSponsorwareâ€� <a href="https://calebporzio.com/sponsorware">here</a> and was interviewed about the process on <a href="https://changelog.com/podcast/381">this episode of The Changelog Podcast</a>.</p>
<p>Also, a friend of mine <a href="https://twitter.com/enunomaduro">Nuno Maduro</a> recently replicated the technique with his project called <a href="https://pestphp.com/">Pest</a> and had similar success:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/C9AFA1F2-F052-4D7A-A3FE-A2B3A74E3EA6.png" alt="Nuno's tweet about Pest"></p>
<p>This technique is fantastic, but it requires me to have a constant stream of new ideas. All of which would become projects I would have to maintain ongoing. I needed something more reasonable for the long haul.</p>
<h2>Phase 3: Sponsored Screencasts</h2>
<p>This is where the VAST majority of my sponsorships came from.</p>
<p>The chart speaks for itself:</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/2049117902.png"></a></p>
<p>So whatâ€™s the secret?</p>
<h3>Educational content.</h3>
<p>Building a useful piece of software is one thing. Educating people on how to use it is an entirely different thing. (A much less fun thing I might add)</p>
<p>I try to make <a href="https://laravel-livewire.com/docs">the docs</a> as good as possible, but thereâ€™s always a need for more advanced content.</p>
<p>Rather than taking on the huge task of creating an entire course or book on  Livewire. I decided to go a different route.</p>
<p>Hereâ€™s exactly what I did that took me from ~$40k to &gt;$100k in ~3 months:</p>
<p>I released a free set of screencasts on the basics of using Livewire:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/FE07E488-D224-4072-9508-05ECD3D6A250.png" alt="My tweet about new Livewire free screencasts"></p>
<p>I added links to other parts of the documentation pointing people towards them so they know theyâ€™re there:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/6D245849-06E2-42A5-82A6-2580BF6BF4EF.png" alt="A call to action telling docs visitors to watch the screencasts"></p>
<p>A few weeks later I added a new â€œprivateâ€� group of screencasts for GitHub sponsors only.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/54ECAE52-5CE3-4E9C-A990-CE0E04E2D9F4.png" alt="A screenshot of a video being restricted to sponsors only"></p>
<p>THIS is the secret sauce ðŸŒ¶ï¸�.</p>
<p>(To make all this happen I built a Laravel app with GitHub authentication that calls on the GitHub API to verify a userâ€™s sponsorship)</p>
<p>Now, people watching the screencasts will naturally encounter these â€œprivateâ€� screencasts and if they like the free ones, they will sponsor me (at $14/mo.) to get access.</p>
<p>I release a new batch of videos every time a new feature comes out, or I decide to cover a new Livewire technique.</p>
<p>I also provide sponsors with access to the source code for each lesson (which is hosted on a separate repo and will eventually become an entire web app written with Livewire).</p>
<p>In terms of income, this has been the single most impactful idea I have EVER had.</p>
<p>It raised my annual revenue by ~$80k in 90 days. Itâ€™s like magic.</p>
<p>Now I have a constant stream of income without having to spend all my time on major course launches. I can keep building the software I love for the community I love and release new screencasts over time (which I actually enjoy doing).</p>
<h2>Nuggets Iâ€™ve Picked Up Along The Way:</h2>
<h3>Make good stuff</h3>
<p>All of this works because I spent years and years honing my craft and producing software that is truly useful. Iâ€™ve poured everything I have into that work, and there are no shortcuts there. You saw earlier how I worked full-time on an open-source project for almost an entire year before seeing any returns. The work people are sponsoring for has to be quality and remain the #1 priority.</p>
<h3>Build an audience</h3>
<p>You can build the greatest tool on the internet, but it means nothing if no oneâ€™s paying attention to you. Building an audience is ESSENTIAL for any of this to work. Twitter followers and email subscribers are your most valuable asset. Again, no shortcuts here. Just hard work, and providing value to people publicly and consistently for a long time.</p>
<h3>Charge an impactful amount</h3>
<p>The biggest mistake people make with GitHub sponsors is offering too small of a first tier.</p>
<p>If people have the option of paying $1-5/mo. instead of &gt;$14, they will pay the lesser amount.</p>
<p>I realized early on that if I want to really make a go of this, Iâ€™d need more than five dollar sponsorships. I started at $9 for a long time and then bumped it to $14 for the screencasts.</p>
<p>Iâ€™ve added a $7 tier that gets no perks for kind folks that just want to say thanks but donâ€™t need anything in return. (These people are the aforementioned Saints ðŸ™�ðŸ�»)</p>
<h3>Pick better tier names</h3>
<p>When you are setting up your sponsorship tiers, pick names that describe the type of person the tier is suited for.</p>
<p>For example. For a higher tier, label it something like â€œThe Agencyâ€� or something that implies that a business should be sponsoring at a higher tier, rather than something vague like â€œPlatinumâ€�.</p>
<p>This way, when people are reading the tiers they will think to themselves: â€œWhat level of usage do I fall underâ€�, rather than: â€œHow much money do I want to spend per monthâ€�.</p>
<h3>Donâ€™t be afraid to talk about your sponsorships and how much you make</h3>
<p>I grew up thinking it was rude to talk about money. This is a lie. I got a ten thousand dollar raise once because a coworker told me how much they made. After I learned what they made I felt comfortable asking for that same amount. Nothing would have happened if they didnâ€™t tell me.</p>
<p>Transparency is health.</p>
<p>I donâ€™t hide what I make because Iâ€™ve benefited from others not hiding what they make.</p>
<p>Even if itâ€™s astronomically higher than me, Iâ€™m never bitter or entitled about it, Iâ€™m only ever excited and inspired. My hope is that others feel the same way.</p>
<p>On top of that, if youâ€™re excited about your GitHub sponsors revenue, others will be too!</p>
<p>Itâ€™s not rude to be totally up-front that you rely on this money and it helps you build the software people are using and benefiting from every day.</p>
<h3>Donâ€™t feel guilty about making a lot of money.</h3>
<p>I always remind myself that I am not a code missionary. If my sponsorship revenue climbs beyond a modest living, THATâ€™S OK. Itâ€™s not a non-profit.</p>
<p>Itâ€™s OK for my income to be proportional to the value my software adds to other peopleâ€™s lives.</p>
<p>This isnâ€™t holy work Iâ€™m doing. itâ€™s software that businesses use to make money. They profit from it. Itâ€™s OK to profit as well.</p>
<h2>Well Wishes</h2>
<p>I hope this saga at least amuses you, and at most provides a blueprint for making your own open-source projects financially sustainable.</p>
<p>SO many open source projects are started with enthusiasm …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</a></em></p>]]>
            </description>
            <link>https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613719</guid>
            <pubDate>Tue, 23 Jun 2020 13:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Hydraulic Erosion]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23612749">thread link</a>) | @schnautzi
<br/>
June 23, 2020 | https://jobtalle.com/simulating_hydraulic_erosion.html | <a href="https://web.archive.org/web/*/https://jobtalle.com/simulating_hydraulic_erosion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p><span>14 Jun 2020</span></p><h2>Simulating hydraulic erosion</h2><p><em>Hydraulic erosion</em> is the process by which water transforms terrain over time. This is mostly caused by rainfall, but also by ocean waves hitting the shore and the flow of rivers. Figure 1 shows the considerable effects that a small stream has had on the rocky environment around it. When creating realistically looking environments, the effects of erosion need to be accounted for. I have experimented with procedural terrain generation before to generate scenes for <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">layered voxel rendering</a> and to demonstrate <a href="https://jobtalle.com/cubic_noise.html" target="_blank">cubic noise</a>. These terrains were very basic and did not account for erosion. Therefore, they lack a lot of detail, making them unrealistic at closer inspection.</p><figure title="A small waterfall on La Palma"><img src="https://jobtalle.com/posts/2020_6_14/img/waterfall.jpg"><figcaption>Figure 1: A small waterfall.</figcaption></figure><p>In this article, I will detail a simple and fast method that approximates the effects of hydraulic erosion. The aim of this method is to create believable environments rather than reaching a high degree of realism. Fidelity may be sacrificed for the sake of speed, as long as the results look natural. Summarized, the method should do the following:</p><ul><li>The results must look <em>natural</em>.</li><li>The algorithm must be <em>simple</em>.</li><li>The algorithm must be <em>fast</em>.</li><li>The algorithm should simulate hydraulic erosion caused by <em>rainfall</em> and <em>rivers</em>.</li></ul><h2>Multiple approaches</h2><p>There are several different approaches when it comes to simulating erosion. All methods simulate the same phenomenon: water moving from high places to low places, eroding terrain as it flows, and depositing sediment as they go further down their paths. This process always results in a number of recognizable terrain features like gulleys and valleys where rivers flow, deltas where they meet their destination and <a href="https://en.wikipedia.org/wiki/Alluvial_fan" target="_blank">alluvial fans</a> where smaller streams combine into bigger rivers. While reading about this topic, I have encountered the following distinct strategies in research literature:</p><ul><li>Erosion is simulated by keeping track of where water is for every position on the terrain. A grid (or 2D array) is created for the environment, and water levels and pressures are kept for every cell. When updating, the pressures determine where the water flows to. While flowing, water moves sediment around.</li><li>Erosion is simulated by dropping many particles simulating raindrops on the terrain. The particles then move down the slopes of the terrain. They can bring sediment with them or deposit it.</li></ul><figure title="An island with simulated erosion"><img src="https://jobtalle.com/posts/2020_6_14/img/island.jpg"><figcaption>Figure 2: An island after erosion has been applied to it.</figcaption></figure><p>Mostly for performance reasons, I've chosen to implement a drop based method. Because most drops don't flow very far, many inactive drop simulations can be terminated early and the bulk of the processing power will go to the drops that actually carve out terrain features. The grid based simulation will need to simulate every part on the terrain for every update cycle.</p><h2>Snowballs</h2><p>The drops in the simulation can be seen as <em>snowballs</em> instead of raindrops. Within the context of the simulation, I believe this is a better analogy. The snowballs start small when they are dropped, but gain more material as they roll down the hills. When they become too big, they start shedding material as they go. When they stop rolling in valleys or in the sea, the snowballs fall apart and leave their material on the terrain.</p><p>The complete erosion algorithm (in <em>Javascript</em>) can be read below. This code uses a <code>heightMap</code> object to erode. This height map can be read from and written to, and the <code>sampleNormal</code> function can be used to get the surface normal. This is a 3D vector pointing upwards from the terrain, so it can be used to determine the slope direction and steepness.</p><pre>/**
 * Let a snowball erode the height map
 * @param {Number} x The X coordinate to start at
 * @param {Number} y The Y coordinate to start at
 */
trace = function(x, y) {
  const ox = (random.getFloat() * 2 - 1) * radius; // The X offset
  const oy = (random.getFloat() * 2 - 1) * radius; // The Y offset
  let sediment = 0; // The amount of carried sediment
  let xp = x; // The previous X position
  let yp = y; // The previous Y position
  let vx = 0; // The horizontal velocity
  let vy = 0; // The vertical velocity

  for (let i = 0; i &lt; maxIterations; ++i) {
    // Get the surface normal of the terrain at the current location
    const surfaceNormal = heightMap.sampleNormal(x + ox, y + oy);

    // If the terrain is flat, stop simulating, the snowball cannot roll any further
    if (surfaceNormal.y === 1)
      break;

    // Calculate the deposition and erosion rate
    const deposit = sediment * depositionRate * surfaceNormal.y;
    const erosion = erosionRate * (1 - surfaceNormal.y) * Math.min(1, i * iterationScale);

    // Change the sediment on the place this snowball came from
    heightMap.change(xp, yp, deposit - erosion);
    sediment += erosion - deposit;

    vx = friction * vx + surfaceNormal.x * speed;
    vy = friction * vy + surfaceNormal.z * speed;
    xp = x;
    yp = y;
    x += vx;
    y += vy;
  }
};

// Simulate 50000 snowballs
const snowballs = 50000;

for (let i = 0; i &lt; snowballs; ++i)
  trace(
    random.getFloat() * width,
    random.getFloat() * height);

// Blur the height map to smooth out the effects
heightMap.blur();
</pre><p>The algorithm has a few notable properties:</p><ul><li>The variables <code>ox</code> and <code>oy</code> encode the <em>offset</em> of a snowball. They are used to read the terrain slope with a certain offset to make the snowball motion a bit rougher, which prevents snowball paths from converging too much.</li><li>When the surface normal points perfectly upwards (when the y value of that normal equals one), the snowball terminates. In practice, this means that snowballs that have reached the edge of the simulated are or the sea floor stop simulating there. Because nothing happens in those areas, simulating erosion would be a waste of processing power.</li><li>When changing the amount of sediment, the snowball edits the height map at its previous position instead of its current position. Erosion and deposition take place behind it to prevent snowballs from digging themselves in.</li><li>After simulating erosion, gaussian blur is applied to the height map. Because the height map in these examples has a low resolution, blur is required to keep the surfaces smooth enough to be visually appealing.</li></ul><p>Because the offset is used while eroding, and because the erosion rate is quite high, every traced snowball has a larger influence on the terrain than a smaller node that looks more like a raindrop would. This results in a fast simulation, but it reduces precision.</p><h2>Results</h2><figure title="The results of the erosion algorithm"><img src="https://jobtalle.com/posts/2020_6_14/img/results.jpg"><figcaption>Figure 3: The results of the erosion algorithm.</figcaption></figure><p>Applying the algorithm above with varying snowball counts gives the results rendered in Figure 3. The algorithm <a href="https://jobtalle.com/HydraulicErosion" target="_blank">works in a browser</a>, and the source code can be found <a href="https://github.com/jobtalle/HydraulicErosion" target="_blank">on GitHub</a>. Pressing the space bar generates a new island. The "starting material" for the algorithm is shown in the first image of figure 3. This island shape was generated using a very similar algorithm to the one I used in <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">my layered voxel rendering example terrains</a>. While the shape does contain some details and ridges, it is very smooth and contains no traces of hydraulic erosion.</p><p>The second image shows the same island after dropping 35.000 snowballs on it. They are dropped randomly and evenly spaced. Because of the random initial conditions of the starting shape, valleys and river like structures form where the snowballs find the quickest way to the sea. 35.000 may seem like a high number, but recall that snowballs that reach the sea floor or the edge of the map terminate early. The majority of drops don't fall on the island, so only a small number will actualy roll down one of the valleys that can be seen in the image.</p><p>The third image shows the same island after dropping 50.000 snowballs. Compared to the previous image, no new details form, although the terrain features are more pronounced.</p><p>The last image shows the island after dropping 100.000 snowballs. This is clearly too much; the ridges become very deep and the shore is very rough. At this point, the results start looking less realistic too. The valleys carve out very sharp terrain features that would erode away themselves.</p><p>All islands in the images above can be generated within half a second on my desktop computer, with the algorithm running on a single CPU thread. Therefore, it is not necessary to reduce the number of snowballs for performance reasons in most applications. The algorithm is fast enough as it is.</p><h2>Conclusion</h2><p>The proposed algorithm provides a fast method to approximate hydraulic erosion. While realism was no priority, erosion and deposition patterns that one would expect do show up when testing the method on various terrains.</p><p>Because the code runs very fast (contrary to most alternative solutions that can be found in the literature), it may be suitable for applications like procedural terrain generation in games. In those applications, it is desirable to produce results quickly, while the results do not need to be very realistic; they just need to look credible.</p><p>The method can be extended to track the paths of river beds. Valleys where many snowballs roll through would realistically be rivers. When an area reaches a certain threshold of "snowball traffic", a river or lake can be created there.</p><p>Another interesting addition would be a texture that keeps track of the amount of erosion and deposition of material on the terrain. This data can then be used to color the terrain; if lots of material is deposited, sand and small particles will accumulate there. Areas where little erosion has taken place will look different from heavily eroded slopes.</p><h2>Appendix: rendering shore waves</h2><figure title="Waves"><img src="https://jobtalle.com/posts/2020_6_14/img/waves.jpg"><figcaption>Figure 4: Rendering shore waves.</figcaption></figure><p>The <a href="https://jobtalle.com/HydraulicErosion" target="_blank">animated example</a> contains waves that move towards the shore of the islands. Besides clarifying the shape of the shore, they don't really serve a purpose with regards to the erosion, but it makes the scene prettier.</p><p>Figure 4 shows the steps that create the wave animation:</p><ol>    <li>First, a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram" target="_blank"><em>Voronoi diagram</em></a> is created around the island shore. Instead of creating a diagram from points, the diagram is created from …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobtalle.com/simulating_hydraulic_erosion.html">https://jobtalle.com/simulating_hydraulic_erosion.html</a></em></p>]]>
            </description>
            <link>https://jobtalle.com/simulating_hydraulic_erosion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612749</guid>
            <pubDate>Tue, 23 Jun 2020 12:02:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sysinternals ProcDump for Linux]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23612212">thread link</a>) | @GordonS
<br/>
June 23, 2020 | https://build5nines.com/sysinternals-procdump-for-linux/ | <a href="https://web.archive.org/web/*/https://build5nines.com/sysinternals-procdump-for-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Sysinternals are very widely used tools from Microsoft in the Windows world, and now the ProcDump utility has been ported over to Linux as an Open Source project from Microsoft. ProcDump is a command-line (CLI) utility for monitoring an application for CPU spikes and generates crash dumps during the spike. An admin or developer can use these crash dumps to determine the cause of the spike. This tool was originally built for Windows, and now it’s available for use on Linux as well!</p>



<p>This is not a community port, but rather an official Open Source project from Microsoft. As such, this is the official Linux version of Sysinternals ProcDump created and maintained by Microsoft. Plus, it’s licensed under the MIT License.</p>



<br><h2>Linux ProcDump Usage</h2>



<pre><code>Usage: procdump [OPTIONS...] TARGET
   OPTIONS
      -h          Prints this help screen
      -C          Trigger core dump generation when CPU exceeds or equals specified value (0 to 100 * nCPU)
      -c          Trigger core dump generation when CPU is less than specified value (0 to 100 * nCPU)
      -M          Trigger core dump generation when memory commit exceeds or equals specified value (MB)
      -m          Trigger core dump generation when when memory commit is less than specified value (MB)
      -T          Trigger when thread count exceeds or equals specified value.
      -F          Trigger when filedescriptor count exceeds or equals specified value.
      -I          Polling frequency in milliseconds (default is 1000)
      -n          Number of core dumps to write before exiting (default is 1)
      -s          Consecutive seconds before dump is written (default is 10)
      -d          Writes diagnostic logs to syslog
   TARGET must be exactly one of these:
      -p          pid of the process
      -w          Name of the process executable</code></pre>



<h2>Linux ProcDump Examples</h2>



<p>Create core dump immediately:</p>



<pre><code>sudo procdump -p 1234</code></pre>



<p>Create 3 core dumps 10 seconds apart:</p>



<pre><code>sudo procdump -n 3 -p 1234</code></pre>



<p>Create 3 core dumps 5 seconds apart:</p>



<pre><code>sudo procdump -n 3 -s 5 -p 1234</code></pre>



<p>Create a core dump each time the process has CPU usage &gt;= 65%, up to 3 times, with at least 10 seconds between each dump:</p>



<pre><code>sudo procdump -C 65 -n 3 -p 1234</code></pre>



<p>Create a core dump when CPU usage is outside the range [10,65]:</p>



<pre><code>sudo procdump -c 10 -C 65 -p 1234</code></pre>



<h2>Download Sysinternals ProcDump for Linux</h2>



<p>The Sysinternals ProcDump for Linux utility is licensed under MIT License, and available over in it’s GitHub repo: <a href="https://github.com/Microsoft/ProcDump-for-Linux" target="_blank" rel="noopener">https://github.com/Microsoft/ProcDump-for-Linux</a></p>



<br><h3>System Requirements</h3>



<ul><li>Minimum Operating System<ul><li>Red Hat Enterprise Linux (RHEL) / CentOS 7</li><li>Fedora 29</li><li>Ubuntu 16.04 LTS</li></ul></li><li>gdb &gt;= 7.6.1</li><li>zlib (buil-time only)</li></ul>







<p>Happy monitoring your process dumps and troubleshooting your apps!</p>

<br><h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is a <strong>Microsoft MVP</strong> and has 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
						
										</div></div>]]>
            </description>
            <link>https://build5nines.com/sysinternals-procdump-for-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612212</guid>
            <pubDate>Tue, 23 Jun 2020 10:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’ve decided to rename Riot]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 222 (<a href="https://news.ycombinator.com/item?id=23611863">thread link</a>) | @anotherevan
<br/>
June 23, 2020 | https://blog.riot.im/the-world-is-changing/ | <a href="https://web.archive.org/web/*/https://blog.riot.im/the-world-is-changing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Hi all,</p><p>It's almost four years since we launched Riot, and it's been a crazy journey - going from a relatively bare bones Matrix app through to today's all-singing, all-dancing encrypted-by-default collaboration tool used by folks ranging from Mozilla to the French Government and beyond.</p><p>However, as some may know, we’ve had a few problems with the name Riot over the years. &nbsp;Firstly, the biggest by far has been from a certain large games company that has consistently blocked us from being able to trademark Riot or even Riot.im - which has been a huge issue when it comes to defending users against abusive forks of the app. We’re in a terrible position if someone forks Riot using the same or similar name and logo, makes some dubious changes, and we can’t take action to persuade the app stores to remove it.</p><p>Secondly, we picked the name “Riot” to evoke something disruptive and vibrant - like a “riot of colour.” &nbsp;There’s a reason the loading animation on the mobile apps has been of the logo running riot through completely different versions of the logo. &nbsp;However, many people hear the word Riot and assume that the app is focused on violence - which it is not.</p><p>Finally, we’ve found that users can get very confused by the different brands that surround Riot. We can’t get away from the fact that Riot builds on Matrix rather than being yet another siloed communication app (and it's very deliberate that Riot is not named after Matrix). However, how come Riot is made by a company called New Vector? Why should I get a server for Riot from Modular, and what do they have to do with Riot or New Vector? What’s RiotX? After all, when I use Slack, it’s made by a company called Slack, who provide hosting called… Slack. Likewise Discord. Likewise Rocket.chat and many others. Back in 2016 it may have made sense to create three different brands (Riot, Modular, New Vector) to spell out the modularity of the ecosystem - but nowadays there are lots of other Matrix clients, vendors and hosting providers that demonstrate perfectly the diversity of the Matrix ecosystem.</p><p><strong>Therefore, we’ve decided to rename Riot (and New Vector, and Modular).</strong></p><p>The new name will be announced in a few weeks once we’re ready, but we wanted to give everyone a heads up so it doesn’t come as a shock. </p><p>This is obviously a bold move: we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. Renaming is inevitably going to cause some confusion. We know that many of you reading this will have put their neck on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users.</p><p>However, we are extremely confident that now is the right time to fix the name. We’re in the process of landing gigantic improvements to Riot’s user experience and usability which will unrecognisably improve the app. &nbsp;So unrecognisably, in fact, that we can shed our skin and celebrate our long-awaited transition into being a truly mainstream-usable app. &nbsp;And most importantly, we’ve finally found a name which we’re really excited about (much more than we ever were about Riot!), and we hope you’ll like it too!</p><p>So… watch this space. We’re going to have our heads down for the next few weeks while we pull together all the waves of improvements we have in flight, and then all shall be revealed.</p><p>Thanks for using and supporting Riot. &nbsp;We’ll see you on the other side!</p><p>Matthew, Amandine &amp; all of New Vector (and Riot, and Modular)</p><p>P.S. discussion over at <a href="https://news.ycombinator.com/item?id=23611863">HN</a><br></p>
			</section></div>]]>
            </description>
            <link>https://blog.riot.im/the-world-is-changing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611863</guid>
            <pubDate>Tue, 23 Jun 2020 10:01:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning operating system development using Linux kernel and Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23611081">thread link</a>) | @weeber
<br/>
June 23, 2020 | https://s-matyukevich.github.io/raspberry-pi-os/ | <a href="https://web.archive.org/web/*/https://s-matyukevich.github.io/raspberry-pi-os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<p>This repository contains a step-by-step guide that teaches how to create a simple operating system (OS) kernel from scratch. I call this OS Raspberry Pi OS or just RPi OS. The RPi OS source code is largely based on <a href="https://github.com/torvalds/linux">Linux kernel</a>, but the OS has very limited functionality and supports only <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberry PI 3</a>.</p>

<p>Each lesson is designed in such a way that it first explains how some kernel feature is implemented in the RPi OS, and then it tries to demonstrate how the same functionality works in the Linux kernel. Each lesson has a corresponding folder in the <a href="https://github.com/s-matyukevich/raspberry-pi-os/tree/master/src">src</a> directory, which contains a snapshot of the OS source code at the time when the lesson had just been completed. This allows the introduction of new concepts gracefully and helps readers to follow the evolution of the RPi OS. Understanding this guide doesn’t require any specific OS development skills.</p>

<p>For more information about project goals and history, please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a>. The project is still under active development, if you are willing to participate - please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a>.</p>

<p>
  <a href="https://twitter.com/RPi_OS" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/twitter.png" alt="Follow @RPi_OS on twitter" height="34">
  </a>

  <a href="https://www.facebook.com/groups/251043708976964/" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/facebook.png" alt="Follow Raspberry Pi OS on facebook" height="34">
  </a>

  <a href="https://join.slack.com/t/rpi-os/shared_invite/enQtNDQ1NTg2ODc1MDEwLWVjMTZlZmMyZDE4OGEyYmMzNTY1YjljZjU5YWI1NDllOWEwMjI5YzVkM2RiMzliYjEzN2RlYmUzNzBiYmQyMjY" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/slack.png" alt="Join Raspberry Pi OS in slack" height="34">
  </a>

  <a href="https://www.producthunt.com/upcoming/raspberry-pi-os" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/subscribe.png" alt="Subscribe for updates" height="34">
  </a>
</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Prerequisites.html">Prerequisites</a></strong></li>
  <li><strong>Lesson 1: Kernel Initialization</strong>
    <ul>
      <li>1.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/rpi-os.html">Introducing RPi OS, or bare metal “Hello, world!”</a></li>
      <li>Linux
        <ul>
          <li>1.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/project-structure.html">Project structure</a></li>
          <li>1.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/build-system.html">Kernel build system</a></li>
          <li>1.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/kernel-startup.html">Startup sequence</a></li>
        </ul>
      </li>
      <li>1.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 2: Processor initialization</strong>
    <ul>
      <li>2.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/rpi-os.html">RPi OS</a></li>
      <li>2.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/linux.html">Linux</a></li>
      <li>2.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 3: Interrupt handling</strong>
    <ul>
      <li>3.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>3.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/low_level-exception_handling.html">Low level exception handling</a></li>
          <li>3.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/interrupt_controllers.html">Interrupt controllers</a></li>
          <li>3.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/timer.html">Timers</a></li>
        </ul>
      </li>
      <li>3.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 4: Process scheduler</strong>
    <ul>
      <li>4.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>4.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/basic_structures.html">Scheduler basic structures</a></li>
          <li>4.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/fork.html">Forking a task</a></li>
          <li>4.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/scheduler.html">Scheduler</a></li>
        </ul>
      </li>
      <li>4.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 5: User processes and system calls</strong>
    <ul>
      <li>5.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/rpi-os.html">RPi OS</a></li>
      <li>5.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/linux.html">Linux</a></li>
      <li>5.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 6: Virtual memory management</strong>
    <ul>
      <li>6.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/rpi-os.html">RPi OS</a></li>
      <li>6.2 Linux (In progress)</li>
      <li>6.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 7: Signals and interrupt waiting</strong> (To be done)</li>
  <li><strong>Lesson 8: File systems</strong> (To be done)</li>
  <li><strong>Lesson 9: Executable files (ELF)</strong> (To be done)</li>
  <li><strong>Lesson 10: Drivers</strong> (To be done)</li>
  <li><strong>Lesson 11: Networking</strong> (To be done)</li>
</ul>


      </section>
    </div></div>]]>
            </description>
            <link>https://s-matyukevich.github.io/raspberry-pi-os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611081</guid>
            <pubDate>Tue, 23 Jun 2020 08:00:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheap tricks for high-performance Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23609434">thread link</a>) | @O_H_E
<br/>
June 22, 2020 | https://deterministic.space/high-performance-rust.html | <a href="https://web.archive.org/web/*/https://deterministic.space/high-performance-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>So you’re writing Rust but it’s not fast enough?
Even though you’re using <code>cargo build --release</code>?
Here’s some small things you can do to increase the runtime speed of a Rust project
– practically without changing any code!</p>

<p>Please remember that the following suggestions <strong>do not</strong> replace actual profiling and optimizations!
I also think it goes without saying that the only way to detect if any of this helps
is having benchmarks that represent how your application behaves under real usage.</p>

<h2 id="tweaking-our-release-profile">Tweaking our <code>release</code> profile</h2>

<p>Let’s first of all enable some more optimizations
for when we do <code>cargo build --release</code>.
The deal is pretty simple:
We enable some features that make building release builds even slower
but get more thorough optimizations as a reward.</p>

<p>We add the flags described below to our main <code>Cargo.toml</code> file,
i.e., the top most manifest file in case you are using a <a href="https://doc.rust-lang.org/1.41.1/book/ch14-03-cargo-workspaces.html">Cargo workspace</a>.
If you don’t already have a section called <code>profile.release</code>, add it:</p>



<h3 id="link-time-optimization">Link-time optimization</h3>

<p>The first thing we’ll do is enable <a href="https://llvm.org/docs/LinkTimeOptimization.html">link-time optimization</a> (LTO).
It’s a kind of whole-program or inter-module optimization as it runs as the very last step
when linking the different parts of your binary together.
You can think of it as allowing
better inlining across dependency boundaries
(but it’s of course more complicated that that).</p>

<p>Rust can use multiple linker flavors,
and the one we want is “optimize across all crates”, which is called “fat”.
To set this, add the <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#lto"><code>lto</code></a> flag to your profile:</p>



<h3 id="code-generation-units">Code generation units</h3>

<p>Next up is a similar topic.
To speed up compile times, Rust tries to split your crates into small chunks
and compile as many in parallel as possible.
The downside is that there’s less opportunities for the compiler
to optimize code across these chunks.
So, let’s <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#codegen-units">tell it</a> to do one chunk per crate:</p>



<h3 id="setting-a-specific-target-cpu">Setting a specific target CPU</h3>

<p>By default, Rust wants to build a binary that works on as many machines
of the target architecture as possible.
However, you might actually have a pretty new CPU with cool new features!
To <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#target-cpu">enable</a> those, we add</p>



<p>as a “Rust flag”,
i.e. the environment variable <code>RUSTFLAGS</code>
or the target’s <code>rustflags</code> field in your <a href="https://doc.rust-lang.org/1.41.1/cargo/reference/config.html"><code>.cargo/config</code></a>.</p>

<h3 id="aborting">Aborting</h3>

<p>Now we get into some of the more unsafe options.
Remember how Rust by default uses <a href="https://doc.rust-lang.org/1.41.1/nomicon/unwinding.html">stack unwinding</a>
(on the most common platforms)?
That costs performance!
Let’s skip stack traces and the ability to catch panics
for reduced code size and better cache usage:</p>



<p>Please note that some libraries might depend on unwinding
and will explode horribly if you enable this!</p>

<h2 id="using-a-different-allocator">Using a different allocator</h2>

<p>One thing many Rust programs do is allocate memory.
And they don’t just do this themselves but actually use an (external) library for that:
an allocator.
Current Rust binaries use the default system allocator by default,
previously they included their own with the standard library.
(This change has lead to smaller binaries and better debug-abiliy
which made some people quite happy).</p>

<p>Sometimes your system’s allocator is not the best pick, though.
Not to worry, we can change it!
I suggest giving both <a href="https://github.com/jemalloc/jemalloc">jemalloc</a> and <a href="https://github.com/microsoft/mimalloc">mimalloc</a> a try.</p>

<h3 id="jemalloc">jemalloc</h3>

<p><a href="https://github.com/jemalloc/jemalloc">jemalloc</a> is the allocator that Rust previously shipped with
and that the Rust compiler still uses itself.
Its focus is to reduce memory fragmentation and support high concurrency.
It’s also the default allocator on FreeBSD.
If this sounds interesting to you, let’s give it a try!</p>

<p>First off, add the <a href="https://docs.rs/jemallocator"><code>jemallocator</code></a> crate as a dependency:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>jemallocator</span> <span>=</span> <span>"0.3.2"</span>
</code></pre></div></div>

<p>Then in your applications entry point (<code>main.rs</code>),
set it as the global allocator like this:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span> <span>=</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span><span>;</span>
</code></pre></div></div>

<p>Please note that jemalloc doesn’t support all platforms.</p>

<h3 id="mimalloc">mimalloc</h3>

<p>Another interesting alternative allocator is <a href="https://github.com/microsoft/mimalloc">mimalloc</a>.
It was developed by Microsoft, has quite a small footprint,
and some innovative ideas for free lists.</p>

<p>It also features configurable security features
(have a look at <a href="https://github.com/purpleprotocol/mimalloc_rust/blob/c6bf4578d3258a0b6a28696196ede6d50e5ee8c2/Cargo.toml#L25-L28">its <code>Cargo.toml</code></a>).
Which means we can turn them off more performance!
Add the <a href="https://docs.rs/mimalloc"><code>mimalloc</code> crate</a> as a dependency like this:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>mimalloc</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.1.17"</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
</code></pre></div></div>

<p>and, same as above, add this to your entry point file:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span> <span>=</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span><span>;</span>
</code></pre></div></div>

<h2 id="profile-guided-optimization">Profile Guided Optimization</h2>

<p>This is a neat feature of LLVM
but I’ve never used it.
Please read <a href="https://doc.rust-lang.org/1.41.1/rustc/profile-guided-optimization.html">the docs</a>.</p>

<h2 id="actual-profiling-and-optimizing-your-code">Actual profiling and optimizing your code</h2>

<p>Now this is where you need to actually adjust your code
and fix all those <code>clone()</code> calls.
Sadly, this is a topic for another post!
(While you wait another year for me to write it, you can read about <a href="https://deterministic.space/secret-life-of-cows.html">cows</a>!)</p>

<p><strong>Edit:</strong> People keep asking for those actual tips on how to optimize Rust code.
And luckily <del>I tricked them</del> they had some good material for me to link to:</p>

<ul>
  <li>The very convenient <a href="https://github.com/flamegraph-rs/flamegraph"><code>cargo flamegraph</code></a> (also works as a standalone tool)</li>
  <li>Christopher Sebastian recently published <a href="https://likebike.com/posts/How_To_Write_Fast_Rust_Code.html">How To Write Fast Rust Code</a></li>
  <li>Jack Fransham’s <a href="http://troubles.md/posts/rustfest-2018-workshop/">Fastware Workshop</a> from RustFest 2018</li>
</ul>


  </div></div>]]>
            </description>
            <link>https://deterministic.space/high-performance-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609434</guid>
            <pubDate>Tue, 23 Jun 2020 02:44:05 GMT</pubDate>
        </item>
    </channel>
</rss>
