<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 03 Feb 2021 17:02:36 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 03 Feb 2021 17:02:36 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Go 1.16 will make system calls through Libc on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25997506">thread link</a>) | @lladnar
<br/>
February 1, 2021 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Go 1.16 will make system calls through libc on OpenBSD</h2>

	<p><small>February  1, 2021</small></p>
</div><div><p>One of the unusual things about <a href="https://golang.org/">Go</a> is that
it started out with the approach of directly making system calls
on Unix, instead of calling the standard C library functions that
correspond to those system calls. <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoCLibraryAPIIssues">There are reasonably good reasons
for Go to make direct system calls</a> and this
works well on Linux, but other Unixes are different. The official
API for Illumos and Solaris system calls requires you to use their
C library, and OpenBSD wants you to do this as well for security
reasons (for <a href="https://lwn.net/Articles/806776/">OpenBSD system call origin verification</a>). Go has used the C library on
Solaris and Illumos for a long time, but through Go 1.15 it made
direct system calls on OpenBSD and so current released versions of
OpenBSD had a special exemption from their system call origin
verification because of it.</p>

<p>The news of the time interval for Go 1.16 is that this is changing. To
quote from the current draft release notes (which are probably soon to
be the official release notes):</p>

<blockquote><p>On the 64-bit x86 and 64-bit ARM architectures on OpenBSD (the
<code>openbsd/amd64</code> and <code>openbsd/arm64</code> ports), system calls are now
made through <code>libc</code>, instead of directly using the <code>SYSCALL/SVC</code>
instruction. This ensures forward-compatibility with future versions
of OpenBSD. In particular, OpenBSD 6.9 onwards will require system
calls to be made through <code>libc</code> for non-static Go binaries.</p>
</blockquote>

<p>As far as I know, Go programs that look up host names or do a few other
operations are very likely to not be statically linked. You can force
static linking (and you'll normally get it if you cross-build), but it
has some drawbacks for hostname lookups in some configurations and you
can't do some other operations at all.</p>

<p>At one level everything is okay with this situation. OpenBSD 6.9 will
almost certainly include Go 1.16 in its ports collection, since it will
be the only version of Go that works on it, and from there you can build
Go programs that will run fine on 6.9. At another level, any dynamically
linked Go program you have will need to be rebuilt with Go 1.16 before
you can run it on OpenBSD 6.9. Hopefully you have the source code and
can still build it (in what will be a 'modular by default' world in Go
1.16). This is nothing really new for OpenBSD, which has always made it
clear that they don't promise ABI or even API compatibility; you always
need to be prepared to rebuild your programs for new OpenBSD versions,
and perhaps to update them to more secure APIs.</p>

<p>(Statically linked Go programs built by Go 1.15 or earlier will likely
keep working on OpenBSD 6.9, assuming that there are no other ABI
changes that affect them. But you should probably plan to rebuild them
with Go 1.16 just to be sure. I don't know what the situation will be
if you want to create Go binaries that work across a range of OpenBSD
versions.)</p>

<p>As the release notes say, Go 1.16 will make system calls through libc
for all programs, whether they're dynamically linked or statically
linked. Right now OpenBSD only requires this for dynamically linked
programs (well, will require it), but always calling via libc is simpler
than to maintain two sets of system call code. And someday OpenBSD may
do something more elaborate so that making system calls via libc is
required even for statically linked programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997506</guid>
            <pubDate>Tue, 02 Feb 2021 04:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unbroken Enigma Message]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25992462">thread link</a>) | @akakievich
<br/>
February 1, 2021 | https://enigma.hoerenberg.com/index.php?cat=Unbroken | <a href="https://web.archive.org/web/*/https://enigma.hoerenberg.com/index.php?cat=Unbroken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://enigma.hoerenberg.com/index.php?cat=Unbroken</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992462</guid>
            <pubDate>Mon, 01 Feb 2021 19:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we develop FDA-compliant machine learning algorithms]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25992363">thread link</a>) | @yshrestha
<br/>
February 1, 2021 | https://innolitics.com/articles/machine-learning-development-for-medical-devices/ | <a href="https://web.archive.org/web/*/https://innolitics.com/articles/machine-learning-development-for-medical-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p>
      by Grace Adams and Yujan Shrestha on January 26, 2021
    </p>
    
    <p>Want to know how we develop safe, effective, and FDA compliant machine learning algorithms? This article describes how we develop machine learning algorithms, points out common pitfalls, and makes documentation recommendations.</p>

<p>When developing a machine learning or AI algorithm, it‚Äôs easy to become overly focused on making the best model possible. While model performance is important, to incorporate the model into a commercial medical device, you‚Äôll need to be able to demonstrate to the FDA that the model is safe and effective. Therefore, it‚Äôs critical to thoroughly document the algorithm‚Äôs development lineage in your design history file. The process outlined in this article will help you do this. We‚Äôve used it to develop AI algorithms within a recently 510(k)-cleared class-II medical device for one of our clients.</p>

<p>The FDA released its <a href="https://www.fda.gov/media/145022/download"><em>Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan</em></a> in January of 2021. In it, they discuss upcoming changes to their approach for regulating ML-based medical devices. The exact details aren‚Äôt public, but we suspect following a consistent development process will be part of it.</p>
      <h2 id="focus-on-process-documentation">
        
        
          Focus on process documentation <a href="#focus-on-process-documentation">üîó</a>
        
        
      </h2>

<p>Our AI development process includes generating reports that detail the input data, model performance, and model selection process. These reports streamline model development by helping developers recognize and correct some of the most common pitfalls in algorithm development, thereby increasing confidence in the AI/ML algorithm‚Äôs safety and efficacy. As a convenient side effect, these reports are a powerful tool when designing a QMS suitable for AI and navigating the FDA clearance process.</p>
    
      <h3 id="some-common-pitfalls-we-have-identified-are">
        
        
          Some common pitfalls we have identified are: <a href="#some-common-pitfalls-we-have-identified-are">üîó</a>
        
        
      </h3>

<ul>
  <li>Laser-focus on chasing higher accuracy metrics and forgetting about the business, clinical, and regulatory context</li>
  <li>Errors in data import and preprocessing</li>
  <li>Clinically unrealistic data augmentation</li>
  <li>Algorithm performance metrics‚Äîsuch as the Dice score‚Äîare not a perfect proxy to clinical performance but are treated as such</li>
  <li>Data leakage or improper training/validation splits leads to undetectable overfitting and a false sense of stellar algorithm performance</li>
  <li>Using data that was acquired with non-clinical (research) protocols that are too different from the device‚Äôs intended use thereby leading to regulatory risk. <sup><a href="#acknowledgments">1</a></sup></li>
  <li>Not being aware of sampling bias in the data thereby leading to regulatory risk. For example, certain age groups may be underrepresented or certain scanner vendors may be overrepresented. <sup><a href="#acknowledgments">1</a></sup></li>
</ul>
    
      <h3 id="these-pitfalls-can-be-mitigated-by-the-following-reports">
        
        
          These pitfalls can be mitigated by the following reports: <a href="#these-pitfalls-can-be-mitigated-by-the-following-reports">üîó</a>
        
        
      </h3>

<ul>
  <li>Input Verification Report</li>
  <li>Data Augmentation Quality Assurance Report</li>
  <li>Model Performance Report</li>
  <li>Model Comparison Report</li>
</ul>
    
      <h3 id="input-verification-report">
        
        
          Input Verification Report <a href="#input-verification-report">üîó</a>
        
        
      </h3>

<p>The input verification report should visualize the dataset as close to the model training step as possible. A common source of error can be simple data processing errors. This report is also an excellent way to verify the quality of the data. If the input data is not very accurate to start with, it will be hard to train an accurate model. In other words, ‚Äúgarbage in equals garbage out.‚Äù</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Input_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="data-augmentation-quality-assurance-qa-report">
        
        
          Data Augmentation Quality Assurance (QA) Report <a href="#data-augmentation-quality-assurance-qa-report">üîó</a>
        
        
      </h3>

<p>Data augmentation is a powerful technique that effectively increases the size of your dataset, reducing the risk of overfitting and increasing accuracy. However, going overboard with data augmentation techniques could distort the images beyond realistic boundaries. The data augmentation QA report takes a random sample of the dataset and produces several augmentations of that image and its annotations. This report allows you to confirm the augmented images are still clinically valid and that the annotations‚Äîsuch as segmentations and fiducial markers‚Äîare augmented properly.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Data_Augmentation_QA_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-performance-report">
        
        
          Model Performance Report <a href="#model-performance-report">üîó</a>
        
        
      </h3>

<p>The model performance report can vary greatly depending on the problem. However, there are four essential properties that this report should have:</p>

<ol>
  <li>Training graphs: These graphs should show how the accuracy and loss metrics develop from epoch to epoch for the training and validation set. They can help you determine if the model converges, when it begins to overfit, and the likelihood of data leakage.</li>
  <li>Statistics table: This table shows any relevant information for the model, such as the training set accuracy at the end of the last training epoch, the validation set accuracy, and the number of parameters in the model.</li>
  <li>Model Architecture: Information about the structure of the model itself. Tensorflow has a built-in function for visualizing this quickly.</li>
  <li>Visualized Inference: This portion of the report will look a lot like the input verification report for the validation set, but it will also include both the human and AI annotations. We place the worst performers at the top of the report to help focus analysis and subsequent iteration.</li>
</ol>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Model_Output_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-comparison-report">
        
        
          Model Comparison Report <a href="#model-comparison-report">üîó</a>
        
        
      </h3>

<p>During the development of any ML model, there are likely to be hundreds of models trained, each with different hyperparameters, data augmentations, or even different architecture configurations. Additionally, model improvements are likely to be made in the post-market phase as more data is acquired and newer ML techniques are discovered. Therefore, it is essential to have a way to compare multiple models so that you can empirically determine which model performs better. The model comparison report includes the training graphs for each of the models, a statistics table for easy model comparison, and the inferences from each of the models on the same validation dataset. Visualizing all of the different models‚Äô inferences is particularly important since the loss function alone is not the full story. For example, a model with worse metrics could be because it is actually finding more human annotation errors than the others.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Models_Comparison_Report.pdf">Click here to view an example</a></p>
    
      <h2 id="the-process">
        
        
          The Process <a href="#the-process">üîó</a>
        
        
      </h2>

<p>The process we have developed is rooted in the idea that good machine learning practices will lead to algorithms that will generalize to a real clinical setting and thus be safe and reliable. Here I‚Äôll use an example project, segmenting the lungs in chest x-rays, to go step-by-step through our development process. I‚Äôll be detailing the use of the four reports and pointing out common sources of errors along the way.</p>
    
      <h2 id="step-1-problem-definition">
        
        
          Step 1: Problem definition <a href="#step-1-problem-definition">üîó</a>
        
        
      </h2>

<p>When beginning any project, it is vital to understand the goals and limitations. We work closely with our clients to make sure that we can meet all their requirements. Some important considerations are:</p>

<ul>
  <li>Speed: Should this run on an embedded device? Should inference be possible without a GPU? How many concurrent inferences are necessary and on what hardware?</li>
  <li>Accuracy: What accuracy do we think is necessary for a clinically useful model? If an algorithm suggests a segmentation for the physician to edit, the minimum accuracy threshold is probably lower than if the algorithm‚Äôs segmentations are used directly for diagnosis. A risk analysis coupled with a literature review can help determine this threshold.</li>
  <li>Development budget: Where should we be on the 80/20 rule? Each .9% added to the accuracy target will scale the cost exponentially. Should we use off the shelf architectures or something more customized? How fast do we need to develop the model? Is this a feasibility study, or do we need to observe more rigorous medical device design controls?</li>
</ul>

<p><em>Example: For the Lung Segmentation problem, it doesn‚Äôt need to run on an embedded device and should always have access to a GPU. The goal is to make the model as accurate as possible, but there will usually be several inferences running concurrently. Ideally, the model will be as small as possible without sacrificing accuracy, as inferences time is related to model size. The budget and timeline are limited, so existing architecture implementations are preferred.</em></p>
    
      <h2 id="step-2-get-data">
        
        
          Step 2: Get data <a href="#step-2-get-data">üîó</a>
        
        
      </h2>

<p>The data used to train and test the model is an essential part of ML development. If a client already has a dataset ready to go, that‚Äôs great! But if not, we are happy to connect them with tools and services for image annotation as needed.</p>

<p><em>Example: I chose to go with a dataset from Kaggle, a machine learning hub where users can find and publish datasets and other resources to advance the data science field. Link to the dataset I used: https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels</em></p>
    
      <h2 id="step-3-data-partition-strategy">
        
        
          Step 3: Data partition strategy <a href="#step-3-data-partition-strategy">üîó</a>
        
        
      </h2>

<p>Once we have a dataset, there are several data processing steps to get it into a form readily consumable by ML. Usually, this involves splitting the dataset into training, validation, and test sets.</p>

<p>First, we work with our client to set aside a test set. The test set should be reasonably representative of the data commonly seen in clinical scenarios. It will not be used at all during model training. Instead, we will use it to see how well the algorithm performs on unseen data. It will also be the ‚Äúacceptance criteria‚Äù used for the final deliverable and to verify the validity of incremental changes in future versions of the model.</p>

<p>After setting aside the test set, we split the remaining data into ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://innolitics.com/articles/machine-learning-development-for-medical-devices/">https://innolitics.com/articles/machine-learning-development-for-medical-devices/</a></em></p>]]>
            </description>
            <link>https://innolitics.com/articles/machine-learning-development-for-medical-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992363</guid>
            <pubDate>Mon, 01 Feb 2021 19:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Global]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25991988">thread link</a>) | @tosh
<br/>
February 1, 2021 | https://blog.repl.it/global | <a href="https://web.archive.org/web/*/https://blog.repl.it/global">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>We had the idea for Replit in Jordan, launched as a startup in New York, and incorporated as a company in San Mateo. The US gave us the infrastructure, the capital, and network to launch our business, and for that we're forever grateful. However, to us, the internet is a <a href="https://www.eff.org/cyberspace-independence">new country</a> and we want to make our citizenship official and our commitment real. We're joining our global community of hackers, students, teachers, and entrepreneurs and becoming a global company and service. Starting today:</p>
<ul>
<li>Our first two non-US compute regions are up --  Mumbai, India and London, England -- making us a global service</li>
<li>We're hiring worldwide making us a globally distributed company</li>
</ul>
<h2 id="global-routing">Global routing</h2>
<p>Previously, Replit has been operating out of a single datacenter in
the United States. When you start a repl, or join multiplayer, all
of your traffic had to make it to our one datacenter.</p>
<p>While that's not a significant issue if you live nearby, for our
friends all over the world it means every time you type a letter,
you had to cross an ocean at least twice! That means you could see
latencies as high as 300ms for each keystroke in the terminal! Now, when you create
a repl, it lives in the datacenter closest to you. Instead of
everyone having to cross the ocean multiple times, you can feel even
closer than your own computer! And if you have friends far away, things
will feel better too. Instead of connecting to a datacenter that is
far away, you'll connect to the datacenter closest to you, and
we'll deliver your bits as quickly as possible,
so you don't have to travel the world all on your own.</p>
<p>If you lived in India prior to our new data center, you saw significant delay in actions like running your code:</p>
<p><img src="https://blog.repl.it/images/global/before.gif" alt="before latency"></p>
<p>This is what you'll see today:</p>
<p><img src="https://blog.repl.it/images/global/after.gif" alt="after latency"></p>
<p>With these changes coding with friends and coworkers from all
over the world will feel closer than ever, and we're only just
getting started! We've made it super easy for us to ship to even
more countries, datacenters, and devices around the world. Before you
know it you might even be able to have a Replit data center in your
own home!</p>
<p><a href="https://blog.repl.it/killing-containers-at-scale">Read more</a> about our infrastructure and challenges with running a globally distributed multiplayer service.</p>

<p>Because we're still a highly collaborative small team and we haven't perfected the art of asynchronous we require employees to overlap with PST working hours for four hours a day. Otherwise you can be wherever you want in the world. </p>
<p><a href="https://repl.it/careers">Apply here</a>.</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/global</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991988</guid>
            <pubDate>Mon, 01 Feb 2021 18:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Argo Workflows v3.0]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25991077">thread link</a>) | @dnsmichi
<br/>
February 1, 2021 | https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e | <a href="https://web.archive.org/web/*/https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="3ed4">We‚Äôre incredibly proud of how far <a href="https://github.com/argoproj/argo" rel="noopener"><strong>Argo Workflows</strong></a> has come since its <a rel="noopener" href="https://blog.argoproj.io/introducing-argo-a-container-native-workflow-engine-for-kubernetes-55c0b4b76fac"><strong>inception</strong></a> three years ago!</p><ul><li id="01a4">17th Oct 2017 ‚Äî first commit</li><li id="947c">6th Feb 2018 ‚Äî v2.0 rewritten in Go</li><li id="dcbd">2nd Sep 2019 ‚Äî first 1,000 stars</li><li id="9355">17th Apr 2020 ‚Äî <a href="https://www.cncf.io/blog/2020/04/07/toc-welcomes-argo-into-the-cncf-incubator/" rel="noopener">became a CNCF incubator project</a></li><li id="5b9b">22nd Jan 2021 ‚Äî 373 contributors, 2k commits, 7.3k stars, 1.3k forks, 5.2k Slack members</li></ul><p id="0265">With this all behind us ‚Äî we‚Äôre round to announce <strong>Argo Workflows v3.0.</strong></p><h2 id="aaf7">What is Argo Workflows?</h2><p id="7875"><strong>Argo Workflows</strong> is a cloud-native workflow engine that can run 10,000s of concurrent workflows, each with 1,000s of steps.</p><h2 id="29df">What can I use it for?</h2><ul><li id="5678">Machine Learning</li><li id="46b6">ETL, Data Analytics &amp; Data Science</li><li id="061c">Data processing pipelines</li><li id="b4d2">Batch processing</li><li id="bce1">Serverless</li><li id="084c">CI/CD</li></ul><h2 id="1f24">Who uses Argo?</h2><p id="d00f">Argo is used to ‚Äúdiscover new physics‚Äù at CERN, for 3D rendering at CoreWeave (on a 1,000 node cluster with 6,000 GPUs), and in Intuit‚Äôs Machine Learning and Data Processing platforms. Argo Workflows is actively used in production by well over <a href="https://github.com/argoproj/argo/blob/master/USERS.md" rel="noopener">100 organizations</a>, including <strong>Adobe, Alibaba Cloud, BlackRock, Capital One, Data Dog, Datastax, Google, GitHub, IBM, Intuit, NVIDIA, SAP, New Relic, and RedHat.</strong></p><h2 id="6abc">Why would I use Argo?</h2><p id="bc11">When we asked our users who were using tools like Kubeflow, Apache Airflow, AWS Batch, AWS Lambda, KNative, TektonCD, and <a href="https://blog.kintohub.com/how-do-we-ditch-jenkins-for-argo-1c0b4df5dab0" rel="noopener">Jenkins</a> why they also use Argo, they said<strong> they love that it is cloud-native, simple, fast, scales, and cost-effective.</strong></p><h2 id="aa48">Big new features every release</h2><p id="d3b3">In the last 12 months, every release has had major new features:</p><ul><li id="34ce"><a rel="noopener" href="https://blog.argoproj.io/whats-coming-up-in-argo-workflows-v2-12-3899bae53562">v2.12: reports and metrics, SSO+RBAC</a></li><li id="9317"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-11-a8b6189bf60e">v2.11: webhooks, memorization</a></li><li id="7fdb"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-10-d20beeee5df3">v2.10: Java and Python SDKs, semaphores, and mutexes</a></li><li id="acc8"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-9-47b9c2b5f456">v2.9: single-sign-on, Windows support, workflow template ref</a></li><li id="3ff0"><a rel="noopener" href="https://blog.argoproj.io/whats-new-in-argo-workflow-v2-8-5356ee1d4f7f">v2.8: cluster workflow templates</a></li><li id="ab13"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-7-6ace8c210798">v2.7: submittable workflow templates, Prometheus metrics</a></li><li id="50f0"><a href="https://github.com/argoproj/argo/releases/tag/v2.6.0" rel="noopener">v2.6: Gomodules, filtering labels</a></li><li id="20d1"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-5-released-ce7553bfd84c">v2.5: API server, the workflow archive, cron workflows</a></li></ul><ul><li id="ed9f">Major upgrade (20k new lines of code) to the user interface with many new features and much more robust</li><li id="1469">Brand new APIs for Argo Events</li><li id="04b7">Controller High-Availability</li><li id="54c8">Key-only artifacts make it easier to perform map-reduce operations</li><li id="0dd0">Moving the repository</li><li id="6230">Go modules support</li></ul><h2 id="cca4">Argo Events API and UI</h2><p id="19ec">Argo Workflows v3.0 comes with a new UI that now also supports Argo Events! The UI is also more robust and reliable.</p><ul><li id="0c4a">New API endpoints for Argo Events</li><li id="d65d">New event-flow page</li><li id="379d">Create, edit, and view log event sources and sensors in the UI</li><li id="ff13">Embeddable widgets</li><li id="9cb9">New workflow log viewer</li><li id="5094">Configurable ‚ÄúGet Help‚Äù button</li><li id="d657">More configurable link buttons (e.g. for linking into your logging facility)</li><li id="1e6f">Seamless reconnection on network errors</li><li id="9264">Refactored code to use more robust React functional components</li></ul><p id="f8ca">The<strong> event-flow page</strong> allows users to understand how event sources and sensors are connected together, as well as linking in the workflows created by triggers, and displaying animations whenever a message is seen.</p><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/1*qi3-DdjCLGEa3V86YhCZyQ.png"></p><figcaption>Event-flow</figcaption></figure><p id="3b26">You can <strong>create and update event sources and sensors</strong> directly in the user interface using the same visual language we use for workflows:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png" width="667" height="274" srcset="https://miro.medium.com/max/552/1*CnLN8MIMQoofSlpAaDSGfg.png 276w, https://miro.medium.com/max/1104/1*CnLN8MIMQoofSlpAaDSGfg.png 552w, https://miro.medium.com/max/1280/1*CnLN8MIMQoofSlpAaDSGfg.png 640w, https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png 667w" sizes="667px" data-old-src="https://miro.medium.com/max/60/1*CnLN8MIMQoofSlpAaDSGfg.png?q=20"></p></div></div><figcaption>Event Sources</figcaption></figure><p id="3435">We‚Äôve added some simple <strong>widgets </strong>you can use to embed the status and progress of a workflow or the latest workflow created by a workflow template or cron workflow:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png" width="619" height="721" srcset="https://miro.medium.com/max/552/1*7iql7XVD9v9-1_-UfjO4LA.png 276w, https://miro.medium.com/max/1104/1*7iql7XVD9v9-1_-UfjO4LA.png 552w, https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png 619w" sizes="619px" data-old-src="https://miro.medium.com/max/52/1*7iql7XVD9v9-1_-UfjO4LA.png?q=20"></p></div></div><figcaption>Widgets</figcaption></figure><p id="f0ac">Rather than editing your workflow by hand, you can also <strong>submit from a template</strong>:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png" width="575" height="237" srcset="https://miro.medium.com/max/552/1*3c0kAYITJpSt4A4FtbvRsA.png 276w, https://miro.medium.com/max/1104/1*3c0kAYITJpSt4A4FtbvRsA.png 552w, https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png 575w" sizes="575px" data-old-src="https://miro.medium.com/max/60/1*3c0kAYITJpSt4A4FtbvRsA.png?q=20"></p></div></div><figcaption>Workflow Creator</figcaption></figure><p id="b213">The log viewer has been updated to allow you to view the init and wait containers easier (helping debug artifact issues). It also allows you to <strong>tail the whole workflow</strong>:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1626/1*aDmxHb6qK0YXPFDqN-bnlQ.png" width="813" height="736" srcset="https://miro.medium.com/max/552/1*aDmxHb6qK0YXPFDqN-bnlQ.png 276w, https://miro.medium.com/max/1104/1*aDmxHb6qK0YXPFDqN-bnlQ.png 552w, https://miro.medium.com/max/1280/1*aDmxHb6qK0YXPFDqN-bnlQ.png 640w, https://miro.medium.com/max/1400/1*aDmxHb6qK0YXPFDqN-bnlQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*aDmxHb6qK0YXPFDqN-bnlQ.png?q=20"></p></div></div></div><figcaption>Log Viewer</figcaption></figure><p id="e514">If you want to try it yourself, you can take a look around the <a href="https://workflows.apps.argoproj.io/" rel="noopener"><strong>test environment</strong></a><strong>.</strong></p><p id="ed2e">We have an extensive demo video you can watch online from January‚Äôs community meeting (starts at 41m):</p><figure><div></div></figure><h2 id="a0d4">Controller High-Availability</h2><p id="c675">The v3.0 release introduces a hot-standby workflow controller feature for high availability and quick recovery by leveraging the Kubernetes leader election feature. The default install enables leader election and one has a pod, which is the leader. Whenever a controller pod crashes, Kubernetes will restart it. To reduce startup time, you can now run two pods. The second pod will be on hot-standby and take over immediately if the leader dies.</p><pre><span id="43b2">kubectl scale deployment/workflow-controller --replicas=2 </span></pre><h2 id="5b79">Key-Only Artifacts</h2><p id="f857">Argo Workflows v3.0 introduces a default artifact repository reference and key-only artifacts, two new features that work together.</p><ul><li id="83b6">Users can configure a default artifact repository for their namespace rather than having to define it explicitly for each workflow.</li><li id="98bd">Workflow specifications do not need to provide non-key fields (e.g. bucket, username/password secret key). They can use just the key (hence ‚Äúkey-only‚Äù), and the non-key fields will be inherited from the artifact repository.</li><li id="e292">Users can specify the key to reference artifacts globally without using parameterized inputs and outputs.</li><li id="fc9b">Easier to specify fan-in artifact patterns, simplifying map-reduce style workflows.</li></ul><p id="c415">As a consequence, we no longer need to replicate non-key elements in manifests, reducing the disk-space needed for workflows.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1766/1*jqBXCrmex2GmJYj_ZlTwZQ.png" width="883" height="483" srcset="https://miro.medium.com/max/552/1*jqBXCrmex2GmJYj_ZlTwZQ.png 276w, https://miro.medium.com/max/1104/1*jqBXCrmex2GmJYj_ZlTwZQ.png 552w, https://miro.medium.com/max/1280/1*jqBXCrmex2GmJYj_ZlTwZQ.png 640w, https://miro.medium.com/max/1400/1*jqBXCrmex2GmJYj_ZlTwZQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*jqBXCrmex2GmJYj_ZlTwZQ.png?q=20"></p></div></div></div></figure><h2 id="424c">New Repository Location</h2><p id="ab61">We‚Äôll be renaming the Argo workflow repository to <a href="https://github.com/argoproj/argo-workflows." rel="noopener">https://github.com/argoproj/argo-workflows.</a> The new name makes it clear that this is the repo for Argo Workflows and not the overall Argo Project.</p><p id="d21a">Github automatically forwards when a repository is renamed, so users should not be significantly impacted.</p><h2 id="1ebd">Go Modules + Go Client v1.19</h2><p id="7eba">In 2020, we migrated to Go modules. Unfortunately, migrating to Go modules is a breaking change and we never completed the work, and it was still not possible to <code>go get github.com/argoproj/argo</code> without some hackery. Release v3 will fix this.</p><h2 id="e08b">v2.12 Long-term Support</h2><p id="2529">We plan to provide long-term support for v2.12. There will be bug fixes, but no new features, for 6+ months.</p><p id="a9d3">What we expect to back-port:</p><ul><li id="0ce7">Bug fixes.</li><li id="a583">Changes to complete features new in v1.12 (e.g SSO+RBAC).</li></ul><p id="57d1">We don‚Äôt plan to back-port:</p><ul><li id="b6e9">UI bug fixes that are based on refactoring that is unique to v3.0. But you can run the v3.0 UI with the v2.12 controller.</li><li id="5658">New features.</li></ul><p id="295a">Argo Workflows v3.1 will contain enhancement to make it easier to write fan-out-fan-in workflows using artifacts, and well as conditional artifacts.</p><p id="f19c">Nothing as big as this is the work of one person, so beyond the core team, we must recognize these major contributors:</p><ul><li id="5fcb">Daisuke Taniwaki ‚Äî Preferred Networks</li><li id="0754">Yuan Tang ‚Äî Ant Group</li><li id="79bc">Mark White</li><li id="1c43">Daniel Herman</li><li id="3e99">Sam Elder ‚Äî Keblotix</li><li id="25af">Michael Crenshaw ‚Äî Colaberry/CCRi</li><li id="1d3f">Xianlu Bird ‚Äî Aliyun</li><li id="d18e">Peter Salanik ‚Äî CoreWeave</li><li id="e8b9">J.P. Zivalich ‚Äî Pipekit</li><li id="30d6">Niklas Hansson ‚Äî Sandvik CODE</li><li id="f435">Antoine Dao ‚Äî Pollination</li><li id="8eca">Clemens Lange ‚Äî CERN</li><li id="ba08">Vaibhav Page ‚Äî Blackrock</li><li id="c4e7">Sumit Nagal ‚Äî Intuit</li><li id="2139">David Breitgand ‚Äî IBM</li></ul></div></div></div>]]>
            </description>
            <link>https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991077</guid>
            <pubDate>Mon, 01 Feb 2021 17:47:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cult of Best Practice]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25990929">thread link</a>) | @zdw
<br/>
February 1, 2021 | https://domk.website/blog/2021-01-31-cult-of-best-practise.html | <a href="https://web.archive.org/web/*/https://domk.website/blog/2021-01-31-cult-of-best-practise.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><time datetime="2021-01-31">31 Jan 2021</time>
    /
    <span>~7 min</span>
  </p>
  


<p>Best practices are, despite the name, not universally good.</p>

<p>Many best practices in programming don‚Äôt meet the definition. They spread not based on merit or evidence but thanks to authority bias and social utility. As they spread, they lose nuance. As they lose nuance, they become easier to evangelise. Combined with lack of experience, they can lead to cult-like behaviour.</p>

<p>Think of an engineering team that got obsessed with a best practice, like test-driven development or writing user stories, to the point of detriment. Many developers have fallen into that trap, myself included.</p>

<p>Why can best practices be harmful? Why do we like following them? When and how do they go wrong? To answer these questions, we need to understand where they come from and how they spread in the context of programming.</p>

<h2 id="impostor-best-practices">Impostor Best Practices</h2>

<p>The main reason some programming best practices are harmful is that they are not real best practices.</p>

<p>Look at the official definition: ‚ÄúA best practice is a method or technique that has been generally accepted as superior to any alternatives because it produces results that are superior to those achieved by other means [‚Ä¶]‚Äù. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The key parts of the definition are ‚Äúgenerally accepted‚Äù and ‚Äúsuperior to any alternatives‚Äù.</p>

<p>The problem with many programming best practices is that they <em>pretend</em> to conform to that definition, but they do not.</p>

<p>Some best practices aren‚Äôt generally accepted. They come from different, less reliable sources of authority. It could be a prominent individual or a specific community who present something as widely accepted when it‚Äôs their own experience or opinion.</p>

<p>We might have a proponent of object-oriented programming saying that it is an accepted best practice, but not everyone agrees. If the proponent is respected and followed in the programming community, many people will put a lot of weight on their opinion, but that doesn‚Äôt make it generally accepted. There are different competing paradigms each with their pros and cons.</p>

<p>Some best practices are not superior in outcomes. They claim they are, but objectively there are equivalent alternatives. For example, is functional programming superior to object-oriented? We can‚Äôt say one is better than the other, even though they are both presented as a best practice by some.</p>

<p>The problem with superiority is that most programming best practices aren‚Äôt evidence-based. Programming is too young, fast-changing and complex to have done the research to establish the evidence for something consistently producing better outcomes. We work in the world of opinions, feelings and anecdotal evidence.</p>

<p>Some best practices are also very volatile. Fast-moving languages and frameworks declare something best practice and supersede it a year later. That isn‚Äôt inherently wrong, but it‚Äôs a sign of how fast our understanding of best can evolve, while best practices are expected to be time-tested. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>However, not all best practices in programming are impostors. There are time-tested, generally accepted, and superior practices. For example, the general idea of automated testing now meets that definition.</p>

<p>Nor are all impostor best practices bad. Not being universally accepted can mean they aren‚Äôt universally accepted <em>yet</em>. Not being superior in general might be a scope problem, and the practice is superior in specific situations.</p>

<p>However, these cases need to be interpreted with nuance, which brings us to the next problem.</p>

<h2 id="lost-in-translation">Lost In Translation</h2>

<p>Good best practices are <em>simple and universal</em>. Many programming best practices tackle complex issues that require nuance and context ‚Äî but that nuance and context get lost as the best practice spreads.</p>

<p>Consider this example: someone, through a lot of trial and error, found a good way to tackle a problem. Because of the learning process, they understand the nuances in how and when to apply it.</p>

<p>The solution works for them and they start sharing their lessons as best practice. This gets picked up by people who skipped the learning and went straight to applying it, missing out on some nuance. Those people share it again. A new cohort of people picks it up. They misunderstand it more and share it again.</p>

<p>Soon, all understanding of why the practice works is lost. People are parroting it as a simplified, absolute catchphrase. ‚ÄúAlways write the tests before the implementation‚Äù. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>The complexity can increase over time too. An idea that was originally simple that required a lot of nuanced interpretation is made increasingly complex by people who miss the point.</p>

<p>Take the example of ‚Äúagile‚Äù. Originally a set of 12 principles, it has been turned into monstrous frameworks that oppose those principles by consultancies that sell organisational transformation.</p>

<p>Once all nuance is lost, the conditions are perfect for the idea to spread. It originated from someone with respect, experience, and authority. The simplicity makes it sound easy. People who don‚Äôt understand it sell it as a panacea. As a result, people can learn about it quickly and start evangelising. Despite its merit-based origin, it has become a social phenomenon.</p>



<p>The social aspect of how best practices spread helps us answer the next question ‚Äî why do we like following them?</p>

<p>When we lack the experience and confidence to form our own opinions, we defer to the next best thing: an authority. This is a well-known cognitive bias. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<p>Thanks to the authority bias, best practices have a social utility. They give us something that people are biased to believe that we can lean on. There are many examples of this utility:</p>

<ul>
  <li>A way to hedge our bets. If we are wrong, we can defend ourselves by saying that we just followed best practices. How could someone blame us?</li>
  <li>A way to mimic the best. If someone we see as an authority does something, it‚Äôs natural for us to try to learn and copy what they do.</li>
  <li>A virtue-signalling mechanism. If something is ‚Äúthe best‚Äù, we naturally want to signal to everyone that we also do what is best.</li>
  <li>A way to fit in. If everyone around us considers something ‚Äúthe best‚Äù, we would be hard-pressed to go against our peers.</li>
</ul>

<h2 id="the-cult">The Cult</h2>

<p>Because of the social nature of best practices, it‚Äôs easy for herd mentality to kick in.</p>

<p>Imagine a team of inexperienced developers with no one seasoned to lean on. They can‚Äôt make all decisions in an informed way ‚Äî following best practices is the next best option.</p>

<p>They struggle with something, and they search for a solution. They come across a simple-looking practice that addresses their problem, supported by someone prominent. Is your code buggy and unreliable? Write more tests. Is your code hard to test? Adopt test-driven development! <sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>Once a solution like that is found, everyone is motivated by the authority and social utility of it. It gets adopted ad absurdum. All nuance is lost. Soon you have a team that insists that every ticket is written as a user story, or that every class has to have tests because it‚Äôs <em>best practice</em>.</p>

<h2 id="way-out">Way Out</h2>

<p>It might seem obvious that adopting something obsessively is a bad idea, but many teams out there operate exactly like that.</p>

<p>The way out of the cult starts with understanding what the commonly presented best practices are ‚Äî a social phenomenon.</p>

<p>Once we realise that, the first step is understanding where they come from and what problem they solve ‚Äî understand their origins and the subtleties of applying them successfully. <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>The next step is to make our own mistakes and learn from them. Break the rules and understand what happens when we don‚Äôt follow a particular practice. Follow it to its logical conclusion and see what happens then. <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup></p>

<p>The trial and error learning involved gives us knowledge much deeper than what we would gain by following the rules.</p>

<p>Having made our own mistakes, the third and final step is to form our own opinions and speak up.</p>

<p>If we‚Äôve understood where a best practice comes from, and we‚Äôve tried what happens when we don‚Äôt follow it, we should have the confidence to make and defend our own opinions about it. We can help the rest of our team see the full picture and break the cult.</p>

<p>Going against the flow like that can be hard. Convincing the rest of a team that something they believe in isn‚Äôt what it promised to be, requires skill and patience. Telling them won‚Äôt be enough. You need to take them on the same learning journey you went on. That‚Äôs how you make progress.</p>

<p>To short-circuit that learning process and prevent best practice cults from forming in the first place, you need to have enough senior engineers on your teams. Each team needs to have someone who is experienced and confident enough to become a trusted authority for their colleagues. Someone who can make informed decisions and bring the necessary nuance.</p>

<p>We need to encourage open-mindedness and independent thinking. We need to scrutinise best practices and understand them in depth. That‚Äôs how we stop the cult.</p>

<hr>



</article></div>]]>
            </description>
            <link>https://domk.website/blog/2021-01-31-cult-of-best-practise.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990929</guid>
            <pubDate>Mon, 01 Feb 2021 17:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pip has dropped support for Python 2]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25990891">thread link</a>) | @feross
<br/>
February 1, 2021 | https://pip.pypa.io/en/stable/news/#id4 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/stable/news/#id4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><p><strong>PROCESS</strong> Version numbers are now simply <code><span>X.Y</span></code> where the leading <code><span>1</span></code>
has been dropped.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Dropped support for Python 3.1.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Removed the bundle support which was deprecated in
1.4. (#1806)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> File lists generated by <cite>pip show -f</cite> are now
rooted at the location reported by show, rather than one (unstated)
directory lower. (#1933)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> The ability to install files over the FTP protocol
was accidentally lost in pip 1.5 and it has now been decided to not restore
that ability.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> PEP 440 is now fully implemented, this means that
in some cases versions will sort differently or version specifiers will be
interpreted differently than previously. The common cases should all function
similarly to before.</p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--download-cache</span></code> and
<code><span>pip</span> <span>wheel</span> <span>--download-cache</span></code> command line flags have been deprecated and
the functionality removed. Since pip now automatically configures and uses
it‚Äôs internal HTTP cache which supplants the <code><span>--download-cache</span></code> the
existing options have been made non functional but will still be accepted
until their removal in pip v8.0. For more information please see
<a href="https://pip.pypa.io/en/stable/reference/pip_install.html#caching">https://pip.pypa.io/en/stable/reference/pip_install.html#caching</a></p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--build</span></code> and <code><span>pip</span> <span>install</span> <span>--no-clean</span></code> are now
<em>NOT</em> deprecated.  This reverses the deprecation that occurred in v1.5.3.
(#906)</p></li>
<li><p><strong>DEPRECATION</strong> Implicitly accessing URLs which point to an origin which is
not a secure origin, instead requiring an opt-in for each host using the new
<code><span>--trusted-host</span></code> flag (<code><span>pip</span> <span>install</span> <span>--trusted-host</span> <span>example.com</span> <span>foo</span></code>).</p></li>
<li><p>Allow the new <code><span>--trusted-host</span></code> flag to also disable TLS verification for
a particular hostname.</p></li>
<li><p>Added a <code><span>--user</span></code> flag to <code><span>pip</span> <span>freeze</span></code> and <code><span>pip</span> <span>list</span></code> to check the
user site directory only.</p></li>
<li><p>Silence byte compile errors when installation succeed. (#1873)</p></li>
<li><p>Added a virtualenv-specific configuration file. (#1364)</p></li>
<li><p>Added site-wide configuration files. (1978)</p></li>
<li><p>Added an automatic check to warn if there is an updated version of pip
available. (#2049)</p></li>
<li><p><cite>wsgiref</cite> and <cite>argparse</cite> (for &gt;py26) are now excluded from <cite>pip list</cite> and
<cite>pip freeze</cite>. (#1606, #1369)</p></li>
<li><p>Add <code><span>--client-cert</span></code> option for SSL client certificates. (#1424)</p></li>
<li><p><cite>pip show --files</cite> was broken for wheel installs. (#1635, #1484)</p></li>
<li><p>install_lib should take precedence when reading distutils config.
(#1642, #1641)</p></li>
<li><p>Send <cite>Accept-Encoding: identity</cite> when downloading files in an attempt to
convince some servers who double compress the downloaded file to stop doing
so. (#1688)</p></li>
<li><p>Stop breaking when given pip commands in uppercase (#1559, #1725)</p></li>
<li><p>pip no longer adds duplicate logging consumers, so it won‚Äôt create duplicate
output when being called multiple times. (#1618, #1723)</p></li>
<li><p><cite>pip wheel</cite> now returns an error code if any wheels fail to build. (#1769)</p></li>
<li><p><cite>pip wheel</cite> wasn‚Äôt building wheels for dependencies of editable requirements.
(#1775)</p></li>
<li><p>Allow the use of <code><span>--no-use-wheel</span></code> within a requirements file. (#1859)</p></li>
<li><p>Attempt to locate system TLS certificates to use instead of the included
CA Bundle if possible. (#1680, #1866)</p></li>
<li><p>Allow use of Zip64 extension in Wheels and other zip files. (#1319, #1868)</p></li>
<li><p>Properly handle an index or --find-links target which has a &lt;base&gt; without a
href attribute. (#1101, #1869)</p></li>
<li><p>Properly handle extras when a project is installed via Wheel. (#1885, #1896)</p></li>
<li><p>Added support to respect proxies in <code><span>pip</span> <span>search</span></code>.
(#1180, #932, #1104, #1902)</p></li>
<li><p><cite>pip install --download</cite> works with vcs links. (#798, #1060, #1926)</p></li>
<li><p>Disabled warning about insecure index host when using localhost. Based off of
Guy Rozendorn‚Äôs work in #1718. (#1456, #1967)</p></li>
<li><p>Allow the use of OS standard user configuration files instead of ones simply
based around <code><span>$HOME</span></code>. (#2021)</p></li>
<li><p>When installing directly from wheel paths or urls, previous versions were not
uninstalled. (#1825, #804, #1838)</p></li>
<li><p>Detect the location of the <code><span>.egg-info</span></code> directory by looking for any file
located inside of it instead of relying on the record file listing a
directory. (#2075, #2076)</p></li>
<li><p>Use a randomized and secure default build directory when possible.
(#1964, #1935, #676, #2122, CVE-2014-8991)</p></li>
<li><p>Support environment markers in requirements.txt files. (#1433, #2134)</p></li>
<li><p>Automatically retry failed HTTP requests by default. (#1444, #2147)</p></li>
<li><p>Handle HTML Encoding better using a method that is more similar to how
browsers handle it. (#1100, #1874)</p></li>
<li><p>Reduce the verbosity of the pip command by default. (#2175, #2177, #2178)</p></li>
<li><p>Fixed <a href="https://github.com/pypa/pip/issues/2031">#2031</a> - Respect sys.executable on OSX when installing from
Wheels.</p></li>
<li><p>Display the entire URL of the file that is being downloaded when downloading
from a non PyPI repository. (#2183)</p></li>
<li><p>Support setuptools style environment markers in a source distribution. (#2153)</p></li>
</div></div>]]>
            </description>
            <link>https://pip.pypa.io/en/stable/news/#id4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990891</guid>
            <pubDate>Mon, 01 Feb 2021 17:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25990469">thread link</a>) | @Tomte
<br/>
February 1, 2021 | https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="A Price Too High: Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment" data-area="article">
<header>
<div>

<div>
<h2>
<span>
A Price Too High
</span>
<span><span>Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment</span>
</span>
</h2>


<p>
Berlin is insisting on the construction of the Nord Stream 2 gas pipeline between Russia and Germany. By doing so, the country is isolating itself in Europe and alienating the United States. The political costs will be too great if the project is completed. It should now be scrapped.
</p>
<p><time datetime="2021-02-01 17:25:39">01.02.2021, 17.25 Uhr</time>
</p>
</div>
</div>
</header>
<div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="28b58880-da32-4f19-a03a-3ac10d435663" data-settings="{&quot;id&quot;:&quot;9fdd3db3-8707-46ea-8d4a-4197034af156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;28b58880-da32-4f19-a03a-3ac10d435663&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg" srcset="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w520_r1.77_fpx56_fpy56.jpg 520w, https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto:‚ÄÇAlexander Demianchuk&nbsp;/ action press
</span>
</figcaption>
</figure>
</div><div>
<p>How much can a natural gas pipeline from Russia be worth to the German government? Is it worth sacrificing Germany‚Äôs foreign policy prestige? Is it worth isolating the country within the European Union and straining relations with Joe Biden, the new president of the United States? How can it be reconciled with Germany‚Äôs climate targets? And why should the German government back a pipeline that benefits the Russian regime, whose policies it otherwise opposes?</p>


<div>
<p>For years, the German government has stuck to this economically dubious and politically misguided project, the brainchild of Russian President Vladimir Putin and his pal, former Chancellor Gerhard Schr√∂der. The greater the resistance within Europe to the project, the more stubbornly the German government has clung to the endeavor. It is increasingly difficult to find any other explanation for this than pride.</p><p>And this, despite the larger, more fundamental issue question facing Berlin: Can the German government achieve its self-proclaimed target of taking on a more significant role in global politics? Its behavior on Nord Stream 2 thus far suggests the contrary. The pipeline, indeed, has become Germany‚Äôs most embarrassing foreign policy problem.</p>
</div>

<p>From the very beginning, Berlin‚Äôs claim that the Nord Stream 2 was purely economic and not at all political in nature has been hypocritical. Pipelines are always political. And this is especially true of this pipeline, because Nord Stream 2 would transport natural gas directly from Russia to Germany through the Baltic Sea. It would allow the state-owned company Gazprom to bypass pipelines in Belarus and Ukraine, making the countries even more dependent on Russia because they will lose transit fees they otherwise would have received. The pipeline would also provide an additional source of foreign currency for the Russian government. This runs counter to the spirit of Europe's sanctions against a regime that for years has shown itself to be an adversary of the European Union and has had opposition figure Alexei Navalny poisoned and imprisoned.</p>

<p><strong>The most effective argument used by pipeline proponents</strong> in recent years has been Donald Trump and U.S. sanctions against the project. "We're not going to let them dictate where we buy our gas!" they would say. But Donald Trump has now been voted out of office, and the Americans are by no means the only ones who oppose the pipeline. Indeed, perhaps the strongest argument against Nord Stream 2 doesn‚Äôt even have anything to do with the U.S. This pipeline is an anti-European project. And the German government is growing increasingly isolated in the EU on the issue. Almost every Eastern European country is opposed to the project, especially Poland and the Baltic states. The project provides affirmation for critics who view Germany as a two-faced, hegemonic country that speaks of European values but pushes through its own interests in a pinch. Last month, the European Parliament once again voted against the pipeline. There has also been criticism from the European Commission, which wants to reduce dependence on individual supplier countries. Even Paris is voicing skepticism.</p>


<section data-area="contentbox">

</section>
<div>
<p>The pipeline doesn‚Äôt even provide any clear economic benefits. It doubles the supply capacity from Russia, but natural gas consumption is stagnating and would have to fall significantly by the middle of the century for Germany to meet its climate targets. The existing pipelines are by far sufficient. Russia is now talking about pumping climate-friendly hydrogen through the pipeline in the future. But those prospects are uncertain and it changes nothing about the political dilemma.</p><p><strong>Of course, the private companies involved</strong> could now try to finish building the last few kilometers of the pipeline, despite the U.S. sanctions ‚Äì at their own risk. They have invested billions, after all. But the lengths to which some politicians in Germany - particularly within the center-left Social Democratic Party once run by Schr√∂der - are willing to go to support the project has been appalling. Manuela Schwesig, the SPD governor of Mecklenburg-Western Pomerania, where Nord Stream 2‚Äôs terminus is located, has even set up a front foundation for environmental protection to complete the environmentally damaging pipeline despite U.S. sanctions. Such shadiness is harmful to Germany's international standing.</p>
</div>
<section>

</section>
<div>
<p>The German government has backed itself into a corner with Nord Stream 2 that can only be explained by economic selfishness or political naivety, but it is ultimately a self-inflicted wound. The time, though, has now come for a clear choice to be made ‚Äì one that doesn‚Äôt chain the country to the pipeline. Nord Stream 2 must be stopped. It would be better to write it off now than to bear the political and economic costs of its completion.</p><p>Angela Merkel should withdraw support for the project, even if that could mean that companies end up having to be compensated. Doing so will be painful politically, but the German government should view the Nord Stream 2 debacle as quittance for the mistakes it has made ‚Äì and as a lesson for the future.</p>
<p><span><svg aria-labelledby="title-dbd86b86-97e8-494a-8e1b-9dfb1182e1bc" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-dbd86b86-97e8-494a-8e1b-9dfb1182e1bc">Icon: Der Spiegel</title><g id="l-s-flag-dbd86b86-97e8-494a-8e1b-9dfb1182e1bc"><path id="vector-dbd86b86-97e8-494a-8e1b-9dfb1182e1bc" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>
</div>
</section>

</div>

</article></div>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990469</guid>
            <pubDate>Mon, 01 Feb 2021 17:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reinforcement Learning at Facebook]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25989578">thread link</a>) | @agbell
<br/>
February 1, 2021 | https://corecursive.com/061-reinforcement-learning/ | <a href="https://web.archive.org/web/*/https://corecursive.com/061-reinforcement-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>Note: This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the
audio, which includes emphasis that‚Äôs not on the page</i></p><div>
<h2 id="intro"><strong>Intro</strong></h2>
<p><strong>Adam:</strong>
Hey, so before We get into it, why don‚Äôt you state your name and what you do?</p>
<p><strong>Jason:</strong>
My name is Jason Gauci. And yeah, I bring machine learning to billions of people.</p>
<p><strong>Adam:</strong>
Hello and welcome to CoRecursive, the stories behind the code, I‚Äôm Adam Gordon Bell. Jason has worked on YouTube recommendations. He was an early contributor to TensorFlow, the open source machine learning platform. His thesis work was cited by DeepMind. They were the people who beat all human players at Go, and that‚Äôs StarCraft, I think. And who knows what else?</p>
<p>If you ever wanted to learn about machine learning, you could do worse than have Jason teach you. But what I find so fascinating with Jason is he recognized this problem that was being solved the wrong way and set out to find a solution to it.</p>
<p>The problem was making recommendations, like on Amazon, people who bought this book might like that book. He didn‚Äôt exactly know how to solve the problem, but he knew it could be done better. So that‚Äôs the show today, Jason‚Äôs going to share his story, but you will eventually change the way Facebook works. And we‚Äôll learn about reinforcement learning and neural nets, and just about the stress of pursuing research at a large company. It all started in 2006 when Jason was in grad school.</p>
<h2 id="phd-program"><strong>PHD Program</strong></h2>
<p><strong>Jason:</strong>
Yeah, so I went to college, picked computer science, and I remember my parents found out a little strange. They said, ‚ÄúOh, you could be a doctor or a lawyer or something, you have the brains for it.‚Äù And then at one point my dad thought it was kind of like going to school to be a TV repairman. And so he wasn‚Äôt really sure, he‚Äôs like, ‚ÄúAre you sure you really want to do this? Now I could just buy another TV or another computer if it breaks.‚Äù And to this day, I have to explain to people, I really don‚Äôt know how to fix computer. If this laptop broke right now, I‚Äôd just have to do the same thing my parents do and just go get another one, I have no idea. But I had an option to do a Master‚Äôs, PhD hybrid or basically do it all in one shot.</p>
<h2 id="capture-the-flag"><strong>Capture The Flag</strong></h2>

<p>And after two years, if I wanted to call it quits, then I would get the Master‚Äôs degree. Yeah, at the time I thought I will just do the Master‚Äôs, I didn‚Äôt really plan on getting a PhD. But actually the very last class that I took in my Master‚Äôs was a class called neuro evolution, which was all about trying to solve problems through neural networks and through evolutionary computation. So America Online had this capture the flag game for free. And I remember I downloaded it on a 56K modem, it took forever. And it was basically like a turn-based capture the flag where you played as one person, and there was a friendly AI for the other three players, and then there was four player enemy AI, and you‚Äôre trying to capture the flag. And if the enemy touched you, you‚Äôre in jail, but the friendly AI could bail you out of jail.</p>
<p><strong>Adam:</strong>
I think I played this. Do you get to see more and more of the ground as you travel?</p>
<p><strong>Jason:</strong>
Yeah, that‚Äôs right. Yeah. Yeah. Do you remember the name of it?</p>
<p><strong>Adam:</strong>
So the game is called Capture the Flag. If you‚Äôve not played it, you view a large field with trees in it from overhead, and you can only see where your players have been, there‚Äôs a fog of war like in StarCraft. Except it‚Äôs turn-based, you move a certain number of moves and then your players freeze there, and the computer gets to take its turn and move its players.</p>
<h2 id="what-is-a-neural-net"><strong>What Is a Neural Net?</strong></h2>
<p><strong>Jason:</strong>
But for my neuro evolution course, my final project, I recreated this game, capture the flag. And then I built an AI for it using neuro evolution. And so just to unpack that, neural networks are effectively like function approximators that are inspired by the way the brain works. And so if you imagine graphing a function on your calculator, I‚Äôm sure everyone‚Äôs done this on their TI 85. You can punch in Y equals X squared and it‚Äôll draw a little parabola on your TI 85 or whatever the calculator is nowadays. And so what a neural network will do is it will look at a lot of data and it can represent almost any function.</p>
<p><strong>Adam:</strong>
So if it‚Äôs your original graph thing, it‚Äôs like telling it X is two, Y is three. You‚Äôre feeding it all these pairs.</p>
<p><strong>Jason:</strong>
Exactly. Yep.</p>
<p><strong>Adam:</strong>
Memorizes them.</p>
<p><strong>Jason:</strong>
Yep. But because there‚Äôs contradictions and there‚Äôs noise in the data and all of that, you won‚Äôt tell it exactly, force it to be Y is three when X is three. But it‚Äôs a hint. You say, ‚ÄúHey, when X is three, Y‚Äôs probably three.‚Äù So if you‚Äôre not there, get a little bit closer to there. And you do this over and over again for so many different Xs that you end up with some shape that won‚Äôt pass through every point, it‚Äôs usually impossible, but it will get close to a lot of the points.</p>
<h2 id="where-it-fails">Where It Fails</h2>
<p><strong>Adam:</strong>
This is basically back propagation. It‚Äôs a form of supervised learning. You‚Äôre training the neural net by supervising it and telling it when it gets the wrong answer, what it should have gotten instead. And to do this, you need to know what the right answer is so that you can train it.</p>
<p><strong>Jason:</strong>
And so that works great to when you have a person going and telling you the perfect answer or the right answer. But for puzzles and games, for example, you don‚Äôt have that. So look at Go, to this day, people haven‚Äôt found the perfect Go game, a Go game for people who are playing perfectly. And so you don‚Äôt have that. And so you have to do something different, you have to learn from experience. So you just say, ‚ÄúLook, this Go game, that‚Äôs a really good move. That‚Äôs better than any move we‚Äôve ever seen at this point in the game.‚Äù It doesn‚Äôt mean it‚Äôs the best, it doesn‚Äôt mean that your goal should be to always make that move, but it‚Äôs really good. A simple way to do that is have a neural network and have it play a lot of Go, and then make a subtle change to it, and have it play a lot of Go again. And then say, ‚ÄúOkay, did that change make this player win more games?‚Äù</p>

<p>If it did, then you keep the change. And if it didn‚Äôt, then you throw it away. And so if you do this enough times, you will end up in what we call a local optimum. In other words, you‚Äôre making these small changes, you‚Äôre picking all the changes that make their Go player better, and eventually you just can‚Äôt find a small change that makes the player better. And so you could think of evolutionary computation at a high level as doing something like that, but it‚Äôs doing it a really large scale. So maybe you have a thousand small changes and 500 of them make the player better. And you can adapt all 500 of those different players and the existing players, you can take all 501 of those players and make a player that‚Äôs step-wise, that‚Äôs better in a big way. And you would just keep doing that.</p>
<p><strong>Adam:</strong>
So this is what Jason learned in his neuro evolution class. He would create all these generations of players, which had random changes, and like evolution, have them play capture the flags against each other, slowly breeding better and better players. Was there a moment where you tested out your algorithm?</p>
<h2 id="jason-watches-his-creation"><strong>Jason Watches His Creation</strong></h2>
<p><strong>Adam:</strong>
Did you try to play it and capture the flag?</p>
<p><strong>Jason:</strong>
Yeah, the real aha moment was, having this God‚Äôs eye view without the fog of war, because I was just an observer, and watching the AI. And specifically watching this almost like Wolfpack behavior, where three players would surround a player and trap them. Just seeing that thing that you‚Äôve seen in nature just emerge organically, that to me was amazing. That was unbelievable. When I saw all the players converge and capture and do this methodical thing and then take the flag. And even, I think at one point two of them had been captured, and so the other two just decided to go for the flag and just forget about any strategy and just go for broke.</p>
<p><strong>Adam:</strong>
Did you watch it and anthropomorphize? Did you cheer for one team?</p>
<p><strong>Jason:</strong>
Yeah. Yeah. Yeah, I did. Naturally, you don‚Äôt want to cheer for the underdog. So yeah, you would see this scenario play out where they would chase after one person, even though there was four of them and only two of the other team, they would chase after one and the other one would get the flag.</p>
<p><strong>Adam:</strong>
I didn‚Äôt follow the strategy. One runs, and then‚Ä¶</p>
<p><strong>Jason:</strong>
Yeah. So one would run and the other four would all chase after that one. And then the second one would go and get the flag and win.</p>
<p><strong>Adam:</strong>
It‚Äôs like a decoy.</p>
<p><strong>Jason:</strong>
Yeah, but it would only happen when the AI was this advantaged. So the way it worked was there‚Äôs four players, so there‚Äôs a bunch of sensory information that was just repeated four times to make the input of the network. And I guess even though it‚Äôs playing against itself, it learned that when two of those inputs are completely shut off, which is what happened when they were captured, to then execute this hail Mary strategy. And yeah, it was just super fun to watch that play out. And I would remember just sitting in the lab cheering for this one person and they would try to come back. In your head, it was hard to know, because it was a big grid, can they get back quick enough to catch this person? So it‚Äôd be pretty suspenseful.</p>

<p>And just seeing all of that, just all encoded in this network, neural, excitation back prop and all these things for understanding what a neural network is doing, all this stuff hadn‚Äôt been invented yet. So it was just a black box and it was just magic. You would run it on the university cluster, who knows what it would do, you would get it back a few days later and you would just see all this amazing emergent behavior. That to me just really lit the spark. And so I had already accepted a job with the intention of just getting a Master‚Äôs and leaving because I just didn‚Äôt see anything that inspired me. But right there at the 11th hour, I took this course. And I said, ‚ÄúThis is amazing.‚Äù The fact that it ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/061-reinforcement-learning/">https://corecursive.com/061-reinforcement-learning/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/061-reinforcement-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989578</guid>
            <pubDate>Mon, 01 Feb 2021 15:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games can fix remote team building]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25989336">thread link</a>) | @masonhipp
<br/>
February 1, 2021 | https://slideswith.com/blog/games-for-remote-team-building | <a href="https://web.archive.org/web/*/https://slideswith.com/blog/games-for-remote-team-building">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>The problem: remote work makes it dramatically harder to socialize with your teammates.</strong></p>
<p>There's no going to the bar, you can't read body language, and spontaneous conversation evaporates. The fundamentals of team building are the same ‚Äî communication, shared values, camaraderie, and a belief in the company mission  ‚Äî but the avenues for establishing those foundations are severely limited when remote.</p>
<p><mark>Online games can solve many of challenges of inherit to remote team building.</mark></p>
<p>Games do several things that make them ideal for building strong connections and creating closeness between peers. They can:</p>
<ul>
<li>lower the bar to social interaction</li>
<li>create unique shared experiences</li>
<li>provide a safe environment for deeper conversation</li>
<li>provide beneficial structure to group interactions</li>
<li>make the most of limited-bandwidth video calls</li>
<li>allow teamwork to be practiced with lower stakes</li>
</ul>
<p>It's also much easier to get buy-in for a trivia night or a game that's fun and amusing than it is to get people excited about yet another zoom happy hour. Let's take a look at why game dynamics are so useful for online connection.</p>
<h2 id="games-create-inclusive-conversations-that-work-online">Games create inclusive conversations that work online</h2>
<p>An important aspect of building a strong team is breaking down the walls between each of the various team members and fostering connections between them. This can be difficult to do naturally in the real world and it is even more challenging virtually.</p>
<p>Most events don't run with an ideal structure for team building, and conversations end up too focused on one speaker or a free-for-all dominated by the loudest voices.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/f9ffbdad43c032944434345296afb2464462dc95/c16e4/images/blog/natural-group-interaction-opt.svg"></p>
<p>With the right game you can create a conversational structure that is much more inclusive and ideal for team boding. Additionally, game conversations are frequently turn-based and lend themselves naturally to online conversation with larger groups.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/8a4599e657de5c00626214a2e1199304450465b2/fed64/images/blog/ideal-group-conversation-opt.svg"></p>
<h2 id="games-teach-teamwork-in-fast-low-risk-environment">Games teach teamwork in fast, low-risk environment</h2>
<p>A high-functioning remote team will be able to work cohesively toward a single goal. The members will understand their strengths, understand how to communicate with one another, and be able to work as an effective and coordinated whole. Learning to do this can take a lot of time.</p>
<p><strong>Games offer a fast iteration cycle with lower consequences of failure, providing an ideal environment for learning to work as a team.</strong></p>
<p>The social cooperation required in games is often very similar to the real world. The communication and interpersonal challenges of a job are frequently replicated in online games ‚Äî but without the high stakes and risk of real world performance and deadlines.</p>
<p>It's also possible to run through many more teamwork scenarios in a game than it is in a real-world work environment. Being able to play multiple games or challenges in a short period of time can also provide more opportunity to learn how to work together than the equivalent period of time working together on an actual project with real-world consequences.</p>
<h2 id="games-offer-a-safe-space-to-talk-about-real-things">Games offer a safe space to talk about real things</h2>
<p>Creating real friendships between team members requires a degree of vulnerability that can be difficult to surface in a day-to-day conversation, and is particularly challenging over video calls.</p>
<p>Friendships between team members generally start with small talk and slowly grow in trust and closeness over time. When it happens naturally, this process can take a long time and requires a lot of interaction (the ratio of real conversation to small talk is very low).</p>
<p>According to psychologist Arthur Aron, who you might know from the popular NY Times article <a href="https://www.nytimes.com/2015/01/09/style/no-37-big-wedding-or-small.html" rel="nofollow noopener noreferrer" target="_blank">36 Questions to Fall In Love</a>, the key to forming close bonds is a gradual increase in mutual vulnerability (real conversations):</p>
<blockquote>
<p>‚ÄúOne key pattern associated with the development of a close relationship among peers is sustained, escalating, reciprocal, personal self-disclosure.‚Äù</p>
<p>‚Äî Aurthor Aron, et. al. <a href="https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003" rel="nofollow noopener noreferrer" target="_blank">The Experimental Generation of Interpersonal Closeness</a></p>
</blockquote>
<p>From a corporate team building perspective the point is this: creating bonds inside of your team will eventually require team members to show mutual vulnerability and have real conversations.</p>
<p>At a company office there is an enormous volume of interactions and all of this happens organically, but we don't have that luxury when working virtually. To be most effective at team building online requires a very intentional approach that prioritizes real conversation and self-disclosure.</p>
<p>Games can add exactly this structure to conversations (as mentioned above) and the games themselves can be specifically designed to foster self-disclosure and real conversation in an approachable and fun environment.</p>
<h2 id="games-help-overcome-the-lower-fidelity-of-video-calls">Games help overcome the lower fidelity of video calls</h2>
<p>Interpersonal communication typically uses an incredible amount of information bandwidth: we instinctively monitor body movements, miniscule sound inflections, facial micro-expressions, <a href="https://en.wikipedia.org/wiki/Proxemics" rel="nofollow noopener noreferrer" target="_blank">proxemics</a>, and much more in instantaneous real time.</p>
<p>Trying to have a conversation over video chat, on the other hand, leads to a near complete breakdown of nonverbal cues and a substantial degradation of verbal communication. Experts have roundly agreed that <a href="https://www.nationalgeographic.com/science/2020/04/coronavirus-zoom-fatigue-is-taxing-the-brain-here-is-why-that-happens/" rel="nofollow noopener noreferrer" target="_blank">Zoom fatigue is both real and costly</a>, and many of them agree that the root cause is related to latency, bandwidth, and the breakdown of natural information transfer between parties (e.g. eye contact).</p>
<blockquote>
<p>‚ÄúFor somebody who‚Äôs really dependent on non-verbal cues, it can be a big drain not to have them,‚Äù</p>
<p>‚Äî Andrew Franklin, assistant Professor of Cyberpsychology at Norfolk State University</p>
</blockquote>
<p>Given how much less bandwidth is available during online communication, many teams instinctively gravitate toward a "transactional only" approach to meetings. This can provide some benefits ‚Äî calls are shorter, reducing overall fatigue, and there is a tighter schedule of defined work ‚Äî but this approach entirely eliminates relationship building. Some teams can function this way (if they've known each other for a while), but for many this elimination of team interaction is a major problem.</p>
<p>Games can help overcome the bandwidth and latency issues by creating a clear structure for communication. Structured, rule-based conversations remove the need for each participant to dynamically read the room to know when to talk and what to say. <mark>The rule-based structure of games replaces the need to follow the meta-structure of a group conversation, allowing the participants focus on the <em>content</em> of the </mark>communication and not who's turn it is to talk.</p>
<p>Structured communication can also reduce conversational error rates (e.g. people talking over each other) and overall make the most of a reduced-bandwidth environment.</p>
<h2 id="games-lower-social-barriers-and-create-buy-in">Games lower social barriers and create buy-in</h2>
<p>The easiest way to silence a video call is to ask a deep or open-ended question ‚Äî people will immediately shut down, trying avoid a situation where they might get burned in front of their peers.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/617201462cf33e37820b89fe119005f69bd1e668/e35ff/images/blog/share-personal-information-optimized.svg"></p>
<p><strong>Sharing personal information is inherently risky, but games provide rules that make it safer. Few people will volunteer personal information to a group, but during a game almost everyone will participate freely when it comes to their turn.</strong></p>
<p>Games provide a safe space for interaction that can make it easier and less risky to be yourself, and in fact even rewards everyone for participating. How many people would do an impression of a farm animal in front of a group? How about during a game of charades?</p>
<p>The other interesting benefit of games is that they are more fun by default. Getting your team to buy into a zoom happy hour or team building exercise is tough ‚Äî but getting them excited about a game of trivia or escape room is much easier.</p>
<h2 id="games-encourage-active-attention">Games encourage active attention</h2>
<p>One very powerful aspect of an online game is that it generally requires all participants to pay attention or risk losing or being called out. <mark>The active attention of a game environment is in direct contrast with many zoom meetings where half of the audience could be in a different tab while you're talking</mark>.</p>
<p>As you might imagine from real-world conversations, paying active attention is a prerequisite for building real relationships and bonds, and games are an excellent tool for creating an environment that's ripe for team building.</p>
<p>A word of caution: active engagement can be very tiring, particularly on video calls, and an overuse of games to force paying attention can easily result in a exhausted audience. The key to avoiding this is proper spacing, breaks, and the right frequency of use.</p>

<p>Think back to a conversation you had with a group of friends or close coworkers. How often did somebody say "do you remember when we did X" .. or ..  "what was that movie we watched during..?"</p>
<p>This kind of information sharing is called <strong>Transactive Memory</strong> and it is a key component to forming close relationships and creating a team that functions well together. <mark>Each person in a highly collaborative team will help <em>maintain the shared group memory and understanding</em> such that the group is maximizing each member's strengths, compensating for weaknesses, and the entire team can work together optimally toward a shared goal</mark>.</p>
<p>Games help to create these shared memories by putting group members into a new experience and then asking everybody to participate, recall information, and work together. These actions all combine into an event that team members can remember together and use to learn and understand each other more deeply.</p>
<blockquote>
<p>The existence of effective transactive memory systems in teams has been found to enhance task performance. Methods of developing transactive memory are therefore an important focus of research. This study aimed to explore one such method, the use of a generic team-skills training program, to develop transactive memory and subsequent task performance [...] <strong>Results confirmed that</strong> <strong>those teams that had been trained to develop a range of team skills such as problem-solving, interpersonal relationships, goal setting, and role allocation evidenced significantly higher team skill, transactive memory, and performance than those that were not trained in ‚Ä¶</strong></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://slideswith.com/blog/games-for-remote-team-building">https://slideswith.com/blog/games-for-remote-team-building</a></em></p>]]>
            </description>
            <link>https://slideswith.com/blog/games-for-remote-team-building</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989336</guid>
            <pubDate>Mon, 01 Feb 2021 15:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Robinhood Misled the Poor and Rewarded the Rich]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25989199">thread link</a>) | @iamspoilt
<br/>
February 1, 2021 | https://themeasureofaplan.com/robinhood/ | <a href="https://web.archive.org/web/*/https://themeasureofaplan.com/robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<!-- site-header -->
		<!-- /site-header --><article>
	
	<!-- post-title -->
	 <!-- /post-title -->

	<p>January 31st, 2021 | Posted in

		<a href="https://themeasureofaplan.com/category/uncategorized/">Uncategorized</a>
		</p>

	<img width="700" height="394" src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg" alt="" loading="lazy" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%20394'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg">	
	
    <!-- if URL contains "?v=clean" do not show the mailchimp email sign-up box-->
	        
        	
	
<p>[Feb-1 update: a new section ‚ÄúClearing Houses &amp; the Plumbing Behind Financial Markets‚Äù has been added]</p>
<p>[Feb-2: updated with Robinhood‚Äôs Q4 2020 revenues from ‚Äúpayment for order flow‚Äù]</p>
<p>&nbsp;<br>
This is a story about Robinhood, an online broker that promised to ‚Äúdemocratize finance for all‚Äù, but ended up deceiving its customers and helping the rich get richer.</p>
<p>So buckle up ‚Äî we‚Äôre heading off to the moon üöÄüåô! But first, let‚Äôs pause for a glance at:</p>
<ul>
<li>A run-down of Robinhood‚Äôs business model, and how they were fined $65 million for failing to disclose that most of their revenues come from Wall Street partners</li>
<li>The opaque world of ‚Äúpayment for order flow‚Äù, and how this creates massive conflicts of interest for Robinhood</li>
<li>The ongoing GameStop ($GME) saga ‚Äî where Robinhood conveniently ends up siding with the hedge funds, to the detriment of everyday investors around the globe</li>
</ul>

<h2>The Origins of Robinhood</h2>
<p>Robinhood‚Äôs co-founders Vlad Tenev and Baiju Bhatt were roommates at Stanford, and set off after graduation to work in New York, building trading software for hedge funds <em>(note to reader: this is one of many ties to the hedge fund world that we‚Äôll come across)</em>.</p>
<p>In 2013, Vlad and Baiju decided to strike off on their own and launched Robinhood ‚Äî an online platform that allowed investors to trade stocks, ETFs, and other financial assets without paying trading commissions.</p>
<p>At the time, competing brokers were charging $5 to $10 per trade, so Robinhood‚Äôs free model helped them to win the trust of millions of customers across America.</p>
<p>Fueled by crisp marketing, simple user interfaces, and their no-fee model, Robinhood grew by leaps and bounds over the next few years. The company now boasts more than 13 million customers, 1,200 employees, and a valuation of $11 billion after raising funds in August 2020.</p>
<p>The chart below from <a href="https://www.ft.com/content/b208cbbe-579c-4cbf-9358-01ae02b4381b" rel="noopener" target="_blank">FT and Pitchbook</a> captures Robinhood‚Äôs meteoric rise:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png"></p>

<h2>Robbing the Hood and Giving to the Rich?</h2>
<p>All was green and all was good for Robinhood and the merry men.</p>
<p>Their founders made proud claims that ‚Äúwe believe the financial system should be built to work for everyone‚Äù, and <a href="https://www.ft.com/content/c3ed6758-e51c-48b1-b6a6-a17ccb265b28" rel="noopener" target="_blank">‚Äúwe didn‚Äôt build Robinhood to make the rich people richer‚Äù</a>.</p>
<p>However, these claims don‚Äôt hold up to close scrutiny.</p>
<p>In December 2020, the SEC (America‚Äôs financial markets regulator) <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">fined Robinhood $65 million</a> for ‚Äúmisleading customers about revenue sources and failing to satisfy duty of best execution‚Äù.</p>
<p>This investigation shined a light on how Robinhood was operating beneath the glitzy marketing and lip service towards democratizing finance.</p>
<p>Excerpts from the <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">SEC press release</a> (my emphasis added):</p>
<p>According to the SEC‚Äôs order, between 2015 and late 2018, <b>Robinhood made misleading statements and omissions in customer communications, including in FAQ pages on its website</b>, about its largest revenue source when describing how it made money ‚Äì namely, payments from trading firms in exchange for Robinhood sending its customer orders to those firms for execution, also known as ‚Äúpayment for order flow.‚Äù</p>
<p>As the SEC‚Äôs order finds, one of Robinhood‚Äôs selling points to customers was that trading was ‚Äúcommission free,‚Äù but due in large part to its unusually high payment for order flow rates, <b>Robinhood customers‚Äô orders were executed at prices that were inferior to other brokers‚Äô prices</b>.  Despite this, according to the SEC‚Äôs order, Robinhood falsely claimed in a website FAQ between October 2018 and June 2019 that its execution quality matched or beat that of its competitors.</p>
<p>The order finds that <b>Robinhood provided inferior trade prices that in aggregate deprived customers of $34.1 million even after taking into account the savings from not paying a commission</b>.  Robinhood made these false and misleading statements during the time in which it was growing rapidly.</p>
<p>‚ÄúRobinhood failed to seek to obtain the best reasonably available terms when executing customers‚Äô orders, causing customers to lose tens of millions of dollars,‚Äù said Joseph Sansone, Chief of the SEC Enforcement Division‚Äôs Market Abuse Unit.  ‚ÄúToday‚Äôs action sends a clear message that the Commission will not allow brokers to ignore their obligations to customers.‚Äù</p>
<p>&nbsp;<br>
In other words:</p>
<ul>
<li>Robinhood was selling its customers‚Äô trade data to market makers and high-frequency traders ‚Äî Wall Street firms that profit off of these trades</li>
<li>This is Robinhood‚Äôs largest source of revenue ‚Äî a fact that they curiously left out on their FAQ page describing how they made money</li>
<li>This practice meant that trades placed on Robinhood weren‚Äôt executed at the best price, costing customer tens of millions of dollars, <b>even after taking into account the savings from not paying a commission</b></li>
</ul>
<p>One more time: Robinhood lied about their business model, made money by selling customer data to Wall Street, at the ultimate expense of its own customers.</p>
<p>If you‚Äôre looking for other reasons to get riled up, how about this other time Robinhood was fined for <a href="https://www.finra.org/media-center/newsreleases/2019/finra-fines-robinhood-financial-llc-125-million-best-execution" rel="noopener" target="_blank">failing to protect their customers‚Äô best interest</a>, or when Robinhood improperly stored their customers‚Äô passwords, leading to <a href="https://www.bloomberg.com/news/articles/2020-10-15/robinhood-estimates-hackers-infiltrated-almost-2-000-accounts" rel="noopener" target="_blank">2,000 accounts being compromised and having funds siphoned off</a>.</p>
<p>Next ‚Äî let‚Äôs dive into how the murky world of ‚Äúpayment for order flow‚Äù works, how Robinhood makes money from it, and why this makes Robinhood beholden to their Wall Street partners.</p>

<h2>Sally Schmo and ‚ÄúPayment for Order Flow‚Äù</h2>
<p>As we saw above, Robinhood‚Äôs main revenue source comes from selling customer trade data to other firms. This is a controversial practice known as ‚ÄúPayment for Order Flow‚Äù (PFOF in financial regulatory lingo).</p>
<p>To give you a sense of it, PFOF was <a href="https://web.archive.org/web/20200817124549/https://money.cnn.com/2000/05/29/investing/q_madoff/" rel="noopener" target="_blank">pioneered by Bernie Madoff</a> (one of history‚Äôs greatest con men), and the practice is <a href="https://www.gbm.scotiabank.com/content/dam/gbm/market-insights/etf/october/2019-10-02-Free-Trading.pdf" rel="noopener" target="_blank">banned in Canada</a>.</p>
<p>It‚Äôs a bit of a tangled web, so I‚Äôve created the graphic below to lay it out in steps:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png"></p>
<p>Let‚Äôs take the example of a Robinhood customer who wants to buy 100 shares of Nokia (NOK).</p>
<ol>
<li>Investor submits an order to buy 100 shares of $NOK at a max price of $4.00 per share ($400 total)</li>
<li>Broker asks the market maker (MM) to find 100 shares of $NOK</li>
<li>MM buys 100 shares of $NOK at the best price it can find ‚Äî $398 in this example ‚Äì and collects $2 of profit</li>
<li>Stock exchange delivers 100 shares of $NOK to the MM</li>
<li>MM delivers 100 shares and gives the broker a cut of the profit (aka, PFOF)</li>
<li>Broker delivers 100 shares of $NOK to the investor for a total of $400</li>
</ol>
<p>After all is said and done, the market maker and Robinhood walk away with $2 in profit, and the investor receives 100 shares of Nokia for $400.</p>
<p>The example above is simplified and uses dummy numbers, but the concept holds true.</p>
<p>Robinhood doesn‚Äôt carry out customer orders itself, it routes them to MMs (such as Citadel) for the MM to execute.</p>
<p>The MM buys the requested shares for a price, resells those shares to the Robinhood customer at a slightly higher price, pockets the difference, and shares some of the profits with Robinhood.</p>
<p>So what‚Äôs the big deal? Why does ‚Äúpayment for order flow‚Äù harm the everyday investor?</p>
<p>When you place an order on Robinhood, you don‚Äôt get transparency on what the best price was, whether your order was executed at that best price, and how much profit was captured by the MM / Robinhood in the process.</p>
<p>Even though Robinhood customers don‚Äôt pay commissions on their trades (the $5 to $10 per trade that brokers used to charge), there is an ‚Äúinvisible cost‚Äù to the customer since they are paying more for the shares that they trade.</p>
<p>Taking this from a different angle, why does the MM pay Robinhood for the order? If the MM wasn‚Äôt able to make a profit on the execution of these trades what would be in it for them?</p>
<p>Keep in mind that Robinhood was fined $65 million by the SEC because Robinhood customers weren‚Äôt getting the best price on their trades, and since Robinhood misled their customer about this practice.</p>

<h2>How Much Does Robinhood Earn from ‚ÄúPayment for Order Flow‚Äù?</h2>
<p>According to <a href="https://cdn.robinhood.com/assets/robinhood/legal/RHS%20SEC%20Rule%20606a%20and%20607%20Disclosure%20Report%20Q4%202020.pdf" rel="noopener" target="_blank">Robinhood‚Äôs regulatory filings for Q4 2020</a>, Robinhood made a whopping $221 million in revenue from PFOF in Q4 2020 alone.</p>
<p>I‚Äôve tabulated the data in a spreadsheet (<a href="https://drive.google.com/drive/u/0/folders/1pM7iQqZejiZIzmzX8XW36hQft7xJ2Hyt" rel="noopener" target="_blank">available here</a>), and have broken out their revenue from each partner:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png"></p>
<p>Nearly half of Robinhood‚Äôs PFOF revenues ‚Äî $108 million in Q4 2020 alone ‚Äî come from Citadel. üö®üö® Remember that name, as they‚Äôll feature prominently in the epic struggle for GameStop stock that follows.</p>
<p>Citadel is a hedge fund and market maker. Its success has vaulted founder Ken Griffin to a <a href="https://en.wikipedia.org/wiki/Kenneth_C._Griffin" rel="noopener" target="_blank">net worth of more than $20 billion</a>. Technically, the two sides of Citadel (hedge fund / market maker) are split into two separate arms ‚Äî but they are both under <a href="https://en.wikipedia.org/wiki/Citadel_LLC" rel="noopener" target="_blank">one parent company</a> and both arms are owned by Ken Griffin.</p>
<p>As a side note, Citadel Securities (the market marker arm) has been fined numerous times in the past, for activities such as <a href="https://www.sec.gov/news/pressrelease/2017-11.html" target="_blank" rel="noopener">‚Äúmisleading customers about pricing trades‚Äù</a>, <a href="https://www.bloomberg.com/news/articles/2020-07-21/citadel-securities-fined-by-finra-for-trading-ahead-of-clients" rel="noopener" target="_blank">‚Äútrading ahead of clients‚Äù</a>, and <a href="https://www.ft.com/content/16cee174-3b7f-11ea-b232-000f4477fbca" rel="noopener" target="_blank">‚Äútrading rule violations‚Äù</a>.</p>
<p>To reiterate ‚Äî Robinhood makes hundreds of millions of dollars per quarter from selling customer data to Wall Street firms such as Citadel. These firms profit off of this ‚Äòorder flow‚Äô. And Robinhood has a documented history of misleading customers about these relationships.</p>
<p>So who is Robinhood beholden to: its customer ‚Äî the general public who trades on the platform ‚Äî or the Wall Street firms who profit off of these trades?</p>
<p>What was that in the back? Did someone say ‚Äúconflict of interest‚Äù?</p>
<p>And yes, it‚Äôs true that most other brokers also make money from PFOF, but none rely on it nearly as much as Robinhood does.</p>
<p>From <a href="https://www.morningstar.ca/ca/news/208445/robinhood-was-indeed-too-good-to-be-true.aspx" rel="noopener" target="_blank">Forbes / Morningstar</a>:</p>
<p>In the first quarter of 2020, 70% of Robinhood‚Äôs revenues derived from payments for order flows, as opposed to 17% for E-Trade and just 3% for Schwab. Yes, Robinhood has observed standard practice‚Äìbut with distinctly above-average enthusiasm.</p>
<p>Enough about PFOF. Let‚Äôs get to the action of the GameStop story to see how conflict of interest plays out in a live situation.</p>

<h2>$GME and Me</h2>
<p>You‚Äôve likely all heard this story already but I‚Äôll ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://themeasureofaplan.com/robinhood/">https://themeasureofaplan.com/robinhood/</a></em></p>]]>
            </description>
            <link>https://themeasureofaplan.com/robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989199</guid>
            <pubDate>Mon, 01 Feb 2021 14:59:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An unexpected find that freed 20GB of unused index space in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 356 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25988871">thread link</a>) | @haki
<br/>
February 1, 2021 | https://hakibenita.com/postgresql-unused-index-size | <a href="https://web.archive.org/web/*/https://hakibenita.com/postgresql-unused-index-size">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Every few months we get an alert from our database monitoring to warn us that we are about to run out of space. Usually we just provision more storage and forget about it, but this time we were under quarantine, and the system in question was under less load than usual. We thought this is a good opportunity to do some cleanups that would otherwise be much more challenging.</p>
<p>To start from the end, <strong>we ended up freeing more than 70GB of un-optimized and un-utilized space</strong> without dropping a single index or deleting any data!</p>
<p>Using conventional technics such as rebuilding indexes and tables we cleared up a lot of space, but then <strong>one surprising find helped us clear an additional ~20GB of unused indexed values!</strong></p>
<p>This is what the free storage chart of one of our databases looked like in the process:</p>
<figure><img alt="Free space over time (higher means more free space)" src="https://hakibenita.com/images/00-postgresql-unused-index-size.png"><figcaption>Free space over time (higher means more free space)</figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="the-usual-suspects"><a href="#the-usual-suspects">The Usual Suspects</a></h2>
<p>Provisioning storage is something we do from time to time, but before we throw money at the problem we like to make sure we make good use of the storage we already have. To do that, we start with the usual suspects.</p>
<h3 id="unused-indexes"><a href="#unused-indexes">Unused Indexes</a></h3>
<p>Unused indexes are double-edged swords; you create them to make things faster, but they end up taking space and slow inserts and updates. Unused indexes are the first thing we always check when we need to clear up storage.</p>
<p>To find unused indexes we use the following query:</p>
<div><pre><span></span><span>SELECT</span>
    <span>relname</span><span>,</span>
    <span>indexrelname</span><span>,</span>
    <span>idx_scan</span><span>,</span>
    <span>idx_tup_read</span><span>,</span>
    <span>idx_tup_fetch</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>))</span> <span>as</span> <span>size</span>
<span>FROM</span>
    <span>pg_stat_all_indexes</span>
<span>WHERE</span>
    <span>schemaname</span> <span>=</span> <span>'public'</span>
    <span>AND</span> <span>indexrelname</span> <span>NOT</span> <span>LIKE</span> <span>'pg_toast_%'</span>
<span>    <span>AND</span> <span>idx_scan</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_read</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_fetch</span> <span>=</span> <span>0</span>
</span><span>ORDER</span> <span>BY</span>
    <span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>)</span> <span>DESC</span><span>;</span>
</pre></div>


<p>The query is looking for <strong>indexes that were not scanned or fetched</strong> since the last time the statistics were reset.</p>
<p>Some indexes may seem like they were not used but they were in-fact used:</p>
<ul>
<li>
<p><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ALL-INDEXES-VIEW" rel="noopener">The documentation</a> lists a few scenarios when this is possible. For example, when the optimizer uses meta data from the index, but not the index itself.</p>
</li>
<li>
<p>Indexes used to enforce unique or primary key constraints for tables that were not updated in a while. The indexes will look like they were not used, but it doesn't mean we can dispose of them.</p>
</li>
</ul>
<p>The find the unused indexes you can actually drop, you usually have to go over the list one by one and make a decision. This can be time consuming in the first couple of times, but after you get rid of most unused indexes it becomes easier.</p>
<p>It's also a good idea to <strong>reset the statistics counters from time to time</strong>, usually right after you finished inspecting the list. PostgreSQL provides a few <a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-STATS-FUNCS-TABLE" rel="noopener">functions to reset statistics</a> at different levels. When we find an index we suspect is not being used, or when we add new indexes in place of old ones, we usually reset the counters for the table and wait for a while:</p>
<div><pre><span></span><span>-- Find table oid by name</span>
<span>SELECT</span> <span>oid</span> <span>FROM</span> <span>pg_class</span> <span>c</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'table_name'</span><span>;</span>
<span>-- Reset counts for all indexes of table</span>
<span>SELECT</span> <span>pg_stat_reset_single_table_counters</span><span>(</span><span>14662536</span><span>);</span>
</pre></div>


<p>We do this every once in a while, so in our case there were no unused indexes to drop.</p>
<h3 id="index-and-table-bloat"><a href="#index-and-table-bloat">Index and Table Bloat</a></h3>
<p>The next suspect is bloat. When you update rows in a table, PostgreSQL marks the tuple as dead and adds the updated tuple in the next available space. This process creates what's called "bloat", which can cause tables to consume more space than they really need. Bloat also affects indexes, so to free up space, bloat is a good place to look.</p>
<p>Estimating bloat in tables and indexes is apparently not a simple task. Lucky for us, some good people on the world wide web already <a href="https://wiki.postgresql.org/wiki/Show_database_bloat" rel="noopener">did the hard work</a> and wrote queries to estimate <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/table/table_bloat.sql" rel="noopener">table bloat</a> and <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/btree/btree_bloat.sql" rel="noopener">index bloat</a>. After running these queries you will most likely find <em>some</em> bloat, so the next thing to do it clear up that space.</p>
<h4 id="clearing-bloat-in-indexes"><a href="#clearing-bloat-in-indexes">Clearing Bloat in Indexes</a></h4>
<p>To clear bloat in an index, you need to rebuild it. There are several ways to rebuild an index:</p>
<ol>
<li>
<p><strong>Re-create the index</strong>: If you re-create the index, it will be built in an optimal way.</p>
</li>
<li>
<p><strong>Rebuild the index</strong>: Instead of dropping and creating the index yourself, PostgreSQL provides a way to re-build an existing index in-place using the <a href="https://www.postgresql.org/docs/current/sql-reindex.html" rel="noopener"><code>REINDEX</code></a> command:</p>
</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>index_name</span><span>;</span>
</pre></div>


<ol>
<li><strong>Rebuild the index concurrently</strong>: The previous methods will obtain a lock on the table and prevent it from being changed while the operation is in progress, which is usually unacceptable. To rebuild the index without locking it for updates, you can <a href="https://www.postgresql.org/docs/current/sql-reindex.html#SQL-REINDEX-CONCURRENTLY" rel="noopener">rebuilt the index concurrently</a>:</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>CONCURRENTLY</span> <span>index_name</span><span>;</span>
</pre></div>


<p>When using <code>REINDEX CONCURRENTLY</code>, PostgreSQL creates a new index with a name suffixed with <code>_ccnew</code>, and syncs any changes made to the table in the meantime. When the rebuild is done, it will switch the old index with the new index, and drop the old one.</p>
<figure>
<figcaption>Clearing bloat in Indexes</figcaption>
</figure>
<p>If for some reason you had to stop the rebuild in the middle, the new index will not be dropped. Instead, it will be left in an invalid state and consume space. To identify invalid indexes that were created during <code>REINDEX</code>, we use the following query:</p>
<div><pre><span></span><span>-- Identify invalid indexes that were created during index rebuild</span>
<span>SELECT</span>
    <span>c</span><span>.</span><span>relname</span> <span>as</span> <span>index_name</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>c</span><span>.</span><span>oid</span><span>))</span>
<span>FROM</span>
    <span>pg_index</span> <span>i</span>
    <span>JOIN</span> <span>pg_class</span> <span>c</span> <span>ON</span> <span>i</span><span>.</span><span>indexrelid</span> <span>=</span> <span>c</span><span>.</span><span>oid</span>
<span>WHERE</span>
    <span>-- New index built using REINDEX CONCURRENTLY</span>
    <span>c</span><span>.</span><span>relname</span> <span>LIKE</span>  <span>'%_ccnew'</span>
    <span>-- In INVALID state</span>
    <span>AND</span> <span>NOT</span> <span>indisvalid</span>
<span>LIMIT</span> <span>10</span><span>;</span>
</pre></div>


<p>Once the rebuild process is no longer active, it should be safe to drop any remaining invalid indexes.</p>
<h4 id="activating-b-tree-index-deduplication"><a href="#activating-b-tree-index-deduplication">Activating B-Tree Index Deduplication</a></h4>
<p>PostgreSQL 13 introduced a new efficient way of storing duplicate values in B-Tree indexes called <a href="https://www.postgresql.org/docs/current/btree-implementation.html#BTREE-DEDUPLICATION" rel="noopener">"B-Tree Deduplication"</a>.</p>
<p>For each indexed value, a B-Tree index will hold in its leaf both the value and a pointer to the row (TID). The larger the indexed values, the larger the index. Up until PostgreSQL 12, when the index contained many duplicate values, all of these duplicate values would be stored in the index leaves. This is not very efficient and can take up a lot of space.</p>
<figure>
<figcaption>B-Tree Index Deduplication</figcaption>
</figure>
<p>Starting at PostgreSQL 13, when B-Tree deduplication is activated, duplicate values are only stored once. This can make a huge impact on the size of indexes with many duplicate values.</p>
<p>In PostgreSQL 13 index deduplication in enabled by default, unless you deactivate it:</p>
<div><pre><span></span><span>-- Activating de-deduplication for a B-Tree index, this is the default:</span>
<span>CREATE</span> <span>INDEX</span> <span>index_name</span> <span>ON</span> <span>table_name</span><span>(</span><span>column_name</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>)</span>
</pre></div>


<p>If you are migrating from PostgreSQL versions prior to 13, you need to rebuild the indexes using the <code>REINDEX</code> command in order to get the full benefits of index de-deduplication.</p>
<p>To illustrate the effect of B-Tree deduplication on the size of the index, create a table with a unique column and a non unique column, and populate it with 1M rows. On each column create two B-Tree indexes, one with deduplication enabled and another with deduplication disabled:</p>
<div><pre><span></span><span>db</span><span>=#</span> <span>CREATE</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span> <span>serial</span><span>,</span> <span>n_not_unique</span> <span>integer</span><span>);</span>
<span>CREATE</span> <span>TABLE</span>

<span>db</span><span>=#</span> <span>INSERT</span> <span>INTO</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span>
<span>SELECT</span> <span>(</span><span>random</span><span>()</span> <span>*</span> <span>100</span><span>)::</span><span>int</span> <span>FROM</span> <span>generate_series</span><span>(</span><span>1</span><span>,</span> <span>1000000</span><span>);</span>
<span>INSERT</span> <span>0</span> <span>1000000</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix1</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix2</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix3</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix4</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>
</pre></div>


<p>Next, compare the sizes of the four indexes:</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>Deduplication</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Not unique</td>
<td>Yes</td>
<td>6840 kB</td>
</tr>
<tr>
<td>Not unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>Yes</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
</tbody>
</table>
<p>As expected, deduplication had no effect on the unique index, but it had a significant effect on the index that had many duplicate values.</p>
<p>Unfortunately for us, PostgreSQL 13 was still fresh at the time, and our cloud provider did not have support for it yet, so we were unable to use deduplication to clear space.</p>
<h4 id="clearing-bloat-in-tables"><a href="#clearing-bloat-in-tables">Clearing Bloat in Tables</a></h4>
<p>Just like in indexes, tables can also contain dead tuples that cause bloat and fragmentation. However, unlike indexes that contain data from an associated table, a table can not just simply be re-created. To re-create a table you would have to create a new table, migrate the data over while keeping it synced with new data, create all the indexes, constraints and any referential constraints in other tables. Only after all of this is done, you can switch the old table with the new one.</p>
<figure>
<figcaption>Clearing bloat in Tables</figcaption>
</figure>
<p>There are several ways to rebuild a table and reduce bloat:</p>
<ol>
<li>
<p><strong>Re-create the table</strong>: Using this method as described above often requires a lot of development, especially if the table is actively being used as it's being rebuilt.</p>
</li>
<li>
<p><strong>Vacuum the table</strong>: PostgreSQL provides a way to reclaim space occupied by bloat and dead tuples in a table using the <a href="https://www.postgresql.org/docs/current/sql-vacuum.html" rel="noopener"><code>VACUUM FULL</code> command</a>. Vacuum full requires a lock on the table, and is not an ideal solution for tables that need to be available while being vacuumed:</p>
</li>
</ol>
<div><pre><span></span><span>-- Will lock the table</span>
<span>VACUUM</span> <span>FULL</span> <span>table_name</span><span>;</span>
</pre></div>


<p>The two options above require either a significant effort, or some down time.</p>
<h4 id="using-pg_repack"><a href="#using-pg_repack">Using pg_repack</a></h4>
<p>Both built-in options for rebuilding tables are not ideal unless you can afford downtime. One popular solution for rebuilding tables and indexes without downtime is the <a href="https://reorg.github.io/pg_repack/" rel="noopener">pg_repack extension</a>.</p>
<p>Being a popular extension, <code>pg_repack</code> is likely available from your package manager or already installed by your cloud provider. To use <code>pg_repack</code>, you first need to create the extension:</p>
<div><pre><span></span><span>CREATE</span> <span>EXTENSION</span> <span>pg_repack</span><span>;</span>
</pre></div>


<p>To "repack" a table along with its indexes, issue the following command from the console:</p>
<div><pre><span></span><span>$</span> pg_repack -k --table table_name db_name
</pre></div>


<p>To rebuild a table with no downtime, the extension creates a new table, loads the data from the original table into it while keeping it ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/postgresql-unused-index-size">https://hakibenita.com/postgresql-unused-index-size</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/postgresql-unused-index-size</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988871</guid>
            <pubDate>Mon, 01 Feb 2021 14:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your MQTT server with authentication and encryption]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25988196">thread link</a>) | @juriansluiman
<br/>
February 1, 2021 | https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/ | <a href="https://web.archive.org/web/*/https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">


<article itemscope="" itemtype="http://schema.org/BlogPosting" id="content">
    <header>
        
          <time datetime="" pubdate="" itemprop="datePublished" content="2021-01-31T00:00:00Z" title="2021-01-31T00:00:00Z">January 2021</time>
    </header>

    <section>
      <p>The last days I have been experimenting in different ways how I can secure a
MQTT setup for my home automation. There‚Äôs an increasing use of IoT here at my
home and most of the applications communicate over MQTT. You simply cannot
control every device and how it gathers information. To prevent eavesdropping,
it‚Äôs time to secure MQTT.</p>
<p>This post is written with the <a href="https://www.troyhunt.com/iot-unravelled-part-3-security/">Troy Hunt IoT series</a>
in mind. Of course, you should patch your devices and put them in a
separate VLAN. However, if you have an MQTT security system and an MQTT light
bulb, did you consider the light bulb had access to the security system via MQTT?
Or did you consider IoT devices that are inside the same VLAN, but don‚Äôt use
MQTT themselves, could sniff all (security) messages communicated over your
message broker? It all boils down to the principles of <em>zero trust</em>.</p>
<p>For my home automation I am an avid <a href="https://www.home-assistant.io/">Home Assistant</a>
user. Since a long time I have a Home Assistant setup which controls a variety
of lights, switches and appliances. When I started introducing MQTT to my
setup, I used it without TLS and without authentication. Over time more
applications communicate over MQTT and I was worrying about two things:</p>
<ol>
<li>Untrusted devices could find and connect to the MQTT server without any effort;</li>
<li>Every message in every topic could be listened for anonymously.</li>
</ol>
<p>That‚Äôs why I set three goals to tighten things up:</p>
<ol>
<li>Every MQTT client must authenticate via unique usernames/passwords. Every
client gets separate credentials so there‚Äôs no reuse of passwords anywhere.</li>
<li>Enable TLS encryption for communication. The MQTT protocol (including
authentication) is plain text, meaning username and password could be sniffed if
no encryption is used.</li>
<li>Use Access Control to prevent devices reading/writing topics they should have
no interest in. If a trusted (authenticated) client sniffs into topics for other
applications, they must be blocked.</li>
</ol>

<p>The message broker I personally use is Mosquitto, as it‚Äôs lightweight and
extremely easy to use. Out of the box, it does allow anonymous connections and
no users are registered, so you need to take care of both.</p>
<p>In your <code>mosquitto.conf</code> file, make sure you have those two lines present and
make sure the mosquitto.passwd file exists (just update the path of the password
file based on your installation):</p>
<pre><code>allow_anonymous false
password_file &lt;path/to/mosquitto&gt;/mosquitto.passwd
</code></pre>
<p>Then supply Mosquitto with the credentials you want to add:</p>
<pre><code>mosquitto_passwd &lt;path/to/mosquitto&gt;/mosquitto.passwd &lt;username&gt;
</code></pre>
<p>Again, replace the path &amp; your preferred username and complete the prompt with
the password.</p>
<p>My installation resides inside docker, so in my case, the configuration files
are located at <code>/mosquitto/config/</code> and I add all my clients in bulk (via Ansible)
using the following command (<code>mqtt</code> is the name of my container)</p>
<pre><code>docker exec mqtt mosquitto_passwd -b /mosquitto/config/mosquitto.passwd &lt;user&gt; &lt;password&gt;
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p>The <code>SIGHUP</code> signal is used in Mosquitto to
<a href="https://mosquitto.org/man/mosquitto-8.html#idm296">reload the configuration</a>
without restarting Mosquitto (which otherwise will probably loose some messages
along the way).</p>
<p><strong>Well done: You completed the first part of your goal securing MQTT!</strong></p>

<p>My favourite reverse proxy for production apps and home installation is <a href="https://traefik.io/">Traefik</a>.
It just integrates flawless with the tools I prefer: a dockerized setup and
automated certification renewal via Let‚Äôs Encrypt. And it‚Äôs so lightweight you
have little overhead for hosts like a Raspberry Pi.</p>
<p>All of my frontend web applications are routed via Traefik‚Äôs HTTP(S) proxy. The
fun thing is it also supports TCP and UDP traffic (which I also utilize in my
failover <a href="https://jurian.slui.mn/posts/openvpn-with-traefik-2.2/">TCP+UDP setup for OpenVPN</a>).</p>
<p>MQTT is plain TCP traffic and Traefik is able to create a TLS tunnel for TCP
traffic, so this is a fairly straightforward thing to configure. To understand
the label configuration below, make sure you read the
<a href="https://doc.traefik.io/traefik/routing/providers/docker/">Traefik documentation</a>.</p>
<pre><code>labels:
  - traefik.enable=true
  
  - traefik.tcp.routers.mqtt.rule=HostSNI(`mqtt.example.com`)
  - traefik.tcp.routers.mqtt.entrypoints=mqtt
  - traefik.tcp.routers.mqtt.tls=true
  - traefik.tcp.routers.mqtt.service=mqtt
  
  - traefik.tcp.services.mqtt.loadBalancer.server.port=1883
</code></pre>
<p>Traefik usually connects to a container‚Äôs port if there‚Äôs only one port exposed.
To be explicit I define a <code>mqtt</code> service in this case, loadbalancing the only port
in the mosquitto container. I make this explicit because the default
(unencrypted) MQTT port is 1883 and the default TLS encrypted port is 8883. If you
ever read back the configuration you should be able to trace things back.</p>
<p>Next, the docker container uses an entrypoint called <code>mqtt</code> defined in the
static configuration. Most Traefik setups use at least a <code>web</code> and <code>websecure</code>
entrypoint, I added <code>mqtt</code> at port <code>8333</code>. This creates a setup where the
docker container itself exposes an (unencrypted) port 1883 towards Traefik, this
container is inaccessible from the outside. Traefik creates an accessible
entrypoint, which will be encrypted, at port 8883. This technique is called
<em>SSL Termination</em>.</p>
<pre><code>[entryPoints]
  [entryPoints.web]
    address = ":80"
  [entryPoints.websecure]
    address = ":443"
  [entryPoints.mqtt]
    address = ":8883"
</code></pre>
<p>Finally, the rule label in the docker container gives a URL to use (like
<code>mqtt.example.com</code>) and with  <code>tls=true</code> you tell Traefik to <a href="https://doc.traefik.io/traefik/https/overview/">handle it as a
TLS connection</a>.</p>
<p><strong>This is great: You are more than halfway through securing MQTT!</strong></p>

<p>Access control in an MQTT server is the final step in securing your messaging
system for IoT. Access control defines access on a per-user basis, so above
steps for authentication and encryption are required to go further down the
security lane. Initiating access control is a principle of a whitelist, anything
<em>not</em> specified means there is <em>no access</em>. You only need to state which clients
have access to which topics, anything else is excluded.</p>
<p>Like the password file, the ACL file is referenced in the mosquitto.conf:</p>
<pre><code>acl_file &lt;path/to/mosquitto&gt;/acl
</code></pre>
<p>Next, you need to fill your ACL file. Jaimyn Mayer has an <a href="https://jaimyn.com.au/mqtt-use-acls-multiple-user-accounts/">excellent tutorial
for composing an ACL file</a>
with the usage of Home Assistant in mind so I won‚Äôt elaborate too much on this.</p>
<p>The basic format of the file consists of sections per user, where every topic
is listed to grant read and/or write access. Because of the nested structure of
MQTT topics, you can use wildcards to group topics at a higher level.</p>
<p>From Jaimyn‚Äôs example, using Home Assistant, Sonoff (WiFi powered) lights and
light sensors:</p>
<pre><code># Give Home Assitant full access to everything
user homeassist
topic readwrite #

# Allow the sonoffs to read/write to cmnd/# and stat/#
user sonoffswitch
topic readwrite cmnd/#
topic readwrite stat/#

# Allows the light sensor to read/write to the sensor topics
user lightsense
topic cmnd/sensor/#
topic stat/sensor/#
</code></pre>
<p>Tip: if you don‚Äôt know which topics are used by your devices, send Mosquitto
the <code>SIGUSR2</code> signal and it outputs a hierarchy of topics:</p>
<pre><code>kill -SIGUSER2 &lt;pid-of-mosquitto&gt;
</code></pre>
<p>In my docker setup this translates to (the output is send to stdout, so you need
to check the container logs):</p>
<pre><code>docker exec mqtt kill -SIGUSR2 1
docker logs mqtt
</code></pre>
<p>Again, when finished composing your ACL file, make sure to reload Mosquitto:</p>
<pre><code>// For normal installation
kill -SIGHUP &lt;pid-of-mosquitto&gt;

// For docker installation
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p><strong>You are awesome! You completed your goal in securing your MQTT message broker!</strong></p>

<p>This ended up as a much longer post than anticipated. I was reluctant to get
going with this setup but it ended up pretty nice. The overhead (and delay in
message delivery) with TLS encryption in comparison with unencrypted MQTT is
unnoticable for me. In addition, it gives me a much safer feeling
compartimentising all the variety of IoT devices. I simply don‚Äôt trust all the
‚Äòthings‚Äô, especially the cheap stuff from far abroad. Now I know that stuff just
can‚Äôt sniff around the communication of other devices.</p>
<h2 id="client-tls-capabilities">Client TLS capabilities</h2>
<p>Just to make one thing clear if you go down this road, it may seem obvious but
encrypting MQTT traffic means every client must connect over TLS only. Switching
over to Traefik means you go over the configuration of every MQTT client (lights,
switches, cameras and so on) to enable a security flag in their respective
settings. Otherwise you end up only <em>pretending</em> being a security endboss.</p>
    </section>

    
</article>

  </div></div>]]>
            </description>
            <link>https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988196</guid>
            <pubDate>Mon, 01 Feb 2021 12:54:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[gemini:// space]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 155 (<a href="https://news.ycombinator.com/item?id=25986378">thread link</a>) | @pabs3
<br/>
January 31, 2021 | https://spwhitton.name//blog/entry/geminispace/ | <a href="https://web.archive.org/web/*/https://spwhitton.name//blog/entry/geminispace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content">
<p>Recently I have become curious about <a href="https://gemini.circumlunar.space/">the Gemini
Project</a> and the content that people have
made available to be retrieved over the gemini:// protocol.  I‚Äôm not convinced
by the arguments for not just using http, and mostly it‚Äôs just that I
typically find more things that I am interested in casually reading through on
people‚Äôs gemlogs than I would on, say, reddit, and similar aggregators.  But
presumably advocates of gemini:// and the text/gemini format would argue that
it‚Äôs various respects in which it differs from the web that makes geminispace
conducive to the production of the sort of content you find there.  So I‚Äôm
remaining open minded about the possibility that having a completely separate
protocol is important, and not just an annoyance because rss2email doesn‚Äôt
work and I had to spend time writing
<a href="https://manpages.debian.org/gmi2email">gmi2email</a>.</p>

<p>I now have a games console at home for the first time in some years, which I
bought in response to the ongoing pandemic, and one thing that I have noticed
is that using it feels like being offline in a way that playing games on a
regular computer never would.  It has a WiFi connection but it doesn‚Äôt have a
web browser, and I am glad that using it provides an opportunity to be
disconnected from the usual streams of information.  And perhaps something
similar ought to be said in favour of how the Gemini project does not just use
http.  There is, perhaps, a positive psychological effect induced by making
the boundary between text/gemini and the web as hard as it is made by using
gemini:// rather than http.</p>

<p>Something about which I find myself much more sceptical is how the
specification for gemini:// and text/gemini is not extensible.  Advocates of
Gemini have this idea that they can‚Äôt include, say, a version number in the
protocol, because the extensibility of the web is what has led to the problems
they think it has, so they want to make it impossible.  Now on the one hand
perhaps the people behind Gemini are in the best position that anyone is in to
come up with a spec which they will finalise and render effectively
unchangeable, because a lot of them have been using Gopher for decades, and so
they have enough experience to be able to say exactly what Gopher is missing,
and be confident that they‚Äôve not missed anything.  But on the other hand,
Gemini is one technological piece in attempts to make a version of the
Internet which is healthier for humans ‚Äì the so-called ‚Äúsmall Internet‚Äù
movement ‚Äì and maybe there will be new ideas about how the small Internet
should be which would benefit from a new version of the Gemini specification.
So it seems risky to lock-in to one version.</p>

<p><a href="https://news.ycombinator.com/item?id=25986378">Comments on Hacker News</a>.</p>

</div>









</div>



</div></div>]]>
            </description>
            <link>https://spwhitton.name//blog/entry/geminispace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986378</guid>
            <pubDate>Mon, 01 Feb 2021 07:14:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Counterfeiting Stock ‚Äì Explaining illegal naked shorting and stock manipulation]]>
            </title>
            <description>
<![CDATA[
Score 333 | Comments 379 (<a href="https://news.ycombinator.com/item?id=25986320">thread link</a>) | @lelf
<br/>
January 31, 2021 | http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html | <a href="https://web.archive.org/web/*/http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<center><b>Counterfeiting Stock 2.0</b></center>

<p>
Illegal naked shorting and stock manipulation are two of Wall Street's deep, dark secrets. These practices have been around for decades and have resulted in trillions of dollars being fleeced from the American public by Wall Street. In the process, many emerging companies have been put out of business. This report will explain the magnitude of this problem, how it happens, why it has been covered up and how short sellers attack a company. It will also show how all of the participants; the short hedge funds, the prime brokers and the Depository Trust Clearing Corp. (DTCC)‚Äîmake unconscionable profits while the fleecing of the small American investor continues unabated.
</p>
<p>
<span>Why is This Important?</span> This problem affects the investing public. Whether invested directly in the stock market or in mutual funds, IRAs, retirement or pension plans that hold stock ‚Äî it touches the majority of Americans.
</p>
<p>
The participants in this fraud, which, when fully exposed, will make Enron look like child's play, have been very successful in maintaining a veil of secrecy and impenetrability. Congress and the SEC have unknowingly (?) helped keep the closet door closed. The public rarely knows when its pocket is being picked as unexplained drops in stock price get chalked up to ‚Äúmarket forces‚Äù when they are often market manipulations.
</p>
<p>
The stocks most frequently targeted are those of emerging companies who went to the stock market to raise start‚Äìup capital. Small business brings the vast majority of innovative new ideas and products to market and creates the majority of new jobs in the United States. It is estimated that over 1000 of these emerging companies have been put into bankruptcy or had their stock driven to pennies by predatory short sellers. 
</p>
<p>
It is important to understand that selling a stock short is not an investment in American enterprise. A short seller makes money when the stock price goes down and that money comes solely from investors who have purchased the company's stock. A successful short manipulation takes money from investment in American enterprise and diverts it to feed Wall Street's insatiable greed‚Äîthe company that was attacked is worse off and the investing public has lost money. Frequently this profit is diverted to off‚Äìshore tax havens and no taxes are paid. This national disgrace is a parasite on the greatest capital market in the world.
</p>
<p>
<span>A Glossary of Illogical Terms</span> ‚Äî The securities industry has its own jargon, laws and practices that may require explaining. Most of these concepts are the creation of the industry, and, while they are promoted as practices that ensure an orderly market, they are also exploited as manipulative tools. This glossary is limited to naked short abuse, or counterfeiting stock as it is more correctly referred to. 
</p>

<ol>
<li><b>Broker Dealer or Prime Broker</b> ‚Äî The big stockbrokers who clear their own transactions, which is to say they move transacted shares between their customers directly, or with the DTC. Small brokers will clear through a clearing house ‚Äî also known as a broker's broker.
</li>
<li><b>Hedge Funds</b> ‚Äî Hedge funds are really unregulated investment pools for rich investors. They have grown exponentially in the past decade and now number over 10,000 and manage over one trillion dollars. They don't register with the SEC, are virtually unregulated and frequently foreign domiciled, yet they are allowed to be market makers with access to all of the naked shorting loopholes. Frequently they operate secretively and collusively. The prime brokers cater to the hedge funds and allegedly receive eight to ten billion dollars annually in fees and charges relating to stock lend to the short hedge funds.
</li>
<li><b>Market Maker</b> ‚Äî A broker, broker dealer or hedge fund who makes a market in a stock. In order to be a market maker, they must always have shares available to buy and sell. Market makers get certain sweeping exemptions from SEC rules involving naked shorting.
</li>
<li><b>Short Seller</b> ‚Äî An individual, hedge fund, broker or institution who sells stock short. The group of short sellers is referred to as ‚Äúthe shorts.‚Äù
</li>
<li><b>The Securities and Exchange Commission</b> ‚Äî The SEC is the federal enforcement agency that oversees the securities markets. The top‚Äìlevel management is a five‚Äìperson Board of Governors who are Presidential appointees. Three of the governors are usually from the securities industry, including the chairman. The SEC adopted Regulation SHO in January 2005 in an attempt to curb naked short abuse.
</li>
<li><b>Depository Trust Clearing Corp</b> ‚Äî Usually known as the DTCC, this privately held company is owned by the prime brokers and it clears, transacts and holds most stock in this country. It has four subsidiaries, which include the DTC and the NCSS. The operation of this company is described in detail later.
</li>
<li><b>Short Sale</b> ‚Äî Selling a stock short is a way to make a profit while the stock price declines. For example: If investor S wishes to sell short, he borrows a share from the account of investor L. Investor S immediately sells that share on the open market, so investor S now has the cash from the sale in his account, and investor L has an IOU for the share from investor S. When the stock price drops, investor S takes some of the money from his account and buys a share, called ‚Äúcovering‚Äù, which he returns to investor L's account. Investor S books a profit and investor L has his share back.
<p>This relatively simple process is perfectly legal‚Äîso far. The investor lending the share most likely doesn't even know the share left his account, since it is all electronic and occurs at the prime broker or DTC level. If shares are in a margin account, they may be loaned to a short without the consent or knowledge of the account owner. If the shares are in a cash account, IRA account or are restricted shares they are not supposed to be borrowed unless there is express consent by the account owner.
</p></li>
<li><b>Disclosed Short</b> ‚Äî When the share has been borrowed or a suitable share has been located that can be borrowed, it is a disclosed short. Shorts are either naked or disclosed, but, in reality, some disclosed shorts are really naked shorts as a result of fraudulent stock borrowing. 
</li>
<li><b>Naked Short</b> ‚Äî This is an invention of the securities industry that is a license to create counterfeit shares. In the context of this document, a share created that has the effect of increasing the number of shares that are in the market place beyond the number issued by the company, is considered counterfeit. This is not a legal conclusion, since some shares we consider counterfeit are legal based upon today's rules. The alleged justification for naked shorting is to insure an orderly and smooth market, but all too often it is used to create a virtually unlimited supply of counterfeit shares, which leads to widespread stock manipulation‚Äîthe lynchpin of this massive fraud. 
<p>
Returning to our example, everything is the same except the part about borrowing the share from someone else's account: There is no borrowed share ‚Äî instead a new one is created by either the broker dealer or the DTC. Without a borrowed share behind the short sale, a naked short is really a counterfeit share.
</p></li>
<li><b>Fails‚Äìto‚ÄìDeliver</b> ‚Äî The process of creating shares via naked shorting creates an obvious imbalance in the market as the sell side is artificially increased with naked short shares or more accurately, counterfeit shares. Time limits are imposed that dictate how long the sold share can be naked. For a stock market investor or trader, that time limit is three days. According to SEC rules, if the broker dealer has not located a share to borrow, they are supposed to take cash in the short account and purchase a share in the open market. This is called a ‚Äúbuy‚Äìin,‚Äù and it is supposed to maintain the total number of shares in the market place equal to the number of shares the company has issued.
<p>
Market makers have special exemptions from the rules: they are allowed to carry a naked short for up to twenty‚Äìone trading days before they have to borrow a share. When the share is not borrowed in the allotted time and a buy‚Äìin does not occur, and they rarely do, the naked short becomes a fail‚Äìto‚Äìdeliver (of the borrowed share).
</p></li>
<li><b>Options</b> ‚Äî The stock market also has separate, but related markets that sell options to purchase shares (a ‚Äúcall‚Äù) and options to sell shares (a ‚Äúput‚Äù). Options are an integral part of short manipulations, the result of SEC promulgated loopholes in Reg SHO. A call works as follows: Assume investor L has a share in his account that is worth $25. He may sell an option to purchase that share to a third party. That option will be at a specific price, say $30, and expires at a specific future date. Investor L will get some cash from selling this option. If at the expiration date, the market value of the stock is below $30 (the ‚Äústrike price‚Äù), the option expires as worthless and investor L keeps the option payment. This is called ‚Äúout of the money.‚Äù If the market value of the stock is above the strike price, then the buyer of the option ‚Äúcalls‚Äù the stock. Assume the stock has risen to $40. The option buyer tenders $30 to investor L and demands delivery of the share, which he may keep or immediately sell for a $10 profit.
</li>
<li><b>Naked call</b> ‚Äî The same as above except that investor L, who sells the call, has no shares in his account. In other words, he is selling an option on something he does not own. The SEC allows this. SEC rules also allow the seller of a naked short to treat the purchase of a naked call as a borrowed share, thereby keeping their naked short off the SEC's fails‚Äìto‚Äìdeliver list. A share of stock that has a naked call as its borrowed shares is marked as a disclosed short when it is sold, even though nobody in the transaction actually owns a share.
</li>
</ol>




<p>
<span>How The System Transacts Stocks</span> ‚Äî This explanation has been greatly simplified in the interest of brevity. 
</p>

<img src="http://counterfeitingstock.com/CS2.0/diagram.png">

<ol>
<li><b>Customers</b> ‚Äî These can be individuals, institutions, hedge funds and prime broker's house accounts.</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</a></em></p>]]>
            </description>
            <link>http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986320</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F# is gaining independence from .NET]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 170 (<a href="https://news.ycombinator.com/item?id=25986316">thread link</a>) | @sidcool
<br/>
January 31, 2021 | https://onurgumus.github.io/2021/01/31/What-the-F.html | <a href="https://web.archive.org/web/*/https://onurgumus.github.io/2021/01/31/What-the-F.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
      <div>
         <section id="main-content">
            

<p>In a previous <a href="https://onurgumus.github.io/2020/12/26/Functional-Programming.html">post</a> I have explained my motivations for functional programming.
It‚Äôs no secret I love F# because F# makes me sleep better. In this post, I would like to discuss some different aspects of F#.</p>

<h2 id="f-is-gaining-independence-from-net">F# is gaining independence from .NET</h2>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/platform.png" alt="F# platforms"></p>

<!--more-->

<p>F# is mostly known to the developer community as the small ignored brother of C# running on the .NET platform. However, what is less known about F# is that it
has come to a level to be .NET independent. Thanks to <a href="https://fable.io/">Fable</a>, today F# can be considered as a complete replacement of TypeScript. Yes,
people do write full-blown SPA, React, Svelte applications by using F# instead of TypeScript. If you think Fable is just a transpiler, think again:  https://github.com/kunjee17/awesome-fable . I would say Fable is on the way being an ecosystem by itself.</p>

<p>There is also a new prototype target for Fable that allows F# code to transpile to Python developed by Dag Brattli.</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/python2.gif" alt="Python"></p>

<p>F# also works as on WebAssembly with <a href="https://fsbolero.io/">Bolero</a> which is still based on .NET. And not to forget another F# web platform called <a href="https://websharper.com/">WebSharper</a> from the same people who developed Bolero.</p>

<p>Just like JavaScript people were using NodeJs to bring the front-end devs to the backend zone, F# also can be used to bring the backend-devs to the front-end realm. I am a living example myself. By using F# in the font-end you can practically share the code between your .NET/Node backend and the browser, giving you an isomorphic development experience.</p>

<p>This somewhat puts F# in an interesting position as historically most dotnet has been languages are managed by Microsoft. But Fable simply liberates
F# from Microsoft and .NET.</p>

<h2 id="the-f-fanboys">The F# fanboys</h2>

<p>You might have heard ‚Äúone of those guys‚Äù like me who is talking about how great functional programming and/or F# is. And from that point, it looks like below</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/music.png" alt="music"></p>

<p>I know it‚Äôs annoying, however, let‚Äôs look at it from the side and this is how an F# developer feels when he or she is suggesting you using F#:
<img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/wheel.png" alt="wheels"></p>

<h2 id="microsofts-and-communitys-stance">Microsoft‚Äôs and community‚Äôs stance</h2>

<p>From Microsoft‚Äôs point of view, F# is actively supported and maintained. There are Microsoft developers actively fixing things and adding new features however as a general Microsoft‚Äôs point of view .NET == C# and that is that. From .NET developer community‚Äôs
point of view, things are even worse. Since all Microsoft docs and tools geared towards C#, adding up unfamiliarity with the functional paradigm, most people follow C# way and completely ignore its little brother F#. I still think this is a missed 
opportunity for the .NET community. For example, let‚Äôs look at the excellent server side F# web framework <a href="https://giraffe.wiki/">Giraffe</a>. 
While C# and asp.net developers are busy memorizing the Microsoft way of handling requests, learning what attributes to decorate their
classes and members, the F# developers who use giraffe, simply rely on functional composition:</p>

<div><div><pre><code><span>let</span> <span>app</span> <span>=</span>
    <span>route</span> <span>"/"</span>
    <span>&gt;=&gt;</span> <span>setHttpHeader</span> <span>"X-Foo"</span> <span>"Bar"</span>
    <span>&gt;=&gt;</span> <span>setStatusCode</span> <span>200</span>
    <span>&gt;=&gt;</span> <span>setBodyFromString</span> <span>"Hello World"</span>
</code></pre></div></div>

<p>As HTTP processing is usually treated as a pipeline by itself on the server-side, it‚Äôs an excellent target for functional programming. Just like lego, plug-in your pipes, and you are good to go.</p>

<p>Furthermore, most developers worry about if they could find an F# job whereas companies who consider making the switch worry if they could find an F# developer.
As of today on linked in there are approximately 700 F# jobs and even most of these are not F# specific rather than they are like ‚ÄúC# or F# developers wanted‚Äù.</p>

<p>And most non-.NET people are not willing to touch anything related to Microsoft even with a 10 foot pole. (Of course, the major exceptions to this are TypeScript and Visual Studio Code which both are widely popular). The  Functional programmers‚Äô camp also dismisses F# at sight blaming it‚Äôs not like Haskell as in for example F# does not support type classes.</p>

<h2 id="couple-of-unique-features-of-f">Couple of unique features of F#</h2>

<p>I am not going to talk about the features of F# but just wanted to highlight a couple of them.</p>

<p>The first one is the file order. Please look at the below photo:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/files.png" alt="file-order"></p>

<p>In F# the order of the files matter. It is somewhat a disliked feature by the newcomers, but it makes the dependencies immediately visible.
So the code in the top file has no dependency on any others below and the 2nd file from the top only depends on the first. When you open a project which you are not 
familiar, file ordering helps to find your way.</p>

<p>The second one is Type Providers:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/sqlprovider.gif" alt="type-providers"></p>

<p>Type providers are somewhat code generators but they do that non-intrusively. Very roughly similar to LISP style macros they expand at compile time. Type providers make it very easy to discover HTML or JSON documents read database rows, file system, and discover DDL and rows within the coding screen without leaving your editor. And everything becomes so type-safe.</p>

<h2 id="develop-fantastic-ui-apps-with-f-and-elmish">Develop fantastic UI apps with F# and Elmish</h2>

<p>Well they say seeing is believing, so let‚Äôs see how well F# handles UI development. While React devs on Facebook trying to solve the state problem over and over again by using hooks and perhaps new experimental
recoil and contexts IMHO, all are horrible options as they encourage rendering code inter-mix with business code reminding me asp.net web forms times where you could write your SQL statements right into the page itself.</p>

<p>F# developers have ported elm architecture to something called elmish and it flourished well among F# community.</p>

<p>Here‚Äôs a list of things you can do with Elmish as you can write your business code once and port it to any UI platform below:</p>

<ul>
  <li>React: <a href="https://github.com/elmish/react">Elmish React</a></li>
  <li>Windows Desktop: <a href="https://github.com/elmish/Elmish.WPF">Elmish WPF</a></li>
  <li>Gaming: <a href="https://github.com/ChrisPritchard/Xelmish">Xelmish</a></li>
  <li>Cross platform UI: <a href="https://github.com/AvaloniaCommunity/Avalonia.FuncUI">Avalonia.FuncUI</a></li>
  <li>Mobile development: <a href="https://github.com/fsprojects/Fabulous">Fabulous</a></li>
  <li>Terminal: <a href="https://github.com/DieselMeister/Terminal.Gui.Elmish">Terminal.Gui.Elmish</a></li>
  <li>Web Assembly: <a href="https://fsbolero.io/">Bolero</a></li>
</ul>

<p>They all share the same single architecture: Elmish. So you can write your code for one and port it to another.</p>

<h2 id="getting-started-and-some-resources">Getting started and some resources</h2>

<p>If you want to get started to F#, the first place you should check out is <a href="https://fsharp.org/">F# Software Foundation</a></p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/fsf2.png" alt="fsharp-foundation"></p>

<p>As you can see FSharp Software Foundation offers mentorship programs periodically, which means you can have a free weekly 1 on 1 session with an experienced F# developer! As of today the program is open for people who want to have an F# mentor or want to be
an F# mentor. You can apply from <a href="https://docs.google.com/forms/d/e/1FAIpQLSdKgZaAcjf7ZxVqBZzyZcBi609BOc0etBnV5XhR6BMihdyYRw/viewform">here</a>.</p>

<p>If you are sold with F# there is one important point to highlight. Do not treat F#, just another language with different syntax especially if you are familiar
with Python, Ruby, JavaScript, C#, etc. You have to embrace functional programming as a paradigm. F# is a functional-first programming language. In other words,
although F# has OOP syntax as well, it mostly makes sense to use F# when you want to get benefit from functional programming concepts. If you try to program
F# the same way you program other imperative languages you won‚Äôt get much benefit.</p>

<p>If you are a C# develeoper and you want to start functional programming with F# this is the go-to book:
<em>Disclaimer: I do not know the author nor I am affiliated with the publisher by any way</em></p>

<p><a href="https://www.manning.com/books/functional-programming-in-c-sharp">Functional programming in C#</a></p>

<p>Although the book is mostly about C#, it will show you how painful to do functional programming with C# and only perhaps then you can develop
some love for F#. Having that said it will also help you to understand some more new coming but confusing features of C# 9 like Records and Pattern matching.
If you think  C# records are for immutability, no they are not. They are for Value semantics and <a href="https://www.sitepoint.com/what-is-referential-transparency/#:~:text=In%20functional%20programming%2C%20referential%20transparency,the%20result%20of%20the%20program.">referential transparency</a>.</p>

<p>To try F# right away you may use the following links:</p>

<p>https://try.fsharp.org/</p>

<p>https://fable.io/repl/</p>

<p>https://tryfsharp.fsbolero.io/</p>

<h2 id="syntax">Syntax</h2>

<p>When you are unfamiliar with F# syntax, it might look a bit cryptic. And I have seen some people complained that it is very verbose. On the contrary, I would make a bold claim that F# beats most other languages when it comes to conciseness. You don‚Äôt believe me? see it your self (make sure you check all implementations)</p>

<p><a href="https://rosettacode.org/wiki/Category:F_Sharp">F# problems on Rosetta Code</a></p>

<h2 id="a-couple-of-toy-projects-of-mine">A couple of toy projects of mine</h2>

<p>I have developed commercial applications with F#, but as public stuff here are a couple of projects I have built. One is a full blazor/web assembly project:</p>

<p>https://github.com/OnurGumus/FBlazorShop</p>

<p>And the actual app for the 3D bin packing problem, in which items of different volumes must be packed into a finite number of bins or containers each of a fixed given volume in a way that minimizes the number of bins used.</p>

<p>https://github.com/OnurGumus/BinDrake</p>

<p>http://bindrake.com/</p>

<p>Trying and learning F# really requires you to dismiss your prejudices and be patient. But in the end, once you master the functional paradigm,
it makes you sleep better as a developer.</p>


             
            
            
            
                  
         </section>
         
      </div>
   </div></div>]]>
            </description>
            <link>https://onurgumus.github.io/2021/01/31/What-the-F.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986316</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That‚Äôs Big Sir to You]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25984970">thread link</a>) | @zdw
<br/>
January 31, 2021 | https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/ | <a href="https://web.archive.org/web/*/https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Hey, folks. Sorry it's been a while, but it's been a busy time. Let's start with the bad news first.</p>

<h2>Bad news</h2>

<p>As you know, SuperDuper 3.3.1 cannot copy a volume with Big Sur on it. We're currently blocked on some issues I don't have direct control over, and as such I don't have a new version for you that <strong>fully</strong> supports Big Sur, nor a timeframe for when that will be released.</p>

<p>Right now, as many of you know, v3.3.1 <strong>will</strong> work with non-boot volumes, but it <strong>won't</strong> work with volumes that have macOS on them, because it will try to do some of the things that no longer work in macOS 11.</p>

<p>I know that's been a disappointment, but that's where we are with v3.3.1.</p>

<h2>Good news!</h2>

<p>However, after wracking my brain for <strong>far</strong> too long, I've come up with a <strong>workaround</strong> that will let you make the backups you need to save your files, and to supplement your Time Machine backup. And for that, we need to go Back...to the Future!</p>

<h2>Huh?</h2>

<p>Let me try to explain.</p>

<p>In Catalina, as I explain in <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/breaking_the_tape/">Breaking the Tape</a>, Apple split the startup volume into two parts: the System volume and the Data volume. We did a ton of work that year to support this new setup in a way that was transparent to the user; SuperDuper automatically creates the proper volumes, converts the drives to APFS as needed, etc.</p>

<p>Worked great.</p>

<p>In macOS 10.15.5, though, <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/black_boxes_and_bugs/">Apple broke 3rd party copy tools</a> in a way that couldn't be worked around without the use of <code>asr</code>, a low-level drive copy tool that has its own issues. They fixed that in 10.15.6...but it was a rather ominous sign for the future.</p>

<p>That ominous sign became terrifying reality in macOS 11. Due to the new Sealed System Volume, use of <code>asr</code> became mandatory if you wanted to make a copy that was bootable. And even <strong>that</strong> didn't work <strong>at all</strong> until <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/big_sur/">November 5th</a> of last year‚Äîjust before Big Sur's official release.</p>

<p>Even now, as of the time of this writing, <code>asr</code> won't make a bootable copy of an M1-based Mac.</p>

<p>So, as of Big Sur, 3rd party tools like SuperDuper can no longer make bootable copies on their own. For that, it's <code>asr</code> or nothing.</p>

<p>It is, indeed, <a href="https://mjtsai.com/blog/2007/06/13/a-very-sweet-solution/">a <em>very</em> <strong>sweet solution</strong></a>.</p>

<p>But, 3.3.1 doesn't know that. It tries to do all the special stuff that we had to do for Catalina, and those things no longer work. And so, as you've seen, that copy generates errors or seems to hang right at the start (because it's thrown exceptions that stop the copy).</p>

<h2>Didn't You Say "Good News"?</h2>

<p>I'm getting there.</p>

<p>SuperDuper! 3.3.1's magic was all about dealing with the split startup volume. It built on the APFS support and scheduling fixes we put into the previous version...and added new things for compatibility with Catalina.</p>

<p>But...what if it <strong>didn't</strong> do that? What if SuperDuper was...<strong>stupider</strong>?</p>

<h2>Wonderfully Awful</h2>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/oUUdW2bTa3Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>I've been testing this out for a while in-house. and I've come up with a weird-sounding workaround that...works!</p>

<p>Basically, you can use SuperDuper to copy the Data volume of the volume group. The result contains all <strong>your</strong> data and applications, can be restored in a few different ways...and can even be made bootable.</p>

<blockquote>
  <p>Note that, as I indicated above, M1 Macs <strong>can't readily boot from external drives</strong>. There are things you can do, if you have an external Thunderbolt 3 drive (USB-C isn't sufficient), but even that won't work if the internal drive is dead. Unless things change, bootable backups are basically a thing of the past on M1-based Macs.</p>
</blockquote>

<h2>How?</h2>

<p>It's actually easy. To accomplish this, use an old version of SuperDuper‚Äî<a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">specifically, v3.2.5</a>‚Äîto copy the Data volume, which is shown in the older version!</p>

<p>v3.2.5 is well tested, having been on the market for quite some time, and is reliable. So we don't have to worry about doing a broad beta test of a partially complete new release. It's already tested, and I've been busy doing the additional testing necessary to prove it works on Big Sur.</p>

<p>Again, this will make a copy of the data that you need to preserve <strong>your</strong> stuff, both Applications and Data, while leaving the Sealed System Volume alone.</p>

<p>And it's a valid source for "restore" during a clean install or migration! So restoration is <strong>easy</strong> and <strong>fast</strong> should it become necessary.</p>

<h2>Neat!</h2>

<p>Yeah, I wish I had thought of this earlier.</p>

<p>So, if you're on Big Sur, and you want to copy a startup drive, here's what to do:</p>

<ol>
<li>Make sure you have your license information handy. You can retrieve it from SuperDuper's Register... page should you need to.</li>
<li>Download and install <a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">SuperDuper! v3.2.5 from here</a>.</li>
<li>Remove SuperDuper! from the Security &amp; Privacy preference pane and restart your Mac. This is important, and works around an Apple bug triggered by the change of SuperDuper!'s bundle ID.</li>
<li>Run SuperDuper and follow the steps to add it back into Security &amp; Privacy.</li>
<li>If your license is missing, re-enter it from your license email. </li>
<li>Turn off "Check for Updates" in our Preferences so we don't nag you about v3.3.1.</li>
<li>Select the "Data" volume in the source pop-up, and a <strong>new</strong> APFS backup volume in the destination pop-up, along with "Backup - all files" (or whatever script you want).
&gt; If you already have a backup volume, you can use Disk Utility to delete <strong>just</strong> the System volume, rather than create a new one. After doing this, you may need to repair it with Disk First Aid before it will show up in SuperDuper.</li>
<li>Make your copy as normal, set up your schedule as needed, etc. Your regular Smart Updates will work as expected.</li>
</ol>

<p>To fully restore, it's easiest to boot to recovery, erase the internal drive you want to restore to, <a href="https://support.apple.com/en-us/HT204904">reinstall the OS from Recovery mode</a>, and then, when prompted to restore during the first boot of the fresh copy of macOS, point at the backup. All your data and applications will be brought in automatically.</p>

<blockquote>
  <p>If you want to make the backup bootable and have an Intel Mac, boot to Recovery (Cmd+R during power on) and install Big Sur to the backup drive. You can then start up from the backup. Note, though, that once made bootable, you can no longer copy <strong>to</strong> the backup until you delete the system volume as above. So <strong>don't</strong> do this unless you need to.</p>
</blockquote>

<h2>Forward-Looking Statements</h2>

<p>It seems clear that the future of bootable backups is unclear.</p>

<p>M1 Macs <strong>can't</strong> be copied in a way that makes them bootable. Bare metal recovery on an M1 Mac isn't possible, since they depend on the contents of their internal drive even when booting externally. And the tools required to make bootable copies of Intel Macs are limited, often fail, and produce inscrutable and undocumented diagnostics when they do.</p>

<p>Everything's a tradeoff, and with the M1 Macs, Apple has given us an amazing new platform, while taking away some of the things that made macOS such a joy to work with. And one of those things is bootable backups.</p>

<p>I have <strong>no idea</strong> if this is going to change for the better in whatever the next macOS version brings, and have no insight into Apple's future plans.</p>

<p>But I <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/practices_make_perfect_backups/">continue to advise multiple backup strategies</a>, including Time Machine (to an APFS volume under Big Sur), SuperDuper! (for a simple copy of your data and applications) and an online backup program (as a last resort).</p>

<p>With that, back to plugging away at a new version.</p>

<p>Thanks for reading, and for using SuperDuper.</p>

</div></div>]]>
            </description>
            <link>https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984970</guid>
            <pubDate>Mon, 01 Feb 2021 02:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NES.css ‚Äì NES-Style CSS Framework]]>
            </title>
            <description>
<![CDATA[
Score 687 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25982999">thread link</a>) | @dsego
<br/>
January 31, 2021 | https://nostalgic-css.github.io/NES.css/ | <a href="https://web.archive.org/web/*/https://nostalgic-css.github.io/NES.css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <a :class="{ active:  scrollPos < 200 }" href="https://github.com/nostalgic-css/NES.css" target="_blank" rel="noopener" @mouseover="startAnimate" @mouseout="stopAnimate">
            <p>Fork me<br>on GitHub</p>
            <i :class="animateOctocat ? 'animate' : ''"></i>
          </a>

          <!-- About -->
          <section>
            <h2 id="about"><a href="#about">#</a>About</h2>
            <p>NES.css is NES-style (8bit-like) CSS Framework.</p>
          </section>


          <!-- Installation -->
          <section>
            <h2 id="installation"><a href="#installation">#</a>Installation</h2>
            <p>NES.css is available via either npm or Yarn, or a CDN.</p>
            <p>Please read <a href="https://github.com/nostalgic-css/NES.css" target="_blank" rel="noopener">README.md</a>.</p>
          </section>

          <!-- Usage -->
          <section>
            <h2 id="usage"><a href="#usage">#</a>Usage</h2>
            <p>NES.css only provides components. You will need to define your own layout.</p>

            <section v-for="sample in collection" :key="sample">
              <section>
                <h3>{{ sample.title | capitalize }}</h3>
                
                <p v-if="sample.description">{{ sample.description }}</p>
                <p v-if="sample.note">{{ sample.note }}</p>
                
              </section>
              <section v-show="sample.showCode">
                
                <pre><code>{{ sample.code }}</code></pre>
              </section>
            </section>
          </section>

          <!-- Members -->
          <section>
            <h2 id="members"><a href="#members">#</a>Members</h2>
            <section>
              <h3><i></i>Core Team Members</h3>
              <p>Here is core team members developing NES.css.</p>

              
            </section>
            <section v-if="emeriti.length > 0">
              <h3><i></i>Core Team Emeriti</h3>
              <p>Here we honor some no-longer-active core team members.</p>

              
            </section>
            <section>
              <h3><i></i>Contributors</h3>
              <template v-for="user in contributors">
                <a class="contributor" :href="'https://github.com/' + user" target="_black">
                  <img class="nes-avatar is-large is-rounded lazy" :data-src="'https://github.com/' + user + '.png?size=64'" :alt="'Contributor ' + user">
                  <p>{{ user }}</p>
                </a>
              </template>
            </section>
          </section>

          <!-- Articles -->
          <section>
              <h2 id="articles"><a href="#articles">#</a>Articles</h2>
              <article>
                <h3>
                  <a href="https://medium.com/@bc_rikko/why-i-created-and-released-nes-css-ee8966bacd09" target="_blank" rel="noopener"><i></i><span>Why I created and released NES.css</span></a>
                </h3>
              </article>
              <article>
                <h3>
                  <a href="https://github.blog/2019-01-20-release-radar-december-2018/#nes-css-1-0" target="_blank" rel="noopener"><i></i><span>Release Radar¬∑December 2018|The GitHub Blog</span></a>
                </h3>
              </article>
          </section>

        </div></div>]]>
            </description>
            <link>https://nostalgic-css.github.io/NES.css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982999</guid>
            <pubDate>Sun, 31 Jan 2021 22:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and the Domestication of Users]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25982860">thread link</a>) | @upofadown
<br/>
January 31, 2021 | https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="https://schema.org/BlogPosting">
	<article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>I have never used WhatsApp, and never will. Despite this, I still feel the need to write an article about WhatsApp since it‚Äôs the perfect case study to help understand a class of businesses models I call ‚Äúuser domestication‚Äù. The domestication of users is high on my list of problems plaguing the human race, and is worth a detailed explanation.</p>
<p>WhatsApp wasn‚Äôt the first instant messenger of its kind, and probably won‚Äôt be the last. I simply chose to focus on WhatsApp since its recent privacy issues have made it a hot topic.</p>
<p>With the meta-explanation out of the way, let us begin.</p>
<h2 id="whatsapps-rise">WhatsApp‚Äôs rise</h2>
<p>For those unfamiliar, WhatsApp is a tool that makes it convenient and easy to help Facebook further its core mission: the optimization and auctioning of human behavior (colloquially known as ‚Äútargeted advertising‚Äù). It originally persuaded people to consent to this by allowing them to send text to each other over the Internet, something that was <a href="https://en.wikipedia.org/wiki/Comparison_of_instant_messaging_protocols">already possible</a>, and combining an easy-to-learn UI with successful marketing. It then expanded to include features such as free voice and video calls. Free calls helped it grow to become the de-facto communication platform many regions. I‚Äôm stunned at its ubiquity every time I visit my extended family in India; I‚Äôm frequently greeted by looks of confusion when I remind them that I don‚Äôt use WhatsApp.</p>
<p>Having its own proprietary chat system incompatible with other clients allowed WhatsApp to build a <a href="https://en.wikipedia.org/wiki/Network_effect">network effect</a>: WhatsApp‚Äôs existing users were held captive by the fact that leaving WhatsApp meant losing the ability to communicate with WhatsApp users. People switching from WhatsApp must convince all their friends to switch, too; this includes less technically inclined friends who had a hard time learning WhatsApp in the first place.</p>
<p>In a WhatsApp world, people who want to keep in touch must abide by the following rules:</p>
<ul>
<li>Everyone can only use the proprietary WhatsApp client to send messages; developing alternative clients isn‚Äôt supported.</li>
<li>Everyone‚Äôs mobile device must run an operating system supported by said client. Since WhatsApp developers will only write a client for popular operating systems, the Android and iOS duopoly strengthens.</li>
<li>Users fully depend on WhatsApp developers. If WhatsApp developers decide to include user-hostile features in the app, users must go with it. They can‚Äôt switch to a different server or client without switching away from WhatsApp and losing the ability to communicate with all their WhatsApp contacts.</li>
</ul>
<h2 id="user-domestication">User domestication</h2>
<p>WhatsApp rose by trapping previously-free beings in their corral and changing their habits to create dependence on masters. Over time, this made it difficult or impossible to return to their previous lifestyle. That process should sound familiar: it‚Äôs eerily similar to the domestication of animals. I call this type of vendor lock-in <strong>user domestication:</strong> the removal of user autonomy to trap users into serving vendors.</p>
<p>I chose this metaphor because animal domestication is a gradual process that isn‚Äôt always deliberate, and typically revolves around one group becoming dependent upon another. For example: there‚Äôs evidence that domestication of dogs began with socialization, resulting in not-entirely-artificial selection promoting genes that resulted in more friendliness with and dependence upon humans.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Whether it happens on purpose or by accident, user domestication almost always follows the same three steps:</p>
<ol>
<li>A high level of dependence given from users to a software vendor</li>
<li>An inability for users to control their software, through at least one of the following methods:
<ol>
<li>Preventing modification of the software</li>
<li>Preventing migration onto a different platform</li>
</ol>
</li>
<li>The exploitation of now-captive users who are unable to resist</li>
</ol>
<p>The completion of the first two steps left WhatsApp users vulnerable to user domestication. With investors to answer to, they had every incentive to implement user-hostile features without consequence.</p>
<p>So, of course, they did.</p>
<h2 id="whatsapps-descent">WhatsApp‚Äôs descent</h2>
<p>Domestication has a purpose: it enables a master species to exploit the domesticated species for its own gain.</p>
<p>Recently, WhatsApp updated its privacy policy to allow sharing data with its parent, Facebook. Users who agreed to use WhatsApp under its previous privacy policy had two options: agree to the new policy or be unable to use WhatsApp again. The WhatsApp privacy policy update is a classic bait-and-switch: WhatsApp lured users in with a sleek interface and the impression of privacy, domesticated them to remove their autonomy to migrate, and then backtracked on its previous commitment to privacy with minimal consequence. Each step in this process enabled the next; had user domestication not taken place, it would be easy for most users to switch away with minimal friction.</p>
<p>Those of us who were sounding the alarm a few years ago experienced a brief moment of sadistic bliss when our titles were upgraded from ‚Äúannoying and paranoid conspiracy theorists‚Äù to just ‚Äúannoying‚Äù.</p>
<h3 id="an-attempt-at-damage-control">An attempt at damage control</h3>
<p>The bait-and-switch operation incurred backlash significant enough for a noticeable minority of users to actually migrate; this number turned out to be slightly more than the rounding error WhatsApp was likely expecting. In response, WhatsApp delayed the change and published the following ad:</p>
<picture>
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.3e9ad6a0c2c8c377c4583cf92bddcd47.avif" type="image/avif" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.09f935219fb9d5ac9fa9bc4acb733d13.webp" type="image/webp" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.8792c2187d444ebc32bf8c386ea0cda9.png" type="image/png" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad.94ed78578e240dfd57f833807f8167ed.avif" type="image/avif">
	<source srcset="https://seirdy.one/p/whatsapp_ad.9efe174613a8b02274fa62feff7b8374.webp" type="image/webp">
	<source srcset="https://seirdy.one/p/whatsapp_ad.b81802ac13cd4a2540211e05819cd29e.png" type="image/png">
	<img width="600" src="https://seirdy.one/p/whatsapp_ad.png" alt="WhatsApp ad describing data not collected">
</picture>

<p>The ad lists various data that WhatsApp doesn‚Äôt collect or share. Allaying data collection concerns by listing data <em>not</em> collected is misleading. WhatsApp doesn‚Äôt collect hair samples or retinal scans either; not collecting that information doesn‚Äôt mean it respects privacy because it doesn‚Äôt change the information WhatsApp <em>does</em> collect.</p>
<p>The ad denies ‚Äúkeep[ing] logs of who everyone is messaging or calling‚Äù. Collecting data is not the same as ‚Äúkeeping logs‚Äù; it‚Äôs possible for metadata to be fed into an algorithm before being discarded. A model can thus learn that two users call each other frequently without keeping logs of the metadata for each call. The fact that they specifically chose to phrase this line around logging implies that WhatsApp either already collects this class of data or has deliberately left the door open to collecting it in the future.</p>
<p>A stroll through WhatsApp‚Äôs <a href="https://web.archive.org/web/20210124061525/https://www.whatsapp.com/legal/updates/privacy-policy/?lang=en">actual privacy policy</a> at the time reveals that they do collect considerable metadata used for marketing through Facebook.</p>
<h2 id="software-freedom">Software freedom</h2>
<p>With user domestication, providing useful software to users is a means to the end of exploiting them. The alternative is simple: make serving users the end in and of itself.</p>
<p>To prevent being controlled by software, users must be in control. Software that allows users to be in control is called <a href="https://en.wikipedia.org/wiki/Free_software">free software</a>. The word ‚Äúfree‚Äù in this context refers to freedom rather than price. Software freedom is similar to the concept of open-source, but the latter is focused on practical benefits rather than ethics. A less ambiguous term that neutrally refers to both free and open-source software is <strong><abbr title="free and open-source software">FOSS</abbr></strong>.</p>
<p>Others have <a href="https://www.gnu.org/philosophy/free-sw.en.html">explained</a> the concepts underpinning free software better than I can, so I won‚Äôt go into detail. It comes down to four essential freedoms:</p>
<ul>
<li>The freedom to run the program as you wish, for any purpose</li>
<li>The freedom to study how the program works, and change it so it does your computing as you wish</li>
<li>The freedom to redistribute copies so you can help others</li>
<li>The freedom to distribute copies of your modified versions to others</li>
</ul>
<h3 id="making-money-with-foss">Making money with FOSS</h3>
<p>The most common objection I hear is that FOSS makes it harder to make money.</p>
<p>The key to making money with FOSS is to make software a <a href="https://www.gwern.net/Complement">commoditized complement</a> of other, more profitable services. Examples of such services include selling support, customization, consulting, training, managed hosting, hardware, and certifications. Plenty of companies use this approach instead of building proprietary software: Red Hat, Collabora, System76, Purism, Canonical, SUSE, Hashicorp, Databricks, and Gradle are some names that come to mind.</p>
<p>Managed hosting isn‚Äôt a basket worth all your eggs if giants like AWS can do the same at a lower price. Being the developer can give an edge in areas like customization, support, and training; it doesn‚Äôt offer as obvious an advantage when it comes to hosting.</p>
<h2 id="foss-isnt-always-enough">FOSS isn‚Äôt always enough</h2>
<p>Free software is a necessary but sometimes insufficient requirement to build domestication immunity. Two more measures include <strong>simplicity</strong> and <strong>open platforms.</strong></p>
<h3 id="simplicity">Simplicity</h3>
<p>When software grows too complex, it needs to be maintained by a large team. Users who disagree with a vendor can‚Äôt easily fork and maintain a multi-million-line codebase, especially if the software in question potentially contains security vulnerabilities. Dependence on the vendor can grow quite problematic when complexity causes development costs to skyrocket; the vendor might resort to implementing user-hostile features to stay afloat.</p>
<p>Complex software that can‚Äôt be developed by a different group of people creates dependence, step one of user domestication. That alone is enough to open the door to problematic developments.</p>
<h4 id="case-study-mozilla-and-the-web">Case study: Mozilla and the Web</h4>
<p>Mozilla was a ray of hope in the browser wars, a space dominated by adtech, surveillance, and vendor lock-in. Unfortunately, developing a browser engine is a monumental task difficult enough for Opera and Microsoft to give up and re-skin Chromium. Browsers are more than the document readers they were meant to be: they‚Äôve evolved into application runtimes with their own stacks for GPU acceleration, Bluetooth, permissions, device enumeration, bundled media codecs, <abbr title="digital rights management">DRM</abbr><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, extension APIs, developer tools‚Ä¶the list goes on. It takes billions of dollars a year to respond to vulnerabilities in such a massive attack surface and keep up with a standard that grows at such a worrying rate. Those billions have to come from somewhere.</p>
<p>Mozilla ended up having to make major compromises to stay afloat. It cut search deals with blatantly user-hostile companies, and bundled the browser with <a href="https://blog.mozilla.org/advancingcontent/2014/02/11/publisher-transformation-with-users-at-the-center/">ads</a> and bloatware such as a partially ‚Ä¶</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982860</guid>
            <pubDate>Sun, 31 Jan 2021 21:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: YaHNd ‚Äì HN Books: The Best Books of Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25980892">thread link</a>) | @yaj54
<br/>
January 31, 2021 | https://yahnd.com/books/ | <a href="https://web.archive.org/web/*/https://yahnd.com/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://yahnd.com/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980892</guid>
            <pubDate>Sun, 31 Jan 2021 18:01:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cab Ride: Drive a train, forever, through a dreamlike land]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25980060">thread link</a>) | @polm23
<br/>
January 31, 2021 | https://powersaurus.itch.io/cab-ride | <a href="https://web.archive.org/web/*/https://powersaurus.itch.io/cab-ride">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Drive a train, forever, through a dreamlike land. <br></p>
<p>Transport passengers to their destination.</p>
<p>Watch the world go by.</p>
<p>Listen to chilled out chiptune music.</p>
<p>In Cab Ride you can drive thousands of different train routes through rolling hills, winding tunnels and weaving between the tall buildings&nbsp;of vast cities. You can drive the train for as long as you like. When you're ready to end your journey, hold down the left arrow key to announce the last station. Stopping at stations along the way means you can pick up and drop off passengers. Try and stop at the marker at each station for a high rating. Or don't! It's up to you.</p>
<p>Cab Ride is a casual train simulation, not aiming for real world accuracy, but like a real train, it takes a while to brake. If you're overshooting stations, watch for the alert for the next station and reduce the throttle so you're ready to stop.</p><p>You can get the PICO-8 cart on the <a href="https://www.lexaloffle.com/bbs/?tid=41332" rel="nofollow noopener">PICO-8 BBS</a> (also play in your browser there if you prefer)<br></p>
<h2>Controls</h2>

<h2>Credits</h2>
<p>Programming - Ben Jones / <a href="https://twitter.com/Powersaurus" rel="nofollow noopener">@Powersaurus</a><br></p>
<p>Music - Stephen 'rych-t' Jones / <a href="https://twitter.com/rych_t" rel="nofollow noopener">Twitter</a> / <a href="https://www.instagram.com/rych_t/" rel="nofollow noopener">Instagram</a> / <a href="https://soundcloud.com/floor-machoor" rel="nofollow noopener">Soundcloud</a><br></p>
<p>Based on code from tutorials by Tom Mulgrew <a href="https://www.lexaloffle.com/bbs/?tid=35767" rel="nofollow noopener">https://www.lexaloffle.com/bbs/?tid=35767</a> licensed under Creative Commons 4 (CC BY 4.0) <a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow noopener">https://creativecommons.org/licenses/by/4.0/<br></a></p>
<p><span></span><a href="https://www.lexaloffle.com/pico-8.php?page=manual" rel="nofollow noopener">Made using PICO-8</a></p></div></div>]]>
            </description>
            <link>https://powersaurus.itch.io/cab-ride</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980060</guid>
            <pubDate>Sun, 31 Jan 2021 16:44:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Should Start an App Store]]>
            </title>
            <description>
<![CDATA[
Score 807 | Comments 286 (<a href="https://news.ycombinator.com/item?id=25979774">thread link</a>) | @quaintdev
<br/>
January 31, 2021 | https://www.ankshilp.com/time_for_github_app_store/ | <a href="https://web.archive.org/web/*/https://www.ankshilp.com/time_for_github_app_store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><header>
    <div>
        <p><a href="https://www.ankshilp.com/">
                <img id="home-image" src="https://www.ankshilp.com/images/avatar.png">
            </a>
        </p>
        
    </div>
    <hr>
</header>
<div>
    <div>
        <h2 id="github-should-start-an-app-store">GitHub Should Start An App Store</h2>
<p>Yesterday, Google suspended Elements - matrix chat app - from play store <a href="https://news.ycombinator.com/item?id=25965443">without any reasonable explanation</a>. I think this was an automated removal triggered by user reports or some other factors. The matrix team tried to reach out to them for explanation to no avail. We have seen this pattern in many cases now. Either it‚Äôs getting overwhelming for Google to monitor apps in its store or they don‚Äôt want apps like Elements which is decentralized to be on their store. The later mostly seems like a conspiracy theory and I think former is more true. In any case, it doesn‚Äôt make any sense for a single entity to govern what gets installed and not on billions of devices. A decentralized app store whould be best to fight this sort of suspensions but it‚Äôs far from reality at the moment. The alternative? GitHub App Store.</p>
<h3 id="but-why-github">But Why GitHub?</h3>
<p>Few reasons why I think GitHub is our best bet:</p>
<ol>
<li>They already host source code of millions of apps. Release integration should be trivial to implement.</li>
<li>Unlike Google they actually listen to their users. They were awesome during <a href="https://github.blog/2020-11-16-standing-up-for-developers-youtube-dl-is-back/">youtube-dl</a> debacle.</li>
<li>Backed by Microsoft. Microsoft has been playing good by the developers for years now. I trust them more than Apple and Google.</li>
<li>They could finally give the desktop the app store it deserves</li>
<li>This is a minor but users will be able to raise issues with developers directly instead writing comments over app pages which I think you would agree completely suck.</li>
</ol>
<p>They will have to create app store applications for major platforms along with provision to host closed source applications on their store and they should be good to go. Honestly I can not imagine any other player being more successful in app stores than GitHub.</p>
<p><em>Update: <a href="https://twitter.com/element_hq/status/1355663753380032512">Google has reinstated Elements</a></em></p>

    </div>

            </div>
        </div></div>]]>
            </description>
            <link>https://www.ankshilp.com/time_for_github_app_store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979774</guid>
            <pubDate>Sun, 31 Jan 2021 16:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Robinhood disabled buys but not sells]]>
            </title>
            <description>
<![CDATA[
Score 699 | Comments 677 (<a href="https://news.ycombinator.com/item?id=25979673">thread link</a>) | @stu2b50
<br/>
January 31, 2021 | https://stu2b50.dev/posts/why-robinhood-d3580b | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/why-robinhood-d3580b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        <p>There's been enough time for the dust to settle and for Robinhood's actual reason for halting trades to come out. But the question of why only buys and not sells has not really been answered in detail, and that's mainly because it's a pain-in-the-ass and delves deep into how the deposit requirements are calculated by the DTCC for brokers. </p>
<h2>First, what happened</h2>
<p>On that fateful day, Gamestop stock had massive volatility, and given the cries of "Buy!" and "Hold!" from /r/WSBs, I'd assume on Robinhood, a broker targeted at retail investors, it'd be heavily imbalanced towards buy trades.</p>
<p>As volatility increased, the DTCC (Depository Trust &amp; Clearing Corporation) increased the deposit requirements for brokers. Basically, when you submit a trade on a broker, the exchange of money for stock doesn't actually happen until 2 days later, and the firm that handles that exchange is called a clearing firm. Before then, Robinhood just sends records: John bought 2 GME for $600, Mary sold 1 GME for $290. If that's all that happened that day, then Robinhood would need to provide $310 dollars to the clearing firm, and receive 1 stock.</p>
<p>That's a credit risk - what if Robinhood doesn't have the money on settlement? The clearing firm would be on the hook. So the DTCC requires that brokers put up a deposit beforehand. On that day, the DTCC massively increased the deposit requirements for brokers</p>
<blockquote>
<p>A spokesman for the DTCC wouldn‚Äôt specify how much it required from specific firms but said that by the end of the day industrywide collateral requirements jumped to $33.5 billion, up from $26 billion.</p>
</blockquote>
<p><a href="https://www.bloomberg.com/opinion/articles/2021-01-29/reddit-traders-on-robinhood-are-on-both-sides-of-gamestop">Levine</a></p>
<blockquote>
<p>The amount required by clearinghouses to cover the settlement period of some securities rose tremendously this week. How much? To put it in perspective, this week alone, our clearinghouse-mandated deposit requirements related to equities increased ten-fold. </p>
</blockquote>
<p><a href="https://blog.robinhood.com/news/2021/1/29/what-happened-this-week">Robinhood</a></p>
<p>So, Robinhood legally could not submit trades on $GME until they could muster the deposits for GME that they needed. And they quickly <a href="https://www.cnn.com/2021/01/29/investing/robinhood-gamestop-reddit/index.html">scrounged up some capital</a> so they could continue on Friday.</p>
<h3>Robinhood's Clearing Firm</h3>
<p>Robinhood actually has their own clearing firm, Robinhood Securities... for some reason, but it's still a DTCC member and must listen to what the SEC regulates. </p>
<h3>update 12:32 - On margin?</h3>
<p>Some people seem to be mistaking the situation. It is not about margin accounts - while yes, Robinhood "instant transfers" provides the illusion of being instant effectively with margin, it's not really the issue here.</p>
<p>Brokers cannot use client money to satisfy their clearing fund obligation.  So whether or not the accounts had a settled balance didn't matter - as you can see from the other brokers which halted buys and did not have "instant transfers".</p>
<p>Again, this is about what's effectively <em>collateral</em> the brokers must put up so that all parties can mitigate the risk of a broker failing. Of course client money is used when the transaction <em>settles</em>, but, naturally, you can't use their money, which isn't yours, as collateral.</p>
<h2>But why ONLY Buys?</h2>
<p>The deposit requirement is </p>
<p><code>deposit = min( 99% 2d VaR + Gap Risk Measure, Deposit Floor Calc) + Mark-to-Market</code></p>
<p>And the variable to look at is the 99% 2d VaR</p>
<blockquote>
<p>The volatility component is designed to capture the market price risk associated with each Member‚Äôs portfolio at a 99th percentile level of confidence. The VaR Charge is the volatility component applicable to most Net Unsettled Positions, and usually comprises the largest portion of a Member‚Äôs Required Deposit. Procedure XV of the Rules currently provides that the VaR Charge shall be calculated in accordance with a generally accepted portfolio volatility margin model utilizing assumptions based on reasonable historical data and an appropriate volatility range. As such, NSCC currently calculates a Member‚Äôs VaR Charge utilizing the VaR model, which incorporates an EWMA volatility
estimation. </p>
</blockquote>
<p><a href="https://www.sec.gov/rules/sro/nscc-an/2018/34-82631.pdf">SEC</a></p>
<p>Remember when I subtracted John's buys of $600 with Mary's sell of $290 to get $310? That's the broker's net unsettled cash positions. The 99% VaR is basically, "99% of the time the broker's net unsettled will not be higher than X". You might remember if you took statistics about confidence intervals; this is the upper 99% confidence interval.</p>
<h3>Bad Desmos Graphs</h3>
<p>So, let's model our risk as a Normal curve, for simplicity's sake. Here I've graphed a normal distribution with a line representing the 95% percentile</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r1.png" alt=""></p>
<p>The Y axis is probability, the X axis is Robinhood's net unsettled positions. The more positive, the more money they'd owe theoretically.</p>
<p>Now, what happens if more people buy than sell? Then it'd shift over to the right</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r2" alt=""></p>
<p>Hasn't the 95% percentile moved rightward as well? Now, what happens if the market is super volatile (i.e, the std dev of the distribution increases)</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r3" alt=""></p>
<p>Wow, now it's even more to the right! </p>
<p>As you can see, <strong>buys make this worse</strong>, <strong>sells make it better</strong>. Robinhood <em>could not</em> execute buys, because it would increase the deposits they'd need, which they legally must obligate by.  Sells, on the other hand, do not have this problem. They would not push the 95% boundary more to the right.</p>
<h2>The Decision</h2>
<p>So really, it's not a bad decision or good decision that Robinhood halted buys of GME - it wasn't a decision, and it wasn't something they alone did.</p>
<p>These brokers halted buys of GME</p>
<ul>
<li>Robinhood</li>
<li>Webull</li>
<li>M1 Finance</li>
<li>Public</li>
<li>E-Trade</li>
</ul>
<p>While others only halted options</p>
<ul>
<li>Interactive</li>
<li>TDA</li>
<li>Schwab</li>
<li>Tradeing212</li>
</ul>
<p>Hmm, see a pattern? The former group includes companies like Robinhood (2013), WeBull (2017), M1 Finance (2015), while the latter has TDA (1975), Schwab(1971), Trading212 (2004).</p>
<p>(Okay, E-Trade is actually old too, but I guess they're just cash-strapped right now?)</p>
<p>Looks like young brokers with a limited capital resources to me.</p>
<h2>Stay or Switch?</h2>
<p>If there's something to fault Robinhood, it's that they're a young, janky broker (and also you might be getting screwed on the spread by Citadel). If they had more money on-hand they might not have had to stop buys of Gamestop. Perhaps they should have expected this and raised more capital earlier. </p>
<p>And that's a real reason to stay away from Robinhood. But for the love of god do not swap to WeBull or something if that's your concern.</p>
<p>And don't do it because you're abhorred by Robinhood's class warfare or something. Because that didn't happen - it was a mixture of SEC regulations and a cash-strapped startup (well, cash-strapped on big broker scales).</p>
<p>Although if you want to get mad at Hedge Funds anyway, feel free! You should always be mad at Hedge Funds. But please pick a real reason - you have no lack of choice to pick from.</p>

    </div>
  

      </div>
    </div></div>]]>
            </description>
            <link>https://stu2b50.dev/posts/why-robinhood-d3580b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979673</guid>
            <pubDate>Sun, 31 Jan 2021 15:55:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IoT Network Watches You as You Shop ‚Äì Without Cameras]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25979480">thread link</a>) | @adunk
<br/>
January 31, 2021 | https://www.thingsquare.com/blog/articles/iot-mesh-retail/ | <a href="https://web.archive.org/web/*/https://www.thingsquare.com/blog/articles/iot-mesh-retail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section><p>Online retailers know a lot about how their customers are navigating their virtual stores. Offline retailers are not so&nbsp;lucky.</p>
<p>Together with consumer behavior experts <a href="https://b-clarity.com/2020/01/08/what-is-the-role-of-touching-in-store/" target="_blank">B:Clarity</a> and a multinational home appliance brand we built a system to help understand customer movement and&nbsp;behavior.</p>
<p>The system consists of wireless sensors that are installed in electronics stores. A few hundred sensors in each&nbsp;store.</p>
<p>There are two types of&nbsp;sensors:</p>
<ul>
<li>Vibration sensors. That trigger when someone is trying out a&nbsp;product.</li>
<li>Light sensors. Trigger when someone is standing in front of a&nbsp;product.</li>
</ul>
<p>With these sensors, we can see what items are most popular, how it correlates to sales data ‚Äì and how to take action to improve&nbsp;sales.</p>
<p>But without collecting any <a href="https://en.wikipedia.org/wiki/Personal_data" target="_blank">personally identifiable information</a>.</p>
<p>This is what the sensors look&nbsp;like:</p>
<div>
<div data-animation="quicksand" data-x-gap="16" data-y-gap="16" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 2},
{&quot;width&quot;: 1100, &quot;cols&quot;: 2},
{&quot;width&quot;: 800, &quot;cols&quot;: 2},
{&quot;width&quot;: 480, &quot;cols&quot;: 2},
{&quot;width&quot;: 300, &quot;cols&quot;: 2}
]">

<p><a href="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor1.jpg" data-title="Laptops with IoT shopping sensors">
<img width="704" height="938" data-src="sensor1.jpg" alt="Laptops with IoT shopping sensors" src="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor1.jpg">
<span>
<span>
<span></span>
</span>
</span>
</a>
</p>


<p><a href="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor2.jpg" data-title="Cleaning equipment with IoT shopping sensors">
<img width="661" height="881" data-src="sensor2.jpg" alt="Cleaning equipment with IoT shopping sensors" src="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor2.jpg">
<span>
<span>
<span></span>
</span>
</span>
</a>
</p>

</div>
</div>


<p>And this is where they are&nbsp;installed:</p>



<h2 id="why-monitor-shoppers-">Why monitor&nbsp;shoppers?</h2>
<p>Online retailers and e-commerce has many ways to gain insight into their customers. Examples include seeing the <a href="https://help.shopify.com/en/manual/reports-and-analytics/shopify-reports/report-types/behaviour-reports#top-online-store-searches" target="_blank">toplist of searched-for items</a>, and the <a href="https://help.shopify.com/en/manual/reports-and-analytics/shopify-reports/report-types/behaviour-reports#top-online-store-searches-with-no-results" target="_blank">toplist of searched-for items with no results</a>.</p>
<p>Physical retailers don‚Äôt want to be left&nbsp;behind.</p>
<p>So many different ways to monitor shoppers in physical stores have been&nbsp;developed.</p>
<p>Amazon Go stores extensively <a href="https://techcrunch.com/2018/01/21/inside-amazons-surveillance-powered-no-checkout-convenience-store/" target="_blank">use cameras</a> to track everything that happens inside their&nbsp;stores.</p>
<p>Many stores provide free WiFi so that they can <a href="https://www.retaildive.com/spons/wi-fi-tracking-a-data-gold-mine-or-privacy-nightmare/572937/" target="_blank">track their customers</a>.</p>
<p>All these solutions have a big problem:&nbsp;privacy.</p>
<p>Cameras see everything ‚Äì much more than they need. And this data is collected and stored. Free WiFi hotspots may capture all kinds of&nbsp;traffic.</p>
<p>This is an obvious privacy problem for the&nbsp;shoppers.</p>
<p>But it is not just a problem for the&nbsp;shoppers.</p>
<p>It also creates a major problem for the companies storing the data: <a href="https://techcrunch.com/2019/09/19/silicon-valley-terrified-california-privacy-law/" target="_blank">personally identifiable data is a liability</a>.</p>
<p>This is why we chose vibration sensors and light sensors. No liability from owning any personally identifiable&nbsp;information.</p>
<p>With only vibration and light, there simply is nothing there to identify individual&nbsp;shoppers.</p>
<div>
<div>
<div data-src="washingmachines.jpg">
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Our IoT shopper system uses simple sensors: vibration and light.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="understanding-shopper-behavior">Understanding shopper&nbsp;behavior</h2>
<p>As a shopper, you want to find the best products, and ‚Äì ideally ‚Äì pay the lowest possible&nbsp;price.</p>
<p>The retailers and producers have slightly different&nbsp;motivations:</p>
<ul>
<li>Brands want customer to buy their products, and not their&nbsp;competitors‚Äô</li>
<li>Retailers want to sell more&nbsp;products</li>
</ul>
<p>And when the motivations of shoppers, retailers, and brands align, business is made. And the more business, the better for&nbsp;all.</p>
<p>Understanding customer behavior is key to improving the experience for&nbsp;everyone.</p>
<p>The sensors detect when people are looking at items. And they report this immediately, so that we can see in real-time where shoppers&nbsp;are.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Shopper hotspots: the IoT mesh network collects its data in real-time, so that we can see where shoppers are ‚Äì right now.
</small>
</p>
</div>
</div>
</div>

<p>But the data is also posted to a backend database. This lets us to more <a href="https://b-clarity.com/case/100-000-human-interactions-cant-be-wrong-touch-increases-sales/" target="_blank">in-depth, off-line analysis</a> of the data, see how it changes over time, and how it improves the&nbsp;sales.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The data is also stored in a backend database so that we can run powerful off-line analytics on the data.
</small>
</p>
</div>
</div>
</div>

<p>To be able to cover large electronics stores, we use a wireless IoT mesh&nbsp;network.</p>
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Electronics stores are large. But a wireless sub-GHz IoT mesh network can easily cover the entire area.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="why-use-a-wireless-iot-mesh-network-">Why use a wireless IoT mesh&nbsp;network?</h2>
<p>A wireless mesh network is a wireless network that automatically extend its&nbsp;range.</p>
<p>The Thingsquare IoT mesh network solution uses so-called <a href="https://www.thingsquare.com/blog/articles/what-is-subghz-networking/" target="_blank">sub-GHz wireless technology</a> that has way better range than traditional WiFi or&nbsp;Bluetooth.</p>
<p>But even with a longer range, it is not always&nbsp;enough.</p>
<p>Electronics stores can be very large. And there is plenty of metal inside them that hampers the wireless&nbsp;coverage.</p>
<p>A mesh network is the ideal technology in these&nbsp;situations:</p>
<ul>
<li><p><strong>Coverage</strong>. Electronics stores can be huge. With a mesh network, we can cover it&nbsp;all.</p>
</li>
<li><p><strong>It just works</strong>. No network planning is&nbsp;needed.</p>
</li>
<li><p><strong>Easy to install</strong>. Just put each device where it should&nbsp;be.</p>
</li>
<li><p><strong>Easy to maintain</strong>. If there are issues with coverage, just add extenders as&nbsp;needed.</p>
</li>
<li><p><strong>Robustness</strong>. If something changes, the network will automatically adapt and&nbsp;overcome.</p>
</li>
</ul>
<p>This is what the wireless mesh network typically looks&nbsp;like:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The IoT mesh network uses range extenders to cover the entire area of the electronics store.
</small>
</p>
</div>
</div>
</div>

<p>In this deployment, the mesh network used one access point and two extenders. Most device are able to reach the access point directly, but some chose to talk to one of the&nbsp;extenders.</p>
<h2 id="battery-life">Battery&nbsp;life</h2>
<p>The sensors are equipped with batteries: one coin-cell battery&nbsp;each.</p>
<p>The Thingsquare IoT mesh system is <a href="https://www.thingsquare.com/blog/articles/sensortag-power/" target="_blank">tailored for extreme low-power operation</a>. Extreme low-power operation in this case means that the sensors can go for several months one a single&nbsp;charge.</p>
<p>For example, the sensors are automatically turned off at night, to conserve their precious&nbsp;power.</p>
<p>But most importantly, the Thingsquare system continuously collects power consumption data from each and every&nbsp;sensor.</p>
<p>This data lets us see the exact behavior at any given time: are there any sensors that behave in a way that require their batteries to be replaced earlier? The Thingsquare system knows the answers to this, and alerts us if this would be the&nbsp;case.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Each sensor measures and reports a detailed break-down of their power consumption.
</small>
</p>
</div>
</div>
</div>

<h2 id="connectivity">Connectivity</h2>
<p>The ioT mesh network is connected to the Internet via a 4G modem. The network maintains a stable encrypted connection to the backend system so that the devices always can be&nbsp;reached.</p>
<p>If the Internet connection would go down at any point during the deployment, the devices hold off from reporting their data until the Internet connection is&nbsp;restored.</p>
<p>With this technique, no data is ever&nbsp;lost.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
A vibration sensor installed on top of a washing machine.
</small>
</p>
</div>
</div>
</div>

<h2 id="technical-details">Technical&nbsp;details</h2>
<p>The software used in the project is the <a href="https://www.thingsquare.com/iot-platform/" target="_blank">Thingsquare IoT platform</a>, with its wireless mesh network and the backend controller in the&nbsp;cloud:</p>
<ul>
<li>Thingsquare‚Äôs IoT mesh <a href="https://www.thingsquare.com/blog/articles/what-is-subghz-networking/" target="_blank">Sub-GHz</a> radio&nbsp;technology</li>
<li>Thingsquare‚Äôs IoT mesh IPv6 networking and the <span>RPL</span> mesh routing&nbsp;protocol</li>
<li><span>TLS</span> end-to-end&nbsp;encryption</li>
<li><a href="https://www.thingsquare.com/blog/articles/channel-hopping/" target="_blank">Channel hopping</a> to avoid problematic radio&nbsp;channels</li>
<li>Cloud deployment on&nbsp;<span>AWS</span></li>
</ul>
<p>The project uses the following hardware&nbsp;components:</p>
<ul>
<li>The Texas Instrument <span>CC1350</span> wireless System-on-a-Chip (which is an earlier version of the current <a href="https://www.ti.com/tool/LPSTK-CC1352R" target="_blank"><span>CC1352R</span> SoC</a> that we currently&nbsp;use)</li>
<li>An <a href="https://invensense.tdk.com/products/motion-tracking/9-axis/mpu-9250/" target="_blank"><span>MPU9250</span> accelerometer</a> to detect&nbsp;vibrations</li>
<li>An <a href="https://www.ti.com/product/OPT3001" target="_blank"><span>OPT3001</span> digital ambient light sensor</a> to measure changes in lighting&nbsp;conditions</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>This project is a multi-year collaboration between a Thingsquare customer and a major multinational home appliance brand. Thingsquare is the technology partner, providing our wireless IoT technology and expertise to make the project come&nbsp;true.</p>
<p>Are you looking to build an IoT project with extreme requirements in terms of scale, coverage, or power consumption? <a href="#" data-modal-target="#start">Get in touch with us today</a> to see how we can help you make your project come&nbsp;true!</p>
</section>
        </div></div>]]>
            </description>
            <link>https://www.thingsquare.com/blog/articles/iot-mesh-retail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979480</guid>
            <pubDate>Sun, 31 Jan 2021 15:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rome in 3D]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25979436">thread link</a>) | @GizmoSwan
<br/>
January 31, 2021 | https://relivehistoryin3d.com/projects/rome-in-3d/ | <a href="https://web.archive.org/web/*/https://relivehistoryin3d.com/projects/rome-in-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div id="primary"><main id="main" role="main"> <img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-400x225.jpg 400w"><p>What is our ‚ÄúRome in 3D‚Äù project in general? Broadly speaking, it is an attempt to give you an opportunity to take a look at Rome as it really was, by the eyes of humans who lived there in that time. Due to this, we are already paying much attention (and will proceed) to the level of details, adding realistic materials, colors, visual and weather effects. That‚Äôs why we are concentrating just on the center of the Rome for now, just to focus on quality and details.</p><p>Now we are planning to add a little additional territory (such as Circus Maximus, Velabrum area), and release our project as a 3d walkthrough application. I hope we will be able to complete it in a year approximately.</p> <img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-400x225.jpg 400w"><p>Boasting some impressive in-video lighting features, the animation focuses on the monumental scale that was flaunted by Rome during its apical architectural stage. And furthermore according to&nbsp; the animators of this video ‚Äì this movie is just a promo, with the entire scope (which took years to animate) to be inducted into a game engine that would be accessible to the interested people.</p><figure id="attachment_92" aria-describedby="caption-attachment-92"><img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-400x225.jpg 400w"><figcaption id="caption-attachment-92"><strong>Baths of Caracalla</strong></figcaption></figure><p>The ¬´ History in 3D ¬ª creative team continues working on a virtual reconstruction of ancient Rome. Our goal is to carry out this project at a new qualitative level using modern available data and technical capabilities. Some time ago, three video trailers about Rome in 3D reconstruction have already been released on our YouTube channel, representing the various stages of work on the reconstruction. Since the recent video was released, a lot of work has been done to update and expand the content, and we believe that the project has been transformed crucially and reached a new level of quality.</p><p>Here, our 3rd trailer about Colosseum district:<br></p><center><br> <iframe title="&quot;HISTORY IN 3D&quot; - ANCIENT ROME 320 AD -  3rd trailer &quot;Walking around Colosseum&quot;" width="500" height="281" src="https://www.youtube.com/embed/btKooS7k3nw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></center><br> &nbsp;<hr><h2>Recent project articles</h2><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src=""></p>   </div></main></div></div></div>]]>
            </description>
            <link>https://relivehistoryin3d.com/projects/rome-in-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979436</guid>
            <pubDate>Sun, 31 Jan 2021 15:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an IKEA Coffee Table into a DIY Server Rack]]>
            </title>
            <description>
<![CDATA[
Score 408 | Comments 195 (<a href="https://news.ycombinator.com/item?id=25978013">thread link</a>) | @thejokersthief
<br/>
January 31, 2021 | https://wiki.eth0.nl/index.php/LackRack | <a href="https://web.archive.org/web/*/https://wiki.eth0.nl/index.php/LackRack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div><div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack_manual_page_1_400x566.png"><img alt="" src="https://wiki.eth0.nl/images/3/33/Lackrack_manual_page_1_400x566.png" decoding="async" width="400" height="566" data-file-width="400" data-file-height="566"></a></p></div></div>



<div><div><p><a href="https://wiki.eth0.nl/index.php/File:LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/7a/LackRack.jpg" decoding="async" width="400" height="300" data-file-width="3072" data-file-height="2304"></a></p><div><p>The first implementation: Red LackRack with Ethernet switch and table lamp</p></div></div></div>
<p>First occurrence on <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Winter" title="Eth0:2010 Winter">eth0:2010 Winterlan</a>, the LackRack is the ultimate, low-cost, high shininess solution for your modular datacenter-in-the-living-room. Featuring the <a rel="nofollow" href="http://www.ikea.com/us/en/catalog/products/40104270">LACK</a> (side table) from Ikea, the LackRack is an easy-to-implement, exact-fit datacenter building block.
It's a little known fact that we have seen Google engineers tinker with Lack tables since way back in 2009.
</p><p>The LackRack will certainly make its appearance again this summer at <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Summer" title="Eth0:2010 Summer">eth0:2010 Summer</a>.
</p>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack-offline.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/79/Lack-offline.jpg" decoding="async" width="250" height="244" data-file-width="250" data-file-height="244"></a></p><div><p>When temporarily not in use, multiple LackRacks can be stacked in a space-efficient way <i>without disassembly</i>, unlike competing 19" server racks.</p></div></div></div><p>The LackRack was first seen on <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Winter" title="Eth0:2010 Winter">eth0:2010 Winterlan</a> in the no-shoe Lounge area. Its low-cost and perfect fit are great for mounting up to 8 U of 19" hardware, such as switches (see below), or perhaps other 19" gear. It's very easy to assemble, and thanks to the design, they are stable enough to hold (for example) 19" switches and you can put your bottle of Club-Mate on top! Multi-shiny LackRack can also be painted to your specific preferences and the airflow is unprecedented!
</p>
<p>You can find a howto on buying a LackRack on <a rel="nofollow" href="http://mrngm.com/eth0/LackRack/">this page</a>. This includes the proof that a 19" switch can indeed be placed in the LackRack in its natural habitat!
</p>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack-w-switch.jpg"><img alt="" src="https://wiki.eth0.nl/images/d/d7/Lackrack-w-switch.jpg" decoding="async" width="250" height="188" data-file-width="2592" data-file-height="1944"></a></p><div><p>Close-up of the LackRack, with a switch, in its natural habitat (the IKEA)</p></div></div></div>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:5x_lackrack.jpg"><img alt="" src="https://wiki.eth0.nl/images/9/99/5x_lackrack.jpg" decoding="async" width="250" height="250" data-file-width="800" data-file-height="800"></a></p><div><p>Illustration of the LackRack's modularity</p></div></div></div><p><i>For assembly in terms of a programming language, this is not the page you need.</i>
</p><p>However, in order to assemble the LackRack, there are a few prerequisites or tools that are needed:
</p>
<ul><li>1 (or more) LACK side table from Ikea</li>
<li>Screwdriver (whether muscle-driven or motor-driven, with preference of the latter)</li>
<li>Wood screws (they should fit in the rack mounts on your appliance, and not exceed 1" in length)</li>
<li>Spare time</li></ul>
<p>That's all! First, follow the assembly instructions in the Ikea manual in order to assemble the LACK.
After that, the installation of your 19" hardware can begin. When assembling a larger number of LACKs, <a rel="nofollow" href="http://www.instructables.com/id/IKEA_Hack_a_Lack/">this link</a> describes a useful tool for fitting the legs to the tabletop.
</p><p>The LackRack is a stackable modular product. Additional elements can be stacked on top easily. Brackets to secure the top element to the bottom one are not included but available from your local non-computer hardware store.
</p>
<ul><li>If you put several LackRacks side by side, the higher levels can be staggered to form a pyramid. This feature is not present in any other of the commercially available rack products.</li></ul>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack2.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/76/Lackrack2.jpg" decoding="async" width="300" height="400" data-file-width="1536" data-file-height="2048"></a></p><div><p>Due to their light weight design, Lackracks will grow to any required size without compromise</p></div></div></div>
<p>Installing hardware in your LackRack is easy!
</p>
<ul><li><i>Optional but recommended</i> - Put the table on its side (which one is your decision) or upside down</li>
<li>Mount the hardware between the left and right leg
<ul><li>If you mount the first item, it is recommended to install it against the table top for good fit. This happens automatically if you have the LackRack upside down, except in zero gravity environments.</li></ul></li>
<li>Screw all the screws that fit in the rack mount in the left and right leg (for stability).
<ul><li>With deep units, a Z-shaped bracket may be advisable to secure the rear of the unit against the underside of the tabletop.</li></ul></li>
<li>&nbsp;???</li>
<li>Profit! (note how <a rel="nofollow" href="http://www.rackable.com/">lackable.com</a> has been bought by sgi recently)</li></ul>
<h2><span id="Note">Note</span></h2>
<p>Current LACK tables have hollow legs; only the top 5 cm (2") is solid. Fitting equipment below the solid section may require the use of cavity plugs, such as <a rel="nofollow" href="https://www.fischer-international.com/en/products/cavity-fixings/board-fixing/metal-cavity-fixing-hm/519772-hm-5-x-37-s">these</a>
</p>
<h2><span id="Goodies">Goodies</span></h2>
<ul><li>You can put food and/or drink on your rack.</li>
<li>You can put a small lamp on top of the rack to see your hardware and/or better find the aforementioned food and drink.</li>
<li>The table can be painted in a color of your preference, or decorated in various ways. The eth0 Design team can advise, for a fee, how to optimally decorate the rack to suit your environment.
<ul><li>That means, no more dull black/gray racks!</li>
<li>Or you can put <a href="https://wiki.eth0.nl/index.php/File:Lack2.jpg" title="File:Lack2.jpg">stickers of your favorite event</a> on them.</li></ul></li>
<li>It's easy to colour-code your datacentre: e.g. <span>red</span> for critical services, <span>grey</span> for office automation, <span>green</span> for file-servers, <span>black</span> for systems and network management.</li>
<li>Cheap!</li>
<li>Easy!</li>
<li>Looks good!</li></ul>
<h2><span id="Alternative_configuration">Alternative configuration</span></h2>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt1.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/74/Lack_alt1.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p><div><p>fitting the equipment to the rear of the front legs</p></div></div></div>
<ul><li>Mounting the equipment to the rear of the front legs is recommended if you plan to fit switches with fiber uplinks; the created tabletop overhang shields the fiber connections from minor mishap</li></ul>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt2.jpg"><img alt="" src="https://wiki.eth0.nl/images/5/57/Lack_alt2.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p><div><p>front view: 8 port switch with fiber uplink, and power bar</p></div></div></div>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt3.jpg"><img alt="" src="https://wiki.eth0.nl/images/f/f3/Lack_alt3.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p></div></div>

<ul><li>Q: Does the LackRack provide redundant power supply?
<ul><li>A: Only if you add it yourself</li></ul></li>
<li>Q: Can I put my (coffee) mug on top and don't have to worry about it if I spill liquid on the LackRack?
<ul><li>A: You can spill coffee on the LackRack, since it can be cleaned quite easily. However, if you have appliances <b>in</b> the LackRack, there is a chance that these appliances cannot handle the coffee (or any other liquid). You should take precautions in order to protect your appliances</li></ul></li></ul>

<p>As from the Ikea <a rel="nofollow" href="http://www.ikea.com/us/en/catalog/products/40104270">product page</a>:
</p>
<ul><li>Product information
<ul><li>Easy to assemble.</li>
<li>Low weight; easy to move.</li>
<li>Readily available desktop area holding your laptop during maintenance.</li>
<li>Levenstein distance of "Lack" and "Rack" is 1. Can this still be a coincidence?</li></ul></li></ul>
<ul><li>Designer:
<ul><li>IKEA of Sweden</li></ul></li></ul>
<ul><li>Product dimensions
<ul><li>Length: 55cm (21 5/8 ")</li>
<li>Width: 55cm (21 5/8 ")</li>
<li>Height: 45cm (17 3/4 ")</li>
<li>Almost 9U of rack space</li></ul></li></ul>
<ul><li>Care instructions
<ul><li>Wipe clean using a damp cloth and a mild cleaner.</li>
<li>Wipe dry with a clean cloth</li></ul></li></ul>
<ul><li>Product description
<ul><li>Top: Particleboard, Fiberboard, ABS plastic, Printed and embossed acrylic paint, Clear acrylic lacquer</li>
<li>Filling material: Paper</li>
<li>Leg: Particleboard, Fiberboard, Foil, Foil</li></ul></li></ul>

<h2><span id="Enterprise_Edition">Enterprise Edition</span></h2>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack_enterprise.jpg"><img alt="" src="https://wiki.eth0.nl/images/4/41/Lackrack_enterprise.jpg" decoding="async" width="400" height="300" data-file-width="1024" data-file-height="768"></a></p><div><p><a rel="nofollow" href="http://revspace.nl/">RevSpace</a> branded LackRack Enterprise Edition</p></div></div></div>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Norco-3216-LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/0/0f/Norco-3216-LackRack.jpg" decoding="async" width="400" height="300" data-file-width="720" data-file-height="540"></a></p><div><p><a rel="nofollow" href="http://www.norcotek.com/item_detail.php?categoryid=1&amp;modelno=RPC-3216">Norco RPC-3216</a> mounted in a LackRack Enterprise Edition.<br>Additional brackets used to raise the shelf and support the 45kg+ weight.</p></div></div></div>
<p><a rel="nofollow" href="http://www.ikea.com/nl/nl/catalog/products/00095036">Ikea LACK coffee table</a>: almost twice as deep, and comes with a shelf. Its size allows both short ends to be used as rack space simultaneously. It's interesting to note that Ikea photographed it from the side; an uncommon artistic approach to 19" server rack photography.
It provides for 8 U of hardware: 4 on either side of the shelf.
</p><p>Following ICT tradition, the Enterprise Edition is more than three times as expensive, while providing less stability than two of the regular products combined.
</p>
<ul><li>Product information
<ul><li>Easy to assemble.</li>
<li>Low weight; easy to move.</li>
<li>Readily available desktop area holding your laptop during maintenance.</li>
<li>Levenstein distance of "Lack" and "Rack" is 1. Can this still be a coincidence?</li></ul></li></ul>
<ul><li>Designer:
<ul><li>IKEA of Sweden</li></ul></li></ul>
<ul><li>Product dimensions
<ul><li>Length: 90cm</li>
<li>Width: 55cm (21 5/8 ")</li>
<li>Height: 45cm (17 3/4 ")</li></ul></li></ul>
<ul><li>Care instructions
<ul><li>Wipe clean using a damp cloth and a mild cleaner.</li>
<li>Wipe dry with a clean cloth</li></ul></li></ul>
<ul><li>Product description&nbsp;:
<ul><li>Top: Particleboard, Fiberboard, ABS plastic, Printed and embossed acrylic paint, Clear acrylic lacquer</li>
<li>Filling material: Paper</li>
<li>Leg: Particleboard, Fiberboard, Foil, Foil</li></ul></li></ul>

<p>It is clear that Ikea has strived to keep many of their products
rack compatible since so many of them are capable of housing 19"
equipment. See <a href="https://wiki.eth0.nl/index.php/List_of_IkeaRacks" title="List of IkeaRacks">List_of_IkeaRacks</a>
</p>


<ul><li><a rel="nofollow" href="http://search.twitter.com/search?q=lackrack">Twitter search on <i>lackrack</i></a></li>
<li><a rel="nofollow" href="http://www.facebook.com/pages/LackRack/267773044028">LackRack fans on Facebook</a></li>
<li><a rel="nofollow" href="http://fenrir.high5.net/view_album.php?set_albumName=LackRack">Photos of an installed RackLack</a> with (fanless) HP Procurve 2510 <b>(in production)</b></li></ul>
<dl><dt>Danish</dt></dl>
<ul><li><a rel="nofollow" href="http://www.sunech.com/2010/01/21/serverrack-fra-ikea/"><b>Sunech</b>: Server rack from Ikea?</a></li>
<li><a rel="nofollow" href="http://www.lydmaskinen.dk/viewtopic.php?f=17&amp;p=273452"><b>Lydmaskinen</b>: Forum thread</a></li></ul>
<dl><dt>Dutch</dt></dl>
<ul><li><a rel="nofollow" href="http://www.webhostingtalk.nl/webhostingtalk-lounge/157237-het-lackrack-van-ikea-3.html"><b>WebHostingTalk</b>: Forum thread</a></li>
<li><a rel="nofollow" href="http://rapture.tweakblogs.net/blog/3449/lackrack.html"><b>Rapture's logs</b>: LackRack</a> (Blogger discovers that his 19" gear lacks mounting brackets, after buying a new LackRack...)</li>
<li><a rel="nofollow" href="http://blog.webwereld.nl/2010/01/25/een-datacenter-in-je-huiskamer/"><b>Webwereld</b>: Een datacenter in je huiskamer</a></li>
<li><a rel="nofollow" href="http://www.matthijs.org/lackrack_2_0"><b>Matthijs.org</b>: LackRack v2.0</a> (LackRack variation for more practical everyday office use)</li></ul>
<dl><dt>English</dt></dl>
<ul><li><a rel="nofollow" href="http://mrngm.com/eth0/LackRack/"><b>mrngm</b>: LackRack - an odyssee</a> (Buyer's guide)</li>
<li><a rel="nofollow" href="http://www.instructables.com/id/IKEA_Hack_a_Lack/"><b>instructables</b>: IKEA Hack-a-Lack</a> (Not about the LackRack per se, but a method for assembling a large number of them)</li>
<li><a rel="nofollow" href="http://www.datacenterknowledge.com/archives/2010/01/21/the-new-data-center-rack-from-ikea/"><b>Data Center Knowledge</b>: The New Data Center Rack From ... IKEA?</a></li>
<li><a rel="nofollow" href="http://blog.makezine.com/archive/2010/01/lackrack_ikea_server_racks_for_livi.html"><b>Make:</b>: Ikea server racks for living room datacenters</a> (<a rel="nofollow" href="http://www.edugeek.net/forums/general-chat/48713-lackrack-ikea-server-racks-living-room-datacenters.html">forum 1</a>, <a rel="nofollow" href="http://forums.hexus.net/general-discussion/179779-lackrack-ikea-server-racks-living-room-datacenters.html">forum 2</a>)</li>
<li><a rel="nofollow" href="http://idle.slashdot.org/story/10/01/21/1717224/LackRack-Makes-Home-Colocation-More-Affordable"><b>Slashdot</b>: LackRack Makes Home Colocation More Affordable</a></li>
<li><a rel="nofollow" href="http://www.nordichardware.com/news,10613.html"><b>NordicHardware</b>: The LackRack - ‚Ç¨5 server rack, for real!</a> (<a rel="nofollow" href="http://www.nordichardware.com/forum/view-previous-topic-vt13397.html">forum</a>)</li>
<li><a rel="nofollow" href="http://dailydiy.com/2010/01/22/lackrack-ikea-server-racks-for-living-room-datacenters/"><b>Daily DIY</b>: LackRack: Ikea server racks for living room datacenters</a></li>
<li><a rel="nofollow" href="http://zedomax.com/blog/2010/01/22/server-hack-how-to-build-your-own-ikea-servers/"><b>Zedomax</b>: Server Hack ‚Äì How to Build Your Own IKEA Servers!</a></li>
<li><a rel="nofollow" href="http://ikeahacker.blogspot.com/2010/01/lack-rack-hack.html"><b>Ikea hacker</b>: The Lack rack hack</a></li>
<li><a rel="nofollow" href="http://www.askcharly.net/blog/buzz/lackrack-tech-enabled-furniture/"><b>AskCharly</b>: LackRack: Tech Enabled Furniture</a></li>
<li><a rel="nofollow" href="http://www.unplggd.com/unplggd/inspiration/ikea-lack-tablenetwork-rackthe-lackrack-107711"><b>unplggd</b>: IKEA Lack+Network Rack=The LackRack</a></li>
<li><a rel="nofollow" href="http://blog.isabel-drost.de/index.php/archives/tag/lackrack"><b>Inductive Bias</b>: Shopping at Ikea</a></li>
<li><a rel="nofollow" href="http://lincgeek.org/blog/?p=940"><b>LincolnBlogs</b>: LackRack</a></li>
<li><a rel="nofollow" href="http://www.lackcluster.org/"><b>LackCluster</b>: LackRack-ed Cluster Computer</a> Practical use of the LackRack</li></ul>
<dl><dt>French</dt></dl>
<ul><li><a rel="nofollow" href="http://www.artiflo.net/2010/01/ikea-arrive-dans-les-datacenter/"><b>Artiflo</b>: Ikea arrives in the datacentre</a></li></ul>
<dl><dt>German</dt></dl>
<ul><li><a rel="nofollow" href="http://blogmmix.ch/kategorie/aktuell/happy-birthday-30-jahre-lack-beistelltisch.html"><b>BlogMMix</b>: Happy birthday, 30 year old sidetable!</a></li>
<li><a rel="nofollow" href="http://www.gamestar.de/hardware/news/vermischtes/2312088/lackrack.html"><b>GameStar</b>: IKEA table as server rack</a></li>
<li><a rel="nofollow" href="http://tipuraneo.blogspot.com/2010/01/gunstiges-19-rack.html"><b>Tipuraneo</b>: Cheap 19" rack</a></li>
<li><a rel="nofollow" href="http://www.sysadminslife.com/hardware/lackrack-billigstes-19-zoll-serverrack-made-by-ikea/"><b>Sysadminslife</b>: LackRack ‚Äì billigstes 19 Zoll Serverrack made by IKEA?</a></li></ul>
<dl><dt><span title="Swedish :)">Ikeaspr√•k</span></dt></dl>
<ul><li><a rel="nofollow" href="http://www.techworld.idg.se/2.2524/1.287656/serverracket-du-hittar-pa-ikea"><b>Techworld</b>: Server racks at Ikea</a> (<a rel="nofollow" href="http://www.sweclockers.com/forum/showthread.php?threadid=906172">forum</a>)</li>
<li><a rel="nofollow" href="http://www.nordichardware.se/nyhet,17256.html"><b>NordicHardware</b>: The world's cheapest 19-inch rack from IKEA</a> (<a rel="nofollow" href="http://nhw.se/forum/viewtopic.php?topic=182544&amp;forum=17">forum</a>)</li>
<li>Mah lackrack is teh shit - <a rel="nofollow" href="http://mickenordin.se/blog/index.php/2011/01/mah-lackrack-is-teh-shit/">http://mickenordin.se/blog/index.php/2011/01/mah-lackrack-is-teh-shit/</a></li></ul>
<dl><dt>Japanese</dt></dl>
<ul><li><a rel="nofollow" href="http://www.isisaka.com/blog/archives/2010/01/ikea19.html"><b>Áü≥ÂùÇ</b>: Ikea-made 19" rack</a></li></ul>
<dl><dt>Russian</dt></dl>
<ul><li><a rel="nofollow" href="http://habrahabr.ru/tag/LACKRack/"><b>–•–∞–±—Ä–∞—Ö–∞–±—Ä</b>: Server rack from Ikea</a></li></ul>
<dl><dt>Spanish</dt></dl>
<ul><li><a rel="nofollow" href="http://www.internetlab.es/post/857/una-nueva-estructura-para-servidores-de-ikea"><b>internetlab</b>: The New Data Center Rack From ... IKEA?</a></li>
<li><a rel="nofollow" href="http://www.acens.com/blog/ikea-diversifica-y-entra-en-el-sector-de-infraestructura-para-datacenters"><b>acens</b>: Ikea diversifies and enters infrastructure market for datacenters</a></li>
<li><a rel="nofollow" href="http://alsanan.info/5456"><b>alasan</b>: LackRack</a></li></ul>
<dl><dt>Portugese</dt></dl>
<ul><li><a rel="nofollow" href="http://blackhold.nusepas.com/2012/02/lackrack-rack-de-bajo-coste-fase-i/">Lackrack, rack de bajo coste: Fase I</a></li></ul>

<ul>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:2x3U_LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/2/26/2x3U_LackRack.jpg" decoding="async" width="90" height="120" data-file-width="2304" data-file-height="3072"></a></p></div>
			<p>2 by 3U LackRack.
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:TripleLackRackDeLuxe.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/7f/TripleLackRackDeLuxe.jpg" decoding="async" width="90" height="120" data-file-width="960" data-file-height="1280"></a></p></div>
			<p>Triple LackRack DeLuxe.
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:LackRackAtIKEA_1.JPG"><img alt="" src="https://wiki.eth0.nl/images/e/e6/LackRackAtIKEA_1.JPG" decoding="async" width="90" height="120" data-file-width="2736" data-file-height="3648"></a></p></div>
			<p>LackRack at IKEA
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:Image005.jpg"><img alt="" src="https://wiki.eth0.nl/images/b/b7/Image005.jpg" decoding="async" width="90" height="120" data-file-width="1046" data-file-height="1395"></a></p></div>
			<p>CCNA Lab LackRack 01
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:Image002.jpg"><img alt="" src="https://wiki.eth0.nl/images/f/f5/Image002.jpg" decoding="async" width="90" height="120" data-file-width="1046" data-file-height="1395"></a></p></div>
			<p>CCNA Lab LackRack 02
</p>
		</div></li>
</ul>
<!-- 
NewPP limit report
Cached time: 20210129104829
Cache expiry: 604800
Dynamic content: false
Complications: []
[SMW] In‚Äêtext annotation parser time: 0.001 seconds
CPU time usage: 0.097 seconds
Real time usage: 0.102 seconds
Preprocessor visited node count: 80/1000000
Preprocessor generated node count: 0/1000000
Post‚Äêexpand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‚Äêexpand size: 2224/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key eth0_wiki:pcache:idhash:625-0!canonical and timestamp 20210129104829 and revision id 12216
 -->
</div></div></div>]]>
            </description>
            <link>https://wiki.eth0.nl/index.php/LackRack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978013</guid>
            <pubDate>Sun, 31 Jan 2021 11:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a personal data warehouse in Snowflake for fun and no profit]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25978000">thread link</a>) | @thomasdziedzic
<br/>
January 31, 2021 | https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit | <a href="https://web.archive.org/web/*/https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5fffb1fb083bda4cd2029cf2" id="sections">
  
    <section data-test="page-section" data-section-theme="white" data-section-id="5fffb1fb083bda4cd2029cf4" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
          &quot;imageOverlayOpacity&quot;: 0.15,
          &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
          &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
          &quot;customSectionHeight&quot;: 10,
          &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
          &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
          &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
          &quot;customContentWidth&quot;: 50,
          &quot;sectionTheme&quot;: &quot;white&quot;,
          &quot;sectionAnimation&quot;: &quot;none&quot;,
          &quot;backgroundMode&quot;: &quot;image&quot;
        }" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-600f55010fc2501849ebea9b"><div><div><div data-block-type="2" id="block-ee8fde62179b7bb27e53"><div><p>I‚Äôve always wanted to build a personal data warehouse and after watching Simon Willison‚Äôs <a href="https://simonwillison.net/2020/Nov/14/personal-data-warehouses/">talk</a>, I got the motivation to finally build it out. In case you aren‚Äôt familiar with the term ‚Äúdata warehouse‚Äù, it‚Äôs basically a database that centralizes your data to be used for analysis. There are many databases you can choose from, for example in Simon Willison‚Äôs talk, he uses <a href="https://www.sqlite.org/index.html">SQLite</a>. I chose <a href="https://www.snowflake.com/">Snowflake</a> because I‚Äôm familiar with it and so far I have liked what Ive seen. Some features that make it stand out for me are things like <a href="https://docs.snowflake.com/en/user-guide/data-time-travel.html">time travel</a>, <a href="https://docs.snowflake.com/en/sql-reference/sql/undrop-table.html">undrop table</a>, a rich set of <a href="https://docs.snowflake.com/en/sql-reference/intro-summary-operators-functions.html">functions</a>, among many others.</p><p>Ok great, so we now have an empty database to start with. But a database is only useful when there is data in it to query. So we must choose which datasets to pull into our freshly minted database. I‚Äôm going to start with bringing in <a href="https://news.ycombinator.com/">Hacker News</a> data because I‚Äôm a big fan of the site and it has an actual <a href="https://github.com/HackerNews/API">API</a> which means we wont have to be scraping HTML. I‚Äôm also going to bring in stock data into the warehouse to see if we can get any stock information out of Hacker News. Finally we‚Äôll analyze the stock market and correlate stocks to the latest GameStop stock craze.</p><p>The first part of the plan will be to get the Hacker News data loaded into Snowflake. Then I‚Äôll use Snowflake‚Äôs Data Marketplace to bring in the stock data, which will save me from writing an ELT (Extract, Load, Transform).</p><h2>Getting an initial dump of the Hacker News data.</h2><p>I wanted to write as little code as possible to get this initial historical dump of Hacker News so I decided to use a combination of curl, bash and parallel to get the job done. I first used <a href="https://ec2instances.info/">ec2instances.info</a> to find a relatively cheap CPU per dollar machine. I spun up a c5a.8xlarge on AWS which has 32 vCPUs.<br>I wouldn‚Äôt be surprised if there were cheaper options, but I just eyeballed it.</p><p>Let‚Äôs get the largest item ID:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611791428293_3993"><div><pre><code>curl https://hacker-news.firebaseio.com/v0/maxitem.json</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611792427454_4138"><div><p>Which returned: 25,806,058</p><p>Sigh, looks like we‚Äôre going to have to do 25 million HTTP calls. Let‚Äôs get started:</p><p>Let‚Äôs generate a file with all of the endpoints we will need to hit. This will be needed for my next one liner:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611792427454_5677"><div><pre><code>for ((i=1; i&lt;25806059; ++i)); do echo "https://hacker-news.firebaseio.com/v0/item/${i}.json"; done &gt; list-of-item-urls</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793513046_4897"><p>Ok, so we have 25 million URLs that we need to download. Let‚Äôs use curl with parallel to download this:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_11393"><div><pre><code>time { parallel --jobs 500 --progress --arg-file ../list-of-item-urls "curl --silent -O {}"; }</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_11459"><p>This fails with an error that we‚Äôve reached a limit regarding the number of open file handles, you will need to add the following line to limits.conf and then reboot the machine:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_14036"><div><pre><code>cat /etc/security/limits.conf 
...
ubuntu           soft    nofile          10000
...</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_14107"><p>Lets try running the download job again and fast forwarding till the end:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_15450"><div><pre><code>~/hackernews/data$ time { parallel --jobs 500 --progress --arg-file ../list-of-item-urls "curl --silent -O {}"; }                                                                               

Computers / CPU cores / Max jobs to run
1:local / 32 / 500

Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete
local:0/25806058/100%/0.0s   

real    1419m19.537s
user    5375m8.349s
sys     3894m15.079s</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_15519"><div><p>The rate at which we were downloading URLs was 25,806,058 / (1,419 * 60 + 19) = 303 URLs per second. </p><p>This was a really slow process, especially given that I used a medium-end machine. My guess is that EBS volumes might not like 25 million files getting created.</p><p>Let‚Äôs see how big the data directory is:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_17011"><div><pre><code>~/hackernews$ du -hs data
100G    data</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_17077"><p>Ouch, lots of little files definitely take up a lot of space. In addition, I haven‚Äôt thought this through. It‚Äôs probably going to be painful uploading 25 million files to Snowflake so lets combine all the files into a single file:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_18389"><div><pre><code>~/hackernews/data$ time { find . -name '*.json' -exec cat {} \; -exec echo \; &gt; ../items ; }

real    2120m33.575s
user    740m24.364s
sys     1208m22.212s
</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_18455"><div><p>Well it doesn‚Äôt look like my laziness paid off.<br>Combining the 25 million files into 1 file on this ec2 instance using an EBS volume took longer than downloading the files at a rate of 25,806,058  / (2,120 * 60 + 33) = 202 files per second. Maybe using a native storage instance would make this go faster, but still, combining millions of little files is a really slow process.‚Äô</p><p>Eighty dollar lesson learned.</p><p>Additionally, when combined into a single file, it takes about 11 gigs.</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_19766"><div><pre><code>ls -lh items
-rw-rw-r-- 1 ubuntu ubuntu 11G Jan 19 12:48 items</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_9850"><p>And compressed, it's still even lower, 4 gigs:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_11094"><div><pre><code>ls -lh items.gz
-rw-rw-r-- 1 ubuntu ubuntu 4.1G Jan 19 12:48 items.gz</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_12186"><div><p>Copying to AWS S3 takes almost no time. So we finally have the data where Snowflake can access it!</p><p>Let's load it in:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_13561"><div><pre><code>use database main_db;

create schema hackernews;

use schema hackernews;

create table raw_items(item variant not null);

copy into raw_items
from s3://hacker-news-dump/items.gz
credentials = (aws_key_id = 'REDACTED' aws_secret_key = 'REDACTED')
file_format = (type = json);

create table items(
  id bigint,
  deleted boolean,
  type string,
  by_ string,
  time timestamp,
  text string,
  dead boolean,
  parent bigint,
  poll bigint,
  kids array,
  url string,
  score bigint,
  title string,
  parts array,
  descendants bigint
);

insert into items(
  id,
  deleted,
  type,
  by_,
  time,
  text,
  dead,
  parent,
  poll,
  kids,
  url,
  score,
  title,
  parts,
  descendants
)
select
  item:id,
  item:deleted,
  item:type,
  item:by,
  item:time,
  item:text,
  item:dead,
  item:parent,
  item:poll,
  item:kids,
  item:url,
  item:score,
  item:title,
  item:parts,
  item:descendants
from raw_items;</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_14726"><div><p>Loading the data takes a couple of minutes but now we have all Hacker News items loaded into Snowflake!</p><h2>Data Quality Checks.</h2><p>Let‚Äôs run some sanity checks on our data by looking for gaps between the ids:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_16858"><div><pre><code>select lag(id, 1) over (order by id) prev_id, id
from items
qualify id - prev_id &gt; 1
order by 1;</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_20248"><div><p>I have 15k gaps in my data. To quote Dyatlov from Chernobyl, <a href="https://www.youtube.com/watch?v=Mg5HOnq7zD0">‚ÄúNot great, not terrible‚Äù</a>.</p><p>I ended up writing a python <a href="https://github.com/thomasdziedzic/hackernews-fill-gaps/blob/master/main.py">script</a> to calculate and download these missing items. If you know how one would generate the missing ids between the gaps (which could be of variable size), I would sure like to learn how you accomplish that because it might have spared me from writing this python script. Moving on‚Ä¶</p><p>I also found that the API returns some nulls for items. So I ran the following to clean those up:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_21920"><div><pre><code>delete from items where id is null;
</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_23295"><div><h2>Review so far and writing an incremental script.</h2><p>I just spent $80 getting the data into Snowflake and I‚Äôm not happy with the performance of the extraction.</p><p>In fact, I was thinking how I was going to maintain this data moving forward, and how I was going to load the data incrementally.<br>I was not satisfied enough with the current approach to keep using it. We must do better, for the sake of my wallet.</p><p>I gave up trying to figure out how to do it purely from a shell scripting perspective, and wrote my own <a href="https://github.com/thomasdziedzic/hackernews-etl/blob/master/main.py">Python script</a> to figure out which items it needs to extract, and then load into Snowflake. This script can be run without user intervention and will keep the data up-to-date. Using Python to write the ELT gave me more flexibility to fix some things that I saw as issues. For example, the script starts N * 4 (where N is the number of logical cpus) jobs and only produces N * 4 files instead of 1 file per item. This approach will avoid having to do an expensive file combination step at the end. I also added some awesome progress bars to the script so that I knew how many requests remain thanks to <a href="https://github.com/alphatwirl/atpbar/issues/21#issuecomment-766468695">Tai Sakuma</a>.</p><p>Running this script from my laptop (a Dell 9370 Developer Edition with 8 logical cores) and spotty Wi-Fi, script extracts items from the API at about 130 items/second. This is slower than extracting from a c5a.8xlarge machine, but at least my laptop isn‚Äôt charging me $1.232/hour for using it. And my script has the benefit of not having to combine millions of tiny files at the end. Let‚Äôs test my incremental loading script out on an ec2 instance to see how it really compares with my naive approach.</p><h2>Downloading incremental data from Hacker News using my script</h2></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611883239126_31321"><div><pre><code>$ time { poetry run python main.py ; }
fetching 116738 items
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-22
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-47
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-14
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-36
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-54
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-19
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-58
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-13
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-52
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-56
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-63
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-62
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-29
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-57
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-26
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-12
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-17
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-4
 100.00% ‚Ä¶</code></pre></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit">https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit</a></em></p>]]>
            </description>
            <link>https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978000</guid>
            <pubDate>Sun, 31 Jan 2021 11:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Black Bart ‚Äì The Buried TV Sequel to Blazing Saddles]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25977514">thread link</a>) | @rbanffy
<br/>
January 31, 2021 | https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/ | <a href="https://web.archive.org/web/*/https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

		
<article id="post-38544">

	
	
	
	<div>

		<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1" alt="" width="840" height="606" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><em><strong>The Mel Brooks classic that became a TV series that ran for four seasons without being broadcast anywhere.</strong></em></p>

<p><em>Update: large parts of this story may, in fact, be fiction. See the addendum at the end for details.</em></p>
<p>Film rights are a strange and complex thing, especially when it comes to existing properties. The contracts for these things can involve a labyrinthine series of clauses and negotiations, where the owners of the original property want to include cut-off clauses that will enable them to claw back the rights and sell them again, possibly for much more money if the adaptation has been a success, the artistic creator wants to hold on to some level of creative control and the film studio wants to ensure that neither of those things happens. We‚Äôve seen assorted shenanigans at work across the board ‚Äì the <a href="https://reprobatepress.com/2018/08/30/big-bond-themes-and-secret-agent-cover-versions/">James Bond</a> copyright snafu that saw the film rights for <strong>Casino Royale</strong> owned and exploited by another company than the one that made the official series, and perhaps most famously in terms of contractual obligations, the first <strong>Fantastic Four</strong> movie, made as a low-budget throwaway affair simply to ensure that the film rights stayed with Constantin Film, who was not quite ready to make a ‚Äòproper‚Äô version of the story but who saw the potential in the property and didn‚Äôt want to let it go.</p>
<p>But perhaps the most absurd of these contractual obligation projects came with <strong>Blazing Saddles</strong>, which was adapted into a TV series that ran for four seasons ‚Äì which would suggest a major hit show by 1970s television standards, except for the fact that it never aired. Not a single episode beyond the pilot was shown on TV anywhere.</p>
<p><strong>Blazing Saddles</strong> was a major hit in 1974 and remains one of the most beloved Hollywood comedies ‚Äì well, perhaps not with Millenials and Generation Z, given the film‚Äôs rather liberal use of the sort of racist language that is now strictly forbidden, even in context. Mel Brooks‚Äô comedy western mocked American racism brutally ‚Äì perhaps a little too brutally in the use of one particular word, which is bandied about throughout the film. It was a different time.</p>
<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1" alt="" width="840" height="605" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Brooks was on fire as a filmmaker in 1974, and there was every reason to expect <strong>Blazing Saddles</strong> to be a massive hit, as indeed it was. Having dealt with studios enough by this point, Brooks knew that they might want to take the project away from him and produce sequels ‚Äì the story essentially opened itself up for on-going narratives. And so he came up with a cunning plan. The contracts for the film stated that there could only be film sequels if a TV series follow-up was made within six months. Brooks and his legal team were pretty certain that the film was too profane and vulgar to ever be adapted as a TV series. I mean, what could they do? Strip it back to its most basic elements while throwing out everything that made the film what it was?</p>
<p>Well, that was precisely what happened. In 1977, Warner Brothers announced plans for a sequel film ‚Äì in fact, a series of sequels ‚Äì to <strong>Blazing Saddles</strong>, and when Brooks and his lawyers waved the contract at them, they pulled their ace card ‚Äì a four-season series based on the original film that had gone into production very quickly in 1974. As Brooks explained, <em>‚ÄúWarner Bros comes to me and says they want to make another Blazing Saddles, and I say, ‚ÄòNo. You don‚Äôt have the right to do that.‚Äô They say, ‚ÄòYes we do, we‚Äôve been making a TV series and still control the rights.‚Äô What TV series? I haven‚Äôt seen a TV show. They take me onto the lot, into a projection booth, and show me three episodes. My lawyers never thought to put in language that said they had to air the damn thing, only that they had to make it.‚Äù</em></p>
<p>You have to almost admire Warner Brothers‚Äô gall here, and ‚Äì oddly ‚Äì their belief in <strong>Blazing Saddles</strong>. Not only did they rush a series into production in 1974, but they kept it in production ‚Äì because the contract only allowed a new movie within six months of the last <strong>Blazing Saddles</strong> project ‚Äì for four years until they finally had a movie ready. TV shows might be cheaper than films, but nevertheless, imagine how much they had to spend, making four seasons of a show just to hold onto the film rights.</p>
<p>In fact, the pilot episode of <strong>Black Bart</strong>, as the series is called, was shown once in 1975 on CBS, with no one even noticing. Well, why would they? As well as changing the title (because the contract also failed to state that any TV series be <em>called</em> <strong>Blazing Saddles</strong>), Brooks wasn‚Äôt credited, with Andrew Bergman, who originally came up with the <strong>Blazing Saddles</strong> idea listed as creator. The show starred Louis Gossett Jr as Sheriff Bart, continuing his battles against both criminals and racists, while the other film characters were replaced with similar, but not identical characters to avoid crediting Brooks. Both the cast ‚Äì including Gerrit Graham ‚Äì and the characters are lightweight versions of the originals, the humour is almost non-existent and the laugh track just hammers home how unfunny the show is. And yet it is a professional work, and arguably no less forced than several other sitcoms of the era. So the question is: why didn‚Äôt they just put in a bit more effort and then show the damn thing instead of paying everyone to shoot twenty-four episodes that would sit, unseen, in the Warner Brothers vaults?</p>
<p><img loading="lazy" src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1" alt="" width="840" height="602" srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" data-lazy-src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Presumably, the answer is that a TV show ‚Äì even a good TV show ‚Äì would have diluted the appeal of another film. The 1970s were a different time (we mentioned that, right?) and there was less crossover of film and TV ‚Äì sure, some films ‚Äì like <a href="https://reprobatepress.com/2020/09/27/go-ape-the-planet-of-the-apes-book-and-comics-of-the-1970s/"><strong>Planet of the Apes</strong></a> ‚Äì were adapted into TV shows, but those shows were rarely successful and were seen as having essentially killed off any chance of audiences then going to the cinema to watch a movie version. If anything, <strong>Black Bart</strong> might have served as a sign of just how bad a Mel Brooks-free version of <strong>Blazing Saddles</strong> could be. So instead of putting any effort into making a decent TV series based on the property (and there‚Äôs certainly the potential there), Warner Brothers simply put the least possible effort into making something that would still legally stand up as a TV show that could, in theory, be broadcast ‚Äì and then buried it.</p>
<p>What the cast and crew thought of all this is hard to gauge ‚Äì Gossett has talked about the weirdness of it all, but you have to wonder just how anyone managed to drum up any enthusiasm once it became clear that the show would never air. Ironically, the plans for a <strong>Blazing Saddles</strong> sequel ultimately went nowhere ‚Äì by 1979, it was clear that the moment had passed and audience tastes had changed. The sequel was shelved, and the series was finally cancelled. The pilot episode has since turned up on the <strong>Blazing Saddles</strong> DVD and blu-ray, but the other episodes have yet to be seen. It‚Äôs entirely possible that they were never even completed beyond the ones shown to Brooks, and may have been trashed. A pity, as we‚Äôll never know if it accidentally improved.</p>
<p><strong>IMPORTANT UPDATE:</strong> We feel it‚Äôs important to point out that some sources are claiming since we originally posted this that the entire story ‚Äì with the exception of the<strong> Black Bart</strong> pilot, which definitely exists and is perhaps a weird enough thing in itself ‚Äì is in fact a spoof that has somehow become accepted as reality ‚Äì ‚Äòfake news‚Äô, as I believe it is known. There are several sources online claiming that this story is authentic; others claiming that it is satire (links appear in the comments). Unless Mel Brooks ‚Äì or perhaps Louis Gossett ‚Äì wants to come clean on the actual facts, it perhaps remains a mystery. Stranger-than-fiction may, or may not, be actual fiction, and isn‚Äôt that depressing when it‚Äôs a story as good as this? As Tony Wilson said (or possibly didn‚Äôt say, there‚Äôs the rub), <em>‚Äúwhen&nbsp;you have to choose between the truth and the legend, choose the legend.‚Äù</em></p>
<p>DAVID FLINT</p>
<p><em><strong>Help support The Reprobate:</strong></em></p>
<p><em><strong><a href="https://www.buymeacoffee.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;ssl=1" alt="buy-me-a-beer" width="199" height="59" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><br>
<a href="https://www.patreon.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;ssl=1" alt="Patreon" width="567" height="283" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></strong></em></p>


		
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article>

	<!-- #comments -->


		</main><!-- #main -->
	</section><!-- #primary -->

	
	<!-- #secondary -->



	</div></div>]]>
            </description>
            <link>https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25977514</guid>
            <pubDate>Sun, 31 Jan 2021 09:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Onion's Genome Has Five Times More DNA Than Humans (2019)]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25975457">thread link</a>) | @disqard
<br/>
January 30, 2021 | https://geneticsunzipped.com/news/2019/1/31/the-onion-test | <a href="https://web.archive.org/web/*/https://geneticsunzipped.com/news/2019/1/31/the-onion-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1565793939038_266584"><div><p>The human genome is an incredible thing. Six billion letters of DNA ‚Äì that‚Äôs more than two metres of DNA in every single cell ‚Äì containing all the genes that enable a single cell to grow into a fully-formed, fully functioning person. </p><p>So when the first draft sequence of the human genome was published in 2001, researchers around the world were eager to discover exactly how many genes must be packed into our glorious genome.</p><p>The answer was a big surprise.</p><p>Many people thought that it must take at least a hundred thousand genes to make a human ‚Äì with a sweepstake on offer to the person who made the closest guess to the final number ‚Äì yet the human genome turns out to contain only 20,000 or so genes (roughly the same number of genes as a fruit fly or nematode worm).</p><p>This seems remarkably low to make an organism with as much dazzling complexity as a human being.  Even more perplexingly, the genes that we do have make up less than two per cent of all that DNA. So what‚Äôs the rest?</p><p>To find out, we need to go back in time to 1972.</p><p>That‚Äôs when geneticist Susumu Ohno published a paper entitled ‚ÄúSo much ‚Äòjunk‚Äô DNA in our genome‚Äù in an obscure scientific journal, the Brookhaven Symposia in Biology, in which he mused upon a mathematical problem.</p><p>By that point, scientists had already measured how much DNA was present in bacteria and figured out that these little bugs must contain a few thousand genes. They also knew that a single human cell contained at least 750 times as much DNA.</p><p>Ohno did a quick back-of-the-envelope calculation ‚Äì if the number of genes in any genome was directly proportional to the amount of DNA, then humans should have‚Ä¶.. three million genes, more or less.</p><p>But, as he pointed out in his paper, ‚Äòlowly lungfish and salamanders‚Äô can have 36 times more DNA in their cells than is present in ours, suggesting that they should have‚Ä¶. A hundred million genes.</p><p>He didn‚Äôt believe it. What would a slimy salamander need with all those genes? Therefore, Ohno concluded, the vast majority of the human genome must be junk. And, correspondingly, varying proportions of other organisms‚Äô genomes must be junk too. And once the Human Genome project revealed that the vast majority of our genome doesn‚Äôt seem to contain actual genes, it looked like he was right.</p><p>The function of this remaining 98% of the human genome - sometimes called ‚Äòjunk DNA‚Äô but more accurately referred to as non-coding DNA ‚Äì is a hotly debated topic in the world of genetics, fought out within the dignified pages of journals and the more febrile atmosphere of scientific conferences.</p><p>An absolutely massive study published in 2012, known as ENCODE, suggested that around 80% of the human genome was functional ‚Äì namely, that it did something important for the proper functioning of our cells and bodies. Just under 10 per cent is thought to be control switches responsible for turning genes on and off at the right time and in the right place, while the rest does all manner of things, from producing little pieces of RNA that control gene activity to organising the three-dimensional structure of the DNA inside a cell.</p><p>Others were unconvinced. For example, evolutionary geneticist Chris Ponting suggests that less than 10% of the human genome is functional, based on how much has been strongly preserved through evolutionary time and must therefore be very important.</p><p>It‚Äôs against this backdrop we bring in the Onion Test, devised by T. Ryan Gregory and posted on his blog in April 2007. It was later formalised as a scientific paper that he published in 2014, together with Alexander Palazzo.</p><p>Put simply, the Onion Test goes like this.</p><p>The onion in your vegetable drawer has five times more DNA than humans. So if you‚Äôre a researcher who thinks that non-coding DNA has a particular function in the genome, can you explain why an onion needs about five times more of it than a human to do the same thing?</p><p>Unpeeling this idea a bit further, Gregory points out that some species of onions have around double the amount of DNA as your regular onions, while others have less than half. Yet they‚Äôre pretty much the same and have the same number of genes, so why would they need double or half the amount of non-coding DNA?</p><p>This argument works for all kinds of species, from Ohno‚Äôs lowly salamanders with their giant genomes containing roughly the same set of genes as other vertebrates, including humans, to the biggest genome discovered to date, which belongs to the Japanese canopy flower, Paris Japonica, with around 150 time more DNA in its genome than a human.</p><p>Then there‚Äôs the poisonous Fugu pufferfish ‚Äì often eaten (very carefully!) as a delicacy in Japan.  They have remarkably compact genomes, roughly an eighth of the size of our own yet containing almost exactly the same repertoire of genes and very little junk.</p><p>Perhaps our obsession with finding function for all the junk in our genome comes from a desire to think that humans are something special in the biological world ‚Äì certainly more special than an onion.</p><p> But in the words of the grumpy geneticist Dan Graur, who I interviewed for my book Herding Hemingway‚Äôs Cats in which I dig into the junk in our genetic trunk,  ‚ÄúEither you have to assume that humans are the pinnacle of creation ‚Äìthat everything is functional and those organisms with more DNA than us have junk DNA but we don‚Äôt. Or you have to assume that humans are a regular organism that has junk DNA just like everything else.‚Äù</p><p><strong>Further reading:</strong></p><ul data-rte-list="default"><li><p><a href="http://www.genomicron.evolverzone.com/2007/04/onion-test/" target="_blank">T. Ryan Gregory‚Äôs original post about the onion test</a></p></li><li><p><a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004351" target="_blank">The case for junk DNA, Palazzo &amp; Gregory (2014), PLoS Genetics</a></p></li><li><p><a href="https://www.sciencemag.org/news/2010/10/scienceshot-biggest-genome-ever" target="_blank">The biggest ever genome - Paris Japonica </a></p></li><li><p><a href="http://bit.ly/HerdingHemingwaysCats" target="_blank">Herding Hemingway‚Äôs Cats - Kat Arney </a>(aff) Chapters 1 and 2</p></li></ul></div></div></div>]]>
            </description>
            <link>https://geneticsunzipped.com/news/2019/1/31/the-onion-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975457</guid>
            <pubDate>Sun, 31 Jan 2021 03:13:05 GMT</pubDate>
        </item>
    </channel>
</rss>
