<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 02 Feb 2021 04:44:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 02 Feb 2021 04:44:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Docker, Django, Traefik, and IntercoolerJS: My go-to stack for building a SaaS]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 212 (<a href="https://news.ycombinator.com/item?id=25973242">thread link</a>) | @simplecto
<br/>
January 30, 2021 | https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: html--><p>This article has been updated. It was previously dated for 2020. Very little has changed, but I call it out where needed.
</p><!--kg-card-end: html--><p>In case you are wondering, that SaaS is Curabase:</p><p><a href="https://www.curabase.com/">https://www.curabase.com</a></p><figure><a href="https://www.curabase.com/"><div><p>Curabase: We make it easy to curate, collaborate, and share bookmarks.</p><p>Curabase makes group bookmarking easier, the same way that Github eases the pain of software development collaboration easier.</p><p><img src="https://www.curabase.com/static/images/favicon/favicon-color-194.png"><span>Curabase</span></p></div><p><img src="https://www.curabase.com/static/images/curabase-opengraph-image.jpg"></p></a></figure><hr><p>I recently published some thoughts on <a href="https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2020/">Django being a great framework for applications</a>. This post expands on that to include the other pieces of infrastructure from development to production environments.</p><p>I have used this stack (or ones that look a lot like it) to build small SaaS apps in 2018, 2019, 2020, and now in 2021.</p><h3 id="my-entire-stack">My entire stack</h3><ul><li>Linux Server/VM Hosted anywhere (I like Azure, Digital Ocean, or Scaleway) <em>(edit: 2021 – I'm in the process of moving everything over to a dedicated server at <a href="https://www.hetzner.com/">Hetzner</a>.)</em></li><li>Docker. Just plain docker</li><li>Traefik for reverse proxy and TLS with LetsEncrypt</li><li>Postgresql running in docker</li><li>Django in a container</li><li>Intercoolerjs for easy and slick Ajax-like front-end work <em>(Edit: 2021 - the creator of intercooler has released <a href="https://htmx.org/">HTMX</a>, the successor to IntercoolerJS.)</em></li><li>Sentry for catching production bugs (easy three-lines added to your config)</li><li>Bitbucket pipelines for CI/CD <em>(Edit: 2021 - I no longer bother with CI / CD for personal projects. It it too much tooling for no benefit)</em></li><li>ZeroTier for VPN/ControlPlane</li></ul><p>For smaller projects I run tests locally in docker containers and then push directly into production. I &nbsp;don't bother with full CI/CD because I don't need the complexity of it all. That said, I do like Bitbucket Pipelines.</p><figure><img src="https://www.simplecto.com/content/images/2020/02/mytechstack.jpg" alt=""><figcaption>A simple diagram of my go-to tech stack</figcaption></figure><!--kg-card-begin: markdown--><p>Woah! that is a lot to unpack here. Let's visualize this another way.</p>
<ul>
<li>Virtual Machine
<ul>
<li>Docker
<ul>
<li>Django
<ul>
<li>Volume mounted data disks</li>
</ul>
</li>
<li>Workers (Long-running django commands)
<ul>
<li>Volume mounted data disks</li>
</ul>
</li>
<li>Postgres
<ul>
<li>Volume-mounted data disks</li>
</ul>
</li>
<li>Traefik</li>
</ul>
</li>
<li>Zero-Tier</li>
<li>SSH</li>
</ul>
</li>
</ul>
<p>Was this helpful? Let me know...</p>
<!--kg-card-end: markdown--><h3 id="hosting">Hosting</h3><p>Your stuff needs a home (yes, even in the "serverless" world. LOL). My personal preferences are <a href="https://azure.com/">Azure</a>, <a href="https://m.do.co/c/c844c6492d23">Digital Ocean</a> <em>(affiliate link)</em>, or <a href="https://scaleway.com/">Scaleway</a>. They each offer enough compute, networking options, storage, and basic services to build out proofs-of-concept or whatever you might need.</p><p>Another honorable mention here is <a href="https://hetzner.com/">Hetzner</a>. They offer a good level of hardware, service and price.</p><h3 id="the-virtual-machines">The Virtual Machines</h3><p>For those side projects and many enterprise applications, <strong>scale is not an issue</strong>. That means that I will not serve thousands of simultaneous users or handling terabytes of data. Therefore I can get by on the smaller offerings – usually under $20/month. Even Azure (the most expensive of the three) offer their burstable VMs. Generally I like to go with <a href="https://www.scaleway.com/en/virtual-instances/development/">Scaleway's Developer line of servers</a>.</p><p><em><strong>Notice that Kubernetes is missing from my stack? When scale is not an issue then you don't need Kubernetes.</strong></em></p><h3 id="docker-just-plain-docker-">Docker. Just plain Docker.</h3><p>I do not rely on the OS vendor (Ubuntu) to make sure that I run the latest Docker on new VMs. Therefore I use the nice little <code>curl|bash</code> technique.</p><pre><code>curl -s https://get.docker.com | sudo bash</code></pre><p>This cure one-liner will get the best and most recent version for your machine running.</p><h3 id="traefik-for-reverse-proxy">Traefik for Reverse Proxy</h3><p>Traefik has been a God-send since I found it. Nginx is great, but it was not built for the Docker universe. Traefik has two killer features that have saved me hours upon hours:</p><ol><li>Automatic TLS with LetsEncrypt. Literally set-it-and-forget-it. With the right API keys and DNS provider you can also do verification with DNS.</li><li>Automatic no-reload configuration using docker labels. When you spin up new services Traefik will pickup the changes automatically because it listens to all Docker-related events. This makes it incredibly convenient to add, remove, or merge services as needed without any hassle.</li></ol><p>My only comment on Traefik is that there is a bit of a learning curve. You have to decide how you want to configure it (config file, command line options, yaml, or docker labels, or use a combination!)</p><!--kg-card-begin: html--><p>Another note here: I have already <a href="https://www.simplecto.com/traefik-2-0-docker-and-letsencrypt/" title="Traefik 2 production ready configurations">published my production configuations for Traefik</a> here.</p><!--kg-card-end: html--><h3 id="postgres-for-database">Postgres for Database</h3><p>Tried and True, PostgreSQL has never let me down. I usually attach one of these containers to a project that needs it without any difficulty. I simply spin up the container, bind the ports, and then bind the data volume to my host disk. Done and Done.</p><!--kg-card-begin: markdown--><h3 id="dockercomposeyml">docker-compose.yml</h3>
<pre><code>version: '3.1'

services:

  db:
    container_name: postgres
    hostname: postgres
    image: postgres:11
    restart: always
    environment:
      POSTGRES_PASSWORD: secretsonly
    volumes:
      - ./data:/var/lib/postgresql/data
    ports:
      - 5432:5432
    networks:
      - web

networks:
    web:
        external: true
</code></pre>
<!--kg-card-end: markdown--><h3 id="dockerized-django-for-web">Dockerized Django for Web</h3><p>Docker deploys nicely in a container, and I have been doing it for a few years now. The benefits of matching your development environment to your production one cannot be overstated, and I have Docker to thank for that.</p><p>Edit: 2021, I've got a reference Django project up that I use as my template for new projects: <a href="https://github.com/simplecto/django-reference-implementation">https://github.com/simplecto/django-reference-implementation</a></p><h3 id="django-commands-for-asynchronous-tasks">Django commands for Asynchronous tasks</h3><p>Also, for asynchronous tasks I simply use <a href="https://docs.djangoproject.com/en/3.0/howto/custom-management-commands/">custom Django commands</a> which are a part of the standard framework. The pattern here is a simple <code>while</code> loop with a <code>sleep()</code> period. It polls the database for relevant actions and then does it's thing. &nbsp;</p><p>Edit: 2021 - This has paid off in a big way. I have been running a website screenshot project for over a year now with this pattern. It takes about 1500 website screenshots per day. All of it is scheduled and managed by a Django command.</p><p>That project lives here: https://github.com/simplecto/screenshots</p><h3 id="intercoolerjs-because-who-needs-the-complexity">IntercoolerJS, because who needs the complexity?</h3><p>I have a lot to say about this, but that will have to go into a series of posts. The tldr; here that I use this lovely little javascript library along with jQuery (<em>yeah, it is 2020, and I still use jQuery</em>) to make parts of my applications <em>feel</em> like single-page-apps but not really.</p><p>IntercoolerJS keeps that old-school "Ajax" (remember that word) goodness and allows me to update the DOM with HTML from the backend. It is seamless, smooth, and really convenient for things like logins and small form updates.</p><p>I strongly suggest you check it out: <a href="https://intercoolerjs.org/">Learn more about IntercoolerJS</a></p><p>Edit 2021: The creator has released <a href="https://htmx.org/">HTMX</a>, the successor to IntercoolerJS.</p><h3 id="sentry-to-catch-production-errors">Sentry to catch production errors</h3><p>I make mistakes. Lots of mistakes--but there is no need to show them to my users, right? Sentry gives me an easy and convenient way to capture production bugs as they happen. Some cool things about them:</p><ol><li>Open source-ish (<a href="https://blog.sentry.io/2019/11/06/relicensing-sentry">relicensed here</a>), so you can host yourself if that is your thing.</li><li>Easy few lines added to your <code>settings.py</code> file in Django and that is it.</li><li>Tight integration to your Git repos and Issue tracking systems for full production defect traceability.</li></ol><p>Another nice thing is that you can disable it for development.</p><p><a href="https://sentry.io/">Check out Sentry here</a>.</p><h3 id="bitbucket-pipelines-for-ci-cd">Bitbucket Pipelines for CI/CD</h3><p>Edit: 2021 - I no longer use CI/CD for deployment of my one-man projects. It is too much tooling and complexity. I simply run tests with PyCharm and ship directly to production from my development machine.</p><p>There are so many CI/CD offerings out there today, but I have been happy with Bitbucket's offering called Pipelines. They offer you a few hundred minutes free every month with the option to top-up as needed for a small fee. I have rarely had problems, and I really enjoy their YAML configuraiton / directive files. </p><p>Using the <code>bitbucket-pipelines.yml</code> file I have been able to do full end-to-end testing by spinning up multiple docker containers, loading the databases, and running hundreds of test in just a few minutes. This was key in speeding things up in our team and enabling 5+ pushes to production per day.</p><p><a href="https://bitbucket.org/">Checkout Bitbucket here</a>.</p><h3 id="zerotier-for-vpn-control-plane">ZeroTier for VPN/Control Plane</h3><p>Finally, we come to the bit of tech that is largely optional but nice to have. &nbsp;Zerotier is a unique kind of network/VPN that I use to link all my personal machines. It works though firewalls (at home, in office) and offers an easy 1 minute setup.</p><p>Using ZeroTier in my last company we were able to remove the SSH Jump Servers which caused a headache in terms of key management and shared bandwidth on a single machine.</p><p>Zerotier work on Linux, Mac, Windows, Android, and iPhone, so you are pretty much covered.</p><p>The one downside to ZeroTier is that I don't entirely understand how it works. It is a lot like MacOS or iPhone in that it "just works" as expected and I rarely (never) have problems. That is a strength from a user experience perspective but a WTF? from a CTO perspective. </p><h3 id="conclusion">Conclusion</h3><p>Hopefully this deeper-dive will prompt some interest and curiosity about Docker, Django, Traefik, and especially IntercoolerJS. It is simple, easy to work with, and allows you to grow out of it when the time comes.</p><p>Edit 2021 - As you can see not a lot has changed. I've been able to add more code to my public repositories that flesh out the ideas expressed here over a year ago.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/docker-django-traefik-intercoolerjs-is-my-stack-for-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25973242</guid>
            <pubDate>Sat, 30 Jan 2021 21:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing 200 broken raspberry Pis to prevent e-waste and donating the money raised]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25972094">thread link</a>) | @technlogger
<br/>
January 30, 2021 | https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3651">

	

	<div>
		
<h2>Introduction</h2>



<div><p>The first batch of the repaired Raspberry Pi’s have been sold! If you missed out on this, don’t worry! There are more to come as I repair them. </p><p>I sold a total of 27 Raspberry Pi’s, 3 people cancelled their orders as they somehow thought these were Raspberry Pi 4’s?! I will relist these  during the week along with a few freshly repaired devices with upgraded SD card slots.</p></div>



<p>After ebay fees and P&amp;P the total was £400 which I have donated to the Raspberry Pi Foundation as can be seen below, more will be coming in a future post to show what this money will go towards. </p>



<figure><img data-attachment-id="3653" data-permalink="https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/image-9/" data-orig-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=1128%2C1062&amp;ssl=1" data-orig-size="1128,1062" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-9" data-image-description="" data-medium-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=300%2C282&amp;ssl=1" data-large-file="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?fit=750%2C706&amp;ssl=1" loading="lazy" width="750" height="706" src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=1024%2C964&amp;ssl=1 1024w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=300%2C282&amp;ssl=1 300w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=768%2C723&amp;ssl=1 768w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?w=1128&amp;ssl=1 1128w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=1024%2C964&amp;ssl=1 1024w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=300%2C282&amp;ssl=1 300w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=768%2C723&amp;ssl=1 768w, https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?w=1128&amp;ssl=1 1128w" data-lazy-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image-9.png?resize=750%2C706&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Donation to the Raspberry Pi foundation</figcaption></figure>



<h2>Replacing and Upgrading Damaged SD Card Slots</h2>



<p>A large amount of the Pi’s had damaged SD card slots, the original slots are made of plastic which was fairly brittle in 2012 when they were released and they really haven’t aged well! </p>



<figure><img data-attachment-id="3649" data-permalink="https://blog.jmdawson.co.uk/img_1561/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1612006255&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.16666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1561" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="750" height="1000" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1561.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>As can be seen on this image the slots have crumbled meaning they no longer hold an SD card. I managed to source the original SD card slots although the seller wanted £2 each for them which just wasn’t worthwhile. I managed to source upgraded metal SD card slots for £0.14p each on aliexpress here: <a href="https://www.aliexpress.com/item/33012711993.html" target="_blank" rel="noreferrer noopener">https://www.aliexpress.com/item/33012711993.html</a></p>



<div><p>Removing the old SD card slot was easy, using a pair of snips I cut as much of the plastic away as possible leaving only the pins to remove. I did this using a soldering iron rather than hot air. </p><p>Installing the new SD card slot was equally as easy, the new slots don’t have the SD card detection switch built in meaning that the detection pads need to be bridged with Solder as can be seen in the image below:</p></div>



<figure><img data-attachment-id="3650" data-permalink="https://blog.jmdawson.co.uk/img_1562/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1612006273&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1562" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="750" height="1000" src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-old-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i2.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1562.jpg?resize=750%2C1000&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Raspberry Pi with the SD card slot replaced. </figcaption></figure>



<p>Overall this was a very easy repair, I will post some detailed guides or maybe even videos on the repairs once I get through some of the backlog so don’t worry if this repair wasn’t in-depth enough for you. </p>



<h2>Conclusion</h2>



<div><p>This SD card slots arriving from China allows me to repair a further 30 of the damaged Raspberry Pi’s which will be for sale soon – Remember that the profits from these sales goes to the Raspberry Pi Foundation. </p><p>The pace will be slowing down a little once this batch of repairs are complete as I have some upcoming hardware reviews I need to prepare for which will be showcased in future posts. </p></div>



<p>As always please leave a comment and share your thoughts on the repair process. </p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25972094</guid>
            <pubDate>Sat, 30 Jan 2021 19:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal Basic Income Is Superior to a $15 Minimum Wage (2019)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 160 (<a href="https://news.ycombinator.com/item?id=25971227">thread link</a>) | @joeyespo
<br/>
January 30, 2021 | https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/ | <a href="https://web.archive.org/web/*/https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="53c18a7c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><em>In this piece, author Jessica Flanigan makes the case that UBI is a better solution than raising the minimum wage, because UBI reaches all workers, paid and unpaid, and would also provide all workers the bargaining power to better choose where and how they want to work. — Scott Santens, Editor, BIT</em></p>
<p>The <a href="https://www.bls.gov/news.release/empsit.nr0.htm?source=post_page---------------------------">latest jobs report from the BLS</a> reports a sudden acceleration of an ongoing trend of job growth, and unemployment in the US is now around 3.7 percent. Despite these impressive job numbers, <a href="https://www.brookings.edu/blog/up-front/2018/10/04/if-real-wages-arent-rising-how-is-household-income-going-up/?source=post_page---------------------------">real wages remain low</a> for American workers. Perhaps in light of this, The U.S. House of Representatives passed the <a href="https://www.washingtonpost.com/politics/house-democratic-push-to-raise-minimum-wage-opens-rift-over-amount-of-hike/2019/04/12/05711400-5d2d-11e9-98d4-844088d135f2_story.html?utm_term=.70a79b170fa0&amp;source=post_page---------------------------">Raise the Wage Act</a> this week, which reflects the goal of the <a href="https://en.wikipedia.org/wiki/Fight_for_$15?source=post_page---------------------------">Fight for $15</a> campaign: increase the federal minimum wage from $7.25 to $15 an hour.</p>
<p>The idea polls well. A <a href="https://thehill.com/hilltv/what-americas-thinking/426780-poll-a-majority-of-voters-want-a-15-minimum-wage?source=post_page---------------------------">majority of voters</a> support raising the federal minimum wage to $15 per hour as well. And most <a href="https://www.pbs.org/newshour/politics/2020-democratic-candidates-embrace-a-15-minimum-wage?source=post_page---------------------------">2020 Democratic presidential candidates</a>, including Joe Biden, Elizabeth Warren, and Bernie Sanders, support a $15 federal minimum wage too.</p>
<p>And it may seem that conditions are perfect for changing the federal minimum wage — unemployment is low, and the idea has a lot of support. But it’s worth thinking about proposals for a $15 federal minimum wage not only in light of Americans’ current economic circumstances but also in light of projected changes to the workforce going forward.</p>
<blockquote><p>A higher minimum wage may benefit people who have jobs, but it doesn’t make life easier for people who aren’t workers. This is what makes the idea of a Universal Basic Income or Negative Income Tax a more promising route. Essentially, if we are interested in helping those most in need, we should focus on policies that put cash in all people’s pockets instead of just the pockets of hourly employees.</p></blockquote>
<p>Ultimately, the advantage of these programs over a $15 minimum wage is that they benefit all citizens and do not disproportionately benefit workers and burden employers. And unlike other costly redistributive policies such as student loan forgiveness and universal healthcare, UBI is better suited to reflect each person’s distinctive circumstances, preferences, and personal values. Below, I outline several reasons why more people should consider the UBI as a viable public policy.</p>
<p>Considering the UBI over the Fight for $15</p>
<p>Overall, the UBI does not rely on maintaining our current economic order in the way that policies that focus on benefiting workers do. This is an advantage because the economy is very likely going to change radically in the next century. Though today’s workers are <a href="http://rh-us.mediaroom.com/2019-06-05-49-Of-Workers-Believe-AI-And-Automation-Will-Have-No-Impact-On-Their-Job?source=post_page---------------------------">not very concerned</a> about automation, <a href="https://www.theverge.com/2018/7/2/17524822/robot-automation-job-threat-what-happens-next?source=post_page---------------------------">economists</a> and <a href="https://www.theguardian.com/commentisfree/2018/aug/06/automation-destroy-millions-jobs-change?source=post_page---------------------------">policy experts</a> argue that they should be.</p>
<p>Even if new technology does not cause significant job losses, workplace transformations associated with new technology are likely to have significant <a href="https://www.brookings.edu/blog/techtank/2018/04/18/will-robots-and-ai-take-your-job-the-economic-and-political-consequences-of-automation/?source=post_page---------------------------">political and economic consequences</a>. Tying the provision of public benefits to participation in the workforce needlessly raises the stakes of any policy that could change the composition of the workforce, and therefore increases the political and economic risks associated with automation. Moreover, the UBI doesn’t limit its benefits to people who are engaged in paid employment. This has four benefits that a higher minimum wage does not.</p>
<p>First, a UBI would benefit people who do valuable unpaid labor, such as childcare and eldercare, as well as people who are employees.</p>
<p>Second, a UBI would not interfere with workers’ and employers’ freedom to set the terms and conditions of their labor. If it is possible to benefit low-income Americans without restricting their freedom to negotiate the terms and conditions of their employment relationships, officials should favor the less restrictive policies.</p>
<p>Third, a UBI would not tie people to their employers. This means that a basic income would potentially enable more economic mobility, enhance workers’ bargaining power, and enable people to stop working if they need to leave the workforce due to disability or caregiving obligations.</p>
<p>Fourth, policies that do not tie assistance to employment would not disproportionately burden employers. The debate over minimum wage increases is often framed as if employers are failing to benefit workers sufficiently. But low-wage work often helps low-skill workers more than anyone else. Without these employment opportunities, they would be even less capable of meeting their basic needs. If the justification for a higher minimum wage is that everyone should be able to support themselves, why should employers bear the full cost of meeting that goal? In contrast, a basic income enables citizens to share the cost of supporting a social safety net rather than treating employers as the only way to achieve it.</p>
<p>A significant benefit of a UBI, in contrast to other recent entitlement reforms such as student loan forgiveness and universal healthcare, is that it doesn’t tell people how to spend it. People have different values, but in-kind benefits assume that all people have the same interest in healthcare or being debt-free. This may be broadly true, but there are tradeoffs. Given the cost of these programs, it’s fair to ask whether people would be better off if we just gave them the money instead. But evidence from developing countries suggests that<a href="https://www.nytimes.com/2014/06/30/opinion/let-them-eat-cash.html?source=post_page---------------------------"> cash does help people better than alternatives</a>.</p>
<p>As I see it, the main challenge to a Basic Income proposal is affordability. Estimates vary, and some argue that a UBI would be <a href="https://socialprotection-humanrights.org/resource/universal-basic-income-proposals-in-light-of-ilo-standards-key-issues-and-global-costing-ess-%e2%94%80-working-paper-no-62/?source=post_page---------------------------">catastrophically</a> <a href="https://www.economist.com/finance-and-economics/2015/05/23/basically-unaffordable?source=post_page---------------------------">expensive</a> whereas others suggest that it is “<a href="https://medium.com/basic-income/basic-income-is-easily-affordable-8389995528b3?source=post_page---------------------------">easily affordable</a>.” Plausibly, while a UBI would save on administrative costs, it does seem that funding sustainable UBI could require making some <a href="https://www.forbes.com/sites/timworstall/2016/06/04/of-course-we-can-afford-a-universal-basic-income-do-we-want-one-though/?source=post_page---------------------------#50c7d99f323c">hard choices</a> about other social programs such as healthcare, education, and defense.</p>
<p>The UBI and Social Security</p>
<p>UBI may seem like a radical idea, but there’s a precedent for it in America. Elderly people already receive what is effectively a basic income through Social Security. Some of them continue to work, while others use their basic income (and retirement savings) to pay their bills so that they can focus on spending time with loved ones or pursuing new hobbies. Some elderly people are disabled, and Social Security enables them to leave the workforce.</p>
<p>Yet older voters <a href="https://thehill.com/hilltv/what-americas-thinking/435278-poll-most-voters-oppose-a-universal-basic-income-programs?source=post_page---------------------------">consistently</a> <a href="https://thehill.com/policy/technology/375587-gallup-poll-americans-split-on-giving-a-universal-basic-income-to-workers?source=post_page---------------------------">oppose</a> Universal Basic Income proposals while younger voters are in favor of it. Even more curiously, older voters <a href="https://www.pollingreport.com/social.htm?source=post_page---------------------------">consistently</a> <a href="https://socialsecurityworks.org/2019/03/26/social-security-polling/?source=post_page---------------------------">oppose</a> cuts to their basic income, Social Security. The difficult position for older voters is that the reasons for opposing a basic income are also reasons to oppose social security. And those who support Social Security should support a basic income as well. Those who oppose the UBI should rethink their support for Social Security. If anything, the case for a UBI is stronger than the case for Social Security because as it is currently structured, <a href="https://www.nber.org/digest/may00/w7520.html?source=post_page---------------------------">Social Security may be a slightly regressive policy</a>, in part <a href="https://www.latimes.com/business/hiltzik/la-fi-hiltzik-mortality-social-security-20180912-story.html?source=post_page---------------------------">because wealthy people live longer.</a></p>
<p><a href="https://bleedingheartlibertarians.com/2014/09/political-authority-and-the-basic-income/?source=post_page---------------------------">Elsewhere</a>, I have argued in favor of a basic income because it is a kind of compensation for the injustices associated with our existing property system. In contrast, minimum wage requirements only compound the injustices of the current system by doubling down on the idea that elevates paid employment over other kinds of potentially valuable work, discourages opportunities for low-skilled workers, and leaves non-workers out of the social safety net. A basic income is more respectful of people’s freedom, more sensitive to recipients’ values, and better suited for a rapidly changing economy.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://basicincometoday.com/opinion-universal-basic-income-is-superior-to-a-15-minimum-wage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25971227</guid>
            <pubDate>Sat, 30 Jan 2021 17:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream media using WebRTC and FFmpeg, and why it's a bad idea]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25970843">thread link</a>) | @dimes
<br/>
January 30, 2021 | https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

                                            
                                                    <header>

    
    <!-- start: .meta -->
    
    <!-- end: .meta -->

	

</header>                        
                        <section>

                            
                            
                            <div>
                                
<p><strong>Note: </strong>The original version of this post highlighted the disadvantages of using a fixed key frame interval. I’ve since learned that this problem can be avoided using intra refresh in the H264 stream.</p>



<p>Streaming media. specifically video, is a fickle beast. This will be a short post, but it will cover everything you need to know to stream media using FFmpeg to WebRTC clients. This technique has many applications, such as streaming synchronized videos to users. </p>



<h2>Setting up the input</h2>



<p>Before inputting a file into FFmpeg, we need to pass a few flags:</p>



<pre><code>&gt; ffmpeg \
  -v info \
  -fflags +genpts \
  -protocol_whitelist pipe,tls,file,http,https,tcp,rtp \</code></pre>



<p>These flags set the log level to info, generate pts if they’re missing, and sets up the protocols we can use. Next we need to provide the input to FFmpeg.</p>



<pre><code>-i in.mp4</code></pre>



<p>In this example, a file name <code>in.mp4</code> is used, but a http(s) URL could also be used. This command starts playback at the beginning of the input file. If you want to start playback in the middle of the input file, then you can add the <code>-ss &lt;time in secs&gt;</code> flag <strong>before</strong> <code>-i</code>.</p>



<h2>Video arguments</h2>



<p>Now the video needs to be converted to an appropriate format for streaming. The format is specific to the application, but common codecs are H264, VP8, and VP9. This example uses H264 due to its ubiquitous support.</p>



<pre><code>-vf realtime,scale=w=min(iw\,1280):h=-2 \
-map 0:v:0 \
-c:v libx264 \
-x264-params intra-refresh=1,fast-pskip=0
-threads 3 \
-profile:v baseline \
-level:v 3.1 \
-pix_fmt yuv420p \
-tune zerolatency \
-minrate 500K \
-maxrate 1.3M \
-bufsize 500K \</code></pre>



<p><code>-vf</code> specifies the video filters to apply. Here, two filters are applied. The first is <code>realtime</code>, which causes playback to happen in real time, which is necessary for streaming. This filter is similar to the <code>-re</code> flag, but works much better with the start time flag (<code>-ss</code>). The second filter scales the video width to a maximum of 1280 pixels while maintaining the aspect ratio. This is important to keep the bitrate appropriate for real time streaming. </p>



<p>The <code>intra-refresh</code> parameter allows users to consume the video stream mid-way through by providing enough metadata over multiple inter frames to decode a full frame. The <code>fast-pskip=0</code>is required for <code>intra-refresh</code> to work if the source video files contains very few frames, which can happen if the video displays static images for long periods of time. There may be another way around this, but I’m not aware of it. </p>



<p>Another important parameter is the <code>-threads 3</code> flag. FFmpeg will use many threads by the default. Normally, this is good because it produces the final result as fast as possible. For real time encoding, however, using a large number of threads has some overhead that can slow down real time output. Using many threads is also a bad idea if you’re running multiple instances of FFmpeg concurrently.</p>



<p>The next two parametrs <code>-profile:v</code> and <code>-level:v</code> specify the profile and level to use for the encoding. These are specific to H264. WebRTC clients can only decode certain profiles and levels, so these need to match the specific configuration of the application. These roughly correspond to the profile-level-id of <code>42e01f</code>. </p>



<p>The pixel format is set to <code>yuv420p</code> using the <code>-pix_fmt</code> flag. This is required as this is the only pixel format supported by WebRTC. <code>-tune zerolatency</code> tunes the encoder for low latency streaming.</p>



<p>Next up are the bitrate parameters. When streaming media, the bitrate should be as low as possible while maintaining the desired quality. This ensures all clients can consume the video in real time. Omitting the <code>-minrate</code> parameter can cause FFmpeg to produce output with an unnecessarily high bitrate. Setting the <code>-maxrate</code> is equally important. A DSL connection can only pull down around 2 Mbps. In order for users to watch the video, they must be able to download it in real time, so the maximum bitrate has to be lower than the slowest connection among your users. Another consideration is that the streaming video might not be the only bandwidth consuming task on the user’s network.</p>



<h2>Audio arguments</h2>



<p>The audio arguments are much simpler.</p>



<pre><code>-af arealtime \
-map 0:a:0 \
-c:a libopus \
-ab 128k \
-ac 2 \
-ar 48000 \</code></pre>



<p>The main thing to note here is that the <code>arealtime</code> filter is used, which is similar to the <code>realtime</code> filter, but for audio.</p>



<h2>Output arguments</h2>



<p>The output can be piped to an RTP endpoint using the <code>tee</code> psuedomuxer. Unfortunately, FFmpeg does not support multiplexing over RTP, so you’ll need two separate RTP endpoints, one for the video stream and one for the audio stream. </p>



<pre><code>-f tee \
[select=a:f=rtp:ssrc=1111:payload_type=&lt;audio-payload_type&gt;]rtp://&lt;audio-ip&gt;:&lt;audio-port&gt;?rtcpport=&lt;audio-rtcpport&gt;|[select=v:f=rtp:ssrc=2222:payload_type=&lt;video-payload_type&gt;]rtp://&lt;video-ip&gt;:&lt;video-port&gt;?rtcpport=&lt;video-rtcpport&gt;</code></pre>



<p>Now you can stream video over RTP! The full command is</p>



<pre><code>&gt; ffmpeg \
  -v info \
  -fflags +genpts \
  -protocol_whitelist pipe,tls,file,http,https,tcp,rtp \
  -i in.mp4
  -vf realtime,scale=w=min(iw\,1280):h=-2 \
  -map 0:v:0 \
  -c:v libx264 \
  -x264-params intra-refresh=1,fast-pskip=0
  -threads 3 \
  -profile:v baseline \
  -level:v 3.1 \
  -pix_fmt yuv420p \
  -tune zerolatency \
  -minrate 500K \
  -maxrate 1.3M \
  -bufsize 500K \
  -af arealtime \
  -map 0:a:0 \
  -c:a libopus \
  -ab 128k \
  -ac 2 \
  -ar 48000 \
  -f tee \
  [select=a:f=rtp:ssrc=1111:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;|[select=v:f=rtp:ssrc=2222:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;</code></pre>
                                                            </div>
                            

                              

                                                        
                                                            
                                                        
                                                            
                            
                            

                            	                           

                            
                        </section>

                    </article></div>]]>
            </description>
            <link>https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970843</guid>
            <pubDate>Sat, 30 Jan 2021 17:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A few HiDPI tricks for Linux]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25970690">thread link</a>) | @woodruffw
<br/>
January 30, 2021 | https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 24, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h2 id="background">Background</h2>

<p>I recently switched my home office to a 2-by-4K HiDPI setup, like so:</p>

<p><a href="https://blog.yossarian.net/assets/hidpi-setup.jpg"><img src="https://blog.yossarian.net/assets/hidpi-setup.jpg" alt="A picture of my home office."></a></p>

<p>As part of that switch, I needed to configure parts of my Linux environment (which was originally
stock Ubuntu, but is now <a href="https://i3wm.org/">i3</a> with a heavily customized userspace) to function
correctly on HiDPI displays.</p>

<p>This post will document most of the changes I applied. Hopefully others will find it useful for
their own HiDPI setups.</p>

<h2 id="90-of-the-way-x11-resources">90% of the way: X11 resources</h2>

<p>As it turns out, there’s a (nearly) one-stop location for configuring the default DPI for
X11 applications: the <code>Xft.dpi</code> setting.</p>

<p>There are lots of ways to configure X11, but I personally use an <code>~/.Xresources</code> file:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>Xft</span>.<span>dpi</span>: <span>163</span>
<span># not used directly; more on this later
</span><span>janus</span>.<span>fractionalDpi</span>: <span>1</span>.<span>63</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Where <code>163</code> and <code>1.63</code> are my DPI and its fractional form, respectively.</p>

<p>On my system, <code>~/.Xresources</code> gets loaded into the X resource database automatically by some
magic that I never configured. However, if yours doesn’t (or you use a different resource file),
you can always tell i3 (or your WM of choice) to load it explicitly with <code>xrdb</code>.</p>

<p>For example, in <code>~/.config/i3/config</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>exec</span> <span>--no-startup-id</span> xrdb ~/.Xresources
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With just this, about 90% of my applications (including GTK based ones, like Firefox) scaled
correctly and were usable without any font or custom scaling changes. Not bad for a single line!</p>

<h2 id="per-application-fixes">Per-application fixes</h2>

<h3 id="spotify">Spotify</h3>

<p>Spotify’s Linux application is a <a href="https://bitbucket.org/chromiumembedded/cef/src/master/">CEF</a>
shell. For reasons that are unclear to me, it doesn’t respect <code>Xft.dpi</code> while normal Chromium
(via <code>snap</code> or <code>apt</code>) does.</p>

<p>To get it to scale correctly, I needed to pass <code>--force-device-scale-factor=1.63</code> to it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>spotify <span>--force-device-scale-factor</span><span>=</span>1.63
</pre></td></tr></tbody></table></code></pre></div></div>

<p>At this point, it became clear to me that the fractional form of my DPI would be nice to set in
as few places as possible, to avoid duplication. Hence the <code>janus.fractionalDpi</code><sup id="fnref:hostname" role="doc-noteref"><a href="#fn:hostname">1</a></sup> above,
and
<a href="https://github.com/woodruffw/dotfiles/blob/master/scripts/spotify">this little <code>spotify</code> wrapper</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span># see the actual script linked above for some program-finding stupidity</span>
<span>real_spotify</span><span>=</span>/snap/bin/spotify

<span># grab the correct fractional DPI from the X resource DB</span>
<span>dpi</span><span>=</span><span>$(</span>xrdb <span>-query</span> | <span>grep</span> <span>"</span><span>$(</span><span>hostname</span><span>)</span><span>.fractionalDpi"</span> | <span>cut</span> <span>-f2</span><span>)</span>
<span>"</span><span>${</span><span>real_spotify</span><span>}</span><span>"</span> <span>--force-device-scale-factor</span><span>=</span><span>"</span><span>${</span><span>dpi</span><span>}</span><span>"</span> <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="sublime-text">Sublime Text</h3>

<p>I use <a href="https://www.sublimetext.com/3">Sublime Text 3</a> as my primary editor. As far as I can tell
it doesn’t use either GTK or Qt (or any other open-source GUI framework), which is probably why
it doesn’t respect <code>Xft.dpi</code>.</p>

<p>To get Sublime Text to scale correctly, I had to set <code>ui_scale</code> to the appropriate fractional DPI
in my user preferences (<code>~/.config/sublime-text-3/Preferences.sublime-settings</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>{</span><span>
  </span><span>"ui_scale"</span><span>:</span><span> </span><span>1.63</span><span>,</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Some lingering pain points:</p>

<ul>
  <li>
    <p>Sublime Text’s input is noticeably laggy when the UI is scaled. It’s not so laggy as to be
unusable, but it’s definitely noticeable even if you aren’t sensitive to latencies (I’m not).</p>
  </li>
  <li>
    <p>Mousing between Sublime Text and other windows causes noticeable stutter/hiccuping during
video playback. I haven’t dug into the X events yet, but my guess is that it’s got some kind
of pessimistic (and serial) <code>XFlush</code> or <code>XSync</code> that takes a decent bit of time on a larger window
buffer. It doesn’t happen with smaller windows (either floating or fixed).</p>
  </li>
</ul>

<h3 id="open-broadcaster-software-obs">Open Broadcaster Software (OBS)</h3>

<p>I haven’t used it recently, but I used to use <a href="https://obsproject.com/">OBS</a> to stream myself
working on open source projects.</p>

<p>When I switched monitors, I noticed that the embedded preview window for my scenes had stopped
working. OBS <em>itself</em> was still fully functional and the <em>separate</em> preview window still worked,
but the embedded preview was always filled in with black pixels.</p>

<p>After a decent bit of hair-pulling, I found a Qt environment variable that “fixed” it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>QT_AUTO_SCREEN_SCALE_FACTOR</span><span>=</span>0 obs
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I still don’t understand why that fixed it, but now my OBS is scaled correctly <strong>and</strong> has a
functional preview embed. I also posted this fix to the
<a href="https://obsproject.com/forum/threads/bug-fix-black-preview-embed-window-on-linux-w-hidpi-monitors.135041/">OBS forum</a>.</p>

<h3 id="feh">feh</h3>

<p>I use <a href="https://github.com/derf/feh"><code>feh</code></a> as my image viewer. By default, it seems to use
a bitmap font that’s incredibly small on HiDPI displays.</p>

<p>To fix it, I modified by default theme to use my distro supplied Ubuntu Roman-face font in
14pt.</p>

<p>In <code>~/.config/feh/themes</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>feh <span>--borderless</span> <span>--scale-down</span> <span>--conversion-timeout</span> 1 <span>\</span>
  <span>--fontpath</span> /usr/share/fonts/truetype/ubuntu <span>--menu-font</span> Ubuntu-R/14
</pre></td></tr></tbody></table></code></pre></div></div>

<p>One thing I haven’t figured out: when I open some higher-resolution images in <code>feh</code>, they’re
occasionally shifted to the right with transparent pixels where some of the image should be.
Clicking and dragging inside the image window causes it to re-render correctly, as does
resizing the window. Not a huge deal, but slightly annoying.</p>

<h3 id="dunst">dunst</h3>

<p>I use <a href="https://dunst-project.org/"><code>dunst</code></a> as my notification daemon.</p>

<p>It didn’t <strong>need</strong> any HiDPI-specific configuration, but I took the opportunity to make its
notifications slightly more readable on these newer displays.</p>

<p>In <code>~/.config/dunst/dunstrc</code> (among many other settings):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>monitor</span> = <span>0</span>
<span>follow</span> = <span>mouse</span>
<span>geometry</span> = <span>"600x120-30+20"</span>
<span>icon_position</span> = <span>left</span>
<span>max_icon_size</span> = <span>64</span>
<span>icon_path</span> = /<span>usr</span>/<span>share</span>/<span>icons</span>/<span>gnome</span>/<span>64</span><span>x64</span>/<span>status</span>/:/<span>usr</span>/<span>share</span>/<span>icons</span>/<span>gnome</span>/<span>64</span><span>x64</span>/<span>devices</span>/
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="other-bits">Other bits</h2>

<h3 id="mouse-acceleration">Mouse acceleration</h3>

<p>My new displays are individually larger and significantly more dense than my previous ones, making
my mouse feel sluggish. I originally configured my mouse acceleration with
<a href="https://www.x.org/archive/X11R7.5/doc/man/man1/xset.1.html"><code>xset</code></a>, but at some point my
system switched to <code>libinput</code> and <code>libinput</code>-based inputs apparently don’t respect <code>xset</code> anymore
(or never did?). Sigh.</p>

<p>The fix is to use <code>xinput</code> instead, with either symbolic names or XIDs for the device and setting
being controlled. For example, this is what I use to set my mouse’s acceleration to the maximum
(<code>1.0</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>xinput <span>--set-prop</span> <span>"USB Optical Mouse"</span> <span>"libinput Accel Speed"</span> 1.0
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Your device and setting names may vary, of course, as may their value ranges (mine happened to be
<code>0.0</code> to <code>1.0</code>). You can use <code>xinput</code> on its own to list the names and XIDs of your devices;
<code>xinput list-props &lt;XID-or-name&gt;</code> can be used to dump a particular device’s properties and
their current values.</p>

<h3 id="i3-workspaces">i3 workspaces</h3>

<p>I use i3’s <a href="https://i3wm.org/docs/layout-saving.html">layout saving/restoring</a> functionality
to automatically load all of my workspaces and their applications when I log in.</p>

<p>Those layouts are stored in a (relaxed) JSON format via <code>i3-save-tree</code>, and contain hardcoded
coordinates. To update them for my new monitors, I just had to recreate each of my workspaces
once on my new monitors and dump them:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span># for each workspace (1A, 1B, ...)</span>
i3-save-tree <span>--workspace</span> 1A <span>&gt;</span> ~/.config/i3/workspaces/1A.json
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…and then fix them up manually to enable the appropriate application swallowing rules.</p>

<h3 id="hexchat">HexChat</h3>

<p>I use <a href="https://hexchat.github.io/index.html">HexChat</a> for IRC.</p>

<p>HexChat’s config file includes individual offsets for each of the sub-panes in the GUI,
which means that it breaks badly if you change your monitor dimensions. I couldn’t figure out
how to fix them, so I ended up deleting my main <code>~/.config/hexchat/hexchat.conf</code> entirely and
recreating my preferred layout from memory. YMMV.</p>

<h3 id="system-icons">System icons</h3>

<p>I didn’t have to make any changes with respect to my system icon sizes, which is <em>probably</em>
because I actually see very few icons during normal i3 usage. Once again, YMMV.</p>

<h2 id="wrapup">Wrapup</h2>

<p>Switching from a set of 3 FHD monitors to two 4K HiDPI ones was <em>relatively</em> painless. The
problems that I had, unsurprisingly, were primarily with the few proprietary applications I use
needing to be spoon-feed DPI information in their own ways — every other problem was
either a bug (OBS + Qt) or a matter of more general reconfiguration.</p>

<hr>



<hr>


<a href="https://www.reddit.com/r/enosuchblog/comments/kjhhp8/a_few_hidpi_tricks_for_linux/">Reddit discussion</a>

<hr>



  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/24/A-few-HiDPI-tricks-for-Linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25970690</guid>
            <pubDate>Sat, 30 Jan 2021 17:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating my awesome Windows 10 dev setup]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25965231">thread link</a>) | @indigodaddy
<br/>
January 29, 2021 | https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/ | <a href="https://web.archive.org/web/*/https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="background"><a href="#background">→</a>Background</h2><p>I recently got the chance to completely reset my Windows 10 machine, and took advantage of the
opportunity to create a dev environment I would love. These were my high-level goals:</p><ul><li>Make WSL my primary dev environment</li><li>Use VSCode as my primary editor</li><li>Have a beautiful terminal</li></ul><h2 id="wsl-%26-vscode"><a href="#wsl-%26-vscode">→</a>WSL &amp; VSCode</h2><p>To achieve this, I started by installing WSL 2. I went with an Ubuntu distro because that's what
I've had the most experience with in the past. You can find instructions on installing WSL and/or
upgrading it to WSL 2 in the <a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">official
docs</a>.</p><p>Next I installed <a href="https://code.visualstudio.com/">VSCode</a>, and the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack">Remote Development extension
pack</a>
which is where things start to get fun. With this extension pack installed, you can edit files in
the WSL filesystem seamlessly with VSCode.</p><h2 id="windows-terminal"><a href="#windows-terminal">→</a>Windows Terminal</h2><p>To get my beautiful terminal going, I installed <a href="https://devblogs.microsoft.com/commandline/windows-terminal-1-0/">Windows
Terminal</a> (WT), which is an
awesome new terminal experience for Windows from Microsoft.</p><p>Although I wanted WSL to be my primary dev environment, I still wanted working in Windows to be a
nice experience as well, so I wanted to make sure my PowerShell terminal was great too. To get that
going, I also installed the latest <a href="https://devblogs.microsoft.com/powershell/announcing-powershell-7-0/">PowerShell
7</a>.</p><p>Now it was time to setup my WT profiles. By default, WT creates a profile for WSL, PowerShell, cmd,
and Azure Cloud Shell. I'm not interested in using cmd or Azure Cloud Shell, and I'm going to be
using PowerShell 7 instead of PowerShell, so I disabled all but the WSL shell. To do this, simply
add the <code>"hidden": true</code> property to the profiles in the WT settings file (click the dropdown in the
header bar and then Settings or <span><kbd>Ctrl</kbd>+<kbd>,</kbd></span>).</p><h3 id="powershell-wt-profile"><a href="#powershell-wt-profile">→</a>PowerShell WT Profile</h3><p>Now to create my PowerShell 7 profile, I added the following object to the profiles array:</p><pre data-language="json" data-index="0"><code><span><span>{</span></span>
<span><span>  </span><span>"guid"</span><span>: </span><span>"</span><span>{346d54ee-6282-41c7-846a-0a2fa38ff66b}</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"name"</span><span>: </span><span>"</span><span>PowerShell</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"commandline"</span><span>: </span><span>"</span><span>pwsh.exe</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"icon"</span><span>: </span><span>"</span><span>%SystemRoot%</span><span>\\</span><span>Installer</span><span>\\</span><span>{8B844F39-E6EE-486B-BE85-96A485AE2B96}</span><span>\\</span><span>PowerShellExe.ico</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"startingDirectory"</span><span>: </span><span>"</span><span>D:</span><span>\\</span><span>code</span><span>"</span></span>
<span><span>}</span></span></code></pre><p>A few things to note:</p><ul><li>To generate a GUID, you can use the <a href="https://www.guidgenerator.com/online-guid-generator.aspx">Online GUID
Generator</a> website</li><li>I am using the <code>pwsh.exe</code> command instead of <code>powershell.exe</code> to use PowerShell 7</li><li>Follow these steps to find the icon path on your system:<ol><li>Open your Start menu and search for PowerShell 7</li><li>Right click on the app and click "Open file location"</li><li>In the file explorer that opens, right click the shortcut and click "Properties"</li><li>On the "Shortcut" tab, click the "Change Icon..." button and copy the file path</li></ol></li><li>I like to set the starting directory to be where I keep all my projects, and ideally this is near
the root of a drive to keep file paths as short as possible</li></ul><h3 id="ubuntu-wt-profile"><a href="#ubuntu-wt-profile">→</a>Ubuntu WT Profile</h3><p>Since I want to make WSL my primary environment, I moved its profile object to the top of the list
so that it will appear first in the new tab dropdown. Then I replaced the top-level <code>defaultProfile</code>
property with the WSL profile's <code>guid</code> property to make it the profile that is opened automatically
when WT launches.</p><p>Similarly to PowerShell, I wanted the starting directory to be <code>~/code</code>. If you try setting that
directly in the WT configuration, you'll find it doesn't work because WT doesn't know how to resolve
it. You can use an absolute path to get there instead, and you need to use a Windows file path that
WT can understand. You can access a WSL distro's file system from Windows using <code>\\wsl$\&lt;distro&gt;</code>, so, I added this property to the Ubuntu profile object: <code>"startingDirectory": "\\\\wsl$\\Ubuntu\\home\\blake\\code"</code> (where <code>Ubuntu</code> should be replaced with the name of your WSL
distro and <code>blake</code> with your WSL username).</p><h3 id="wt-theme"><a href="#wt-theme">→</a>WT Theme</h3><p>Finally, I wanted to get a new theme for my WT. I decided I would like to use the same colour scheme
as I was using for VSCode at the time, which was the <a href="https://marketplace.visualstudio.com/items?itemName=sdras.night-owl">Night
Owl</a> theme. So (naturally), <a href="https://chimerical.ca/posts/generate-windows-terminal-scheme">I
created</a> a <a href="https://marketplace.visualstudio.com/items?itemName=blake-mealey.generate-wt-scheme">VSCode
plugin</a> to
automatically generate a WT theme.</p><p>Here's what my terminal looks like with the Night Owl theme:</p><p><span>
      <a href="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Windows Terminal with Night Owl" title="Windows Terminal with Night Owl" src="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png" srcset="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/63868/terminal.png 250w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/0b533/terminal.png 500w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png 1000w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png 1232w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><h2 id="shell-profiles"><a href="#shell-profiles">→</a>Shell Profiles</h2><p>Next up I wanted to get my shell profiles started. We'll iterate on these more later on. Your shell
profile is a script that gets run when the terminal starts which can be used to configure the
current environment. For PowerShell, this will be a PowerShell script and for WSL it will be a bash
script.</p><h3 id="powershell-profile"><a href="#powershell-profile">→</a>PowerShell Profile</h3><p>Let's start with PowerShell again. You can run <code>echo $PROFILE</code> to see if a profile script already
exists. For me it did, and it was located at
<code>C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</code>. If it doesn't exist for you,
it's not a big deal. It seems that PowerShell looks in a <a href="https://devblogs.microsoft.com/scripting/understanding-the-six-powershell-profiles/">variety of
places</a> and you
can just create a script in the appropriate place and it should work. Here's what I added to my
profile script:</p><pre data-language="ps1" data-index="1"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value nano</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name edit </span><span>-</span><span>Value editor</span></span>
<span></span>
<span><span>function</span><span> </span><span>profile_alias</span><span> { editor $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name profile </span><span>-</span><span>Value profile_alias</span></span>
<span></span>
<span><span>function</span><span> </span><span>reload_alias</span><span> { </span><span>&amp;</span><span> $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name reload </span><span>-</span><span>Value reload_alias</span></span></code></pre><p>Let's break this down a bit. First of all, I am creating a couple aliases (<code>editor</code> and <code>edit</code>) for
my in-terminal editor. I prefer to use a terminal editor instead of a GUI editor because it reduces
context switching when working in the terminal, and is much faster to load the file to make a quick
edit. That said, if you wanted to use VSCode, you could replace <code>nano</code> with <code>code</code>.</p><p>The reason I create an alias for my editor command is so that I can change the editor at any time
and not have to change my muscle memory to use the new command. It also means I can create more
aliases that open the editor without having to change all of them if I change my editor.</p><p>Next, I add the <code>profile</code> alias which opens the profile script in my editor (the <code>editor</code> alias is
already coming in handy!). This is great because now I don't need to remember where my profile is
ever again, I can just run <code>profile</code> and can start editing it right away. I also add a <code>reload</code>
alias which simply reloads the shell using the profile script. This lets me use my changes to the
profile script without having to create a new terminal instance.</p><h3 id="bash-profile"><a href="#bash-profile">→</a>Bash Profile</h3><p>Now let's do the same thing for bash. In bash, the profile is a bash script located at <code>~/.bashrc</code>.
By default it contains a lot of stuff already, so I like to add my changes to the bottom of the
script. Here's what I added:</p><pre data-language="bash" data-index="2"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>nano</span><span>"</span></span>
<span><span>alias</span><span> editor=</span><span>"</span><span>$EDITOR</span><span>"</span></span>
<span><span>alias</span><span> edit=</span><span>"</span><span>editor</span><span>"</span></span>
<span></span>
<span><span>export</span><span> PROFILE=</span><span>"</span><span>~/.bashrc</span><span>"</span></span>
<span><span>alias</span><span> profile=</span><span>"</span><span>editor </span><span>$PROFILE</span><span>"</span></span>
<span><span>alias</span><span> reload=</span><span>"</span><span>source </span><span>$PROFILE</span><span>"</span></span>
<span></span>
<span><span>alias</span><span> explorer=</span><span>"</span><span>explorer.exe</span><span>"</span></span></code></pre><p>This is very similar to the PowerShell script. First, we create an <code>EDITOR</code> environment variable.
Some Linux programs respect the <code>EDITOR</code> variable, so it's a good idea to set it if you want more
programs to know which editor you want to use. Then we use <code>EDITOR</code> to create our <code>editor</code> and
<code>edit</code> aliases just like before.</p><p>Then, I add the same <code>profile</code> and <code>reload</code> aliases to edit and reload the profile script.</p><p>Finally, I added another alias which maps <code>explorer</code> to <code>explorer.exe</code> which makes it the same
command for opening the Windows File Explorer in WSL as in PowerShell.</p><h2 id="terminal-editor"><a href="#terminal-editor">→</a>Terminal Editor</h2><p>Let's revisit our terminal editor. I started with nano because it's a pretty intuitive and easy to
use editor for terminals. I don't have a lot of terminal editor experience, so I'm not very handy
with Vim, and even nano can be a bit awkward to use.</p><p>So, I did a bit of research to see if there were any editors that had more similar keyboard
shortcuts and navigation to a modern GUI text editor, like VSCode. I found
<a href="https://micro-editor.github.io/">micro</a> which is available cross-platform, which is perfect!</p><h3 id="powershell-editor"><a href="#powershell-editor">→</a>PowerShell Editor</h3><p>Let's install it. In PowerShell, it's most easily installed via <a href="https://scoop.sh/">scoop</a> or
<a href="https://chocolatey.org/">Chocolatey</a>. If you don't have either installed yet I'd highly recommend
you do, as it makes installing programs in Windows a much easier experience. I'm going to use scoop
for the purposes of this guide. With scoop installed, simply run <code>scoop install micro</code>. Now you can
run <code>micro</code> to edit your files.</p><p>Let's update our profile script to use it:</p><pre data-language="ps1" data-index="3"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value micro</span></span></code></pre><h3 id="ubuntu-editor"><a href="#ubuntu-editor">→</a>Ubuntu Editor</h3><p>To install on Ubuntu, we can run the install script from the micro website:</p><pre data-language="bash" data-index="4"><code><span><span>curl https://getmic.ro </span><span>|</span><span> bash</span></span></code></pre><p>Now we can update our bash profile to use it:</p><pre data-language="bash" data-index="5"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>micro</span><span>"</span></span></code></pre><h3 id="micro-theme"><a href="#micro-theme">→</a>Micro Theme</h3><p>One issue you might notice once you start editing in micro is that it's theme clashes with your WT
theme. One option could be to port your WT theme to micro, but this is quite a bit of work. I found
using the built-in <code>simple</code> theme uses your terminal theme's background colour and seems to fit
quite well for me.</p><p>To do this, you'll have to configure micro for PowerShell and WSL separately. To configure it, open
micro, press <span><kbd>Ctrl</kbd>+<kbd>E</kbd></span> to open the command prompt, then enter the command <code>set colorscheme simple</code>.</p><h2 id="terminal-prompt"><a href="#terminal-prompt">→</a>Terminal Prompt</h2><p>Finally, to make our terminal really pretty, we need to customize the prompt. There's lots of
options out there for this, but the most popular one seems to be
<a href="https://github.com/ohmyzsh/ohmyzsh">ohmyzsh</a> for Bash and
<a href="https://github.com/JanDeDobbeleer/oh-my-posh">oh-my-posh</a> for PowerShell. I'm not a huge fan of
these because in my experience they slow down the terminal to a point which makes me frustrated to
use them, and since they are separate solutions for each environment they must be configured separately.</p><p>Enter <a href="https://starship.rs/">Starship</a>, a "blazing-fast," cross-platform alternative with a
delightfully simple prompt and some awesome customization (with the promise of even more coming in
future releases). Since WSL and PowerShell both have access to the Windows filesystem, we can even
store the Starship configuration in a central place and have both pull from it.</p><h3 id="powershell-starship"><a href="#powershell-starship">→</a>PowerShell Starship</h3><p>To install Starship for PowerShell, we can again use scoop: <code>scoop install starship</code>. To load
starship, we again need to edit our profile (now with our snazzy editor and single-command alias):</p><pre data-language="ps1" data-index="6"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Invoke-Expression</span><span> (</span><span>&amp;</span><span>starship init powershell)</span></span></code></pre><p>Now we can run our <code>reload</code> alias and see the beautiful prompt immediately.</p><h3 id="bash-starship"><a href="#bash-starship">→</a>Bash Starship</h3><p>Installing Starship for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</a></em></p>]]>
            </description>
            <link>https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25965231</guid>
            <pubDate>Sat, 30 Jan 2021 01:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Siliconpr0n: High Resolution Chip Maps]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25964865">thread link</a>) | @lelf
<br/>
January 29, 2021 | https://siliconpr0n.org/map/ | <a href="https://web.archive.org/web/*/https://siliconpr0n.org/map/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://siliconpr0n.org/map/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964865</guid>
            <pubDate>Sat, 30 Jan 2021 00:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1 supports “billion of colors” a.k.a. HDR 10-bit output]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 195 (<a href="https://news.ycombinator.com/item?id=25964501">thread link</a>) | @singhkays
<br/>
January 29, 2021 | https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/ | <a href="https://web.archive.org/web/*/https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When most people hear Apple in a sentence, their next thought is likely the color. This is because color has always played an exciting role in Apple’s history: from the original Mac to the iMac, from the G3 to the Cube, from Bondi Blue to Snow White. The introduction of color played a vital part in these products' success as it helped create strong visual brand recognition.</p>
<p>The prominent use of color no doubt stems from Steve Jobs obsessing over the smallest details. For instance, there was a time when Steve spent 30 minutes picking the <a href="https://www.businessinsider.com/steve-jobs-attention-to-detail-2011-10">perfect shade of gray for the restroom signs</a>! and another time <a href="https://www.businessinsider.com/steve-jobs-attention-to-detail-2011-10#he-insisted-on-making-the-circuit-board-inside-the-mac-look-great-2">when he insisted on making the circuit board inside the Mac look great</a>. An engineer told him:</p>
<blockquote>
<p>“The only thing that matters is how well it works. Nobody is going to see the PC board.”</p>
</blockquote>
<p>Jobs response was:</p>
<blockquote>
<p>“I want it to be as beautiful as possible, even if it’s inside the box. A great carpenter isn’t going to use lousy wood for the back of a cabinet, even though nobody’s going to see it.”</p>
</blockquote>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_800x0_resize_q75_lanczos.jpg" alt="Apple iMac in Bondi Blue color"> <figcaption>
<p>iMac G3 in Bondi Blue released in 1998
<a href="https://en.wikipedia.org/wiki/IMac_G3">[Wikipedia]</a></p>
</figcaption>
</figure>
<p>For as long as we’ve had TVs, color has been an important metric to judge the display’s quality. We’ve witnessed technologies such as CRT, Plasma, and LCD compete to display the most life-like color. The newest technology to enter this fray is High Dynamic Range, aka HDR. The aim remains the same i.e. to recreate an image closer to that seen by the human eye. Traditionally, every video has been delivered in an 8-bit specification known as Rec. 709, displaying up to millions of shades of colors. HDR improves upon this by stepping up to 10 or 12-bit standard known as Rec. 2020 or BT.2020, representing 60 times more color combinations with smoother shade gradations aka “Billions of colors”.</p>
<p>Apple has generally been at the forefront of adopting the latest display technology. Some notable examples include - introducing high-resolution Retina Displays when 1366x768 was a very common resolution for Windows laptops, <a href="https://www.engadget.com/2015-10-30-apple-imac-5k-el-capitan-billions-colors.html">Shipping 2015 Retina iMacs</a> with 10-bit displays i.e. “Billions of colors”, <a href="https://www.apple.com/newsroom/2017/09/apple-tv-4k-brings-home-the-magic-of-cinema-with-4k-and-hdr/">Apple TV 4K, which was one of the first consumer devices to support Dolby Vision HDR in 2017</a>, <a href="https://www.apple.com/newsroom/2017/09/apple-tv-4k-brings-home-the-magic-of-cinema-with-4k-and-hdr/">automatic upgrades of HD titles to Dolby Vision</a> for iTunes users - a move that is still unrivaled, iPhone 12 which is the first smartphone to be able to <a href="https://www.apple.com/newsroom/2020/10/apple-introduces-iphone-12-pro-and-iphone-12-pro-max-with-5g/">record videos in the Dolby Vision HDR format</a>. Apple also sells <a href="https://www.apple.com/pro-display-xdr/">Pro Display XDR</a>, that costs upward of ~$5000 and ticks all the right boxes for any professional doing color-accurate work.</p>
<p>Therefore, with Apple’s color pedigree, it was surprising to see that on the M1 device specification page, there is <strong>no mention of whether M1 devices can output “Billions of colors”</strong>. In contrast, the Intel-based devices clearly outline this support.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_800x0_resize_lanczos_2.png" alt="Apple MacBook Pro specifications showing support for outputting &quot;Billions of colors&quot;"> </a><figcaption>
<p>Specs for the Intel MacBook Pro show that it can output “Billions of Colors”
<a href="https://support.apple.com/kb/SP794?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_800x0_resize_lanczos_2.png" alt="Apple MacBook Pro specifications with no support for outputting &quot;Billions of colors&quot;"> </a><figcaption>
<p>No mention of “Billions of Colors” for M1 MacBook
<a href="https://support.apple.com/kb/SP824?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<p><strong>EDIT: 1/25/21</strong> - Adding specs for Mac Mini as that’s what was tested. The MacBook spec comparison was for apples-to-apples similar device class purposes.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_800x0_resize_lanczos_2.png" alt="Apple Mac Mini M1 without any support for billions of colors"> </a><figcaption>
<p>No mention of “Billions of Colors” for M1 Mac Mini
<a href="https://support.apple.com/kb/SP823?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<p>Even the trusty method of viewing the value in <code>"About this mac" -&gt; "System Report" -&gt; "Graphics/Displays"</code> doesn’t show anything. Usually, this would list a value of 30-bit here (<em>i.e. 10-bit per RGB channel</em>). On M1 devices, the below is what you see when connected to an HDR capable display i.e. no mention of whether the M1 Mini is outputting a 10-bit video signal.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_1200x0_resize_lanczos_2.png 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_800x0_resize_lanczos_2.png" alt="Apple M1 Silcon system report graphics/displays"> </a>
</figure>
<p><strong>So I set about testing 10-bit output support myself.</strong></p>

<ul>
<li><strong>TV</strong> - 2017 Vizio M65-E0 (<a href="https://www.displayspecifications.com/en/model/dd6cb89">Display Specifications</a>)</li>
<li><strong>Monitor</strong> - Philips Brilliance P272P7VU 4K UHD 27" (<a href="https://www.displayspecifications.com/en/model/8e9287b">Display Specifications</a>)</li>
<li><strong>2020 Mac Mini M1</strong> connected through a HDMI cable</li>
</ul>

<p>For this test, I used my trusty 2017 Vizio M65-E0 TV that has a 10-bit panel. I connected the Mac Mini to my Denon AVR-X1300 receiver. The “Displays” settings on Mac OS immediately gave me an option of enabling HDR.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_1200x0_resize_lanczos_2.png 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_800x0_resize_lanczos_2.png" alt="Apple M1 Silcon displays hdr setting">
</figure>
<h3 id="apple-tv-hdr-test">Apple TV HDR test</h3>
<p>Next, I fired up the Apple TV app. Immediately on the “Library” tab, I saw another menu item for HDR titles that’s not visible when connected to a non-HDR display.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_800x0_resize_lanczos_2.png" alt="Apple TV app shows HDR category when HDR is enabled in display settings">
</figure>
<p>Then I used the Apple TV app to play 2017’s Wonder Woman and confirmed through the TV info that it received an HDR10 signal.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_1500x0_resize_q75_lanczos.jpg 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_800x0_resize_q75_lanczos.jpg" alt="Apple TV app shows HDR category when HDR is enabled in display settings">
</figure>
<h3 id="youtube-hdr-test">YouTube HDR test</h3>
<p>Next, I played an HDR video from YouTube on Safari. I confirmed that I could select the HDR formats for this video, and the video was playing in HDR mode using “Stats for nerds” info. The “Color” values of <code>smpte2084 (PQ) / bt2020</code> confirmed that the video was playing in HDR mode.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_800x0_resize_lanczos_2.png" alt="YouTube plays in HDR mode on Apple Silicon M1"> </a>
</figure>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_800x0_resize_lanczos_2.png" alt="YouTube stats for nerds confirms BT2020 color on Apple Silicon M1"> </a>
</figure>
<h3 id="spears-munsil-quantization-test">Spears Munsil quantization test</h3>
<p>I also found a video with an 8-bit and 10-bit quantization artifact test pattern <a href="https://www.avsforum.com/threads/10-bit-gradient-test-patterns.2269338/">here</a>. When I played this video on the TV, the 10-bit pattern was completely smooth.</p>
<p>NOTE: <em>In the image below, both 8-bit and 10-bit appear equally banded because of the 8-bit capture from my smartphone. In reality, the 10-bit pattern is completely smooth compared to the 8-bit pattern.</em></p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test.jpg" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_1500x0_resize_q75_lanczos.jpg 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_800x0_resize_q75_lanczos.jpg" alt="Spears Munsil Quantization Test video 8-bit vs 10-bit"> </a>
</figure>
<p><a href="https://www.avsforum.com/threads/10-bit-gradient-test-patterns.2269338/">Download test video from here</a></p>

<p>At this point, it’s clear that the Mac Mini can output an HDR10 signal when connected to an HDR capable display. Next, I explored if it can output a 10-bit signal / Billions of colors to a non-HDR 10-bit display. This was done by connecting to the Philips Brilliance P272P7VU monitor.</p>
<h3 id="10-bit-psd-test">10-bit PSD test</h3>
<p>The first test was done by displaying a 10-bit PSD file in “Preview”, which supports 10-bit files. <strong>If the M1 outputs a 10-bit signal, then the gradients in the file would be smooth.</strong> Opening the file in “Preview” confirmed the 10-bit output as the test pattern was completely smooth. I also opened the same file in another image viewer called “Pixea” and observed banding which most likely is because “Pixea” doesn’t support 10-bit files. In the image below, the same file is open in “Preview” on the left and “Pixea” on the right.</p>
<p>NOTE: <em>You might not observe the difference between the two images below as during the upload and publishing this image might get converted to 8-bit. On my machine the left image is completely smooth while the right displays banding.</em></p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_800x0_resize_lanczos_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_800x0_resize_lanczos_2.png" alt="10-bit PSD file in a 10-bit viewer vs 8-bit viewer"> </a>
</figure>
<p><a href="https://imagescience.com.au/knowledge/10-bit-output-support">Download the 10-bit PSD file from here</a></p>
<h3 id="spears-munsil-quantization-test-1">Spears Munsil quantization test</h3>
<p>I also ran the “Spears Munsil” quntaization pattern on this monitor and observed the 10-bit pattern had less banding. I ran the test with the latest version of VLC Player - 3.12.1 that is a native Apple Silicon binary.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_800x0_resize_lanczos_2.png" alt="Spears Munsil Quantization Test shows 10-bit pattern has less banding"> </a><figcaption>
<p>Spears Munsil Quantization Test shows 10-bit pattern has less banding</p>
</figcaption>
</figure>
<h3 id="switchresx-test">SwitchResX test</h3>
<p>Using SwitchResX, I confirmed that the display was set to “Billions of colors” mode i.e. outputting a 10-bit signal.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_800x0_resize_lanczos_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_800x0_resize_lanczos_2.png" alt="YouTube plays in HDR mode on Apple Silicon M1">
</figure>

<p>Reach out if you have any questions! Feel free to follow me on</p>
<ul>
<li>Twitter - <a href="https://twitter.com/singhkays">@singhkays</a></li>
<li>LinkedIn - <a href="https://www.linkedin.com/in/singhkays/">https://www.linkedin.com/in/singhkays/</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964501</guid>
            <pubDate>Fri, 29 Jan 2021 23:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe's Vaccine Disaster]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 408 (<a href="https://news.ycombinator.com/item?id=25964197">thread link</a>) | @danielfoster
<br/>
January 29, 2021 | https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When European Commission President Ursula von der Leyen talks about politics, there is never a shortage of superlatives and grandiloquence. Until recently, that was also true when she was talking about the extremely sensitive issue of vaccines.</p>


<div>
<p>In late November, von der Leyen gushed about the contracts the European Union had signed with various producers, saying it meant that Europeans would have "access to the most promising future vaccines under development" against the coronavirus. When it became clear in December that the first people in the EU would be vaccinated soon after Christmas, she even injected a bit of pathos, tweeting "It's Europe's moment." When the vaccinations then began, she wrote of a "touching moment of unity" and a "European success story."</p><p>These days, though, von der Leyen is noticeably quieter – a silence that could have to do with the fact that the erstwhile "success story" might ultimately turn out to be the greatest disaster of her entire political career.</p>
</div>

<div>
<p>Europe is facing a vaccine disaster. Whereas countries like Israel, Britain and the United States. are quickly moving ahead with vaccinations, the EU is reeling from a string of setbacks. First, U.S. pharmaceutical giant Pfizer and its German partner BioNTech informed Brussels that it would be delivering far less vaccine than planned in the coming weeks. Then, the company AstraZeneca said it would only be delivering 31 million doses of its vaccine by the end of March instead of the 80 million Europe had been expecting. And again, the Commission was caught completely off guard.</p><p>Since then, frustration and anger has been growing across the EU. Europe, one of the most affluent regions in the world, is proving to be unable to quickly protect its citizens from a deadly disease, while other countries are showing how it is done.</p>
</div>

<div>
<p>And the boss is nowhere to be found.</p><p>The louder the criticism has grown, the less has been heard from the erstwhile loquacious Commission president. She has, at times, been like the phantom of Brussels. Requests for comment from the press have been systematically blocked by her communications department and she has essentially gone into hiding. This week, though, at the World Economic Forum, she wasn't able to entirely avoid the issue. "Now, the companies must deliver," she said. In other words, the companies are to blame, not us. Not me.</p><p>It is, to put it bluntly, a pattern that has occurred frequently throughout her career.</p>
</div>


<section data-area="contentbox">

</section>
<div>
<p>Whenever von der Leyen, a member of Chancellor Angela Merkel's Christian Democrats (CDIU), has taken on a new leadership position, she has never just been the new minister. She has always acted as though she would do everything different – better – than her predecessor. It has frequently sounded as though von der Leyen planned to reinvent whatever department or ministry she had just assumed control of, making it more functional and more glamorous at the same time. But by the time it became necessary to dive into the sordid details, she had usually moved on.</p><h3>Posing as the Mother of the Nation</h3><p>When von der Leyen was appointed family minister in 2005, she introduced a generous federally funded program for parental leave and expanded daycare offerings, essentially revolutionizing her party's family-policy image in the process. But when it came to addressing the difficulties associated with opening a huge number of new daycare facilities – that was left to her successor.</p><p>When she became minister of labor and social affairs in 2009, she promised a hot lunch for every child. The result, though, was a confusing collection of regulations. "Ursula von der Leyen was excellent at posing as the mother of the nation and launching illusory programs for the poor," says Ulrich Schneider, head of the federation of German welfare associations.</p>
</div>
<figure>
<div data-component="Image" data-zoom-id="f735a15a-9591-4123-a135-fee30656a638" data-settings="{&quot;id&quot;:&quot;88a76b76-b089-42e0-ab96-55e7ceb11a42&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f735a15a-9591-4123-a135-fee30656a638&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg" srcset="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w488_r0.7463002114164905_fpx50_fpy40.28.jpg 488w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w616_r0.7463002114164905_fpx50_fpy40.28.jpg 616w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg 718w," width="706" height="946" sizes="706px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w488_r0.7463002114164905_fpx50_fpy40.28.jpg 488w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w616_r0.7463002114164905_fpx50_fpy40.28.jpg 616w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg 718w," title="AstraZeneca head Pascal Soriot in 2014" alt="AstraZeneca head Pascal Soriot in 2014">
</span>
</span>
</span>
</p><figcaption>
<p>AstraZeneca head Pascal Soriot in 2014</p>
<span>
Foto: Facundo Arrizabalaga / epa-efe / Shutterstock
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>And at the Defense Ministry? The bureau is still trying to clean up the messes that its former boss left behind.</p><p>In each instance, von der Leyen's departure was perfectly timed. Just as the time had come for evaluations, she had already climbed up to the next rung on her career ladder.</p><p>Which is why she is now faced with a real problem. First of all, there isn't really anywhere left to go from her current post in Europe's top position. And second, the pandemic has hit the fast-forward button on political developments, with the consequences of political decisions taking mere weeks to manifest themselves instead of several years. "I am absolutely stunned by how negligent Ursula von der Leyen has been in overseeing the start of vaccinations in recent months," says Lars Klingbeil, general secretary of Germany's Social Democrats (SPD).</p><p>Indeed, von der Leyen finds herself in an extremely difficult situation. The next several weeks could decide her political future.</p><p>On Tuesday of this week, she delivered a video address to the World Economic Forum, where she spoke about Donald Trump, the storming of the Capitol and the question as to whether democracy has been damaged in the last four years. She spoke about climate change, biodiversity, artificial intelligence and digitalization.</p><p>In the first several minutes of her talk, she only briefly mentioned the coronavirus pandemic, and it was fully 15 minutes before she even said the word "vaccine." Only to say things like: "We know that in a pandemic there is no time to lose."</p><h3>Bazaar Bargaining</h3><p>Initially, of course, things looked quite good on the vaccine front. Back in summer, nobody was willing to predict that the first vaccine would be approved in the EU as early as December and that vaccinations would begin. Nor that a second vaccine would quickly follow in January. Von der Leyen was also able to claim a significant success when the EU agreed on a joint vaccination strategy in June, despite the fact that the bloc's 27 member states had always defended sovereignty when it came to health care policy. For the Commission president, it represented a gain of both prestige and power. Fleetingly, at least.</p><p>The problems began soon thereafter. Negotiations with vaccine producers bogged down, and it wasn't until November that the EU was able to reach a purchase agreement with BioNTech/Pfizer and with Moderna, the manufacturers of the two most successful vaccines thus far introduced. The EU negotiating team, according to people familiar with the talks, was intent on pushing down the price. There was also allegedly an extended disagreement on liability issues, particularly with Pfizer.</p><p>While others simply acted with expedience and placed huge orders, the EU – right in the middle of the worst pandemic in a century – decided to bargain like they were at the bazaar. Von der Leyen, of course, didn't lead these negotiations personally. But she is the boss, and carries the political responsibility.</p><p>After a year of the pandemic, hundreds of millions of Europeans are tired, frustrated and desperate for an appointment to finally get vaccinated. No other issue is as important at the moment – for the economy, for society and for politics. And the time will come to assign blame for the missteps that have been made. The search for where to place that blame won't start down below among the army of EU bureaucrats. It will start at the top.</p>
</div>
<section>

</section>
<div>
<p>Given that truth, von der Leyen's press department has been energetic in its defense of the Commissions actions. After all, the EU has secured rights to 2.3 billion doses of vaccine, they have pointed out, with 760 million of them from BioNTech/Pfizer and Moderna.</p><p>But what use is that when the availability of the vaccine will remain so limited for the foreseeable future? When the producers are unable to deliver what they have agreed to – or can only deliver much later?</p><p>And what, actually, is in those contracts, which have thus far remained confidential? Are the deliveries promised by the producers legally binding? Or did the Commission agree to flimsy fine print such that it has no leverage against the producers?</p><p>Thus far, only the contract with the German company Curevac has been made public. It says that the producer will make "reasonable best efforts" to deliver the agreed upon number of doses within the negotiated time frame. Pascal Soriot, the head of AstraZeneca, is now claiming the same thing. The Curevac contract also says that the producer must inform purchasers as quickly as possible of possible delays, explain the causes for those delays and present a revised timeline for delivery. That, though, is all.</p><p>Should the AstraZeneca contract contain the same language, it would be politically explosive. Tiemo Wölken, a member of European Parliament with Germany's Social Democrats, believes the contract is similar in that regard. "The wording of the delivery requirement for Curevac is supposedly similar," he says. "As such, what Soriot is saying doesn't sound implausible."</p><p>That would be a huge embarrassment for von der Leyen, but it would come as welcome news for a man who isn't yet out of the firing line himself: German Health Minister Jens Spahn. At home, Spahn has been the subject of scathing critique for the flubbed beginning of the vaccination campaign. Spahn, who just recently warned the country that "10 difficult weeks" were still to come, is now able to deflect some of the criticism to Brussels – onto the shoulders of fellow CDU member Ursula von der Leyen.</p><h3>Moving Too Slowly</h3><p>There is a history to their vaccine-related relationship. In mid-June, Spahn pushed ahead with his counterparts from France, the Netherlands and Italy, reaching an initial agreement with AstraZeneca. They planned to share the order with all EU member states. But that's not how things worked out.</p><p>Several countries intervened, the Chancellery in Berlin got involved and, in late June, Spahn and the others handed over responsibility for the negotiations to the European Commission. Thereafter, say people involved in the process, the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802">https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964197</guid>
            <pubDate>Fri, 29 Jan 2021 23:25:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baking with machine learning (2020)]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25963556">thread link</a>) | @pizza
<br/>
January 29, 2021 | https://sararobinson.dev/2020/04/30/baking-machine-learning.html | <a href="https://web.archive.org/web/*/https://sararobinson.dev/2020/04/30/baking-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>Like many people, I’ve been entertaining myself at home by baking a ton and talking about my sourdough starter as if it were a real person. I’m pretty good at following recipes, but I decided I wanted to take things one step further and understand the science behind what differentiates a cake from a bread or a cookie. I also like machine learning so I thought: what if I could combine it with baking??!</p>

<p>I’ll start by explaining why baking presents an interesting ML problem. Then I’ll show you how I collected my own dataset, trained a simple model, deployed it, built a little app to get predictions, and used the model to invent a new recipe. If you’re only here for the recipe, I suppose you can <a href="#recipe">skip ahead</a>.</p>

<p>Are videos more your thing? Here’s me <a href="https://www.youtube.com/watch?v=-4saaQZSmBw">speaking about</a> how I built this.</p>

<h2 id="why-would-you-use-machine-learning-for-baking">Why would you use machine learning for baking?</h2>

<p>Maybe you’re thinking, couldn’t you just read a book or even a <a href="https://lifehacker.com/how-to-free-yourself-from-recipes-with-a-few-golden-coo-1450617561" target="_blank">blog post</a> that explains the sugar, fat, and flour ratios that make up different baked goods? Sure, I could do that. But my attention span has been pretty short these days, and that approach doesn’t really scale. If I learn enough to start inventing my own recipes, that only directly benefits the people who can eat them, which is currently not many.</p>

<p>Now maybe you’re thinking, couldn’t we solve this with traditional programming? For example, if the typical flour:liquid ratio for bread is 5:3, I could write a program like this:</p>

<figure><pre><code data-lang="python"><span>ratio</span> <span>=</span> <span>flour_amt</span> <span>/</span> <span>water_amt</span>

<span>if</span> <span>ratio</span> <span>&gt;</span> <span>1.5</span> <span>and</span> <span>ratio</span> <span>&lt;</span> <span>2</span><span>:</span>
    <span>print</span><span>(</span><span>"It's bread!"</span><span>)</span></code></pre></figure>

<p>That <em>kind of</em> works, but it’ll quickly get unwieldy. What if the flour:water ratio is close, but not exactly 5:3? What if I want to predict more than just bread? And what if I don’t feel like converting ingredient amounts into ratios? I am lazy (in certain ways) and I want to input my ingredient amounts without doing any math, and then have something magically tell me what it thinks it is.</p>

<p>Enter 🌟 machine learning 🌟</p>

<p>This is a great fit for ML because I can gather recipe data and train a model to identify patterns in that data. Since a lot of people have written about baking ratios, I’m going to assume there are some high-level patterns about them that I can teach a model to learn.</p>

<p>Hopefully by now I’ve convinced you that this will be a fun problem to solve with machine learning. But maybe you’re <em>still</em> skeptical, and you’re wondering: what’s the point of this? Don’t you already know what you’re baking when you follow a recipe? It seems silly to have a model tell you what you already know. All of that is true if I simply input an existing recipe into my model and ask it for a prediction. Remember, though, that the whole reason I’m doing this is to learn things like what makes a cake a cake, and not a cookie. Then I can experiment with different ratios to create a new recipe. Maybe I want to invent something that my model thinks is 50% cake, 50% cookie.</p>

<h2 id="creating-the-dataset">Creating the dataset</h2>

<p>I couldn’t find an existing dataset of basic baking ingredients, so I decided to create my own very small one. Luckily there is no shortage of recipes on the internet, and I found 33 recipes each of breads, cakes, and cookies to make a dataset with 99 total recipes. To keep this problem relatively simple, I looked only at the following ingredients:</p>

<ul>
  <li>Flour: If a recipe called for different types of flour, I counted it it all towards the flour amount</li>
  <li>Sugar: I also combined different sugars (granulated, brown, etc.) as one amount</li>
  <li>Sourdough starter: If you know, you know</li>
  <li>Salt</li>
  <li>Yeast</li>
  <li>Milk</li>
  <li>Water</li>
  <li>Oil</li>
  <li>Eggs</li>
  <li>Baking powder</li>
  <li>Baking soda</li>
  <li>Butter</li>
</ul>

<p>I tracked it all in a spreadsheet that looks like this:</p>

<p><img src="https://sararobinson.dev/assets/media/spreadsheet.png" alt="Baking spreadsheet dataset"></p>

<p>I know, I’m using cups and teaspoons and not something more universal like grams. If my little model becomes a smash hit, I will try to add metric system support.</p>

<p>While collecting the data, I did my best to include various types of breads, cakes, and cookies so that the model could handle a diverse repertoire of baked goods.</p>

<h2 id="processing-data">Processing data</h2>

<p>I went into this thinking I could feed my ingredient inputs directly into my machine model, since ML model inputs need to be numeric. Not quite. There are a few problems with the data in its current form.</p>

<p>First, my spreadsheet has a mix of units: I’m using cups for some ingredients, teaspoons for others, and eggs are just eggs. I don’t want my model to think that 1 unit of flour is the same as 1 unit of yeast (can you imagine what would happen there?). Since the majority of my data is in cups, I decided to convert everything else to cups. For teaspoons, this was fairly straightforward since 1 teaspoon is around .02 cups. For eggs, after some research I settled on 1 egg being approximately .2 cups. It’s not perfect, but now everything is in the same units.</p>

<p>Next I needed a way to scale the data. Some recipes make 2 giant cakes, while others make a small loaf of bread. Converting all ingredient amounts to the same scale will ensure my model doesn’t give more weight to bigger recipes. I decided to scale amounts by converting each ingredient to a percentage of the total recipe. To do this I took the sum of each row, and then divided each ingredient by the sum to get its percentage. The bread recipe in the screenshot above becomes:</p>

<p><img src="https://sararobinson.dev/assets/media/scaled_inputs.png" alt="Scaled recipe inputs"></p>

<p>With my 99 recipes all converted to the same unit and scaled to percentages, it’s time to build and train a model.</p>

<h2 id="building-a-tensorflow-model">Building a TensorFlow model</h2>

<p>I’m going to use TensorFlow’s <a href="https://www.tensorflow.org/api_docs/python/tf/keras" target="_blank">Keras API</a> for this model, which makes the model code pretty short:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>16</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>num_ingredients</span><span>,)),</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>16</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>3</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>                
<span>])</span></code></pre></figure>

<p>My model output is a softmax array, which means it’ll output the probability a particular recipe is a bread, cake, or cookie (in that order). Softmax means that all the probabilities will add to 1. So a 97% confident bread prediction would look like the following:</p>

<figure><pre><code data-lang="python"><span>[</span><span>.97</span><span>,</span> <span>.02</span><span>,</span> <span>.01</span><span>]</span></code></pre></figure>

<p>After training, my model has reached 90% accuracy. Pretty cool! But can I trust it, or is it overfitting the training data?</p>

<p>🚨This is definitely not an ML best practice, but I will be testing my model on real-world, production data. Mostly because I got tired of copying enough recipes into my spreadsheet to make a test set. Do not try this at home 🚨</p>

<p>To test the model, I made up the following recipe:</p>

<ul>
  <li>Flour: 1 c</li>
  <li>Sugar: 1 c</li>
  <li>Salt: ½ tsp</li>
  <li>Eggs: 1</li>
  <li>Butter: 1 c</li>
</ul>

<p>The model predicts cookies with 84% confidence. Sounds reasonable. What about an edge case, like a bread without yeast or sourdough starter? Let’s try:</p>

<ul>
  <li>Flour: 4 c</li>
  <li>Salt: ½ tsp</li>
  <li>Water: 1.2 c</li>
  <li>Oil: 3 tsp</li>
  <li>Baking powder: 2 tsp</li>
</ul>

<p>My model says bread with 99% confidence, nice! If I instead wrote a series of if statements to handle that edge case, you can see how it would quickly get very long.</p>

<h2 id="deploying-the-model-to-ai-platform">Deploying the model to AI Platform</h2>

<p>I don’t want to be the only one who gets to use this model, so it’s time to deploy it. I’m going to deploy it to Google Cloud <a href="https://cloud.google.com/ai-platform/prediction/docs" target="_blank">AI Platform Prediction</a>. In order to do that, I need to use the TensorFlow <code>model.save()</code> method to save my model assets to a Cloud Storage Bucket. Then I can use gcloud to deploy my model from the command line, pointing it at the bucket path of my saved model.</p>

<p>When you save your TensorFlow model, you can pass it a local filepath or a Cloud Storage bucket. Here I’ll pass it my GCS bucket directly:</p>

<figure><pre><code data-lang="python"><span>model</span><span>.</span><span>save</span><span>(</span><span>'gs://my_gcs_bucket/path'</span><span>)</span></code></pre></figure>

<p>With that, I’m ready to deploy using gcloud (you can also deploy via the UI or the API):</p>

<figure><pre><code data-lang="python"><span>!</span><span>gcloud</span> <span>ai</span><span>-</span><span>platform</span> <span>versions</span> <span>create</span> <span>'v1'</span> \
<span>--</span><span>model</span> <span>'baking'</span> \
<span>--</span><span>origin</span> <span>'gs://path/to/saved/model'</span> \
<span>--</span><span>runtime</span><span>-</span><span>version</span> <span>2.1</span> \
<span>--</span><span>framework</span> <span>TENSORFLOW</span> \
<span>--</span><span>python</span><span>-</span><span>version</span> <span>3.7</span></code></pre></figure>

<p>When your model has deployed, you’ll see it in your cloud console like this:</p>

<p><img src="https://sararobinson.dev/assets/media/caip-prediction.png" alt="Cloud AI Prediction UI"></p>

<h2 id="building-a-web-app">Building a web app</h2>

<p>🙏 <em>Shout out to my teammate <a href="https://twitter.com/_davideast" target="_blank">David</a> for his help on the web app</em> 🙏</p>

<p>It would be fun if I had a basic web app to get predictions on my model. That way I could quickly experiment with different ingredient ratios. Remember that my model needs the ingredient inputs all converted to cups and then scaled as percentages of the total recipe. It would be mean if I made people do those calculations on their own, so this should probably be handled server side – a great use for <a href="https://cloud.google.com/functions" target="_blank">Cloud Functions</a>:</p>

<p><img src="https://sararobinson.dev/assets/media/arch-diagram.png" alt="Architecture diagram"></p>

<p>I’ll use the Python runtime and write a function that takes the ingredient inputs in their user-friendly units and converts them to cups and then to percentages. From the same function I can send that scaled input to my model and return a nice, readable prediction to the web app. A snippet of the function is below, and you can find it all in <a href="https://gist.github.com/sararob/1fb9fb132a93bdda95f7a71d2afd38ad" target="_blank">this gist</a>.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>get_prediction</span><span>(</span><span>request</span><span>):</span>

    <span>data</span> <span>=</span> <span>request</span><span>.</span><span>get_json</span><span>()</span>
    <span>prescaled</span> <span>=</span> <span>dict</span><span>(</span><span>zip</span><span>(</span><span>columns</span><span>,</span> <span>data</span><span>))</span>
    <span>scaled</span> <span>=</span> <span>scale_data</span><span>(</span><span>prescaled</span><span>)</span>
    
    <span># Send scaled inputs to the model
</span>    <span>prediction</span> <span>=</span> <span>predict_json</span><span>(</span><span>'gcp-project-name'</span><span>,</span> <span>'baking'</span><span>,</span> <span>scaled</span><span>)</span>
    
    <span># Get the item with the highest confidence prediction
</span>    <span>predicted_ind</span> <span>=</span> <span>np</span><span>.</span><span>argmax</span><span>(</span><span>prediction</span><span>)</span>
    <span>label_map</span> <span>=</span> <span>[</span><span>'Bread'</span><span>,</span> <span>'Cake'</span><span>,</span> <span>'Cookies'</span><span>]</span>
    <span>baked_prediction</span> <span>=</span> <span>label_map</span><span>[</span><span>predicted_ind</span><span>]</span>
    <span>confidence</span> <span>=</span> <span>str</span><span>(</span><span>round</span><span>(</span><span>prediction</span><span>[</span><span>predicted_ind</span><span>]</span> <span>*</span> <span>100</span><span>))</span>

    <span>if</span> <span>baked_prediction</span> <span>==</span> <span>'Bread'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's bread! 🍞"</span> 
    <span>elif</span> <span>baked_prediction</span> <span>==</span> <span>'Cake'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's cake! 🧁"</span>
    <span>elif</span> <span>baked_prediction</span> <span>==</span> <span>'Cookies'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's cookies! 🍪"</span>

    <span>return</span> <span>"{} {}</span><span>% </span><span>confidence"</span><span>.</span><span>format</span><span>(</span><span>emoji</span><span>,</span> <span>confidence</span><span>)</span></code></pre></figure>

<p>And here’s the app! I will preface this by saying that I’m lucky to work with amazingly talented people. I <a href="https://twitter.com/SRobTweets/status/1255213096718786568" target="_blank">tweeted</a> an early version of this web app and <a href="https://twitter.com/_davideast" target="_blank">David</a> volunteered to make it look, well, a lot better:</p>

<p><a href="https://whatareyoubaking.com/" target="_blank"><img src="https://sararobinson.dev/assets/media/bakeml.gif"></a></p>

<p>If you want to play around with it yourself, <strong><a href="https://whatareyoubaking.com/" target="_blank">it’s here</a></strong>. I’m sure you’ll try to do something weird with it (this is the internet after all), just keep in mind that the model has been trained on minimal data and it only knows about 3 things: bread, cake, and cookies. So if you enter the ingredients for a brownie or anything else, it’ll do its best to slot it into the only 3 categories it knows about. Think of it …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sararobinson.dev/2020/04/30/baking-machine-learning.html">https://sararobinson.dev/2020/04/30/baking-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://sararobinson.dev/2020/04/30/baking-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25963556</guid>
            <pubDate>Fri, 29 Jan 2021 22:26:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird compiler bug – Same code, different results]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25962756">thread link</a>) | @zaitanz
<br/>
January 29, 2021 | https://blog.zaita.com/mingw64-compiler-bug/ | <a href="https://web.archive.org/web/*/https://blog.zaita.com/mingw64-compiler-bug/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>There are approximately 7.5x10^18 grains of sand on Earth. This story is about finding changes in an equation that has a difference of approximately 1e-18 out of hundreds of billions of calculations. That is 7 grains of sand that are different to what we expect across the entire planet Earth.</p>
<p>After spending days generating gigabytes of debug logs and GDB breakpoints, I finally discovered a very peculiar bug in the compiler. I thought this would be an interesting story to tell.</p>
<p><strong>Update: Thanks to gus_massa and wiml @ HackerNews for pointing out I had used associative instead of commutative</strong></p>
<h2>Background</h2>
<p>Back in 2008 I started developing a scientific modelling platform called the <a href="https://niwa.co.nz/fisheries/tools-resources/spatial-population-modelling">Spatial Population Model (SPM)</a>. This software is designed to model or simulate and ocean environments to approximate the health of fish stocks. The output of SPM is used to create scientific reports that are given to Governments for the setting of commercial fishing quota. </p>
<p>Due to the political nature of these reports, reproducibility and integrity of results is crucial. Scientists from around the world will use the software to re-run models across different Operating Systems and compilers to validate results.</p>
<p>Since it was 2008, it was decided that SPM would not be multi-threaded. This is because of: no C++ standard threading, average computer had 2 cores, incompatibility with auto-differentiation libraries) </p>
<p>Fast forward to 2020/21 where many-core systems are commonplace. I had recently acquired for myself an AMD 5950X 16c/32t CPU and was keen to apply it to some modelling work. SPM is still in use as a world leading spatial modelling platform and has received continual updates. I’ve had a long interest in bringing concurrency to SPM to invent new methods of scientific modelling that evolve the underlying mathematics. As a proof of concept, I wanted to start working through threading the internal gradient calculation. Models in SPM are user defined and can be enormous (&gt;100k lines of input text) so we’re unable to analytically determine the gradient function through auto-differentiation. We use an iterative approach tweaking model parameters to calculate the gradient. These tweaks are independent and therefore can be parallelised. </p>
<p>This seemed like a relatively straight forward piece of work. I would need to:</p>
<ol>
<li>Move all of the classes to be children of a new Model class</li>
<li>Remove all singletons</li>
<li>Keep the floating-point operations in the exact same order when calculate on the main thread (IEEE-754)</li>
<li>Support an arbitrary number of threads</li>
<li>Produce identical results regardless of the number of threads, Operating System or compiler</li>
</ol>
<h2>IEEE-754 or the floating-point nightmare</h2>
<p>The development of scientific modelling platforms like SPM requires a significant amount of thought and effort around reproducibility. Given the same input files, any user must be able to re-run your model and get the exact same answer out. This seems incredibly obvious, but it’s not…</p>
<p><a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE-754</a> is the standard for floating-point arithmetic. Floating point math in computers is an approximation. Whenever you see a floating point value it is highly unlikely to be completely accurate. Floating-point arithmetic is commutative, but not associative. So for floating-point numbers,
A + B = B + A always, but
A + (B + C) != (A + B) + C in many cases.
The order in which operations occur within your model will influence the output. While this is inconsequential for small programs or games; this continual adding of errors for scientific models where the number of operations is in the hundreds of billions is consequential. </p>
<p>Every thread we spawn must run the same operations in the exact same order. When the threads give their results back to the main thread, they must do so in a way that ensures that all future operations happen in the exact same order. This is regardless of the number of threads or number of parameters in the model.</p>
<p><em>Side Note: Within scientific models, we use double precision numbers (double) and not single precision (float). Single precision does not have enough precision to handle the number of calculations required. At the end of a model the error added by the approximation of floating-point math is very significant. This limits us to using CPUs over GPUs as the double precision performance of GPUs is not that much better than a modern CPU when you have to factor in the added complexity of writing GPU specific code.</em></p>
<h2>The first signs of trouble</h2>
<p>With my task list ready, I started to work through re-factoring the code. Everything was modified to use a central model class as the parent for the system. This allows me to spawn as many model classes as threads. Everything was compiling and running without crashes. Time to check the output..</p>
<div data-language="text"><pre><code>1999.818926297566804 // original score running no threads
1999.8189264475995515 // my new score running 32 threads</code></pre></div>
<p>A slight difference, nothing to be concerned about as I had probably changed the order of execution for some of the equations by threading them. I was testing with a small model that ran in &lt;5 seconds, so working through each of the instantiated classes to check the code won’t take too long. Another day down and nothing obvious was found. Time to run the application through GDB and the <a href="https://en.wikipedia.org/wiki/AddressSanitizer">Sanitizers</a> looking for issues… nope nothing there either.</p>
<p>A simple model will have recruitment/breeding, ageing and death. I started to reduce and simplify the processes in the model to see if I could identify any key process or parameter. I removed the random number generate and commented out a large amount of complex math… but still no luck.</p>
<h2>Down the rabbit hole of debug logging and GDB</h2>
<p>After three days of trying to find the issue, I had added a LARGE amount of debug logging and had resorted to doing step throughs in GDB looking for a point at which I would notice a change in the result. The log files were 20MBs+ and the model would only show issues after a few iterations… why not immediately?</p>
<p>Was I calling a function later in the model that had the issue? Or was the issue starting earlier but at a greater precision that I was printing. I was printing my debug output with a <a href="https://en.cppreference.com/w/cpp/io/manip/setprecision">precision</a> of 15. Time to increase the precision to 20. This is basically the maximum amount of precision you can print from a double with accuracy. I did a few more model runs and saw that the variation in results had moved to much earlier in the model… almost immediately.</p>
<p>The model would load the configuration file, then construct all of the user defined objects in memory. As part of constructing these objects a bunch of calculations would be run to build caches. To save on moving data between threads each thread would repeat the same process. Every new thread would get the configuration file that had been loaded, create all of the objects and run the initial calculations. GDB showed that even these initial calculates were having different results.</p>
<p>My working folder was littered with files named “fuck”, “fuck1” and “fuckN” each with more than 20MBs of debug output for a small model run. Diff was run across files to see where changes were occurring and how small they were… But still no luck.. everything was going wrong almost immediately but I had no idea why.</p>
<h2>Surely it’s not a compiler bug?</h2>
<p>SPM uses the GCC and MinGW64 compilers. This allows us to have near-identical code for Windows and Linux with common makefiles. I have always preferred <a href="https://jmeubank.github.io/tdm-gcc/">TDM-GCC</a> as this has a current release. In this instance, TDM-GCC 9.2.0 from March 2020. Running the sanitizers was done on OpenSuSe Tumbleweed Linux using GCC 10.2.1. These are both very modern versions of the GCC compiler suite. I have never been one to blame tools for a bug in my code.</p>
<p>At this point, I am way down the rabbit hole trying to find the cause of this bug. Some testing had shown me that:</p>
<ul>
<li>The original binary would produce the same result on every run</li>
<li>My new binary would produce the same result on every run, but different to the original</li>
<li>My new binary would produce the same result regardless of the number of threads.. from 1 to 100</li>
</ul>
<p>That last observation made me curious. Why did my new code produce a different result when I ran it with only one thread? What would make it different from the original binary. Having only 1 thread that was executing would eliminate any race conditions.</p>
<p>In the original binary, we do not create any threads. We load the model, build and run it. In the new code, even with one thread we create that thread, load the model, build and run it. What was I doing during the thread creation process that would cause this issue? Time for GBs of log files and GDB.</p>
<p>Stepping through every operation to validate the output lead me into what we call a selectivity. This is a static piece of code that takes an input, calls a standard simple piece of math and returns an output. These few lines of code had returned different results in a thread and not. Time to analyse the following code:</p>
<div data-language="c++"><pre><code>double CLogisticSelectivity::calculateResult(int Age) {
    double dRet = 0.0;
    double dTemp = (dA50-Age)/dAto95;

    if(dTemp &gt; 5.0)
      dRet = 0.0;
    else if (dTemp &lt; -5.0)
      dRet = dAlpha;
    else
      dRet  = dAlpha/(1.0+pow(19.0,dTemp));

    return dRet;
}</code></pre></div>
<p>If I gave the code Age = 1 then ran it I got the following results:</p>
<div data-language="text"><pre><code>Local  = 0.0010370292068795884059
Thread = 0.0010370292068795879722</code></pre></div>
<p>What gives? There is nothing in here that should be different in a thread. I am not passing in anything but an int with the value of 1. I edited the code to make dA50 and dAto95 local variables to remove any potential race conditions or thread wonkiness and still had the same error in output. Everything was initialized within the same function and the only external value was an Integer. Weird…</p>
<h2>Compiler bug? But how…</h2>
<p>Looking at the code, the only things that could create the bug were the operators and pow() call. These are part of the C++ standard offering so it’s highly unlikely that either of these would have an error. What next? Off to <a href="https://blog.zaita.com/mingw64-compiler-bug/%5Bhttps://godbolt.org/">GodBolt</a> …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.zaita.com/mingw64-compiler-bug/">https://blog.zaita.com/mingw64-compiler-bug/</a></em></p>]]>
            </description>
            <link>https://blog.zaita.com/mingw64-compiler-bug/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25962756</guid>
            <pubDate>Fri, 29 Jan 2021 21:24:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IKEA using AR to let users decide which furniture fits where (2020)]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25960679">thread link</a>) | @valkrieco
<br/>
January 29, 2021 | https://karlsnotes.com/ikea-and-the-future-of-living/ | <a href="https://web.archive.org/web/*/https://karlsnotes.com/ikea-and-the-future-of-living/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-97">

	
		<!-- .entry-header -->

		<div>
			
<p>The keyword guiding IKEA’s history is <em>innovation.</em></p>



<p>Ever since its start in 1943, the name IKEA has been synonymous with minimal, cheap furniture that can be bought and assembled in one’s own home. Its first innovation is also its most famous one – the flatpack furniture. By introducing this concept, and moving furniture assembly onto the user – contrary to what other furniture stores were doing – it allowed the company to reduce costs. This concept made IKEA the world’s biggest furniture store, with no real worldwide competition. This enviable position, allowed it to focus on other innovations and products that could improve the IKEA brand and allow the company to enter new markets.</p>



<p>There were, of course, a number of high profile <a href="https://gizmodo.com/the-ikea-tv-reviewed-worse-than-assembling-100-bookshe-5919216">mistakes</a>, but how else would a company from Sweden make €12.4 billion profit, if not for continuously making mistakes and learning from them along the way? The IKEA furniture made in the 1950s might not be fitting for today or appropriate in 10 years, while the food sold by the company 20 years ago might not respect the increasing sustainable lifestyle of many of its customers. The creation of <a href="https://space10.com/">SPACE10</a>, IKEA’s very own <a href="https://x.company/">‘X</a>’, the former Google X, has helped the company to experiment with new concepts and projects to address these challenges and keep the company on the forefront to new challenges. IKEA is changing how customers live, eat, and work, and its future will have a bigger role in our everyday lives.</p>



<p>There are four main areas where I believe IKEA is spearheading new concepts, new technology, and better practices:</p>



<ol><li>Food</li><li>Housing</li><li>the Smart Home</li><li>Augmented Reality</li></ol>



<p>I’ll delve deeper into each category and explain how IKEA is expected to be innovating in each, and then we’ll briefly look at how IKEA has the potential to rival Amazon, as it makes the jump from a furniture store to the everyday store.</p>



<h3>1. Food</h3>



<p>A few years after the flatpack furniture was invented, IKEA started opening IKEA Bistros and food markets, in its out-of-town stores.</p>



<p><em>“It’s difficult to do business with someone on an empty stomach.”</em></p>



<p>These were the words of IKEA founder Ingvar Kamprad, who wanted to start serving food to the people spending whole days at IKEA stores out of the city. What better way to keep customers at your store than to offer them cheap AND good food?</p>



<p>The meatball remains an IKEA favourite, and the word itself has become as synonyms to IKEA as the flatpack furniture. With millions of IKEA meatballs sold each year, you would think the company would not want to upset the cart by changing recipes and adding new items to the menu. However IKEA did just that, and in mid-2020 it rolled out its ‘<a href="https://www.ikea.com/kr/en/p/allemansraetten-vegetable-balls-frozen-100-vegetables-40346434/">veggie balls</a>’ and the ‘<a href="https://www.ikea.com/gb/en/this-is-ikea/sustainable-everyday/veggie-hot-dog-plant-based-goodness-pub166a3131">veggie hotdog</a>’ for public consumption. Two of the most famous IKEA food staples now have their vegetarian version, with the veggie balls producing around 15 to 20 times less carbon footprint than the meatballs. IKEA also joined forces with other organisations to buy sustainably farmed <a href="https://www.ikea.com/gb/en/this-is-ikea/sustainable-everyday/patar-special-edition-from-uganda-with-love-a-very-special-single-origin-100-arabica-coffee-pub1e423691">coffee</a>, and <a href="https://www.ikea.com/gb/en/this-is-ikea/sustainable-everyday/egentid-good-for-you-the-farmers-and-the-planet-pub561f3b31">tea</a> and created the ‘IKEA Food <a href="https://www.ikea.com/gb/en/this-is-ikea/sustainable-everyday/ikea-food-better-chicken-pub4fcff351">Better Chicken</a>’ programme which seeks to source chicken under strict animal welfare criteria.</p>



<div id="w-node-0c78ba3acc40"><figure><img src="https://i2.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99db1a0428adda3ed5a_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F0d586b7c-d38b-4215-84a6-c66fc5f76825_1200x800.jpeg?w=640&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>Like other companies in the food sector, IKEA recognises the increasing number of individuals becoming aware of the carbon footprint needed to sustain the current consumption pattern. SPACE10 has been trying to build on the meatball’s legacy by creating new concepts which leave a much smaller carbon footprint, like meatballs made from artificial meat and those made from insects, which are not unconventional ideas in 2020, even if they have yet to enter the mainstream markets. The Lab also has a concept of a 3D printed meatball, which is more of an aesthetical project rather than a ready-to-serve meatball, however, this goes to show how SPACE10 is seeking to broaden the perspective of both IKEA itself, as well as its customers, to future possibilities in the food sector.</p>



<h3>2. Housing</h3>



<p>In the early 1990s, IKEA realised that the <a href="https://data.oecd.org/price/housing-prices.htm">increase in residential property prices</a> is making it harder and harder for certain sections of the population looking to buy a home without having to break the bank. <a href="https://www.boklok.com/">BoKlok</a> was born from an agreement between Swedish construction giants, Skanska, and IKEA, to build and design low-cost housing, complete with, of course, IKEA furnishing. Sweden, Norway, Denmark, and Finland have been the first beneficiaries of this project, while the <a href="https://www.archpaper.com/2020/05/ikea-modular-boklok-development-offshoot-manufacturer/">United Kingdom</a> will be the first country to host BoKlok housing outside of the Nordics.</p>



<p>BoKlok, which was also called ‘<a href="https://medium.com/@bartholomewhearn/the-flat-pack-taken-to-the-next-level-the-boklok-concept-26078e433b3f">the flatpack taken to the next level</a>’, prides itself in using as limited and as sustainable resources as possible. The design and materials used for the pre-fabricated blocks make the houses’ energy-efficient and environmentally sustainable. This modular housing technique, allows BoKlok to build up to 80% of the houses in a factory and then transport and assemble them to the construction site itself.</p>



<div id="w-node-e435fd46d758"><figure><img src="https://i0.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99da95d27563a12bf17_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Fe876dbf1-6044-4545-9c0c-99bb6e96fb3c_1200x630.jpeg?w=640&amp;ssl=1" alt="BoKlok UK achieves planning acceptance on first UK development |  www.skanska.co.uk" data-recalc-dims="1"></figure></div>



<p>With BoKlok, IKEA has managed to infiltrate the housing market, and as housing prices continue to rise above median wages, the company will continue to find a market for low-cost housing. What made BoKlok successful, and continues to do so, is the cost-cutting every step of the way, with profits then being passed on to the consumer. A combination of cheap land, a single standard design, and large-volume manufacturing allows IKEA to create entire housing estates while eliminating brokers and their fees. Buying a flat with BoKlok is also as simple as buying a new bed frame from IKEA – you just have to register at the nearest IKEA store for available housing units.</p>



<p>While this is already disruptive in the current housing market, IKEA, or rather IKEA’s SPACE10 has already come up with a BoKlok on steroids – a new concept for future housing and working environment. ‘<a href="https://www.urbanvillageproject.com/">The Urban Village Project</a>’ shares the same aims of BoKlok, that of creating a sustainable and affordable way of living, but it also aims higher – to completely transform the housing market, by “bypassing the interests of short-term investors”. What this means is that the Project looks for financing by collaborating with “pension funds, future-oriented companies and municipalities” in order to drive down costs, and combine the project with co-operative structures to keep housing within the community. All managed through a neat-looking app.</p>



<div id="w-node-2227ad890b79"><figure><img src="https://i0.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99d234ed0583a59caba_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F21b99d3b-2ea6-47b7-b930-5c8a9f0856ff_1200x675.jpeg?w=640&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>Related to this, is IKEA’s <a href="https://www.theverge.com/2019/6/4/18652178/ikea-rognan-robot-murphy-bed-furniture-ori-living-democratic-design-days">announcement</a> that it will start to create robotic furniture for small spaces. Rolling out in places like Hong Kong and Japan, micro-apartments will be the first to feel the benefits of the Rognan furniture, which transforms easily depending on what you need to use at the time. The idea is that one will not use a certain section of the place while busy doing something else, like not using the bed if you’re on the sofa – and Rognan helps to maximise space accordingly.</p>



<div id="w-node-cb2d728635af"><figure><img src="https://i2.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99ed5fd03adadf17e70_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F29718baf-50d5-4c9d-917e-55d18b183521_1000x563.gif?w=640&amp;ssl=1" alt="New IKEA collaboration features robotic furniture for small space living |  6sqft" data-recalc-dims="1"></figure></div>



<p>In the near future, I would also see IKEA getting into the workspaces sector, providing low-cost offices for freelancers and even startups looking to cut costs. Coworking is expected to grow to an estimated <a href="https://www.prnewswire.com/news-releases/global-coworking-spaces-market-2020-2030---covid-19-growth-deviations-trends--developments-competitive-landscape-analysis-301078785.html">$11.52 billion in 2023</a>, with Europe, IKEA’s home territory, leading the way, which makes it easier for the company to integrate this sector into its current BoKlok partnership with Skanska.</p>



<h3>3. the Smart Home</h3>



<p>In more recent years, IKEA added smart home products in its catalogue. While the company was relatively late to the party, today the IKEA customer has a number of functional smart products to choose from and which can be easily connected through the IKEA Home smart app, as well as other third-party applications. In typical IKEA fashion, its mantra of ‘making not using space’, the company did not just copy other smart appliances – IKEA’s wireless chargers can be integrated into furniture, and a SONOS Bluetooth speaker is produced either as a bookshelf or as a lamp, and both work with Google Assistant, Alexa, and Siri voice assistants. This is certainly an area were IKEA will be looking to improve on. By creating its own smart technology as an integrated part of its furniture, the company would be able to get a better understanding of how its products are being used, for how long, and can even signal to the owner when that furniture needs repairing or replacing.</p>



<div id="w-node-55f2fdd96208"><figure><img src="https://i1.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99d04c5930384f862ec_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Fe8f7e7b8-c1c0-42f4-825c-24b79e539dea_970x646.jpeg?w=640&amp;ssl=1" alt="The Review: Is the New Ikea x Sonos Speaker Worth It? - Western Living  Magazine" data-recalc-dims="1"></figure></div>



<p>A series of projects called ‘<a href="https://www.everydayexperiments.com/">Everyday Experiments</a>’, by SPACE10, continue on this trend of making sure that the smart appliances being created are beneficial to the consumer. These experiments recognise the increasing multi-dimensional use of one’s house, from living quarters, to play areas, to work stations. The latter is an increasingly important part of one’s home, especially since the COVID-19 pandemic. Smart improvements to the house have to respect the serenity one looks for in a home, making life easier and more comfortable, while avoiding adding further technological distractions. There are also, of course, privacy issues when it comes to smart furniture or appliances, so IKEA would also be wary of further technological intrusiveness on its customers.</p>



<p>Some of these experiments are more likely to be used in everyday situations than others, such as the one using <a href="https://www.everydayexperiments.com/light-gestures">hand gestures</a> to control a light fitting, making it easier for someone to switch on/off or dim the lights without having to move.</p>



<div id="w-node-af9a579989cd"><figure><img src="https://i2.wp.com/uploads-ssl.webflow.com/5f9dc8a1a036811f1b6788fb/5f9eb99d7943e0448eb6f49c_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F9bd14c8f-8475-47d4-85ce-df380139d4f9_900x504.png?w=640&amp;ssl=1" alt="Image for post" data-recalc-dims="1"></figure></div>



<p>While IKEA might need to collaborate with other technological companies, such as SONOS, and depend on Google, Amazon, and Apple for voice assistants in order to grow its smart ecosystem in the short term, its better understanding of the home and what tenants want from it, allow IKEA to be in a position to create superior, practical smart appliances, than other companies in the field. Björn Block, Business Leader at IKEA Home Smart, himself <a href="https://www.theverge.com/2019/12/18/21024497/ikea-smart-home-tech-sweden-furniture-sonos-meatballs-bjorn-block">said that</a>:</p>



<p>“We’re (<em>IKEA</em>) definitely into the tech space, we’re into the digital space, and we really want to be here and really play this because I think that we can also make a difference.”</p>



<p>Which leads us to the fourth and final …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karlsnotes.com/ikea-and-the-future-of-living/">https://karlsnotes.com/ikea-and-the-future-of-living/</a></em></p>]]>
            </description>
            <link>https://karlsnotes.com/ikea-and-the-future-of-living/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25960679</guid>
            <pubDate>Fri, 29 Jan 2021 18:35:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[M5Paper – a 4.7“ 940x540 multitouch e-ink ESP32 dev kit for $70]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25959694">thread link</a>) | @sxp
<br/>
January 29, 2021 | https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/ | <a href="https://web.archive.org/web/*/https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_28_005"><div>
<p>I’m pleased to say, that M5Stack did it again. They managed to release another ESP32 based product and keep me on my tosies! From incredible small Atom (review pending), through most feature-packed M5StickC (<a href="https://notenoughtech.com/review/m5stickc-plus/">review</a>) to power development Fire Kit Core  (<a href="https://notenoughtech.com/review/this-esp32-is-on-fire-m5stack-core/">review</a>) – each product brought joy to my eyes despite being basically the same: an ESP32 based all-in-one development board. And they did it again thanks to <a href="https://m5stack.com/products/m5paper-esp32-development-kit-960x540-4-7-eink-display-235-ppi">M5Paper</a> – a unique mashup between ESP32 and e-ink displays.</p>



<h2>M5Paper – phone-size wonder</h2>



<figure><img data-attachment-id="25176" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/m5paper-7/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg" data-orig-size="1024,1024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;MI 9&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610400037&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.75&quot;,&quot;iso&quot;:&quot;659&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="M5Paper-7" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg" loading="lazy" width="1024" height="1024" src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg?x19519" alt="" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-696x696.jpg 696w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7-696x696.jpg 696w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-7.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>It’s not the first ESP32 &amp; e-ink display combo, but it’s the first one I really wanted to have. Convincing M5Stack to send me one wasn’t the problem. The device is so high in demand, that I had to wait till Xmas to get mine. It is not just me that likes the concept. M5Paper is in stock right now, but if you are unlucky, it also surfaces on <a href="https://www.banggood.com/custlink/mDvdSKZvLF">Banggood</a> and <a href="https://s.click.aliexpress.com/e/_Af1yn5">AliExpress</a>.</p>



<p>M5Paper nails the design thanks to 4.7-inch, 940*540 multitouch 16 level grayscale e-ink display. It’s not just an e-ink ESP32 module, it’s a well-thought-through product that deserves everyone’s attention.  The phone form factor feels great in my hand and lightning-fast (for an e-ink) display creates this PDA alike impression. </p>




<h3>Inside M5Paper</h3>



<p>While the device doesn’t make it difficult to peak inside, M5Paper isn’t designed to be opened and tinkered with. You won’t find any hidden pins or ways to interact with the board, but there is enough space to swap the LiPo battery for a bigger one, in case 1150mAh isn’t enough. And you get 3 Grove connectors to plug external sensors and other fun add-ons. </p>



<figure><img data-attachment-id="25180" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/m5paper-1-2/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg" data-orig-size="1024,704" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;MI 9&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609353360&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.75&quot;,&quot;iso&quot;:&quot;238&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="M5Paper-1-2" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg" loading="lazy" width="1024" height="704" src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg?x19519" alt="" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-768x528.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-150x103.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-218x150.jpg 218w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-300x206.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-696x479.jpg 696w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-100x70.jpg 100w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-768x528.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-150x103.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-218x150.jpg 218w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-300x206.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-696x479.jpg 696w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2-100x70.jpg 100w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-2.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Under the hood, M5Paper comes with a very familiar ESP32 module surrounded by pretty decent hardware – just take a look at the specs:</p>



<figure><table><tbody><tr><td>SP32-D0WDQ6-V3</td><td>240MHz dual core, 600 DMIPS, 520KB SRAM, Wi-Fi, dual mode Bluetooth</td></tr><tr><td>Flash</td><td>16MB</td></tr><tr><td>PSRAM</td><td>8MB</td></tr><tr><td>Ports</td><td>TypeC*1, HY2.0-4P*3 , TF-card(microSD) slot</td></tr><tr><td>E-Ink Display</td><td>Model Number：EPD_ED047TC1 | 540*960@4.7″ | Grayscale : 16 Levels | Display area : 58.32*103.68mm | Display Driver : IT8951</td></tr><tr><td>Physical Button</td><td>Multi-function button*1 ， Reset Button*1</td></tr><tr><td>RTC</td><td>BM8563</td></tr></tbody></table></figure>



<p>It’s a very clever design to include BM8563 Real-Time Clock, as you can save a lot of power by using RTC to trigger the events rather than sleep policies of ESP32. Combined with the e-ink, M5Paper can last ages on a single charge. This is reinforced by the default firmware as well. The power button at the back of the device disables ESP32 when pressed and the “volume” rocker wakes it up when held for a couple of seconds. </p>




<h3>Putting “kindle” into M5Paper</h3>



<p>The device feels like a small-sized phone in the hand. It has just enough screen estate to break the development board impression and appear as intriguing “kindle” alike device. It’s not an e-reader, M5Paper is even more awesome. The display is simply perfect as far as e-inks go. 16 level greyscale enables images and advanced shading while multitouch (2-point) touchscreen is responsive enough, so I don’t hate using the onscreen keyboard. </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/notenoughtech.com\/home-automation\/m5paper-the-kindle-of-development-and-automation\/&quot;}"><li><figure><img data-attachment-id="25171" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/m5paper-2/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg" data-orig-size="1024,1024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;MI 9&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610399978&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.75&quot;,&quot;iso&quot;:&quot;423&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="M5Paper-2" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg" loading="lazy" width="1024" height="1024" src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg?x19519" alt="" data-id="25171" data-full-url="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg" data-link="https://notenoughtech.com/?attachment_id=25171" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-696x696.jpg 696w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2-696x696.jpg 696w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-2.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="25170" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/m5paper-1/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg" data-orig-size="1024,1024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;MI 9&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610399967&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.75&quot;,&quot;iso&quot;:&quot;505&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="M5Paper-1" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg" loading="lazy" width="1024" height="1024" src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg?x19519" alt="" data-id="25170" data-full-url="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg" data-link="https://notenoughtech.com/?attachment_id=25170" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-696x696.jpg 696w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg 1024w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-768x768.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-150x150.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-300x300.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1-696x696.jpg 696w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/M5Paper-1.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul></figure>



<p>Navigating through menus is fairly quick, and even though menus take 2-3 screen refresh cycles to fully materialise, you can quickly jump from screen to screen. Frankly speaking, I played with less responsive LCD screens in the past!</p>



<p>Just remember, there is no backlight. The device is perfectly visible in a full sunshine, but completely useless in the dark.</p>




<h3>The “I’m still all-in-one development board”</h3>



<p>It’s not the first take on e-ink display by M5Stack. They merged it before with their Core INK – an e-ink-equipped take on M5Stick series. Unlike <a href="https://m5stack.com/collections/m5-core/products/m5stack-esp32-core-ink-development-kit1-54-elnk-display?variant=37404426174636">Core INK</a>, M5Paper is missing one thing that I really liked – the ability to program the board in the web browser wirelessly. I can only hope that the support will be added soon, as programming M5Stack wirelessly feels like magic.</p>



<p>Update: 23/01/2021: Dev team from M5Stack had confirmed that integration for UIFlow is on the way, we should see M5Paper joining the UIFlow as well soon!</p>



<figure><img data-attachment-id="25195" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/2021-01-23-14_18_47-window/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg" data-orig-size="900,341" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021-01-23-14_18_47-Window" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg" loading="lazy" width="900" height="341" src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg?x19519" alt="" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg 900w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-768x291.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-150x57.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-300x114.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-696x264.jpg 696w" sizes="(max-width: 900px) 100vw, 900px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg 900w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-768x291.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-150x57.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-300x114.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window-696x264.jpg 696w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-23-14_18_47-Window.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Just like other M5Stack devices, M5Paper supports Arduino IDE &amp; MicroPython. The product is fairly new, so it lacks in community projects, but the documentation explains basics and shows you how to handle an e-ink display with sample projects. Apart from online examples, M5Paper supports M5Stack Burner software. You can try community projects and easily reverse back to the default firmware.</p>



<figure><img data-attachment-id="25182" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/2021-01-22-00_05_29-m5burner-1/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg" data-orig-size="1634,1345" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021-01-22-00_05_29-M5Burner-1" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg" loading="lazy" width="1634" height="1345" src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg?x19519" alt="" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg 1634w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-768x632.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-1536x1264.jpg 1536w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-150x123.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-300x247.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-696x573.jpg 696w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-1068x879.jpg 1068w" sizes="(max-width: 1634px) 100vw, 1634px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg 1634w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-768x632.jpg 768w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-1536x1264.jpg 1536w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-150x123.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-300x247.jpg 300w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-696x573.jpg 696w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1-1068x879.jpg 1068w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-22-00_05_29-M5Burner-1.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Unless an e-ink is what you really want, I’d pick <a href="https://m5stack.com/collections/m5-core/products/m5stack-esp32-core-ink-development-kit1-54-elnk-display?variant=37404426174636">Core INK</a> series if you are getting started. M5Paper expects customers a bit of knowledge to take the advantage of the ESP32 inside. The demo panel promises interesting features, but to my disappointment, the “Home Automation” panel isn’t released as a source code, and I cannot integrate it with my house appliances. It’s a shame. </p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/notenoughtech.com\/home-automation\/m5paper-the-kindle-of-development-and-automation\/&quot;}">
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/notenoughtech.com\/home-automation\/m5paper-the-kindle-of-development-and-automation\/&quot;}">
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/notenoughtech.com\/home-automation\/m5paper-the-kindle-of-development-and-automation\/&quot;}"><figure><img data-attachment-id="25149" data-permalink="https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/attachment/2021-01-19-00_00_02-window/" data-orig-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg" data-orig-size="422,426" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2021-01-19-00_00_02-Window" data-image-description="" data-medium-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg" data-large-file="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg" loading="lazy" width="422" height="426" src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg?x19519" alt="" srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg 422w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window-150x151.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window-300x303.jpg 300w" sizes="(max-width: 422px) 100vw, 422px" data-lazy-srcset="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg 422w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window-150x151.jpg 150w, https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window-300x303.jpg 300w" data-lazy-src="https://notenoughtech.com/wp-content/uploads/2021/01/2021-01-19-00_00_02-Window.jpg?x19519&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>




</div>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/notenoughtech.com\/home-automation\/m5paper-the-kindle-of-development-and-automation\/&quot;}">
<h3>Buy M5Paper</h3>



<p>Buy it using these links to support NotEnoughTech.</p>








</div>
</div>



<h2>Final Thoughts</h2>



<p>I’m a little disappointed that M5Paper isn’t compatible with UIFlow, I hope this will change with time. I do love the device and I’m already thinking about potential projects. If you feel comfortable with Arduino IDE programming, go for it. Hardware-wise, <a href="https://m5stack.com/collections/m5-core/products/m5paper-esp32-development-kit-960x540-4-7-eink-display-235-ppi">M5Paper</a> is an amazing device worth the money spent on it. But if you are getting started, expect a steeper learning curve, limited tutorial materials, perhaps, you would be better off with <a href="https://m5stack.com/collections/m5-core/products/m5stack-core2-esp32-iot-development-kit?variant=35960244109476">M5Stack Core 2 </a>or <a href="https://m5stack.com/collections/m5-core/products/m5stack-esp32-core-ink-development-kit1-54-elnk-display?variant=37404426174636">Core INK</a> instead. I will try to get my hands on both! If you have any questions, please let me know in this <a href="https://www.reddit.com/r/Not_Enough_Tech/comments/l2nh9n/m5paper_the_kindle_of_development_and_automation/">Reddit thread</a>.</p>
</div></div></div>]]>
            </description>
            <link>https://notenoughtech.com/home-automation/m5paper-the-kindle-of-development-and-automation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25959694</guid>
            <pubDate>Fri, 29 Jan 2021 17:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StrictMark: Markdown, Refactored]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25958444">thread link</a>) | @gritzko
<br/>
January 29, 2021 | http://doc.replicated.cc/%5EWiki/strictmark.sm | <a href="https://web.archive.org/web/*/http://doc.replicated.cc/%5EWiki/strictmark.sm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><a href="https://daringfireball.net/projects/markdown/">Markdown</a> is a wonderful lightweight markup: minimalistic,
easy to read and write. Markdown is supported by GitHub,
Bitbucket, Reddit, Diaspora, Stack Exchange, and many others.
It is not without issues though.  Markdown is precedent-based,
so to say.  It aimed to codify preexisting practices which
were... diverse.  For that reason, it is messy and inconsistent
between implementations.  </p>
<p>StrictMark is a rational <em>subset</em> of Markdown that implements
all the features with the shortest <em>formal</em> grammar possible.
Hence, uniform syntax and no ambiguities.  The idea is that
StrictMark can reuse all the existing Markdown support,
without sharing the weight of the legacy syntax and its
incidental complexity.</p>
<p>StrictMark is Markdown, refactored.</p>
<h2>Markdown critique</h2>
<p>Markdown implementations are inconsistent. Vim highlights it one
way, VS Code does it differently, and the resulting HTML is yet
another thing. A textbook fix for inconsistent implementations
is having a <em>formal grammar</em>.  That might be either a proper
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">eBNF</a> grammar or just some regexes in simpler cases.  There
must be something formal and unambiguous.  HTML has it, CSS has
it, every markup or programming language has it.  But Markdown.
Sadly, the syntax itself is so ambiguous that making a formal
grammar becomes a road of pain. For example, HTML (which is
hardly lightweight) has a uniform syntax for its <code>&lt;/elements&gt;</code>.
With Markdown, every element has its own syntax and those
syntaxes interact.  Markdown formal grammar was attempted in the
past, but if you ask me, the result was underwhelming. The <a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">PEG
based grammar</a> is 700 lines long. For a <em>minimalistic</em>
markup, that is <strong>a lot</strong>. So ironic.</p>
<p><a href="http://commonmark.org/">CommonMark</a> is a Markdown codification effort that produced
the most complete spec so far.  Still, that spec is
rule-and-exception based, no grammar.  The text of the spec is
full of "legalese":</p>
<blockquote><p>Â«An indented code block cannot interrupt a paragraph, so
there must be a blank line between a paragraph and a
following indented code blockÂ»</p></blockquote>
<p>Here it describes the specifics of interrelations between two
particular markup elements. But <code>N</code> elements produce <code>N*N</code>
relations!  Consider that ATX headings are always single-line
while Setext headings can be multiline. Why? Because the spec
says so. It is one big heap of rules and another one of
exceptions. That's why it advises a "parsing strategy" and
not a parser generator.</p>
<p>Whether the CommonMak spec has fixed all the corner cases and
ambiguities is unclear.  Or maybe clear, as the spec is actively
revised. So is the code.  The CommonMark C parser is 10KLoC of
hand-written code.  It has plenty of exceptions and tweaks.
While writing <a href="http://doc.replicated.cc/%5EWiki/ron.sm">RON</a> docs, I ran into issues immediately;
had to use the HEAD version which has those issues fixed.</p>
<p>Overall, that seemingly theoretical grammar problem causes
plenty of <em>accidental complexity</em>.  Markdown is messy and hard
to reason about;  it is not always clear how to interpret a
given construct.  That combinatorial mess may not be a problem
for its current uses, of course.  (Although, I highly doubt
that.) After all, the existing libcmark parser is fuzzed,
thus reasonably reliable.  Still, Markdown is a very shaky
base if you want to build on top of it.  To build something
more advanced than a README.  Like, full WYSIWYG editing or
diff highlighting or other complex behavior.</p>
<h2>StrictMark principles</h2>
<p>StrictMark's objective is to make a Markdown <em>subset</em> which is a
<em>proper markup language</em>. To  remove that incidental complexity
by rationalizing the grammar and making it formal.  This
document <a href="http://doc.replicated.cc/%5EWiki/strictmark.sm?@text">is StrictMark</a>.</p>
<p>One may ask, why do I want to make Markdown a proper language?
After all, there is HTML which is proper enough. Yes, HTML is a
widely supported standard, but it is hopelessly elephantine.
Let's think, who can afford to develop/support a proper HTML
engine?  That is roughly one-and-a-half companies in the world.
Hence the interest in a minimalistic hypertext markup language.</p>
<p>The next question is obvious.  If StrictMark is ever used at
some scale, would not it become elephantine, naturally?
Consider Wikipedia/Mediawiki markup.  Once neat and lean like
all such markups, it evolved into an elephantine <a href="https://en.wikipedia.org/w/index.php?title=Sneakers&amp;action=edit">mess</a>.
What about table support, for example?  Some people think it is
necessary, quite deservedly so.</p>
<p>I plan to prevent feature sprawl by enabling <a href="https://en.wikipedia.org/wiki/Transclusion">transclusion</a>.
A document may reference other documents and objects through
hyperlinks.  It can also <em>include</em> other objects and documents,
through hyperlinks.  The good old <code>&lt;img&gt;</code> tag is an example of
transclusion.  That will not even extend the syntax: StrictMark
reuses the image syntax for the general case of transclusion.
Once you need a table, you transclude a table!  It is up to the
renderer to deal with all those other data types.  CSV is a much
better format for tables than HTML or Markdown.</p>
<p>StrictMark is a backwards compatible subset of CommonMark, for
the most part.  Any existing CommonMark tooling will support
StrictMark reasonably well.  A StrictMark parser may not
understand arbitrary Markdown.</p>
<p>StrictMark principles:</p>
<ol><li><p>A formal grammar.  StrictMark is a <em>regular language</em> in its
structural part (i.e. blocks).  The inline markup syntax is
based on regex-defined <em>markers</em>.  That way, a decent parser
can be implemented in regexes only.</p></li>
<li><p>There is one way to do a thing, as uniform as possible.
Hence: spaces, not tabs!  Because spaces can replace tabs,
not the other way around. ATX headings only. Formatting
brackets are <code>*one char*</code> wide only. All block formatting is
indented uniformly.</p></li>
<li><p>Minimize ambiguity. Same character should not denote lists
and emphasis, etc.</p></li>
<li><p>No spooky action-at-a-distance.  Each line can be parsed
separately.  All the structural markup is 4-char-wide, hence
indents are uniform. This restriction makes the nesting
structure clear and unambiguous.</p></li>
<li><p>Inline markup has very limited nesting; it is of secondary
importance anyway.  There is clear markup precedence; a
<code>code</code> span wins over <code>strong</code>, <code>strong</code> wins over <code>emph</code>.</p></li>
<li><p>HTML is not the only output format.  It could be PDF, DOC,
TeX, whatever.  Hence, no HTML inserts. Use transclusion
for other formats.</p></li>
<li><p>Keep markup to the minimum. The plain text form must stay
clean and readable.</p></li>
<li><p>If the StrictMark interpretation contradicts CommonMark or
CommonMark has an ambiguity then screw CommonMark.</p></li></ol>
<p>Interestingly enough, <a href="https://johnmacfarlane.net/beyond-markdown.html">similar ideas</a> were proposed in the
CommonMark community some years ago.</p>
<h2>Inline markup</h2>
<p>Markdown inline markup may seem like an easy part. Sadly, it is
not.  Due to very irregular and ambiguous syntax, implementing
it properly is difficult.  For that reason, StrictMark
rationalizes the inline markup in the following ways:</p>
<ol><li><p>All inline markup is seen as bracketing.  Brackets are
matched separately, using regular expressions; e.g.
<code>(?&lt;=\s)[*](?=\S)</code> is the opening bracket for STRONG.
Bracket pairs only become effective if they satisfy the
precedence rules.</p></li>
<li><p>Bracket precedence, lower to higher:</p>
<ol><li><p><code>_emphasized_</code>,</p></li>
<li><p><code>[link][1]</code>,</p></li>
<li><p><code>*strong*</code>,</p></li>
<li><p><code>\* escapes</code>, </p></li>
<li><p>`<code>code</code>`.</p></li></ol></li>
<li><p>An open bracket can be paired with any following closing
bracket of that kind.  A new open bracket will cancel any
preceding unmatched open bracket of its kind.</p></li>
<li><p>In case of overlap, higher-precedence brackets win; in case
of equal-precedence, the earlier range wins.</p></li>
<li><p>Higher-precedence brackets may nest in lower-precedence, but
not the other way around (the lower one is cancelled).  In
case of equal-precedence, the earlier range wins.</p></li>
<li><p>No double symbols, i.e. <code>*strong*</code> not <code>**strong**</code>.</p></li></ol>
<p>Compared to CommonMark, restrictions are many:</p>
<ul><li><p>no double-symbol syntax,</p></li>
<li><p>no arbitrary nesting,</p></li>
<li><p>only reference links, the label is 1 symbol long,</p></li>
<li><p>no way to put backticks inside a code span.</p></li></ul>
<p>That may seem restrictive, but again: inline formatting has a
supplementary role.  It must pull its own weight or it must not
be there.  The accurate bracket patterns are listed in the
grammar appendix.</p>
<h2>Links, images and transclusions</h2>
<p>The only form of links CommonMark supports is full reference
links.  The link label must be exactly one symbol long. This
approach:</p>
<ul><li><p>matches a common established practice of using numbered
references;</p></li>
<li><p>minimizes the visual noise in the text flow;</p></li>
<li><p>keeps reference definitions exactly 4 symbols long.</p></li></ul>
<p>Reference definitions can be placed anywhere.  It is nice to put
them at the end of a section or in the end of the document.
Example:</p>
<pre><code>    see [Replicated Object Notation][1]

    [1]: http://doc.replicated.cc/ron.sm "What is RON"
</code></pre>
<p>If you have more than 10 links, use letters. 
In case you have thousands of links, use Unicode symbols.</p>
<p>Transclusions and images use the same syntax as links, 
with an exclamation mark <code>!</code> prepended.
Example:</p>
<pre><code>    ![here is the table][T]
    [T]: /table?@tab "this might be any object"
</code></pre>
<h2>Block markup</h2>
<p>StrictMark has tree types of blocks:</p>
<ol><li><p>container blocks (lists, blockquotes, divs),</p></li>
<li><p>leaf blocks (paragraphs, headers, rulers, fenced code blocks).</p></li></ol>
<p>Container and entry blocks can contain other blocks, leaf blocks
can not.  Depending on the type of a leaf block, it can contain
text, metadata or nothing at all, </p>
<p>The block-related markup goes in the beginning of the
line, in blocks of four symbols.  That part of a line  is called
a <em>block stack</em>.  The allowed blockstack pattern is
<code>(INDENT|QUOTE)* LIST? LEAF?</code>.  In absence of an explicit leaf
block, a formatted text paragraph is implied.</p>
<p>A block can be continued in the following lines; that is
signaled by indents (four spaces) in place of the block markup.
An empty line is considered to be a continuation line for the
container blocks in the stack, but not for the leaf block.</p>
<p>Example:</p>
<pre><code> #  Multiline
    header

 1. here the entry starts,
    and then it continues

    and continues...
 2. ...till the next entry.
</code></pre>
<p>Changes in blockstack depth cause container nesting changes.
Additional indent of less than 4 spaces is not meaningful.
That allows for easier line-by-line parsing and interpretation.
If an indent level starts with a bare indent, that creates a
generic container block (in other words, a <code>div</code>).  With
CommonMark, that should be a code block.  StrictMark generalizes
that slightly.</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://doc.replicated.cc/%5EWiki/strictmark.sm">http://doc.replicated.cc/%5EWiki/strictmark.sm</a></em></p>]]>
            </description>
            <link>http://doc.replicated.cc/%5EWiki/strictmark.sm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25958444</guid>
            <pubDate>Fri, 29 Jan 2021 15:46:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Johnson and Johnson single-shot vaccine appears 66% effective in global trial]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 261 (<a href="https://news.ycombinator.com/item?id=25957820">thread link</a>) | @heyheyheysome
<br/>
January 29, 2021 | https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Johnson &amp; Johnson's long-awaited vaccine appears to protect against COVID-19 with just one shot. It's not as strong as some of its two-shot rivals but still potentially helpful for a world in dire need of more doses.</p><div><p><span><span><div><div title="How the other vaccines in line for Canada's approval compare" role="button" tabindex="0"><div><div aria-labelledby="1850380867702-metadata-" title="How the other vaccines in line for Canada's approval compare"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/309/727/COVID-OTHER-VACCINESS-BIRAK-290121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Canada has other vaccines in line for approval -- how they compare to the ones already being rolled out and how COVID-19 variants are a complicating factor.<!-- --> <!-- -->2:03</span></span></span></p><p><span><p>Johnson &amp; Johnson's long-awaited vaccine appears to protect against COVID-19 with just one shot — it's not as strong as some of its two-shot rivals but still potentially helpful for a world in dire need of more doses.</p>  <p>J&amp;J said Friday that in the U.S. and seven other countries where their trial has been conducted, the single-shot vaccine was 66 per cent effective overall at preventing moderate to severe illness, and much more protective — 85 per cent — against the most serious symptoms.</p>  <p>There was some geographic variation. The vaccine worked better in the U.S. — 72 per cent effective against moderate to severe COVID-19 — compared to 57 per cent in South Africa, where it was up against an easier-to-spread mutated virus.</p>  <p>Dr. Matthew Oughton, an infectious disease&nbsp;specialist at Jewish General Hospital in Montreal, told CBC News the trial data "certainly looks promising for a single dose, which of course will certainly ease a lot of the logistics we've been dealing with so far with the current vaccines that have been granted approval."</p>  <p>He said by examining mixed populations across continents, the J&amp;J trial is not only "looking at differences in how different groups of people respond, that also means that they capture different viral variants, so they have a good sense of the real-world efficacy of this vaccine."</p>  <p>With vaccinations off to a rocky start globally, experts have&nbsp;been counting on a one-dose vaccine that would stretch scarce supplies and avoid the logistics nightmare of getting people to return for boosters.</p>    <h2>Greater protection&nbsp;vs. more shots</h2>  <p>But with some competing vaccines shown to be 95 per cent effective after two doses, the question is whether somewhat less protection is an acceptable tradeoff for getting more shots in arms quickly.</p>  <p>Matthew Miller, an associate professor at the Institute for Infectious Disease Research at McMaster University, told CBC News by email that the decision will depend on multiple factors, including "the procurement timelines for specific vaccines in each country" and how prevalent the newly circulating variants become.</p>  <p>"Some high-risk populations may need vaccines that confer higher degrees of protection, while less efficacious vaccines might be appropriate for lower-risk populations," he said.</p>  <p>The Canadian government signed an agreement with Johnson &amp; Johnson for up to 38 million doses of their vaccine, though as of earlier this month, officials said a vaccine schedule had not been finalized.</p>  <p><em><strong>WATCH \ Dr. Matthew Oughton, infectious diseases specialist, encouraged by data so far:</strong></em></p>  <p><span><span><div><div title="Johnson &amp; Johnson vaccine 'very promising,' says infectious disease specialist" role="button" tabindex="0"><div><div aria-labelledby="1850072131736-metadata-" title="Johnson &amp; Johnson vaccine 'very promising,' says infectious disease specialist"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/15/283/JNJ.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Calling the clinical trial 'thorough,' infectious disease specialist Dr. Matthew Oughton says Johnson &amp; Johnson's single-shot COVID-19 vaccine is also easier to handle logistically compared to approved vaccines in Canada.<!-- --> <!-- -->3:40</span></span></span></p>  <p>J&amp;J said that within a week, it will file an application for emergency use in the U.S., and then abroad. It expects to supply 100 million doses to the U.S. by June, and expects to have some ready to ship as soon as authorities give the green light.</p>  <p>The U.S. Food and Drug Administration has set a 50 per cent threshold for any COVID-19 vaccine to be considered for emergency use authorization.</p>  <h2>No deaths reported in the vaccine group</h2>  <p>The J&amp;J data comes from&nbsp;preliminary findings from a study of 44,000 volunteers that isn't completed yet. Researchers tracked illnesses starting 28 days after vaccination — about the time when people getting a two-dose vaccine would have needed another shot.</p>  <p>After day 28, no one who got vaccinated needed hospitalization or died, regardless of whether they were exposed to "regular COVID or these particularly nasty variants," Dr. Mathai Mammen, global research chief for J&amp;J's Janssen Pharmaceutical unit, told The Associated Press.&nbsp;When the vaccinated did become infected, they had a milder illness.</p>  <p>Dr. Anthony Fauci, director of the U.S. National Institute of Allergy and Infectious Diseases, also was particularly encouraged by the findings with respect to patients with the most serious symptoms.</p>  <p>"This really tells us that we have now a value-added vaccine candidate," said Fauci at a Friday briefing of U.S. health officials in President Joe Biden's administration.</p>    <p>Defeating the scourge that has killed more than two million people worldwide will require vaccinating billions, and the shots currently being rolled out in different countries&nbsp;require two doses a few weeks apart for full protection. Early data is mixed on exactly how well all the different kinds work, but shots made by Pfizer and Moderna appear to be about 95 per cent protective after the second dose.</p>  <p>But amid shortages, some countries have advised delaying the second dose of certain vaccines with little data on how that would affect protection.</p>  <h2>Company also testing 2-shot vaccine</h2>  <p>All COVID-19 vaccines train the body to recognize the new coronavirus, usually by spotting the spike&nbsp;protein that coats it. But they're made in very different ways.</p>  <p><em><strong>WATCH \ Canadian labs working hard to track new variatns:</strong></em></p>  <p><span><span><div><div title="Growing concern about COVID-19 variants in Canada" role="button" tabindex="0"><div><div aria-labelledby="1848895043807-metadata-" title="Growing concern about COVID-19 variants in Canada"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/940/735/boudjikanian-variant-concerns.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>COVID-19 numbers are falling, but Canadian health officials are becoming increasingly concerned about the presence of two coronavirus variants. A variant first found in the U.K. has been confirmed in three provinces while a variant first discovered in South Africa variant has been found in two provinces.<!-- --> <!-- -->4:15</span></span></span></p>  <p>J&amp;J's shot uses a cold virus like a Trojan horse to carry the spike gene into the body, where cells make harmless copies of the protein to prime the immune system in case the real virus comes along.</p>  <p>Rival AstraZeneca makes a similar cold virus vaccine that requires two doses. Both the AstraZeneca and J&amp;J vaccines can be stored in a refrigerator, making them easier to ship and&nbsp;use in developing countries than the frozen kind made by Pfizer and Moderna.</p>  <p>J&amp;J said its vaccine works consistently in a broad range of people: A third of participants were over age 60, and more than 40 per cent had other illnesses putting them at risk of severe COVID-19, including obesity, diabetes and HIV.</p>  <h2>Vaccine producers need to be 'nimble': Fauci</h2>  <p>J&amp;J said the vaccine is safe, with reactions similar to other COVID-19 shots, such as fever, that occur when the immune system is revved up.</p>  <p>"Gambling on one dose was certainly worthwhile," said&nbsp;Mammen, but J&amp;J has&nbsp;hedged its bets with a study of a two-dose version of its vaccine, which is still underway.</p>  <p>While it released few details, the company said there were no serious allergic reactions. But occasionally other COVID-19 vaccines trigger such reactions, which can be reversed if promptly treated — and authorities have warned people to be on the lookout regardless of which type of vaccine is used.</p>  <p>A handful of coronavirus variants have gained attention in recent weeks, a development that Fauci and the new director of the Centers for Disease Control described as one to be expected.</p>  <p>"I think we should be treating every case right now as if it's a variant," said the CDC's Dr. Rochelle Walensky.</p>  <p>"We will continue to see the evolution of mutants," said&nbsp;Fauci. "We will have to be nimble to adjust to make versions of the vaccine that are actually specifically directed to whatever mutations are prevalent at the time."</p>  <p>Friday's interim results come on the heels of another vaccine in final testing. Novavax reported this week that its vaccine appears 89 per cent effective in a U.K. study, and that it also seems to work — though not as well — against new mutated versions of the virus circulating in Britain and South Africa. A larger study in the U.S. and Mexico is still enrolling volunteers.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009</link>
            <guid isPermaLink="false">hacker-news-small-sites-25957820</guid>
            <pubDate>Fri, 29 Jan 2021 14:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pony – High-Performance Safe Actor Programming]]>
            </title>
            <description>
<![CDATA[
Score 318 | Comments 150 (<a href="https://news.ycombinator.com/item?id=25957307">thread link</a>) | @ibraheemdev
<br/>
January 29, 2021 | https://www.ponylang.io/discover/ | <a href="https://web.archive.org/web/*/https://www.ponylang.io/discover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
      

      

<h2 id="what-is-pony">What is Pony?</h2>

<p>Pony is an open-source, object-oriented, <a href="https://en.wikipedia.org/wiki/Actor_model">actor-model</a>, <a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities-secure</a>, high-performance programming language.</p>

<p>If you are looking to jump in and get started with Pony <em>right now</em>, you can try it in your browser using the <a href="http://playground.ponylang.io/">Pony Playground</a>. Keep reading if you are interested in what makes Pony different and why you should consider using it.</p>

<p>If you are interested in the early history of Pony and how it came into existence, you’re in luck: <a href="https://www.ponylang.io/blog/2017/05/an-early-history-of-pony/">“An Early History of Pony”</a>.</p>

<h2 id="what-makes-pony-different">What makes Pony different?</h2>

<h3 id="pony-is-type-safe">Pony is type safe</h3>

<p><em>Really type safe</em>. There’s a mathematical <a href="https://www.ponylang.io/media/papers/fast-cheap-with-proof.pdf">proof</a> and everything.</p>

<h3 id="pony-is-memory-safe">Pony is memory safe</h3>

<p>There are no dangling pointers and no buffer overruns. The language doesn’t even have the concept of null!</p>

<h3 id="exception-safe">Exception-Safe</h3>

<p>There are no runtime exceptions. All exceptions have defined semantics, and they are <em>always</em> caught.</p>

<h3 id="data-race-free">Data-race Free</h3>

<p>Pony doesn’t have locks nor atomic operations or anything like that. Instead, the type system ensures at compile time that your concurrent program can never have data races. So you can write highly concurrent code and never get it wrong.</p>

<h3 id="deadlock-free">Deadlock-Free</h3>

<p>This one is easy because Pony has no locks at all! So they definitely don’t deadlock, because they don’t exist!</p>

<h3 id="native-code">Native Code</h3>

<p>Pony is an ahead-of-time (AOT) compiled language. There is no interpreter nor virtual machine.</p>

<h3 id="compatible-with-c">Compatible with C</h3>

<p>Pony programs can natively call C libraries. Our compiler is able to generate a C-header file for Pony libraries. Consequently, C/C++ programs can natively call Pony programs!</p>

<h2 id="why-pony">Why Pony?</h2>

<p>There’s plenty to love about Pony, but more than anything else, what we love most is that Pony makes it easy to write fast, safe, efficient, highly concurrent programs. How? The Pony type system introduces a novel concept: “reference capabilities”. <a href="https://tutorial.ponylang.io/capabilities/reference-capabilities.html">Reference capabilities</a> allow you to label different bits of data based on how that data can be shared. The Pony compiler will then verify that you are in fact correctly using the data based on the labels you provide. Reference capabilities combined with Pony’s actor model of concurrency makes for a powerful pairing. Let’s dig in and take a quick look:</p>

<h3 id="mutable-state-is-hard">Mutable state is hard</h3>

<p>The problem with concurrency is shared mutable data. If two different threads have access to the same piece of data then they might try to update it at the same time. At best this can lead to those two threads having different versions of the data. At worst the updates can interact badly resulting in the data being overwritten with garbage. The standard way to avoid these problems is to use locks to prevent data updates from happening at the same time. This causes big performance hits and is very difficult to get right, so it causes lots of bugs.</p>

<h3 id="immutable-data-can-be-safely-shared">Immutable data can be safely shared</h3>

<p>Any data that is immutable (i.e. it cannot be changed) is safe to use concurrently. Since it is immutable it is never updated and it’s the updates that cause concurrency problems.</p>

<h3 id="isolated-data-is-safe">Isolated data is safe</h3>

<p>If a block of data has only one reference to it then we call it <em>isolated</em>. Since there is only one reference to it, isolated data cannot be <em>shared</em> by multiple threads, so there are no concurrency problems. Isolated data can be passed between multiple threads. As long as only one of them has a reference to it at a time then the data is still safe from concurrency problems.</p>

<h3 id="every-actor-is-single-threaded">Every actor is single threaded</h3>

<p>The code within a single actor is never run concurrently. This means that, within a single actor, data updates cannot cause problems. It’s only when we want to share data between actors that we have problems.</p>

<h3 id="reference-capabilities-enforce-safe-data-handling">Reference capabilities enforce safe data handling</h3>

<p>By sharing only immutable data and exchanging only isolated data we can have safe concurrent programs without locks. The problem is that it’s very difficult to do that correctly. If you accidentally hang on to a reference to some isolated data you’ve handed over or change something you’ve shared as immutable then everything goes wrong. What you need is for the compiler to force you to live up to your promises. Pony reference capabilities allow the compiler to do just that.</p>

<p>If you ask us, that’s pretty damn cool and a hell of a reason to give Pony a try.</p>

<h2 id="why-not-pony">Why not Pony?</h2>

<p>There are many valid reasons to not use Pony. Amongst these are:</p>

<ul>
<li>Lack of API stability</li>
<li>Lack of high-quality 3rd party libraries</li>
<li>Limited native tooling</li>
</ul>

<h3 id="api-stability">API stability</h3>

<p>Pony is pre-1.0. We regularly have releases that involve breaking changes. This lack of stability is plenty of reason for many projects to avoid using Pony.</p>

<h3 id="batteries-required">Batteries required</h3>

<p>If your project is going to succeed or fail based on the size of community around the tools you are using, Pony is not a good choice for you. While it’s possible to write stable, high-performance applications using Pony, you will have to do a decent amount of work. The pool of open source, ready to use Pony libraries is very small. If it’s not in the standard library then odds are you are going to have to add it yourself, either by writing it from scratch in Pony or by wrapping an existing C library using Pony’s excellent <a href="https://tutorial.ponylang.io/c-ffi/">C-FFI</a> functionality.</p>

<h3 id="tooling">Tooling</h3>

<p>There’s a wide swath of tooling that some people have come to expect that isn’t currently available for Pony. We don’t have an IDE. You can use standard debuggers like GDB or LLDB but the experience still has some rough edges. If you are comfortable working with a basic text editor and using LLDB, VTune and other tools, you’ll probably be ok. Just don’t expect a full, robust ecosystem. We aren’t there yet.</p>

<p>If your project isn’t going to get a great deal of benefit from any of Pony’s strengths, then you shouldn’t use Pony. If you are writing a single threaded application without any overriding performance concerns, and you need access to a large community and wealth of libraries then you’re much better off selecting another language. However, we hope that you see enough potential in Pony to start playing around with it even if it isn’t right for your current project.</p>

<h2 id="the-pony-philosophy">The Pony Philosophy</h2>

<p>In the spirit of <a href="http://www.jwz.org/doc/worse-is-better.html">Richard Gabriel</a>, the Pony philosophy is neither “the-right-thing” nor “worse-is-better”. It is “get-stuff-done”.</p>

<h3 id="correctness">Correctness</h3>

<p>Incorrectness is simply not allowed. <em>It’s pointless to try to get stuff done if you can’t guarantee the result is correct.</em></p>

<h3 id="performance">Performance</h3>

<p>Runtime speed is more important than everything except correctness. If performance must be sacrificed for correctness, try to come up with a new way to do things. <em>The faster the program can get stuff done, the better. This is more important than anything except a correct result.</em></p>

<h3 id="simplicity">Simplicity</h3>

<p>Simplicity can be sacrificed for performance. It is more important for the interface to be simple than the implementation. <em>The faster the programmer can get stuff done, the better. It’s ok to make things a bit harder on the programmer to improve performance, but it’s more important to make things easier on the programmer than it is to make things easier on the language/runtime.</em></p>

<h3 id="consistency">Consistency</h3>

<p>Consistency can be sacrificed for simplicity or performance.
<em>Don’t let excessive consistency get in the way of getting stuff done.</em></p>

<h3 id="completeness">Completeness</h3>

<p>It’s nice to cover as many things as possible, but completeness can be sacrificed for anything else. <em>It’s better to get some stuff done now than wait until everything can get done later.</em></p>

<p>The “get-stuff-done” approach has the same attitude towards correctness and simplicity as “the-right-thing”, but the same attitude towards consistency and completeness as “worse-is-better”. It also adds performance as a new principle, treating it as the second most important thing (after correctness).</p>

<h2 id="guiding-principles">Guiding Principles</h2>

<p>Throughout the design and development of the language, the following principles should be adhered to.</p>

<ul>
<li><p>Use the get-stuff-done approach.</p></li>

<li><p>Simple grammar. Language must be trivial to parse for both humans and computers.</p></li>

<li><p>No loadable code. Everything is known to the compiler.</p></li>

<li><p>Fully type safe. There is no “trust me, I know what I’m doing” coercion.</p></li>

<li><p>Fully memory safe. There is no “this random number is really a pointer, honest.”</p></li>

<li><p>No crashes. A program that compiles should never crash (although it may hang or do something unintended).</p></li>

<li><p>Sensible error messages. Where possible use simple error messages for specific error cases. It is fine to assume the programmer knows the definitions of words in our lexicon, but avoid compiler or other computer science jargon.</p></li>

<li><p>Inherent build system. No separate applications required to configure or build.</p></li>

<li><p>Aim to reduce common programming bugs through the use of restrictive syntax.</p></li>

<li><p>Provide a single, clean and clear way to do things rather than catering to every programmer’s preferred prejudices.</p></li>

<li><p>Make upgrades clean. Do not try to merge new features with the ones they are replacing, if something is broken remove it and replace it in one go. Where possible provide rewrite utilities to upgrade source between language versions.</p></li>

<li><p>Reasonable build time. Keeping down build time is important, but less important than runtime performance and correctness.</p></li>

<li><p>Allowing the programmer to omit some things from the code (default arguments, type inference, etc) is fine, but fully specifying should always be allowed.</p></li>

<li><p>No ambiguity. The programmer should never have to guess what the compiler will do, or vice-versa.</p></li>

<li><p>Document required complexity. Not all language features have to be trivial to understand, but complex features must have full explanations in the docs to be allowed in the language.</p></li>

<li><p>Language features should be minimally intrusive when not used.</p></li>

<li><p>Fully defined semantics. The semantics of all language features must be available in the standard language docs. It is not acceptable to leave behavior undefined or “implementation dependent”.</p></li>

<li><p>Efficient hardware access must be available, but this does not have to pervade the whole language.</p></li>

<li><p>The standard library should be implemented in Pony.</p></li>

<li><p>Interoperability. Must be interoperable with other languages, but this may require a shim layer if non-primitive types are …</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ponylang.io/discover/">https://www.ponylang.io/discover/</a></em></p>]]>
            </description>
            <link>https://www.ponylang.io/discover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25957307</guid>
            <pubDate>Fri, 29 Jan 2021 14:03:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking about software engineering]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25956644">thread link</a>) | @funkisjazz
<br/>
January 29, 2021 | https://nintil.com/programming | <a href="https://web.archive.org/web/*/https://nintil.com/programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="mobile-panel">
<article>

<div>
<p>Though I'm right now not employed as a software engineer I have been writing code under various hats for the last few years (As a data scientist, ML engineer, and software engineer). Naturally me being me I have not just done the thing but also reflected about the thing. Questions like what's good software, what does being a good software engineer mean, how should meetings be ran, and so on. Here are some thoughts on that.</p>

<h2 id="the-cost-of-disagreement">The cost of disagreement</h2>
<p>In many cases a disagreement may be over something that both sides agree is not sizable. I can think something is 80% good whereas you think it's just 75% and I can think the opposite of your solution. But we can agree that the cost to resolve that disagreement can defeat the gains from actually choosing the best solution. So "I disagree but let's go ahead" is something that should be done in these cases, with a coin flip if needed. Consensus-driven decision making may be good at some stages, especially if paired with good processes around meetings but it can lead to gridlock.</p>
<p>I'm of course not the first one in proposing the "<a href="https://en.wikipedia.org/wiki/Disagree_and_commit">disagree and commit</a>" principle though I only learned this had a name very recently.</p>
<h2 id="meetings">Meetings</h2>
<p>Meetings can be terrible, meetings can be great. Bad meetings tend to occur because people show up without having thought much about what is to be discussed in the meeting. Isn't the point of the meeting to do the thinking? That's one way, perhaps the most common way of viewing meetings, and it's a lazy default because they don't impose homework on you. But doing the thinking in real time, with many voices to be sequentially heard and given a constrained time is not great for good decision making. Many times I've seen meetings that dragged on forever where disagreements would keep circling back and forth, or where we would simply be talking past each other.</p>
<p>A better way to run meetings, which I also tried, is to collate whatever is it that the outcome should be before the meeting. If it's an architecture design meeting, do the work, usually the meeting owner can do most of it, even if they know it won't be 100% perfect. Then ask for feedback a week ahead of the meeting. Incorporate the feedback to the document, repeat. Note down disagreements; have a literal "Standing disagreements" section in the document with the key points that are not quite agreed on, plus the reasoning behind them. Having everyone review the disagreements and having time to do so, on (digital) paper sets up a clearer goal for the meeting: Iron out specific points. During the meeting, a moderator would go one by one over those points and ask for a decision, then highlighting in bold which option was chosen. Then we would move to the next point and so on. Everyone liked this kind of meeting.</p>
<h2 id="ownership">Ownership</h2>
<p>Lack of ownership is the root of all evil (ok, some exaggeration here). Everyone's problem is no one's problem. In documentation, lack of ownership means finding obsolete documentation and no one person to go to to get it fixed; or what's worse, no system in place to enforce that the documentation is up to date (i.e. every document could disappear 6 months after it's published unless whoever uploaded or created it says otherwise in an email the system sends them after six months, documents shouldn't live rent free). Or having a team dedicated to tirelessly aggregating information so that everything everyone is doing is visible. We had something like this in my first job at the London Electric Vehicle Company (LEVC) and I suspect this may be more common in automotive or aerospace than in software or in biotech.</p>
<p>Apple had a very clever idea in defining <a href="https://twitter.com/michael_nielsen/status/1279478277585817600">Directly Responsible Individuals</a> (DRIs) for everything. Having a name accountable instead of a vague "the team" or "the process" makes it easy to make changes. I think many people are reluctant to blame individuals for mistakes they make, but well timed blame (feedback about what mistakes were made, potentially there being consequences for grave mistakes etc) can both help the blamed individual (They can know what to improve) and the team as a whole to succeed.</p>
<p>Something I once thought is that many decisions that involve estimates could be made into bets, either for small amounts of money or some kind of token. If you say X will be finished in a week and it takes longer, then you lose. This could be gamed by overestimating how long things take, but something like this seems like the right way to get better at making decisions involving uncertainty.</p>
<h2 id="questions-as-systemic-failures">Questions as systemic failures</h2>
<p>Every question asked in an internal Slack is a policy failure. It means the existing information systems failed to deliver an answer, and the user falls back to manually asking the hive mind's tacit knowledge. This has various problems: One, it introduces longer delays between question and answer, especially if whoever knows the answer is in another timezone. Two, it embraces tacit knowledge in a distributed and incoherent fashion: If there is no one true answer there can be many answers and that can lead to disagreements and wrong decisions. Instead, ideally there is a centralized repository of information where for each Q there is one and only one A, and a team dedicated to getting owners of various systems to actually codify their knowledge. This should work well with the ownership system above.</p>

<h2 id="good-software">Good software</h2>
<p>Good software is code that is readable, fast, flexible, and scalable. Out of these only speed is the one that is universally agreed on how to measure. The rest are fuzzy, as are most things in life.</p>
<p>Readable code pretty much depends on who is writing it; <a href="https://github.com/jayfoad/aoc2019apl/blob/master/p12.dyalog">Dyalog</a> looks like <a href="https://en.wikipedia.org/wiki/Brainfuck">Brainfuck</a> to me, and the many parenthesis in Lisps can make code hard to read to someone who is not a lisper (I did the experiment; I spent some time learning basic Clojure and while I remain not a Clojurian, the parenthesis become less of an issue). Lifetimes in Rust seem obscure until one know how they work.</p>
<p>Flexible code is code that is easier to extend. This is hard to quantify but anyone that has coded knows it when they see it; a given piece of code can just effortlessly do something new with a two line change, or it may need a thousand line change to work again. The former is more flexible than the latter. Moreover this flexibility shouldn't come at the expense of readability though sometimes this can be the case.</p>
<p>Scalable code is code that works well with small as well as big inputs, this can be achieved in a single machine or many.</p>
<p>The extent to which these matter depend on who is developing it (Readable code depends on individual preferences), and flexibility is not really needed if the end result is more or less fixed; but it's really desired in a startup that is constantly adapting. In that environment, speed may be sacrificed for extra flexibility.</p>
<p>The code that should be written absent any constraints is good code, but real life situations means that the right thing to do is to make tradeoffs and move ahead. Those decisions are at the heart of what experience in software engineering is.</p>
<h2 id="static-types">Static types</h2>
<p>Static typing is great. Early on in a codebase in Python back at Aiden.ai, we made the decision of going for static typing using myopia as much as we could. So instead of writing something like</p>
<pre><code><span>def </span><span>sum_one</span><span>(</span><span>x</span><span>):
  </span><span>return </span><span>x+</span><span>1
</span></code></pre>
<p>We would rather much write</p>
<pre><code><span>def </span><span>sum_one</span><span>(</span><span>x</span><span>:int)-&gt;int:
  </span><span>return </span><span>x+</span><span>1
</span></code></pre>
<p>Or even further, in some cases we would use <em>newtypes</em> to make these type annotations more meaningful, dataclasses to bundle data together, as well as exhaustive enumerations to ensure that all variants of an enum get handled, for example:</p>
<pre><code><span>class </span><span>Operation</span><span>(</span><span>Enum</span><span>):
  </span><span>Multiply="</span><span>Multiply</span><span>"
  Add="</span><span>Add</span><span>"
Value = Union[int,float]
</span><span>def </span><span>assert_never</span><span>(</span><span>x</span><span>: NoReturn) -&gt; NoReturn:
    </span><span>raise </span><span>AssertionError</span><span>(</span><span>f</span><span>"</span><span>Invalid value: </span><span>{x</span><span>!r</span><span>}")
</span><span>def </span><span>do_the_op</span><span>(</span><span>a</span><span>:Value,</span><span>b</span><span>: Value, </span><span>op</span><span>:Operation) -&gt; Value:
  </span><span>if </span><span>op is Operation.Multiply:
    </span><span>return </span><span>a*b
  </span><span>else if </span><span>op is Operation.Add:
    </span><span>return </span><span>a+b
  </span><span>else</span><span>:
    </span><span>assert_never</span><span>(op)   
  
</span></code></pre>
<p>So if we ever say remove an operation or add a new one, mypy will force us to handle it. This is enforced dynamically but most importantly also statically so the code won't pass tests if there is a missing variant.</p>
<p>All these typing (Plus a custom pandas typechecker I wrote, but that's another story) made it relatively easy to refactor, and add new features when we needed to do so. It would have been a huge pain to fly blind without the types. Python has a tendency to blow up in your face when you least expect it. Starting with types from day 1 is something I don't regret having gone for, it didn't make the coding any slower and saved a lot of time (Or so we imagine!).</p>
<p>There seems to be a trend now towards types everywhere. Javascript died (for any serious developer) to let Typescript rise and Ruby, while still around with the Sorbet type checker, got Crystal.</p>
<p>As a <a href="https://en.wikiquote.org/wiki/Theodore_Kaczynski#:%7E:text=Consistent%20failure%20to%20attain%20goals,low%20self%2Desteem%20or%20depression.&amp;text=text%20on%20wikisource-,The%20Industrial%20Revolution%20and%20its%20consequences%20have,disaster%20for%20the%20human%20race.&amp;text=The%20industrial%2Dtechnological%20system%20may%20survive%20or%20it%20may%20break%20down.">wise man</a> once said, <em>Python and its consequences have been a disaster for the human race</em>. Python has a tendency to blow up in your face, even with all the typing. The typechecker may be happy but it doesn't guarantee that if it thinks something is type T it's actually so, maybe what you thought was a number is actually a string and because of duck typing it can take a few function calls for the error to manifest itself.</p>
<h2 id="yolo-programming-vs-chill-programming">YOLO programming vs chill programming</h2>
<p>I believe there is a tradeoff between writing a lot of code and writing correct code. In a day you could write X lines of code or you could write X/2. Two days of programmer B will produce the same as one day of programmer A but probably the latter will have introduced fewer bugs. You can write more or less tests, you can be more or less sure that something you just wrote is actually correct.</p>
<p>As you can expect from the number of typos here, I'm more of a YOLO programmer than a chill programmer. I'm the guy that was once pushing to prod from a one-handed GitHub hot fix from my phone as I was having dinner in a hotel in Tokyo (That one did work!).</p>
<p>YOLO programming when the programming language …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/programming">https://nintil.com/programming</a></em></p>]]>
            </description>
            <link>https://nintil.com/programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956644</guid>
            <pubDate>Fri, 29 Jan 2021 12:42:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt browser: mouseless copy/paste]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25956152">thread link</a>) | @jmercouris
<br/>
January 29, 2021 | https://nyxt.atlas.engineer/article/visual-mode.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/visual-mode.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Tested with Nyxt 2 Pre-release 6.</p><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="By John Mercouris">
  <title>visual-mode: mouse-free copy</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>


</header>
<p>Nyxt has a new visual-mode (mouseless text selection)!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-select.png"></p>

<p>Visual mode is a mouseless way of selecting <span>any</span> text on any page (with as few keystrokes as possible). Conceptually based on <code>vi</code>'s visual mode, Nyxt adapts it for the web.</p>

<p>The first step is to run the <code>visual-mode</code> command.</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-enable.png"></p>
<p>After doing so, you will be presented with hints to select a starting paragraph for your cursor.</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-paragraph.png"></p>
<p>Upon selecting a paragraph, a cursor will appear. You can move the cursor around and press <code>shift-space</code> to toggle the mark (start/stop highlighting).</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-cursor.png"></p>
<p>Importantly, you can use all your favorite keybindings (move by word, move to next line, beginning of line, etc.)!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-select.png"></p>
<p>Eureka! Just like that, we have selected text, no mouse required!</p>

<p>A very special thank you to <span data-cites="kssytsrk">@kssytsrk</span> for this wonderful addition to Nyxt!</p>
<p>Thanks for reading :-)</p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/visual-mode.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956152</guid>
            <pubDate>Fri, 29 Jan 2021 11:14:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turbo Pascal: A Great Choice for Programming Under CP/M (2013)]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25956128">thread link</a>) | @elvis70
<br/>
January 29, 2021 | https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>CP/M was blessed with many programming languages, each with their own strengths and weaknesses.  I think that Turbo Pascal stands out from these and I'm not alone.  When Turbo Pascal was released in 1983 by Borland, as their first software development application, it was quickly adopted by schools, universities, hobbyists and professional software developers.  Turbo Pascal combined ease of use, power, speed and a great manual all for the really low price of $49.95.</p>
<h2>Why Use Turbo Pascal Under CP/M?</h2>
<p>With TP you get an Integrated Development Environment (IDE), so that you can edit, compile and run all from the same application.  Since the IDE is only 34Kb there is plenty of space left on a disk for your source code and compiled programs.  This is particularly handy for single disk machines.  The editor is very functional and uses a subset of the Wordstar key combinations.</p>
<p>Pascal was designed to be easy to compile and because TP uses a single pass compiler, compilation speed is incredibly quick.  The downside of the compilation speed is that the code is quite a literal translation without much optimization.  However, for many applications this won't be much of an issue compared to the increased programmer productivity.</p>
<p>If you need parts of your program to run faster, you can always embed inline machine code into functions/procedures or access functions in external binaries.  The latter option allows you to create libraries in assembly language and use a jump table to access individual functions with the <code>external</code> keyword.</p>
<p>In 1986 Borland released Turbo Pascal 3.0 which added support for <em>overlays</em>.  The running code could now be swapped in and out from disk as needed.  With careful planning, you could escape the normal 64Kb limit and only be constrained by the capacity of the disk you are running the application from.</p>
<p>The standard library offers a good range of functions and TP keeps quite close to Standard Pascal as defined by Jensen &amp; Wirth in their '<a href="http://books.google.co.uk/books?id=xXSZbSLFTM8C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false">User Manual and Report</a>'.  As with all Pascal implementations, there are problems porting programs between implementations.  However, if you aren't using any of the operating system specific calls, then you can easily port to the MS-DOS and CP/M-86 versions.  My only gripe is that TP doesn't support procedures and functions passed as parameters.</p>
<p>Finally, Borland included a highly readable and very complete <a href="http://bitsavers.trailing-edge.com/pdf/borland/turbo_pascal/Turbo_Pascal_Version_3.0_Reference_Manual_1986.pdf">manual</a>.  It covered not just the IDE, language and libraries, but also detailed information on the memory layout and calling conventions from assembly language.  This meant that you could quickly get up and running with few additional resources.</p>
<h2>How to install</h2>
<p>First download <a href="http://www.retroarchive.org/cpm/lang/TP_301A.ZIP">Turbo Pascal 3.01a</a> for CP/M-80 and unzip the archive.</p>
<p>Put at least <code>TINST.*</code> and <code>TURBO.*</code> files onto a disk.  The real advantage of not copying all the files is seen if you only have a single drive.  The extra room will allow you to edit, compile and run your programs all from the same disk.  For instructions on how to create a virtual disk for z80pack look at: <a href="https://techtinkering.com/articles/emulating-a-cpm-system-with-z80pack/">Emulating a CP/M System With z80pack</a>.</p>
<p>Boot up your CP/M system, put in the disk with TP on it and change to this drive if necessary.  In my examples I am using <code>B:</code></p>
<p>Run the <code>TINST</code> program to set up the screen:</p>
<pre><code>B&gt; tinst
</code></pre>
<p>Press <code>S</code> for <em>Screen Installation</em> and select the appropriate terminal for your set up.  I'm using z80pack, so I select ANSI.  You probably don't want to alter this definition so say No to altering it.  Then enter the speed in Mhz of your machine.  If a suitable terminal isn't listed consult the TP manual for advice.</p>
<p>If you want to configure additional editor commands, you can do this via the <em>Command Installation</em> option.  At the very least, if you have them, you'll probably want to configure the page-up, page-down keys as well as the cursor keys to represent character-left, character-right, line-up and line-down.  If not press <code>Q</code> to quit.</p>
<h2>Usage</h2>
<p>To start the IDE run:</p>
<pre><code>B&gt; turbo
</code></pre>
<p>You should now be looking at the Turbo Pascal splash screen, showing the version, copyright message and which terminal is configured.  At the bottom you are asked whether to 'Include error messages'.  For the moment press <code>Y</code>.</p>
<p>Now you will be presented with the main screen.  You have a number of commands on this screen, which are accessed by a single letter.</p>
<p><img src="https://techtinkering.com/img/articles/turbo_pascal_cpm_main.png"></p><p>To work with a pascal source file, first press <code>W</code> and then enter a filename.  This is the file that the editor will open and it is also the file that the compiler will compile if you haven't selected a main file.</p>
<p>To edit the work file, press <code>E</code>.  The editor uses Wordstar key combinations which you can read more about in the manual.  For now the following keys will be useful to know:</p>
<table>
  <tbody><tr><th>Key command</th><th>Action</th></tr>
  <tr><td>CTRL-s</td><td>Character Left</td></tr>
  <tr><td>CTRL-d</td><td>Character Right</td></tr>
  <tr><td>CTRL-e</td><td>Character Up</td></tr>
  <tr><td>CTRL-x</td><td>Character Down</td></tr>
  <tr><td>CTRL-k s</td><td>Save Document</td></tr>
  <tr><td>CTRL-k d</td><td>Quit</td></tr>
</tbody></table>
<p>You can also use any keys that you configured above with the <em>Command Installation</em> option in <code>tinst</code>.</p>
<p>Files are edited in memory so to save them to disk you press <code>S</code> from the main menu.</p>
<p>To compile and run the work file, or main file if selected, press <code>R</code>.  Depending on what is set in the compiler options, this will either compile to a <code>com</code> file or will compile to memory.</p>
<h3>Hello, world!</h3>
<p>To try this with the traditional 'Hello, world!' program, set the work file to <code>hello.pas</code>, edit the file and enter the following, then quit the editor.</p>
<pre><code>program helloworld;
begin
  writeln('Hello, world!');
end.
</code></pre>
<p>Compile and run it by pressing <code>R</code> from the main menu.  You should see it compile and then say hello to the world.</p>
<h2>Video</h2>
<p>The following video shows the creation of a FizzBuzz program using Turbo Pascal and allows us to see just how quick and easy it is.</p>
<p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/acYu0sL9Ol0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<p>The source code for <code>fizzbuzz.pas</code> used in the video is as follows:</p>
<pre><code>program fizzbuzz(output);
var
  i: integer;
begin
  for i := 1 to 100 do
  begin
    if i mod 15 = 0 then
      write('FizzBuzz ')
    else if i mod 3 = 0 then
      write('Fizz ')
    else if i mod 5 = 0 then
      write('Buzz ')
    else
      write(i, ' ');
  end
end.
</code></pre>

<p>Get the <a href="http://bitsavers.trailing-edge.com/pdf/borland/turbo_pascal/Turbo_Pascal_Version_3.0_Reference_Manual_1986.pdf">Turbo Pascal 3.0 Manual</a> for CP/M-80, CP/M-86 and PC-DOS/MS-DOS from <a href="http://bitsavers.org/">bitsavers.org</a>.  It is a wonderfully well-laid out manual and you should have no problems using this to learn and get the most out of Turbo Pascal.  You may also want to take a look at a copy of the old Borland musuem page: <a href="http://edn.embarcadero.com/article/20792">Antique Software: Turbo Pascal v3.02</a>.</p>
<p>You are now ready to use Turbo Pascal to write and compile applications like it was 1986.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956128</guid>
            <pubDate>Fri, 29 Jan 2021 11:06:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 3D maze game for the ZX Spectrum]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25955914">thread link</a>) | @todsacerdoti
<br/>
January 29, 2021 | https://jamesmead.org/blog/2021-01-23-youtube-video-of-my-3d-maze-game-for-the-zx-spectrum | <a href="https://web.archive.org/web/*/https://jamesmead.org/blog/2021-01-23-youtube-video-of-my-3d-maze-game-for-the-zx-spectrum">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
      
        <h2>James O'Grady plays, reviews and mods (!) a game I wrote in Z80 machine code in 1984</h2>
    </header>

    <section>
      <p><img src="https://jamesmead.org/images/graphic-adventures-for-the-spectrum-48k.jpg" alt="Book cover for 'Graphic Adventures for the Spectrum 48K'"></p>

<p>I recently stumbled across <a href="#the-youtube-video">a quirky Youtube video</a> which piqued my interest. In the video <a href="https://twitter.com/JAMOGRAD">James O'Grady</a> demonstrated a 3D maze game. He'd typed in the code for the game from a familiar-sounding book called <a href="https://www.amazon.co.uk/dp/0744700132">Graphic Adventures for the Spectrum 48K</a>.</p>

<p>The nominal author of this book, Richard Hurley, was one of my teachers and he included programs written by me and a number of my friends. The 3D maze game was one I wrote in about 1984 when I was 16. In the video James goes on to critique the game, to explore some ways to improve it, and to read some reviews of the book from magazines of the time.</p>

<p>In my early teens I played a lot of games on the ZX81 and then the Spectrum, but as I got older I became bored of playing the games and more interested in writing them. I learnt a lot about programming games from typing in code from magazines and books.</p>

<p>The first games I developed were written entirely in <a href="https://worldofspectrum.org/ZXBasicManual/">Sinclair BASIC</a>, e.g. <a href="https://github.com/floehopper/sub-hunt">Sub Hunt</a> which was published in <a href="https://spectrumcomputing.co.uk/index.php?cat=96&amp;id=2000461">an earlier book</a>, but I quickly realised I would need to use machine code to get the performance I wanted. Initially I wrote small bits of machine code to speed up critical bits of the games. However, the 3D Maze game in the video was the first game I wrote pretty much entirely in Z80 machine code using the excellent <a href="https://en.wikipedia.org/wiki/Zeus_Assembler">Zeus assembler</a> and with my trusty copy of <a href="https://archive.org/details/CompleteSpectrumROMDisassemblyThe">The Complete Spectrum ROM Disassembly</a>. It was closely based on the "3D Monster Maze" game by J.K. Greye Software.</p>

<h3 id="the-zx81-original">The ZX81 original</h3>

<p>
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/nKvd0zPfBE4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<blockquote>
  <p>
    Most importantly, from the point of view of video game history, the ZX81 was the computer which hosted the world's first ever 3D game on a home computer - JK Greye's 3D Monster Maze. A simple labyrinth is generated, and the player has to find their way out, all the while being stalked by a Tyrannosaurus Rex. The whole experience was rendered in what is now referred to as 'first person' view - ie, you see what you would see out of the eyes of the character in the maze, as pictured in the ZX81's rather blocky but still effective graphics. A quick play of this game on an emulator is recommended to all fans of Doom, Quake, Unreal, Half Life and all the other FPSs which are now so popular, as it really is the literal grandaddy of them all. It is difficult now to describe the impact this game had on a public who had quite literally never seen anything like it.
    –
    <cite>
      <a href="https://h2g2.com/edited_entry/A821648">The Hitchhiker's Guide to the Galaxy (Earth Edition): The Wonderful Computers of Clive Sinclair</a>
    </cite>
  </p>
</blockquote>

<h3 id="my-version">My version</h3>

<p>One slight disappointment was that unlike in "3D Monster Maze" there was no "monster" in my version of the game or at least not in the version James was playing. I know that I did eventually add a Tyrannosaurus Rex to the game, but I vaguely remember having to rush for a publication deadline, so the monster might've have missed the cut! If I recall correctly, a friend with better artistic skills than me drew a T Rex in a series of "frames" walking towards the observer. I then traced the drawings onto graph paper and converted them into <a href="https://en.wikipedia.org/wiki/ZX_Spectrum_character_set">user-defined graphic characters</a>. I do half wonder whether these might be the mystery bytes which James refers to at one point in his video. Otherwise I believe the program uses calls to the ROM, e.g. <a href="https://speccy.xyz/rom/asm/24b7">this line-drawing subroutine</a>, to draw the walls of the maze.</p>

<p>
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/Q656CqMIXLY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h3 id="the-youtube-video">The Youtube video</h3>

<p>James must've been incredibly patient to type in all the raw numbers for the machine code with only very rudimentary checksums. And, given that the game is written entirely in machine code and the assembler source code is lost in the mists of time, I was impressed that James managed to successfully modify the game in a couple of different ways using a load of judicious <a href="https://en.wikipedia.org/wiki/PEEK_and_POKE"><code>PEEK</code>s and <code>POKE</code>s</a> and apparently without the use of a disassembler. In particular he's written a nice maze editor program which runs on the Spectrum and allows you to design your own maze. I was quite amused to learn that the maze had to be square - I can't imagine it would've been much harder for me to have allowed rectangular ones!</p>

<p>James is very fair in his criticisms of the game - his main observation is that it's not very interesting to play, but it is very fast compared to other similar games. I also enjoyed reading the reviews of the book he'd found in a couple of magazines of the time. I had a lovely exchange with him in <a href="https://www.youtube.com/watch?v=Q656CqMIXLY&amp;lc=UgzsXaL19aLWF7T3qCp4AaABAg">the Youtube comments</a> and he <a href="https://twitter.com/JAMOGRAD/status/1351920870621589506">changed the title</a> of the Youtube video to include my name which was a nice gesture. Anyway, this was a brilliant trip down memory lane for me and reminded me of my programming roots!</p>

<h3 id="playing-the-game">Playing the game</h3>

<p>If you feel as if you want the full "type it in" experience, the Portuguese (!) version of the book is available for <a href="https://archive.org/download/World_of_Spectrum_June_2017_Mirror/World%20of%20Spectrum%20June%202017%20Mirror.zip/World%20of%20Spectrum%20June%202017%20Mirror/sinclair/books/g/GraphicAdventuresForTheSpectrum48K(AventurasGraficasParaOSpectrum48K)(TemposLivres).pdf">download</a> from <a href="https://spectrumcomputing.co.uk/index.php?cat=96&amp;id=2000168">Spectrum Computing</a> and you can find the game in "Labirinto" (chapter 4, page 105). Otherwise, <a href="https://github.com/floehopper/3d-maze">this GitHub repo</a> includes a set of <a href="https://worldofspectrum.org/faq/reference/formats.htm#TAP">TAP format</a> files which might work in a Spectrum emulator, although I haven't yet had a chance to try them myself.</p>


    </section>

    
  </article></div>]]>
            </description>
            <link>https://jamesmead.org/blog/2021-01-23-youtube-video-of-my-3d-maze-game-for-the-zx-spectrum</link>
            <guid isPermaLink="false">hacker-news-small-sites-25955914</guid>
            <pubDate>Fri, 29 Jan 2021 10:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantquake: 2020 and the Revenge Against the Nerds]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25953890">thread link</a>) | @apsec112
<br/>
January 28, 2021 | https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/ | <a href="https://web.archive.org/web/*/https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" alt="fbpx" src="https://www.facebook.com/tr?id=818746408901300&amp;ev=PageView&amp;noscript=1">

<!-- End Facebook Pixel Code -->
<meta name="generator" content="Powered by Slider Revolution 5.4.8.3 - responsive, Mobile-Friendly Slider Plugin for WordPress with comfortable drag and drop interface.">

		
				
		

		
	<!-- Global site tag (gtag.js) - Google Analytics -->



<!-- Hotjar Tracking Code for https://rhsfinancial.com/ -->





	<!--<div class="modal fade calendly_wrap" id="myModal">
		<div class="modal-dialog modal-lg modal-dialog-centered" role="document">
            <div class="modal-content">
                <div class="modal-body">
                    <div class="calendly-inline-widget" style="min-width: 320px; height: 500px;" data-url="https://calendly.com/rhs15minutes/consultation"></div>
					<script type="text/javascript" src="https://assets.calendly.com/assets/external/widget.js"></script>
                </div>
            </div>
		</div>
	</div>-->
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				
				
			</header>
						
			
		
				
			
			

									<main id="main">
				<div>
			
<section id="content">
			
	
					<article id="post-4844">
						
														
						
																									<div>
				
<p><span>2020, the most fascinating and boring year of my life, is over, and despite one of the most violent market crashes in history and the sharpest recession of all time, US equity investors clocked in another good year on the calendar. The S&amp;P 500 index finished the year up 18.4%; this despite being down by as much as 30% in March, making 2020 one of the wildest swinging markets in history.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/ccd34ab62ba3cdcc49abe8547f2cff73.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>But if you didn’t earn double digit returns last year you were in good company. The bull market was extremely concentrated in a narrow subset of stocks and most others floundered over the year. By my count, of the top 5,000 stocks trading on US exchanges (this includes over a thousand foreign stocks with US listings), only a little over half finished 2020 in positive territory and the median return was only 4.3%. If you didn’t have the good fortune to buy the few winners you were left behind, as happened with some of the industry’s best. Many of the world’s largest and previously most successful hedge funds and institutional money managers had a terrible 2020, including the top two: Ray Dalio’s Bridgewater Associates and Jim Simon’s Renaissance Technologies, each famous for their billionaire visionary founders, uniquely<span> <a href="https://www.bloomberg.com/news/articles/2019-11-12/the-unsolved-mystery-of-the-medallion-fund-s-success">secretive</a>/<a href="https://www.youtube.com/watch?v=HXbsVbFAczg">creepy</a></span> company culture, and astounding market-beating performance over decades, each suffered <em>negative double-digit</em> returns in their main funds in 2020. Similarly, some of the industry’s most highly regarded names such as <span><a href="https://www.institutionalinvestor.com/article/b1p9nxxx1d47xk/AQR-to-Liquidate-Some-Funds-After-Persistent-Outflows">AQR</a></span>, <a href="https://www.bloomberg.com/news/articles/2020-11-17/renaissance-two-sigma-see-losses-as-quant-giants-navigate-chaos"><span>Two Sigma</span></a>, and <span><a href="https://www.morningstar.com/articles/1012650/dfa-is-paying-the-price-for-its-conviction">Dimensional Fund Advisors</a></span> all suffered massive investor redemptions in the face of substantial underperformance in 2020.</span></p>
<p><span>All these fund managers pursue a variety of different strategies in a variety of different markets, but they all have one thing in common: they’re quants. They take a data-driven approach to investing, using mathematical models based typically on decades of market returns to execute their strategy, often employing teams of Ph.D mathematicians, computer scientists, and economists to crunch the numbers. They generally pay little attention to the “human interest” elements of investing like the executive bio or squishy concepts like “product market fit” or five year strategic plans. There are a lot of different ways to be a quant, but if you are one, or invested with one in 2020, you probably had a bad year. 2020 was the year of the swashbuckling stock-picker. As Bloomberg declared in a year-end article, <span><a href="https://www.bloomberg.com/news/articles/2020-12-30/human-run-hedge-funds-trounce-quants-in-year-defined-by-pandemic">Human-Run Hedge Funds Trounce Quants in Covid Year</a></span>. 2020 was the revenge&nbsp;<em>against</em> the nerds.</span></p>
<p><span>So what happened? Leo Tolstoy famously wrote, “All happy families are alike; each unhappy family is unhappy in its own way.” So it was with investing in 2020, there were many different investing strategies that went unhappily in 2020, and all the strategies that went happily looked pretty much the same. Let’s look at the unhappy families first and then return to the one thing that went well in 2020.</span></p>
<h3>Diversification</h3>
<p>2020 saw a repeat of something we’ve witnessed a few times in the last decade, not only did US stocks have an especially good year, they did substantially better than pretty much every other market. Investors who diversified across multiple asset classes therefore had much weaker returns.</p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020.png"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1024x619.png" alt="" width="1024" height="619" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-200x121.png 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-300x181.png 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-400x242.png 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-600x363.png 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-768x464.png 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-800x484.png 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1024x619.png 1024w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1200x726.png 1200w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020.png 1470w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p>
<p><span>Just about the only major asset that beat the S&amp;P 500 last year was gold. The shiny metal held its weight during the crisis in March and powered through the rest of the year. Emerging market stocks also put in a solid year, virtually tied with the US market, despite suffering an even harder crash in March. Most other major assets, however, had much more modest returns, including the stock markets of most other rich, industrialized nations. Investors diversified across these major markets still likely had reasonably positive returns, but were a far cry from the meteoric rise of the S&amp;P 500.</span></p>
<p><span>Of course, how investors allocated both across and within these asset classes was of tantamount importance to their outcomes in 2020, and generally these outcomes frustrated quants at every turn. Whether picking stocks within a market or allocating across asset classes, quants often rely on measures of valuation, volatility, or momentum to guide their process, based on the historical success of these metrics in predicting returns, and in nearly every case following the numbers led investors astray in 2020, starting with perhaps the most time-tested of financial strategies, value investing.</span></p>
<h3><span>Value and Fundamentals</span></h3>
<p><span>For investors like yours truly who believe markets ultimately have to have some <span><a href="https://rhsfinancial.com/2020/08/11/does-reality-matter-stock-market-2020/">relation to reality</a></span>, the following joke tweet from December is a little too on the nose.</span></p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg" alt="" width="960" height="395" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-200x82.jpg 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-300x123.jpg 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-400x165.jpg 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-600x247.jpg 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-768x316.jpg 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-800x329.jpg 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg 960w" sizes="(max-width: 960px) 100vw, 960px"></a></p>
<p><span>Value investors ask the same seemingly reasonable question of investments we all ask when we’re considering buying a good or service: is the price I have to pay a good deal compared to the quality I’m getting? In practice this generally means value investors seek to buy assets whose prices are low relative to their cashflows or other economic fundamentals. Value investing has an intellectual pedigree going back to at least the 1920s with the classic writings of Graham and Dodd and is perhaps most famous for their most successful student, Warren Buffett (who also didn’t do so well last year). Value investing has been out of favor for several years now, especially in the US market, something I documented extensively in my <span><a href="https://rhsfinancial.com/2020/08/11/does-reality-matter-stock-market-2020/">two part</a> <a href="https://rhsfinancial.com/2020/08/19/does-reality-matter-part2/">series</a></span> last year on market valuations.</span></p>
<p><span>Last year was a miserable one for value investors. Within the US market, value stocks lagged the market in the first couple months, fell further during the crash, and recovered slower than the rest of the market. Though they rallied harder in the last two months of the year, value stock both large and small finished the year finished the year just barely above zero, as judged by the commonly followed Russell 1000 Value (large stocks) and Russell 2000 Value (small stocks) indexes.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,id:^RLVTR,include:true,,id:^RUJTR,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/273b52a1901248cfb2556266430d94d6.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>Applying the value effect around the world gave even worse results. Choosing between stock markets, the US started the year the most expensive market in the world, and those in Europe were among the cheapest. But as we saw, the US market became more expensive still, and European stock investors barely ended the year in positive territory. Value stocks within foreign markets similarly failed to keep up with their broader market aggregates. One index of value stocks around the world, the MSCI ACWI Value Index, finished the year up a mere 0.42%. Taking an even more expansive view of valuation and applying it across global assets, buying those stocks, bonds, commodities, and currencies measured as cheap and selling those measured as expensive would have lost you about 12% in 2020 (through November) according to <span><a href="https://www.aqr.com/Insights/Datasets/Value-and-Momentum-Everywhere-Factors-Monthly">AQR’s methodology</a></span>.</span></p>
<p><span>Skeptics of value investing often point out that value stocks are usually cheap for a reason: they’re junk. Indeed, if you simply sort the market based on a simple valuation metric like price to book ratio you’ll often find that the most undervalued stocks are in declining industries, have weak balance sheets and margins, and are projected to lose market share. Value investors often try to avoid “value traps” like this by augmenting their value factors with metrics to score some measure of “quality”, looking at profitability measures like return on equity, for example. Adding such quality filters would have only made things worse in 2020. Among the cheapest stocks in the market, the most profitable among them did the worst last year.</span></p>
<p><span>Professor Ken French keeps an invaluable <span><a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">online database</a></span> to quants that records the track records to different portfolios of stocks sorted on a variety of metrics. Looking at a double-sorted portfolio of the stocks that are in the lowest quintile of valuation and the highest quintile of profitability, here’s how such a portfolio did last year (through November) compared to the S&amp;P 500.</span></p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value.png"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1024x546.png" alt="" width="1024" height="546" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-200x107.png 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-300x160.png 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-400x213.png 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-600x320.png 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-768x409.png 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-800x426.png 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1024x546.png 1024w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1200x639.png 1200w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value.png 1490w" sizes="(max-width: 1024px) 100vw, 1024px"></a><span>The most profitable, cheapest stocks in the US lost more than half of their value in the crash last year, before recovering to end up down “only” about 20% last year, a staggering 33.8% behind the S&amp;P 500.</span></p>
<p><span>Take a moment to consider how counterintuitive this ought to seem. I think most people, even without much financial savvy, would consider the strategy of “buy highly profitable companies at attractive valuations” to seem like a fairly reasonable one, the sort of things that might actually deliver superior results over the long run, and indeed if we look at the long run data it has, as we’ll see further down the page. You might even suspect that such a prudent strategy might shine especially during a period of great economic tumult and uncertainty, and indeed it often has historically. But that is absolutely&nbsp;<em>not</em> what happened during the chaos of 2020. And that wasn’t the only curveball 2020 threw quants either.</span></p>
<h3><span>Low Volatility/Risk Parity</span></h3>
<p><span>After value, low volatility strategies are some of the most commonly used quant approaches of the last decade. Research going back to the 70s shows that those stocks whose prices are relatively more stable tend to roughly keep up with the rest of the market or nearly so when times are good, but lose far less value during panics and bear markets. Thus, over the long run they’ve done about as good or better as the rest of the market with a lot less risk. That is… decidedly not what happened last year. Within the US market, two of the most popular quant funds of recent years have been the iShares US Minimum Volatility ETF and the Invesco S&amp;P 500 Low Volatility ETF, two ETFs that use a quantitative approach to pick the least volatile stocks within the US market. With tens of billions of dollars between them, here’s how these two flavors of low volatility stock investing did last year.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,id:USMV,include:true,,id:SPLV,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/e209c9c736d2bc0d5a747dbb1304a1a5.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>Yikes. Low volatility …</span></p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/">https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/</a></em></p>]]>
            </description>
            <link>https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25953890</guid>
            <pubDate>Fri, 29 Jan 2021 04:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1938 vs. 1940 (2018)]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25952042">thread link</a>) | @diodorus
<br/>
January 28, 2021 | https://pecaquet.com/2018/10/08/1938-vs-1940/ | <a href="https://web.archive.org/web/*/https://pecaquet.com/2018/10/08/1938-vs-1940/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>A key defence of appeasement, and especially the 1938 Munich Agreement, is that it gave Britain and France time to rearm against the Nazi threat. It is actually an ex-post argument: Chamberlain himself sold his policies as a bid for peace, not time. He launched no rearmament effort until March 1939, when Hitler reneged on Munich. The idea has nevertheless achieved a surprising degree of acceptance, especially in Britain. It was worthwhile sacrificing Czechoslovakia in 1938 the better to be able to face Germany militarily in 1939/40, so it goes. Except it wasn’t.</p>
<p>In this post I set out why the Entente partners actually <em>lost&nbsp;</em>time at Munich in as few words as possible. The long argument can be found in <em>The Bell of Treason</em>or in my <em>International History Review&nbsp;</em>article on the subject. It is touched upon in the rest of the Munich literature, of course, though not with the full data.</p>
<p>The first reason Britain and France were worse off in 1939 than 1938 is that in 1939 they got a far weaker set of allies. In September 1938, they could count on Czechoslovakia and the Soviet Union. In September 1939, they only had Poland. Czechoslovakia had fully mobilised, possessed a well-equipped army, and could base its defence on a long fortification barrier. Poland was surprised in the middle of mobilization, its army was ill equipped, and – thanks to the Molotov-Ribbentrop pact of August 1939 – it was invaded from both sides. The longer explanation, again, is in my book.</p>
<p><img data-attachment-id="183" data-permalink="https://pecaquet.com/tank-factory/" data-orig-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png" data-orig-size="636,474" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tank factory" data-image-description="" data-medium-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=300" data-large-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=636" src="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=1100" alt="tank factory" srcset="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png 636w, https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=150 150w, https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=300 300w" sizes="(max-width: 636px) 100vw, 636px"></p>
<p><em>Nuremberg Panzer factory (Ullstein Bild – Photo12 / Collection Bernard Crochet)</em></p>
<p>The key data is military. France, and with it Britain, lost time because the one to one-and-a-half years between 1938 and 1939/40 helped Germany far more than it helped them. This was partly because the Germans were able to seized the large Czechoslovak stockpiles and factories. A third of the tanks that pierced the French front in May 1940, causing the French collapse, were built in Czechoslovakia. Germany faced dire raw-material and production bottlenecks in 1938, which were relieved through time gained, the Czech annexation, and the Molotov-Ribbentrop pact. Meanwhile, German rearmament proper had only begun in 1935 when Hitler had reintroduced conscription. By 1938, Germany had thus been forming new army divisions for three years. By 1939 this was four years and by 1940 almost five: half as long again as by 1938.</p>
<p>I set out the relative army numbers, in simplified form, in the table below. France did not need to re-arm because it was already armed at or close to its full potential. Its accretion in military strength between 1938 and 1939 was limited. Germany’s accrued power was considerable. The difference became even more marked by 1940. This does not count the relative value of the Czechoslovak or Polish armies nor any Soviet contribution. Britain’s expeditionary force only increased from two to five divisions in the interval, so it can be ignored.</p>
<table>
<tbody>
<tr>
<td>
<p>Divisions</p>
</td>
<td>France 1938</td>
<td>Germany 1938</td>
<td></td>
<td>France 1939</td>
<td>
<p>Germany 1939</p>
</td>
</tr>
<tr>
<td>Infantry – regular</td>
<td>
<p>35</p>
</td>
<td>36</td>
<td></td>
<td>37</td>
<td>
<p>54</p>
</td>
</tr>
<tr>
<td>Infantry – reserve</td>
<td>
<p>21</p>
</td>
<td>8</td>
<td></td>
<td>18</td>
<td>
<p>35</p>
</td>
</tr>
<tr>
<td>Motorized / armoured</td>
<td>
<p>9</p>
</td>
<td>13</td>
<td></td>
<td>10</td>
<td>
<p>13</p>
</td>
</tr>
<tr>
<td>Fortress</td>
<td>
<p>15</p>
</td>
<td>12</td>
<td></td>
<td>21</td>
<td>
<p>12</p>
</td>
</tr>
<tr>
<td>Cavalry</td>
<td>
<p>5</p>
</td>
<td>1</td>
<td></td>
<td>5</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Total</td>
<td>
<p>85</p>
</td>
<td>70</td>
<td></td>
<td>91</td>
<td>
<p>115</p>
</td>
</tr>
</tbody>
</table>
<p>After the war started, France was able to put together another twenty divisions, while Germany assembled another forty. So France’s position changed from an advantage of fifteen divisions in 1938, to a disadvantage of twenty-four by 1939, which became forty-five in May 1940. This is a quantitative, not a qualitative overview, but two additional factors are worth mentioning. First, the 1938 German tanks were all Panzer I and II models, fitted with inferior armour and firepower. The mark I Panzer did not even possess a canon, just a machinegun. The tanks that pierced the French front in 1940 were mark III and IV – still at the prototype stage in 1938. Second, the German army was only able to push through Belgium, in 1940, by taking its border fortresses with glider and parachute units. In 1938, these elite units were still being assembled.</p>
<p>Germany lacked the firepower to defeat France in 1938. Indeed, it faced defeat at the hands of a stronger coalition, possibly in short order. It also follows, finally, that it was not in a position to launch an attack on Britain. This goes to the core of the theory that Chamberlain bought time by helping muster the country’s air defences. Actually in 1938 Britain was already producing Spitfires and Hurricanes, and output rhythms were not sped up until the spring of 1939 – and even then still less than to a wartime pace – so that the time gained was close to nil. But the key is that the <em>Luftwaffe</em>, even in 1940, could only launch an assault on Britain from bases in Belgium and northern France. It was not possible to do that from Germany. So until France fell, there could be no Battle of Britain. And if Germany lacked the land forces to defeat France in 1938 or 39…</p>
<p>The Battle of Britain was this incredibly romantic moment, immortalized by Churchill. Seen more coldly, though, it was only one of many turning points in WWII, the first among which were the falls of Poland, then France. The Battle of Britain was not even “the end of the beginning” (that was reserved to El Alamein). I want to close this post with Churchill’s own words, making exactly the point I make in the preceding paragraph.</p>
<p>“The German armies were not capable of defeating the French in 1938 or 1939. The vast tank production with which they broke the French front did not come into existence until 1940, and, in the face of French superiority in the West and an unconquered Poland in the East, they could certainly not have concentrated the whole of their air-power against England as they were able to do when France had been forced to surrender. This takes no account either of the attitude of Russia or of whatever resistance Czechoslovakia might have made. I have thought it right to set out the figures of relative air-power in the period concerned, but they do not in any way alter the conclusions which I have recorded. For all the above reasons, the year’s breathing-space said to be “gained” by Munich left Britain and France in a much worse position compared with Hitler’s Germany than they had been at the Munich crisis.”</p>
<p>(Winston S. Churchill, <em>The Second World War&nbsp;</em>(6 vols, Boston, 1948-53), vol. I, p. 304).</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2018-10-08T07:13:06+00:00">October 8, 2018</time><time datetime="2018-10-08T17:35:38+00:00">October 8, 2018</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://pecaquet.com/2018/10/08/1938-vs-1940/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25952042</guid>
            <pubDate>Fri, 29 Jan 2021 00:53:50 GMT</pubDate>
        </item>
    </channel>
</rss>
