<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Dec 2020 01:31:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Dec 2020 01:31:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Impact of Apple Silicon Macs on Broadway]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25534863">thread link</a>) | @da02
<br/>
December 24, 2020 | https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/ | <a href="https://web.archive.org/web/*/https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"><main><article role="article"><div><p>In a previous life, I was an electronic music designer working on Broadway shows in New York City. Broadway shows look glamorous and expensive on the outside, but it’s often quite the opposite on the inside –&nbsp;at least for the music department. One of the toughest parts of my job as an electronic music designer was to find the best performance-to-cost ratio for computer rigs powering keyboards, guitars, playback tracks, and more.</p><p>Over the past decade, Broadway has replaced large sections of traditional orchestras with synthesizers, playback systems, and electronic drum pads. I’m not in support of that, but that’s a story for another day. The point here is that Broadway’s reliance on computer-driven rigs has increased, while the typical budget required to build high-end stable rigs hasn’t increased at the same rate.</p><p>Some shows I’ve worked at set aside a $10,000-$12,000 budget for two keyboard rigs. That sounds like a lot of money at first, but it’s not. For live shows, it’s usually best to have a 1:1 backup in case the main rig fails. That fact alone means you have to design a rig that fits within 50% of the proposed budget. Furthermore, a high-quality keyboard controller alone is $1,500-2,000 –&nbsp;so that means there’s $3,000 left for a computer and everything else.</p><p>Due to budget constraints, many shows end up using Mac minis. Historically speaking, the Mac mini’s computing power has been a bottleneck for electronic music designers on Broadway. In a perfect world, we’d all like to use the best-sounding sample libraries for our work, but that was never feasible with the Mac mini. Thus, the compromise was always to reduce sound quality to fit within the Mac mini’s compute constraints.</p><p>Apple Silicon changes everything for Broadway electronic music designers. The new M1 Mac mini is capable of running high-end sample libraries and virtual instruments in a stable manner, and it’s only going to get better with M2, M3, and M4-series chips in the future. The performance per dollar characteristics of Apple Silicon machines are going to have a huge impact on Broadway’s sound, and I’m very excited to see, or hear, what happens.</p></div></article></main></div></div>]]>
            </description>
            <link>https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25534863</guid>
            <pubDate>Fri, 25 Dec 2020 07:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fictional Videogame Stills]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25530307">thread link</a>) | @doener
<br/>
December 24, 2020 | https://www.suzannetreister.net/Ampages/Amenu.html | <a href="https://web.archive.org/web/*/https://www.suzannetreister.net/Ampages/Amenu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
      <td colspan="4"> 
        <p><span size="2" face="Verdana, Arial, Helvetica, sans-serif"><b><span size="1" color="#99CC33">Suzanne 
          Treister<br>
          </span></b><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33">1991-1992</span><span size="1" color="#99CC33"> 
          </span></span> </p>
        <p><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><i><strong>Fictional 
          Videogame Stills</strong></i> </span></p>
        <p><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33">In 
          the late 1980s I was making paintings about computer games. In January 1991 I bought an Amiga computer and made a series of fictional 
          videogame stills using Deluxe Paint II. I photographed them straight 
          from the screen as there was no other way to output them that I knew 
          of apart from through a very primitive daisy wheel printer where they appeared as washed out dots. <p>
          
          The effect of the photographs perfectly reproduced the highly 
          pixellated, raised needlepoint effect of the Amiga screen image. Conceptually 
          this means of presentation was also appropriate in that it made it seem 
          like I had gone into a videogame arcade and photographed the games there, 
          lending authenticity to the fiction.</p></span><span color="#99cc33" face="Verdana, Arial, Helvetica, sans-serif" size="1">The first seven works on this page form a series titled, 'Q. Would you recognise a Virtual Paradise?'</span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><p>
          
          Many of these works were shown in London at the Edward Totah Gallery in March 
        1992 (<a href="https://www.suzannetreister.net/Ampics/Installations/Totah-Installation1992/EdwardTotah_1992.html" target="_self">view installation</a>) and later that year</p></span><span color="#99cc33" face="Verdana, Arial, Helvetica, sans-serif" size="1"> at the Exeter Hotel in Adelaide, Australia.<br> 
        In 1995 the 'Q. Would you recognise a Virtual Paradise?' series was shown in London at the Royal Festival Hall in the exhibition<em> It's a Pleasure</em>, curated by Leah Kharibian.</span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><br>
        Recent venues: Somerset House, London, 2018 <a href="https://www.suzannetreister.net/Ampics/Installations/SomersetHouse2018/SomersetHouse2018.html" target="_self">view installation</a> ; Akron Art Museum, Ohio, USA 2019 and tour; Moderna Museet, Stockholm, Sweden, 2019/20 <a href="https://www.suzannetreister.net/InstallationV/Moderna-Museet_2019.html" target="_self">view installation</a><p>
          
          The original Amiga floppy disks which stored the image files are  corrupt, but the  photographic art works remain.</p></span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><p>
          
          For 
          more information <a href="https://www.suzannetreister.net/Ampages/Treister_Essay.pdf">download my essay</a> 
          from '<a href="http://www.intellectbooks.co.uk/ppbooks.php?isbn=9781841501420" target="_blank">Videogames 
            and Art</a>', Ed. Andy Clarke, Grethe Mitchell, Publ. Intellect Books, 
        UK 2007</p></span></p>
<p><span color="#996633" size="1" face="Verdana, Arial, Helvetica, sans-serif"> <a href="https://www.suzannetreister.net/Videography/Videogames_Video.html" target="_self">view video version</a><p>
            
          click 
  titles below to view enlargements of photo works</p></span></p></td>
    </div></div>]]>
            </description>
            <link>https://www.suzannetreister.net/Ampages/Amenu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25530307</guid>
            <pubDate>Thu, 24 Dec 2020 19:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GoDaddy employees told they were getting a holiday bonus in a phishing test]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 234 (<a href="https://news.ycombinator.com/item?id=25529584">thread link</a>) | @arkadiyt
<br/>
December 24, 2020 | https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/ | <a href="https://web.archive.org/web/*/https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<h2>Roughly 500 employees failed the test, which claimed they would receive a $650 bonus.</h2>



<p>“2020 has been a record year for GoDaddy, thanks to you!” the email read.</p>



<p>Sent by Happyholiday@Godaddy.com, tucked underneath a glittering banner of a snowflake and stamped with the words “GoDaddy Holiday Party,” the Dec. 14 email to hundreds of GoDaddy employees promised some welcome financial relief during an <a href="https://coppercourier.com/story/tens-of-millions-of-americans-face-economic-ruin-unless-congress-gets-its-sht-together/">otherwise stressful year</a>.</p>



<p>“Though we cannot celebrate together during our annual Holiday Party, we want to show our appreciation and share a $650 one-time Holiday bonus!” the email read. “To ensure that you receive your one-time bonus in time for the Holidays, please select your location and fill in the details by Friday, December 18th.”</p>



<p>But, two days later, the company sent another email.</p>



<p>“You’re getting this email because you failed our recent phishing test,” the company’s chief security officer Demetrius Comes<strong> </strong>wrote. “You will need to retake the Security Awareness Social Engineering training.”</p>



<figure><picture>
	<source media="(max-width: 320px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=284">
	<source media="(max-width: 768px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=676">
	<source media="(max-width: 1280px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=1400">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=1400" width="1400" height="9999" alt="" title="">
	
	
</picture></figure>



<figure>
		<picture>
	<source media="(max-width: 320px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=284">
	<source media="(max-width: 768px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=676">
	<source media="(max-width: 1280px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=1400">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=1400" width="1400" height="9999" alt="" title="">
	
	
</picture><span>A Dec. 14 email sent to hundreds of GoDaddy employees offered a holiday bonus to employees. It turned out to be a phishing test.</span><figcaption>Screenshots of the email were sent to The Copper Courier by multiple GoDaddy employees.</figcaption>
	</figure>



<p>Phishing tests are sent by companies to gauge their employees’ susceptibility to phishing attacks, where people outside the company will attempt to disguise themselves as trusted sources to gain access to sensitive information, like usernames and passwords.</p>



<p>The follow-up email from Comes said that roughly 500 GoDaddy employees clicked on the holiday bonus email and “failed the test.”</p>



<p>Scottsdale-based GoDaddy, the world’s largest domain registrar and web-hosting company, did not respond to repeated requests for comment about the emails. The emails were forwarded to The Copper Courier by three GoDaddy employees.</p>



<p>Earlier this year, <a href="https://www.forbes.com/sites/daveywinder/2020/05/05/godaddy-confirms-data-breach-what-19-million-customers-need-to-know/?sh=235bf0a91daa">Forbes reported</a> that 28,000 GoDaddy customers were impacted after a data breach compromised their account usernames and passwords.&nbsp;</p>



<p>Despite the company <a href="https://investors.godaddy.net/newsroom/news-releases/press-release-details/2020/GoDaddy-Reports-Second-Quarter-2020-Earnings-Results/default.aspx">surpassing 20 million customers this year</a> and reporting “record customer growth,” the company <a href="https://aboutus.godaddy.net/newsroom/news-releases/press-release-details/2020/GoDaddy-Blog-Update/default.aspx">laid off or reassigned</a> hundreds of employees during the coronavirus pandemic, <a href="https://www.abc15.com/news/business/godaddy-to-lay-off-hundreds-close-texas-offices">including in Arizona</a>, Iowa, and Texas.</p>



<p>GoDaddy is not the first company this year to trick employees into falling for phishing scams by dangling the carrot of a potential bonus.</p>



<p>In September, Tribune Publishing, which owns <a href="https://www.tribpub.com/#">several major newspapers</a> around the country, sent a similar email to its employees.</p>



<p>The email, circulated by <a href="https://twitter.com/justin_fenton/status/1308851669397053440">several furious Tribune employees on Twitter</a>, said the company was giving out targeted bonuses of $5,000-$10,000, only to later reveal itself as a phishing test sent by the company.</p>



<figure><div>
<figure><blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>I've been able to confirm that this was in fact! an internal test from <a href="https://twitter.com/tribpub?ref_src=twsrc%5Etfw">@tribpub</a>. If you click the links, you get a message from the company's training contractor saying you clicked on a simulated phishing test.</p><p>The level of cruelty is actually stunning, even for this company.</p></div>— Danielle Ohl (@DTOhl) <a href="https://twitter.com/DTOhl/status/1308850196978298880?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote></figure>
</div></figure>



<p>“The level of cruelty is actually stunning,” Tribune reporter Danielle Ohl <a href="https://twitter.com/DTOhl/status/1308850196978298880?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1308850196978298880%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.vice.com%2Fen%2Farticle%2Fy3z8g5%2Ftribune-publishing-out-evils-itself-with-phishing-email-promising-bonuses">wrote at the time</a>.</p>



<p>A Tribune spokesperson <a href="https://www.vice.com/en/article/y3z8g5/tribune-publishing-out-evils-itself-with-phishing-email-promising-bonuses">later told Vice News</a> that the exercise was part of a regular, internal test to assess phishing risks and said that it had no intention of offending its employees. “In retrospect, the topic of the email was misleading and insensitive, and the company apologizes for its use,” the statement read.</p>



<p><em>Want to talk about phishing tests you’ve received from your employer? Reach the reporter at <a href="mailto:lorraine@couriernewsroom.com">lorraine@couriernewsroom.com</a> or 480-243-4086.</em></p>
				</div><div>
	<hr>
	<div>
    <a href="https://coppercourier.com/author/lorrainelonghi/">
        <picture>
	<source media="(max-width: 90px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/11/Lorraine-Longhi-.jpg?w=90">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/11/Lorraine-Longhi-.jpg?w=90" width="90" height="9999" alt="Lorraine Longhi" title="Lorraine Longhi">
</picture>    </a>
    <div>
        <p>
            <a href="https://coppercourier.com/author/lorrainelonghi/">
                Lorraine Longhi            </a>
            is a reporter for The Copper Courier. She is a native of the Southwest and has lived in Phoenix since 2006. A graduate of ASU’s Walter Cronkite School of Journalism, she previously worked for The Arizona Republic, covering city government, education, and the impact of statewide decisions.        </p>
        
    </div>
</div>
</div></div>]]>
            </description>
            <link>https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25529584</guid>
            <pubDate>Thu, 24 Dec 2020 17:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In CPython, types implemented in C are part of the type tree]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25528557">thread link</a>) | @todsacerdoti
<br/>
December 24, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In CPython, types implemented in C actually are part of the type tree</h2>

	<p><small>December 24, 2020</small></p>
</div><div><p>In Python, in theory all types descend from <code>object</code> (they are
direct or indirect subclasses of it). For years, I've believed (and
written) that this was not the case at the implementation level for
types written in native C code in CPython (the standard implementation
of Python and the one you're probably using). Types written in C
might behave as if they descended from <code>object</code>, but I thought their
behavior was actually entirely stand-alone, implemented by each
type separately in C. Courtesy of <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">Python behind the scenes #6:
how Python object system works</a>,
I've discovered that I'm wrong.</p>

<p>In CPython, C level Python types are not literally subclasses of
the C level version of <code>object</code>, because of course C doesn't have
classes and subclasses in that sense. Instead, you usually describe
your type by defining a <a href="https://docs.python.org/3/c-api/typeobj.html"><code>PyTypeObject</code></a> struct for it, with
all sorts of fields that you fill in or don't fill in as you need
them, including a <a href="https://docs.python.org/3/c-api/typeobj.html#c.PyTypeObject.tp_base"><code>tp_base</code></a> field
for your base type (if you want more than one base type, you need
to take the alternate path of a <a href="https://docs.python.org/3/c-api/typeobj.html#heap-types">heap type</a>). When
CPython needs to execute special methods or other operations on
your type, it will directly use fields on your <code>PyTypeObject</code>
structure (and as far as I know, it only uses those fields, with
no fallbacks). On the surface, this looks like the <code>tp_base</code> field
is essentially decorative and is only used to report your claimed
<code>__base__</code> if people ask.</p>

<p>However, there is a bit of CPython magic hiding behind the scenes.
In order to actually use a <code>PyTypeObject</code> as a type, you must
register it and make it ready by calling <a href="https://docs.python.org/3/c-api/type.html#c.PyType_Ready"><code>PyType_Ready</code></a>. As part
of this, <code>PyType_Ready</code> will use your type's <code>tp_base</code> to fill
in various fields of your <code>PyTypeObject</code> if you didn't already do
that, which effectively means that your C level type will inherit
those fields from its base type (and so on all the way up to
<code>object</code>). This is outlined in <a href="https://docs.python.org/3/c-api/typeobj.html#cols">a section of the C API</a>, but of course
I never read the C API myself because I never needed to use it.
The <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">how [the] Python object system works</a>
article has more details on how this works, if you're curious, along
with details on how special methods also work (which is more
interesting than I had any idea, and I've looked at this area
before).</p>

<p>(The distinction between what is considered a 'type' and what is
considered a 'class' by <code>repr()</code> is somewhat arbitrary; see the
sidebar <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ClassesAndTypes">here</a>. C level things defined with
<code>PyTypeObject</code> will probably always be considered types instead of
classes.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree</link>
            <guid isPermaLink="false">hacker-news-small-sites-25528557</guid>
            <pubDate>Thu, 24 Dec 2020 15:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oklab: A perceptual color space for image processing]]>
            </title>
            <description>
<![CDATA[
Score 222 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25525726">thread link</a>) | @ingve
<br/>
December 23, 2020 | https://bottosson.github.io/posts/oklab/ | <a href="https://web.archive.org/web/*/https://bottosson.github.io/posts/oklab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>A perceptual color space is desirable when doing many kinds of image processing. It is useful for things like:</p><ul><li>Turning an image grayscale, while keeping the perceived lightness the same</li><li>Increasing the saturation of colors, while maintaining perceived hue and lightness</li><li>Creating smooth and uniform looking transitions between colors</li></ul><p>Unfortunately, as far as I am aware, while there are color spaces that aim to be perceptually uniform, none are without significant drawbacks when used for image processing.</p><p>For this reason I have designed a new perceptual color space, designed to be simple to use, while doing a good job at predicting perceived lightness, <a href="https://en.wikipedia.org/wiki/Colorfulness">chroma</a> and hue. It is called the <strong>Oklab color space</strong>, because it is an OK Lab color space.</p><p>Before diving into the details of why a new color space is needed and how it was derived, here is the everything needed to use the color space:</p><p>A color in Oklab is represented with three coordinates, similar to how <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a> works, but with better perceptual properties. Oklab uses a D65 whitepoint, since this is what sRGB and other common color spaces use. The three coordinates are:</p><ul><li><span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span> – perceived lightness</li><li><span><span><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> – how green/red the color is</li><li><span><span><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> – how blue/yellow the color is</li></ul><p>For many operations, <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span>-coordinates can be used directly, but they can also be transformed into polar form, with the coordinates lightness, chroma and hue, <span><span><math><semantics><mrow><mi>L</mi><mi>C</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">LCh</annotation></semantics></math></span></span>:</p><p><span><span><span><math><semantics><mrow><mi>C</mi><mo>=</mo><mrow><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>=</mo><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mn>2</mn></mtext><mo>(</mo><mi>b</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">C={\sqrt {a^2+b^2}}, \qquad h^{\circ}=\text{atan2}(b,a)</annotation></semantics></math></span></span></span></p><p>From <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup></mrow><annotation encoding="application/x-tex">h^{\circ}</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> can be computed like this:</p><p><span><span><span><math><semantics><mrow><mi>a</mi><mo>=</mo><mi>C</mi><mi>cos</mi><mo>(</mo><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>)</mo><mo separator="true">,</mo><mspace width="2em"></mspace><mi>b</mi><mo>=</mo><mi>C</mi><mi>sin</mi><mo>(</mo><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">a=C\cos(h^{\circ}),\qquad b=C\sin(h^{\circ})</annotation></semantics></math></span></span></span></p><p>Lets look at a practical example to see how Oklab performs, before looking at how the <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span> coordinates are computed.</p><blockquote><h4 id="comparing-oklab-to-hsv">Comparing Oklab to HSV <a href="#comparing-oklab-to-hsv"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Here’s an Oklab color gradient with varying hue and constant lightness and chroma.</p><p><img alt="Oklab varying hue plot" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_oklab.png" width="1130"></p><p>Compare this to a similar plot of a HSV color gradient with varying hue and constant value and saturation (HSV using the sRGB color space).</p><p><img alt="HSV varying hue plot" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_hsv.png" width="1130"></p><p>The gradient is quite uneven and there are clear differences in lightness for different hues. Yellow, magenta and cyan appear much lighter than red and blue.</p><p>Here is lightness of the HSV plot, as predicted by Oklab:</p><p><img alt="HSV varying hue plot lightness" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_hsv_lightness.png" width="1130"></p></blockquote><h3 id="implementation">Implementation <a href="#implementation"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><h4 id="converting-from-xyz-to-oklab">Converting from XYZ to Oklab <a href="#converting-from-xyz-to-oklab"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Given a color in <span><span><math><semantics><mrow><mi>X</mi><mi>Y</mi><mi>Z</mi></mrow><annotation encoding="application/x-tex">XYZ</annotation></semantics></math></span></span> coordinates, with a D65 whitepoint, Oklab coordinates can be computed like this:</p><p>First the <span><span><math><semantics><mrow><mi>X</mi><mi>Y</mi><mi>Z</mi></mrow><annotation encoding="application/x-tex">XYZ</annotation></semantics></math></span></span> coordinates are converted to an approximate cone responses:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l \\ m \\ s \end{pmatrix} = \mathbf{M_1} \times \begin{pmatrix} X \\ Y \\ Z \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>A non-linearity is applied:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l' \\ m' \\ s' \end{pmatrix} = \begin{pmatrix} l^{\frac 1 3} \\ m^{\frac 1 3} \\ s^{\frac 1 3} \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>Finally, this is transformed into the <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span>-coordinates:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} L \\ a \\ b \end{pmatrix} = \mathbf{M_2} \times \begin{pmatrix} l' \\ m' \\ s' \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>with the following values for <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1}</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2}</annotation></semantics></math></span></span>:</p><p><span><span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>1</mn><mn>8</mn><mn>9</mn><mn>3</mn><mn>3</mn><mn>0</mn><mn>1</mn><mn>0</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>3</mn><mn>6</mn><mn>1</mn><mn>8</mn><mn>6</mn><mn>6</mn><mn>7</mn><mn>4</mn><mn>2</mn><mn>4</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>1</mn><mn>2</mn><mn>8</mn><mn>8</mn><mn>5</mn><mn>9</mn><mn>7</mn><mn>1</mn><mn>3</mn><mn>7</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>3</mn><mn>2</mn><mn>9</mn><mn>8</mn><mn>4</mn><mn>5</mn><mn>4</mn><mn>3</mn><mn>6</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>2</mn><mn>9</mn><mn>3</mn><mn>1</mn><mn>1</mn><mn>8</mn><mn>7</mn><mn>1</mn><mn>5</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>3</mn><mn>6</mn><mn>1</mn><mn>4</mn><mn>5</mn><mn>6</mn><mn>3</mn><mn>8</mn><mn>7</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>4</mn><mn>8</mn><mn>2</mn><mn>0</mn><mn>0</mn><mn>3</mn><mn>0</mn><mn>1</mn><mn>8</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>2</mn><mn>6</mn><mn>4</mn><mn>3</mn><mn>6</mn><mn>6</mn><mn>2</mn><mn>6</mn><mn>9</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>6</mn><mn>3</mn><mn>3</mn><mn>8</mn><mn>5</mn><mn>1</mn><mn>7</mn><mn>0</mn><mn>7</mn><mn>0</mn></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1} = \begin{pmatrix} +0.8189330101 &amp; +0.3618667424 &amp; -0.1288597137 \\ +0.0329845436 &amp; +0.9293118715 &amp; +0.0361456387 \\ +0.0482003018 &amp; +0.2643662691 &amp; +0.6338517070 \end{pmatrix}</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>2</mn><mn>1</mn><mn>0</mn><mn>4</mn><mn>5</mn><mn>4</mn><mn>2</mn><mn>5</mn><mn>5</mn><mn>3</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn><mn>9</mn><mn>3</mn><mn>6</mn><mn>1</mn><mn>7</mn><mn>7</mn><mn>8</mn><mn>5</mn><mn>0</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>0</mn><mn>4</mn><mn>0</mn><mn>7</mn><mn>2</mn><mn>0</mn><mn>4</mn><mn>6</mn><mn>8</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>1</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>7</mn><mn>7</mn><mn>9</mn><mn>9</mn><mn>8</mn><mn>4</mn><mn>9</mn><mn>5</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>2</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>2</mn><mn>8</mn><mn>5</mn><mn>9</mn><mn>2</mn><mn>2</mn><mn>0</mn><mn>5</mn><mn>0</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>5</mn><mn>0</mn><mn>5</mn><mn>9</mn><mn>3</mn><mn>7</mn><mn>0</mn><mn>9</mn><mn>9</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>2</mn><mn>5</mn><mn>9</mn><mn>0</mn><mn>4</mn><mn>0</mn><mn>3</mn><mn>7</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn><mn>8</mn><mn>2</mn><mn>7</mn><mn>7</mn><mn>1</mn><mn>7</mn><mn>6</mn><mn>6</mn><mn>2</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>0</mn><mn>8</mn><mn>6</mn><mn>7</mn><mn>5</mn><mn>7</mn><mn>6</mn><mn>6</mn><mn>0</mn></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2} = \begin{pmatrix} +0.2104542553 &amp; +0.7936177850 &amp; -0.0040720468 \\ +1.9779984951 &amp; -2.4285922050 &amp; +0.4505937099 \\ +0.0259040371 &amp; +0.7827717662 &amp; -0.8086757660 \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>The inverse operation, going from Oklab to XYZ is done with the following steps:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msup><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msup><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l' \\ m' \\ s' \end{pmatrix} = \mathbf{M_2}^{-1} \times \begin{pmatrix} L \\ a \\ b \end{pmatrix},\qquad \begin{pmatrix} l \\ m \\ s \end{pmatrix} = \begin{pmatrix} {(l')}^{3} \\ {(m')}^{3} \\ {(s')}^{3} \end{pmatrix},\qquad \begin{pmatrix} X \\ Y \\ Z \end{pmatrix} = \mathbf{M_1}^{-1} \times \begin{pmatrix} l \\ m \\ s \end{pmatrix}</annotation></semantics></math></span></span></span></p><h4 id="converting-from-linear-srgb-to-oklab">Converting from linear sRGB to Oklab <a href="#converting-from-linear-srgb-to-oklab"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Since this will be a common use case, here is the code to convert linear sRGB values to Oklab and back. To compute linear sRGB values, see <a href="https://bottosson.github.io/posts/colorwrong/#what-can-we-do%3F">my previous post</a>.</p><p>The code is in C++, but without any fancy features so should be easy to translate. The code is available in public domain, feel free to use it any way you please.</p><pre><code>struct Lab {float L; float a; float b;};
struct RGB {float r; float g; float b;};

Lab linear_srgb_to_oklab(RGB c) 
{
    float l = 0.4121656120f * c.r + 0.5362752080f * c.g + 0.0514575653f * c.b;
    float m = 0.2118591070f * c.r + 0.6807189584f * c.g + 0.1074065790f * c.b;
    float s = 0.0883097947f * c.r + 0.2818474174f * c.g + 0.6302613616f * c.b;

    float l_ = cbrtf(l);
    float m_ = cbrtf(m);
    float s_ = cbrtf(s);

    return {
        0.2104542553f*l_ + 0.7936177850f*m_ - 0.0040720468f*s_,
        1.9779984951f*l_ - 2.4285922050f*m_ + 0.4505937099f*s_,
        0.0259040371f*l_ + 0.7827717662f*m_ - 0.8086757660f*s_,
    };
}

RGB oklab_to_linear_srgb(Lab c) 
{
    float l_ = c.L + 0.3963377774f * c.a + 0.2158037573f * c.b;
    float m_ = c.L - 0.1055613458f * c.a - 0.0638541728f * c.b;
    float s_ = c.L - 0.0894841775f * c.a - 1.2914855480f * c.b;

    float l = l_*l_*l_;
    float m = m_*m_*m_;
    float s = s_*s_*s_;

    return {
        + 4.0767245293f*l - 3.3072168827f*m + 0.2307590544f*s,
        - 1.2681437731f*l + 2.6093323231f*m - 0.3411344290f*s,
        - 0.0041119885f*l - 0.7034763098f*m + 1.7068625689f*s,
    };
}
</code></pre><p>This is everything you need to use the Oklab color space! If you need a simple perceptual color space, try it out.</p><p>The rest of the post will go into why a new color space was needed, how it has been constructed and how it compares with existing color spaces.</p><hr><p>What properties does a perceptual color space need to satisfy to be useful for image processing? The answer to this is always going to be a bit subjective, but based on my experience, these are a good set of requirements:</p><blockquote><ul><li><strong>Should be an opponent color space</strong>, similar to for example <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a>.</li><li><strong>Should predict lightness, chroma and hue well</strong>. <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span> should be perceived as orthogonal, so one can be altered without affecting the other two. This is useful for things like turning an image black and white and increasing colorfulness without introducing hue shifts etc.</li><li><strong>Blending two colors should result in even transitions</strong>. The transition colors should appear to be in between the blended colors (e.g. passing through a warmer color than either original color is not good).</li><li><strong>Should assume a D65 whitepoint</strong>. This is what common color spaces like sRGB, rec2020 and Display P3 uses.</li><li><strong>Should behave well numerically</strong>. The model should be easy to compute, numerically stable and differentiable.</li><li><strong>Should assume normal well lit viewing conditions</strong>. The complexity of supporting different viewing conditions is not practical in most applications. Other models could be used in conjunction if this is needed in some case.</li><li><strong>If the scale/exposure of colors are changed, the perceptual coordinates should just be scaled by a factor</strong>. More complex models that depend on absolute luminance should be avoided since the viewing conditions can not be accurately controlled and incorrect behavior would be confusing.</li></ul></blockquote><h3 id="what-about-existing-models%3F">What about existing models? <a href="#what-about-existing-models%3F"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><p>Let’s look at existing models and how they stack up against these requirements. Further down there are graphs that illustrate some of these issues.</p><blockquote><ul><li><strong><a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a> and <a href="https://en.wikipedia.org/wiki/CIELUV">CIELUV</a></strong> – Largest issue is their inability to predict hue. In particular blue hues are predicted badly. Other smaller issues exist as well</li><li><strong><a href="https://en.wikipedia.org/wiki/CIECAM02">CIECAM02-UCS</a> and the newer CAM16-UCS</strong> – Does a good job at being perceptually uniform overall, but doesn’t meet other requirements: Bad numerical behavior, it is not scale invariant and blending does not behave well because of its compression of chroma. Hue uniformity is decent, but other models predict it more accurately.</li><li><strong><a href="https://en.wikipedia.org/wiki/OSA-UCS">OSA-UCS</a></strong> – Overall does a good job. The transformation to OSA-UCS lacks an analytical inverse unfortunately which makes it impractical.</li><li><strong><a href="https://scholarworks.rit.edu/theses/2858/">IPT</a></strong> – Does a great job modelling hue uniformity. Doesn’t predict lightness and chroma well unfortunately, but meets all other requirements. Is simple computationally and does not depend on the scale/exposure.</li><li><strong><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-25-13-15131&amp;id=368272">JzAzBz</a></strong> – Overall does a fairly good job. Designed to have uniform scaling of lightness for HDR data. While useful in some cases this introduces a dependence on the scale/exposure that makes it hard to use in general cases.</li><li><strong><a href="https://en.wikipedia.org/wiki/HSL_and_HSV">HSV</a> representation of sRGB</strong> – Only on this list because it is widely used. Does not meet any of the requirements except having a D65 whitepoint.</li></ul></blockquote><p>So, all in all, all these existing models have drawbacks.</p><p>Out of all of these, two models stand out: CAM16-UCS, for being the model with best properties of perceptual uniformity overall, and IPT for having a simple computational structure that meets all the requirements besides predicting lightness and chroma well.</p><p>For this reason it is reasonable to try to make a new color space, with the same computational structure as IPT, but that performs closer to CAM16-UCS in terms of predicting lightness and chroma. This exploration resulted in Oklab.</p><h3 id="how-oklab-was-derived">How Oklab was derived <a href="#how-oklab-was-derived"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><p>To derive Oklab, three datasets were used:</p><ul><li>A generated data set of pairs of colors with the same lightness but random hue and chroma, generated using CAM16 and normal viewing conditions. Colors were limited to be within Pointer’s Gamut – the set of possible surface colors.</li><li>A generated data set of pairs of colors with the same chroma but random hue and lightness, generated using CAM16 and normal viewing conditions. Colors were limited to be within Pointer’s Gamut</li><li>The <a href="https://github.com/nschloe/colorio/blob/master/colorio/data/ebner_fairchild.yaml">uniform perceived hue</a> data used to derive IPT. From this data, colors were combined into pairs of colors with equal perceived hue.</li></ul><p>These datasets can be used to test prediction of lightness, chroma and hue respectively. If a color space accurately models <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>, then all pairs in lightness dataset should have the same value for <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, all pairs in the chroma dataset the same value for <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and all pairs in the hue dataset the same values for <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>.</p><p>To test a color space it is not possible to simply check the distance in predictions in the tested color space however, since that will depend on the scaling of the color space. It is also not desirable to exactly predict ground truth values for <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>, since it is more important that our model has perceptually orthogonal coordinates, than that the model has the same spacing within each coordinate.</p><p>Instead the following approach was used to create an error metric independent of the color space:</p><ul><li>For each dataset all the pairs are converted to the tested color space.</li><li>Coordinates that are supposed to be the same within a pair are swapped to generate a new set of altered pairs:<ul><li>For the lightness dataset, the L coordinates are swapped between the pairs, and so on.</li><li>These altered pair would be equal to the original pair if the model predicts the datasets perfectly.</li></ul></li><li>The perceived distance between the original colors and the altered colors are are computed using <a href="https://en.wikipedia.org/wiki/Color_difference">CIEDE2000</a>.</li><li>The error for each pair is given as the minimum of the two color differences.</li><li>The error for the entire dataset is the root mean squared error of the color differences.</li></ul><p>Oklab was derived by optimizing the parameters of a color space with the same structure as IPT, to get a low error on all the datasets. For completeness, here is the structure of the color space – the parameters to optimize are the 3x3 matrices <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1}</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2}</annotation></semantics></math></span></span> and the positive number <span><span><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span></span>.</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l \\ m \\ s \end{pmatrix} = \mathbf{M_1} \times \begin{pmatrix} X \\ Y \\ Z \end{pmatrix}</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mi>γ</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mi>γ</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mi>γ</mi></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} L \\ a \\ b \end{pmatrix} = \mathbf{M_2} \times \begin{pmatrix} l^\gamma \\ m^\gamma \\ s^\gamma \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>A couple of extra constraints were …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bottosson.github.io/posts/oklab/">https://bottosson.github.io/posts/oklab/</a></em></p>]]>
            </description>
            <link>https://bottosson.github.io/posts/oklab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25525726</guid>
            <pubDate>Thu, 24 Dec 2020 07:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raster CRT Typography (According to Dec)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25523322">thread link</a>) | @dcminter
<br/>
December 23, 2020 | https://www.masswerk.at/nowgobang/2019/dec-crt-typography | <a href="https://web.archive.org/web/*/https://www.masswerk.at/nowgobang/2019/dec-crt-typography">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
		<article role="article">
		
		<time datetime="2019-02-20">February 20, 2019</time>
		<p>A closer look at the glyphs drawn by the DEC terminals VT100 and VT220.</p>
		<p><span>R</span>ecently, I engaged in a bit of analog media emulation, namely for the purpose of the reenactment of raster CRT graphics as seen on “glass terminals” like the iconic VT-series by the Digital Equipment Corporation (DEC). An endeavor, which raises a few questions, like, is there anything special to the media, what did the fonts really look like, and can we reconstruct them from specifications? </p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-crt-typography.png" alt="VT100 Series CRT Typography" width="800" height="800">
			<figcaption><em>(Not a DEC manual.)</em></figcaption>
		</figure>

		<p>Thanks to a tiny wealth of technical information available on the web, at sites like <a href="https://vt100.net/dec/vt220/glyphs" target="_blank" rel="noopener">vt100.net</a> and <a href="http://bitsavers.org/pdf/dec/terminal/" target="_blank" rel="noopener">bitsavers.org</a>, determining the look of these fonts should be easy. E.g., we may reconstruct the glyphs from the terminals’ ROMs. This way, we should be able to determine their exact forms. There are even TrueType-fonts available, meant to recreate the typography of the VT220, “<a href="http://sensi.org/~svo/glasstty/" target="_blank" rel="noopener">Glass TTY VT220</a>,” including scanlines, and “<a href="https://www.dafont.com/dec-terminal-modern.font" target="_blank" rel="noopener">DEC Terminal Modern</a>” with modernized, smooth outlines:</p>


		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-vt220-ttf.png" alt="VT220 TrueType fonts" width="710" height="415">
			<figcaption>Modern TrueType fonts recreating the glyphs of the VT220.<br>Mind that the VT-terminals supported two resolution modes, one at 132 characters per line and one at 80 characters (char-matrix 9×10 and 10×10, respectively), the latter introducing an extra spacing of one pixel.</figcaption>
		</figure>

		<p>Having a closer look at the two fonts, there are some notable differences (the differences in spacing may be explained by the two characters per line modes of the VT-terminals), however, neither looks right. Comparing them to photos of the similar VT100, there are discernible differences, not only in the font weight, but also in the size and form of the conters and the overal “feel” of the font. However, the apparent confusion about the weight of the font isn’t especially helped by photos of the real thing either, as the impression conveyed by them differs widely by lens, exposure and camera settings used:</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-vt100-adventure.jpg" alt="VT100 displaying Adventure / Colossal Cave." width="900" height="627">
			<figcaption>VT100 displaying Adventure / Colossal Cave<cite>Photo: <a href="https://en.wikipedia.org/wiki/File:Vt100-adventure.jpg" target="_blank" rel="noopener">Wikipedia, Dave Fischer</a>, 2008, Wikimedia Commons (edited, N.L.).</cite></figcaption>
		</figure>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-vt100-dir.jpg" alt="VT100 displaying a directory listing." width="900" height="702">
			<figcaption>VT100 displaying a directory listing<cite>Photo: <a href="https://www.flickr.com/photos/54568729@N00/9636183501" target="_blank" rel="noopener">Jason Scott</a>, 2013, Creative Commons (edited, N.L.).</cite></figcaption>
		</figure>

		<p>Since photos aren’t much of a help here either, it may be time for a look at the…</p>

		<h2>ROMs</h2>

		<p>Since ROMs are available, we may start there, since they are the closest, we may get, to the real thing, aren’t they? What could possibly go wrong?</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-roms.png" alt="VT100 and VT220 separated characters as in ROM" width="558" height="410">
			<figcaption><p>Separated ROM readings of the VT100 (left) and the VT220 (right).<br><cite>VT220 separation by Paul Flo Williams, <a href="https://vt100.net/dec/vt220/glyphs" target="_blank" rel="noopener">vt100.net</a> (2008). VT100 complemented by me, N.L.</cite></p>
			<p>Character definitions differ for “a”, “c”, “g”, “2”, “6”, “7”, “9”, “@”, “%”, “{”, “}”, “|”, “°” and in the forms of the control characters (␉ ␍ ␊ ␤ ␋). Moreover, there are additional characters on the VT220.</p></figcaption>
		</figure>

		<p>Now, this doesn’t look right either. Obviously, the glyphs will be rendered stretched vertically to about double height, but there’s more going on here. The characters just don’t look right. P.e., have a closer look at “p” and “q” or the offset in the dots of the downward right stroke of “k”, not to speak of the funny digits “6” and “9” of the VT100 or the distorted “2”! Moreover, at a closer look, the character matrix is just 8×10, while we expected at least 9×10 (and 10×10 for 80-cols mode) — as described in the specifications. Clearly, this is not what is displayed on the screen.</p>

		<h2>Phosphor</h2>
		<p>Let’s have another look at the manuals, specifically at the “<a href="https://vt100.net/docs/vt100-tm/ek-vt100-tm-002.pdf" target="_blank" rel="noopener">VT100 Series Technical Manual</a>” <cite>(2<sup>nd</sup> edition, EK-VT100-TM-002; DEC, Maynard, Massachsetts, Aug. 1979)</cite>. As we learn there, it’s all about phosphor latency:</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-phosphor-flanks.png" alt="VT100 and VT220 phosphor latency" width="743" height="390">
			<figcaption><p>Pulse widths and phosphor activation flanks for the VT100 and VT200.<br><cite>(VT100 Series Technical Manual, EK-VT100-TM-002, p. 4-78)</cite></p>
			<p>Mind that the flanks of the signal pulses are highly idealized and will be also sloped in analog real life.</p></figcaption>
		</figure>

		<p>The time it takes for the phosphor to become fully activated is actually longer than the pulse representing the timing to draw a single pixel (40 nanoseconds). Meaning, if we were to attempt to display just a single pixel, the phosphor on this particular spot will never reach its full activation level resulting in a fuzzy image of varying brightnesses between dimmer, thin strokes and heavier, thick strokes. So the typography has to adjust for this, by streching the pulses to double width (80 ns), at least, in order to provide an even image and legible text and to work around the shallow flanks of the screen intensification.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-monitor-repsonse.png" alt="VT100 and VT220 monitor response" width="800" height="250">
			<figcaption>Single and double pixel-widths, pulse timing and phosphor activation.<br><cite>(As above, re-edited N.L.)</cite></figcaption>
		</figure>

		<h2>Dot Stretching Circuitry</h2>
		<p>To provide for this, the VT-terminals employ a special technique, called <em>dot stretching:</em> The individual rows of a character matrix as in ROM are modified on-the-fly by prolonging any pulses for an active pixel for yet another pixel. Where there’s a single pixel in ROM, there will be two on the screen, where there are two in a row, there will be three displayed. (This is equivalent to OR-ing a word with itself by an offset of one pixel or bit to the right.)</p>
		<p>By this, our 8×10 matrix extends to the expected 9×10 (or 10×10 for the 80-columns mode, where the last pixel, which is set only for the line-drawing characters, will be stretched for yet another pulse.)</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-dot-stretching.png" alt="VT100 and VT220 dot streching" width="830" height="376">
			<figcaption>Dot streching on the VT100 and VT200.<br><cite>(VT100 Series Technical Manual, EK-VT100-TM-002, p. 4-78)</cite></figcaption>
		</figure>

		<p>However, this will provide different results for normal character size and double-width characters! Thanks to the wonders of dot stretching, there are two distinct fonts in one, each of them specially suited for the display size by the amount of detail exhibited!</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-dot-stretching-flanked.png" alt="VT100 and VT220 dot streching" width="410" height="410">
			<figcaption><p>1) as in ROM<br>
			2) single width with dot stretching<br>
			3) double width with dot stretching<br>
			4) single width with dot stretching and latency (flanks)<br>
			5) double width with dot stretching and latency (flanks)</p>
			<p><cite>(1, 2 &amp; 3 by Paul Flo Williams, <a href="https://vt100.net/dec/vt220/glyphs" target="_blank" rel="noopener">vt100.net</a>, 4 &amp; 5 added by me, N.L.)</cite></p></figcaption>
		</figure>

		<p>It’s crucially the image given in (2), representing dot streching, which provides the blocky, rather bold strokes found in modern representation of the font. However, if we add the sine- and cosine-like ramps of the flanks of the rising and dropping phosphor activation (compare 4 &amp; 5 and the timing diagram above), we arrive at a closer rendition of the screen image (mind that the VT100 and VT220 are said to expose quite discernible scanlines).</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-character-rendering.png" alt="VT100 and VT220 screen rendering" width="300" height="182">
			<figcaption><p>VT220 character samples (80-columns mode).<br>1) as in ROM<br>
			2) normal size with dot stretching<br>
			3) rising and dropping phosphor flanks applied<br>
			4) phosphor bleed added</p>
			<p>Mind, how the conters “open up” in 4 and 5.</p>
			<p><cite>(1 &amp; 2 by Paul Flo Williams, <a href="https://vt100.net/dec/vt220/glyphs" target="_blank" rel="noopener">vt100.net</a>, 3 &amp; 4 and negative image added by me, N.L.)</cite></p></figcaption>
		</figure>

		<p>As we may say, a rather extreme example of the media instructing typographical forms, or, <em>vice versa,</em> the glyph design working by the media and its specific technological constraints to arrive at the desired typography. Having a look at the effects of phosphor activation, latency and bleed, we may also understand, why individual photos of VT-terminal screens show varying font weights, according to the exposure in respect to the brightness of the monitor, while an overall smoothness of the font is still preserved.</p>
		
		<p>And here is another representation of the ROM-separations (compare the image above) with effects applied, providing a closer impression of the screen rendition:</p>
		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-glyphs-color.png" alt="VT100 and VT220 glyphs" width="320" height="430">
			<figcaption>Apparent glyphs: VT100 (left) and VT220 (right).</figcaption>
		</figure>
		<p>The double-width screen characters of the VT100 as compared to their normal, single-width appearance (black on white and as perceived on a screen):</p>
		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-vt100-charwidths.png" alt="VT100 double width and single width glyphs" width="526" height="366">
			<figcaption>VT100 double width and single width characters.</figcaption>
		</figure>

		<h2>Workbench Images</h2>

		<p>And here are, finally, two images <em>”from the workbench”,</em> showing my own attempts to recreate the screen experience in a web browser (HTML5, canvas API). Yea, there may be a bit too much retro-blur, however, you get the idea:</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-fontdemo-vt100.png" alt="VT100 screen emulation" width="650" height="320">
			<figcaption>VT100 emulation (screenshot).</figcaption>
		</figure>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/VTterm-fontdemo-vt220.png" alt="VT220 screen emulation" width="650" height="320">
			<figcaption>VT220 emulation (screenshot).</figcaption>
		</figure>

		<p>And that’s all for this episode…</p>


		
		

		<p><small><em>Discuss/comment on  <a href="https://news.ycombinator.com/item?id=19528618" target="_blank" rel="noopener">Hacker News</a> (oops, front page).</em></small></p>
		</article>

</div></div>]]>
            </description>
            <link>https://www.masswerk.at/nowgobang/2019/dec-crt-typography</link>
            <guid isPermaLink="false">hacker-news-small-sites-25523322</guid>
            <pubDate>Wed, 23 Dec 2020 23:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going All in on the Mac App Store]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 223 (<a href="https://news.ycombinator.com/item?id=25521679">thread link</a>) | @s3cur3
<br/>
December 23, 2020 | https://www.unboundapp.com/blog/mac-app-store/ | <a href="https://web.archive.org/web/*/https://www.unboundapp.com/blog/mac-app-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        

        <section>
            <p>With the announcement of the <a href="https://developer.apple.com/app-store/small-business-program/">App Store Small Business Program</a>, I’ve stopped selling Unbound directly via the web site. I thought it would be worth explaining how I came to that decision.</p>
            <p>The original motivation for selling the app directly was simple: Apple took a 30% cut of sales, whereas <a href="https://paddle.com/">Paddle</a>, the payment processor &amp; authentication tool I was using to sell directly only took [<em>not-publicly-disclosed-but-substantially-less-than–30</em>]%. With the drop in Mac App Store fees, that gap has shrunk considerably… to the point that it’s no longer worth keeping Paddle around.</p>
            <h2 id="directsalesareaworseexperienceforcustomers">1. Direct sales are a worse experience for customers.</h2>
            <p>From a customer’s perspective, every direct sale is its own little special snowflake, and you have to figure out how to get your license key, where in the app to enter it, etc. </p>
            <p>For the most tech-savvy users, this is pretty much a non-issue (until, of course, you migrate to a new computer and have to dig through your email to find your product key—good luck!). But a substantial percentage of users had trouble with this, and it was the #1 source of support requests for me.</p>
            <p>In contrast, virtually <em>every</em> Mac user is familiar with the Mac App Store. (And even if they aren’t, it can’t be a <em>worse</em> experience than trying to figure out a third-party platform!) Moving installs between machines is a non-issue, and there’s no such thing as an activation problem. </p>
            <h2 id="directsalesincreasetheoverheadofeachrelease">2. Direct sales increase the overhead of each release.</h2>
            <p>Unbound is not my day job, and revenue-wise, it probably doesn’t have any conceivable path to become my full-time income. (I’m measuring my income here in <a href="https://twitter.com/TylerAYoung/status/1341815721182056465" target="_blank">lattes per month</a>!) That means I can only work on it during nights &amp; weekends—a rather limited amount of time.</p>
            <p>For that reason, I want to maximize the time I actually spend shipping new features. Selling directly meant that I had to cut two builds, and go through two release processes, every time I wanted to ship an update. (And of course I’ve already mentioned the support burden of direct sales—support takes time directly away from development!)</p>
            <h2 id="directsalesareasecurityandprivacyliability">3. Direct sales are a security and privacy liability.</h2>
            <p>If Paddle suffered a data breach, suddenly <em>I</em> would be on the hook for exposing people’s emails or (God forbid) credit card data. While this has <em>not</em> happened, and I have no reason whatsoever to think Paddle is anything but competent, I’m still much happier trusting Apple’s security practices than <em>any</em> third party. (And if <em>Apple</em> has a security breach, I feel like I’m unlikely to take the blame from customers—the vast majority of them have done business with Apple directly in the past, whether for their computers, phones, or even just iTunes purchases.)</p>
            <p>Even apart from a data breach, removing all third parties from the equation is a privacy win for customers—I can proudly tell people the app collects <em>no</em> data whatsoever, whereas Paddle had to “phone home” to validate product keys.</p>
            <h2 id="itsjustnotworthitanymore">It’s just not worth it any more.</h2>
            <p>Given all that, the math just doesn’t work out in support of doing direct sales any more. Even if I moved sales to accepting credit cards directly, a 3.5% fee with all those downsides is substantially worse for both me and my customers than a flat 15%.</p>
            <p>Onward and upward!</p>
            <p>– Tyler</p>
            <p>Let me know what you think—find me on Twitter <a href="https://twitter.com/TylerAYoung">@TylerAYoung</a> or email me at my first name at unboundapp.com.</p>
        </section>

        <section>
            <img src="https://www.unboundapp.com/images/unbound-for-mac-icon-512.png" width="100" height="100" alt="Unbound Photo Browser icon">
            <h2>Unbound for Mac</h2>
            <a href="https://itunes.apple.com/us/app/unbound/id690375005?ls=1&amp;mt=12"><img src="https://www.unboundapp.com/images/badge-mac.svg" width="180" alt="Download on the Mac App Store"></a>
        </section>

        
    </section></div>]]>
            </description>
            <link>https://www.unboundapp.com/blog/mac-app-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25521679</guid>
            <pubDate>Wed, 23 Dec 2020 20:16:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comic Mono]]>
            </title>
            <description>
<![CDATA[
Score 612 | Comments 215 (<a href="https://news.ycombinator.com/item?id=25520510">thread link</a>) | @thesephist
<br/>
December 23, 2020 | https://dtinth.github.io/comic-mono-font/ | <a href="https://web.archive.org/web/*/https://dtinth.github.io/comic-mono-font/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>A legible monospace font… the very typeface you’ve been trained to recognize since childhood. This font is a fork of <a href="https://github.com/shannpersand">Shannon Miwa</a>’s <a href="https://github.com/shannpersand/comic-shanns">Comic Shanns</a> (version 1).</p>

<p>
  <a href="https://dtinth.github.io/comic-mono-font/">
    <img src="https://repository-images.githubusercontent.com/164606802/cd83d680-894c-11e9-83f7-c353c70df1cb" alt="Screenshot">
  </a>
</p>

<h2 id="download">Download</h2>
<ul>
  <li><a href="https://dtinth.github.io/comic-mono-font/ComicMono.ttf">ComicMono.ttf</a></li>
  <li><a href="https://dtinth.github.io/comic-mono-font/ComicMono-Bold.ttf">ComicMono-Bold.ttf</a></li>
</ul>

<h2 id="differences-from-comic-shanns">Differences from Comic Shanns</h2>
<ol>
  <li>All glyphs have been adjusted to have exactly the same width (using code based on <a href="https://github.com/cpitclaudel/monospacifier">monospacifier</a>).</li>
  <li>The glyph metrics have been adjusted to make it display better alongside system font, based on <a href="https://fonts.google.com/specimen/Cousine">Cousine</a>’s metrics.</li>
  <li>The name is changed to <code>Comic Mono</code>.</li>
  <li>A bold version of the font is generated using <a href="https://fontforge.github.io/Styles.html#Embolden">FontForge’s Embolden</a> operation.</li>
</ol>

<p>I have no font creation skills; I’m just a software developer. This font family is created by patching the original font, <a href="https://github.com/shannpersand/comic-shanns">Comic Shanns (v1)</a>, using a Python script, <a href="https://dtinth.github.io/comic-mono-font/generate.py"><code>generate.py</code></a>.</p>

<h2 id="what-does-it-look-like">What does it look like?</h2>
<p>
  <a href="https://dtinth.github.io/comic-mono-font/#what-does-it-look-like">
    Check it out!
  </a>
</p>

<div><div><pre><code><span>#!/usr/bin/env python2
# -*- coding: utf-8 -*-
</span>
<span>"""
Generates the Comic Mono font files based on Comic Shanns font.

Required files:
- vendor/comic-shanns.otf
- vendor/Cousine-Regular.ttf

Based on:
- monospacifier: https://github.com/cpitclaudel/monospacifier/blob/master/monospacifier.py
- YosemiteAndElCapitanSystemFontPatcher: https://github.com/dtinth/YosemiteAndElCapitanSystemFontPatcher/blob/master/bin/patch
"""</span>

<span>import</span> <span>os</span>
<span>import</span> <span>re</span>
<span>import</span> <span>sys</span>

<span>reload</span><span>(</span><span>sys</span><span>)</span>
<span>sys</span><span>.</span><span>setdefaultencoding</span><span>(</span><span>'UTF8'</span><span>)</span>

<span>import</span> <span>fontforge</span>
<span>import</span> <span>psMat</span>
<span>import</span> <span>unicodedata</span>

<span>def</span> <span>height</span><span>(</span><span>font</span><span>):</span>
    <span>return</span> <span>float</span><span>(</span><span>font</span><span>.</span><span>capHeight</span><span>)</span>

<span>def</span> <span>adjust_height</span><span>(</span><span>source</span><span>,</span> <span>template</span><span>,</span> <span>scale</span><span>):</span>
    <span>source</span><span>.</span><span>selection</span><span>.</span><span>all</span><span>()</span>
    <span>source</span><span>.</span><span>transform</span><span>(</span><span>psMat</span><span>.</span><span>scale</span><span>(</span><span>height</span><span>(</span><span>template</span><span>)</span> <span>/</span> <span>height</span><span>(</span><span>source</span><span>)))</span>
    <span>for</span> <span>attr</span> <span>in</span> <span>[</span><span>'ascent'</span><span>,</span> <span>'descent'</span><span>,</span>
                <span>'hhea_ascent'</span><span>,</span> <span>'hhea_ascent_add'</span><span>,</span>
                <span>'hhea_linegap'</span><span>,</span>
                <span>'hhea_descent'</span><span>,</span> <span>'hhea_descent_add'</span><span>,</span>
                <span>'os2_winascent'</span><span>,</span> <span>'os2_winascent_add'</span><span>,</span>
                <span>'os2_windescent'</span><span>,</span> <span>'os2_windescent_add'</span><span>,</span>
                <span>'os2_typoascent'</span><span>,</span> <span>'os2_typoascent_add'</span><span>,</span>
                <span>'os2_typodescent'</span><span>,</span> <span>'os2_typodescent_add'</span><span>,</span>
                <span>]:</span>
        <span>setattr</span><span>(</span><span>source</span><span>,</span> <span>attr</span><span>,</span> <span>getattr</span><span>(</span><span>template</span><span>,</span> <span>attr</span><span>))</span>
    <span>source</span><span>.</span><span>transform</span><span>(</span><span>psMat</span><span>.</span><span>scale</span><span>(</span><span>scale</span><span>))</span>

<span>font</span> <span>=</span> <span>fontforge</span><span>.</span><span>open</span><span>(</span><span>'vendor/comic-shanns.otf'</span><span>)</span>
<span>ref</span> <span>=</span> <span>fontforge</span><span>.</span><span>open</span><span>(</span><span>'vendor/Cousine-Regular.ttf'</span><span>)</span>
<span>for</span> <span>g</span> <span>in</span> <span>font</span><span>.</span><span>glyphs</span><span>():</span>
    <span>uni</span> <span>=</span> <span>g</span><span>.</span><span>unicode</span>
    <span>category</span> <span>=</span> <span>unicodedata</span><span>.</span><span>category</span><span>(</span><span>unichr</span><span>(</span><span>uni</span><span>))</span> <span>if</span> <span>0</span> <span>&lt;=</span> <span>uni</span> <span>&lt;=</span> <span>sys</span><span>.</span><span>maxunicode</span> <span>else</span> <span>None</span>
    <span>if</span> <span>g</span><span>.</span><span>width</span> <span>&gt;</span> <span>0</span> <span>and</span> <span>category</span> <span>not</span> <span>in</span> <span>[</span><span>'Mn'</span><span>,</span> <span>'Mc'</span><span>,</span> <span>'Me'</span><span>]:</span>
        <span>target_width</span> <span>=</span> <span>510</span>
        <span>if</span> <span>g</span><span>.</span><span>width</span> <span>!=</span> <span>target_width</span><span>:</span>
            <span>delta</span> <span>=</span> <span>target_width</span> <span>-</span> <span>g</span><span>.</span><span>width</span>
            <span>g</span><span>.</span><span>left_side_bearing</span> <span>+=</span> <span>delta</span> <span>/</span> <span>2</span>
            <span>g</span><span>.</span><span>right_side_bearing</span> <span>+=</span> <span>delta</span> <span>-</span> <span>g</span><span>.</span><span>left_side_bearing</span>
            <span>g</span><span>.</span><span>width</span> <span>=</span> <span>target_width</span>

<span>font</span><span>.</span><span>familyname</span> <span>=</span> <span>'Comic Mono'</span>
<span>font</span><span>.</span><span>version</span> <span>=</span> <span>'0.1.1'</span>
<span>font</span><span>.</span><span>comment</span> <span>=</span> <span>'https://github.com/dtinth/comic-mono-font'</span>
<span>font</span><span>.</span><span>copyright</span> <span>=</span> <span>'https://github.com/dtinth/comic-mono-font/blob/master/LICENSE'</span>

<span>adjust_height</span><span>(</span><span>font</span><span>,</span> <span>ref</span><span>,</span> <span>0.875</span><span>)</span>
<span>font</span><span>.</span><span>sfnt_names</span> <span>=</span> <span>[]</span> <span># Get rid of 'Prefered Name' etc.
</span><span>font</span><span>.</span><span>fontname</span> <span>=</span> <span>'ComicMono'</span>
<span>font</span><span>.</span><span>fullname</span> <span>=</span> <span>'Comic Mono'</span>
<span>font</span><span>.</span><span>generate</span><span>(</span><span>'ComicMono.ttf'</span><span>)</span>

<span>font</span><span>.</span><span>selection</span><span>.</span><span>all</span><span>()</span>
<span>font</span><span>.</span><span>fontname</span> <span>=</span> <span>'ComicMono-Bold'</span>
<span>font</span><span>.</span><span>fullname</span> <span>=</span> <span>'Comic Mono Bold'</span>
<span>font</span><span>.</span><span>weight</span> <span>=</span> <span>'Bold'</span>
<span>font</span><span>.</span><span>changeWeight</span><span>(</span><span>32</span><span>,</span> <span>"LCG"</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>"squish"</span><span>)</span>
<span>font</span><span>.</span><span>generate</span><span>(</span><span>'ComicMono-Bold.ttf'</span><span>)</span>
</code></pre></div></div>

<h2 id="cdn">CDN</h2>
<p>You can use this font in your web pages by including the stylesheet. CDN is provided by <a href="https://www.jsdelivr.com/package/npm/comic-mono">jsDelivr</a>.</p>
<div><div><pre><code><span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span> <span>href=</span><span>"https://cdn.jsdelivr.net/npm/comic-mono@0.0.1/index.css"</span><span>&gt;</span>
</code></pre></div></div>

<h2 id="npm-package">npm Package</h2>
<p>The contents of this package is also <a href="https://www.npmjs.com/package/comic-mono">published to npm</a>, although the font files are not optimized. See fontsource package (below) for a better option.</p>

<h2 id="packages-published-by-third-parties">Packages published by third parties</h2>
<ul>
  <li>Fontsource: <a href="https://www.npmjs.com/package/@fontsource/comic-mono">@fontsource/comic-mono</a> (<a href="https://github.com/fontsource/fontsource/pull/117">thanks @DecliningLotus</a>)</li>
  <li>Arch Linux AUR: <a href="https://aur.archlinux.org/packages/ttf-comic-mono-git/">ttf-comic-mono-git</a> (maintained by DBourgeoisat)</li>
</ul>

<h2 id="license">License</h2>
<p>It is licensed under the <a href="https://dtinth.github.io/comic-mono-font/LICENSE">MIT License</a>.</p>


      
      
      
    </div></div>]]>
            </description>
            <link>https://dtinth.github.io/comic-mono-font/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25520510</guid>
            <pubDate>Wed, 23 Dec 2020 18:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Software Bugs Using Symbolic Execution]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25520031">thread link</a>) | @rsas
<br/>
December 23, 2020 | https://sasnauskas.eu/finding-software-bugs-using-symbolic-execution/ | <a href="https://web.archive.org/web/*/https://sasnauskas.eu/finding-software-bugs-using-symbolic-execution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>The idea of dynamic <em>symbolic execution</em> is to execute a piece of software on any input.
All possible execution paths are explored simultaneously without specifying concrete values.
Consider the following example where the input <code>x</code> is unknown, i.e., symbolic:</p>
<div><pre><code data-lang="c"><span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>0</span><span>)</span> <span>{</span>
    <span>// ...
</span><span></span><span>}</span> <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&gt;</span> <span>100</span><span>)</span> <span>{</span>
    <span>// ...
</span><span></span><span>}</span> <span>else</span> <span>{</span>
    <span>assert</span><span>(</span><span>"should not reach this!"</span><span>)</span>
<span>}</span>
</code></pre></div><p>Symbolic execution runs this code on all three <em>execution paths</em> (<code>x&lt;0</code>, <code>x&gt;100</code>, <code>0&lt;=x&lt;=100</code>) and generates three concrete test cases: <code>x=-1</code>, <code>x=101</code> and <code>x=23</code> after hitting the assertion.</p>
<p>You don’t need to write test cases manually anymore.
You catch assertion failures and memory safety errors along the execution paths.
Ok, that is all in theory, but can this approach work for real-world programs in practice?</p>
<h3 id="klee">KLEE</h3>
<p><a href="https://klee.github.io/">KLEE</a> is a symbolic execution engine that executes unmodified, real-world programs on any input.
You compile your program to <a href="http://llvm.org/">LLVM</a> bitcode, mark some inputs as symbolic, and start KLEE.
KLEE explores possible execution paths using constraint solving and generates concrete test cases for each of them.
In case of a bug, you can replay your program with the input that triggered it.</p>
<p>In November 2019, the seminal <a href="http://llvm.org/pubs/2008-12-OSDI-KLEE.html">OSDI 2008 paper</a> on KLEE <a href="https://www.imperial.ac.uk/news/193808/paper-co-authored-professor-cadar-elected-acm/">has been elected to ACM SIGOPS Hall of Fame</a>.
Over the past decade, the research and application of KLEE resulted in over 150 scientific publications, dozens of Ph.D. theses, research grants, tools, and security startups.
On my behalf, I spent more than five years of my life with KLEE as well and learned a lot along the way.</p>
<h3 id="testing-network-protocols-using-klee">Testing Network Protocols Using KLEE</h3>
<p>In 2007, I struggled to find my research thesis until I came across Cristian Cadar’s paper <a href="https://www.doc.ic.ac.uk/~cristic/talks/exe-ccs-2006.pdf">“EXE: Automatically Generating Inputs of Death”</a>.
Inspired by the idea of symbolic execution, I asked myself the following question: <em>Can I mark the protocol header of an incoming network packet symbolic before passing it to the network stack?
If so, can I find protocol specification and implementation bugs with this technique?</em></p>
<p>I wrote an e-mail to Cristian Cadar and promptly received an answer.
Moreover, Cristian and Daniel Dunbar generously sent me the source code of KLEE, a new tool they were working on, even before its official release to the public.</p>
<p>In the following five years of my Ph.D. journey, I extended KLEE to execute several protocol stacks that talk to each other.
I applied this technique to test sensor networks and found a couple of interesting bugs in the Contiki OS described in my <a href="http://www.comsys.rwth-aachen.de/fileadmin/papers/2010/2010-04-ipsn-sasnauskas-KleeNet.pdf">IPSN 2010 paper</a>.
One of them caused a dead-lock of a sensor node inside the TCP/IP stack requiring a hardware reset.
It was a real bug observed in sensor network deployments.</p>
<p>I have not used KLEE actively since 2015 and was curious to give it a try (again).
Meanwhile, Contiki OS has been forked to <a href="https://github.com/contiki-ng/contiki-ng">Contiki-NG</a>.
I cloned the repo and compiled the test case called <code>20-packet-parsing</code> to LLVM bitcode.
Inside the test case, I marked the test packet buffer (~1KB) symbolic using KLEE’s <code>klee_make_symbolic</code> function.</p>
<p>After running for a couple of minutes on my old Mac, KLEE discovered two memory errors (out of bound pointers) while parsing certain protocols' headers.
I reported these findings with the concrete test cases to the security team of Contiki-NG for further analysis.
To me, this small test is yet another evidence that KLEE remains to be a useful research and test case generation tool.</p>
<h3 id="open-challenges-and-opportunities">Open Challenges and Opportunities</h3>
<p>Applying symbolic execution to arbitrary real-world programs is hard.
You often have to model the execution environment and find effective ways to cope with non-determinism and path explosion.
Moreover, many of the path constraints are difficult yet intractable to be solved in time with today’s solvers.</p>
<p>Nevertheless, studying and applying symbolic execution (using KLEE) opens many opportunities.
You will learn about program structure, compilers, SAT/SMT solvers, and how to write other kinds of testing tools.
Given this bag of knowledge, I wrote tools to <a href="https://www.cs.utah.edu/~regehr/papers/p1-sasnauskas.pdf">fuzz Android apps</a>, <a href="https://github.com/google/souper">superoptimize LLVM IR</a>, and more recently at work, a tool to <a href="https://arc.aiaa.org/doi/pdf/10.2514/6.2018-2665">fuzz satellite control procedures</a> written in SPELL.</p>
<p>Consider giving symbolic execution a try.
If you are a Ph.D. student and struggling to find a thesis topic in this area, <a href="http://matt.might.net/articles/phd-school-in-pictures/">don’t forget the bigger picture and keep pushing</a>.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://sasnauskas.eu/finding-software-bugs-using-symbolic-execution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25520031</guid>
            <pubDate>Wed, 23 Dec 2020 17:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview advice that got me offers]]>
            </title>
            <description>
<![CDATA[
Score 598 | Comments 350 (<a href="https://news.ycombinator.com/item?id=25519718">thread link</a>) | @ZainRiz
<br/>
December 23, 2020 | https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>“What would you say if I asked you to design me a service capable of responding to thousands of user requests every second and latency was critical?”</p><p>“Umm...that you have to solve this problem at work. But you’re out of ideas, and are looking to interviewees for suggestions”</p><p>That’s the actual response I gave the interviewer the first time I was asked a design question. He had a good laugh. But then still made me design the service.</p><p>In the decade since I’ve lost track of how many hours I’ve spent in the interview room, on both sides of the table. I’ve worked at Microsoft, Google, and Stripe, and received offers from many other companies. As I interviewed, I realized one thing: standard interviewing advice falls woefully short.</p><p>What good does it do to practice coding problems for weeks if your mind goes blank in an interview room? Everyone says to be wary of the recruiters, but what if you weren’t? How can you show your “best self” if you’re too afraid to let it out?</p><p>I tested the answers to these questions multiple times (sometimes by accident). Turns out conventional wisdom gets you conventional results. But you can do better. Interviewing is a skill and anyone can learn it.</p><p>For some reason no one talks about these aspects of interviewing, but I’ve found them helpful time and time again.</p><p>We’ll cover:</p><ul><li>Using recruiters to your advantage</li><li>Going to real interviews for practice</li><li>Being open to learning during interviews</li><li>Keeping those skills sharp even when you’re not job hunting</li></ul><h2 id="tip-1-use-recruiters-to-your-advantage">Tip #1: Use recruiters to your advantage</h2><p>Their voice sounds so friendly and helpful when you chat with them on the phone. “Zain, I’m looking forward to seeing you when you come for your interview!” Clearly it’s all an act, past-me assumed. I was sure they were secretly judging me, deciding if I was good enough to work at the company.</p><p>And they do judge. But not in the way I was expecting.</p><p>Recruiters aren’t evaluating you technically, not by the time you pick up the phone anyways. Their decision on whether you have the technical chops to be worth interviewing was made well before that call. If you’re being offered an interview: Congratulations, you've already passed that bar</p><p>Now the recruiter wants to work <em>with</em> you. Their whole job is to, you know, recruit. They know that you statistically have poor interview prep skills, and are happy to help fix that flaw. Why discard strong candidates who can’t interview well? They’ll level the playing field by helping everyone show their best selves when interviewing.</p><p><strong>How can you take advantage of this?</strong></p><p>Ask them questions! Things like:</p><ul><li>“What should I do to prepare for the interview?”</li><li>“What are the company values that would be good to highlight during the interview?”</li></ul><p>And be forthright about any problems you run into:</p><ul><li>If you get sick the day before the interview, call up the recruiter and ask to reschedule. They want to test you when you're at your best!</li><li>Work pressures left you with no time to prepare? You can still try rescheduling. At worst they'll say "sorry, we can't do that". It will not hurt your chances of getting in</li></ul><p>Your mad technical skills no longer matter to them. If anything, humility and an openness to learning will show you in the best light.</p><h2 id="tip-2-go-to-real-interviews-for-practice">Tip #2: Go to real interviews for practice</h2><p>You need to build up your interviewing skills. LeetCode is great, but it doesn’t come close to the real thing. Try to interview at actual companies as much as possible. And don't limit yourself to the companies you care about.</p><p><strong>Learn to deal with pressure</strong></p><p>When you're in a real interview the world changes: You're locked in a cage with a lion. Every heartbeat is a gorilla bashing against the walls. Your mental gears gunk up as your body goes into fight or flight mode. Your clammy hands struggle to write half legible code on the white board. A threat hides behind every shadow. Even an innocuous "Would you like something to drink?" is a nefarious test: do I pick coke or coffee?</p><p>You only get that experience in a real interview. And only real interviews teach you how to deal with it. The first interview will kick your ass. So will the second. But once you get a few under your belt you'll get used to the adrenaline rush. Perhaps enjoy it even. You'll become a bullfighter, confidently facing down the charging bull. That’s how you get over the fear.</p><p>You may even find that these practice interviews are much easier! When the stakes are low that lion doesn't look so fierce. I've found that I perform the best in the interviews where I don't care about the outcome. I'm much more relaxed and at ease. I can think faster, my brain reaches out to more possibilities. Now, even in important interviews I try to convince myself that I don't really care. That mindset shift is only possible because I got to experience it in the low stakes games first.</p><p><strong>Learn to answer the more ambiguous questions</strong></p><p>And what about the questions? After each interview write down all the questions you were asked. The same evening look over the questions while they’re still fresh in your mind. Focus especially on the behavioral and design ones which have no clear right answer. Consider how you could have responded better. Are there stories from your life you could have referenced? Wait a few days and look at them again. You’ll find better answers.</p><p>Each answer you prepare this way becomes a blob of paint on your pallet. Chances are high that you'll come across similar questions in future interviews. Over time you'll be able to mix the answers from your pallet to paint a picture highlighting how your abilities make you a valuable asset to the company.</p><p><strong>Stay open to serendipity</strong></p><p>As you do these interviews, you may discover that the “practice” company is actually interesting after all. Recruiters count on that. I’ve had recruiters suggest I interview even when I told them I didn’t find the company interesting. “Maybe you’ll change your mind after seeing us up close”, they suggest.</p><p>And I did. More than once.</p><h2 id="tip-3-be-open-to-learning-during-the-interview">Tip #3: Be open to learning during the interview</h2><p>I learned this one by accident, but boy does it pay off.</p><p>In a college career fair once I was walking through the booths with my bag full of swag. My eyes caught a pile of rubik’s cubes being given away by some company I'd never heard of. I wanted one! Of course I couldn't just go up and ask for it directly, so I went and chatted with the guy manning the booth. His name was Vince. A few minutes later I walked away with my prized rubik's cube in hand. That evening I got a call from Vince offering to conduct a full interview loop on campus. I already had a job offer from a company I liked, but I thought "Sure, why not? I could use the experience"</p><p>I had no intention of joining the company, they were some boring finance business. There was nothing to lose. So during the interview I felt free to ask any question I wanted. When I thought I got the answer to an interview question wrong, I'd ask "I don't think I did so great here. What's the right answer to this problem?" (I wanted to learn the answer for future interviews!). When I was asked a challenging question I could grin and delight in the problem solving aspect instead of worrying about how badly it would reflect on me. (Remember my smart aleck remark in the intro? That was this interview.)</p><p>Turns out they liked that: the next day I had a second job offer. At a significantly higher salary than my first one. Oh, and they wanted to fly me to New York in two weeks for an introduction to the company. I still didn’t want to join, but a free trip to New York? Sign me up! The company's name: Bloomberg</p><p>Bloomberg was a practiced hand at recruiting. They had a full two days of events to leave us starry eyed about the company (I came thiiiiis close to accepting their offer). While there, Vince told me I’d made a great impression by fearlessly asking questions, even when I was stumped.</p><p>Since then I’ve stopped hesitating before asking any question in an interview. Let your curiosity run free! Don’t cage it! And as an interviewer, I can attest: sincere interest is always a good sign.</p><h2 id="tip-4-keep-your-skills-sharp-even-when-you-re-not-job-hunting">Tip #4: Keep your skills sharp even when you’re not job hunting</h2><p><a href="https://twitter.com/docjamesw">James Whittaker</a> recommends trying to get a job offer every year, just to make sure you can.</p><p>It's an extremely liberating feeling knowing that even if you lose your job you'll be able to find another one quickly. That's a huge stress off your back.</p><p>I haven't been very good about this myself, but every once in a while I'll accept an invitation from a recruiter (it helps to set up your LinkedIn account). I don't bother doing any prep for these interviews, at least not initially. Those interviews show me the areas I need to brush up on or where the industry practices are changing.</p><p>For example, in a tech screen I did last summer there was some miscommunication and I didn’t realize they expected actual working code. Instead of the usual pseudocode written in a google doc, the interviewer told me to select my language of choice on an online IDE. Now, I don't have a particular language I consider myself super proficient in. I touch many different tools at work and end up having to use a different language about every 5 months. So even basic things like "create an array" tends to require googling the syntax. Given that, what's my favorite language of choice? C#, hands down. So I selected that.</p><p>What hadn't occurred to me at the time is that C# is a very verbose language which Visual Studio beautifully automates away the tedious parts of. This online IDE automated nothing. Even for a basic task like creating an array I had to spend precious interview minutes looking up the right package to import and the exact syntax to use. Needless to say, I ran out of time. I crashed and burned there, but it opened my eyes to the way interviews are changing and how I needed to prepare in the future.</p><p>Four months later a company called Stripe reached out to me. They also expect you to write working code and even let you use your own IDE. This time I was ready. And now I work there. (Psst, <a href="https://stripe.com/jobs/search">we're hiring</a>…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares/">https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25519718</guid>
            <pubDate>Wed, 23 Dec 2020 17:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anti-diarrhoea drug drives cancer cells to cell death]]>
            </title>
            <description>
<![CDATA[
Score 347 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25518831">thread link</a>) | @gmays
<br/>
December 23, 2020 | https://aktuelles.uni-frankfurt.de/englisch/anti-diarrhoea-drug-drives-cancer-cells-to-cell-death/ | <a href="https://web.archive.org/web/*/https://aktuelles.uni-frankfurt.de/englisch/anti-diarrhoea-drug-drives-cancer-cells-to-cell-death/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">

				
<article id="post-48447">

	
	
	
<div><figure><img src="https://aktuelles.uni-frankfurt.de/wp-content/uploads/2020/12/beitragsbild_durchfallmittel-krebszellen.jpg" alt="" srcset="https://aktuelles.uni-frankfurt.de/wp-content/uploads/2020/12/beitragsbild_durchfallmittel-krebszellen.jpg 650w, https://aktuelles.uni-frankfurt.de/wp-content/uploads/2020/12/beitragsbild_durchfallmittel-krebszellen-300x208.jpg 300w" sizes="(max-width: 650px) 100vw, 650px"><figcaption><em>In glioblastoma cells, the antidiarrheal drug loperamide triggers the degradation of the endoplasmic reticulum. In the normal state, it is coloured yellow in these microscopic images. In the degradation state, it glows as a red signal (marked with arrows). Left scale bar: 20 µm, right scale bar (inset): 5 µm (Photos: Svenja Zielke et. al.)</em></figcaption></figure></div>



<p><strong>In cell culture,
loperamide, a drug commonly used against diarrhoea, proves effective against
glioblastoma cells. A research team at Goethe University has now unravelled the
drug’s mechanisms &nbsp;of action of cell
death induction and – in doing so – has shown how this compound could help attack
brain tumours that otherwise are difficult to treat.</strong></p>



<p>The research group led by Dr Sjoerd van Wijk from the Institute of Experimental Cancer Research in Paediatrics at Goethe University already two years ago found evidence indicating that the anti-diarrhoea drug loperamide could be used to induce cell death in glioblastoma cell lines. They have now deciphered its mechanism of action and, in doing so, are opening new avenues for the development of novel treatment strategies.</p>







<h3><strong>When cells digest themselves</strong></h3>



<p>In certain types of tumour cells, administration
of loperamide leads to a stress response in the endoplasmic reticulum (ER), the
cell organelle responsible for key steps in protein synthesis in the body. The
stress in the ER triggers its degradation, followed by self-destruction of the
cells. This mechanism, known as autophagy-dependent cell death occurs when
cells undergo hyperactivated autophagy. Normally, autophagy regulates normal
metabolic processes and breaks down and recycles the valuable parts of damaged
or superfluous cell components thus ensuring the cell’s survival, for example
in the case of nutrient deficiency. In certain tumour cells, however, hyperactivation
of autophagy destroys so much cell material that they are no longer capable of
surviving.</p>



<p>“Our experiments with cell lines show that
autophagy could support the treatment of glioblastoma brain tumours,” says van
Wijk. Glioblastoma is a very aggressive and lethal type of cancer in children
and adults that shows only a poor response to chemotherapy. New therapeutic
approaches are therefore urgently required. The research group led by van Wijk
has now identified an important factor that links the ER stress response with
the degradation of the ER (reticulophagy):&nbsp;
The “Activating Transcription Factor” ATF4 is
produced in increased amounts both during ER stress and under the influence of
loperamide. It triggers the destruction of the ER membranes and thus of the ER.</p>







<h3><strong>Anti-diarrhoea drug
triggers cell death in glioblastoma cells</strong></h3>



<p>“Conversely, if we block ATF4, far fewer
cells in a tumour cell culture die after adding loperamide,” says van Wijk,
describing the control results. In addition, the research group was able to detect
ER debris in loperamide-treated cells under the electron microscope. “ER
degradation, that is, reticulophagy, visibly contributes to the demise of
glioblastoma cells,” says van Wijk. The team also showed that loperamide triggers
only autophagy but not cell death in other cells, such as embryonic mouse
fibroblasts. “Normally, loperamide, when taken as a remedy against diarrhoea,
binds to particular binding sites in the intestine and is not taken up by the
bowel and is therefore harmless”.</p>







<h3><strong>Mechanism of action
also applicable to other diseases</strong></h3>



<p>The loperamide-induced death of
glioblastoma cells could help in the development of new therapeutic approaches
for the treatment of this severe form of cancer. “However, our findings also
open up exciting new possibilities for the treatment of other diseases where ER
degradation is disrupted, such as neurological disorders or dementia as well as
other types of tumour,” says van Wijk. However, further studies are necessary before
loperamide can actually be used in the treatment of glioblastoma or other
diseases. In future studies it has to be explored, for example, how loperamide
can be transported into the brain and cross the blood-brain barrier.
Nanoparticles might be a feasible option. The research team in Frankfurt now wants
to identify other substances that trigger reticulophagy and examine how the
effect of loperamide can be increased and better understood.</p>



<p>The research group led by Sjoerd van Wijk
is funded by the Frankfurt Foundation for Children with Cancer (<em>Frankfurter
Stiftung für krebskranke Kinder</em>) and the Collaborative Research Centre 1177
“Molecular and Functional Characterisation of Selective Autophagy” funded by
the German Research Foundation (Deutsche Forschungsgemeinschaft). The work is
the result of collaboration with Dr Muriel Mari and Professor Fulvio Reggiori
(University of Groningen, The Netherlands) and Professor Donat Kögel
(Experimental Neurosurgery, Goethe University).</p>



<p><strong>Publication:
</strong>Svenja Zielke, Simon Kardo, Laura Zein,
Muriel Mari, Adriana Covarrubias-Pinto, Maximilian N. Kinzler, Nina Meyer,
Alexandra Stolz, Simone Fulda, Fulvio Reggiori, Donat Kögel and Sjoerd van
Wijk: <strong>ATF4 links ER stress with
reticulophagy in glioblastoma cells</strong>. Taylor &amp; Francis Online <a href="https://doi.org/10.1080/15548627.2020.1827780">https://doi.org/10.1080/15548627.2020.1827780</a></p>

	
	
	
	
	
	
</article><!-- #post-48447 -->
				

			</div></div>]]>
            </description>
            <link>https://aktuelles.uni-frankfurt.de/englisch/anti-diarrhoea-drug-drives-cancer-cells-to-cell-death/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25518831</guid>
            <pubDate>Wed, 23 Dec 2020 15:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India’s booming dark data economy]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25517476">thread link</a>) | @CapitalistCartr
<br/>
December 23, 2020 | https://restofworld.org/2020/all-the-data-fit-to-sell/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/all-the-data-fit-to-sell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>A</span>yushi Sahu was ambushed. One evening in 2018, five months after her wedding, the 21-year-old college student was visiting her parents in the central Indian state of Chhattisgarh, when her husband showed up unannounced, his father and uncle in tow.</p>



<p>As the men settled in the living room, her husband said he had something he wanted them to hear. He took out his mobile phone and pressed “play.” The audio was loud and clear: private conversations between Sahu and her friends and family,<strong> </strong>which had been recorded without her permission. And it wasn’t only audio: “call logs, SMS, and WhatsApp messages, each photo and video, recordings of my video calls — he claimed to have accessed everything,” Sahu said. That was when she realized that her husband had, for months, been spying on her.</p>



<p>This was also how Sahu learned of certain things he had been holding against her. (Her name has been changed to protect against retaliation.) He had been offended to hear her complaining to her mother about problems with her in-laws. And he objected to her talking to a male friend. “He made a scene as if he was ‘exposing’ me,” Sahu recalled. “I was just sharing my concerns. That’s normal.”</p>



<p>Her husband played several more recordings, until his father eventually intervened. “I don’t want to listen to any more of this. You have heard it all? Okay, then,” he said, before reaching out to comfort Sahu, who was still in shock.</p>



<p>After processing the experience, Sahu decided she was willing to shrug it off, apologize, and move on, but her new husband continued to behave strangely. Eventually, she felt she had no choice but to end the marriage. “I don’t understand why he had to take this spying route,” she reflected. “He could have just asked. You know, in India, men can scold their wives, right? He could have done that. What was the need to go so deep into my phone and record my conversations?”</p>



<p>Sahu has no idea how her phone was bugged or for how long she was surveilled. But she has one clue: Her Vivo smartphone was an engagement gift from her husband.</p>



<p>It is likely that Sahu’s phone had off-the-shelf spyware on it. Her husband may have installed it himself or even consulted a private detective before marrying her, who provided him with the phone. In either case, he would have been part of a growing trend of individuals — often, jealous lovers — making use of personal surveillance technology.</p>



<p>According to Kunwar Vikram Singh, the chairman of the Association of Private Detectives and Investigators in India, it’s now common for wealthy families to assess the suitability of a potential bride or groom by hiring a private detective, a vetting that usually costs around $500. He attributes this to India’s changing social mores, especially among urban elites. “Work culture has changed. Values have changed,” Singh reflected, citing the influx of women into the workforce as one contributing factor. “We tell people, ‘You spend lakhs and crores on marital ceremonies; spend a few thousand on investigators’,” he said.</p>



<p>Whatever the reason, India’s private-detective services have been growing over the past decade. Singh estimates that the sector is now worth roughly $1.2 billion<strong> </strong>nationally. But because of the sensitive nature of the field, it’s impossible to know for sure: There are no official statistics, and many clients still pay in cash. “They don’t want to leave any footprint,” he noted.</p>



<p>The services offered by the detectives mainly fall into two categories: corporate and personal. The corporate investigations often involve banks hiring investigators to get information on shifty borrowers and financial firms looking for background checks on employees. The personal services range from child monitoring to matrimonial background checks. Every agency has its own specialization. Karnam Choudhary, a Jaipur-based detective who operates the Siyol Detective Network, which has around 1,500 freelance private investigators across the country, says that “since 2016, personal cases make up almost 70%.”</p>



<p>The boom in business has coincided with a growing reliance on consumer-grade spyware. These are mostly smartphone apps that cannot easily be detected, secretly record all of a device’s activity, and route that data to a third-party dashboard. A private investigator’s first move used to be shadowing somebody in person; today, many of them begin by advising the client to present the object of their suspicion with a malware-infected smartphone.</p>



<p>Growing demand for spyware first caught the attention of India’s software engineers several years ago, long before the coronavirus pandemic led to a spike. In 2013, while researching viruses and cybersecurity for his final-year engineering project, Gujarat-based coder Tushar Mepani began meeting parents who wanted to keep closer tabs on their teenagers’ whereabouts. “I could not sleep at night when these millionaires told me about their kids’ behavior,” he said, apparently in earnest. The initial prototype of <a href="http://www.convants.com/">what became his first app for tracking children</a>, EasySpyPhone, was restricted to recording calls and collecting text messages and location data, but more recent iterations can spy on social media platforms like Facebook and WhatsApp, secretly turn on a phone’s microphone to record calls and video, and capture screenshots, all for around $20 or $40 per month. “Parents were very happy,” Mepani reflected. “They learned who their kids are friends with — and who is diverting them. The app has saved kids from being spoiled.”</p>



<figure><blockquote><p>“We had no idea at the time whether people would be interested in this, but it clicked with users.”</p></blockquote></figure>



<p>Mepani doesn’t sell only one or two products, however; through his Android spyware company, Convants Information Security, he licenses surveillance software to multiple vendors, who repackage it under different names. He won’t reveal the details of these arrangements, calling them “internal business,” but he claims to have made more than 20,000 sales. In 2014, Choudhary, the Jaipur-based detective, used Mepani’s software to launch his <a href="http://spymobileprocess.com/">agency’s own app, Spy Mobile Process</a>. Instead of paying for a full investigation, those who buy Choudhary’s app may use it to conduct their own inquiries, with guidance from detectives. “We had no idea at the time whether people would be interested in this,” he said. “But it clicked with users.”</p>



<p>All of this exists in a legal gray area. As of now, there are no laws in India regulating the selling or purchasing of so-called stalkerware. Nor is there much clarity about the privacy laws currently on the books. In India, it is not illegal to physically surveil a target, for instance, but things get fuzzier when it comes to tracking somebody’s location via mobile phone. Courts have been forced to establish statutes, case by case. In 2018, for instance, a family court in Delhi <a href="https://theprint.in/judiciary/evidence-collected-in-breach-of-privacy-does-not-make-it-inadmissible-in-court-delhi-hc/452288/">admitted evidence collected from spyware</a> in a case concerning a marital dispute, stating that the right to a fair trial outweighed privacy protections.</p>



<p>But staying on the right side of the law doesn’t seem to trouble many spyware vendors. Insofar as they are concerned about legal exposure, most will simply add disclaimers that place the onus on the user. Before installing software, the customer should get “proper written consent to do so by the owner of the smartphone” and understand that it is the “responsibility of the buyer to obey all laws of their country.”</p>



<p>In August 2020, Google introduced a new Ads Policy imposing restrictions on advertising for spyware and surveillance technology. “The updated policy will prohibit the promotion of products or services that are marketed or targeted with the express purpose of tracking or monitoring another person or their activities without their authorization,” the company wrote in its updated policy. However, Google made two exceptions: “private investigation services,” like Choudhary’s, and “products or services designed for parents to track or monitor their underage children,” like Mepani’s.</p>



<p>Private detectives who admit to using spyware almost universally insist that any problems stemming from it are the result of abuse. But what they say publicly is one thing, and how they market their services is another. While Choudhary claims his app is not intended for spying on spouses, a <a href="https://twitter.com/Siyol007/status/670517689576726528?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed&amp;ref_url=notion%3A%2F%2Fwww.notion.so%2FSahil-Chajotra-JK-detectives-0f27a3d4a117474eac2b15f591b5d764">November 2015 tweet</a> from his company’s official account said just the opposite. In a series of phone interviews, Mepani also denied marketing his product to jealous husbands and wives, even as his website made clear that these are target demographics. “But you know,” he added, “it is like a knife. You can cut fruits, or you can cut someone’s head.”</p>



<p>However unsettling, the spyware sector is only one small part of a much vaster infrastructure. More than 500 million people in India use the internet every month, creating troves of private information with every click, scroll, swipe, and download. What they watch, how they date, whom they work for, and where they spend their money is constantly being captured and monetized. All this has given rise to a multimillion-dollar dark data economy, in which no piece of information is too personal to trade.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-40x18.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-400x177.png 400w, https://restofworld.org/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-600x265.png 600w, https://restofworld.org/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-1000x442.png 1000w, https://restofworld.org/wp-content/uploads/2020/12/carlo-cadenas-india-data-brokers-inline-2-1-1600x708.png 1600w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>The black market</strong> for data, as it exists online in India, resembles those for wholesale vegetables or smuggled goods. Customers are encouraged to buy in bulk, and the variety of what’s on offer is mind-boggling: There are databases about parents, cable customers, pregnant women, pizza eaters, mutual funds investors, and almost any niche group one can imagine. A typical database consists of a spreadsheet with row after row of names and key details: Sheila Gupta, 35, lives in Kolkata, runs a travel agency, and owns a BMW; Irfaan Khan, 52, lives in Greater Noida, and has a son who just applied to engineering college. The databases are usually updated every three months (the older one is, the less it is worth), and if you buy several at the same time, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/all-the-data-fit-to-sell/">https://restofworld.org/2020/all-the-data-fit-to-sell/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/all-the-data-fit-to-sell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25517476</guid>
            <pubDate>Wed, 23 Dec 2020 13:35:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BlocklySQL: A new block-based editor for SQL]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25517043">thread link</a>) | @leeuw01
<br/>
December 23, 2020 | https://www.dbinf.informatik.uni-wuerzburg.de/google-blockly-4efa0da/sql/index.html | <a href="https://web.archive.org/web/*/https://www.dbinf.informatik.uni-wuerzburg.de/google-blockly-4efa0da/sql/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    

    

    

    

    

    

    <div id="diagramDiv">
        <p>Class diagramm:</p>
        <p><img src="https://www.dbinf.informatik.uni-wuerzburg.de/classicmodels/classicmodels.JPG" alt="Classicmodels Class diagramm">
    </p></div>

    

    




</div>]]>
            </description>
            <link>https://www.dbinf.informatik.uni-wuerzburg.de/google-blockly-4efa0da/sql/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25517043</guid>
            <pubDate>Wed, 23 Dec 2020 12:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building My Own Chess Engine]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25516430">thread link</a>) | @rbanffy
<br/>
December 23, 2020 | https://healeycodes.com/building-my-own-chess-engine/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/building-my-own-chess-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 20, 2020<!-- --> in<!-- --> <span><a href="https://healeycodes.com/tags/python">Python</a></span></p></header><section><p>I have been learning chess (again) and how to program a chess engine (for the first time) over the last month. After skimming some introductory texts, I was convinced that building a simple chess engine — one that would put up a fair fight against a casual player — would take no more than a few days.</p>
<p>I was wrong.</p>
<p>But I made it there in the end and created a toy chess engine (<a href="https://github.com/healeycodes/andoma">healeycodes/andoma</a>) that I am proud of. It can play a game of chess and solve simple chess puzzles like mate-in-two or mate-in-three. It has a slim UCI interface which means it can be hooked up to lichess.org via <a href="https://github.com/ShailChoksi/lichess-bot">lichess-bot</a> — a bridge between the lichess API and chess bots.</p>
<p>The first speed bump in its development was grasping the computational the complexity of chess — how fast, and wide, the search tree grows. When a chess game starts, white can open in twenty different ways and black can respond in twenty different ways also. After the first full turn, there are 400 variations possible. After the third full turn, there are <a href="https://en.wikipedia.org/wiki/Shannon_number#Shannon's_calculation">over 119 million</a>.</p>
<p>Claude Shannon calculated that there are around <code>10^120</code> possible games of chess in his seminal paper <em>Programming a Computer for Playing Chess</em> in 1950. In <em>Rage Against the Machines</em>, Nate Silver <a href="https://fivethirtyeight.com/features/rage-against-the-machines/">quotes</a> Diego Rasskin-Gutman, who said:</p>
<blockquote>
<p>There are more possible chess games than the number of atoms in the universe.</p>
</blockquote>
<p>Given unlimited resources, it actually doesn’t take many lines of code to calculate every legal variation of chess. Here, the Python package <a href="https://python-chess.readthedocs.io/en/latest/">python-chess</a> is used for board representation and legal move generation.</p>
<div data-language="python"><pre><code><span>from</span> chess <span>import</span> Board<span>,</span> Move<span>,</span> STARTING_FEN


positions <span>=</span> <span>{</span><span>}</span>


<span>def</span> <span>generate_tree</span><span>(</span>fen<span>)</span><span>:</span>
    board <span>=</span> Board<span>(</span>fen<span>)</span>
    legal_moves <span>=</span> <span>list</span><span>(</span>board<span>.</span>legal_moves<span>)</span>
    <span>if</span> fen <span>in</span> positions<span>:</span>
        positions<span>[</span>fen<span>]</span> <span>+=</span> legal_moves
    <span>else</span><span>:</span>
        positions<span>[</span>fen<span>]</span> <span>=</span> legal_moves

    <span>for</span> move <span>in</span> legal_moves<span>:</span>
        board<span>.</span>push<span>(</span>move<span>)</span>
        next_fen <span>=</span> board<span>.</span>fen<span>(</span><span>)</span>
        board<span>.</span>pop<span>(</span><span>)</span>
        
        generate_tree<span>(</span>next_fen<span>)</span>

<span>try</span><span>:</span>
    generate_tree<span>(</span>STARTING_FEN<span>)</span>
<span>except</span> RecursionError<span>:</span> 
    <span>print</span><span>(</span><span>len</span><span>(</span>positions<span>)</span> <span>+</span> <span>sum</span><span>(</span><span>len</span><span>(</span>p<span>)</span> <span>for</span> p <span>in</span> positions<span>)</span><span>)</span></code></pre></div>
<p>This program throws a <code>RecursionError</code> and prints <code>59691</code> — the number of different positions the search tree contained when it crashed. All we need to fix this, is another universe to run the program in.</p>
<p>Given that there are computational limits to abide by, as well as the time control rules of chess, improvements over a naive brute force search must be made.</p>
<h2 id="evaluation"><a href="#evaluation" aria-label="evaluation permalink"></a>Evaluation</h2>
<p>In order to search for good positions, it is necessary to understand what makes a good position <em>good</em>. The most simplistic way of describing a position’s strength is to compare the total value material of each side.</p>
<p>Tomasz Michniewski, author of the <a href="https://www.chessprogramming.org/Simplified_Evaluation_Function">Simplified Evaluation Function</a>, defined some values that are “designed specifically to compensate for the lack of any other chess knowledge”. This is perfect for me — a beginner chess player.</p>
<p>This snippet sums the material on the initial board using Michniewski’s piece values.</p>
<div data-language="python"><pre><code><span>import</span> chess

piece_values <span>=</span> <span>{</span>
    chess<span>.</span>PAWN<span>:</span> <span>100</span><span>,</span>
    chess<span>.</span>ROOK<span>:</span> <span>500</span><span>,</span>
    chess<span>.</span>KNIGHT<span>:</span> <span>320</span><span>,</span>
    chess<span>.</span>BISHOP<span>:</span> <span>330</span><span>,</span>
    chess<span>.</span>QUEEN<span>:</span> <span>900</span><span>,</span>
    chess<span>.</span>KING<span>:</span> <span>20000</span>
<span>}</span>

board <span>=</span> chess<span>.</span>Board<span>(</span>chess<span>.</span>STARTING_FEN<span>)</span>
white_material <span>=</span> <span>0</span>
black_material <span>=</span> <span>0</span>

<span>for</span> square <span>in</span> chess<span>.</span>SQUARES<span>:</span>
    piece <span>=</span> board<span>.</span>piece_at<span>(</span>square<span>)</span>
    <span>if</span> <span>not</span> piece<span>:</span>
        <span>continue</span>
    <span>if</span> piece<span>.</span>color <span>==</span> chess<span>.</span>WHITE<span>:</span>
        white_material <span>+=</span> piece_values<span>[</span>piece<span>.</span>piece_type<span>]</span>
    <span>else</span><span>:</span>
        black_material <span>+=</span> piece_values<span>[</span>piece<span>.</span>piece_type<span>]</span></code></pre></div>
<p>Michniewski also provides <a href="https://www.chessprogramming.org/Piece-Square_Tables">piece-square tables</a>, which alter the value of a piece depending on which square it sits on. For example, it’s better for pawns to progress up the board and it’s better for knights to be near the center of the board.</p>
<p>The bonus of a square may be positive, neutral, or negative. The piece-square tables are presented from White’s POV and must be mirrored for Black.</p>
<div data-language="text"><pre><code># a knight's bonuses depending on square
-50,-40,-30,-30,-30,-30,-40,-50,
-40,-20,  0,  0,  0,  0,-20,-40,
-30,  0, 10, 15, 15, 10,  0,-30,
-30,  5, 15, 20, 20, 15,  5,-30,
-30,  0, 15, 20, 20, 15,  0,-30,
-30,  5, 10, 15, 15, 10,  5,-30,
-40,-20,  0,  5,  5,  0,-20,-40,
-50,-40,-30,-30,-30,-30,-40,-50,</code></pre></div>
<p>For the king, Michniewski provides two tables — one for the middle game and one for the end game. He defines the end game as being either if:</p>
<blockquote>
<p>Both sides have no queens or</p>
</blockquote>
<blockquote>
<p>Every side which has a queen has additionally no other pieces or one minorpiece maximum.</p>
</blockquote>

<p>The evaluation of a chess board is one of the things that’s kept me interested in chess engines. Evaluation rules are easy to add and take away. I refactored the code from Go to Python to be able to prototype different rules faster.</p>
<p>After piece-square tables, one might look at pawn structure, mobility, center control, connectivity, trapped pieces, king safety, space, tempo, and other patterns (this list is taken from the Chess Programming Wiki’s <a href="https://www.chessprogramming.org/Evaluation">Evaluation</a> page).</p>
<h2 id="searching-with-minimax"><a href="#searching-with-minimax" aria-label="searching with minimax permalink"></a>Searching With Minimax</h2>
<p><a href="https://en.wikipedia.org/wiki/Minimax">Minimax</a> is a search algorithm that finds the next optimal move by minimizing the potential loss in a worst case scenario. Chess is a game of perfect information — by looking at the board it’s possible to know exactly what an opponent is capable of. However, this search for moves is limited by the evaluation function and the depth that computing resources are able to reach.</p>
<p>The search space is a tree of legal moves which grows exponentially at every level (the average branching factor is around 35). By the time the tree is explored, the path to many future boards is known as well as which path restricts the opponent’s possible gains the most.</p>
<p>The leaf nodes of the tree return the evaluation of their current state. Non-leaf nodes inherit their value from a descendant node. Eventually, the recursive function reduces down to a value for the given board.</p>
<p>This function can be used to pick the next best move by calling it on every legal move available in the current turn. A great visual resource for this algorithm is Sebastian Lague’s <a href="https://www.youtube.com/watch?v=l-hh51ncgDI">Algorithms Explained – minimax and alpha-beta pruning</a>.</p>
<div data-language="python"><pre><code><span>def</span> <span>minimax</span><span>(</span>board<span>,</span> depth<span>,</span> maximizing_player<span>)</span><span>:</span>
    <span>if</span> depth <span>==</span> <span>0</span> <span>or</span> board<span>.</span>is_game_over<span>(</span><span>)</span><span>:</span>
        <span>return</span> evaluate<span>(</span>board<span>)</span>
    <span>if</span> maximizing_player<span>:</span>
        value <span>=</span> <span>-</span><span>float</span><span>(</span><span>'inf'</span><span>)</span>
        <span>for</span> move <span>in</span> board<span>.</span>legal_moves<span>:</span>
            board<span>.</span>push<span>(</span>move<span>)</span>
            value <span>=</span> <span>max</span><span>(</span>value<span>,</span> minimax<span>(</span>board<span>,</span> depth <span>-</span> <span>1</span><span>,</span> <span>False</span><span>)</span><span>)</span>
            board<span>.</span>pop<span>(</span><span>)</span>
	    <span>return</span> value
    <span>else</span><span>:</span>
        value <span>=</span> <span>float</span><span>(</span><span>'inf'</span><span>)</span>
        <span>for</span> move <span>in</span> board<span>.</span>legal_moves<span>:</span>
            board<span>.</span>push<span>(</span>move<span>)</span>
            value <span>=</span> <span>min</span><span>(</span>value<span>,</span> minimax<span>(</span>board<span>,</span> depth <span>-</span> <span>1</span><span>,</span> <span>True</span><span>)</span><span>)</span>
            board<span>.</span>pop<span>(</span><span>)</span>
        <span>return</span> value</code></pre></div>
<h2 id="alpha-beta-pruning"><a href="#alpha-beta-pruning" aria-label="alpha beta pruning permalink"></a>Alpha-beta pruning</h2>
<p>My chess engine uses <a href="https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">alpha-beta pruning</a> as an improvement over the naive minimax algorithm — which does not fare well against the exponential nature of chess. Branches of the search tree can be eliminated when it is clear that another branch shows more promise. This significantly reduces the number of moves required to be generated.</p>
<p><span>
      <a href="https://healeycodes.com/static/a99200aacf6d6cfc643aaa45317d65aa/42a19/alpha-beta-pruning.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Branches of a minimax search tree being stopped early" title="Branches of a minimax search tree being stopped early" src="https://healeycodes.com/static/a99200aacf6d6cfc643aaa45317d65aa/42a19/alpha-beta-pruning.png" srcset="https://healeycodes.com/static/a99200aacf6d6cfc643aaa45317d65aa/a8a0d/alpha-beta-pruning.png 300w,
https://healeycodes.com/static/a99200aacf6d6cfc643aaa45317d65aa/dface/alpha-beta-pruning.png 600w,
https://healeycodes.com/static/a99200aacf6d6cfc643aaa45317d65aa/42a19/alpha-beta-pruning.png 1024w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
  </a>
    </span></p>
<p>By reducing the depth of branches that will not bear fruit we can search deeper down the better parts of the tree.</p>
<p>The speed of alpha-beta pruning can be increased by applying <a href="https://www.chessprogramming.org/Move_Ordering">move ordering</a>. This is where the more promising branches of the search tree are searched first — which means less time is spent in the worst branches as they will be cut off early.</p>
<p>Move ordering cannot be 100% accurate but it’s a powerful optimization.</p>
<p>In <a href="https://github.com/healeycodes/andoma">my engine</a>, a cheap (but not perfect) <code>move_value</code> function is used to sort the initial legal move nodes from best to worst. The logic of this function is capture in its docstring:</p>
<div data-language="python"><pre><code><span>'''
How good is a move?
A promotion is great.
A weaker piece taking a stronger piece is good.
A stronger piece taking a weaker piece is bad.
Also consider the position change via piece-square table.
'''</span></code></pre></div>
<h2 id="communication-and-the-uci-protocol"><a href="#communication-and-the-uci-protocol" aria-label="communication and the uci protocol permalink"></a>Communication and the UCI Protocol</h2>
<p>The <a href="https://github.com/healeycodes/andoma/blob/main/uci-interface.md">Universal Chess Interface</a> (UCI) is a open protocol to hook up chess engines to user interfaces. The communication is done through standard input and standard output and messages end with <code>\n</code>. The move format is long algebraic notation — like <code>e2e4</code>, or <code>e1g1</code> for white short castling, and an example of a promotion to queen is <code>a7a8q</code>.</p>
<p>There are many configuration commands in the specification and it initially seemed overwhelming. After debugging, I found that not many were required to get a chess engine to the <em>Hello World</em> stage.</p>
<p>In order to hook my chess engine up to lichess via <a href="https://github.com/ShailChoksi/lichess-bot">lichess-bot</a>, I implemented the following. These commands are send to the engine from lichess-bot:</p>
<ul>
<li><code>uci</code> - the engine reports its name, authors, and <code>uciok</code></li>
<li><code>isready</code> - the engine reports that it’s ready: <code>readyok</code></li>
<li><code>position startpos moves e2e4</code> - the engine sets it’s internal state to match the list of moves</li>
<li><code>go</code> - the engine should now calculate and respond with the next best move, like <code>g8f6</code></li>
</ul>
<h2 id="a-promise"><a href="#a-promise" aria-label="a promise permalink"></a>A Promise</h2>
<p>I have found a great joy interacting with the chess community over the last month. Lichess is a fantastic resource and endlessly fun to play on. The UI is slick and light — and the post-match analysis is revealing and simple to use. It’s <a href="https://github.com/ornicar/lila">open source</a> and relies on donations and sponsorships.</p>
<p>I took breaks from writing this article to play chess against Dad on a real board. We’re missing a white rook and use a pencil sharpener as a replacement piece. He has been telling me stories about playing chess decades ago — before IBM’s <a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">Deep Blue</a> emerged and beat Garry Kasparov, the reigning world champion, on its second attempt in 1997.</p>
<p>If you are within my social circle, you will have experienced me evangelizing chess and chess engines over the last month — now that I have published this, I promise to chill out a little bit ♟️</p>
<h2 id="other-resources"><a href="#other-resources" aria-label="other resources permalink"></a>Other Resources</h2>
<p>To build <a href="https://github.com/healeycodes/andoma">healeycodes/andoma</a>, I used the following resources (and recommend all of them).</p>
<ul>
<li><a href="https://www.chessprogramming.org/Main_Page">Chess Programming Wiki</a> — an incredible wealth of knowledge exists here. I spent hours reading through intermediate and advanced concepts just for fun</li>
<li><a href="https://www.youtube.com/watch?v=l-hh51ncgDI">Algorithms Explained – minimax and alpha-beta pruning</a> — Sebastian Lague’s breakdowns …</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://healeycodes.com/building-my-own-chess-engine/">https://healeycodes.com/building-my-own-chess-engine/</a></em></p>]]>
            </description>
            <link>https://healeycodes.com/building-my-own-chess-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25516430</guid>
            <pubDate>Wed, 23 Dec 2020 11:04:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Koans (2013)]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25514238">thread link</a>) | @mmettler
<br/>
December 22, 2020 | https://stevelosh.com/blog/2013/04/git-koans/ | <a href="https://web.archive.org/web/*/https://stevelosh.com/blog/2013/04/git-koans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on April 8th, 2013.</p><p>Inspired by <a href="http://blog.sanctum.geek.nz/vim-koans/">Vim Koans</a>.</p>

<ol><li><a href="#s1-silence">Silence</a></li><li><a href="#s2-one-thing-well">One Thing Well</a></li><li><a href="#s3-only-the-gods">Only the Gods</a></li><li><a href="#s4-the-hobgoblin">The Hobgoblin</a></li><li><a href="#s5-the-long-and-short-of-it">The Long and Short of It</a></li></ol>

<h2 id="s1-silence"><a href="#s1-silence">Silence</a></h2>

<p>A Python programmer handed her <code>~/.gitconfig</code> to Master Git.  Among the many
lines were the following:</p>

<pre><code>[alias]
; Explicit is better than implicit.  If we want to merge
; we should do so ourselves.
pull = pull --ff-only</code></pre>

<p>Master Git nodded.  "<code>git pull origin master</code>," said the programmer.</p>

<p>Master Git pulled down the latest changes on <code>master</code> and automatically merged
them with the programmer's changes.</p>

<p>"But Master Git, did I not say to only fast-forward in my configuration?!" she
cried.</p>

<p>Master Git looked at her, nodded, and said nothing.</p>

<p>"Then why did you not warn me of a problem with my configuration?" she asked.</p>

<p>Master Git replied: "there was no problem."</p>

<p>Months later the programmer was reading <code>git --help config</code> for a different
reason and found enlightenment.</p>

<h2 id="s2-one-thing-well"><a href="#s2-one-thing-well">One Thing Well</a></h2>

<p>A UNIX programmer was working in the cubicle farms.  As she saw Master Git
traveling down the path, she ran to meet him.</p>

<p>"It is an honor to meet you, Master Git!" she said.  "I have been studying the
UNIX way of designing programs that each do one thing well.  Surely I can learn
much from you."</p>

<p>"Surely," replied Master Git.</p>

<p>"How should I change to a different branch?" asked the programmer.</p>

<p>"Use <code>git checkout</code>."</p>

<p>"And how should I create a branch?"</p>

<p>"Use <code>git checkout</code>."</p>

<p>"And how should I update the contents of a single file in my working directory,
without involving branches at all?"</p>

<p>"Use <code>git checkout</code>."</p>

<p>After this third answer, the programmer was enlightened.</p>

<h2 id="s3-only-the-gods"><a href="#s3-only-the-gods">Only the Gods</a></h2>

<p>The great historian was trying to unravel the intricacies of an incorrect merge
that had happened many months ago.  He made a pilgrimage to Master Git to ask
for his help.</p>

<p>"Master Git," said the historian, "what is the nature of history?"</p>

<p>"History is immutable.  To rewrite it later is to tamper with the very fabric of
existence."</p>

<p>The historian nodded, then asked: "Is that why rebasing commits that have been
pushed is discouraged?"</p>

<p>"Indeed," said Master Git.</p>

<p>"Splendid!" exclaimed the historian.  "I have a historical record of a merge
commit with two parents.  How can I find out which branch each parent was
originally made on?"</p>

<p>"History is ephemeral," replied Master Git, "the knowledge you seek can be
answered only by the gods."</p>

<p>The historian hung his head as enlightenment crushed down upon him.</p>

<h2 id="s4-the-hobgoblin"><a href="#s4-the-hobgoblin">The Hobgoblin</a></h2>

<p>A novice was learning at the feet of Master Git.  At the end of the lesson he
looked through his notes and said, "Master, I have a few questions.  May I ask
them?"</p>

<p>Master Git nodded.</p>

<p>"How can I view a list of <em>all</em> tags?"</p>

<p>"<code>git tag</code>", replied Master Git.</p>

<p>"How can I view a list of <em>all</em> remotes?"</p>

<p>"<code>git remote -v</code>", replied Master Git.</p>

<p>"How can I view a list of <em>all</em> branches?"</p>

<p>"<code>git branch -a</code>", replied Master Git.</p>

<p>"And how can I view the current branch?"</p>

<p>"<code>git rev-parse --abbrev-ref HEAD</code>", replied Master Git.</p>

<p>"How can I delete a remote?"</p>

<p>"<code>git remote rm</code>", replied Master Git.</p>

<p>"And how can I delete a branch?"</p>

<p>"<code>git branch -d</code>", replied Master Git.</p>

<p>The novice thought for a few moments, then asked: "Surely some of these could be
made more consistent, so as to be easier to remember in the heat of coding?"</p>

<p>Master Git snapped his fingers.  A hobgoblin entered the room and ate the novice
alive.  In the afterlife, the novice was enlightened.</p>

<h2 id="s5-the-long-and-short-of-it"><a href="#s5-the-long-and-short-of-it">The Long and Short of It</a></h2>

<p>Master Git and a novice were walking along a bridge.</p>

<p>The novice, wanting to partake of Master Git's vast knowledge, said:
"<code>git branch --help</code>".</p>

<p>Master Git sat down and lectured her on the seven forms of <code>git branch</code>, and
their many options.</p>

<p>They resumed walking.  A few minutes later they encountered an experienced
developer traveling in the opposite direction.  He bowed to Master Git and said
"<code>git branch -h</code>".  Master Git tersely informed him of the most common <code>git
branch</code> options.  The developer thanked him and continued on his way.</p>

<p>"Master," said the novice, "what is the nature of long and short options for
commands?  I thought they were equivalent, but when that developer used <code>-h</code> you
said something different than when I said <code>--help</code>."</p>

<p>"Perspective is everything," answered the Master.</p>

<p>The novice was puzzled.  She decided to experiment and said "<code>git -h branch</code>".</p>

<p>Master Git turned and threw himself off the railing, falling to his death on the
rocks below.</p>

<p>Upon seeing this, the novice was enlightened.</p>
</article></div></div>]]>
            </description>
            <link>https://stevelosh.com/blog/2013/04/git-koans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25514238</guid>
            <pubDate>Wed, 23 Dec 2020 03:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things You're Allowed to Do]]>
            </title>
            <description>
<![CDATA[
Score 522 | Comments 407 (<a href="https://news.ycombinator.com/item?id=25513713">thread link</a>) | @thesephist
<br/>
December 22, 2020 | https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/ | <a href="https://web.archive.org/web/*/https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>This is a list of things you’re allowed to do that you thought you couldn’t, or didn’t even know you could.</p>
<p>I haven’t tried everything on this list, mainly due to cost.
But you’d be surprised how cheap most of the things on this list are (especially the free ones).</p>
<p><strong>Note that you can replace “hire” or “buy” with “barter for” or “find a DIY guide to” nearly everywhere below.</strong>
E.g. you can clean the bathroom in exchange for your housemate doing a couple hours research for you.</p>
<h3 id="learning-and-decision-making">Learning and decision making</h3>
<ul>
<li>Hire a researcher or expert consultant
<ul>
<li>I hired a researcher (<a href="https://acesounderglass.com/">Elizabeth Van Nostrand</a>, whom you can and should <a href="https://acesounderglass.com/hire-me/">hire</a> too) to help write this very post, which is largely about how to hire people to do things!</li>
<li>They can:
<ul>
<li>Help validate whether a crazy idea is possible</li>
<li>Do <a href="https://acesounderglass.com/tag/epistemicspotcheck/">epistemic spot checks</a> of your work</li>
<li>Map the landscape of opinions on a topic</li>
<li>Write literature surveys</li>
<li>Find people worth talking to about a potential topic and writing briefs about them</li>
<li>Opposition or market research</li>
<li>Find options for big purchases like houses or insurance</li>
<li>Compile datasets</li>
<li>Find un-Googleable things</li>
</ul>
</li>
<li>To find one:
<ul>
<li>Look for books or scholarly articles on the topic, and email the author
<ul>
<li>Graduate students are especially good, and often know more than the “experts”</li>
<li>If you find someone genuinely interested in what you’re working on, you might be able to collaborate and not pay</li>
</ul>
</li>
<li>Look for interested individuals in the long tail of blogs
<ul>
<li>E.g. by Google searching with <code>"site: medium.com"</code> and finding the authors</li>
</ul>
</li>
<li>Use a matchmaking service (see <a href="#appendix-sources-of-experts">Appendix</a>)</li>
<li>Search through professional organizations directories (e.g. Bar Association, American Academy of Pediatrics)</li>
<li>Google the topic +
<ul>
<li>“blog”</li>
<li>“podcast”</li>
<li>“expert witness”</li>
<li>“book”</li>
<li>“consultant”</li>
<li>“reddit”</li>
</ul>
</li>
</ul>
</li>
<li>What do I pay them?
<ul>
<li>Some post their prices online</li>
<li>If you’re hiring a grad student you can pay them at or above their school’s graduate student stipend, which you can Google.</li>
<li><a href="https://www.lesswrong.com/posts/evyBmPw9ZnzmoFmP6/experiment-a-good-researcher-is-hard-to-find">Make sure they get something out of the project</a> (and other tips)</li>
</ul>
</li>
</ul>
</li>
<li>Ask questions online
<ul>
<li>You know those answers you enjoy reading on Stack Exchange, Reddit, Quora, etc.?  Someone had to ask those questions. It can be you.</li>
<li>If you’re embarrassed by the question, it’s easy to be anonymous</li>
</ul>
</li>
<li>Run surveys
<ul>
<li>Twitter
<ul>
<li>Or ask someone with a larger following to do it</li>
</ul>
</li>
<li>Google Surveys</li>
<li>Amazon Mechanical Turk</li>
</ul>
</li>
<li>Run <a href="https://www.gwern.net/Nootropics#blinding-yourself">genuine randomized control trials on yourself</a></li>
<li>Buy research
<ul>
<li>See <a href="#appendix-sources-of-research">Appendix</a>, <a href="https://blog.alexa.com/sites-for-market-research/">here</a>, or <a href="https://web.jinfo.com/go/blog/73431">here</a></li>
<li>Or find it on <a href="https://twitter.com/Sci_Hub">SciHub</a> or <a href="https://twitter.com/libgen_project">Libgen</a></li>
</ul>
</li>
<li>Hire someone to pentest/doxx you
<ul>
<li>Or put out a bounty for it, like <a href="https://www.gwern.net/Blackmail#pseudonymity-bounty">Gwern used to</a></li>
</ul>
</li>
<li>Hire a graphic designer to turn your appalling sketches into beautiful diagrams or slides</li>
<li>Host small gatherings or conferences on topics you care about
<ul>
<li>These are much easier to set up than you’d think, especially in the age of Zoom</li>
<li>If you can use the gathering to bootstrap a group chat or community, so much the better!</li>
</ul>
</li>
<li>Hire a tutor
<ul>
<li><a href="https://www.italki.com/">Language tutors</a> are surprisingly cheap and better than any app</li>
<li><a href="https://www.wyzant.com/">Wyzant</a> and many other sites exist for general tutoring</li>
<li>For niche tutoring you can try general freelance sites like <a href="https://www.fiverr.com/">Fiverr</a> or <a href="https://www.upwork.com/">Upwork</a></li>
<li>Services like <a href="https://www.sharpestminds.com/">Sharpest Minds</a> exist for professional training</li>
</ul>
</li>
<li>Hire someone just as an excuse to make yourself complete a project
<ul>
<li>Sure you could proofread your own document.  But if you hire a proofreader, you have to actually deliver them something at some point.</li>
</ul>
</li>
</ul>
<h3 id="interpersonal">Interpersonal</h3>
<ul>
<li><a href="https://guzey.com/personal/what-should-you-do-with-your-life/#cold-emails-and-twitter">Cold contact people</a>
<ul>
<li>Yes, even famous people. Just make sure you have something to say.</li>
</ul>
</li>
<li><a href="https://guzey.com/follow-up/">Follow up many times</a>
<ul>
<li>You won’t make people mad if you’re polite.</li>
</ul>
</li>
<li>Just ask for things
<ul>
<li>Free upgrades</li>
<li>Coupons
<ul>
<li>At checkout you can just ask “Do you have any coupons I can apply to this?”</li>
</ul>
</li>
<li>Raises</li>
<li>Better terms in a job offer
<ul>
<li>Easier than asking for a raise - you have more leverage</li>
</ul>
</li>
<li>Waiving admission or graduation requirements</li>
<li>It’s okay if the things are crazy.  You can always mollify afterward by saying “I know that’s a crazy thing to ask for, but I have a rule that I always ask.”</li>
</ul>
</li>
<li><a href="http://mindingourway.com/obvious-advice/">Ask obvious questions</a></li>
<li>Buy goods/services from your friends
<ul>
<li>It’s not weird unless you make it weird</li>
<li>Everyone knows some starving artists and needs to buy holiday gifts</li>
<li>Doesn’t apply to every service obviously: don’t take out loans from your friends</li>
</ul>
</li>
<li>Not tell white lies
<ul>
<li>You can be nice and tell the truth at the same time.</li>
<li>Especially to children when they annoy you.</li>
</ul>
</li>
<li>Say “I don’t know” or “I don’t have an opinion” when you don’t</li>
<li>Ask people out on dates
<ul>
<li>This one might just be directed at young me…</li>
</ul>
</li>
<li>Don’t drink, even when you’re expected to
<ul>
<li>Don’t drink alcohol, I mean.</li>
<li>Actually heck, don’t drink water either if you don’t want.</li>
</ul>
</li>
<li>Travel to friends just to visit them</li>
<li>Move close to friends</li>
<li>Live in multiple places with multiple people
<ul>
<li>Rent spare rooms or couches part-time in multiple homes</li>
<li>Arrange your own timeshare system with friends</li>
</ul>
</li>
<li>Be a nomad</li>
<li>Romance
<ul>
<li>Hire a matchmaker</li>
<li>Buy premium versions of dating apps</li>
<li>Get couples therapy</li>
</ul>
</li>
<li>Give to charity
<ul>
<li>You really can, to the best of our knowledge, <a href="https://www.givewell.org/giving101/Your-dollar-goes-further-overseas">save someone’s (statistical) life</a> with not that much money.
Let that idea really, fully osmose through your brain before you pass it over.</li>
</ul>
</li>
</ul>
<h3 id="support-and-accountability">Support and accountability</h3>
<ul>
<li>Hire a coach
<ul>
<li>For your professional area
<ul>
<li><a href="https://www.newyorker.com/magazine/2011/10/03/personal-best">An Atul Gawande article on the subject</a></li>
<li><a href="https://www.npr.org/2020/02/03/802422904/when-things-click-the-power-of-judgment-free-learning">On clicker training</a></li>
</ul>
</li>
<li>Personal trainer</li>
<li>Nutritionist</li>
<li>Meditation guide</li>
</ul>
</li>
<li>Visit a therapist</li>
<li>Visit a physical therapist</li>
<li>Buy task-specific devices that prevent multitasking
<ul>
<li>Kindle</li>
<li>Freewrite Traveller</li>
<li>Dedicated music players</li>
<li>Dedicated notebooks for specific purposes (day planner, exercise log, etc.)</li>
</ul>
</li>
<li>Engage a human productivity monitor
<ul>
<li>I know two people who have hired people to sit next to them or frequently contact them to keep them on-task</li>
<li>Examples: <a href="https://www.focusmate.com/">focusmate.com</a> and <a href="https://coding-pal.com/">coding-pal.com</a></li>
</ul>
</li>
</ul>
<h3 id="making-the-most-of-your-resources">Making the most of your resources</h3>
<ul>
<li>Grocery delivery</li>
<li>Cleaning services
<ul>
<li>Can be regular or just when you need a big spring clean</li>
<li>Don’t forget carpet and vent cleaning</li>
</ul>
</li>
<li>Laundry service</li>
<li>Nannies over daycare</li>
<li>Modify your stuff
<ul>
<li>Tape over annoying LED lights</li>
<li>Remove logos (<a href="https://www.youtube.com/watch?v=WVeGDitPqKo">example</a>)</li>
<li>Write in books</li>
<li>Rip off tags</li>
<li>Rotate your monitor to portrait</li>
</ul>
</li>
<li>Repair your stuff, or get it repaired
<ul>
<li>Shoes</li>
<li>Clothes</li>
<li>Luggage and <a href="https://rainypass.com/">outdoor gear</a></li>
<li>Furniture</li>
<li>Car
<ul>
<li>You can buy at-home car care</li>
</ul>
</li>
</ul>
</li>
<li>Write on a post-it note affixed to a greeting card rather than on the greeting card itself, so the recipient can throw away the post-it and reuse your card
<ul>
<li>Employ similar logic for any disposable/consumable item</li>
</ul>
</li>
<li>Treat fines like payments
<ul>
<li>E.g. park illegally and let yourself think of the (expected value of the) fine as a parking fee</li>
<li>Obviously don’t break rules that matter like blocking a fire exit</li>
</ul>
</li>
<li><a href="https://donotpay.com/">Contest unjust fines</a></li>
<li>Telemedicine</li>
<li>Surgery for appearance or comfort</li>
<li>At-home vet care</li>
<li>Enroll <a href="https://www.dummies.com/health/how-to-enroll-in-a-clinical-trial/">yourself</a> (or <a href="https://loyalfordogs.com/">your pet</a>) in a clinical trial or research study</li>
<li>Generate your own audiobooks
<ul>
<li><a href="https://gutenbergreloaded.com/collections/all">gutenbergreloaded.com</a></li>
</ul>
</li>
<li>Generate your own ebooks
<ul>
<li><a href="https://1dollarscan.com/">1dollarscan.com</a></li>
</ul>
</li>
<li>Get verbal things written down
<ul>
<li><a href="https://transcribeme.com/">transcribeme.com</a></li>
<li><a href="https://otter.ai/">otter.ai</a></li>
</ul>
</li>
<li>Personal assistant services (or a real PA if you can afford it)
<ul>
<li><a href="https://getmagic.com/">Magic</a>, <a href="https://www.taskrabbit.com/">TaskRabbit</a>, <a href="https://www.fancyhands.com/">Fancy Hands</a>, and similar services can approximate many of these.
There are also more serious services like <a href="https://withdouble.com/">Double</a>.</li>
<li>Manage email</li>
<li>Helping you move</li>
<li>Getting visas and arranging travel</li>
<li>Stand in line for you</li>
<li>Errands</li>
<li>Filing paperwork</li>
</ul>
</li>
<li>And if you grew up in a thrifty family, like me:
<ul>
<li>Paying for parking in convenient location</li>
<li>Hotels where you can sleep comfortably</li>
<li>Non-public transportation, especially when traveling</li>
<li>Buying comfortable mattress, shoes, etc.</li>
<li>Buying clothes for appearance or comfort instead of just the lowest price</li>
<li>Bottled water when you’re thirsty
<ul>
<li>And in general fulfilling any bodily need for &lt; $5 (restrooms, buying a hat when you forgot yours, etc.)</li>
</ul>
</li>
<li>Buy your way out of advertising on e.g. Spotify or YouTube</li>
<li>Actually turn the heat/AC on
<ul>
<li>And in general, <a href="https://radimentary.wordpress.com/2018/01/29/hammertime-day-1-bug-hunt/">being willing to spend a few minutes to fix small annoyances</a></li>
<li>Seriously, just put WD-40 on that squeaky hinge already</li>
</ul>
</li>
</ul>
</li>
</ul>

<ul>
<li>Katja Grace’s <a href="https://meteuphoric.com/2014/03/25/how-to-trade-money-and-time/">How to trade money and time</a></li>
<li>Sam Bowman’s <a href="https://medium.com/@s8mb/things-i-recommend-you-buy-and-use-second-edition-457a8e7163f6">Things I Recommend You Buy and Use</a></li>
<li>Rob Wiblin <a href="https://medium.com/@robertwiblin/things-i-recommend-you-buy-and-use-rob-edition-1d7b2ce27d68">channeling Sam</a></li>
<li><a href="https://www.lesswrong.com/posts/KuFSkLwhSkEZJYALE/collating-widely-available-time-money-trades">Estimated hourly costs of buying free time</a> (see comments)</li>
</ul>
<hr>
<p><em>Thanks to
<a href="https://www.gwern.net/">Gwern</a>,
<a href="https://twitter.com/an1lam">Stephen Malina</a>,
<a href="https://twitter.com/alexeyguzey">Alexey Guzey</a>,
<a href="https://twitter.com/robot__dreams">Elliot Jin</a>,
<a href="https://twitter.com/iandanforth">iandanforth</a>,
<a href="https://twitter.com/jmclulow">Joshua M. Clulow</a>,
<a href="https://twitter.com/K4y1s">Kay</a>,
<a href="https://news.ycombinator.com/user?id=zoba">zoba</a>,
<a href="https://news.ycombinator.com/user?id=ryandrake">ryandrake</a>,
a guy I can’t name who offers “personal assistant concierge services for high-net-worth families,”
and <a href="https://acesounderglass.com/">Elizabeth Van Nostrand</a>
for some of the ideas above.</em></p>
<hr>



<table>
<thead>
  <tr>
    <th>Name</th>
    <th>Type</th>
    <th>Comments</th>
    <th>Target Audience</th>
    <th>URL</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Expertise Finder</td>
    <td>Academics to comment on many subjects</td>
    <td></td>
    <td>Journalists</td>
    <td><a href="https://expertisefinder.com/">link</a></td>
  </tr>
  <tr>
    <td>Womenâ€™s Media Center SheSource</td>
    <td>Women only, focuses on current events and politics</td>
    <td></td>
    <td>Journalists</td>
    <td><a href="https://www.womensmediacenter.com/shesource/">link</a></td>
  </tr>
  <tr>
    <td>National Association of Personal Financial Advisors</td>
    <td>Financial only</td>
    <td>Seems like a low bar to entry</td>
    <td>Journalists</td>
    <td><a href="https://www.napfa.org/newsroom">link</a></td>
  </tr>
  <tr>
    <td>ProfNet</td>
    <td>Wide range of experts</td>
    <td>Owned by PR firm, presumably works for experts more than you</td>
    <td>Journalists</td>
    <td><a href="https://profnet.prnewswire.com/ProfNetHome/What-is-Profnet.aspx">link</a></td>
  </tr>
  <tr>
    <td>Coursera Expert Network</td>
    <td>Academics from top schools only</td>
    <td>Presumably biased towards people who have made Coursera courses</td>
    <td>Journalists</td>
    <td><a href="https://experts.coursera.org/">link</a></td>
  </tr>
  <tr>
    <td>ExpertFile</td>
    <td>Curated experts from universities, institutions, think tanks, associations, companies and other sources</td>
    <td></td>
    <td>Journalists</td>
    <td><a href="https://expertfile.com/">link</a></td>
  </tr>
  <tr>
    <td>GURU</td>
    <td>Aimed mostly at professional expertise (Sales, Marketing, Eng, etc.)</td>
    <td></td>
    <td>Businesses</td>
    <td><a href="https://www.guru.com/">link</a></td>
  </tr>
  <tr>
    <td>Amber Biology</td>
    <td>Biologists only</td>
    <td></td>
    <td>Science projects?</td>
    <td><a href="https://www.amberbiology.com/">link</a></td>
  </tr>
  <tr>
    <td>Help a Reporter Out (HARO)</td>
    <td></td>
    <td>Requires affiliation with a highly ranked website</td>
    <td>Journalists</td>
    <td><a href="https://www.helpareporter.com/">link</a></td>
  </tr>
  <tr>
    <td>Self Improvement Experts Directory</td>
    <td></td>
    <td></td>
    <td>Individuals</td>
    <td><a href="https://www.selfgrowth.com/experts.html">link</a></td>
  </tr>
  <tr>
    <td>JurisPro</td>
    <td>Expert witnesses</td>
    <td></td>
    <td>Lawyers</td>
    <td><a href="https://www.jurispro.com/">link</a></td>
  </tr>
  <tr>
    <td>ForensisGroup</td>
    <td>Expert witnesses</td>
    <td></td>
    <td>Lawyers</td>
    <td><a href="https://www.forensisgroup.com/">link</a></td>
  </tr>
  <tr>
    <td>Expert Institute</td>
    <td>Expert witnesses</td>
    <td></td>
    <td>Lawyers</td>
    <td><a href="https://www.expertinstitute.com/">link</a></td>
  </tr>
</tbody>
</table>                                                                                                                                   


<ul>
<li>Top choices:
<ul>
<li><a href="https://www.ibisworld.com/">IBIS</a></li>
<li><a href="https://profound.com/">Profound</a></li>
<li><a href="https://www.eifl.net/e-resources/research-monitor">Research Monitor</a></li>
<li><a href="https://www.euromonitor.com/store">EuroMonitor</a></li>
</ul>
</li>
<li><a href="https://www.insideview.com/">Inside View</a></li>
<li><a href="https://www.census.gov/">US Census Data</a></li>
<li><a href="https://www.sba.gov/offices/headquarters/oee/resources/2836">SBAâ€™s Office of Entrepreneurship Education Resources</a></li>
<li><a href="http://www.pewresearch.org/">Pew Research Center</a></li>
<li><a href="https://www.statista.com/">Statista</a></li>
<li><a href="https://www.marketresearch.com/">marketresearch.com</a></li>
<li><a href="https://www.plunkettresearch.com/how-to-buy/">Plunkett Research</a></li>
<li><a href="https://market-intelligence.com.au/">The Market Intelligence Co.</a></li>
<li><a href="https://www.jinfo.com/">Jinfo</a></li>
<li><a href="https://www.idc.com/">IDC</a></li>
<li><a href="https://www.gartner.com/en">Gartner</a></li>
<li><a href="https://pitchbook.com/">Pitchbook</a></li>
<li><a href="https://www.crunchbase.com/">Crunchbase</a></li>
</ul>
</article>

        </div></div>]]>
            </description>
            <link>https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25513713</guid>
            <pubDate>Wed, 23 Dec 2020 02:20:13 GMT</pubDate>
        </item>
    </channel>
</rss>
