<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Sep 2020 12:54:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Sep 2020 12:54:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Costs of running a Python webapp for 55k monthly users]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24372084">thread link</a>) | @caspii
<br/>
September 3, 2020 | https://keepthescore.co/blog/posts/costs-of-running-webapp/ | <a href="https://web.archive.org/web/*/https://keepthescore.co/blog/posts/costs-of-running-webapp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

          


<article>
  <header>
    <h2 dir="auto"><a href="https://keepthescore.co/blog/posts/costs-of-running-webapp/">Costs of running a Python webapp for 55k monthly users</a></h2>
    <p><time datetime="2020-09-04T00:00:00+02:00">Fri Sep 4, 2020</time> by Caspar</p>
  </header>
  

<p>How much does running a webapp in production actually cost? Maybe more than you think. Keepthescore.co is a Python flask application running on DigitalOcean and Firebase. It currently has around 55k unique visitors per month, per day it‚Äôs around 3.4k.</p>

<p><img src="https://keepthescore.co/blog/money-tree.jpg" alt="A money tree">
<em>Image by <a href="https://unsplash.com/@micheile">Micheile Henderson</a></em></p>

<p>Here‚Äôs a monthly breakdown with some background information on each cost:</p>

<h3 id="servers-and-database-on-digitalocean">Servers and database on DigitalOcean</h3>

<p><strong>Costs per month: $95</strong></p>

<p>The webapp runs on two identical DigitalOcean servers (4 vCPUs, 8GB RAM, 80GB disk). We use a <a href="https://en.wikipedia.org/wiki/Blue-green_deployment">blue-green deployment</a>, which is a great way of running and hosting a webapp (more on that in a future post) but it does mean that you need 2 identical production servers.</p>

<p>The database is a hosted Postgres instance also on DigitalOcean.</p>

<p>Note: the servers are oversized for the load we‚Äôre currently seeing. The reason for that is that we tried to solve a production issue by increasing the server specs. It didn‚Äôt solve the problem, and now we can‚Äôt down-size the servers without re-provisioning them ü§∑‚Äç‚ôÄÔ∏è.</p>

<hr>

<h3 id="code-repo-on-github">Code repo on GitHub</h3>

<p><strong>Costs per month: $0</strong></p>

<p>This is free. Thanks GitHub!
</p><hr>

<h3 id="amazon-web-services">Amazon Web Services</h3>

<p><strong>Costs per month: $60</strong></p>

<p>We use a reporting tool called <a href="https://www.metabase.com/">Metabase</a> to generate insights and reports from the database. The tool itself is opensource and free, but hosting it is fairly expensive. Currently it runs on an EC2 instance. There are definitely some savings that could be realised here.
</p><hr>

<h3 id="google-cloud">Google Cloud</h3>

<p><strong>Costs per month: $1.32</strong></p>

<p>We use Firebase for the <a href="https://keepthescore.co/basketball-scoreboard/">realtime basketball scoreboard</a>. We also use the Google Sheets API for some custom scoreboards. Overall it must be said that the Google Cloud APIs are great value for money (so far).</p>

<p>We have plans to move away from DigitalOcean and onto Google Cloud infrastructure in the next year.
</p><hr>

<h3 id="dns-hosting">DNS hosting</h3>

<p><strong>Costs per month: $5</strong></p>

<p>Our domain is registered with <a href="https://dnsimple.com/">DNSimple.com</a>.
</p><hr>



<p><strong>Costs per month: $10</strong></p>

<p>Scoreboards and this blog have the option of allowing a discussion on the same page ‚Äì this uses the <a href="https://disqus.com/">Disqus</a> service. Disqus has a free tier but they began showing ads so we were forced to move to the paid tier.</p>

<p>We are planning to move to <a href="https://commento.io/">Commento</a> in the future, which is cheaper, has no ads, and respects your privacy.
</p><hr>

<h2 id="is-it-worth-it-is-there-revenue">Is it worth it? Is there revenue?</h2>

<p>In total that‚Äôs around <strong>$171 USD per month</strong>. If you‚Äôre running a company with employees that would be peanuts, but in this case the cost is being borne by a single indie-developer out of his own pocket.</p>

<p>The bigger issue is that on the revenue side there‚Äôs a big fat zero. This is the reason why we are currently working on monetization. This will include banner ads and payments via Stripe. Expect to see these features land by next week! Anyway, more about that in a future post.</p>

<h2 id="you-are-spending-way-too-much-money">You are spending way too much money!</h2>

<p>This post generated an interesting discussion on <a href="https://news.ycombinator.com/item?id=24372084">Hacker News</a>. One recurring theme
was that our stack is large and expensive and that we could massively reduce costs.</p>

<p>This is true. But here are some things that are also true:</p>

<ul>
<li>‚ÄúReducing costs‚Äù is not our primary objective at the moment: time is more valuable than money right now.</li>
<li>We are not devops experts and optimizing operations takes time.</li>
<li>Our primary objective right now is velocity of product development.</li>
</ul>

<p>There will be a follow up post once we do optimize our stack.</p>

<p>Thanks for listening and so long, üëã</p>


  

  
  <hr>
  
  

</article> 



        </div> <!-- /.blog-main -->

        


      </div> <!-- /.row -->
    </div></div>]]>
            </description>
            <link>https://keepthescore.co/blog/posts/costs-of-running-webapp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24372084</guid>
            <pubDate>Fri, 04 Sep 2020 05:46:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libvirt ‚Äì The Unsung Hero of Cloud Computing (2013)]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24370966">thread link</a>) | @vikrantrathore
<br/>
September 3, 2020 | https://vyomtech.com/2013/12/17/libvirt_the_unsung_hero_of_cloud_computing.html | <a href="https://web.archive.org/web/*/https://vyomtech.com/2013/12/17/libvirt_the_unsung_hero_of_cloud_computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><p><span>December 17, 2013</span>
        </p>
    <div id="libvirt-the-unsung-hero-of-cloud-computing">

<p><img alt="Libvirt The Unsung Hero of Cloud Computing Platforms" src="https://vyomtech.com/_images/libvirt_the_unsung_hero.png"></p><p>Initially my intention was to write an article on <strong>Round up of open source Cloud Management Platforms (CMP)</strong>, but while doing research found one piece of software library so fundamental, that it holds the key to very existence of Cloud Computing services and platforms as we know it today (that includes Amazon AWS, OpenStack and CloudStack). So I decided to postpone my idea and started to write an article on this <strong>Unsung hero of Cloud Computing</strong> called libvirt <a href="#f1" id="id1">[1]</a>, which I believe many people won‚Äôt have heard of. Obviously talking about software library tend to be technical, so this article will have a technical tone, but I will attempt to make it readable for everyone interested in Cloud Computing.</p>
<p>Libvirt is an open source API, daemon and management tool for managing platform virtualzation and these APIs are widely used in the orchestration layer of Cloud Management Platform. Libvirt makes it possible to control and manage millions of compute nodes, storage and network devices via common programmable interface. Its like being able to control and orchestrate fleet of millions of car irrespective of different manufacturer, model, or engine through a common interface from a single car (it can be more then one car for redundancy and high availability). What started as a management API for Xen, today has been extended to support major components of Cloud Computing platforms.</p>
<div id="libvirt-goals-architecture">
<h2>Libvirt Goals &amp; Architecture</h2>
<p>Libvirt defines following terms for its goals <a href="#f2" id="id2">[2]</a>:</p>
<p><img alt="Mapping of libvirt terms to virtualized or containerized physical machine" src="https://vyomtech.com/_images/libvirt_terms_mapping.png"></p><ul>
<li><strong>Node</strong> is a single physical machine.</li>
<li><strong>Hypervisor</strong> is a layer of softeare allowing to virtualize a node in a set of physical machines with possible different configurations that the node itself.</li>
<li><strong>Domain</strong> is an instance of an operating system (or subsystem in case of container virtualization like OpenVZ and lxc) running on a virtualized machine provided by the hypervisor.</li>
</ul>
<p>Based on above terms <strong>‚ÄúThe goal of libvirt is to provide a common and stable layer sufficient to securely manage domains on a node, possibly remote‚Äù</strong>. So libvirt should provide all APIs needed to do the management, such as: provision, create, modify, monitor, control, migrate and stop the domains - within the limits of the support of the hypervisor for those operations. This implies following sub-goals:</p>
<ul>
<li>All API can be carried remotely though secure APIs</li>
<li>While most API will be generic in term of hypervisor or Host OS, some API may be targeted to a single virtualization environment as long as the semantic for the operations from a domain management perspective is clear</li>
<li>the API should allow to do efficiently and cleanly all the operations needed to manage domains on a node, including resource provisioning and setup</li>
<li>the API will not try to provide high level virtualization policies or multi-nodes management features like load balancing, but the API should be sufficient so they can be implemented on top of libvirt</li>
<li>stability of the API is a big concern, libvirt should isolate applications from the frequent changes expected at the lower level of the virtualization framework</li>
<li>the node being managed may be on a different physical machine than the management program using libvirt, to this effect libvirt supports remote access, but should only do so by using secure protocols.</li>
<li>libvirt will provide APIs to enumerate, monitor and use the resources available on the managed node, including CPUs, memory, storage, networking, and NUMA partitions.</li>
</ul>
<p>So libvirt is intended to be a building block for higher level management tools and for applications focusing on virtualization of a single node (the only exception being domain migration between node capabilities which involves more than one node).</p>
<div id="libvirt-driver-based-architecture">
<h3>Libvirt Driver Based Architecture</h3>
<p><img alt="libvirt driver based architecture" src="https://vyomtech.com/_images/libvirt_architecture.png"></p><p>Libvirt to support wide variety of hypervisor implements a driver-based architecture. Based on car analogy, it means delegating the actual implementation of control of different cars to the drivers specifically designed for make, model and engine of the specific car. Libvirt currently supports:</p>
<p><strong>Hypervisor</strong></p>
<ul>
<li>LXC - Linux Containers</li>
<li>OpenVZ</li>
<li>QEMU</li>
<li>Test - Used for testing</li>
<li>UML - User Mode Linux</li>
<li>VirtualBox</li>
<li>VMware ESX</li>
<li>VMware Workstation/Player</li>
<li>Xen</li>
<li>Microsoft Hyper-V</li>
<li>IBM PowerVM (phyp)</li>
<li>Parallels</li>
<li>Remote - Accessing libvirt on remote node through libvirtd (libvirt daemon)</li>
</ul>
<p><strong>Storage</strong></p>
<ul>
<li>Directory backend</li>
<li>Local filesystem backend</li>
<li>Network filesystem backend</li>
<li>Logical Volume Manager (LVM) backend</li>
<li>Disk backend</li>
<li>iSCSI backend</li>
<li>SCSI backend</li>
<li>Multipath backend</li>
<li>RBD (RADOS Block Device) backend</li>
<li>Sheepdog backend</li>
</ul>
<p><strong>Virtual Networks</strong></p>
<ul>
<li>Bridging</li>
<li>NAT</li>
<li>VEPA (Virtual Ethernet Port Aggregator)</li>
<li>VN-LINK</li>
</ul>
</div>
<div id="libvirt-api-structure">
<h3>Libvirt API structure <a href="#f3" id="id3">[3]</a></h3>
<p><img alt="libvirt API structure" src="https://vyomtech.com/_images/libvirt_api_structure.png"></p><p>The figure above shows the five main objects exported by the API:</p>
<dl>
<dt><strong>virConnectPtr</strong></dt>
<dd>Represents the connection to a hypervisor. Use one of the virConnectOpen functions to obtain connection to the hypervisor which is then used as a parameter to other connection API‚Äôs.</dd>
<dt><strong>virDomainPtr</strong></dt>
<dd>Represents one domain either active or defined (i.e. existing as permanent config file and storage but not currently running on that node). The function virConnectListAllDomains lists all the domains for the hypervisor.</dd>
<dt><strong>virNetworkPtr</strong></dt>
<dd>Represents one network either active or defined (i.e. existing as permanent config file and storage but not currently activated). The function virConnectListAllNetworks lists all the virtualization networks for the hypervisor.</dd>
<dt><strong>virStorageVolPtr</strong></dt>
<dd>Represents one storage volume generally used as a block device available to one of the domains. The function virStorageVolLookupByPath finds the storage volume object based on its path on the node.</dd>
<dt><strong>virStoragePoolPtr</strong></dt>
<dd>Represents a storage pool, which is a logical area used to allocate and store storage volumes. The function virConnectListAllStoragePools lists all of the virtualization storage pools on the hypervisor. The function virStoragePoolLookupByVolume finds the storage pool containing a given storage volume.</dd>
</dl>
<p>These names follow C conventions, but developers of cloud computing platforms and applications do not need to use C directly, there are language bindings available for major languages. Currently libvirt API language bindings <a href="#f4" id="id4">[4]</a> are available for C#, Java, OCaml, Perl, PHP, Python, Ruby.</p>
</div>
<div id="domain-management-architecture">
<h3>Domain Management Architecture</h3>
<p>There are two distinct means for domain management using libvirt API.</p>
<p><strong>1. Single node domain management</strong></p>
<p><img alt="libvirt API structure" src="https://vyomtech.com/_images/libvirt_single_node_domain_management.png"></p><p>As illustrated in the figure above in this mode applications (cloud management platform i.e. CMP applications) and domains exist on the same node. In this scenario applications directly works through the libvirt api on the host operating system (os) to control and manage the local domains.</p>
<p><strong>2. Multi node domain management</strong></p>
<p><img alt="libvirt API structure" src="https://vyomtech.com/_images/libvirt_multi_node_domain_management.png"></p><p>As shown in the figure above, applications (CMP applications) using libvirt API and the domains to manage or control are on separate nodes. In this mode a special domain called <strong>libvirtd</strong> (libvirt daemon) needs to run on remote nodes. The management application nodes use the nodes underlying network communicattion to communicate with remote <em>libvirtd</em> through the local libvirt using custom protocol. Actually libvirt uses Remote <a href="#f6" id="id5">[6]</a> driver for communicating with remote node and remote API calls are handled synchronously. Remote driver for libvirt supports a range of transports like:</p>
<dl>
<dt><em>tls</em></dt>
<dd>TLS 1.0 (SSL 3.1) authenticated and encrypted TCP/IP socket, usually listening on a public port number. To use this you will need to generate client and server certificates. The standard port is 16514. This is the <strong>default</strong> transport, if no other is specified.</dd>
<dt><em>unix</em></dt>
<dd>nix domain socket. Since this is only accessible on the local machine, it is not encrypted, and uses Unix permissions or SELinux for authentication. The standard socket names are /var/run/libvirt/libvirt-sock and /var/run/libvirt/libvirt-sock-ro (the latter for read-only connections).</dd>
<dt><em>ssh</em></dt>
<dd>Transported over an ordinary ssh (secure shell) connection. Requires Netcat (nc) installed and libvirtd should be running on the remote machine. You should use some sort of ssh key management (eg. ssh-agent) otherwise programs which use this transport will stop to ask for a password.</dd>
<dt><em>ext</em></dt>
<dd>Any external program which can make a connection to the remote machine by means outside the scope of libvirt.</dd>
<dt><em>tcp</em></dt>
<dd>nencrypted TCP/IP socket. Not recommended for production use, this is normally disabled, but an administrator can enable it for testing or use over a trusted network. The standard port is 16509.</dd>
<dt><em>libssh2</em></dt>
<dd>Transport over the SSH protocol using libssh2 instead of the OpenSSH binary. This transport uses the libvirt authentication callback for all ssh authentication calls and therefore supports keyboard-interactive authentication even with graphical management applications. As with the classic ssh transport netcat is required on the remote side.</dd>
</dl>
</div>
</div>
<div id="libvirt-project">
<h2>Libvirt Project <a href="#f5" id="id6">[5]</a></h2>
<p>According to statistics on ohloh libvirt in a nutshell:</p>
<ul>
<li>15,188 commits made  by 331 contributors representing 481,506 lines of code</li>
<li>Mostly written in C</li>
</ul>
<table>
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead>
<tr><th colspan="2">Libvirt project</th>
</tr>
</thead>
<tbody>
<tr><td>C</td>
<td>74%</td>
</tr>
<tr><td>C++</td>
<td>9%</td>
</tr>
<tr><td>XML</td>
<td>6%</td>
</tr>
<tr><td>14 Other</td>
<td>11%</td>
</tr>
</tbody>
</table>
<ul>
<li>Established, mature codebase maintained by a very large development team with increasing year on year commits.</li>
<li>Estimated 128 years of efforts (COCOMO model)</li>
</ul>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>Libvirt is one very important library on whose giant shoulders cloud computing services and platforms like Amazon AWS, Google Compute Engine, OpenStack, CloudStack, Eucalyptus and numberous others are standing. Also this API enables developers and companies to build new and innovative cloud computing services or platforms and build awesome applications or services on top of it. Libvirt started in 2005 and with growing popularity of cloud computing, this project will continue to grow. But in most of the conferences, talks and papers related to Cloud Computing I did not find much coverage of libvirt, so while researching Cloud Management platform thought of writing and article on it. Kudos to all the libvirt code contributors for building a beautiful abstraction layer and making life easier for cloud computing services and platform developers. In spite of not getting as much press and coverage as ‚Ä¶</p></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vyomtech.com/2013/12/17/libvirt_the_unsung_hero_of_cloud_computing.html">https://vyomtech.com/2013/12/17/libvirt_the_unsung_hero_of_cloud_computing.html</a></em></p>]]>
            </description>
            <link>https://vyomtech.com/2013/12/17/libvirt_the_unsung_hero_of_cloud_computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24370966</guid>
            <pubDate>Fri, 04 Sep 2020 01:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg (curl) has been denied entry to the US for 870 days]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 150 (<a href="https://news.ycombinator.com/item?id=24369233">thread link</a>) | @tehwebguy
<br/>
September 3, 2020 | https://daniel.haxx.se/us-visa.html | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/us-visa.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p> Time passed since Daniel applied for a US visa </p>
<p><span>
  <span id="days">00</span> days, <span id="hours">00</span> hours,
  <span id="minutes">00</span> minutes and <span id="seconds">00</span> seconds
</span></p><p> Background </p>
<p>
 On June 26th 2017, Daniel was denied to travel to the US - while still having
 a valid ESTA and passport. He was then denied ESTA on April 3, 2018. When
 subsequently applying for a visa instead, there has been no response for over
 two years. (To <i>visit</i>, not to apply for permanent residency.)
</p><p>
 This page was edited with new content on: <b>September 4, 2020</b>.
</p><p> Blog posts </p>
<p> First blog post: <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/">Administrative

 purgatory</a>
</p><p> The one year anniversary: <a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/">One

year in still no visa</a>.
</p><p> <a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/">Two years in</a>

</p><p> FAQ </p>
<p>
<a href="#long">Do you know why this takes so long?</a>
</p><div>
<p> No. They've just informed me "someone is working on it" and that it "may take a long time" but without qualifying what that means.
</p><p> I've talked to several persons who've experienced similar situations, and
  I've learned about waiting times up to 20 months until a definite "no". I used
  to think of that as a sort of "worst case" waiting time. Now we know it can
  take longer...
</p></div>
<p>
<a href="#esta">Why don't you just apply for an ESTA?</a>
</p><p>
  I already did and they denied me that. See one of the <a href="#images">images below</a>.
</p>
<p>
Why did they deny you ESTA?
</p><p>
  I don't know as they won't tell. And I also don't know why they can't respond to my visa application.
</p>
<p>
<a href="#working">So, someone is working on it?</a>
</p><p>
  Allegedly, yes. I'm sure that person must be working very hard...
</p>
<p>
<a href="#eventually">Do you think they will grant you a visa eventually?</a>
</p><div>
<p>
  No. I've been in contact with many people who have been in similar
  situations such as this, as well as many people who have applied for visas
  for very complicated matters, and it is basically unheard of that it would
  take this long time and still end up with a positive response in the end.
</p><p>
  Someone emailed me and explained how they got their visa approved after 10
  months waiting - so it obviously <i>can</i> happen after a fairly
  long time!
</p></div>
<p>
<a name="#arab">Did you travel to any arab countries, middle-east, North Korea, Sudan, Iran or Iraq?</a>
</p><p>
 No.
</p>
<p>
<a name="#ever">Did you ever visit the US?</a>
</p><div>
<p> Yes, I've visted the US around a dozen times over a time period of almost
 twenty years. I've applied and gotten ESTA permissions several times. I have
 many friends living and working in the US.
</p><p> My latest visit to the US was in December 2016 - using the same ESTA and
 passport I subsequently wanted to use in the summer of 2017 when I was first
 denied travelling to the US.
</p></div>
<p>
<a href="#blocked">How many trips have this blocked you from taking so far?</a>
</p><div>
<p> I've been invited personally to several meetings in the US that I couldn't
 attend. (excluding IETF, HTTPbis or QUIC meetings)
</p><ol>
<li> San Francisco June 2017. Mozilla All Hands.
</li><li> San Francisco June 2018. Mozilla All hands.
</li><li> San Francisco October 2018. Conference speaking engagement.
</li><li> Orlando, Florida December 2018. Mozilla All hands.
</li><li> Portland, Oregon January 2019. Conference speaking engagement.
</li><li> California, March 2019. Conference speaking engagement.
</li><li> Summer of 2019. Wedding.
</li></ol>
</div>
<p>
<a href="#employer">Can't your employer help you?</a>
</p><p> We've already tried all available ways to get information or otherwise
bring this effort forward. To no avail.
</p>
<p>
<a href="#Mozilla">Will Mozilla move more meetings outside of the US?</a>
</p><p> Yes. Several of the coming All hands are now planned and scheduled to
happen outside of the US, for example in Canada and Germany. But I will not be
there to experience them since I quit Mozilla in December 2018.
</p>
<p>
Will your visa situation change when you've quit Mozilla?
</p><p> Unfortunately, there is no reason to suspect or hope so.
</p>
<p>
<a href="#lost">Maybe they lost your application?</a>
</p><div>
<p> I emailed them in July 2019 just to make sure they just hadn't
 forgot about my case or similar over the past year, and I received their
 reply on August 1st 2019. The response said "I have forwarded your email to
 my supervisor to highlight the problem."  - but then nothing more came.
</p><p> I emailed them again on January 28, 2020.<br>
<img src="https://daniel.haxx.se/media/651-days-email.png">
</p><p>
 They responded very politely:
 </p><pre>Dear Sir,
&nbsp;
All applications are processed in the most expeditious manner
possible. While we understand your frustration, we are required to follow
immigration law regarding visa issuances. This process cannot be expedited or
circumvented. Rest assured that we will contact you as soon as the
administrative processing is concluded.
</pre>
</div>
<p>
<a href="#likely">What do you think is the most likely explanation for this treatment?</a>
</p><div>
<p> I think one of the likelier explantions is that someone somewhere has
 found my name and my code used in some evil or malicious manner and drawn the
 wrong conclusions about how my code ended up there or how I could've been
 involved. Like for example in some malware, virus or other attack software. I
 make tools and code available for free and openly and sometimes those are
 unfortunately used in ways I don't condone.
</p><p> Since they won't tell me why, basically all theories are equally likely.
 We just won't know.
</p></div>
<p>
Any other plausible explanations?
</p><div>
<p> People have mentioned my domain name <b>haxx.se</b> or suggested it is
because I've referred to myself as "a hacker" at times. I find that unlikely
since I used the domain and used the term for decades before this.
</p><p> Others have offered the explanation that the immigration authorities
might've decided that I violated the ESTA rules in a previous visit. I can of
course not know what they think, but I have not violated those rules.
</p></div>
<p>
<a href="#crime">Convicted of a crime?</a>
</p><p>
No, I've never been convicted of a crime in Sweden and not anywhere else. Not even
charged. Nor have I ever been involved in a lawsuit of any kind.
</p>
<p>
<a href="#license">Can you change the curl license?</a>
</p><div><p>
Lots of people suggest this, most probably in jest, but let me be perfectly
clear: no I won't change the curl license.
</p><ol>
 <li> excluding a specific user would make a license to not be open source anymore
 </li><li> curl has many more copyrights than mine, it would be hard
 </li><li> curl is bigger than me personally, I wouldn't do it anyway
</li></ol>
</div>
<p>
<a href="#covid">But Covid-19?</a>
</p><p>
During the Corona pandemic (starting in spring 2020), the US has closed its
borders for a lot of more people who otherwise would have been allowed
entry. I suspect the visa processing has slowed down during this period since
people can't go there anyway. But I have not been notified about anything and
I still expect to get a rejection at some point. Pandemic or not.
</p>
<p>
<a href="#officials">Have you contacted any US officials?</a>
</p><div><p>
A US citizen friend of mine sent the following text in an email to the
U.S. Congressman Gerry Connolly on September 3, 2020.
</p><pre>Dear Representative Gerry Connolly:
&nbsp;
Could you please help my friend Daniel Stenberg *finally* gain permission to
travel to the US? He has been denied permission to travel to the US for years,
yet there is no cause for it.
&nbsp;
On June 26, 2017, Mr. Stenberg was denied to travel to the US, even though he
had a valid ESTA and passport. He was then denied ESTA on April 3, 2018. He
then applied for a visa in April 2018, and has *still* not heard anything.
&nbsp;
This is especially galling because is a widely-known leader in the computer
community. He developed and maintains the "curl" program, a program used
worldwide by many software developers and computer system administrators. In
October 2017 he won the "Polhem prize" for his work on curl; in that ceremony
the Swedish king personally handed Daniel a gold medal. In February 2019 he
joined wolfSSL, an American company (he's their only Swedish hire), and yet
he's still not allowed to travel to the US.
&nbsp;
Perhaps there is a confusion about the word "hacker". In the computer
community, a "hacker" is NOT someone who breaks into computers, a hacker
is "a person who delights in having an intimate understanding of the
internal workings of a system, computers and computer networks in
particular."  ( IETF RFC 1983, https://tools.ietf.org/html/rfc1983).

Mr. Stenberg does *not* break into computers without authorization.
&nbsp;
At the least, the State Department should have asked questions instead of
reflexively denying entry to a world leader in the computer industry.
&nbsp;
More information is available on his personal website:
https://daniel.haxx.se/us-visa.html

https://daniel.haxx.se/about.html

&nbsp;
Thank you very much!
&nbsp;
--- [name redacted]
</pre>
</div>
<p> Images </p>
<p> This is what the online visa application status site showed for my case on
July 30, 2019:
</p><center>
<img src="https://daniel.haxx.se/media/Administrative-Processing.png"></center>
<p> This is what an ESTA rejection looks like:
</p><center>
<img src="https://daniel.haxx.se/media/ESTA-travel-not-authorized.png"></center>
</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/us-visa.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24369233</guid>
            <pubDate>Thu, 03 Sep 2020 21:45:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an Efficient Vulkan Renderer]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24368353">thread link</a>) | @noch
<br/>
September 3, 2020 | https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer/ | <a href="https://web.archive.org/web/*/https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>

27 Feb 2020

</span></p><p>In 2018, I wrote an article ‚ÄúWriting an efficient Vulkan renderer‚Äù for GPU Zen 2 book, which was published in 2019. In this article I tried to aggregate as much information about Vulkan performance as I could - instead of trying to focus on one particular aspect or application, this is trying to cover a wide range of topics, give readers an understanding of the behavior of different APIs on real hardware and provide a range of options for each problem that needs to be solved.</p>

<p>At the time of publishing this article, the <a href="https://www.amazon.com/GPU-Zen-Advanced-Rendering-Techniques-ebook/dp/B07SYP7P6B">Kindle edition of the book</a> is available for $2.99 on Amazon - that‚Äôs cheaper than a cup of coffee and it‚Äôs definitely worth your time and money. It contains many great articles about rendering effects and design.</p>

<p>This, however, is the full, free of charge copy of the article - hopefully it will help graphics programmers to understand and use Vulkan to the full of its ability. The article has been lightly edited to mention Vulkan 1.1/1.2 promotions where applicable - fortunately, not much has changed in the last two years for Vulkan performance, so the content should still be mostly accurate.</p>

<p>Enjoy!</p>

<!--more-->



<p>Vulkan is a new explicit cross-platform graphics API. It introduces many new concepts that may be unfamiliar to even seasoned graphics programmers. The key goal of Vulkan is performance ‚Äì however, attaining good performance requires in-depth knowledge about these concepts and how to apply them efficiently, as well as how particular driver implementations implement these. This article will explore topics such as memory allocation, descriptor set management, command buffer recording, pipeline barriers, render passes and discuss ways to optimize CPU and GPU performance of production desktop/mobile Vulkan renderers today as well as look at what a future looking Vulkan renderer could do differently.</p>

<p>Modern renderers are becoming increasingly complex and must support many different graphics APIs with varying levels of hardware abstraction and disjoint sets of concepts. This sometimes makes it challenging to support all platforms at the same level of efficiency. Fortunately, for most tasks Vulkan provides multiple options that can be as simple as reimplementing concepts from other APIs with higher efficiency due to targeting the code specifically towards the renderer needs, and as hard as redesigning large systems to make them optimal for Vulkan. We will try to cover both extremes when applicable ‚Äì ultimately, this is a tradeoff between maximum efficiency on Vulkan-capable systems and implementation and maintenance costs that every engine needs to carefully pick. Additionally, efficiency is often application-dependent ‚Äì the guidance in this article is generic and ultimately best performance is achieved by profiling the target application on a target platform and making an informed implementation decision based on the results.</p>

<p>This article assumes that the reader is familiar with the basics of Vulkan API, and would like to understand them better and/or learn how to use the API efficiently.</p>



<p>Memory management remains an exceedingly complex topic, and in Vulkan it gets even more so due to the diversity of heap configurations on different hardware. Earlier APIs adopted a resource-centric concept ‚Äì the programmer doesn‚Äôt have a concept of graphics memory, only that of a graphics resource, and different drivers are free to manage the resource memory based on API usage flags and a set of heuristics. Vulkan, however, forces to think about memory management up front, as you must manually allocate memory to create resources.</p>

<p>A perfectly reasonable first step is to integrate <code>VulkanMemoryAllocator</code> (henceforth abbreviated as VMA), which is an open-source library developed by AMD that solves some memory management details for you by providing a general purpose resource allocator on top of Vulkan functions. Even if you do use that library, there are still multiple performance considerations that apply; the rest of this section will go over memory caveats without assuming you use VMA; all of the guidance applies equally to VMA.</p>

<h2 id="memory-heap-selection">Memory heap selection</h2>

<p>When creating a resource in Vulkan, you have to choose a heap to allocate memory from. Vulkan device exposes a set of memory types where each memory type has flags that define the behavior of that memory, and a heap index that defines the available size.</p>

<p>Most Vulkan implementations expose two or three of the following flag combinations<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<ul>
  <li><code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT</code> ‚Äì this is generally referring to GPU memory that is not directly visible from CPU; it‚Äôs fastest to access from the GPU and this is the memory you should be using to store all render targets, GPU-only resources such as buffers for compute, and also all static resources such as textures and geometry buffers.</li>
  <li><code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code> ‚Äì on AMD hardware, this memory type refers to up to 256 MB of video memory that the CPU can write to directly, and is perfect for allocating reasonable amounts of data that is written by CPU every frame, such as uniform buffers or dynamic vertex/index buffers</li>
  <li><code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>  ‚Äì this is referring to CPU memory that is directly visible from GPU; reads from this memory go over PCI-express bus. In absence of the previous memory type, this generally speaking should be the choice for uniform buffers or dynamic vertex/index buffers, and also should be used to store staging buffers that are used to populate static resources allocated with <code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT</code> with data.</li>
  <li><code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT | VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT</code> ‚Äì this is referring to GPU memory that might never need to be allocated for render targets on tiled architectures. It is recommended to use lazily allocated memory to save physical memory for large render targets that are never stored to, such as MSAA images or depth images.
On integrated GPUs, there is no distinction between GPU and CPU memory ‚Äì these devices generally expose <code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT | VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code> that you can allocate all static resources through as well.</li>
</ul>

<p>When dealing with dynamic resources, in general allocating in non-device-local host-visible memory works well ‚Äì it simplifies the application management and is efficient due to GPU-side caching of read-only data. For resources that have a high degree of random access though, like dynamic textures, it‚Äôs better to allocate them in <code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT</code> and upload data using staging buffers allocated in <code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code> memory ‚Äì similarly to how you would handle static textures. In some cases you might need to do this for buffers as well ‚Äì while uniform buffers typically don‚Äôt suffer from this, in some applications using large storage buffers with highly random access patterns will generate too many PCIe transactions unless you copy the buffers to GPU first; additionally, host memory does have higher access latency from the GPU side that can impact performance for many small draw calls.</p>

<p>When allocating resources from <code>VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT</code>, in case of VRAM oversubscription you can run out of memory; in this case you should fall back to allocating the resources in non-device-local <code>VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT</code> memory. Naturally you should make sure that large frequently used resources such as render targets are allocated first. There are other things you can do in an event of an oversubscription, such as migrating resources from GPU memory to CPU memory for less frequently used resources ‚Äì this is outside of the scope of this article; additionally, on some operating systems like Windows 10 correct handling of oversubscription requires APIs that are not currently available in Vulkan.</p>

<h2 id="memory-suballocation">Memory suballocation</h2>

<p>Unlike some other APIs that allow an option to perform one memory allocation per resource, in Vulkan this is impractical for large applications ‚Äì drivers are only required to support up to 4096 individual allocations. In addition to the total number being limited, allocations can be slow to perform, may waste memory due to assuming worst case possible alignment requirements, and also require extra overhead during command buffer submission to ensure memory residency. Because of this, suballocation is necessary. A typical pattern of working with Vulkan involves performing large (e.g. 16 MB ‚Äì 256 MB depending on how dynamic the memory requirements are) allocations using <code>vkAllocateMemory</code>, and performing suballocation of objects within this memory, effectively managing it yourself. Critically, the application needs to handle alignment of memory requests correctly, as well as <code>bufferImageGranularity</code> limit that restricts valid configurations of buffers and images.</p>

<p>Briefly, <code>bufferImageGranularity</code> restricts the relative placement of buffer and image resources in the same allocation, requiring additional padding between individual allocations. There are several ways to handle this:</p>

<ul>
  <li>Always over-align image resources (as they typically have larger alignment to begin with) by bufferImageGranularity, essentially using a maximum of required alignment and <code>bufferImageGranularity</code> for address and size alignment.</li>
  <li>Track resource type for each allocation, and have the allocator add the requisite padding only if the previous or following resource is of a different type. This requires a somewhat more complex allocation algorithm.</li>
  <li>Allocate images and buffers in separate Vulkan allocations, thus sidestepping the entire problem. This reduces internal fragmentation due to smaller alignment padding but can waste more memory if the backing allocations are too big (e.g. 256 MB).</li>
</ul>

<p>On many GPUs the required alignment for image resources is substantially bigger than it is for buffers which makes the last option attractive ‚Äì in addition to reducing waste due to lack of extra ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer/">https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer/</a></em></p>]]>
            </description>
            <link>https://zeux.io/2020/02/27/writing-an-efficient-vulkan-renderer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24368353</guid>
            <pubDate>Thu, 03 Sep 2020 20:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm Hub: data science without the hassle of managing infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24365697">thread link</a>) | @jdoliner
<br/>
September 3, 2020 | https://www.pachyderm.com/blog/pachyderm-hub-is-now-in-production/ | <a href="https://web.archive.org/web/*/https://www.pachyderm.com/blog/pachyderm-hub-is-now-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"><article><div><div><p><img src="https://www.pachyderm.com/images/blog-images/hub-ga-announcement-hero.jpg" alt=""></p><p>Today we‚Äôre announcing the production ready availability of <a href="https://hub.pachyderm.com/">Pachyderm Hub</a>, our powerful end-to-end machine learning and data lineage platform in the cloud. Hub delivers all the key features of the <a href="https://www.pachyderm.com/">Pachyderm</a> suite but in a completely managed cloud-native environment. You no longer need to have Kubernetes and cloud infrastructure expertise in-house, Pachyderm Hub let‚Äôs you seamlessly spin up a cluster in minutes.</p><p>While Pachyderm always delivered the power teams needed to do data science at scale, you also needed a strong systems administration and architecture team to get Kubernetes and containers into production. Kuberenetes is way more than just software you download and install. It needs monitoring and management, backup, redundancy, capacity and upgrade planning, to name just a few. That represents a real challenge for some organizations. Now, we‚Äôve removed the barriers to entry, which makes it possible for smaller teams to start doing data science faster.</p><p>Pachyderm Hub includes all of the features that were challenging for teams to set up, like autoscaling with GPUs, security and isolation, backup, and automation. Now you can rely on Pachyderm‚Äôs trained team of Kubernetes experts to handle the infrastructure for you and concentrate on data science instead of systems administration. Kubernetes is powerful, but the real power comes from the applications you can run on it.</p><blockquote><h4 id="you-simply-bring-your-code-and-data-pachyderm-hub-handles-all-the-infrastructure">You simply bring your code and data, Pachyderm Hub handles all the infrastructure.</h4></blockquote><p>More than anything, Pachyderm Hub delivers on our ultimate vision for a fully collaborative, shareable, and reproducible data science platform. It does what Git did for data, bringing powerful version control and collaboration to your AI applications development. Pachyderm Hub makes team collaboration and sharing data, code, and infra totally seamless. Team members can create and share workspaces, invite other team members to collaborate, and behind the scenes the platform scales transparently as you add workloads.</p><p>Since our launch 2014, Pachyderm‚Äôs data science platform has quickly become a foundation for the <a href="http://ai-infrastructure.org/">emerging Canonical Stack (CS) in machine learning</a>. Because other platforms only let you track metadata, they lack the true iron-clad immutability of a robust version controlled file system. If your data can change after you‚Äôve recorded your metadata then you can‚Äôt reproduce critical data science results. Our customers understand the need for true data lineage and data versioning. That‚Äôs why over the past year, Pachyderm has attracted tremendous new enterprise customers like Shell, LogMeIn, Battelle Ecology, and AgBiome, as well as multiple government agencies, pharmaceutical and bioinformatics companies, two major North American banks, and other Fortune 500 powerhouses.</p><p>Beyond data versioning, customers choose Pachyderm because they need a clean, simple and elegant data science pipeline system that delivers data science at scale. The Pachyderm platform allows teams to bring any framework, language or library and fit them together into a smooth, automated workflow with ease. If it can run in a Docker container it can run on Pachyderm.Customers aren‚Äôt locked into one tool like Spark, R or Python, or one machine learning framework, like Pytorch or Tensorflow. They can use it all on one complete system.</p><blockquote><h4 id="launch-your-free-workspace-todayhttpshubpachydermcom"><a href="https://hub.pachyderm.com/">Launch your free workspace today!</a></h4></blockquote><p>If you‚Äôre ready to do production workloads you can easily upgrade to benefit from GPUs and enterprise team collaboration, just <strong><a href="https://www.pachyderm.com/request-a-demo/">talk with one of our experts</a></strong>, or join our <strong><a href="https://www.pachyderm.com/slack/">open source community on Slack</a></strong> and check out the Pachyderm codebase on <strong><a href="https://github.com/pachyderm/pachyderm">Github</a></strong>.</p></div></div></article></div></div>]]>
            </description>
            <link>https://www.pachyderm.com/blog/pachyderm-hub-is-now-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24365697</guid>
            <pubDate>Thu, 03 Sep 2020 16:28:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Home Office Projects Series: Air conditioner setup]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24364080">thread link</a>) | @gcds
<br/>
September 3, 2020 | https://www.techprowd.com/home-office-projects-series-air-conditioner-setup/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/home-office-projects-series-air-conditioner-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>After I have moved from a tiny tiny apartment 9m^2 in Tokyo to a big one 3LDK (2 western-style rooms, kitchen, living/dining room, and tatami room) I decided that I am going to use one of the westerner rooms as my home office/laboratory and with this idea, a lot of project ideas appeared in my head what I could do with my home office. One of the first projects which I have already finished was getting an Air Conditioner in the home office room</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-7.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-7.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-7.png 1000w, https://www.techprowd.com/content/images/2020/09/image-7.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I bought two Panasonic ACs for the home office and bedroom. The living room already had an air conditioner. They are pretty small and. efficient units for 6 tatamis sized room (~9.72m^2)</p><p>As a European from North Europe Japanese spring/summer has hitten hard for an unexpected guy coming from a different continent. The weather until late May was without any issues pleasant temperatures sunny days and then <strong>THE Rainy Season</strong> came which introduced me with the new term <strong>Humidity</strong> to which I was never used or never had much concern living in Europe. When your room humidity level reaches 70-80% you would want to reduce the humidity level quickly as high humidity can introduce a lot of problems for your apartment. This is where Air Conditioner comes which helps with these issues by utilizing Dehumidifier mode which reduces humidity in the room pretty quickly.</p><p>After this unexpectedly pretty long Rainy season the real summer came up with really high temperatures as far as 35-45¬∫C which were devastating as my apartment was the top floor so it would heat up to around 32¬∫C in the home office room as soon as 8 AM. So the air conditioner was a must item in my home office!</p><p>Not to forget the winters in Tokyo can get mildly cold too, but so you know Japanese apartments in most cases lack any central heating system so you have few options to warm up urself:</p><ul><li>Electric Fan Heater (Most common device in Europe I think)</li><li>Electric Radiator</li><li>Electric Infrared Heater</li><li>Electric Blanket</li><li>Kerosine Heater</li><li>Gas Fan Heater</li><li>Gas Heater</li></ul><p>Yes I know burning stuff inside the apartment for westerners would sound crazy but most Japanese apartments there are special pipes/tubes in walls with covers for exhaust fumes, etc. same with air conditioners their special pipes for passing air conditioner refrigerant/electrical lines to the outside.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-8.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-8.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-8.png 1000w, https://www.techprowd.com/content/images/2020/09/image-8.png 1002w" sizes="(min-width: 720px) 720px"></figure><p>You probably would not believe if I told you that the small square socket near the bottom big pipe is a gas outlet. Yes, <strong>GAS </strong>outlet and the most interesting thing is it is in every room so technically I could run Gas heaters (which someone told me are cheaper than electrical counterparts) to heat rooms but that's for later on it is still just the beginning of Autumn!</p><h2 id="the-reason-why-i-choose-panasonic-air-conditioners"><br>The reason why I choose Panasonic Air Conditioners</h2><p>One of the main reasons I choose Panasonic was because my living room had Panasonic AC cs-409cfr2-w which was provided with an apartment from all 4 rooms only one living room had AC preinstalled. I had in plan to make my apartment a bit smarter I guess so I found out that Panasonic AC (In Japan don't know other countries as they heavily differ in features) I decided to go with Panasonic as they had special modules which are plugged into AC and then connects to Gateway module which would allow me to control all AC remotely.</p><h2 id="i-wouldn-t-be-an-engineer-if-i-would-not-try-to-take-apart-them-before-they-were-installed-by-professionals">I wouldn't be an engineer if I would not try to take apart them before they were installed by professionals</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-10.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-10.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-10.png 1000w, https://www.techprowd.com/content/images/2020/09/image-10.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-11.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-11.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-11.png 1000w, https://www.techprowd.com/content/images/2020/09/image-11.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-12.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-12.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-12.png 1000w, https://www.techprowd.com/content/images/2020/09/image-12.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I had to take them apart as I will need to install radio modules myself as I was scared that AC installers going to charge extra as in Japan all services usually cost extra and it's not cheap!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-13.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-13.png 600w, https://www.techprowd.com/content/images/2020/09/image-13.png 768w" sizes="(min-width: 720px) 720px"></figure><p>One of the things I like about Japan that almost everything has a schematic on there somewhere hidden makes trying to understand things much easier.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-14.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-14.png 600w, https://www.techprowd.com/content/images/2020/09/image-14.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Everything looks so clean!</p><p>This module connects to the LAN and bridges all Panasonic 920Mhz compatible devices to the network.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-15.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-15.png 600w, https://www.techprowd.com/content/images/2020/09/image-15.png 640w"></figure><p>At first look, it didn't look that small, and first thought it was running some arm embedded Linux or similar stuff as it is usual with IoT devices. When it arrived from Amazon I was amazed by how small it is:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-16.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-16.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-16.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-16.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-16.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Again how I would not be tinkerer if I don't take it apart and see which SoC it runs?</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-17.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-17.png 600w, https://www.techprowd.com/content/images/2020/09/image-17.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-18.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-18.png 600w, https://www.techprowd.com/content/images/2020/09/image-18.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-20.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-20.png 600w, https://www.techprowd.com/content/images/2020/09/image-20.png 768w" sizes="(min-width: 720px) 720px"></figure><p>I was amazed as you! I guess it's custom labeled <a href="https://www.st.com/en/microcontrollers-microprocessors/stm32f417ve.html">STM32F417VET6</a> 168Mhz ARM Cortex-M4! It's not even ARM9 or anything. </p><p>Considering it managers something similar to the <a href="https://en.wikipedia.org/wiki/6LoWPAN">6LoWPAN</a> network, act as <a href="https://echonet.jp/hems_en/">Echonet Lite (Japanese home automation internet protocol)</a> gateway, and also communicates with Panasonic servers as the Panasonic AC app works even outside the home internet network. I was amazed at how much they cramped inside it.</p><p>It uses <a href="http://file.elecfans.com/web1/M00/99/0F/o4YBAF0VytaAI7ezABH66fmIRIg854.pdf?filename=RTL8201F-VB-CG.pdf">Realtek RTL8201FR</a> Ethernet PHY Receiver for ethernet communication and <a href="https://www.silabs.com/wireless/proprietary/ezradiopro-sub-ghz-ics/device.si4432">Silicon Labs Si4432</a> Wireless Transceiver.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-21.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-21.png 600w, https://www.techprowd.com/content/images/2020/09/image-21.png 640w"></figure><p>This module plugs into the AC indoor unit mainboard.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-22.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-22.png 600w, https://www.techprowd.com/content/images/2020/09/image-22.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Same radio transceiver but no idea about MCU as it proprietary something sad...</p><h2 id="installation-day">Installation day</h2><p>Early morning Japanese AC installers ringed at the door and came to install my AC's for which I have waited for over a month (It is summer period pretty busy I guess) I was already ready to install myself as I have watched enough of youtube videos to know how everything goes just needed to rent tools but sadly I had already paid for installation when I bought them.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-23.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-23.png 600w, https://www.techprowd.com/content/images/2020/09/image-23.png 768w" sizes="(min-width: 720px) 720px"></figure><p>The installers were pretty clean and quick-witted with their work it took a few hours to get two units installed!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-24.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-24.png 600w, https://www.techprowd.com/content/images/2020/09/image-24.png 768w" sizes="(min-width: 720px) 720px"></figure><p>They have some special playdough or something similar to seal the hole.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-25.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-25.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-25.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-25.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-25.png 2400w" sizes="(min-width: 720px) 720px"></figure><h2 id="air-conditioner-automation">Air Conditioner Automation</h2><p>Panasonic has a pretty decent mobile application to control the air conditioners. (Sadly it's in Japanese)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-27.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-27.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-27.png 1000w, https://www.techprowd.com/content/images/2020/09/image-27.png 1242w" sizes="(min-width: 720px) 720px"></figure><p>The app was nice but I wanted it to integrate into some other automation services which technically according Panasonic not possible apart Echonet Lite protocol.</p><p>So I spent one Saturday reverse engineering the communication protocol between iOS application and Panasonic Web Servers and managed to make NodeJS based client to their API.</p><figure><a href="https://github.com/aurimasniekis/eolia-client"><div><p>aurimasniekis/eolia-client</p><p>A NodeJS Panasonic Eolia Air Conditioner App API Client - aurimasniekis/eolia-client</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/15481?s=400&amp;v=4"></p></a></figure><p>Afterward, I spend some time trying to integrate this client with <a href="https://homebridge.io/">HomeBridge</a>. </p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-28.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-28.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-28.png 1000w, https://www.techprowd.com/content/images/2020/09/image-28.png 1242w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-29.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-29.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-29.png 1000w, https://www.techprowd.com/content/images/2020/09/image-29.png 1242w" sizes="(min-width: 720px) 720px"></figure><p>Everything went smoothly until I reached Panasonic API rate limitations some calls required a 2min delay in between calls which made using HomeKit practically impossible as HomeKit updates the accessory state every time you change some parameters. Of course, I could try to buffer those changes and send one request but then it would deny the whole idea of making it quicker to use. So I scrapped the idea but the code is still here if anybody is interested:</p><figure><a href="https://github.com/aurimasniekis/homebridge-eolia"><div><p>aurimasniekis/homebridge-eolia</p><p>A Panasonic Eolia Air Conditionner integration into HomeBridge - aurimasniekis/homebridge-eolia</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>aurimasniekis</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/15481?s=400&amp;v=4"></p></a></figure><p>So what I can do to make it better. Then I found out that Panasonic Wireless Gateway also exposes as Echonet Lite gateway and all air conditioners are available to be commanded via it without any limitations. After playing around with several libraries (Compared to other protocols and automation standards these severely lacks community libraries üò£) I managed to produce some code that was able to control ACs with the easy and best thing it's instant and no Beeping sound perfect for thermostat style operation!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-26.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-26.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-26.png 1000w, https://www.techprowd.com/content/images/2020/09/image-26.png 1045w" sizes="(min-width: 720px) 720px"></figure><p>So far I haven't done anything more regarding Echonet Lite integration but I have some plans which I want to work on one of them is to make the Echonet Lite to Web API bridge interface but this time to use Golang as I have done some light coding in a different project (Which I am going to soon release an article about pretty soon)</p><p>The next article in this series will be my home office workbench design and construction.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.techprowd.com/home-office-projects-series-air-conditioner-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24364080</guid>
            <pubDate>Thu, 03 Sep 2020 13:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Earth's mountains form in millions of years, Moon ones near instantaneously]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24363074">thread link</a>) | @uncertainquark
<br/>
September 3, 2020 | https://jatan.space/exploring-moon-mountains/ | <a href="https://web.archive.org/web/*/https://jatan.space/exploring-moon-mountains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-4045">
				<div>
<p>Unlike the millions of years it takes for most mountains on Earth to form, lunar mountains crop out near instantaneously, geologically speaking.</p>



<p>Earth‚Äôs mountains primarily form when two colliding plates of the Earth‚Äôs crust lift up volumes of rock, slowly creating an elevated landform. Over millions of years, wind, water and gravity erode these uplifted sections, wearing their surface to make the mountains we are familiar with today.</p>



<p>But the Moon has no plate tectonics, atmosphere or running water. How then does it boast mountains several kilometers high? For instance, <a href="https://moontoday.jatan.space/2019/03/18/mount-as-high-as-everest-zeeman-mons/">Zeeman Mons</a> on the lunar farside peaks as tall as Mount Everest.</p>



<p>The answer lies in the one of the most apparent features on the Moon ‚Äì craters.</p>



<p>Most lunar craters are <a href="https://moontoday.jatan.space/2019/05/27/what-does-a-fresh-crater-look-like-hell/">small and bowl-shaped</a>, formed when asteroids and comets impact the surface. This shape persists for crater sizes up to about 20 kilometers. Larger craters display more complexity.</p>



<p>The force imparted on the Moon‚Äôs surface by larger asteroids and comets, especially those with high velocities, can be tremendous. In such cases, in addition to a crater being formed, the surface in and around the impact point is compressed further. This causes the crust to melt. When the melted crust can‚Äôt be compressed any further, it bounces right back up, forming a central mountain. This process is visualized in the GIF below.</p>







<p>Most lunar mountains are formed by this highly energetic process that takes a geologically negligible passage of time. The kilometer-plus high central peaks of the young, city-sized <a href="https://moontoday.jatan.space/2019/03/11/glorious-aristarchus/">Aristarchus crater</a> and 86-kilometer-wide <a href="https://moontoday.jatan.space/2018/10/15/tycho-crater/">Tycho crater</a> are fine examples.</p>







<figure><img loading="lazy" width="1200" height="633" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C633&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?w=1870&amp;ssl=1 1870w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1024%2C540&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=200%2C105&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=768%2C405&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1536%2C810&amp;ssl=1 1536w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C633&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>The central peak of Tycho crater.&nbsp;<a rel="noreferrer noopener" href="http://lroc.sese.asu.edu/posts/384" target="_blank">Credit: NASA LRO</a></figcaption></figure>



<p>Aristarchus crater was one of the candidate landing sites for the now-cancelled Apollo 17+ missions. Visiting Aristarchus or Tycho in a future surface mission will allow us to study the exposed lunar interior by the virtue of their central mountains. Craters larger than these offer two central peaks.</p>



<p>The mechanics work such that for larger crater sizes or more energetic impacts, the newly formed central peak splits into two before it can solidify. The 93-kilometer-wide <a href="https://moontoday.jatan.space/2019/04/08/a-peak-inside-the-moon-with-copernicus/">Copernicus</a> and 77-kilometer-wide <a href="https://moontoday.jatan.space/2019/01/21/y-shaped-mountains-in-king-crater/">King</a> craters respectively host two distinct peaks, each towering more than six kilometers!</p>











<p>Apart from allowing scientists to study the lunar interior, such places are key to understanding mechanics of impacts that form such features, found not just on the Moon but across the Solar System.</p>



<h3>Put a ring on it </h3>



<p>For even larger craters, the twin peaks widen into a ring of mountains, like a liquid drop causing a ripple on still water. The 312-kilometer-wide <a href="https://moontoday.jatan.space/2019/06/10/the-crowned-crater-of-schrodinger/">crater of Schr√∂dinger</a> on the Moon‚Äôs farside is a well preserved example, despite being almost four billion years old.</p>







<p>A <a href="https://earthandsolarsystem.wordpress.com/2016/06/21/new-paper-a-robotic-mission-concept-to-return-samples-from-the-schrodinger-basin/">mission to Schr√∂dinger</a> can help solve fundamental mysteries about the Moon‚Äôs evolution, like if the Moon indeed had a global magma ocean‚Äìa hypothesis tied to <a href="https://jatan.space/apollo-moon-origin/">its origin</a>. Further, Schr√∂dinger lies inside the Moon‚Äôs largest impact crater, the 2,500-kilometer-wide South Pole-Aitken basin. The impact that created the basin excavated deep into the lunar crust, and perhaps even the mantle. Since Schr√∂dinger formed later, its impact could‚Äôve penetrated deeper and uplifted more materials, offering insights‚Äìliterally and figuratively‚Äìinto the lunar interior.</p>



<p>The <a href="https://en.wikipedia.org/wiki/Chicxulub_crater">Chicxulub crater</a> on Earth, linked to the extinction of dinosaurs, is also thought to have formed as a ringed crater, but wore down of its original form due to Earth‚Äôs active weathering. As such, Schr√∂dinger offers an analog to better understand Chicxulub.</p>



<p>For crater sizes beyond 500 kilometers, you get not one but multiple rings of mountains. The 930-kilometer-wide ancient crater of <a href="https://moontoday.jatan.space/2019/01/07/outstanding-orientale-multi-ring-basin-on-the-moon/">Orientale</a> on the Moon‚Äôs farside boasts three mountain rings, most of which is preserved.</p>







<p>Missions to both Schr√∂dinger and Orientale can tell us exactly when did large asteroids and comets excessively bombard bodies in the Solar System. This period of blistering impacts is particularly important as Earth is thought to have gotten its water during this time.</p>



<p>For some ancient craters, like Imbrium on Moon‚Äôs nearside, only parts of the outermost mountain ring are visible today. The rest of the interior has been drowned in lava, which you see as dark regions on the Moon. The prominent, arc-shaped mountain range of <a href="https://moontoday.jatan.space/2018/10/08/the-mountain-range-montes-apenninus/">Montes Apenninus</a>, forming Imbrium‚Äôs southeast border, stretches 600 kilometers long.</p>







<p>Multi-ring impact basins exist on many other worlds in the Solar System, like <a href="https://airandspace.si.edu/multimedia-gallery/9780640jpg">Caloris</a> on Mercury, <a href="https://www.planetary.org/space-images/20130614_g8gsrngbas01">an unnamed basin</a> on Jupiter‚Äôs moon Ganymede, <a href="https://commons.wikimedia.org/wiki/File:Dione_-_Evander_basin.jpg">Evander</a> on Saturn‚Äôs moon Dione, and more. Jupiter‚Äôs moon Callisto boasts the largest multi-ring basin of the solar system, called <a href="https://en.wikipedia.org/wiki/Valhalla_(crater)">Valhalla</a>, spanning 3800 kilometers wide.</p>







<p>The ubiquity of mountains formed by impacts across the Solar System and their consistent patterns indicate common geological mechanisms. And the Moon being so close to us presents us with an opportunity to study these fundamental processes in planetary science.</p>



<figure><img loading="lazy" width="1200" height="858" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=1200%2C858&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?w=2233&amp;ssl=1 2233w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=1024%2C732&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=200%2C143&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=768%2C549&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=1536%2C1099&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=2048%2C1465&amp;ssl=1 2048w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/moon-mountains.jpg?resize=1200%2C858&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>Changing morphology of mountains and craters on the Moon with increasing size. Graphic: Jatan Mehta</figcaption></figure>



<h3>Exploring the mountains</h3>



<p>Moon orbiters use remote sensing techniques to understand the composition of the lunar mountains. But to better understand the composition, structure and origin, surface missions are needed, especially sample return ones to determine precise ages. To that end, NASA had selected several of the above mentioned places as <a href="https://www.lpi.usra.edu/meetings/leag2009/presentations/Day-2%20PM/03-35_Gruener.pdf">candidate landing sites</a> for the now cancelled Constellation program to return humans to the Moon.</p>



<p>However, sending landing and roving missions to lunar mountains is a bit of an engineering hurdle. Most surface missions of the past landed in the dark lunar plains ‚Äì vast, solidified lava regions that provide a relatively uniform surface for spacecraft to land on. The rocky nature of the mountainous regions make it more difficult to safely touch down on. However, things may change with NASA‚Äôs upcoming Artemis missions.</p>



<p>The Artemis program aims to explore the lunar poles in this decade, both <a href="https://www.nasa.gov/content/commercial-lunar-payload-services-overview">robotically</a> and with <a href="https://www.nasa.gov/press-release/nasa-names-companies-to-develop-human-landers-for-artemis-moon-missions">humans</a>. This requires developing precision landing technologies for safe descent on the challenging polar terrain, as a result also enabling surface missions to the lunar mountains. But there is a type of mountain that spacecraft can visit even with present-day technologies.</p>



<p>The Moon has experienced several distinct periods of volcanism in the last four billion years. Lava slowly oozing out of openings on the surface during such times have formed <a href="https://moontoday.jatan.space/2018/11/05/unique-volcanic-domes-of-gruithuisen/">volcanic domes</a>. These domes aren‚Äôt as tall as the impact-created mountains and have gentle slopes. China‚Äôs third Moon landing mission, Chang‚Äôe 5, launching end of 2020 is targeting the largest such lunar dome, Mons R√ºmker.</p>







<p>The 70-kilometer-wide Mons R√ºmker is thought to have formed less than two billion years ago. The Chang‚Äôe 5 mission aims to bring back samples from the dome and determine its exact age. Since scientists use the Moon to <a href="https://www.planetary.org/articles/0401-the-lunar-chronology">calibrate the timing</a> of events across bodies in the Solar System, analysis of Chang‚Äôe 5 samples would be an invaluable addition to happenings in the geologically recent past.</p>



<p>Mountains on the Moon are a marvel that give us a peak (pun intended) into the lunar interior, help discern the chain of events in the Solar System‚Äôs evolution and improve our understanding of the physical processes that shape airless worlds everywhere.</p>



<hr>



<blockquote><p>This post was made possible thanks to&nbsp;<a href="https://www.patreon.com/uncertainquark">my Patreon</a> supporters. I don‚Äôt display ads to run my blog and instead rely on my readers so if you like my work, consider&nbsp;<a href="https://www.patreon.com/uncertainquark">supporting me</a>.&nbsp;üöÄ</p></blockquote>



<p><em><a href="https://science.thewire.in/the-sciences/lunar-mountains-craters-landing-sites-solar-system/">Republished</a> by The Wire Science.</em></p>

</div>

			</article>
					</div>
	</div>
</main><!--/.neve-main-->




</div></div>]]>
            </description>
            <link>https://jatan.space/exploring-moon-mountains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24363074</guid>
            <pubDate>Thu, 03 Sep 2020 11:54:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India authorises sale of electric vehicles without batteries]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24362305">thread link</a>) | @baybal2
<br/>
September 3, 2020 | https://www.electricmotorengineering.com/india-sale-of-electric-vehicles-without-batteries/ | <a href="https://web.archive.org/web/*/https://www.electricmotorengineering.com/india-sale-of-electric-vehicles-without-batteries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Batteries comprise 30-40% of the upfront cost. To push electric mobility, the Ministry of Road Transport and Highway (MORTH) of India, announced that all the states and union territories (UTs) <strong>have now been allowed the registration and sale of electric vehicles (EVs) without pre-fitted batteries</strong>.<br>
The move is likely to provide the necessary boost for the<strong> wider adoption of EVs across the country.</strong><br>
Practically, the government is striving to create an ecosystem to accelerate the uptake of electric mobility in the country. This will not only protect the environment and reduce the oil imports but also provide opportunities to the sunrise industry.<br>
What is the situation in India? According to the <a href="https://www.smev.in/"><strong>Society of Manufacturers of Electric Vehicles</strong></a>, the sale of electric vehicles in this country increased by 20% in 2019-20, mainly driven by rising sales of two-wheelers.</p>
    </div></div>]]>
            </description>
            <link>https://www.electricmotorengineering.com/india-sale-of-electric-vehicles-without-batteries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24362305</guid>
            <pubDate>Thu, 03 Sep 2020 09:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unix `Who` Command]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24361957">thread link</a>) | @warenhor
<br/>
September 3, 2020 | https://gauthier.uk/blog/who/ | <a href="https://web.archive.org/web/*/https://gauthier.uk/blog/who/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentBody"><p>While working on a completely different project, I started to ask myself how the <code>who</code> command was working under the hood. In the end, I thought it was a good topic for a blog post.</p><h2 id="who-is-who">Who is <code>who</code></h2><p>Let‚Äôs start with the basics. the <code>who</code> command allows you to list the users currently logged on the system.
For example, on my machine:</p><pre><code>$ who
gauthier tty2         2020-08-30 15:06 (tty2)
gauthier pts/1        2020-08-30 15:06 (tmux(1555).%0)
gauthier pts/2        2020-08-30 16:41 (tmux(1555).%6)
gauthier pts/4        2020-08-30 15:57 (tmux(1555).%3)
</code></pre><p>It tells me that I am logged on the ‚Äúphysical‚Äù terminal <code>tty2</code> and on three pseudo terminals. Indeed my current session of Gnome Shell is running on <code>tty2</code> and I have 3 <code>tmux</code> windows open.</p><p>But where is it getting those information? Probably from a file as everything is a file with Linux, but let‚Äôs check which one and how the data is stored there.</p><h2 id="a-bit-of-reverse-engineering">A bit of reverse engineering</h2><p>In order to see what the <code>who</code> command is doing I could try to find the source code and dig into it. But I found it fun to use <code>strace</code> to check what the process was doing instead. Since we are expecting <code>who</code> to read system files, we can only focus on the <code>open</code> syscalls.</p><pre><code>$ strace who 2&gt;&amp;1 | grep open
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/usr/lib/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/usr/lib/locale/locale-archive", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/var/run/utmp", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/etc/localtime", O_RDONLY|O_CLOEXEC) = 3
</code></pre><p>We can quickly filter what is interesting and what is not. The first files two files <code>/etc/ld.so.cache</code>, <code>/usr/lib/libc.so.6</code> are shared libraries loaded by the process, those are interesting us.</p><p>Then <code>/usr/lib/locale/locale-archive</code>, <code>/var/run/utmp</code> and <code>/etc/localtime</code> are opened. Let‚Äôs see what those files are storing.</p><p>When exploring this kind of topics, it is always interesting to first search into the man pages before starting browsing the web. The 5th section of the manual is dedicated to ‚Äúfile formats and conventions‚Äù and seems a good place to start.</p><h3 id="locale-archive">locale-archive</h3><pre><code>$ man -wK 5 '/usr/lib/locale/locale-archive'
</code></pre><p>Sends us to <code>locale(5)</code> where we can read:</p><pre><code>The  locale  definition file contains all the information that the localedef(1) command needs to convert it into the binary locale data‚Äêbase.
</code></pre><p>The page also sends us to <code>locale(7)</code> for more explanation about those informations:</p><pre><code>A  locale is a set of language and cultural rules. These cover aspects such as language for messages, different character sets, lexico‚Äêgraphic conventions, and so on. A program needs to be able to determine its locale and act accordingly to be portable to different cultures.
</code></pre><p>So the <code>who</code> command read from this file, probably using the <code>setlocale(3)</code> function, to find out how the information should be formated and displayed.</p><p>We can actually check it:</p><pre><code>$ LC_ALL='fr_FR.utf8' who
gauthier tty2         Sep  2 11:38 (:1)
gauthier pts/1        Sep  2 12:11 (tmux(2445).%0)
gauthier pts/2        Sep  2 12:37 (tmux(2445).%1)
gauthier pts/3        Sep  2 13:04 (tmux(2445).%2)
</code></pre><p>Indeed, the date is is not formated the same way!</p><h3 id="localtime">localtime</h3><pre><code>$ man -wK 5 '/etc/localtime'
</code></pre><p>Sends us to <code>localtime(5)</code> which explains:</p><pre><code>The /etc/localtime file configures the system-wide timezone of the local system that is used by applications for presentation to the user.
</code></pre><p>Probably <code>who</code> uses this file (or uses a function that is using this file) to print timestamps (columns 4 and 5 of <code>who</code>'s output) using the correct timezone configured by the user.</p><h3 id="utmp">utmp</h3><p>Finally comes <code>/var/run/utmp</code>:</p><pre><code>$ man -wK 5 '/var/run/utmp'
/usr/share/man/man5/utmp.5.gz
</code></pre><p>Where we can read:</p><pre><code>The  utmp  file  allows  one to discover information about who is currently using the system.  There may be more users currently using the system, because not all programs use utmp logging.
</code></pre><p>Great! We found where the <code>who</code> command is getting its data. It would be nice to be able to read this file to get those data without using the <code>who</code> command. Unfortunately:</p><pre><code>The file is a sequence of utmp structures, declared as follows in &lt;utmp.h&gt; (note that this is only one of several definitions around; details depend on the version of libc):
</code></pre><p>At this point we understood what the <code>who</code> command is doing: it is reading <code>/var/run/utmp</code>, parsing the content and formating it nicely. Let‚Äôs see if we can reproduce this simple behavior.</p><h3 id="my-own-who">My own <code>who</code></h3><p>What we simply need to do is: open <code>/var/run/utmp</code>, read <code>n</code> bytes (where <code>n</code> is the size of the <code>utmp</code> structure), print the info contained in each structure, continue until we reach the end of the file. With a bit of formating, we can even make it look like the original <code>who</code> command.</p><pre><code>#include &lt;utmp.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;time.h&gt;

int main() {
  // set the right locale to display the information nicely
  setlocale(LC_ALL, "");

  // open the file
  FILE * file= fopen("/var/run/utmp", "rb");

  // just for safety
  if (file == NULL) {
    return 1;
  }

  // initialize the utmp structure
  struct utmp entry;

  // read the entries from the file one by one
  while (fread(&amp;entry, sizeof(struct utmp), 1, file) != 0) {
    if (entry.ut_type != USER_PROCESS)
      continue;

    // format the date (remember who uses the /etc/localtime?)
    char date[80];
    time_t raw_time = entry.ut_tv.tv_sec;
    struct tm *ts = localtime(&amp;raw_time);
    strftime(date, sizeof(date), "%Y-%m-%d %H:%M", ts);

    // print the output for this entry, tries to mock who's output
    printf("%-8s %-12s %s (%s)\n", entry.ut_user, entry.ut_line, date, entry.ut_host);
  }

  fclose(file);
}
</code></pre><pre><code>$ clang -o who who.c
$ ./who
gauthier tty2         2020-08-31 10:02 (tty2)
gauthier pts/1        2020-08-31 10:03 (tmux(2220).%0)
gauthier pts/2        2020-08-31 10:08 (tmux(2220).%1)
gauthier pts/3        2020-08-31 10:33 (tmux(2220).%5)
</code></pre><p>TADA!</p><p>We can also check with <code>strace</code> if the behavior is the same:</p><pre><code>$ strace ./who 2&gt;&amp;1 | grep -e open
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/usr/lib/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/usr/lib/locale/locale-archive", O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, "/var/run/utmp", O_RDONLY) = 3
openat(AT_FDCWD, "/etc/localtime", O_RDONLY|O_CLOEXEC) = 4
</code></pre><p>Indeed our program is doing the same as the original <code>who</code>.</p><p>Of course, this only mocks the most basic features of the <code>who</code> command and doesn‚Äôt handle any option, like the famous <code>who am i</code> or <code>who mom hates</code>.</p><h3 id="going-further">Going further</h3><p>There is still a lot to say about the <code>who</code> command. We could for example mention the <code>lastlog</code> command and its corresponding file <code>/var/log/wtmp</code>, dig into the <code>utmp</code> structure, or just try to understand what <code>utmp</code> stands for.</p></div></div>]]>
            </description>
            <link>https://gauthier.uk/blog/who/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361957</guid>
            <pubDate>Thu, 03 Sep 2020 08:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic SSL Certificates for internal IP's for home k8 setup using LetsEncrypt]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 81 (<a href="https://news.ycombinator.com/item?id=24361930">thread link</a>) | @gcds
<br/>
September 3, 2020 | https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>One of the issues I discovered while playing with microk8s Kubernetes setup locally was that many services and tools like <code>Kubernetes Dashboard</code> uses HTTPS for access and I don't want to use Self-Signed SSL certificates as it would require me installing these certificates in every device I use which would be a pain in the butt. So I was on the journey finding a way to have an SSL Certificate for my internal IP addresses. This article will document my journey of getting automatic SSL certificates for my internal microk8s Kubernetes setup.</p><h2 id="ssl-certificate-for-internal-ip-address">SSL Certificate for internal IP address?</h2><p>My first question was is there a way to get an SSL certificate from Public trusted Certificate Authority after looking at many free services like Let's Encrypt and similar services don't provide certificates to IP addresses, but only to domain names.</p><p>After discovering the issue with no way to get an SSL certificate for internal IP I was looking into other options for my problem. After racking my brains for a few minutes I had a question: Could I create a DNS A record for internal IP and would it work? A quick visit to my DNS control panel adding A record to the local IP address and visiting the domain name and seeing my local IP address served website I was amazed that it worked.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image.png 1000w, https://www.techprowd.com/content/images/2020/09/image.png 1212w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-1.png" alt=""></figure><p>Discovering that I can have a domain name for internal IP working I was surprised now I had curiosity if I will be able to use service like Let's Encrypt to generate an SSL Certificate for this domain name but if I remember correctly the Let's Encrypt requires external access to verify domain name ownership. Hmm, maybe there is a way to verify domain name ownership without external access? After some digging around Let's Encrypt documentation, I found that there many ways to verify domain ownership one of them is DNS plugins which have many DNS providers to automatically verify domains by modifying DNS records using API from those providers. In my case it is DigitalOcean.</p><p>Following <code>certbot-dns-digitalocean</code> <a href="https://certbot-dns-digitalocean.readthedocs.io/en/stable/">documentation</a>I tried to generate a certificate for internal IP but I ran into the issue that default macOS <code>certbot</code> installation from <code>brew install certbot</code> had no <code>certbot-dns-digitalocean</code> plugin available.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>After a quick search online I found that DNS Plugins are not installed by default with <code>certbot</code>. I needed to install <code>certbox-dns-digitalocean</code> plugin using PIP</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Afterward, I was able to generate a certificate without many issues:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Applying SSL certificate to local HTTPS server I was able to get HTTPS valid response from the internal IP address using a domain name</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-5.png" alt=""></figure><p>Now that I know that I can generate &amp; use an SSL certificate for internal IP address just by using a domain name. Now I can try to migrate this knowledge to integrate this to microk8s local setup.</p><h2 id="integrating-let-s-encrypt-with-dns-challenge-into-microk8s-setup-using-cert-manager">Integrating Let's Encrypt with DNS challenge into microk8s setup using <code>cert-manager</code></h2><p>I am not going to describe microk8s Kubernetes setup as it is pretty straightforward compared to the plain Kubernetes setup.</p><p>The first step is to install <code>cert-manager</code> I will be using Helm to install it.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now let's configure Certificate Issuer. I will be using the configuration for DigitalOcean but it should be pretty easy to follow instructions from <a href="https://cert-manager.io/docs/configuration/acme/dns01/">documentation</a>.</p><p>First, we need DigitalOcean API token Base64 encoded to be saved in secrets</p><p>You can encode token to base64 using <code>echo -n "Token" | base64</code></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now we need to configure Certificate Issuer. (I had to change kind from <code>Issuer</code> to <code>ClusterIssuer</code> because of namespace issues)</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now that we configured everything we should use the SSL certificate somewhere for this article I will configure microk8s ingress to allow access to <code>kubernetes-dashboard</code> via <code>https://server.techprowd.com/dashboard</code></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now after applying the resources we can check if our certificate resource was created and check if our Let's Encrypt Certificate was created too</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Now that everything created we should be able to access <code>https://server.techprowd.com/dashboard</code></p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-6.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-6.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-6.png 1000w, https://www.techprowd.com/content/images/2020/09/image-6.png 1135w" sizes="(min-width: 720px) 720px"></figure><p>If I understood correctly the Certificate will be automatically renewed when expiration time comes up.</p><p>So that's all for this article. I hope this helped other people who had similar ideas like me when started working with Kubernetes.</p><p>P.S. I am not a professional Kubernetes engineer and everything mentioned in this article is just my assumptions and trying out practices in the local environment.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.techprowd.com/automatic-ssl-certificates-for-home-microk8s-setup-using-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361930</guid>
            <pubDate>Thu, 03 Sep 2020 08:27:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heuristics to Generate Startup Ideas (2019)]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24361055">thread link</a>) | @docuru
<br/>
September 2, 2020 | https://avichal.com/2019/02/24/heuristics-to-generate-startup-ideas/ | <a href="https://web.archive.org/web/*/https://avichal.com/2019/02/24/heuristics-to-generate-startup-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2992">
	<!-- .entry-header -->

	<div>
		
<p>I regularly help pre-seed entrepreneurs identify and evaluate potential startup opportunities. The following is a set of heuristics I‚Äôve developed and collected over the years that might of use.</p>



<p>These heuristics are just a starting point to <strong>identify interesting, unsolved problems</strong> in the world that may turn in to great startups. Entrepreneurs must still go deep on understanding their customers, the business model, have a clear answer to <a href="https://avichal.com/2017/11/27/why-now/">Why Now?</a> there is a big shift in the market, and <a href="http://paulgraham.com/startupideas.html">focus on identifying problems rather than generating ideas that <em>sound</em> good.</a></p>



<ol><li>Tools inside a big company ‚Äî High growth companies often first experience a problem other companies will soon face and solve it internally. Bringing these tools to everyone else can work well, e.g. Asana was inspired by the Facebook internal tasks tool, Cloudera was inspired by Facebook‚Äôs internal data infrastructure. </li><li>Consumer generation shift ‚Äî Think about a consumer company that started ~7 years ago. Generations shift in about 7-10 years, thus tastes evolve, and platforms shift. Thus there is an opening to acquire customers, e.g. Snapchat started 2011 while Facebook started 2004</li><li>Big company acquisitions ‚Äî If a company is acquired for $5B+, consider a competitor. This may indicate product maturity, a departure of talent after earnouts, or becoming focused on profits vs. product investment. Now may be a great time to re-imaginge LinkedIn or Github</li><li>Market validation from other startups ‚Äî Find a company that recently raised a series A and approach solving the problem differently. Often the first company to identify an opportunity will not win but does indicate customers have a real problem they want solved.</li><li>Revisit ideas that were too early ‚Äî Look back at ideas that were hot 10 years ago because entrepreneurs have a tendency to be too early. See if any might make sense now, e.g. Instacart vs. Webvan.</li><li>Invert a successful company‚Äôs core competency ‚Äî Take the core strength of a company and flip it on its head to see what a product experience may be if you did the opposite, e.g. Snapchat was based on ephemerality and Facebook based on permanence of identity, or Southwest was based on a point-to-point model with only one type of plane whereas other airlines use a hub and spoke model with multiple types of planes.</li><li>Extend consumer behaviors to businesses ‚Äî Take a product used by consumers and think about how it might apply to prosumers, enterprises, and small businesses, e.g. LinkedIn vs Facebook.</li><li>Turn open source projects in to SAAS businesses ‚Äî Find open source projects that are very popular and turn these in to out of the box services for enterprises, e.g. PagerDuty is like Nagios.</li><li>Compete with old world industries using software ‚Äî Find an industry that is resistant to using software and build a vertically integrated version to compete with that industry, e.g. Atrium vs. law firms.</li><li>Low NPS, fragmented industries ‚Äî Identify a large, a highly-fragmented industry with terrible net-promoter-score and build a modern, software-first version of their product, e.g. OpenDoor (credit to <a href="https://twitter.com/rabois">Keith Rabois</a> for this one) </li><li>Make things programmable ‚Äî Take a desktop utility, move it online, and make it more powerful by making it more programmable, e.g. Airtable and Notion (similar to <a href="http://blog.eladgil.com/2019/01/interesting-markets-2019-edition.html">Elad Gil‚Äôs idea around devsumers</a>)</li><li>Unbundle a company ‚Äî Look at the functions of modern companies and unbundle them to make them available for companies of all sizes, e.g. WeWork is the unbundled facilities group at most big companies</li><li>Look to engineers‚Äô hobbies ‚Äî Figure out where hobbyist engineers are spending their spare time and how to productize that (<a href="http://cdixon.org/2013/03/03/what-the-smartest-people-do-on-the-weekend-is-what-everyone-else-will-do-during-the-week-in-ten-years/">Chris Dixon‚Äôs idea</a>)</li><li>Understand how teens communicate ‚Äî Figure out where teenagers are spending their time to see what the communication products of the next decade may be. Teens are unencumbered and very creative, so seek to understand the motivations instead of judge.</li><li>Travel and observe non-software solutions ‚Äî Travel to new places to discover non-software solutions that other countries/people/markets have come up with to various problems, e.g. I was in Moscow in 2006 and people could just hail any stranger on the street to drive them somewhere like a cab. It may not have been a big leap if you saw this behavior to Uber/Lyft on your phone.</li><li>Look at behaviors in certain geographies ‚Äî Smaller, homogenous culture countries (Sweden, Korea, Japan) are early adopters of many technologies. Spend time there to understand what they are doing that isn‚Äôt globally popular yet, e.g. watching other people play video games or mobile payments took off in these markets very early relative to the US.</li><li>Unbundle the government ‚Äî Think about what services the government offers and how you might build a profitable business model around these, perhaps even by offering these services in a more cost-effective way back to the government, e.g. SpaceX is a private NASA, FedEx is a private postal service.</li><li>Verticalize an already successful business ‚Äî Find a massively successful business such as Salesforce and target it for a vertical that is traditionally challenging to access, e.g. Veeva is a pharma industry specific CRM worth $15B+ and raised only $7M in funding.</li><li>Build something for a distribution channel ‚Äî Identify a new distribution channel that would enable access to a new customer, and then think through what that customer wants that the distribution channel does not want to provide, e.g. Pinterest and Yelp built on SEO, Paypal built on eBay, YouTube embedded inside MySpace before MySpace had a video product.</li><li>Draft on a regulatory shift ‚Äî Build behind a big regulatory shift to compete with large incumbents who will be slow to move and have regulatory + technical baggage, e.g. Oscar Health after Obamacare. I‚Äôm sure some companies will spin up to help people transition to a post-GDPR world.</li></ol>



<p>I‚Äôm sure there are other good heuristics to use as a starting point. If anyone sends me others, I‚Äôll add them to my blog post as a reference for others.</p>




			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
</article></div>]]>
            </description>
            <link>https://avichal.com/2019/02/24/heuristics-to-generate-startup-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361055</guid>
            <pubDate>Thu, 03 Sep 2020 05:37:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coping with Cats]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 144 (<a href="https://news.ycombinator.com/item?id=24361029">thread link</a>) | @luu
<br/>
September 2, 2020 | https://acesounderglass.com/2020/09/02/coping-with-cats/ | <a href="https://web.archive.org/web/*/https://acesounderglass.com/2020/09/02/coping-with-cats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10918">
	<!-- .entry-header -->

	
	
	<div>
		<p>I love my two cats dearly and they bring a lot of joy to my life, but they also bring other things, like poop, and fur.&nbsp; When I tried to research mitigations for any of these it was 100% SEO listicles, so I‚Äôm sharing my raw data in the hopes that the next person can find something real-if-incomplete instead of a list of every automated litter box that has ever been manufactured.</p>
<p>I wrote the bulk of this in February, but then one of the cats developed dermatitis and I put it on pause until I could make sure it wasn‚Äôt caused by anything on this list. Alas, it wasn‚Äôt, she‚Äôs just allergic to my new apartment. But then I wanted to test something else, and suddenly six months had passed. So if the tenses seem weird, that‚Äôs why.</p>
<p>(Links are affiliate links when possible)</p>

<p>I screwed up choosing my new apartment (this was written before the allergy thing). I remembered to check for space to put the litter box in the bathroom, but in my joy at finding a place that allowed that at all after so many that did not,&nbsp; I forgot to check if that space was also where you stood to wash your hands. So I ended up having to put the box in the living room. I‚Äôve done that before and didn‚Äôt want to go back to having to keep the window open year round and still smelling poop. I also didn‚Äôt love the aesthetic.&nbsp; So I set up something kind of elaborate.</p>
<h2><a href="https://kittyvent.com/products/kitty-vent">KittyVent Litter Box Ventilator</a></h2>
<p>This is a long piece of hosing with a gentle fan in it, and a plastic thingy to block off a window that has a hole for the hose to connect to (similar to what you‚Äôd use for a portable air conditioner)</p>
<p><img src="https://cdn.shopify.com/s/files/1/2969/4434/products/IMG_0842_075fb887-2c88-400b-9bc8-3973573e3915_1024x1024@2x.jpg?v=1545953794" width="423" height="282"></p>
<p>The window-blocking thing works vertically but won‚Äôt stay up on its own, I had to tape it. The fan is extremely quiet, you can‚Äôt tell it‚Äôs on from more than six inches away. I‚Äôm very sure it works because the first time I noticed a smell, I found the fan had been turned off.</p>
<p>There are instructions for how to DIY this available online (e.g. <a href="https://www.instructables.com/id/Cat-Litter-Box-Odor-Eliminator-Fan-FlowCat/">here</a>), but I just bought it and it worked fine.</p>
<h2>Litterbox Holding End Table</h2>
<p>To make it less hideous, I got an end table designed to hold a litter box. Amazon is full of these, but most have only a single entrance and no ventilation. I assume these are aimed at people who haven‚Äôt thought things through. I wanted something I could connect a vent to and actually get rid of the smell. You might be able to cut a hole in one of the ventless ones to attach the hose to but I didn‚Äôt feel like bothering, so I got one with ventilation.</p>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/91iP7ZrigoL._AC_SL1500_.jpg" width="443" height="420"></p>
<p>I chose ecoFlex (<a href="https://www.amazon.com/gp/product/B01BM8E4KK/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B01BM8E4KK&amp;linkId=12a658675d21d4d4f9cad298d5ba2314">affiliate link</a>)&nbsp; because matched my it existing furniture and was the only option with both ventilation holes and a second shelf. For this, I accepted it being really much larger than it needed to be. Also the copytext said something about liquid-proof, non-smell-absorbant material, although who knows how true that is. Then I packing taped the ventilation hose to a hole in the back that wasn‚Äôt shown in the pictures, apparently intended for electric cords to automated litter boxes.</p>
<p>My cats adapted stupidly well to this- when I set up the litter box with the door open, they both used it within 10 minutes, despite their other litter box still being available. They did just as well when I closed the door.</p>
<p>Some litter does escape the table, so have a plan for that.</p>
<h2>Dog Poop Bags</h2>
<p>My weird conservation instincts push me not to empty the litter box until I can fill a bag. Otherwise I‚Äôm wasting valuable bag. So I bought a bunch of very small, very cheap bags and stored them in that shelf in the litter box end table, which is why I wanted it so much. I chose Amazon Basics Dog Poop Bags (<a href="https://www.amazon.com/gp/product/B00NABTGY2/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B00NABTGY2&amp;linkId=4d1641dea9b445b48539e119879ecada">affiliate link</a>) based on WireCutter‚Äôs <a href="https://thewirecutter.com/reviews/best-dog-poop-bags/">recommendation</a> and so far they are resoundingly fine.</p>
<h2>Dr Esley Cat Litter (<a href="https://www.amazon.com/gp/product/B07L9WFY14/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B07L9WFY14&amp;linkId=37e0a6f0fb2ce49f0ba47c52c36791d7">affiliate link</a>)</h2>
<p>I got this because Sweethome recommended it. I didn‚Äôt appreciate how much better it was working until a delivery screw up made me use <a href="https://www.amazon.com/gp/product/B06ZZYMWVT/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B06ZZYMWVT&amp;linkId=e9f8cccc7ed36fc1765011ac565da4d4">Arm and Hammer</a> and there started to be a smell where there hadn‚Äôt been before.</p>

<h2><a href="https://www.litter-robot.com/litter-robot-3.html">Litter Robot 3</a></h2>
<p>This is so close to being a truly great product, but isn‚Äôt quite reliable enough to be the only litter box. It had a tendency to get stuck in an unusable position, which eventually forces the cats to go elsewhere. The drawer the poop stays in doesn‚Äôt completely contain the smell. Also the range of litter between ‚Äúexcess will get dumped‚Äù and ‚Äútoo low‚Äù is uncomfortably thin. I‚Äôd still recommend it as a second litter box to cut down on scooping, or in a populous household where there will always be someone to turn it off and on again.</p>
<h2>Two Layer Litter Mat (<a href="https://www.amazon.com/gp/product/B00G67FD6W/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B00G67FD6W&amp;linkId=9e1bbec26c9a003b834013f6cbb1bc7d">affiliate link</a>)</h2>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/81BjAf-AA6L._AC_SL1000_.jpg"></p>
<p>This actually worked great at its stated purpose of catching litter the cats track out of the box, but when the cats pooped on it (say, because the litter box had been upside down for six hours), it was almost impossible to clean, especially if I caught it less than instantly. Plus it is ugly.</p>
<h2>Open Window with a Fan</h2>
<p>This was definitely better than not having an open window with a fan, but there‚Äôs no comparison between it and the vent-with-hose.</p>


<h2>Silicone Grooming Gloves (<a href="https://www.amazon.com/gp/product/B01N9KSITZ/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B01N9KSITZ&amp;linkId=cf4e5b0147e03c93e42da573c5afaf32">affiliate link</a>)</h2>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/713JHXyZS9L._AC_SL1000_.jpg" width="356" height="321"></p>
<p>These collect a lot of hair, plus their squishiness means you can brush bony areas that would be a problem for a metal comb. The cats start purring the instant I pet them with these.</p>
<p>Downside: kind of a pain to get the hair off the glove, does not pick up 100% of the fur it loosens, so be sure to use it somewhere easy to vacuum or at least not your own lap.</p>

<h2>The Dryer</h2>
<p>Turns out dryers are reasonably good at removing cat hair if you wait long enough. Remember to clean the lint trap frequently.</p>
<h2>Reusable Lint Roller</h2>
<p>I tried two made of the same material- a paddle shaped one (<a href="https://www.amazon.com/gp/product/B07SBM761G/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B07SBM761G&amp;linkId=94a8f23a77ace6722af2df51d72f696b">affiliate link</a>)</p>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/71Dh0-dIIwL._SL1467_.jpg" width="341" height="324"></p>
<p>and a more traditional roller shaped one (<a href="https://www.amazon.com/gp/product/B00BAGTNAQ/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B00BAGTNAQ&amp;linkId=cb9987743b51a7b5feea72739bf6ac92">affiliate link</a>)</p>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/61VbLSzuCrL._SL1500_.jpg" width="340" height="272"></p>
<p>Of these, I found the wand shaped one easier to use, and the roller easier to clean. I prioritized use, but your mileage may vary. Also, you need to actually read the instructions on how to use it, running it back and forth like disposable lint roller just redistributes the hair.</p>
<p>Here is a picture of a pillow after I ran the paddle shaped one over part of it several times. I think this gives a good idea of what it‚Äôs capable of, i.e. it‚Äôs a significant improvement but doesn‚Äôt get everything.</p>
<p><img src="https://lh3.googleusercontent.com/CdwlDpVYOYR7uoDoi2G-hNc8DLvvdJcuKTEiekukqxS_Ao3h9i5dMpu5j-s6GWrwGTe-34ILa7rc-Y83frrUc5SpqWEqErREaYHV8QACkzN1Qc7ziND_ZkQ7bPRcB2J6jcr9cxcOWwBpDKwT-zVo5dalEK1QTcm5cntNpZpe213JKFvj0cH-3aSXp9gjvW_yvmj_PRXNWBOEbkCwYiz_sVkrhebNvKv48qHgcu0hq7P-cW5DGbFncCoHJYGk0hn5zUSJGTfBZycsdWoq9wwXV3fepvtl8koVwGgAZTu-eGAifmoPK1RIQurOfZd8aYCANtifgD21PKFn0UTrFUx6gJ1paCdQ2uEVuYunpuxPVALjhQddhCI74D525eMhQ2b7-pj7q74Q9s-DI1_DHsmdvxwlGAzbPKowjkgj_XCi3kcq6MgV4ApNaZvSE89ZV3dok7peQEkh3WdP6p_V5WZbTMLdxwSqrUWU2gWNgt5R9Su6mxnSad_vpkMcSmCmln5j5aLfC0hBCOPWtYBiZ20pr0x9q2atPvG6kUhElanjCNtJBYvsgewnqxSCbzqB0tcfJ3UNFuETuFCgQ_kSU_5JMMeqa2oi94i1GH2Gogjm9wMKO3iruENNYaRmHW-9ogCsfvOHPPP558lJu78AOFY3Ld2zEjEfijgu22QP1U3vxkZBFGR_fKbfkvI=w1760-h1320-no" width="340" height="255"></p>
<p>Note: inbetween writing this and publishing, the paddle brush people offered me actual money to publish a review, which I plan on taking them up on, assuming I can find the form.</p>
<h2>Shark Pet-Perfect II Handheld Vacuum (<a href="https://www.amazon.com/gp/product/B0037HHFMO/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B0037HHFMO&amp;linkId=4140bcc636b3132e9c69552f56ebb21e">affiliate link</a>)</h2>
<p>Sweethome‚Äôs top handheld vacuum pick was sold out everywhere and their second is specifically called out as being bad at fur, so I selected based on Amazon reviews. As a vacuum cleaner it is Not Fucking Around- it is super powerful and sucks anything off my floors. It advertises a special whirling brush aimed specifically at pet hair, but I found it choked on soft surface I tried it on, and the bristles were better. The biggest complain on Amazon was the battery life, but I got it for spot cleaning not marathons, so it‚Äôs been fine and I appreciate not paying for a feature I don‚Äôt use.</p>
<p>All of the anti-cat-hair devices work better if I stay very on top of them. Given time, the fur works itself deeper into the fabric and nothing will work except picking it out with actual human fingers.</p>

<h2>The Furminator (<a href="https://www.amazon.com/gp/product/B07MZLNVSW/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B07MZLNVSW&amp;linkId=ea4961e2a9d1ed7f9540a55d8364f886">affiliate link</a>)</h2>
<p>This is another one that was great at its official objective but failed a secret objective. It was absolutely amazing at removing fur from the cats (on areas broad and unbony enough to support the comb), and they liked it, but it left them less soft. I did not get these cats to have them at less than their maximum softness.</p>
<h2><span>Rubber Thingies You Throw in the Washer and Dryer&nbsp;</span></h2>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/71uRMoJP33L._AC_SL1500_.jpg" width="402" height="402"></p>
<p>I ran an experiment and as far as I can tell these are no better than just running an article through the dryer. Before/after photos (which I unfortunately didn‚Äôt save) didn‚Äôt show more hair being removed and the thingies are completely free of hair after many uses, which suggests to me they‚Äôre not helping much.</p>
<p>I tried wetting them and running them over a pillow case and they indeed picked up something, so I‚Äôm leaving them in my washer just in case.</p>
<p>I used LEADTEAM (<a href="https://www.amazon.com/gp/product/B07THZ68TT/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B07THZ68TT&amp;linkId=8efe81ab9e97d47fa558f5f04ff3d1f9">affiliate link</a>) and didn‚Äôt test any others, they looked identical.</p>
<h2>Wool Dryer Balls (<a href="https://www.amazon.com/gp/product/B00S0U2NVG/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B00S0U2NVG&amp;linkId=6ab6affdfd3d806f607cc564889f6bbf">affiliate link</a>)</h2>
<p><img src="https://images-na.ssl-images-amazon.com/images/I/410dKWoCFkL._AC_.jpg" alt="Smart Sheep Reusable Wool Dryer Balls, 3-Pack" width="337" height="320"></p>
<p>Testing the dryer inserts is difficult because it‚Äôs really hard to get a control group. I can‚Äôt put in half a blanket and see what the other half does. I can‚Äôt even use my two identical blankets, because they‚Äôre not guaranteed to have identical amounts of hair on them. I tried with socks but was kind of out of patience by that point. I was pretty confident the rubber ones were doing nothing, but despite a really silly amount of rigor involving photos and test swabs with the lint roller, I just can‚Äôt tell with these.</p>
<h2>Disposable Lint Rollers</h2>
<p>These were better than nothing but not as good as the reusable roller.</p>

<p>My cats were never great at eating but had gotten to the point where between the two of them someone was vomiting almost every day without cause (cause = ‚ÄúI went too long without eating‚Äù, ‚ÄúI ate too fast because I went too long without eating‚Äù and hairballs), and one had lost a noticeable amount of weight (her current weight would be fine if she‚Äôd started there, but losing almost 20% of her body weight for no known reason is concerning). There was also behavior that made me think they didn‚Äôt like their food- things like persistently begging and then when I put new food down, sniffing it, looking upset and begging more. So I talked to the vet.</p>
<h2>Prescription Food and/or B12 vitamins (<a href="https://www.amazon.com/gp/product/B07MWKYP86/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B07MWKYP86&amp;linkId=8707696381553f9939f9fdf6dda878ff">affiliate link</a>)</h2>
<p>I started both of these at the same time and now the cats are down to vomiting once a week, tops, some of which is for cause. They don‚Äôt love the prescription food by they will eat it. They‚Äôre fine with the vitamins.</p>
<p>In terms of specific brands:</p>
<ul>
<li>They hate <a href="https://www.royalcanin.com/us/cats/products/vet-products/feline-selected-protein-adult-pd-canned-cat-food">Royal Canin Duck and Pea protein</a>. When I included this in their diet they ate only two cans of food per day (one Royal Canin, one of their old food, Friskies), which is little enough that the already-underweight one was losing ‚Ä¶</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acesounderglass.com/2020/09/02/coping-with-cats/">https://acesounderglass.com/2020/09/02/coping-with-cats/</a></em></p>]]>
            </description>
            <link>https://acesounderglass.com/2020/09/02/coping-with-cats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361029</guid>
            <pubDate>Thu, 03 Sep 2020 05:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Daemons]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24361013">thread link</a>) | @aryamansharda
<br/>
September 2, 2020 | https://blog.digitalbunker.dev/2020/09/03/understanding-daemons-unix/ | <a href="https://web.archive.org/web/*/https://blog.digitalbunker.dev/2020/09/03/understanding-daemons-unix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
		
<p>In this article, we‚Äôll take a closer look at daemons. We‚Äôll understand exactly what they are, how they‚Äôre implemented, and the scope of their responsibility.&nbsp;</p>



<h2><strong>Overview</strong></h2>



<p>Simply put, a daemon (pronounced dee-mon) is an intentionally orphaned background process. Additionally, daemons are detached from the terminal in which they‚Äôre spawned, operate without user interaction, and are descendants of the system‚Äôs init process.</p>



<p>Daemons will silently wait in the background for specific events to occur or conditions to be met before executing.</p>



<p>At boot time, Linux will start the init process (init is itself a daemon) which will serve as the parent of all processes and assign it PID 1 (process identification number). It‚Äôs important to mention that the init function is a special process that is not attached to any terminal.</p>



<p>After the boot sequence is complete, Linux will start up any previously declared daemons. These will be created through a series of fork() and exit() commands which will intentionally create an orphaned process that will eventually be adopted by the init process ‚Äì more on this soon.</p>



<h2><strong>Use Cases</strong></h2>



<p>Conventionally, daemon process names end with the letter ‚Äúd‚Äù. If you‚Äôre interested in seeing all daemons installed on your Linux machine, use this command:</p>



<p><code>service --status-all</code></p>



<p>You‚Äôve certainly encountered daemons whether you were aware of them or not:&nbsp;</p>



<ul><li>A web server is simply a process that runs continuously in the background waiting to process and respond to HTTP requests (http daemon)</li><li>sshd is the dameon responsible for SSH operations</li><li>‚ÄúMAILURE_DEMON‚Äù is a daemon that notifies the sender of invalid email recipients&nbsp;</li><li>Monitoring hardware activity like hard drive health&nbsp;</li><li>cron jobs</li></ul>



<h2><strong>Implementation</strong></h2>



<p>We‚Äôll take a look at the code to create a daemon shortly, but let‚Äôs establish some basics first.&nbsp;</p>



<p>Calling the fork() function creates a new process referred to as the child process. The child process runs in parallel with the process that triggered the fork() (the parent process).&nbsp;</p>



<p>A child process shares the same program counter and CPU registers as its parent. So, when a new child process is created, both the child and parent processes will execute the next instruction after the fork() call in parallel.&nbsp;</p>



<p>Here‚Äôs a simple example from Michigan Tech:&nbsp;</p>



<div><figure><img src="https://lh5.googleusercontent.com/Q9blfMxaFBFWjoLw_h9HxBAJYRhW5WO6ws4atHZKsY-6Bf5y9bu-EBQJ7qJ8F_piFCvK6wct0U-l9ykXRpt1DZZy_XdJZRCjnjx7WNjLpQu8sx59rsdAxQ25y-PGCJdGJ_VvpzwL" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>After fork(), both the parent and the child processes execute the following code in parallel.</p>



<div><figure><img src="https://lh3.googleusercontent.com/OeO_ztEonrxuE5Lw-N_7YS-3gOl0G0h8lQHUdax3632W6aooeiDSf7wOBIGU1aqyF_yCs6hnHv1IqJxtreeTsS_mkdukzMqcfbw2wPp_eEisclimHbtDUC45tetfvxQ_moeOVIvb" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>You can also make their execution paths differ if desired. If the fork() call succeeds, the PID of the child process is returned in the parent, and 0 is returned in the child.&nbsp;</p>



<p>In order to create a daemon, we‚Äôll fork() to create a child process and then exit() the parent. This, as previously mentioned, will purposefully create an orphaned process that will be adopted by init. </p>



<p>Our new daemon is now free to sit silently in the background outside of any terminal and perform its task.</p>



<p>While this is a practical understanding, the actual implementation is a bit more nuanced. </p>



<p>We‚Äôll need to make sure to do the following:</p>



<ul><li>Close all open file descriptors</li><li>Change the working directory</li><li>Separate from the terminal and ignore I/O signals</li><li>Disassociate from the process group and control terminal</li><li>Don‚Äôt reacquire a control terminal </li><li>Reset the file access creation mask</li></ul>



<p>The following implementation is inspired by Pascal Werkl‚Äôs work. I‚Äôve added additional documentation to make it more approachable for someone that is unfamiliar with C and/or Linux systems. I encourage you to <a href="https://github.com/pasce/daemon-skeleton-linux-c/">checkout the original code here</a>.</p>







<h2>Understanding the double fork()</h2>



<p>Let‚Äôs try and understand why we need 2 fork() calls in the code above.&nbsp;</p>



<p>When we run this program in the terminal, several environmental settings ‚Äì specifically the shell we‚Äôre working in ‚Äì are replicated to our child process. So, we‚Äôll need to disassociate our daemon from its spawning terminal.</p>



<p>That‚Äôs why we call <code>setsid()</code> and create our own independent session for the child process. </p>



<p>However, in doing so, this child process will be in its own session and process group and therefore it‚Äôll be its own session leader. The main takeaway here is that there is potential for the session leader to reacquire a terminal later on (i..e. if say the user were to open up another terminal). </p>



<p>We don‚Äôt want that. Remember, we want to be completely independent of the terminal and any user-input.</p>



<p>By calling fork() a second time, we ensure that this new process (fork-2) will have a PID outside the bounds of fork-1‚Äôs session. Since we are not calling <code>setsid()</code> on the fork-2 process, no new session is being made. In other words, we know that fork-2 is <em><strong>not</strong></em> a session leader and therefore there‚Äôs no risk of it acquiring a terminal in the future. </p>



<p>Finally, by killing fork-2‚Äôs parent, we know that we‚Äôve created an orphaned process that is adopted by init and can‚Äôt reacquire a terminal or be affected by user input.</p>



<blockquote><p>TLDR: The 2 fork() calls removes any chance of the daemon reacquiring a controlling terminal and helps ensure that the daemon is re-parented onto init. </p><p>If the use of the secondary fork() isn‚Äôt clear, don‚Äôt worry ‚Äì it‚Äôs more to do with handling a potential edge case in the environment than a necessity in a generic daemon implementation.</p></blockquote>



<h2><strong>Wrapping Up</strong></h2>



<p>Thanks for checking out this article! If you have any topic requests, please contact me or leave a comment below!</p>



<p>If you‚Äôre interested in seeing all installed daemons on your machine, use this command on Linux machines:&nbsp;</p>



<p><code>service --status-all</code></p>



<blockquote><p>Remember daemon names generally end in ‚Äúd‚Äù</p></blockquote>



<h4>Feel free to check out some of my other websites!</h4>



<p><a href="http://stickerspot.digitalbunker.dev/" target="_blank" rel="noreferrer noopener">http://stickerspot.digitalbunker.dev/</a></p>



<p><a href="http://halfway.digitalbunker.dev/" target="_blank" rel="noreferrer noopener">http://halfway.digitalbunker.dev/</a></p>



<p><a href="https://mixrecipes.digitalbunker.dev/" target="_blank" rel="noreferrer noopener">https://mixrecipes.digitalbunker.dev/</a></p>



<p><a href="http://http//lowpolygonart.com/" target="_blank" rel="noreferrer noopener">http://www.lowpolygonart.com/</a></p>




			
				</div></div>]]>
            </description>
            <link>https://blog.digitalbunker.dev/2020/09/03/understanding-daemons-unix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24361013</guid>
            <pubDate>Thu, 03 Sep 2020 05:27:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be Indistractable]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24360966">thread link</a>) | @nireyal
<br/>
September 2, 2020 | https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you | <a href="https://web.archive.org/web/*/https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>√¢‚Ç¨ÀúJust a second. I just need to respond to this one thing,√¢‚Ç¨‚Ñ¢ I said to my daughter, as I attended to my iPhone.</p>
<p>Only much later could I count the mistakes in that statement. No, it wouldn√¢‚Ç¨‚Ñ¢t take √¢‚Ç¨Àújust a second√¢‚Ç¨‚Ñ¢; no, I didn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúneed√¢‚Ç¨‚Ñ¢ to respond to the email √¢‚Ç¨‚Äú I√¢‚Ç¨‚Ñ¢m an author and researcher, and thus rarely receive messages that have a drop-everything-and-answer urgency to them. And no, it wouldn√¢‚Ç¨‚Ñ¢t be √¢‚Ç¨Àúone thing√¢‚Ç¨‚Ñ¢. My brain would be too tempted, I√¢‚Ç¨‚Ñ¢d feast on it all.</p>
<p>After I finished, I looked up and my daughter was gone. The worst part: before I became distracted, we had been playing a lovely game, telling each other what superpower we most wished for. It could have brought us closer together, but I√¢‚Ç¨‚Ñ¢d just blown the spirit and substance of it big-time.</p>
<p>If you√¢‚Ç¨‚Ñ¢re a parent in the 21st century, I bet you√¢‚Ç¨‚Ñ¢ve experienced your own version of this. But it√¢‚Ç¨‚Ñ¢s not just parents, it√¢‚Ç¨‚Ñ¢s all of us in our interactions with each other. Distraction has become the norm. We√¢‚Ç¨‚Ñ¢re blessed with pocket-sized supercomputers that connect us to anyone and everyone, and a buffet of information. But there√¢‚Ç¨‚Ñ¢s a dark side: those same gadgets distract us, often at the moments that matter most.</p>
<p>Of course, smartphones didn√¢‚Ç¨‚Ñ¢t invent distraction √¢‚Ç¨‚Äú they√¢‚Ç¨‚Ñ¢re just the latest culprit. Before that, we blamed television. And before that, it was the telephone, or comic books, or the radio. Go back more than 2,000 years, and Socrates was even criticising the written word, for causing √¢‚Ç¨Àúforgetfulness in the learners√¢‚Ç¨‚Ñ¢ souls√¢‚Ç¨‚Ñ¢.</p>
<p>Still, our present feels different, with the sources of distraction seeming greater in number and more ubiquitous. One <a href="https://journals.sagepub.com/doi/full/10.1177/0013916514539755">study</a> in 2014 showed that when two people are talking, the mere presence of a smartphone resting on a table is enough to change the character of their conversation. That√¢‚Ç¨‚Ñ¢s a tame example. To see the seriousness of the problem, look at the sobering <a href="https://www.nhtsa.gov/risky-driving/distracted-driving">statistics</a> on √¢‚Ç¨Àúdistracted driving√¢‚Ç¨‚Ñ¢ in the United States.</p>
<p>After I abandoned my daughter and our game for an utterly inconsequential email, I realised I needed to deal with my distraction problem. First, I tried a popular approach: I blamed technology and made a serious attempt at a √¢‚Ç¨Àúdigital detox√¢‚Ç¨‚Ñ¢. I bought a flip phone, subscribed to a print newspaper, and even purchased a 1990s-era word processor without an internet connection. I convinced myself that, once I banished all the technology from my life, I√¢‚Ç¨‚Ñ¢d become the disciplined writer and focused father I√¢‚Ç¨‚Ñ¢d always strived to be.</p>
<p>Talk about a rude awakening. Sitting at my ancient word processor, my eyes began to peer over to my now-tantalising bookshelf. √¢‚Ç¨ÀúHmmm,√¢‚Ç¨‚Ñ¢ I said to myself, √¢‚Ç¨ÀúI really should take a glance at this book√¢‚Ç¨‚Ñ¢. I√¢‚Ç¨‚Ñ¢d justify the distraction as necessary for √¢‚Ç¨Àúresearch√¢‚Ç¨‚Ñ¢. And if it wasn√¢‚Ç¨‚Ñ¢t reading, then I√¢‚Ç¨‚Ñ¢d find something else √¢‚Ç¨‚Äú the laundry that <em>needed</em> to be folded right now, my desk that <em>needed</em> to be tidied-up this minute. The technology wasn√¢‚Ç¨‚Ñ¢t distracting me. <em>I</em> was distracting me.</p>
<p>That√¢‚Ç¨‚Ñ¢s when I started a five-year journey to understand <a href="https://www.nirandfar.com/distractions/">distraction</a>, its causes and its cures. I discovered a great deal that I found surprising and counterintuitive, and I developed methods to deal with my distraction that actually worked √¢‚Ç¨‚Äú and didn√¢‚Ç¨‚Ñ¢t involve me trying to turn back time and operate a flip phone. I realised that distraction often begins from within, not without, and found that the fix came from identifying and managing the psychological discomfort that leads us off track.</p>
<p>As often as not, distraction is your brain ducking challenging feelings such as boredom, loneliness, insecurity, fatigue and uncertainty. These are the internal triggers √¢‚Ç¨‚Äú the <a href="https://www.nirandfar.com/kids-video-game-obsession/">root causes</a> √¢‚Ç¨‚Äú that prompt you to find the comfort of distraction and open a browser tab, Twitter or email, instead of focusing on the matter at hand. Once you identify these internal triggers, you can decide to respond in a more advantageous manner. You won√¢‚Ç¨‚Ñ¢t always be able to control how you feel √¢‚Ç¨‚Äú but you can learn to control how you react to the way you feel. A trigger that once sent you to Twitter can perhaps lead instead to 10 deep breaths.</p>
<p>Distraction, in other words, is a symptom of a problem √¢‚Ç¨‚Äú not the problem itself. Those deeper and systemic reasons √¢‚Ç¨‚Äú such as an inability to cope with fear, anxiety or stress √¢‚Ç¨‚Äú deserve our concern, because it√¢‚Ç¨‚Ñ¢s only when we start to address them that we can make real progress. When we begin to understand what we√¢‚Ç¨‚Ñ¢re trying to avoid by clicking over to Twitter or checking the news for the 10th time today, we can begin to address the issue itself, and not medicate it through more distraction. We also begin to appreciate how habitual the act of avoiding discomfort via distraction can be, and how much it√¢‚Ç¨‚Ñ¢s become a part of how we work and live.</p>
<p>The good news is that there√¢‚Ç¨‚Ñ¢s something paradoxical about discomfort: it√¢‚Ç¨‚Ñ¢s actually the best tool we have for evolving and developing as a species. Feeling bad isn√¢‚Ç¨‚Ñ¢t actually bad; it√¢‚Ç¨‚Ñ¢s what helped us survive. Writing in 2001, the American psychologist Roy Baumeister and his colleagues <a href="https://psycnet.apa.org/record/2018-70020-001">observed</a>: √¢‚Ç¨ÀúIf satisfaction and pleasure were permanent, there might be little incentive to continue seeking further benefits or advances.√¢‚Ç¨‚Ñ¢ If we didn√¢‚Ç¨‚Ñ¢t feel bad, in other words, we√¢‚Ç¨‚Ñ¢d never achieve good.</p>
<p>Once you understand the depth of distraction, you can start to manage it and improve. After years of experiments, I found myself less distracted √¢‚Ç¨‚Äú a quality that improved nearly every aspect of my life. It turns out that being able to focus on the subjects and people in my life who matter improved everything from my health to my happiness to my productivity. That can seem obvious, but I couldn√¢‚Ç¨‚Ñ¢t have fully appreciated the joys of living an indistractable life if I hadn√¢‚Ç¨‚Ñ¢t gotten there on my own after a five-year journey. Being indistractable can lead you to not just change your life for the better, but also experience life fully.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Self-explore</strong></p>
<p>Identifying the triggers that made you feel bad in the first place requires self-exploration. When you notice yourself feeling distracted, pause and ask yourself what you√¢‚Ç¨‚Ñ¢re feeling. Are you worried? Are you afraid? Then go one step deeper. What caused the sensation? How does it feel in your body?</p>
<p>In exploring my own internal triggers, I began to appreciate that my anxiety about a project, which might lead me to find a tempting Wikipedia rabbit hole, was actually adaptive: the fact that I was anxious was good because it meant I was trying to become better. It was sometimes even as easy as saying to myself: √¢‚Ç¨ÀúYou√¢‚Ç¨‚Ñ¢re getting distracted right now because you√¢‚Ç¨‚Ñ¢re worried this won√¢‚Ç¨‚Ñ¢t be up to snuff. That√¢‚Ç¨‚Ñ¢s okay. It means you√¢‚Ç¨‚Ñ¢re trying to do your best work, and that√¢‚Ç¨‚Ñ¢s something to feel good about.√¢‚Ç¨‚Ñ¢ It seems like a simple mental trick, but even that thought can have a profound influence in keeping you on track.</p>
<p>There√¢‚Ç¨‚Ñ¢s an interesting paradox about internal triggers: they can be big, imposing, powerful issues, and yet the fixes can sometimes be easy and quick. Here√¢‚Ç¨‚Ñ¢s an example: let√¢‚Ç¨‚Ñ¢s say that an internal trigger when you√¢‚Ç¨‚Ñ¢re about to get started on a looming project is boredom. You just can√¢‚Ç¨‚Ñ¢t bring yourself to get excited about doing your taxes. And because you get bored, you get distracted. But if you know you√¢‚Ç¨‚Ñ¢re going to get bored, you can find ways to avoid the distraction that will soothe the boredom. For instance, if you set a time limit to work on the otherwise mind-numbing task that is so short, you won√¢‚Ç¨‚Ñ¢t have a chance to get bored. Anyone can work on their taxes for just 10 minutes. This is called the <a href="https://www.nirandfar.com/strange-sex-habits-of-silicon-valley/">10-minute rule</a>, and it√¢‚Ç¨‚Ñ¢s an effective way to avoid distractions of all sorts. The point is to anticipate the internal trigger and then intercept it with a new routine rather than allowing yourself to slink away into doing something you didn√¢‚Ç¨‚Ñ¢t intend to do.</p>
<p>In the case of my interaction with my daughter, the internal trigger might have been anxiety about work or <a href="https://www.nirandfar.com/fomo/">fear of missing out</a> (on an email). But I can address both of those proactively, so that they don√¢‚Ç¨‚Ñ¢t interfere with precious daddy-daughter time. In the case of my work anxiety, I could make sure that someone on my team is monitoring incoming messages. I could put up an √¢‚Ç¨Àúout of office√¢‚Ç¨‚Ñ¢ email that encourages people to call me if there√¢‚Ç¨‚Ñ¢s really an emergency. Or in reality, I could get comfortable with the discomfort that I might indeed be missing out on something, but that√¢‚Ç¨‚Ñ¢s all right too. Any one of those is a better and more constructive response to the internal trigger than being distracted.</p>
<p>Whatever approach you take to address your inner triggers, it√¢‚Ç¨‚Ñ¢s encouraging to note that merely recognising uncomfortable feelings and identifying them could be beneficial. For instance, in a smoking-cessation <a href="https://www.sciencedirect.com/science/article/abs/pii/S0376871611002535?via%3Dihub">study</a>, researchers found that participants who learned to acknowledge and explore their cravings managed to quit smoking at double the rates of those in the American Lung Association√¢‚Ç¨‚Ñ¢s best-performing cessation programme. Just identifying and investigating a craving had a tremendous impact.</p>
<p><strong>Reframe</strong></p>
<p>Once you√¢‚Ç¨‚Ñ¢ve identified the triggers, you can reframe the task at hand. Sure, you might be √¢‚Ç¨Àúforced to do your taxes√¢‚Ç¨‚Ñ¢. But another way of thinking about that is that you √¢‚Ç¨Àúget to review last year√¢‚Ç¨‚Ñ¢s business successes√¢‚Ç¨‚Ñ¢. It sounds laughable, but it works. When I hit rough patches mid-book writing, I would say: √¢‚Ç¨ÀúI get to share this with my audience,√¢‚Ç¨‚Ñ¢ as opposed to: √¢‚Ç¨ÀúI really have to work on the book today.√¢‚Ç¨‚Ñ¢</p>
<p>Here√¢‚Ç¨‚Ñ¢s one strategy: I found the fun in whatever I was doing. Yes, I know, this is where you roll your eyes, but hear me out. I learned to stay focused on the tedious work of writing books by looking for and finding the mystery embedded in my work. I wasn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúwriting√¢‚Ç¨‚Ñ¢, I was √¢‚Ç¨Àúexploring√¢‚Ç¨‚Ñ¢. I wasn√¢‚Ç¨‚Ñ¢t Ernest Hemingway; I was Scooby-Doo. Research indicates that even the simple act of thinking of something that you don√¢‚Ç¨‚Ñ¢t enjoy as ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-24360966</guid>
            <pubDate>Thu, 03 Sep 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even in Go, concurrency is still not easy]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 112 (<a href="https://news.ycombinator.com/item?id=24359650">thread link</a>) | @benhoyt
<br/>
September 2, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Even in Go, concurrency is still not easy (with an example)</h2>

	<p><small>September  1, 2020</small></p>
</div><div><p>Go is famous for making concurrency easy, through good language
support for <a href="https://golangbot.com/goroutines/">goroutines</a>. Except
what Go makes easy is only one level of concurrency, the nuts and
bolts level of making your code do things concurrently and communicating
back and forth through channels. Making it do the right things
concurrently is still up to you, and unfortunately Go doesn't
currently provide a lot of standard library support for correctly
implemented standard concurrency patterns.</p>

<p>For example, one common need is for a limited amount of concurrency;
you want to do several things at once, but only so many of them.
At the moment this is up to you to implement on top of goroutines,
channels, and things like the <a href="https://golang.org/pkg/sync/"><code>sync</code></a>
package. This is not as easy as it looks, and quite competent people
can make mistakes here. As it happens, I have an example ready to
hand today.</p>

<p><a href="https://github.com/google/gops">Gops</a> is a convenient command to
list (and diagnose) Go processes that are currently running on your
system. Among other things, it'll tell you which version of Go they
were compiled with, which is handy if you want to see if you have out
of date binaries that should be rebuilt and redeployed. One of the
things <code>gops</code> needs to do is look at all of the Go processes on your
system, which it does concurrently. However, it doesn't want to look
at too many processes at once, because <a href="https://github.com/google/gops/pull/118">that can cause problems with
file descriptor limits</a>. This
is a classic case of <em>limited concurrency</em>.</p>

<p>Gops implements this at the moment with code in <a href="https://github.com/google/gops/blob/6fb0d860e5fa50629405d9e77e255cd32795967e/goprocess/gp.go#L29">goprocess.FindAll()</a>
that looks like this, in somewhat sketched and reduced form:</p>

<blockquote><pre>func FindAll() []P {
   pss, err := ps.Processes()
   [...]
   found := make(chan P)
   limitCh := make(chan struct{}, concurrencyProcesses)

   for _, pr := range pss {
      limitCh &lt;- struct{}{}
      pr := pr
      go func() {
         defer func() { &lt;-limitCh }()
         [... get a P with some error checking ...]
         found &lt;- P
      }()
   }
   [...]

   var results []P
   for p := range found {
      results = append(results, p)
   }
   return results
}
</pre>
</blockquote>

<p>(In the real code there's a WaitGroup for coordination, and the
<code>found</code> channel gets closed appropriately.)</p>

<p>How this works is clear, and is a standard pattern (covered in eg
Go 101's <a href="https://go101.org/article/channel-use-cases.html">Channel Use Cases</a>). We use a
buffered channel to provide a limited number of tokens; sending a
value into the channel implicitly takes a token (and blocks if the
token supply is exhausted), while receiving a value from it puts a
token back in. We take a token before we start a new goroutine, and
the goroutine releases the token when it's done.</p>

<p>Except that <a href="https://github.com/google/gops/issues/123">this code has a bug if there are too many processes
to examine</a>. Even knowing
that there is a bug in this code, it may not be obvious.</p>

<p>The bug is that the goroutines only receive from <code>limitCh</code> to release
their token after sending their result to the unbuffered <code>found</code>
channel, while the main code only starts receiving from <code>found</code>
after running through the entire loop, and <strong>the main code takes
the token in the loop and blocks if no tokens are available</strong>. So
if you have too many processes to go through, you start N goroutines,
they all block trying to write to <code>found</code> and don't receive from
<code>limitCh</code>, and the main <code>for</code> loop blocks trying to send to <code>limitCh</code>
and never reaches the point where it starts receiving from <code>found</code>.</p>

<p>At one level, this bug is a very fragile bug; it only exists because
of multiple circumstances. If the goroutines took the token by
sending to <code>limitCh</code> instead of the main <code>for</code> loop doing it, the
bug would not exist; the main <code>for</code> loop would start them all, many
would stop, and then it would go on to receive from <code>found</code> so that
they could receive from <code>limitCh</code> and release their token so other
goroutines would run. If the goroutines received from <code>limitCh</code> to
release their token before sending to <code>found</code>, it wouldn't exist
(but because of error handling, it's simpler and more reliable to
do the receive in a <code>defer</code>). And if the entire <code>for</code> loop was in
an additional goroutine, the main code would go on to receive from
<code>found</code> and unblock completed goroutines to release their tokens,
so the fact that the <code>for</code> loop was blocked waiting to send to
<code>limitCh</code> wouldn't matter.</p>

<p>At another level, this shows how concurrency is not easy as easy
as it looks in Go. All you need is one mistake and things skid to
a halt, and all of the code involved can look good to a casual
examination. Getting concurrency correct is simply hard for people
(we can debate about why, but I think that it is is very clear).</p>

<p>(I'm sure that the people who wrote and approved the change that
added this concurrency limiting code to gops were good programmers.
A tricky case still tripped them up, passing all of their scrutiny.
Even when I knew that there was a concurrency problem in the code
and where it was (because my <code>gops</code> was hanging all of a sudden,
and <a href="https://github.com/go-delve/delve">Delve</a> told me where
everything was stuck), it still took me some time to see what the
exact problem was.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24359650</guid>
            <pubDate>Thu, 03 Sep 2020 00:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a keyboard/video/mouse switch for my two 4k monitors]]>
            </title>
            <description>
<![CDATA[
Score 442 | Comments 219 (<a href="https://news.ycombinator.com/item?id=24357308">thread link</a>) | @car
<br/>
September 2, 2020 | https://haim.dev/posts/2020-07-28-dual-monitor-kvm/ | <a href="https://web.archive.org/web/*/https://haim.dev/posts/2020-07-28-dual-monitor-kvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I like my two big hi-res monitors. I love my keyboard and my mouse. And I connect them to my stationary
‚Äúmain‚Äù PC and to several other Windows and Mac laptops, alternatively. I‚Äôd like to easily switch where these peripheral
devices are connected to, and that‚Äôs the traditional role of a <a href="https://en.wikipedia.org/wiki/KVM_switch">KVM switch</a>.</p><p>Unfortunately for me, KVM switches that support 4K/60hz resolutions cost hundreds of dollars, there are
no KVM switches that support USB-C, and I couldn‚Äôt find KVM switches that support multiple high-res monitors
either.</p><p>So I decided to implement a mixed hardware/software solution: my monitors (all monitors today really) have more
than one input, so I can connect all my computers simultaneously. The idea is:</p><ul><li>Switch USB devices in hardware.</li><li>Detect this switch in software, and switch monitors inputs as needed.</li></ul><p>To switch USB devices, I ordered <a href="https://www.amazon.ca/gp/product/B01N6GD9JO">this USB 3.0 two-computer switch</a> from Amazon,
that‚Äôs $38 Canadian, under $30 USD.</p><p>To automatically switch monitor inputs, I <a href="https://github.com/haimgel/display-switch">wrote some software</a>.</p><p>My plan was:</p><ul><li>Watch for USB device connections/disconnections.</li><li>When a configured device is connected, use <a href="https://en.wikipedia.org/wiki/Display_Data_Channel#DDC/CI">DDC/CI</a> to
send a command to all connected monitors to switch inputs.</li><li>In case the power management turned the video output off, turn it on again (otherwise the monitors will auto-switch
back to the input that actually supplies video output).</li></ul><p>I needed this to happen on Windows and on a Mac, and mature cross-platform support for USB low-level
control and hot plug, DDC/CI and monitor power management is non-existent. I ended up implementing this two
times: <a href="https://github.com/haimgel/display-switch/tree/master/MacOS">once in Swift</a>, for MacOS, and the
<a href="https://github.com/haimgel/display-switch/tree/master/Windows">second time in Rust</a>, for Windows.</p><p>Amazingly enough, this works really well: when I press the button on the USB switch, monitor input is changed
instantaneously, it feels like a ‚Äúreal‚Äù KVM switch! üéâ</p></div></div>]]>
            </description>
            <link>https://haim.dev/posts/2020-07-28-dual-monitor-kvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24357308</guid>
            <pubDate>Wed, 02 Sep 2020 19:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DNS-based alternative to the web for structured data]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24354559">thread link</a>) | @elliottinvent
<br/>
September 2, 2020 | https://www.num.uk/blog/announcing-num | <a href="https://web.archive.org/web/*/https://www.num.uk/blog/announcing-num">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-holder">
      <div id="content">
        
<p>1st September 2020, by Elliott Brown</p>
<h4>Today we're announcing NUM, a new DNS-based protocol to store and retrieve structured data</h4>
<p>
  The Namespace Utility Modules (NUM) protocol can be used to store structured data for any domain name or email address. NUM&nbsp;records can be stored in the DNS of the independent NUM zone (e.g. <code>_num.example.com</code>) or in the hosted NUM zone (a DNS-based store of NUM records below the domain <code>num.net</code>) using a simple web interface: <a href="https://www.numserver.com/" target="_blank">NUM Server</a> <img src="https://www.num.uk/images/link-external.png" title="Content on another site." alt="Content on another site.">.
</p>
<p>
  We're announcing this experimental protocol to the technical community today and are very interested in feedback and input.
</p>
<h5>Custom and standardised records</h5>
<p>
  Custom NUM records can store structured data for any purpose, particular use cases are standardised with <a href="https://www.num.uk/modules">modules</a> <img src="https://www.num.uk/images/link-internal.png" title="Content elsewhere on this site." alt="Content elsewhere on this site.">. One of our leading use cases for NUM is contact information. Enabling organisations and individuals to store contact data in the DNS opens up lots of new possibilities like dialling a domain name or email address.
</p>
<h5>Automatically populating the DNS with millions of pieces of structured data</h5>
<p>
  As well as offering a simple, user-friendly way to adopt NUM, the NUM Server also helps overcome the chicken-and-egg problem. We&nbsp;intend to populate NUM records for millions of domain names based on website information hosted on those domain names. We&nbsp;expect to publish this data in early 2021.
</p>
<h5>Free, unrestricted and unlimited access to data</h5>
<p>
  Since NUM data is stored and served using DNS it's ultra-fast, reliable and massively scalable. Access to records on the NUM Server is free, unrestricted and unlimited forever. NUM enables organisations and individuals to take back control of their data and provides a valuable resource to developers building devices, apps and services.
</p>
<h5>Find out more</h5>

<h5>Experimenting with NUM</h5>
 


      </div>
    </div></div>]]>
            </description>
            <link>https://www.num.uk/blog/announcing-num</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354559</guid>
            <pubDate>Wed, 02 Sep 2020 16:06:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XLS: Accelerated HW Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24354083">thread link</a>) | @victor82
<br/>
September 2, 2020 | https://google.github.io/xls/ | <a href="https://web.archive.org/web/*/https://google.github.io/xls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/google/xls/tree/main/docs_src/README.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                <p><img src="https://google.github.io/xls/images/xls_logo_623_250.png" alt="XLS Logo">
</p>


<!-- nav -->

<h2 id="what-is-xls">What is XLS?</h2>
<p>The XLS (Accelerated HW Synthesis) project aims to enable the rapid development
of <em>hardware IP</em> that also runs as efficient <em>host software</em> via "software
style" methodology.</p>
<p>XLS implements a High Level Synthesis (HLS) toolchain which produces
synthesizable designs from flexible, high-level descriptions of functionality.
It is fully Open Source: Apache 2 licensed and developed via GitHub.</p>
<p>XLS is used inside of Google for generating feed-forward pipelines from
"building block" routines / libraries that can be easily retargeted, reused, and
composed in a latency-insensitive manner.</p>
<p><em>Not yet available</em>, but active work in progress is the implementation of XLS
<em>concurrent processes</em>, in Communicating Sequential Processes (CSP) style, that
allow pipelines to communicate with each other and induct over time.</p>
<p>XLS is still experimental, undergoing rapid development, and not an officially
supported Google product. Expect bugs and sharp edges. Please help by trying it
out, <a href="https://github.com/google/xls/issues">reporting bugs</a>, and letting us know
what you think!</p>
<h2 id="building-from-source">Building From Source</h2>
<p>Currently, XLS must be built from source using the Bazel build system.</p>
<p><em>Note:</em> Binary distributions of the XLS library are not currently available, but
we hope to enable them via continuous integration, <a href="https://github.com/google/xls/issues/108">see this issue</a>.</p>
<p>The following instructions are for the Ubuntu 20.04 (Focal) Linux distribution.
Note that we start by assuming <a href="https://docs.bazel.build/versions/master/install-ubuntu.html">Bazel has been
installed</a>.</p>
<pre><code># Follow the bazel install instructions:
# https://docs.bazel.build/versions/master/install-ubuntu.html
#
# Afterwards we observe:

$ bazel --version
bazel 3.2.0

$ sudo apt install python3-dev python3-distutils python3-dev libtinfo5

# py_binary currently assume they can refer to /usr/bin/env python
# even though Ubuntu 20.04 has no `python`, only `python3`.
# See https://github.com/bazelbuild/bazel/issues/8685

$ mkdir -p $HOME/opt/bin/
$ ln -s $(which python3) $HOME/opt/bin/python
$ echo 'export PATH=$HOME/opt/bin:$PATH' &gt;&gt; ~/.bashrc
$ source ~/.bashrc

$ bazel test -c opt ...
</code></pre>

<p>A reference build/test environment setup is also provided via <code>Dockerfile</code>:</p>
<pre><code>~$ git clone https://github.com/google/xls.git
~$ cd xls
~/xls$ docker build .  # Performs optimized build and test.
</code></pre>

<h2 id="stack-diagram-and-project-layout">Stack Diagram and Project Layout</h2>
<p>Navigating a new code base can be daunting; the following description provides a
high-level view of the important directories and their intended organization /
purpose, and correspond to the components in this XLS stack diagram:</p>
<p><img src="https://google.github.io/xls/images/xls_stack_diagram.png" alt="XLS Stack Diagram">
</p>

<ul>
<li><a href="https://github.com/google/xls/tree/main/dependency_support"><code>dependency_support</code></a>:
  Configuration files that load, build, and expose Bazel targets for <em>external</em>
  dependencies of XLS.</li>
<li><a href="https://github.com/google/xls/tree/main/docs"><code>docs</code></a>: Generated documentation
  served via GitHub pages:
  <a href="https://google.github.io/xls/">https://google.github.io/xls/</a></li>
<li><a href="https://github.com/google/xls/tree/main/docs_src"><code>docs_src</code></a>: Markdown file
  sources, rendered to <code>docs</code> via
  <a href="https://google.github.io/xls/contributing/#rendering-documentation">mkdocs</a>.</li>
<li>
<p><a href="https://github.com/google/xls/tree/main/xls"><code>xls</code></a>: Project-named
  subdirectory within the repository, in common Bazel-project style.</p>
<ul>
<li><a href="https://github.com/google/xls/tree/main/xls/build"><code>build</code></a>: Build macros
  that create XLS artifacts; e.g. convert DSL to IR, create test targets for
  DSL code, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/codegen"><code>codegen</code></a>: Verilog
  AST (VAST) support to generate Verilog/SystemVerilog operations and FSMs.
  VAST is built up by components we call <em>generators</em> (e.g.
  PipelineGenerator, SequentialGenerator for FSMs) in the translation from XLS
  IR.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/common"><code>common</code></a>: "base"
  functionality that layers on top of standard library usage. Generally we use
  <a href="https://abseil.io/">Abseil</a> versions of base constructs wherever possible.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/contrib/xlscc"><code>contrib/xlscc</code></a>:
  Experimental C++ syntax support that targets XLS IR (alternative path to
  DSLX) developed by a sister team at Google, sharing the same open source /
  testing flow as the rest of the XLS project. May be of particular interest
  for teams with existing C++ HLS code bases.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/data_structures"><code>data_structures</code></a>:
  Generic data structures used in XLS that augment standard libraries; e.g.
  BDDs, union find, min cut, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/delay_model"><code>delay_model</code></a>:
  Functionality to characterize, describe, and interpolate data delay for
  XLS IR operations on a target backend process. Already-characterized
  descriptions are placed in <code>xls/delay_model/models</code> and can be referred to via
  command line flags.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx"><code>dslx</code></a>: A DSL (called
  "DSLX") that mimics Rust, while being an immutable expression-language
  dataflow DSL with hardware-oriented features; e.g.  arbitrary bitwidths,
  entirely fixed size objects, fully analyzeable call graph. XLS team has found
  dataflow DSLs are a good fit to describe hardware as compared to languages
  designed assume von Neumann style computation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx/fuzzer"><code>dslx/fuzzer</code></a>: A
  whole-stack multiprocess fuzzer that generates programs at the DSL level and
  cross-compares different execution engines (DSL interpreter, IR interpreter,
  IR JIT, code-generated-Verilog simulator). Designed so that it can easily be
  run on different nodes in a cluster simultaneously and accumulate shared
  findings.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/examples"><code>examples</code></a>: Example
  computations that are tested and executable through the XLS stack.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/experimental"><code>experimental</code></a>:
  Artifacts captured from experimental explorations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/ir"><code>ir</code></a>:
  XLS IR definition, text parser/formatter, and facilities for abstract
  evaluation and execution engines (<a href="https://google.github.io/xls/interpreters/">IR interpreter</a>,
  <a href="https://google.github.io/xls/ir_jit/">JIT</a>).</li>
<li><a href="https://github.com/google/xls/tree/main/xls/modules"><code>modules</code></a>:
  Hardware building block DSLX "libraries" (outside the DSLX standard library)
  that may be easily reused or instantiated in a broader design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/netlist"><code>netlist</code></a>: Libraries
  that parse/analyze/interpret netlist-level descriptions, as are
  generally given in simple structural Verilog with an associated cell library.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/passes"><code>passes</code></a>: Passes that
  run on the XLS IR as part of optimization, before scheduling / code
  generation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/scheduling"><code>scheduling</code></a>:
  Scheduling algorithms, determine when operations execute (e.g. which
  pipeline stage) in a clocked design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/simulation"><code>simulation</code></a>:
  Code that wraps Verilog simulators and generates Verilog testbenches for XLS
  computations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/solvers"><code>solvers</code></a>:
  Converters from XLS IR into SMT solver input, such that formal proofs can be
  run on XLS computations; e.g. Logical Equalence Checks between XLS IR and a
  netlist description.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/synthesis"><code>synthesis</code></a>:
  Interface that wraps backend synthesis flows, such that tools can be
  retargeted e.g. between ASIC and FPGA flows.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tests"><code>tests</code></a>:
  Integration tests that span various top-level components of the XLS project.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tools"><code>tools</code></a>:
  <a href="https://google.github.io/xls/tools/">Many tools</a> that work with the XLS system and its libraries in a
  decomposed way via command line interfaces.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/uncore_rtl"><code>uncore_rtl</code></a>:
  Helper RTL that interfaces XLS-generated blocks with device top-level for e.g.
  FPGA experiments.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/visualzation"><code>visualization</code></a>:
  Visualization tools to inspect the XLS compiler/system interactively. See
  <a href="https://google.github.io/xls/ir_visualization/">IR visualization</a>.</li>
</ul>
</li>
</ul>

<p>Discussions about XLS - development, debugging, usage, and anything else -
should go to the <a href="https://groups.google.com/g/xls-dev">xls-dev mailing list</a>.</p>
<h2 id="contributors">Contributors</h2>
<p>The following are
<a href="https://github.com/google/xls/graphs/contributors">contributors</a> to the XLS
project, see our
<a href="https://google.github.io/xls/contributing/">contributing documentation</a> and
<a href="https://github.com/google/xls/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">good first issues</a>!</p>
<ul>
<li><a href="https://github.com/brajiang">Brandon Jiang</a></li>
<li><a href="https://github.com/cdleary">Chris Leary</a></li>
<li><a href="https://github.com/dmlockhart">Derek Lockhart</a></li>
<li><a href="https://github.com/felixzhuologist">Felix Zhu</a></li>
<li><a href="https://github.com/hmontero1205">Hans Montero</a></li>
<li><a href="https://github.com/jbaileyhandle">Jonathan Bailey</a></li>
<li><a href="https://github.com/julianviera99">Julian Viera</a></li>
<li><a href="https://github.com/kevineharlley">Kevin Harlley</a></li>
<li><a href="https://github.com/meheffernan">Mark Heffernan</a></li>
<li><a href="https://github.com/per-gron">Per Gr√∂n</a></li>
<li><a href="https://github.com/rchen152">Rebecca Chen (Pytype)</a></li>
<li><a href="https://github.com/rhundt">Robert Hundt</a></li>
<li><a href="https://github.com/RobSpringer">Rob Springer</a></li>
<li><a href="https://github.com/spurserh">Sean Purser-Haskell</a></li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://google.github.io/xls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354083</guid>
            <pubDate>Wed, 02 Sep 2020 15:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories]]>
            </title>
            <description>
<![CDATA[
Score 333 | Comments 108 (<a href="https://news.ycombinator.com/item?id=24353976">thread link</a>) | @kercker
<br/>
September 2, 2020 | http://brendanfong.com/programmingcats.html | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<img src="http://brendanfong.com/programmingcats_files/seal.gif" width="150">
<h2>
<a href="http://brendanfong.com/">Brendan Fong</a>,
<a href="https://bartoszmilewski.com/">Bartosz Milewski</a>,
and
<a href="http://math.mit.edu/~dspivak/">David Spivak</a>
</h2>
Department of Mathematics<br>
Massachusetts Institute of Technology<br>
<b>Office:</b> 2-180<br>
<b>Email:</b> {bfo,dspivak} -- mit/edu  <center>

<h2> IAP 2020</h2>
<img src="http://brendanfong.com/programmingcats_files/pigskell.jpeg" width="300">
</center>

<h3> General information</h3>

<table>
<colgroup><col width="105"> <col width="300">
</colgroup><tbody><tr><td>Room:</td><td>4-163</td></tr>
<tr><td>Dates:</td><td> Jan 7‚Äî31 (MTWRF)</td></tr>
<tr><td>Time:</td><td> 2‚Äî3pm</td></tr>
<tr><td>Prerequisites:</td><td> None</td></tr>
<tr><td>Credit:</td><td> 3 units (1-0-2) (P/D/F)</td></tr>
</tbody></table>
<p>

<b>Summary</b>: In this course we explain how category theory‚Äîa branch of mathematics known for its ability to organize the key abstractions that structure much of the mathematical universe‚Äîhas become useful for writing elegant and maintainable code. In particular, we'll use examples from the Haskell programming language to motivate category-theoretic constructs, and then explain these constructs from a more abstract and inclusive viewpoint. Hands-on programming exercises will be used to demonstrate categorical ideas like "the universal property of products" in working Haskell code. A rough list of topics includes: 
</p><ol>
<li>Sets, types, categories, functors, natural transformations</li>
<li>Universal constructions and associated data types</li>
<li>Adjunctions and cartesian closed categories</li>
<li>Algebras, catamorphisms, anamorphisms</li>
<li>Monads, comonads, Kleisli arrows</li>
<li>Monoids, monoidal categories, lax monoidal functors, applicatives</li>
<li>Profunctors, (co)ends, optics</li>
</ol>
<b>We will assume no background knowledge on behalf of the student</b>, starting from scratch on both the programming and mathematics.

(<a href="http://brendanfong.com/programmingcats_files/flyer.pdf">Flyer</a>)
<p>
Students are very welcome to audit.
</p><hr>

<h3>Course details</h3>
<p>
Course notes and videos will be published here following each class. Feedback about the notes is welcome <a href="https://docs.google.com/document/d/1CQF1k01Ik_ehEpvE0KzYhLZbfMQY-kPW8QAm48xTe7k/edit">
here</a> or via email to the instructors.
</p>
<p>
Students taking the course for credit will be required to complete three problem
sets. There will be no exam. See the <a href="http://brendanfong.com/programmingcats_files/C4P-syllabus.pdf">syllabus</a> for more details.
</p>

<p>The instructors will lead problem discussion and be available for questions each
day from 3 to 4pm, in the course classroom, 4-163.
</p>

<p>
There will be no class on Monday 1/20 (MLK Day).
</p>

<hr>

<h3>Course resources</h3>
    
<ul>
    <li>
        <a href="http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">Course notes: Programming with Categories</a>
    </li>
    <li>
        <a href="https://www.youtube.com/playlist?list=PLhgq-BqyZ7i7MTGhUROZy3BOICnVixETS">Class videos</a>
    </li>
    <li>
        <a href="https://roamresearch.com/#/app/programming-with-categories/page/4PUHYRX13">David Dalrymple's summaries of each class</a>
    </li>
    <li>
        <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Discussion forum</a>
    </li>
</ul>
    
<hr>

<h3>Problem sets</h3>
<ul>
<li>
  <a href="http://brendanfong.com/programmingcats_files/ps1.pdf">PS1</a> (<a href="http://brendanfong.com/programmingcats_files/pset1-solutions.pdf">Solutions</a>)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps2.pdf">PS2</a> (Due 1/24)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps3.pdf">PS3</a> (Due 1/31)
</li>
</ul>

<hr>

<h3>Open access and remote participation</h3>

<p>
  All are welcome to attend the lectures in person. We encourage those participating remotely to post questions and discuss course content on the <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Azimuth Forum</a>.
</p>
<hr>

<h3>Additional resources</h3>
<ul>
  <li>
    <a href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/">Bartosz' blog and book on Category Theory for Programmers</a>
  </li>
  <li>
    <a href="https://www.youtube.com/user/DrBartosz/playlists">Bartosz' lectures on Category Theory</a>
  </li>
  <li>
    <a href="https://ocw.mit.edu/courses/mathematics/18-s097-applied-category-theory-january-iap-2019/">Brendan and David's previous MIT course on Applied Category Theory</a>
  </li>
  <li>
    <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">An online forum dedicated to discussing this course, and applied category theory in general</a>
  </li>
</ul>

<hr>

<h3> Mailing list </h3>
Join the <a href="https://docs.google.com/forms/d/e/1FAIpQLSdnuk-lIrjBJPLAO17ZkxeSgV7f6oCp3VUmuAJd138daYDQXA/viewform">mailing list</a> to get updates.
<hr>


<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative
Commons License" width="50" src="http://brendanfong.com/programmingcats_files/88x31.png"></a>
<span size="-2">This
<span xmlns:dc="http://purl.org/dc/elements/1.1/" href="http://purl.org/dc/dcmitype/Text" rel="dc:type">work</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Brendan Fong, Bartosz Milewski, and David Spivak</span> is licensed 
under a
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
Attribution-Share Alike 3.0 Unported License</a>.
</span>


</div>]]>
            </description>
            <link>http://brendanfong.com/programmingcats.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353976</guid>
            <pubDate>Wed, 02 Sep 2020 15:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Clojure in the command line with Babashka]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24353476">thread link</a>) | @Borkdude
<br/>
September 2, 2020 | https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html | <a href="https://web.archive.org/web/*/https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://www.karimarttila.fi/img/2020-09-01-using-clojure-in-command-line-with-babashka_img_1.png" alt="Ordinary Clojure code"></p>

<p><em>Ordinary Clojure code - can be run in REPL or in command line with Babashka (the whole file can be found <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">here</a> )</em></p>

<h3 id="introduction">Introduction</h3>

<p>I never bothered to learn <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a> so that I could be really fluent with it. If I needed anything beyond basic Bash stuff I immediately used <a href="https://www.python.org/">Python</a> in command-line scripting.</p>

<p>I‚Äôm currently implementing my Clojure simple server again, this time using the <a href="https://github.com/weavejester/integrant">Integrant</a> library. In this new version, I implemented three data stores: CSV, AWS DynamoDB, and Postgres. I had already implemented importing development data into DynamoDB (using Python), this time I used <a href="https://github.com/borkdude/Babashka">Babashka</a> to import development data into Postgres - mainly just to have an excuse to try if I could replace Python with Clojure when scripting something with Bash.</p>

<p>The scripts can be found in my <a href="https://github.com/karimarttila/clojure">Clojure git</a> repo in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>.</p>

<h3 id="developing-with-babashka">Developing with Babashka</h3>

<p>The really neat thing with Babashka is that you can develop your Babashka scripts as part of your Clojure project, or independently but using your favorite Clojure IDE. The picture above shows Clojure code in my favorite Clojure IDE, <a href="https://cursive-ide.com/">Cursive</a>. I have the Clojure code that imports data into the Postgres database in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>, so I have the following extra path in my <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/deps.edn">deps.edn</a>:</p>

<div><div><pre><code><span> </span><span>:postgres</span><span> </span><span>{</span><span>:extra-paths</span><span> </span><span>[</span><span>"postgres"</span><span>]}</span><span>
</span></code></pre></div></div>

<p>Then the nice thing is that I can develop the Clojure code as part of project‚Äôs other Clojure code. Let‚Äôs first create a short bash script that tells Babashka to run your Clojure code with a flag so that we know in the Clojure code when we are running the code using Babashka or using Clojure IDE REPL (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">run-bb-load-data.sh</a>):</p>

<div><div><pre><code><span>#/bin/bash</span>

<span>export </span><span>POSTGRES_PASSWORD</span><span>=</span>simpleserver
<span>export </span><span>RUNNING_BB</span><span>=</span>TRUE
bb bb_postgres.clj
</code></pre></div></div>

<p>The flag is the <code>RUNNING_BB</code> export above.</p>

<p>Then in the Clojure code we have a top level form <code>(run-me)</code> in the namespace (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">bb_postgres.clj</a>):</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-me</span><span> </span><span>[]</span><span>
  </span><span>"Loads data only if running from Babashka script which sets the environment variable.
  We don't want the repl to load the data when reloading the namespace.
  In repl experimentation use the rich comment below."</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>running-bb?</span><span> </span><span>(</span><span>System/getenv</span><span> </span><span>"RUNNING_BB"</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>=</span><span> </span><span>running-bb?</span><span> </span><span>"TRUE"</span><span>)</span><span>
      </span><span>(</span><span>import-data</span><span>))))</span><span>

</span><span>(</span><span>run-me</span><span>)</span><span>
</span></code></pre></div></div>

<p>I.e. when reloading the namespace REPL runs the code but if the flag is not set it doesn‚Äôt actually do anything - it imports the code only if we are running the code using Babashka. The reason for this is that when I reload the namespace as part of my Clojure workflow I don‚Äôt want the data import to happen. For development purposes to test importing data, or any other function, I have a <code>rich comment</code> at the end of the file:</p>

<div><div><pre><code><span>(</span><span>comment</span><span>
  </span><span>(</span><span>def</span><span> </span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>)</span><span>
  </span><span>(</span><span>get-raw-products</span><span> </span><span>data-dir</span><span> </span><span>2</span><span>)</span><span>
  </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)</span><span>
  </span><span>(</span><span>do</span><span>
    </span><span>(</span><span>delete-products!</span><span>)</span><span>
    </span><span>(</span><span>delete-product-groups!</span><span>))</span><span>
  </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>))</span><span>
  </span><span>(</span><span>load-users</span><span> </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>)))</span><span>
  </span><span>(</span><span>import-data</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-product-groups</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-products</span><span>)</span><span>
  </span><span>)</span><span>
</span></code></pre></div></div>

<p>The <code>comment</code> block is here so that REPL does not run this code when reloading, of course. The function calls you see inside the comment block are just experiments added in no particular order. I can send any of these forms individually to be evaluated in the REPL - a typical Clojure trick when developing with REPL.</p>

<h3 id="babashka-use-cases">Babashka Use Cases</h3>

<p>I really like the idea that I can now use Clojure in shell scripting. Of course I could use Clojure in shell scripting also without Babashka but JVM boot takes quite a long time which makes testing of the script in command line a bit painful. Not so with Babashka - Babashka boots lightning fast:</p>

<div><div><pre><code>Œª&gt; <span>time </span>bb <span>'(println "Hello world!")'</span>
Hello world!

real	0m0.006s
user	0m0.003s
sys	0m0.003s
</code></pre></div></div>

<p>The use cases using Babashka in my personal scripting probably is a bit like I used Babashka to import data into the Postgres database in this exercise:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-sql</span><span> </span><span>[</span><span>command</span><span>]</span><span>
  </span><span>(</span><span>sh/sh</span><span> </span><span>"psql"</span><span> </span><span>"--host"</span><span> </span><span>"localhost"</span><span> </span><span>"--port"</span><span> </span><span>"5532"</span><span> </span><span>"--username=simpleserver"</span><span> </span><span>"--dbname=simpleserver"</span><span> </span><span>"-c"</span><span> </span><span>command</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>insert-product-group!</span><span> </span><span>[</span><span>product-group</span><span>]</span><span>
  </span><span>(</span><span>println</span><span> </span><span>"Inserting product-group: "</span><span> </span><span>product-group</span><span>)</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[[</span><span>id</span><span> </span><span>name</span><span>]</span><span> </span><span>product-group</span><span>
        </span><span>command</span><span> </span><span>(</span><span>str</span><span> </span><span>"INSERT INTO product_group VALUES ('"</span><span> </span><span>id</span><span> </span><span>"', '"</span><span> </span><span>name</span><span> </span><span>"');"</span><span>)]</span><span>
    </span><span>(</span><span>run-sql</span><span> </span><span>command</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>load-product-groups</span><span> </span><span>[</span><span>product-groups</span><span>]</span><span>
  </span><span>(</span><span>doseq</span><span> </span><span>[</span><span>pg</span><span> </span><span>product-groups</span><span>]</span><span>
    </span><span>(</span><span>insert-product-group!</span><span> </span><span>pg</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>get-product-groups</span><span> </span><span>[</span><span>data-dir</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>raw</span><span> </span><span>(</span><span>with-open</span><span> </span><span>[</span><span>reader</span><span> </span><span>(</span><span>io/reader</span><span> </span><span>(</span><span>str</span><span> </span><span>data-dir</span><span> </span><span>"/product-groups.csv"</span><span>))]</span><span>
              </span><span>(</span><span>doall</span><span>
                </span><span>(</span><span>csv/read-csv</span><span> </span><span>reader</span><span>)))</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>into</span><span> </span><span>{}</span><span>
                             </span><span>(</span><span>map</span><span>
                               </span><span>(</span><span>fn</span><span> </span><span>[[</span><span>item</span><span>]]</span><span>
                                 </span><span>(</span><span>str/split</span><span> </span><span>item</span><span> </span><span>#</span><span>"\t"</span><span>))</span><span>
                               </span><span>raw</span><span>))]</span><span>
    </span><span>product-groups</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>import-data</span><span> </span><span>[]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)]</span><span>
</span><span>;...</span><span>
    </span><span>(</span><span>load-product-groups</span><span> </span><span>product-groups</span><span>)</span><span>
</span><span>;...</span><span>
</span></code></pre></div></div>

<p>I.e. parsing CSV, transforming data, and then call some program with the transformed data, possibly read what was returned and do other stuff. You could possibly do all this using plain old Bash but I never bothered to learn Bash in that level that I can do more than test some flags and call other programs using Bash.</p>

<h3 id="how-do-i-use-the-babashka-script-in-this-exercise">How Do I Use the Babashka Script in This Exercise?</h3>

<p>I used Babashka to load development data into the Postgres data store. During development I built a custom Postgres image and provided a <a href="https://github.com/casey/just">Just</a> recipe to start the data store (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/Justfile">Justfile</a>):</p>

<div><div><pre><code><span># Start local postgres</span>
@postgres:
    <span>cd </span>postgres <span>&amp;&amp;</span> ./run-docker-compose.sh
</code></pre></div></div>

<p>The <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-docker-compose.sh">run-docker-compose.sh</a> starts the Postgres docker container, creates the schema and finally calls <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">./run-bb-load-data.sh</a> which loads the data into the development Postgres data store:</p>

<div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>echo</span> <span>"NOTE: Remember to destroy the container if running again!"</span>
<span>echo</span> <span>"Starting docker compose..."</span>
docker-compose <span>-p</span> ss-postgres <span>-f</span> docker-compose-setup-local-postgres.yml up <span>-d</span>
<span>sleep </span>5
<span>echo</span> <span>"Creating Simple Server schemas..."</span>
./create-schema.sh
<span>sleep </span>1
<span>echo</span> <span>"Loading data..."</span>
./run-bb-load-data.sh
<span>sleep </span>1
docker logs <span>-f</span> ss-postgres_postgres_1
</code></pre></div></div>

<h3 id="clojure-babashka-vs-python-in-shell-scripting">Clojure (Babashka) vs Python in Shell Scripting</h3>

<p>Let‚Äôs finally compare Python and Clojure (Babashka) when doing some Linux shell scripting.</p>

<p><strong>Easiness</strong>. Both languages are pretty easy and fast to work if you have used them. Developing Python scripts is pretty fast - you just run the script in command line. Working with Clojure has one additional plus: you can use the Clojure REPL.</p>

<p><strong>Library support</strong>: Python wins. When you are scripting in Python and you realize that it would be nice e.g. to use some AWS library - just use it (e.g. <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/dynamodb/pysrc/table_importer.py">table_importer.py</a> - the AWS <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a> library). The library support for Babashka is not as extensive, of course - but Babashka supports quite many namespaces outside <code>clojure.core</code> and also some additional libraries: <a href="https://github.com/borkdude/babashka#built-in-namespaces">Babashka built-in namespaces</a> - keep eye on that page, maybe Babashka library support is growing in the future!</p>

<p>So, the library support might not be as good as with Python. But I really do love Clojure and if I‚Äôm implementing apps using Clojure it is really nice to do some ad hoc scripting using Babashka.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It‚Äôs nice to have another scripting tool in my toolbox: <a href="https://github.com/borkdude/babashka">Babashka</a>. Time will tell if I start using Clojure instead of Python as my preferred scripting language, thanks to Babashka. At least in this exercise Babashka did really well.</p>

<p><em>The writer is working at Metosin using Clojure in cloud projects. If you are interested to start a Clojure project in Finland or you are interested to get Clojure training in Finland you can contact me by sending email to my Metosin email address or contact me via LinkedIn.</em></p>

<p>Kari Marttila</p>

<ul>
  <li>Kari Marttila‚Äôs Home Page in LinkedIn: <a href="https://www.linkedin.com/in/karimarttila/">https://www.linkedin.com/in/karimarttila/</a></li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353476</guid>
            <pubDate>Wed, 02 Sep 2020 14:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Tagging Best Practices: Using Terraform and CloudFormation to Enforce Tags]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24353412">thread link</a>) | @toeknee123
<br/>
September 2, 2020 | https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/ | <a href="https://web.archive.org/web/*/https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->            
                
                <!-- End Toc -->
				

<p>Once <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/" target="_blank">you have adopted an AWS tagging strategy</a>, you‚Äôll need to make sure that all your existing AWS resources and any new ones you create abide by it. Consistency is the key - if you don‚Äôt proactively enforce your AWS tagging strategy, you‚Äôll always be playing catch up and chasing down team members to make sure they add the right tags to their resources.</p>

<p>While you can apply AWS tags to your resources manually using the <a href="https://docs.aws.amazon.com/cli/latest/reference/resourcegroupstaggingapi/tag-resources.html" target="_blank">AWS CLI</a> or <a href="https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html" target="_blank">AWS Tag Editor</a>, you‚Äôll probably find this cumbersome and error-prone at scale. A better approach is to automatically apply AWS tags to your resources and use rules to enforce their consistent usage.</p>

<p>Depending on the tool you use to maintain your infrastructure on AWS, your method of proactively enforcing AWS tags on new resources may vary. In this guide, I‚Äôll highlight two tools: Terraform and AWS CloudFormation. You‚Äôll see how to use each to create and update AWS cost allocation tags on your resources and then enforce the proper use of specific tags for new resources. By proactively enforcing your AWS tagging strategy, you‚Äôll minimize your time spent auditing and correcting improper AWS tags and force developers to learn best AWS tagging best practices for your environment.</p>



<p>The first infrastructure management tool I‚Äôll cover is <a href="https://www.terraform.io/" target="_blank">Terraform</a>. Terraform works across a variety of cloud hosting providers to help you provision and maintain your AWS resources. With Terraform, you can define your servers, databases, and networks in code and apply your changes programmatically to your AWS account.</p>

<p>If you‚Äôre new to Terraform, they have a well-documented <a href="https://learn.hashicorp.com/terraform/getting-started/intro" target="_blank">Getting Started guide</a> and several <a href="https://github.com/terraform-providers/terraform-provider-aws/tree/master/examples" target="_blank">AWS template examples on GitHub</a>. In this section, I‚Äôll show you some snippets from a demo Terraform project and module that <a href="https://github.com/CloudForecast/cf-terraform-demo" target="_blank">is available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags:</p>

<ol>
  <li>Tag a New AWS EC2 Instance with Terraform</li>
  <li>Using Terraform to Update Existing AWS Tags</li>
  <li>Enforce AWS Tags with Terraform</li>
</ol>

<h3 id="tag-a-new-aws-ec2-instance-with-terraform">Tag a New AWS EC2 Instance with Terraform</h3>

<p>If you want to deploy an EC2 instance with AWS Tags using Terraform, your configuration might include something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td><pre>resource "aws_instance" "cart" {
  connection {
    type = "ssh"
    user = "ubuntu"
    host = self.public_ip
    private_key = file(var.private_key_path)
  }

  instance_type = "t2.micro"

  ami = var.aws_amis[var.aws_region]

  key_name = aws_key_pair.auth.key_name

  vpc_security_group_ids = [aws_security_group.default.id]

  subnet_id = aws_subnet.default.id

  provisioner "remote-exec" {
    inline = [
      "sudo apt-get -y update",
      "sudo apt-get -y install nginx",
      "sudo service nginx start",
    ]
  }
  tags = {
    contact = "j-mark"
    env = "dev"
    service = "cart"
  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The above example includes three AWS cost allocation tags: <code>contact</code>, <code>env</code>, and <code>service</code> with values described as strings. When you <a href="https://www.terraform.io/docs/commands/apply.html" target="_blank">apply this configuration</a>, Terraform will connect to AWS and deploy an EC2 instance having the AWS tags you specified.</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383259429_cf-2020-08-02-a.png" alt=""></p>

<h3 id="using-terraform-to-update-existing-aws-tags">Using Terraform to Update Existing AWS Tags</h3>

<p>Terraform makes it easy to update already existing resources with AWS tags in reversible and consistent ways. If you‚Äôre using AWS tags to keep track of a resource‚Äôs contact (e.g.: <code>j-mark</code> in the above example), you‚Äôre likely to need to update the AWS tag when the team member leaves or changes roles.</p>

<p>To update the AWS tags on your resource, simply update the corresponding tags in your Terraform configuration. The new tags will overwrite any previous tags assigned to the resource, including tags added outside of Terraform.</p>

<p>For example, to change the <code>contact</code> cost allocation tag on the EC2 instance above, you might update the <code>tags</code> block above with the following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>tags = {
  contact = "l-duke"
  env = "dev"
  service = "cart"
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>When you apply this configuration, the AWS tags will be automatically updated in the AWS console:</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383277121_cf-2020-08-02-b.png" alt=""></p>

<p>If you keep your Terraform configuration files in version control - which is probably a good idea - you will be able to see how tags have changed over time. You can also review changes using the same code review process that your application code goes through to help you catch mistakes in the execution of your tagging strategy.</p>

<h3 id="enforce-aws-tags-with-terraform">Enforce AWS Tags with Terraform</h3>

<p>As your infrastructure grows, a code review process likely won‚Äôt be enough to prevent improper AWS tagging. Fortunately, you can enforce AWS tag names and values using <a href="https://www.terraform.io/docs/configuration/variables.html" target="_blank">variables</a> and custom validation rules in Terraform.</p>

<p>In the examples above, the <code>tags</code> list was hard-coded into the EC2 instance definition. A more scalable pattern would be to break your EC2 instance template into its own <a href="https://www.terraform.io/docs/configuration/modules.html" target="_blank">module</a> and use a <code>tags</code> variable. You can then write a <a href="https://www.terraform.io/docs/configuration/variables.html#custom-validation-rules" target="_blank">custom validation rule</a> to check that the tags comply with your strategy.</p>

<p>For example, if you want to check that:</p>

<ol>
  <li>The user specifies at least one tag</li>
  <li>The <code>contact</code> tag is either <code>j-mark</code> or <code>l-duke</code></li>
  <li>The <code>env</code> tag is set</li>
  <li>The <code>service</code> tag is either <code>cart</code> or <code>search</code></li>
</ol>

<p>You might create a module with a variable specified like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>variable "tags" {
  description = "The tags for this resource."
  validation {
    condition = length(var.tags) &gt; 0 &amp;&amp; contains(["j-mark", "l-duke"], var.tags.contact) &amp;&amp; var.tags.env != null &amp;&amp; contains(["cart", "search", "cart:search"], var.tags.service)
    error_message = "Invalid resource tags applied."

  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now when you run <code>terraform plan</code> with a missing or invalid tag, you‚Äôll get an error:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>Error: Invalid value for variable
...
Invalid resource tags applied.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Your rules can be as complex as <a href="https://www.terraform.io/docs/configuration/index.html" target="_blank">Terraform‚Äôs Configuration Language</a> allows, so functions like <code>regex()</code>, <code>substr()</code>, and <code>distinct()</code> are all available. That said, there are some caveats to this approach.</p>

<p>First, custom variable validation is an experimental feature in Terraform. <a href="https://www.terraform.io/docs/configuration/terraform.html#experimental-language-features" target="_blank">Experimental features</a> are subject to change, meaning that you might need to pay attention to Terraform update mores closely. To enable <code>variable_validation</code>, add the following to your <code>terraform</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>terraform {
  experiments = [variable_validation]
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Second, Terraform‚Äôs variable validation only happens during the <code>terraform plan</code> phase of your infrastructure‚Äôs lifecycle. It can‚Äôt prevent users from accidentally changing your tags directly in the AWS console, and it‚Äôs only as good as the validation rules you write. If you start using a new resource but forget to add validation rules, you might end up with lots of resources that don‚Äôt adhere to your tagging strategy.</p>

<p>Another option for paid Terraform Cloud customers is <a href="https://www.terraform.io/docs/cloud/sentinel/index.html" target="_blank">Sentinel</a>, which allows you to create custom policies for your resources. I won‚Äôt cover this method here, but Terraform has created an <a href="https://www.terraform.io/docs/cloud/sentinel/examples.html" target="_blank">example policy</a> to show you how to enforce mandatory AWS tags.</p>



<p>Similar to Terraform, AWS <a href="https://aws.amazon.com/cloudformation/" target="_blank">CloudFormation</a> lets you provision AWS resources based on configuration files. Unlike Terraform, CloudFormation is part of Amazon‚Äôs offerings, so it won‚Äôt necessarily help you if you want to use another infrastructure provider. The approach to tagging your resources in CloudFormation is similar to that used by Terraform, but as you‚Äôll see, the configuration format is different.</p>

<p>If you‚Äôre new to AWS CloudFormation, <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/GettingStarted.Walkthrough.html" target="_blank">Amazon‚Äôs official walkthrough</a> will help you get started deploying some basic templates. In this section, I‚Äôll show you some snippets from a demo AWS CloudFormation template which is <a href="https://github.com/CloudForecast/cf-cloudformation-demo" target="_blank">also available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags section:</p>

<ol>
  <li>AWS CloudFormation Template to Deploy Tags</li>
  <li>Using CloudFormation to Update AWS Tags</li>
  <li>CloudFormation Template to Enforce AWS Tags</li>
</ol>

<h3 id="aws-cloudformation-template-to-deploy-tags">AWS CloudFormation Template to Deploy Tags</h3>

<p>AWS CloudFormation is designed to make it easy to create AWS resources with a single template file. Using a CloudFormation template, every resource that can be deployed with an AWS tag.</p>

<p>For example, to create a new EC2 instance with the same three AWS tags used in the Terraform example above, add an array of <code>Tags</code> to the resource‚Äôs <code>Properties</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre>"Resources" : {
  "WebServerInstance": {  
    "Type": "AWS::EC2::Instance",
    "Metadata" : {...},
    "Properties": {
      "Tags" : [
       {
          "Key" : "contact",
          "Value" : "j-mark"
       },
       {
          "Key" : "env",
          "Value" : "dev"
       },
       {
          "Key" : "service",
          "Value" : "cart"
       }
      ],
      ...       
    }
  },
  ...         
},
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Using <a href="https://aws.amazon.com/cli/" target="_blank">AWS CLI</a>, you can <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/create-stack.html" target="_blank">deploy this CloudFormation template as a new stack</a>. This will ensure your template is valid and create the specified resources with their tags on AWS:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>If you have lots of similar resources in your template, you can deploy AWS tags to all the resources in the stack at once using the <code>--tags</code>  flag with the <code>create-stack</code> or <code>update-stack</code> commands:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre># Creating a stack with tags
aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"

# Updating a stack with tags
aws cloudformation update-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="using-cloudformation-to-update-aws-tags">Using CloudFormation to Update AWS Tags</h3>

<p>If you want to change the contact on your EC2 instance created above, simply change the <code>Tags</code> section of your template file and use the <code>[update-stack](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html)</code> <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html" target="_blank">command</a> to deploy your changes.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre>"Tags" : [
 {
    "Key" : "contact",
    "Value" : "l-duke"
 },
  ...
],
</pre></td></tr></tbody></table></code></pre></div></div>

<p>AWS CloudFormation behaves the same way that Terraform does when you update tags outside your template file. Any tags set manually will be overridden by the <code>update-stack</code> ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</a></em></p>]]>
            </description>
            <link>https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353412</guid>
            <pubDate>Wed, 02 Sep 2020 14:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To be creative, Chinese philosophy teaches us to abandon ‚Äòoriginality‚Äô]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24353137">thread link</a>) | @canada_random1
<br/>
September 2, 2020 | https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>When I was 15</strong>, one of my closest friends died unexpectedly. Our physics teacher broke the news to me after I√¢‚Ç¨‚Ñ¢d sat an exam, having wondered all the way through why my friend wasn√¢‚Ç¨‚Ñ¢t there doing the same. I still don√¢‚Ç¨‚Ñ¢t have the words to describe how I felt: it was something approaching shock, distress, disorientation. I didn√¢‚Ç¨‚Ñ¢t know what to think, much less what to do. I spent many nights awake and many days in a daze.</p>
<p>Fifteen years later, when I was in graduate school, another friend died suddenly, a man I loved very much. I remember checking my phone and finding out, to my dismay, via text message. But while my initial response was much the same as before, there was a palpable difference in how I felt later on. While I was again surprised and saddened, I was much less disoriented than I√¢‚Ç¨‚Ñ¢d been as a teenager. I could still think, and I could still get things done. It seemed to me that I√¢‚Ç¨‚Ñ¢d become better at living with loss.</p>
<p>You might think that the reason for this difference is obvious √¢‚Ç¨‚Äú I was older, and I√¢‚Ç¨‚Ñ¢d had more experience in coping with death. But raw experience alone isn√¢‚Ç¨‚Ñ¢t enough: what matters more is whether we learn from experience. And learning from experience, especially an experience as difficult as the death of a loved one, can involve quite a lot. Among other things, it can involve creativity.</p>
<p>This claim might seem surprising. After all, creativity is often associated with the idea of a lone creative genius, an individual who not only excels at what they do, but also transforms the world in the process. Further, even if we don√¢‚Ç¨‚Ñ¢t limit ourselves to romantic or heroic perspectives on the nature and value of creativity, it√¢‚Ç¨‚Ñ¢s commonly thought that creativity at least aims at novelty or originality.</p>
<p>This way of thinking about creativity isn√¢‚Ç¨‚Ñ¢t universal. The <a href="http://cup.columbia.edu/book/the-complete-works-of-zhuangzi/9780231164740"><em>Zhuangzi</em></a> (√®≈Ω≈†√•¬≠ÔøΩ), a classical Chinese philosophical and literary text, provides a different perspective. On one interpretation, creativity isn√¢‚Ç¨‚Ñ¢t conceived as aiming at novelty or originality, but rather <em>integration</em>. Instead of aiming at something new, it aims at something that combines well with the situation of which it√¢‚Ç¨‚Ñ¢s a part.</p>
<p>The story of Wheelwright Pian, from a chapter of the Zhuangzi known as the <em>Tian Dao</em> (√•¬§¬©√©ÔøΩ‚Äú), meaning √¢‚Ç¨ÀúHeaven√¢‚Ç¨‚Ñ¢s Way√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúThe Way of Heaven√¢‚Ç¨‚Ñ¢, effectively illustrates this perspective on creativity as it pertains to artists or artisans. In this short vignette, a wheelwright known as Pian (√¶‚Ä∞ÔøΩ) tells a duke that the book of sages√¢‚Ç¨‚Ñ¢ advice he√¢‚Ç¨‚Ñ¢s reading is nothing but √¢‚Ç¨Àúchaff and dregs√¢‚Ç¨‚Ñ¢. Angered, the duke demands an explanation. The wheelwright responds that, at least concerning his craft, he can create what he does only because he√¢‚Ç¨‚Ñ¢s developed a √¢‚Ç¨Àúknack√¢‚Ç¨‚Ñ¢ for it that can√¢‚Ç¨‚Ñ¢t be wholly conveyed in words. If the blows of his mallet are too gentle, his chisel slides and won√¢‚Ç¨‚Ñ¢t take hold. If they√¢‚Ç¨‚Ñ¢re too hard, it bites in and won√¢‚Ç¨‚Ñ¢t budge. √¢‚Ç¨ÀúNot too gentle, not too hard √¢‚Ç¨‚Äú you can get it in your hand and feel it in your mind,√¢‚Ç¨‚Ñ¢ he says. √¢‚Ç¨ÀúSo, I√¢‚Ç¨‚Ñ¢ve gone along for 70 years and at my age I√¢‚Ç¨‚Ñ¢m still chiselling wheels. When the men of old died, they took with them the things that couldn√¢‚Ç¨‚Ñ¢t be handed down. So, what you are reading there must be nothing but the chaff and dregs of the men of old.√¢‚Ç¨‚Ñ¢</p>
<p>Although he√¢‚Ç¨‚Ñ¢s a √¢‚Ç¨Àúlowly√¢‚Ç¨‚Ñ¢ craftsperson, the wheelwright has something important to teach the duke. He√¢‚Ç¨‚Ñ¢s been creating wheels by hand for many years and has developed an ability to act and to execute his craft in an integrated manner that can√¢‚Ç¨‚Ñ¢t be fully captured through an algorithmic list of instructions. He responds to precise particularities in the wood, his tools and his body to create what he wants √¢‚Ç¨‚Äú something he doesn√¢‚Ç¨‚Ñ¢t accomplish by imposing a plan.</p>
<p>Striving for originality can be counterproductive when it comes to achieving genuinely fresh results</p>
<p>The sages√¢‚Ç¨‚Ñ¢ advice for living well is therefore mere √¢‚Ç¨Àúdregs√¢‚Ç¨‚Ñ¢ if it√¢‚Ç¨‚Ñ¢s interpreted as instructions that one can simply read and then complete. Living well in general involves much more than this; namely, a spontaneous integration between contrasting types such as the hard and the soft, as well as the learned and the spontaneous, the active and the passive, and even the unproductive and the productive √¢‚Ç¨‚Äú all of which apply in the case of carving wheels, as well as elsewhere. In other words, living well involves creativity.</p>
<p>This kind of creativity isn√¢‚Ç¨‚Ñ¢t taken to aim at novelty or originality as such. The wheelwright is presented as creative not because of anything to do with his, or his projects√¢‚Ç¨‚Ñ¢, novelty or originality, but instead because of his ability to create wheels in a sensitive, responsive and √¢‚Ç¨‚Äú crucially √¢‚Ç¨‚Äú well-integrated manner: one not learned by rote, but rather via engaging in sustained, spontaneous activity.</p>
<p>We can use the story of Wheelwright Pian to better understand why learning to live with loss is a creative pursuit. Although there√¢‚Ç¨‚Ñ¢s an abundance of books dispensing advice on how to do so, ultimately learning to live with death is a deeply personal endeavour that √¢‚Ç¨‚Äú like carving wheels √¢‚Ç¨‚Äú can√¢‚Ç¨‚Ñ¢t be fully captured through a programmatic set of directions. We must respond to precise particularities of our situation (concerning our thoughts, feelings and overall circumstances) to create what we want to create (such as a sense of peace or closure). This isn√¢‚Ç¨‚Ñ¢t something that can be accomplished by imposing a plan, even if we make various provisional and highly malleable √¢‚Ç¨Àúplans√¢‚Ç¨‚Ñ¢ on the fly as we go along.</p>
<p>Moreover, in working through our thoughts, feelings and circumstances in all their particularities, it√¢‚Ç¨‚Ñ¢s not that we√¢‚Ç¨‚Ñ¢re doing anything all that different from what countless others have had to do as they√¢‚Ç¨‚Ñ¢ve learned to cope with loss. Nonetheless √¢‚Ç¨‚Äú again, like carving wheels √¢‚Ç¨‚Äú it√¢‚Ç¨‚Ñ¢s plausibly a creative activity, in that it involves a spontaneous integration between contrasting types such as the grieving and the celebratory, the resentful and the grateful, the distressed and the joyous. The ability to live with death, too, in a sensitive, responsive, and well-integrated manner isn√¢‚Ç¨‚Ñ¢t learned by rote, but rather via engaging in sustained, spontaneous activity. Indeed, even the philosopher Zhuangzi himself can be understood as engaging in such a creative process after the death of his own wife in chapter 18 of the text, the <em>Zhi Le</em> (√®‚Ä°¬≥√¶¬®‚Äö), meaning √¢‚Ç¨ÀúPerfect Happiness√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúPerfect Joy√¢‚Ç¨‚Ñ¢.</p>
<p><strong>This way of thinking</strong> about creativity has a variety of other potential benefits. First, even if creativity were taken to aim at originality, de-emphasising originality might ironically result in greater creativity. This is because striving for originality can actually be counterproductive when it comes to achieving genuinely fresh results: if we focus on the task of achieving something original, we√¢‚Ç¨‚Ñ¢ll explore only the range of possibilities deemed sufficiently likely to yield that result, leaving out a lot that could have contributed to achieving something original.</p>
<p>But imagine instead that we worked with idea that creativity wasn√¢‚Ç¨‚Ñ¢t about novelty. That doesn√¢‚Ç¨‚Ñ¢t mean we√¢‚Ç¨‚Ñ¢d have to give up the value of originality entirely, but rather see it as one of a range of possible outcomes. Casting a wider net in this way might hence make creativity (whatever it involves) easier to achieve.</p>
<p>Second, focusing on integration could encourage us to better understand creative agents as being intimately connected with, and products of, their environments. This would broaden our notion of creativity in a way that might allow us to see creativity demanded in a greater range of activities. After all, many of life√¢‚Ç¨‚Ñ¢s activities, from the mundane to the meaningful, aren√¢‚Ç¨‚Ñ¢t learned by rote, but rather via spontaneous action that integrates contrasting aspects. Just for starters, additional examples might include getting along with one√¢‚Ç¨‚Ñ¢s family, building relationships with colleagues and organising one√¢‚Ç¨‚Ñ¢s finances.</p>
<p>This alternative perspective on creativity might help us to see it as an everyday phenomenon in which we all participate √¢‚Ç¨‚Äú rather than an extraordinary talent or gift that only a few enjoy. And it might also allow us to make sense of the idea of <a href="https://link.springer.com/chapter/10.1007/978-3-319-43893-1_19#:~:text=As%20an%20art%20practice%2C%20calligraphy,Daoist%20aesthetic%20concerns%20discussed%20here.&amp;text=The%20aesthetic%20of%20the%20everyday,and%20the%20need%20for%20imagination">living creatively</a>: of an integrated life, lived spontaneously, in which all of life√¢‚Ç¨‚Ñ¢s contrasting aspects can be arranged to form a rich and variegated whole.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353137</guid>
            <pubDate>Wed, 02 Sep 2020 13:44:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Actively Discourage Online Tooling like jwt.io and Online JSON Validators]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 163 (<a href="https://news.ycombinator.com/item?id=24352360">thread link</a>) | @pcr910303
<br/>
September 2, 2020 | https://www.jvt.me/posts/2020/09/01/against-online-tooling/ | <a href="https://web.archive.org/web/*/https://www.jvt.me/posts/2020/09/01/against-online-tooling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Something my colleagues know well is how little I trust online tools like <a href="https://jwt.io/">jwt.io</a>, online JSON validators or online tooling in general, but it also bleeds into <a href="https://www.jvt.me/mf2/2020/08/zebqf/">comments I make online</a> and in my blog posts, too, and I thought I'd share a little bit of a reason as to why.</p><p>Instead of using an online service, I will reach for a way to run it locally, using whichever programming language toolchain I have available. But why? Why wouldn't I recommend something like jwt.io? Or an online JSON validator, especially if they boast client-side functionality, and mean I don't need things installed?</p><p>Let's start with a bit of background. Firstly, I'd just like to caveat this all with the note that <strong>I have no access to Production data, customer or otherwise</strong>. All of these examples are referencing Non-Production examples.</p><p>I also want to caveat this with the fact that this is <strong>not a personal attack</strong> on jwt.io. I am using them as an example as they're a well-known and well-used service, and I've seen issues with it before. Auth0 run it, and are probably one of the few companies we'd want to be running it. It's also <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io">Open Source</a> <em>but</em> one of the great difficulties of Web-hosted services are that we have no idea if the source code that we're told is being used is actually being used!</p><p>I'm currently working on the Open Banking platform for Capital One. We're fortunate to have very restricted access to Production, which makes things safer for everyone. One thing we strive to do is to treat Non-Production secrets like Production ones where possible - where we shouldn't have access to them at all, and shouldn't be sharing them with external services. Some of these Non-Production secrets may be usable outside of Capital One, for instance Open Banking Sandbox signing certificates.</p><p>We perform a fair bit of testing in our Non-Production environments and sometimes need to debug things, such as what's inside a JWT (as Open Banking introduces several places they're used). I've been burned a number of times by folks putting a Non-Production JWT or an Open Banking Sandbox certificate into jwt.io. Although Non-Production, these are sensitive in of themselves, as they have implementation details for our services, and as mentioned, certain things could be used outside of Capital One.</p><p>The biggest reason I hear from folks using online tooling is that it's easier, and that they'd rather do that than find out how to run it locally. I disagree with this, but am quite biased, as I often have a blog post for many of these common issues. I love sharing my blog with others and having a handy solution, or if I don't have an answer to a problem, I'll find out how and <a href="https://www.jvt.me/tags/blogumentation/">blogument it for later</a>. So I see that reaching for online tooling is more just because we've got folks who aren't aware of how they could do otherwise.</p><p>One great thing about removing the need for an online tool is that you can self-serve it once you have the tools locally. You can run it locally when you've got no internet (which isn't as much of an issue in these Coronavirus times) but also regardless of whether the upstream service is broken. You can use it with other i.e. command-line tooling, for instance how I've set up <a href="https://gitlab.com/jamietanna/dotfiles-arch/-/blob/master/terminal/home/bin/unpack">this command-line script</a> to handle a lot of common data formats I deal with and unpack them to a human-readable format.</p><p>But most importantly, by telling people to put sensitive data (such as credentials, configuration files, etc) it's a really dangerous lesson for our teams. We're teaching people to blindly trust arbitrary websites that they don't have any relationship with, nor have fully audited the source code, when posting potentially sensitive data.</p><p>I realise this may not be something you do when running it locally, but it's less likely for a well-known library running locally to need to reach outbound.</p><p>jwt.io is an interesting example, because although it boasts that it runs as a client-side solution, you may not have been aware that <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io/commit/b362ab19a9f37e337b5f8ea38987aa680aa6e0a9">until last September</a>, there were metrics being determined which although may have seemed innocent, show that it's easy for other functionality to be hidden in a seemingly client-side-only website. Unless you audit everything, every time, you're in a risky position where you may be leaking data you're not expecting to.</p><p>I feel that we can do something to help services that handle potentially sensitive data with helping educate the user that they should be more careful, because jwt.io's warning definitely doesn't help with folks who don't fully appreciate what the risk is if jwt.io isn't actually as trustworthy as the user thinks:</p><blockquote><p>Warning: JWTs are credentials, which can grant access to resources. Be careful where you paste them! We do not record tokens, all validation and debugging is done on the client side.</p></blockquote><p>What do you think? Am I maybe being a little too sensitive? Am I not being sensitive enough?</p><p>Edit: Based on some conversations being had in response to the post, I thought it'd mention I've written about how to <a href="https://www.jvt.me/posts/2019/06/13/pretty-printing-jwt-openssl/">pretty-print a JWT locally with OpenSSL</a> and <a href="https://www.jvt.me/posts/2018/08/31/pretty-printing-jwt-ruby/">a Ruby alternative</a>.</p></div></div>]]>
            </description>
            <link>https://www.jvt.me/posts/2020/09/01/against-online-tooling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352360</guid>
            <pubDate>Wed, 02 Sep 2020 12:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The problem with C]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24352258">thread link</a>) | @fanf2
<br/>
September 2, 2020 | https://cor3ntin.github.io/posts/c/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://cor3ntin.github.io/posts/c/fight.jpeg" alt="Fish"></p>
<p>In the early 70s, C was created at Bell Labs as a byproduct of the development of UNIX.
It quickly became one of the most popular programming languages.
But it was not expressive enough for Bjarne Stroustrup.
And so, in 1983, as a byproduct of his Ph.D. thesis, he extended C.</p>
<p>C with classes was born.</p>
<p>At the time, Bjarne Stroustrup understood that a programming language has many components,
not only the language, its compiler, but also a linker and libraries.
Offering a familiar tool also makes adoption easier.
In this historical context, it makes sense that C++ would be based on C.</p>
<p>Fast-forward 40 years later.</p>
<p>Both C and C++ are widely used in the industry.
But go 5 minutes on the Internet and C developers will tell you that C++ is the most horrific man-made creation,
while many C++ developers wait for the day when C finally burns in the hot flames of hell.</p>
<h2 id="so-what-happened">So what happened?</h2>
<p>On the surface, C and C++ cater to the same use cases: high performance, deterministic, native but portable code for the widest range of hardware and applications.</p>
<p>But C is proudly a low-level language. A nicer assembly.</p>
<p>From day one, C++ had magic. Dark witchcraft: destructors. Suddenly the compiler was doing things on its own.
It also had type inference very early on, but the developers of the mid-80s were not quite ready for that and Bjarne Stroustrup
was pressured into removing <code>auto</code>, until it was added back to C++11.</p>
<p>From then, C++ got more and more tools to build abstractions.
I don‚Äôt think it would be fair to say that C++ is a low-level or high-level language. It‚Äôs both, by design.
But building high-level abstractions while not sacrificing performance is hard.
C++ then needed tools to achieve that: <code>constexpr</code>, move semantics, templates, and an ever-growing standard library.</p>
<p>Fundamentally I think C trusts developers while C++ trusts compilers.
This is a massive difference that sharing the same native types or syntax for while loop cannot hide.</p>
<p>C++ developers blame C for all their lost limbs, while C developers probably think C++ is batshit crazy.
I imagine that is a fair perspective if you look at C++ through a C lense. C++ is pretty wild <em>as a superset of C</em>.
A seasoned C person looking at C++ expecting familiarity in C++ will not find it. C++ is not C.
This is enough to feed flamewars for generations.</p>
<p>But as much as I dislike C, I don‚Äôt have any legitimacy to make fun of it. See, I have some experience with C++ but I
wrote very little C. It was probably bad C.
A language is also its good practices, patterns, idioms, and these take years to learn. If you try to write C code like it‚Äôs C++ or C++ like it is C, you will have a bad time.
Knowing <a href="https://www.youtube.com/watch?v=YnWhqhNdYyk">C doesn‚Äôt teach you C++</a>. Knowing C++ does not teach you C.</p>
<p>So can we all stop saying C/C++, regret the unfortunate naming, and sing kumbaya in harmony?
Not so fast.</p>
<p>See, despite being philosophically different from C, C++ is still somewhat a superset of C.
That is to say, you can include a C header in a C++ translation unit and that should compile.
And this is where it gets messy.</p>
<p>C++ is not an extension of C.
It is designed as a separate standard, by a different committee, different people.
Logically, people who like C++'s philosophy will get involved in the C++ community and the C++ standardization process
while other people might try to get involved with C.
Committees, whether its C‚Äôs or C++'s, only manifest intent and direction through their respective end-product: the standards; standards which are the fruits of numerous voting.</p>
<p>At the same time, it is difficult for a compiler to know that it is dealing with a C header or a C++ header.</p>
<p><code>extern "C"</code> is not used consistently and only affects mangling, but neither grammar nor semantics.
And headers only exists in the eyes of the preprocessor, for a C++ compiler, everything is a C++ translation unit, and therefore C++.
And yet, people include C headers in C++ and expect it to ‚Äújust work‚Äù ‚Ñ¢Ô∏è.
Which it mostly does.</p>
<p>We can wonder then,</p>
<h2 id="how-c-maintains-c-compatibility-while-being-developed-by-different-people-in-different-places">How C++ maintains C compatibility while being developed by different people in different places?</h2>
<p>Badly, I‚Äôm afraid.</p>
<p>A coworker recently reminded me of Conway‚Äôs law:</p>
<blockquote>
<p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization‚Äôs communication structure</p>
</blockquote>
<p>By that logic, it would stand to reason that if the two committees don‚Äôt interoperate,
neither would the languages they produce.</p>
<p>C++ maintains a list of <a href="http://eel.is/c++draft/diff.iso">incompatibilities with C</a> and <a href="http://eel.is/c++draft/diff.library">its standard library</a>.
This list does not seem to reflect the many features that were added to C11 and C18 but are not valid C++ constructs. <a href="https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B">Wikipedia</a> draws a clearer picture.</p>
<p>Listing incompatibilities isn‚Äôt sufficient to get a measure of incompatibilities between both languages.</p>
<p>Functions that exist in the C++ standard library but whose primary declaration is expected to come from C are difficult to make <code>constexpr</code>, and more difficult still to make <code>noexcept</code>.
C compatibility translates to performance costs and C functions are optimization barriers.</p>
<p>Many C constructs are valid C++ but should never pass a code review (<code>NULL</code>, <code>longjmp</code>, <code>malloc</code>, create/destroy functions, <code>free</code>, C  casts), etc.</p>
<p>These might not be bad C idioms, but they are bad C++. C++ has a stronger type system,
and unfortunately using C idioms punch a giant hole in that type system, and so C compatibility has a cost in terms of safety.</p>
<p>Don‚Äôt get me wrong, C++ still care about C compatibility. Somewhat.
And interestingly C cares about C++. Somewhat.
Truth be told, C might care about C++ more than C++ cares about C.
So each committee cares somewhat about what the other does.
We care reluctantly.</p>
<p>See, C++ is aware of the many foundational libraries written in C, not only the <code>libc</code> but also <code>zip</code>, <code>png</code>, <code>curl</code>, <code>openssl</code> (!), and countless others, which are used in many, many C++ projects.
We can‚Äôt break that.</p>
<p>But recently, especially over the past decade, C++ has become much bigger than C.
C++ has more users - and a much more active community: <a href="https://nullprogram.com/blog/2018/11/21/">There Are No C Conferences</a>.
Maybe that‚Äôs why the C++ committee is now over 10 times the size of the C committee.</p>
<p>C++ then is a force to be reckoned with and the C committee has to consider not breaking C++.
To the point that if a standard would track another, these days, C++ leads and C follow.</p>
<p>C++ is now on a steady three years cycle come rain or shine, or deadly pandemics.
Meanwhile, C has a major release every decade or so.
This makes sense. As a lower-level language, C doesn‚Äôt need to evolve as fast.</p>
<p>The C landscape is also rather different from the C++ landscape.
C caters to more platforms and a lot more compilers.
Everybody and their dog is writing C compilers because the language has a surface area small enough to make that possible, whereas the C++ committee will only really consider 4 implementations, all of which are represented at every meeting.
As a result, many features in C are implementation-defined or optionally supported so that the variety of compilers that exist can claim conformance without doing much work, which I‚Äôm told pleases regulatory bodies.</p>
<p>C++ these days is more interested in portability than implementation freedom. Yet another difference of philosophy.</p>
<h2 id="so-your-proposal-breaks-c-compatibility">So, your proposal breaks C compatibility</h2>
<p>Parts of my <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2178r1.pdf">P2178</a> paper theoretically affects C compatibility.
In such cases, none of the options seems satisfactory.</p>
<p>You could be told that you have to first get your feature into C. Which means more meetings.
Meetings you might not be able to attend because C has strict <a href="https://thephd.github.io/follow-the-river-wg14-ithaca-2019">attendance rules</a> - Excluding individuals not willing to put down thousands of dollars to become ISO members.
This is because the C committee is forced to adhere strictly to ISO rules.</p>
<p>It might also take a decade if the standard just shipped.
And most importantly, it might go nowhere if the C committee doesn‚Äôt understand or doesn‚Äôt care about the particular problem you are trying to solve.
And they probably don‚Äôt have the bandwidth to deal with it.
And you may not have the bandwidth to deal with C. After all, you joined C++ to improve C++.
In fact, if the room invites you to ‚Äútalk to the C committee‚Äù, it is likely your proposal is dead, even in the unlikely event that no one in the room was against it.</p>
<p>Another likely scenario is that the C committee accepts a version of a proposal that is slightly different from what exists in C++.
<code>true</code>? Let‚Äôs make that a macro. <code>char16_t</code> ? Let‚Äôs make that a typedef. <code>char32_t</code>? Not necessarily UTF-32. <code>static_assert</code> ? <code>_Static_assert</code>.</p>
<p>The list goes on. Should we blame C? Probably not. Their committee does what they think is best for their language.
The opposite is true too. In C++20 designated initializers were inspired by C‚Äôs but are slightly different because they would otherwise not fit with the C++ initialization rules.</p>
<p>I am part of the problem. C has VLAs. I would vote against a proposal to adopt that in standard C++, <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kills-The-VLA">too many security issues</a>. A proposal to add <code>_Generic</code> to C++ would be over-my-dead-body. I am not sure if <code>_Generic</code> attempts to palliate to the lack of template or the lack of overloads, but C++ has both these features - from my point of view <code>_Generic</code> doesn‚Äôt fit into the big picture of what I imagine C++ to be.</p>
<p>Both committees seem also inconsistent in how much they care about the other language.
Sometimes we go to great lenghts (<a href="https://en.cppreference.com/w/cpp/numeric/complex">std::complex</a>), sometimes we don‚Äôt care at all (<a href="https://en.cppreference.com/w/c/language/array">static array parameters</a>).</p>
<p>There is no way around this. Don‚Äôt forget that each committee is a bunch of people
voting at different times in different rooms and trying to control the outcome would defeat the purpose
of having a vote.
Putting people in the same room is not realistic either. ISO might object and the participation inbalance
would put C people at an enormous disadvantage.</p>
<h2 id="c-compatibility-doesnt-matter-kinda">C compatibility doesn‚Äôt matter, kinda</h2>
<p>If you are a C developer, I imagine you see C as a neat programming language.
But for the rest of us, C is something else.</p>
<p>C is the universal, cross-language glue that ties it all together.</p>
<p>For C++ users, C is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/c/">https://cor3ntin.github.io/posts/c/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352258</guid>
            <pubDate>Wed, 02 Sep 2020 11:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of a Switch]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24351706">thread link</a>) | @pkolaczk
<br/>
September 2, 2020 | https://pkolaczk.github.io/in-defense-of-switch/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/in-defense-of-switch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-09-02T00:00:00+00:00">September 02, 2020</time>
</header>

  <p>Recently I came across a <a href="https://levelup.gitconnected.com/if-else-is-a-poor-mans-polymorphism-ab0b333b7265">blog post</a>
whose author claims, from the perspective of good coding practices, polymorphism is strictly superior to branching. 
In the post they make general statements about how branching statements lead to unreadable, unmaintainable, inflexible code and
how they are a sign of immaturity. However, in my opinion, the topic is much deeper and in this post 
I try to objectively discuss the reasons for and against branching.</p>

<!--more-->



<p>Before I dive into polymorphism vs branching dilemma, let‚Äôs first define what we mean when we say some code is
flexible and easy to extend. In my career I reviewed thousands of lines of code, and I had thousands of lines of my code
reviewed by others, and during these reviews it often occured that the terms <em>code extensibility</em> or <em>flexibility</em> 
mean different things to different people. Familiarity with the code-base or particular programming style plays a huge role.</p>

<p>For example, someone used to writing code in a Java/C# OOP style would generally consider dynamic polymorphism through 
interfaces a standard way of providing extensibility to the code, 
while a C programmer may find a switch or if/else much more 
approachable than OOP. There are also many other factors related 
to maintainability as quality of documentation, good naming, separation of concerns, etc. These factors are orthogonal 
to the ‚Äúpolymorphism vs branching‚Äù dimension and also far too broad for a single blog post, so I won‚Äôt discuss them.</p>

<p>For the sake of this post, let‚Äôs define <em>extensibility</em> as the inverse of number of distinct units in the codebase
that need to be changed in order to implement a new feature. The more places you have to touch to implement the feature, 
the harder the code is to change. Obviously, it is much better when you have to touch only
one unit of code (one function, one class, one module, one package) rather than change 10 distinct unrelated units.</p>


<p>Imagine you‚Äôre writing a calculator. Your program gets an expression as an input and outputs the computed value.
For example the user inputs <code>1 + 2 * 3</code> and the output is <code>7</code> 
(or <code>9</code> if you‚Äôve messed up the operator precedence like one of my former CS students).</p>

<p>Why such a silly example? Who is writing calculators these days? Probably no-one, but this looks like a classic example given
in many programming classes. And it is easy enough to illustrate the concept.</p>

<p>How can we model a structure to represent an expression?
You‚Äôd probably use classes or structures. Here is the code in Scala:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>value</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>+</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>Then it is quite easy to build an expression and evaluate it:</p>
<div><div><pre><code><span>Add</span><span>(</span><span>Const</span><span>(</span><span>2</span><span>),</span> <span>Const</span><span>(</span><span>3</span><span>)).</span><span>eval</span> <span>// evaluates to 5 </span>
</code></pre></div></div>


<p>This OOP-based solution is indeed very extensible when it comes to add a new operator.
The example above is missing subtraction operation. We can add one by defining a new class:</p>

<div><div><pre><code><span>case</span> <span>class</span> <span>Sub</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>-</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>That‚Äôs really awesome ‚Äì we didn‚Äôt have to touch any old code at all! 
OOP definitely rocks here.</p>


<p>Imagine you continued to extend our calculation engine with more operation classes over the next few years.
You‚Äôve added multiplication, division, modulo, variables, logarithms, trigonometric functions, etc.</p>

<p>Then suddenly a new requirement comes ‚Äì users want to not only evaluate the value of an expression,
but also do symbolic manipulation ‚Äì e.g. simplify expressions. For example, given an expression
<code>a + a</code> they want to get an expression <code>2 * a</code> as a result.</p>

<p>This requirement can‚Äôt be captured by the <code>eval</code> method on the <code>Expression</code> interface. We need a new method:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
<span>}</span>
</code></pre></div></div>

<p>And as the next step, they would likely want to be able to display the expression as a String:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
    <span>def</span> <span>toString</span><span>:</span> <span>String</span>
<span>}</span>
</code></pre></div></div>

<p>How many units of code do you have to change now to implement these features?
<strong>All the implementations of <code>Expression</code></strong>. Before touching all the classes, the code wouldn‚Äôt even compile.
It looks like in the context of this kind of feature, our polymorphic solution is terribly non-extensible.</p>


<p>Let‚Äôs take a step back and let‚Äôs see how we could implement this differently.
Scala and many other modern languages have a feature called <em>pattern matching</em>
which can be considered a very flexible, powerful switch.</p>

<p>Instead of defining the operations like <code>eval</code> or <code>simplify</code> on the case classes,
let‚Äôs pull them up:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>


<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now adding a new operation like <code>Sub</code> would require two changes to the code ‚Äì adding a new class
<em>and</em> adding a new case in the match (switch) statement.</p>

<p>Some may say this much worse not only because of more places to update, but because of a possibility of
forgetting to update the switches which could lead to runtime errors due to unhandled cases.
Fortunately, Scala designers thought about this by providing the <code>sealed</code> keyword, which instructs the compiler
that all case classes can be defined in the same module only. This unlocks pattern exhaustiveness analysis and the
compiler would warn about missing cases:</p>

<div><div><pre><code><span>sealed</span> <span>trait</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>

<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>What about adding new functions like <code>simplify</code> or <code>toString</code>? 
It requires to changle only <strong>one place</strong> ‚Äì by adding the required methods. 
No changes to the existing code are needed!</p>

<div><div><pre><code><span>def</span> <span>simplify</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Expression</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Add</span><span>(</span><span>Const</span><span>(</span><span>0</span><span>),</span> <span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>x</span><span>,</span> <span>Const</span><span>(</span><span>0</span><span>))</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>other</span> <span>=&gt;</span> <span>other</span>
  <span>}</span>
<span>}</span>

<span>def</span> <span>toString</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>String</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span><span>.</span><span>toString</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>"("</span> <span>+</span> <span>toString</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>" + "</span> <span>+</span> <span>toString</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>"</span><span>)</span> 
  <span>}</span>
<span>}</span>
</code></pre></div></div>


<p>The blog post I mentioned in the introduction stated that using polymorphism instead of
branching leads to more readable code. I find this statement far too general and actually very debatable.</p>

<p>First, even in their own example given by the author of that blog, the solution using branching was a lot
shorter and less complex than the solution using OOP. While brief code is not always more readable than a longer version of it,
in that case, I found branching to be very explicit and easy to follow. 
It is much easier to understand the control flow
in such a program because all targets are explicitly given in a single place. In the OOP solution, 
the actual implementations are hidden behind the interface and it is much harder to find them all without additional 
help of a good IDE with a ‚Äújump to implementations‚Äù feature 
(which fortunately often works well for statically typed languages, but I‚Äôve seen IDEs sometimes 
struggle with dynamic languages like Python).</p>

<p>Second, in general case, branching has an advantage that the function logic may depend on more than
one object type or even the actual data. For example, in the example from this post, 
the transformation <code>a * (b + c)</code> =&gt; <code>a * b + a * c</code> would depend on 
both addition and multiplication. In the classic OOP solution, would you place it in the <code>Add</code> or in the <code>Mul</code> class? 
Neither seems right. Also, putting it into one of them creates a dependency on the other one. 
An expression simplifier with code scattered accross multiple classes heavily depending on each other 
would be hard to understand.</p>


<p>This is a blog on high performance programming, so the post would be incomplete without a 
section on performance. In theory, a sufficiently good compiler should produce the same
code regardless of the choice between branching or dynamic polymorphism, but is this the case in reality?
Compilers have limitations and often don‚Äôt generate the best result code possible.</p>

<p>Let‚Äôs consider a more realistic example this time.
Some time ago I was working on serializing/deserializing code in a database system.
I stumbled upon a set of classes that described data types. They all implemented 
a common interface defining methods for serializing and deserializing values of given data type
and also computing serialized data lenghts. The following Rust snippet is a huge simplification 
of that code, but it illustrates the concept:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>DataType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span><span>;</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>BoolType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>IntType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>LongType</span><span>;</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>BoolType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>1</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>IntType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>4</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>LongType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>8</span> <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>data_len</span><span>(</span><span>data_type</span><span>:</span> <span>&amp;</span><span>dyn</span> <span>DataType</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
    <span>data_type</span><span>.len</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>Given a reference to a <code>DataType</code> object, it is trivial to compute the data size associated with it, 
without knowing the exact static type:</p>

<div><div><pre><code><span>let</span> <span>t1</span> <span>=</span> <span>IntType</span><span>;</span>
<span>let</span> <span>t2</span> <span>=</span> <span>LongType</span><span>;</span>
<span>let</span> <span>v</span><span>:</span> <span>Vec</span><span>&lt;&amp;</span><span>dyn</span> <span>DataType</span><span>&gt;</span> <span>=</span> <span>vec!</span><span>[</span><span>&amp;</span><span>t1</span><span>,</span> <span>&amp;</span><span>t2</span><span>];</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>0</span><span>]));</span>  <span>// prints 4</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>1</span><span>]));</span>  <span>// prints 8</span>
</code></pre></div></div>

<h2 id="performance-of-dynamic-dispatch">Performance of Dynamic Dispatch</h2>

<p>The implementation of the <code>data_len</code> function is actually very simple:</p>


<p>Wow! A single assembly instruction! 
It jumps to the address stored in the the vtable of the object pointed by the <code>rsi</code> register.
The target of the jump depends on the actual type of the object. Here is the code generated for <code>IntType.len</code>:</p>



<p>The codes for the other types differ only in the constant value.</p>

<p>These are only 3 instructions to return the result. Shouldn‚Äôt it be fast? 
Let‚Äôs measure this. Let‚Äôs put more random <code>DataType</code> objects ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pkolaczk.github.io/in-defense-of-switch/">https://pkolaczk.github.io/in-defense-of-switch/</a></em></p>]]>
            </description>
            <link>https://pkolaczk.github.io/in-defense-of-switch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351706</guid>
            <pubDate>Wed, 02 Sep 2020 10:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes: Make your services faster by removing CPU limits]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24351566">thread link</a>) | @iansinnott
<br/>
September 2, 2020 | https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/ | <a href="https://web.archive.org/web/*/https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>At Buffer, we‚Äôve been using <a href="https://kubernetes.io/case-studies/buffer/">Kubernetes since 2016</a>.  We‚Äôve been managing our k8s (kubernetes) cluster with <a href="https://kops.sigs.k8s.io/">kops</a>, it has about 60 nodes (on AWS), and runs about 1500 containers. Our transition to a micro-service architecture has been full of trial and errors. Even after a few years running k8s, we are still learning its secrets. This post will talk about how something we thought was a good thing, but ended up to be not as great as we thought: <strong>CPU limits</strong>.</p>
<h2 id="cpu-limits-and-throttling">CPU limits and Throttling</h2>
<p>It is s general recommendation to set CPU limits. <a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-resource-requests-and-limits">Google, among others, highly recommends it</a>. The danger of not setting a CPU limit is that containers running in the node could exhaust all CPU available. This can trigger a cascade of unwanted events such as having key Kubernetes processes (such as <code>kubelet</code>) to become unresponsive. So it is in theory a great thing to set CPU limit in order to protect your nodes.</p>
<p>CPU limits is the maximum CPU time a container can uses at a given period (100ms by default). The CPU usage for a container will never go above that limit you specified. Kubernetes use a mechanism called <a href="https://en.wikipedia.org/wiki/Completely_Fair_Scheduler">CFS Quota</a> to <strong>throttle</strong> the container to prevent the CPU usage from going above the limit. That means CPU will be artificially restricted, making the performance of your containers lower (and slower when it comes to latency).</p>
<h2 id="what-can-happen-if-we-dont-set-cpu-limits">What can happen if we don‚Äôt set CPU limits?</h2>
<p>We unfortunately experienced the issue. The <code>kubelet</code> , a process running on every node, and in charge of managing the containers (pods)  in the nodes became unresponsive. The node will turn into a <code>NotReady</code> state, and containers (pods) that were present will be rescheduled somewhere else, and create the issue in the new nodes. Definitely not ideal isn‚Äôt it?</p>
<h2 id="discovering-the-throttling-and-latency-issue">Discovering the throttling and latency issue</h2>
<p>A key metric to check when you are running container is the <code>throttling</code> . This indicate the number of time your container has been throttled. Interestingly, we‚Äôve discovered a lot of containers having throttling no matter if the CPU usage was near the limits or not. Here the example of one of our main API:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-usage-limits.png" alt="Kubernetes pods CPU usage and limits"></p>
<p>You can see in the animation that the CPU limits is set at <code>800m</code> (0.8 core, 80% of a core), and the peak usage is at most <code>200m</code> (20% of a core). After seeing, we might think we have plenty of CPU to let the service running before it throttle right? . Now check this one out:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-throttling-low-usage.gif" alt="Kubernetes pods Low CPU usage, High limit, lot of throttling"></p>
<p>You can notice the CPU throttling occurs, even though the CPU usage is below the CPU Limits. The maximum CPU usage isn‚Äôt even near the CPU limits.</p>
<p>We‚Äôve then found a few resources(<a href="https://github.com/kubernetes/kubernetes/issues/67577">github issue</a>, <a href="https://www.youtube.com/watch?v=LpFApeaGv7A&amp;feature=youtu.be&amp;t=1204">zanado talk</a>,  <a href="https://medium.com/omio-engineering/cpu-limits-and-aggressive-throttling-in-kubernetes-c5b20bd8a718">omio post</a>) talking about how throttling lead to poorer performances and latency for your services.</p>
<p><strong>Why do we see CPU throttling while CPU usage is low?</strong>
The tldr is basically a bug in the Linux kernel throttling unecessarly containers with CPU limit. If you‚Äôre curious about the nature of it, I invite you to check Dave Chiluk‚Äôs <a href="https://www.youtube.com/watch?v=UE7QX98-kO0">great talk</a>, a <a href="https://engineering.indeedblog.com/blog/2019/12/unthrottled-fixing-cpu-limits-in-the-cloud/">written version</a> also exists with more details.</p>

<p>After many long discussions, we‚Äôve decided to remove the CPU limits for all services that were directly or indirectly on the critical path of our users.</p>
<p>This wasn‚Äôt an easy decision since we value the stability of our cluster. We‚Äôve experimented in the past some instability in our cluster with services using too much resources and disrupting all other services present in the same node.  That time was a bit different, we understood more about how our services needed to be and had a good strategy to roll this out.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/unleash-k8s.jpg" alt="Buffer-remove-cpu-limits-announcement"></p>
<h2 id="how-to-keep-your-nodes-safe-when-removing-limits-">How to keep your nodes safe when removing limits ?</h2>
<p><strong>Isolating ‚ÄúNo CPU Limits‚Äù services:</strong></p>
<p>In the past we‚Äôve seen some nodes going to a <code>notReady</code> state, mainly because some services were using too much resources in a node.</p>
<p>We‚Äôve decided to put those services on some specific nodes (tainted nodes), so those services will not disrupt all the ‚Äúbounded‚Äù ones.  We have better control and could identify easier if any issue occurs with a node. We did this by tainting some nodes and adding toleration to services that were ‚Äúunbounded‚Äù. Check <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">the documentation</a> on how you can do that.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/buffer-k8s-infrastructure-nodes.jpg" alt="Buffer k8s nodes infrastructure"></p>
<p><strong>Assigning the correct CPU and memory request:</strong></p>
<p>The main worry we had was service using too much resources and leading to nodes becoming unresponsive. Because we now had great observability of all services running in our cluster (with Datadog), I‚Äôve analyzed a few months of usage of each service we wanted to ‚Äúunbound‚Äù. I‚Äôve assigned the maximum CPU usage as the CPU request with a &gt; 20% margin. This will make sure to have allocated space in a node. If k8s won‚Äôt try to schedule any other service in that node.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/choose-cpu-request-based-on-max.png" alt="Chose CPU request based on max"></p>
<p>You can see in the graph that the peak CPU usage was <code>242m</code> CPU core (0.242 CPU core). Simply take this number and make it a bit higher to become the CPU request. You can notice that since the service is user facing, the peak CPU usage matches peak traffic time.</p>
<p>Do the same with your memory usage and requests, and you will be all set!
To add more safety, you can use the horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have room for it. Set an alert if your cluster do not have any room, or use the node austoscaler to add it automatically.</p>
<p>The downsides are that we lose in ‚Äú<a href="https://wiki.openvz.org/WP/Containers_density">container density</a>‚Äù, the number of containers that can run in a single node. We could also end up with a lot of ‚Äúslack‚Äù during a low traffic time.
You could also hit some high CPU usage, but nodes autoscaling should help you with it.</p>
<h2 id="results">Results</h2>
<p>I‚Äôm happy to publish really great results after few weeks of experimentation, we‚Äôve already seen really great latency improvements across all the services we‚Äôve modified:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/speedup-no-cpu-limits2.png" alt="faster-kubernetes-containers"></p>
<p>The best result happened on our main landing page (<a href="https://buffer.com/">buffer.com</a>) where we speed the service up to <strong>22x</strong> faster!</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/no-cpu-limit-speedup-buffer-com.jpg" alt="buffer.com speedup without cpu limits"></p>
<h2 id="is-the-linux-kernel-bug-fixed">Is the Linux kernel bug fixed?</h2>
<p>The bug <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=763a9ec06c4">has been fixed and merged into the kernel</a> for Linux distribution running 4.19 or higher (kudo again to <a href="https://twitter.com/dchiluk">Dave Chiluk</a> for finding and fixing that).</p>
<p>However, as for <em>September 2nd 2020</em>, when reading <a href="https://github.com/kubernetes/kubernetes/issues/67577">the kubernetes issue</a>, we can see various Linux projects that keep referencing the issue, so I guess some Linux distribution still have the bug and working into integrating the fix.</p>
<p>If you are below a Linux distribution that has a kernel version below 4.19, I‚Äôd recommend you to upgrade to the latest Linux distribution for your nodes, but in any case, you should try removing the CPU limits and see if you have any throttling.  Here a non exhausting list of various managed Kubernetes services or Linux distribution:</p>
<ul>
<li>Debian: The latest version <a href="https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/%5Bhttps://www.debian.org/releases/buster/">buster</a> has the fix,  it looks <a href="https://tracker.debian.org/news/1167353/accepted-linux-latest-419-105deb10u5deb9u1-source-amd64-into-oldstable-oldstable/">quite recent (august 2020)</a>. Some previous version might have get patched</li>
<li>Ubuntu: The latest version <a href="https://releases.ubuntu.com/20.04/">Ubuntu Focal Fosa 20.04</a> has the fix.</li>
<li>EKS has the fix since <a href="https://github.com/aws/containers-roadmap/issues/175">December 2019</a>. Upgrade your AMI if you have a version below than that</li>
<li>kops: Since <a href="https://github.com/kubernetes/kops/pull/9283">June 2020</a>,  <code>kops 1.18+</code> will start using <code>Ubuntu 20.04</code> as the default host image. If you‚Äôre using a lower version of kops, you‚Äôll have to probably to wait the fix. We are currently in this situation.</li>
<li>GKE (Goggle Cloud) : The kernel fix was merged in <a href="https://cloud.google.com/container-optimized-os/docs/release-notes#cos-stable-77-12371-141-0">January 2020</a>. But it does looks like throttling are <a href="https://news.ycombinator.com/item?id=24356903">still hapenning</a></li>
</ul>
<p>ps: Feel free to <a href="https://news.ycombinator.com/item?id=24351566">comment</a> if you have more precise information, I‚Äôll update the post accordingly</p>
<p><strong>If the fix solved the throttling issue?</strong></p>
<p>I‚Äôm unsure if totally solved the issue. I will give it a try once we hit a kernel version where the fix has been implemented and will update this post accordingly. If anyone have upgrade I‚Äôm keen to hear their results.</p>
<h2 id="takeaways">Takeaways</h2>
<ul>
<li>If you run Docker containers under Linux (no matter Kubernetes/Mesos/Swarm) you might have your containers underperforming because of throttling</li>
<li>Upgrade to the latest version of your distribution hoping the bug is fixed</li>
<li>Removing CPU limit is a solution to solve this issue, but this is dangerous and should be made with extra-care (prefer upgrading your kernel first and monitor throttling first)</li>
<li>If you remove CPU limits, carefully monitor CPU and  memory usage in your nodes, and make sure your CPU requests are</li>
<li>A safe way to is to use the Horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have space.</li>
</ul>
<p>üëâ<strong>Hacker news update: lot of insighful <a href="https://news.ycombinator.com/item?id=24351566">comments</a>. I‚Äôve updated the post to have better recommendations. You should prefer upgrading your kernel version over removing the CPU limits. Be really mindful, set the proper CPU requests, add the necessary monitoring when you do this</strong></p>
<p>I hope this post helps you get performance gains on the containers you are running. If so, don‚Äôt hesitate to share or <a href="https://news.ycombinator.com/item?id=24351566">comment</a> with always some insighful comments</p>
<p>Special thanks to <a href="https://www.linkedin.com/in/dilyevsky/">Dmitry</a>, <a href="https://coderanger.net/">Noah</a> and <a href="https://mydev.org/">Andre</a> that adviced me on this.</p>
<h4 id="next-reads">Next reads:</h4>
<p>üëâ <a href="https://erickhun.com/posts/why-you-should-have-a-side-project/">Why you should have a side project</a></p>
<p>üëâ <a href="https://erickhun.com/posts/sharing-knowledge-in-a-remote-team/">How we share technical knowledge in a remote team, across timezones</a></p>




        <center>

            
            <a href="https://twitter.com/eric_khun" data-size="large" data-show-count="true">Follow @eric_khun</a>
            <br>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=fb" target="_blank" rel="noopener" aria-label="Facebook">
              
            </a>
  
            
            <a href="https://twitter.com/intent/tweet/?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20by%20@eric_khun%20&amp;url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=tw" target="_blank" rel="noopener" aria-label="Twitter">
              
            </a>
  
            
            <a href="https://erickhun.com/cdn-cgi/l/email-protection#3c034f495e56595f480177495e594e525948594f190f5d190e0c715d5759190e0c4553494e190e0c4f594e4a555f594f190e0c5a5d4f48594e190e0c5e45190e0c4e5951534a55525b190e0c7f6c69190e0c50555155484f1c1a5d514c075e5358450177495e594e525948594f190f5d190e0c715d5759190e0c4553494e190e0c4f594e4a555f594f190e0c5a5d4f48594e190e0c5e45190e0c4e5951534a55525b190e0c7f6c69190e0c50555155484f1c111c5448484c4f190f5d190e5a190e5a594e555f57544952125f5351190e5a4c534f484f190e5a57495e594e525948594f115a5d4f48594e114f594e4a555f594f115253115f4c491150555155484f190e5a1a4f0159515d5550" target="_self" rel="noopener" aria-label="E-Mail">
              
            </a>
  
            
            <a href="https://reddit.com/submit/?url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;resubmit=true&amp;title=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits&amp;s=red" target="_blank" rel="noopener" aria-label="Reddit">
              
            </a>
  
            
            <a href="whatsapp://send?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20-%20https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=whatsapp" target="_blank" rel="noopener" aria-label="WhatsApp">
              
            </a>
    
          </center>
      </div></div>]]>
            </description>
            <link>https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351566</guid>
            <pubDate>Wed, 02 Sep 2020 09:47:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hash Monster: ESP-32 Tamagotchi for WiFi Cracking]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24351269">thread link</a>) | @wolframio
<br/>
September 2, 2020 | https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking | <a href="https://web.archive.org/web/*/https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Would you like to have a portable WiFi capture tool that fits in your pocket? A device that saves PCAP captures into micro sd card to later review them on Wireshark or crack those WPA / WPA2 passphrases. Sounds like something out of the <a href="https://nsa.gov1.info/dni/nsa-ant-catalog/wireless-lan/index.html" target="_blank" rel="nofollow noopener">NSA spy WiFi toolset</a> but It's very easy to setup with the ESP32 WiFi Hash Monster and the <a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5 Stack Development Kit</a>.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/5658dfbd47952c4395bccb7da3699c7ff86527064f6b43771f3da3456ec43fa9.png"></p><p><strong>The Hash Monster</strong></p><p>If you are now thinking it seems similar to the <a href="https://www.vice.com/en_us/article/xwekw4/pwnagotchi-is-the-open-source-handheld-that-eats-wi-fi-handshakes" target="_blank" rel="nofollow noopener">Pwnagotchi project</a> and is not causal, G4lile0 the author of Hash Monster was inspired by it to make an alternative that runs on the M5 Stack Development Kit, an ESP32 powered portable platform. ESP32 is a series of dual-core up to 240Mhz, low-cost, low-power system on a chip microcontroller with integrated Wi-Fi and dual-mode Bluetooth/BLE.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/ac7ba2d12ae49bb808d323edae91463b7f97656872f7d24c91dab86d4ba1653d.jpeg"></p><p>Pwnagotchi is a tamagochi like device powered by bettercap and running on a Raspberry Pi Zero W that learns from its surrounding WiFi environment in order to maximize the crackable WPA key material it captures (either through passive sniffing or by performing deauthentication and association attacks). This material is collected on disk as PCAP files containing any form of handshake supported by hashcat, including full and half WPA handshakes as well as PMKIDs. Or put quickly, it's a tamagochi who eats WiFi handshakes to be happy.</p><p>Hash Monster runs in a smaller size and cheaper platform superior to the Pwnagotchi in several aspects. While Pwnagotchi is based on the Raspberry Pi Zero and requires assembling a DIY kit with various components such as an eInk screen and an external powerbank, the Hash Monster works on directly on the tiny M5Stack device. M5 Stack couples an ESP32 with a small LCD display, buttons and internal battery. It‚Äôs a modular, stackable, scalable, and portable device which is powered with an ESP-32 core, which makes it open source, low cost, full-function, and easy for developers to handle ESP32 IoT product development. You can program M5Stack through Arduino, C++, Blockly or MicroPython to name a few. The complete development kit for M5 Stack just under $45 provides a friendly price and full-featured resources which makes it a good starter kit for you to explore ESP32. While the M5 Stack includes a built-in battery 110mAh, it can be upgraded with a stackable 700 mAh lipo battery extension module.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/615059260bcadb5085e71de543154bec6c52222f5d1efda91cdcafdbe403cce2.png"></p><p>The similarity between Pwnagotchi and Hash Monster is that they capture both PSK handshakes from WPA / WPA2 networks and PSK hashes contained in beacon frames with PMKID. A great advantage of PMKID cracking is that everything you need is available over the air even if there are no stations connected and only a single packet capture is required. Later we can crack these hashes with standard tools such as aircrack or hashcat, and thus obtain the credentials. Of course, we should only do this in networks that we manage ourselves or that we have permission to audit.</p><p><strong>The process.</strong></p><p>Hardware requirements:</p><ul><li><a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5Stack CORE Development Kit</a> with built-in 110mAh Battery ($45)</li></ul><p>Optionally:</p><ul><li><a href="https://bit.ly/3gYtI48" target="_blank" rel="nofollow noopener">Extended Battery M5Stack Core Development Kit Capacity 700mAh Stackable Module</a> (USD$12)</li><li><a href="https://www.banggood.com/M5Stack-Multi-function-Digital-Watch-with-700mAh-Battery-for-M5Stack-ESP32-Core-p-1551727.html?rmmds=search&amp;cur_warehouse=CN" target="_blank" rel="nofollow noopener">Smart Watch Module with 700mAh Battery for M5Stack ESP32 Core</a> ($15)</li></ul><p>The software installation is pretty straight forward:</p><p>1.Setup Arduino IDE environment.</p><p><em>M5Stack Arduino IDE Setup in 5 minutes <a href="https://www.youtube.com/watch?v=U2es-l4z2Zg" target="_blank" rel="nofollow noopener">https://www.youtube.com/watch?v=U2es-l4z2Zg</a></em></p><p>2. Add M5 stack / ESP32 library. (read the <a href="https://docs.m5stack.com/" target="_blank" rel="nofollow noopener">M5 Stack documentation</a> , its pretty solid. As far as ‚Äúinstallation‚Äù goes)</p><p>3. Git clone G4lile0 code.</p><p><a href="https://github.com/G4lile0/ESP32-WiFi-Hash-Monster" target="_blank" rel="nofollow noopener">https://github.com/G4lile0/ESP32-WiFi-Hash-Monster</a></p><p>4. Compile &amp; upload the file to the M5Stack.</p><p>5. Go handshake/PMKID fishing.</p><p>6. Review captures.</p><p>The monster hash saves the files in the micro sd card in pcap format so they can be used by most network analysis tools directly. The files are saved sequentially with the pattern 1.pcap, 2.pcap, etc.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/3dfd72fd0d7415f58f7320b77d722a313f4568f49c863c9bbb502f18d8f454f9.png"></p><p><strong>Cracking notes: Aircrack &amp; hashcat.</strong></p><p>In order to complete this tutorial, we will try doing dictionary attacks against a handshake file from Hash Monster. We will do this with two known tools ‚Äì Aircrack-ng and Hashcat, which relies respectively on CPU and GPU power. We will be running these tools from linux, even though they are both found in a Windows version as well. Remember to use recent versions to benefit from the PMKID attack in addition to the traditional cracking of handshakes.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/adb3724e47a02d9fe14b83454cae422f882a9c99ccc78f0f2db6ef6e7a7f6f9b.png"></p><p>Aircrack-ng can be used for very basic dictionary attacks running on your CPU. Before you run the attack you need a wordlist. I recommend using the infamous rockyou dictionary file:</p><p># download the 134MB rockyou dictionary file</p><pre><code><code>curl -L -o rockyou.txt https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt</code></code></pre><p>Note, that if the network password is not in the wordlist you will not crack the password.</p><p># -a2 specifies WPA2, -b is the BSSID, -w is the wordfile</p><pre><code><code>aircrack-ng -a2 -b AC:FC:E3:C9:AB:C0 -w rockyou.txt 3.cap</code></code></pre><p>If the password is cracked you will see a KEY FOUND! message in the terminal followed by the plain text version of the network password.</p><p>Cracking an WiFi password using brute force attack for a long WiFi password without GPUs or Cloud help, will be a nightmare but if the password is short or you know the key pattern it will be "easily" cracked.</p><p>Here you have a small guide for linux (Ubuntu) to crack the WiFi password using the files stored on the SD_Card of the Purple Hash Monster using your computer.</p><p>First we need to install <strong>hashcat</strong></p><pre><code><code>sudo apt-get update</code><br>
<code> sudo apt install hashcat</code></code></pre><p>EAPOL/PMKID stored on the SD-Card are <em>pcap</em> files, we have to convert to <em>hccapx</em> format to work with hashcat. In terminal from the directory were we have the <em>pcap</em> file from the SD-CARD:</p><pre><code><code>wget https://raw.githubusercontent.com/hashcat/hashcat-utils/master/src/cap2hccapx.c</code><br>
<code> gcc -o cap2hccapx cap2hccapx.c</code><br>
<code> ./cap2hccapx 1.pcap 1.hccapx</code></code></pre><p>For example if we know that the wifi password has a lenght of 8 digits we can run the following command, and in few seconds we will have the WiFi Password :)</p><pre><code><code>hashcat --force -m 2500 -a 3 -1 ?d -o cracked 1.hccapx ?1?1?1?1?1?1?1?1</code></code></pre><p><strong>Final notes</strong></p><p>Although in my case I exclusively use the M5 Stack for the pocket monster hash, there are undoubtedly several projects that run on the M5 Stack and you will certainly want to take a look if you are interested in wifi and bluetooth security attack tools for this platform.</p><p>M5 Stack WiFi SSID Scanner by Elkentaro</p><p><a href="https://github.com/elkentaro/M5_SSID_scanner_collector" target="_blank" rel="nofollow noopener">https://github.com/elkentaro/M5_SSID_scanner_collector</a></p><p>Covid Sniffer: BLE COVID exposure app sniffer using M5 Stack</p><p><a href="https://gitlab.com/mschmidl/covidsniffer" target="_blank" rel="nofollow noopener">https://gitlab.com/mschmidl/covidsniffer</a></p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/02ee78aa44062073eb950642e19a44a548daf55d3217643f1a98cc84d37bc7d6.jpeg"></p></article></div>]]>
            </description>
            <link>https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351269</guid>
            <pubDate>Wed, 02 Sep 2020 08:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economics of Skyscraper Height]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24351069">thread link</a>) | @keiferski
<br/>
September 2, 2020 | https://buildingtheskyline.org/economics-of-skyscraper-height-series/ | <a href="https://web.archive.org/web/*/https://buildingtheskyline.org/economics-of-skyscraper-height-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article class="page"><div><p><img src="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg" alt="" width="978" height="652" srcset="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg 978w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-300x200.jpg 300w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-768x512.jpg 768w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-640x427.jpg 640w" sizes="(max-width: 978px) 100vw, 978px"></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part I)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018</p>
<p>Many people look at skyscrapers around the world and conclude they are unnecessarily tall. This blog post discusses the economics of skyscraper height. Contrary to popular belief, most skyscrapers have a strong economic rational. <a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part II)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 3, 2019</p>
<p>What drives the heights of the world‚Äôs tallest buildings? This post reviews some of the theories that may causes skyscrapers to be economically ‚Äútoo tall.‚Äù Some theories are ‚Äúnefarious,‚Äù some are benign, while others are productive. <a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part III)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 21, 2019</p>
<p>Supertall skyscrapers are assumed to be driven by greed and ego. This blog post reviews the evidence for eight world-record-breaking buildings completed since 1930. The case studies demonstrate, however, that the reality is a bit more complex. <a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part IV): Construction Costs Around the World</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noopener noreferrer">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; June 4, 2019</p>
<p>What does it cost to build a skyscraper? The blog post reviews the economics of skyscraper supply. One of the reasons why we increasingly see supertalls in Asia is the because of cost of construction is so low there.&nbsp; So, what are the ‚Äúcostnomics‚Äù that generate building height? <a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>

<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --></div></article></main></div></div></div>]]>
            </description>
            <link>https://buildingtheskyline.org/economics-of-skyscraper-height-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351069</guid>
            <pubDate>Wed, 02 Sep 2020 08:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lesser-known Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 393 | Comments 127 (<a href="https://news.ycombinator.com/item?id=24350647">thread link</a>) | @Sandeepg33k
<br/>
September 1, 2020 | https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>API</code> is the acronym for Application Programming Interface which defines interactions between multiple software architecture layers. Programmers carry out complex tasks easily using APIs in software development. Without APIs, a programmer's life would have been miserable with no proper(security, for example) access to data,  knowing unnecessary low level details etc.</p>
<p>When it comes to Web APIs, there are extremely useful  objects, properties and functions available to perform tasks as minor as accessing DOM to as complex as managing audios, videos, graphics, etc. </p>

<p>If you are from the web development background, you are using many of them already. Here is the list of very well known web APIs.</p>
<ul>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">Canvas</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">Fetch</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/History_API">History</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation_API">Geolocation</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">DOM</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Console_API">Console</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API">Drag &amp; Drop API</a></li>
</ul>
<p>In this article, I am going to talk about 10 more web APIs that are not so popular. Lesser popular doesn't mean, they are not useful. You can use them in various use-cases of your project. Please have a look.</p>

<p>If you would like to jump into the source code or see the demonstration immediately, here are the quick links to them:</p>
<blockquote>
<ul>
<li><a target="_blank" href="https://github.com/atapas/demolab/tree/master/code/src/demos/web-apis">Link to the Source Code @GitHub</a></li>
<li><a target="_blank" href="https://demo.greenroots.info/categories/web-apis/">Link to the Web API DemoLab</a></li>
</ul>
</blockquote>
<p>Note: Web APIs are nothing but the interfaces, functions, objects, properties written and exposed using vanilla JavaScript. However the usage of the web APIs is not limited to the vanilla JavaScript based application alone. It is very straightforward to use them with an Angular, React or Vue based applications as well.</p>
<p>All the examples I have used to demonstrate the web apis in this article are written using reactjs. You can find them in the github link mentioned above. Please feel free to fork, change and use!</p>

<p>A big (pain) point about  using a web API is, most of them are not standardized yet. It means, the support for a web API  may differ from one browser vendor to another. For example, You may find an API working with the Chrome browser but, not supported by Firefox or Edge browsers yet.</p>
<p>I would suggest a couple of ways to have a check on this,</p>


<p>Alright, time to get started knowing them. Hope you also find these useful.</p>
<h2 id="1-fullscreen-api">1. üì∫ Fullscreen API</h2>
<p>Do you have the need to show any of the DOM elements in full-screen mode? The full-screen use-case is very demanding for gaming applications, online video platforms(like, youtube) etc. </p>
<p>The <code>Fullscreen API</code> provides methods to present a specific Element (and its children) in a full-screen mode. There is a method available to exit full-screen mode once it is no longer needed. Not only that, this API can also help to perform any actions when a DOM element transition into a full-screen mode or comes out of it.</p>
<p>In the example below, my favorite Santa Claus can get into the full-screen mode and come out of it with ease.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598715764074/fR7trCfsA.gif?auto=format,compress&amp;gif-q=60" alt="full_screen.gif"></p>
<p>In the code below, the <code>manageFullScreen()</code> function uses  the <code>requestFullscreen()</code> API on an element which is having an id called, <code>fs_id</code>. </p>
<pre><code><span>const</span> manageFullscreen = () =&gt; {
   <span>document</span>.getElementById(<span>'fs_id'</span>).requestFullscreen();
}
</code></pre>
<p>This element with id, <code>fs_id</code> is a <code>DIV</code> with a child element, i.e, the Santa Clause image.</p>
<pre><code>&lt;div className=<span>"column"</span>&gt;
  <span><span>&lt;<span>div</span> <span>id</span>=<span>"fs_id"</span>&gt;</span>
    <span>&lt;<span>Img</span> <span>fixed</span>=<span>{imageData.image.childImageSharp.fixed}</span> <span>alt</span>=<span>"santa"</span> /&gt;</span>
   <span>&lt;/<span>div</span>&gt;</span>

    <span>&lt;<span>StyledButton</span> 
         <span>onClick</span>=<span>{manageFullscreen}</span>&gt;</span>
            Enter Fullscreen with Santa
    <span>&lt;/<span>StyledButton</span>&gt;</span>
 <span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>You can check if the <code>Fullscreen API</code> is supported by the browser,</p>
<pre><code><span>if</span> (<span>document</span>.fullscreenEnabled) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Also watch out for the useful handlers like,</p>
<ul>
<li><code>onfullscreenchange</code>: An event handler for the fullscreenchange event.</li>
<li><code>onfullscreenerror</code>: An event handler for the fullscreenerror event.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-fullscreen/">https://demo.greenroots.info/web-apis/web-apis-fullscreen/</a></p>
<h2 id="2-clipboard-async-api">2. üìã Clipboard Async API</h2>
<p>What is a clipboard in comuping?</p>
<blockquote>
<p>The clipboard is a buffer that some operating systems provide for short-term storage and transfer within and between application programs.</p>
</blockquote>
<p>There are mainly three operations you can perform with the clipboard. They are, <code>copy</code>, <code>cut</code> and <code>paste</code>. The Clipboard API provides the ability to respond to these three operations. </p>
<p>Interestingly, copying content to the clipboard is open as in, there is no need of a user permission. However, for pasting the content from the clipboard to the user application, the user needs to grant permission for it. It is achieved using another web API called, <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Permissions_API">Permission API</a></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716493747/PwPwDDK8Y.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Here is a simple example of the copy-paste operation,</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716547383/PoXUNZmnr.gif?auto=format,compress&amp;gif-q=60" alt="clip_board.gif"></p>
<p>This is how to check if the feature is supported by the browser,</p>
<pre><code><span>if</span> (navigator.clipboard 
     &amp;&amp; navigator.clipboard.read 
     &amp;&amp; navigator.clipboard.write) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Here is the async API function for writing the content to the clipboard,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performCopy</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
      <span>await</span> navigator.clipboard.writeText(copyText);
      <span>console</span>.log(<span>`<span>${copyText}</span> copied to clipboard`</span>);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to copy: '</span>, err);
   }
}
</code></pre>
<p>The Async API function to read the content from the clipboard and do something with it,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performPaste</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
       <span>const</span> text = <span>await</span> navigator.clipboard.readText();
       setPastetext(text);
       <span>console</span>.log(<span>'Pasted content: '</span>, text);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to read clipboard contents: '</span>, err);
   }
}
</code></pre>
<p>Note: With the inclusion of the <code>Clipboard Async API</code>, you can get rid of the usage of <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document/execCommand">document.execCommad()</a> function as it is obsolete now.</p>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/">https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/</a></p>
<h2 id="3-resize-observer-api">3. üßê Resize Observer API</h2>
<p>Do you want to take some actions based on the changes to the content or border box of a DOM element? Are you thinking of writing a handler by yourself? What if I tell you, there is already one provided by the web API implementation?</p>
<p>Here is a story about a dumb button. We use a range slider to resize the button. While the button gets resized, we also want to control the text color, without letting the button know much about it. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717277220/dITL6Nog2.gif?auto=format,compress&amp;gif-q=60" alt="resizer.gif"></p>
<p>First, create a button and specify an id so that, we can access the button later using the id.</p>
<pre><code>&lt;StyledButton id=<span>"dumbBtnId"</span>&gt;
   I am a Dumb Button
&lt;<span>/StyledButton&gt;</span>
</code></pre>
<p>Now we create a slider using the <code>range</code> input type from HTML5. A <code>resize()</code> function is invoked when the slider value changes.</p>
<pre><code>&lt;div&gt;
   <span><span>&lt;<span>input</span> 
         <span>onChange</span>=<span>{(event)</span> =&gt;</span> resize(event)} 
         type="range" 
         min={minRange} 
         max={maxRange} 
         defaultValue={rangeValue} /&gt;
<span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>The <code>resize()</code> function simply sets the width of the button as the slider range value so that, it can be resized dynamically.</p>
<pre><code><span>const</span> resize = event =&gt; {
   <span>const</span> value = event.target.valueAsNumber;
   setRangeValue(value);
   <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
   dumbBtn.style.width = <span>`<span>${value}</span>px`</span>;
 }
</code></pre>
<p>So far, so good? Now for every range value change, the button gets resized. We have a <code>ResizeObserver</code> observing this change and change the color of the button text.</p>
<pre><code>useEffect(() =&gt; {
   <span>try</span> {
            <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
            <span>var</span> resizeObserver = <span>new</span> ResizeObserver(entries =&gt; {
                <span>for</span>(<span>const</span> entry <span>of</span> entries) {
                    
                    
                   entry.target.style.color = <span>'green`;
                }
      });
      resizeObserver.observe(dumbBtn);
   } catch(e) {
            setSupported(false);
            console.log(e);      
   }
}, [rangeValue]);</span>
</code></pre>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-api-resize-observer/">https://demo.greenroots.info/web-apis/web-api-resize-observer/</a></p>
<h2 id="4-image-capture-api">4. üì∑ Image Capture API</h2>
<p>There are some cool and useful APIs around user media like, audio, video etc. I love the <code>Image Capture API</code> which helps us to capture an image or grab a frame from the video devices(like webcam). Not only that, you can also perform actions on capturing an image or grabbing a frame.</p>
<p>First, get the user media access. In this case we are getting the webcam access.</p>
<pre><code>navigator.mediaDevices.getUserMedia({video: <span>true</span>})
  .then(mediaStream =&gt; {
     <span>document</span>.querySelector(<span>'video'</span>).srcObject = mediaStream;
     <span>const</span> track = mediaStream.getVideoTracks()[<span>0</span>];
     setTrack(track);
  }).catch(error =&gt; {
     <span>console</span>.error(<span>` <span>${error}</span> is not yet supported`</span>);
     setError(error);
});
</code></pre>
<p>Just like the clipboard paste operation, a webcam media access permission has to be granted by the user.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717565379/MCRNY49Tl.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Now Grab a frame and do something. In this example, I am just drawing the frame on a Canvas.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.grabFrame()
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#grabFrameCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>I can also take a picture and do the similar thing.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.takePhoto().then(blob =&gt; createImageBitmap(blob))
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#takePhotoCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>To stop the video streaming from the webcam, just call he method <code>stop()</code> on the running video track.</p>
<pre><code><span>const</span> videoOff = () =&gt; {
   track.stop();
 }
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717833234/MPOxVZ92M.png?auto=format&amp;q=60" alt="chrome_Umvi16wUlu.png"></p>
<p>Also watch out for the methods,</p>
<ul>
<li><code>getPhotoCapabilities()</code>: To get the ranges of available configuration options.</li>
<li><code>getPhotoSettings()</code>: To get the current photo configuration settings.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-image-capture/">https://demo.greenroots.info/web-apis/web-apis-image-capture/</a></p>
<h2 id="5-broadcast-channel-api">5. üì° Broadcast Channel API</h2>
<p>The <code>Broadcast Channel API</code> allows communication between browsing contexts (windows, tabs, iframes) and workers on the <strong>same origin</strong>. Think of a use-case like, once you logout from an app running in a browser tab, you want to broadcast it to the app instances opened in other tabs of the same browser.</p>
<p>Here is an example where a sender is sending a message to the receiver and the same is being ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</a></em></p>]]>
            </description>
            <link>https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350647</guid>
            <pubDate>Wed, 02 Sep 2020 06:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A round-up of topology-based papers at ICML 2020]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24350436">thread link</a>) | @Topolomancer
<br/>
September 1, 2020 | https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>With this year‚Äôs <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning&nbsp;(ICML)</a>
being over, it is time to have another instalment of this series.
Similar to <a href="http://bastian.rieck.me/blog/posts/2019/icml_tda_roundup/">last year‚Äôs post</a>, I shall cover
several papers that caught my attention because of their use of
topological concepts‚Äîhowever, <em>unlike</em> last year, I shall not
restrict the selection to papers using <a href="https://en.wikipedia.org/wiki/Topological_data_analysis">topological data analysis&nbsp;(TDA)</a>.</p>
<p><strong>Caveat lector:</strong> I might have missed some promising papers. Any
suggestions for additions are more than welcome! Please reach out
to me via <a href="https://twitter.com/Pseudomanifold">Twitter</a> or
<a href="mailto:bastian@rieck.me">e-mail</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_chen.png" alt="Learning Flat Latent Manifolds with VAEs" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04881">Learning Flat Latent Manifolds with VAEs</a>
by <a href="https://argmax.ai/team/nutan-chen">Nutan Chen</a>, <a href="https://www.argmax.ai/team/alexej-klushyn">Alexej Klushyn</a>,
Francesco Ferroni, <a href="http://bayerj.github.io/">Justin Bayer</a>, and
<a href="https://argmax.ai/team/patrick-van-der-smagt">Patrick van der Smagt</a>
discusses an interesting modification of variational autoencoders, viz.
an extended loss term that regularises the latent space to be
<em>flat</em>&nbsp;(i.e. having no <a href="https://en.wikipedia.org/wiki/Curvature">curvature</a>).
The main idea is to ensure that the <a href="https://en.wikipedia.org/wiki/Metric_tensor">Riemannian metric tensor</a>
is the identity matrix.</p>
<p>The ingenious implication of such a latent space is that the Euclidean
distance is a good proxy for the similarity between data points, whereas
this is <em>not</em> a priori the case for other latent spaces. It is interesting
to note that there is a ‚Äòsibling‚Äô paper to this one, which was published
at ICLR 2020, namely <a href="https://openreview.net/pdf?id=S1g6xeSKDS">Mixed-curvature Variational Autoencoders</a>.
This paper presents an autoencoder whose latent space is a product of
Riemannian manifolds, whose curvature is either fixed or learnable.</p>
<p>I am glad to see that curvature is starting to attract more attention
from the machine learning community. It is such a fundamental property
of a manifold but can influence the validity of many calculations in
latent spaces. It also has some beneficial properties for <a href="https://openreview.net/pdf?id=BylEqnVFDB">graph
classification</a>, but this is
maybe a better topic for a subsequent post!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hoferb.png" alt="Graph Filtration Learning" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1905.10996">Graph Filtration Learning</a> by
<a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> is arguably<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> the first step
towards properly integrating topological features into neural networks
for graph classification! Briefly put, we developed a homological
<code>READOUT</code> function&nbsp;(to use the parlance of graph neural networks)
that gives rise to a learnable filter function‚Äîa <em>filtration</em>.</p>
<p>This concept might be unknown to some readers, but a filtration in this
context is a scalar-valued function on the vertices of a graph that
permits <em>sorting</em> it. Filtrations serve as the backbone for many
topology-based algorithms, primarily for the aforementioned <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>,
which permits us to study multi-scale topological
features&nbsp;(connected components, cycles, etc.) of an object.
Prior to this paper, filtrations were pre-defined or chosen based on
some target function, such as the vertex degree function of a graph. Our
approach changes this‚Äîleading to a filtration that is learnable in an
end-to-end fashion and thus specifically designed for a classification
problem.</p>
<p>We manage to achieve this by first initialising our filter function
based on a regular graph neural network; essentially, one level of
message passing between nodes is sufficient. This provides us with
a non-trivial filter function whose performance we can subsequently
adjust by calculating the topological features induced by said filter,
and vectorising the resulting representations. Since each of these steps
is differentiable<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, the resulting function is also differentiable,
making it possible to adjust the filter for the best classification
results.</p>
<p>I would recommend this paper to anyone who is interested in learning
more about the benefits that a topology-based perspective brings to
certain application problems. Being able to learn the <em>right</em> topological features
to classify a set of graphs opens up exciting opportunities.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hofera.png" alt="Topologically Densified Distribution" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04805">Topologically Densified Distributions</a>
by <a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> studies regularisation properties of
over-parametrised neural networks in the context of small sample-size learning.
This is achieved by studying the properties of latent
representations&nbsp;(the paper uses the term <em>internal representation</em>,
but this is equivalent). More precisely, generalisation properties are
analysed via the <a href="https://en.wikipedia.org/wiki/Pushforward_measure">push-forward probability measure</a>
induced by the latent representation&nbsp;(or <em>encoding</em>).</p>
<p>The authors show that probability mass concentration around training
samples in the latent space is linked to the generalisation capabilities
of a model, but, even more exciting, such a concentration can be achieved by applying
topological constraints on samples from that space! In the context of
this paper, such constraints pertain to measuring the <em>connectivity</em> of
samples. This is achieved using <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>, specifically,
by calculating a zero-dimensional Vietoris‚ÄìRips complex‚Äîif you are
not familiar with this term, just think of a minimum spanning tree.</p>
<p>What I particularly enjoyed about this paper is that it starts providing
solid answers to fundamental concepts in machine learning. All too often,
we remain in the realm of the empirical and just <em>observe</em> whether our
network generalises. This paper ventures into hitherto-unknown territories
and gives us a theoretical justification!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_moor.png" alt="Topological Autoencoders" width="250"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1906.00722">Topological Autoencoders</a> by
<a href="https://michaelmoor.ml/">Michael Moor</a>,
<a href="https://expectationmax.github.io/">Max Horn</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>, and
<a href="https://bsse.ethz.ch/mlcb/karsten.html">Karsten Borgwardt</a> deals with
regularising the latent space in terms of its topology. More precisely,
we preserve the topological features of the input data in the respective
latent space&nbsp;(on the batch level, respectively). While we restrict
our experiments to connected components for now&nbsp;(so no cycles
yet, even though our method generalises to higher dimensions),
our approach makes it possible to create latent representations
that ‚Äòmimic‚Äô the topological features of the input.</p>
<p>This leads to a nice plug-and-play loss term that can be easily
integrated into most architectures, and we can demonstrate that, among
others, it considerably improves the quality of a ‚Äòvanilla‚Äô autoencoder
architecture. To achieve this goal, we had to solve all kinds of
interesting adventures, one of them being how to make everything
differentiable. Interestingly, we end up with a similar necessary
condition for differentiability than for the graph filtration learning
paper, viz. the pairwise distances between different samples of the
input batch need to be <em>unique</em>.</p>
<p>The coolest feature of our method is that it technically <em>only</em> requires
a distance metric between input samples<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, nothing more‚Äîno feature
vector representation or anything. It can thus conceivably be used to
represent the topology of any object you fancy&nbsp;(including
documents, images, and graphs).</p>
<p>If you are interested in a beautifully-animated high-level introduction
to this publication, you should take the time to read Michael‚Äôs <a href="https://michaelmoor.ml/blog/topoae/main/">blog post on our paper</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_rezende.png" alt="Normalizing Flows on Tori and Spheres" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.02428">Normalizing Flows on Tori and Spheres</a> by
<a href="https://danilorezende.com/">Danilo Jimenez Rezende</a>,
<a href="https://gpapamak.github.io/">George Papamakarios</a>,
<a href="https://scholar.google.com/citations?user=o-h0vrQAAAAJ">S√©bastien Racani√®re</a>,
<a href="http://malbergo.me/">Michael S. Albergo</a>,
<a href="https://scholar.google.com/citations?user=zK77P6MAAAAJ">Gurtej Kanwar</a>,
<a href="https://web.mit.edu/physics/people/faculty/shanahan_phiala.html">Phiala E.  Shanahan</a>,
and <a href="http://theoryandpractice.org/">Kyle Cranmer</a>
present a novel method for calculating normalising flows on more complex
spaces than the usual Euclidean ones. Specifically, as the title
implies, they develop methods for calculating such flows on tori and
spheres.</p>
<p>What I enjoyed about this paper is the smart way of constructing flows
iteratively: first, flows on the circle are being constructed&nbsp;(using
different concepts for defining a <a href="https://en.wikipedia.org/wiki/Diffeomorphism">diffeomorphism</a>, the most favourite of
mine being a <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_transformation">M√∂bius transformation</a>).
Since a torus can be described as the Cartesian product of circles, this
is sufficient to describe flows on tori of arbitrary dimensions! Next,
the flows are generalised to higher-dimensional spheres.</p>
<p>While I am by no means and expert in normalising flows, I liked
reading this paper a lot. The theory is well-developed and it is another
one of those publications that shows you how to go beyond the boundaries
of what is currently possible. Moreover, I enjoyed the discussion of the
implementation details‚Äîit turns out that achieving numerical stability
here is another feat that deserves some mention!</p>

<p>This year‚Äôs ICML also featured an interesting array of topology-based
papers. Not all of them fit neatly into the field of topological data
analysis&nbsp;(TDA), but I am happy to see that the community is
starting to pick up this fundamental topic. I remain convinced that
a topology-driven perspective is needed to answer certain foundational
questions in machine learning. Here‚Äôs to the future of topology!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Even if say so myself. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Under mild assumptions, viz. provided that the filter function
values are unique for each vertex. This can always be achieved by
a small symbolic perturbation. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Practically, it might not even require the properties of a metric,
although the mathematician in me is screaming at the horrors of this
thought. <a href="#fnref:3" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350436</guid>
            <pubDate>Wed, 02 Sep 2020 06:03:30 GMT</pubDate>
        </item>
    </channel>
</rss>
