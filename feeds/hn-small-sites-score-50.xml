<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 23 Feb 2021 08:35:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 23 Feb 2021 08:35:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Modern software controls dependencies because it helps software authors]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26210576">thread link</a>) | @todsacerdoti
<br/>
February 20, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Modern software controls dependencies because it helps software authors</h2>

	<p><small>February 20, 2021</small></p>
</div><div><p>Over on Twitter <a href="https://twitter.com/thatcks/status/1363196953065099265">I had a hot take</a>:</p>

<blockquote><p>Hot take: Every distribution packager who's saying "you shouldn't
bundle dependencies" is implicitly telling software authors "you
should do more work for us and limit the features (and reliability) of
your software".</p>
</blockquote>

<p>(This was sparked by reading <a href="https://blogs.gentoo.org/mgorny/2021/02/19/the-modern-packagers-security-nightmare/">The modern packager√¢‚Ç¨‚Ñ¢s security
nightmare</a>,
<a href="https://lobste.rs/s/zb1c4k/modern_packager_s_security_nightmare">via</a>.
I'm not exactly on one side or the other, but <a href="https://twitter.com/thatcks/status/1363263921960980485">I do think distributions
should be honest about what they're asking for</a> and I
don't think they're going to get it.)</p>

<p>This hot take is a bit too narrow. What really matters is software
authors and modern software systems restricting the versions of
dependencies (for both maximum and minimum versions). Explicit or
implicit bundling on top of that just makes the problem slightly worse
for distributions.</p>

<p>For software authors, restricting the versions of dependencies that
they work with reduces the amount of work that they have to do,
both to test against a range of versions and to either forever chase
after whatever changes those dependencies like to make or to forever
limit what features of dependencies they use to ones available in
old versions (and sometimes both at once). In theory, both testing
and chasing after changes would be dealt with by <a href="http://semver.org/">Semantic Versioning</a> (if everyone followed it), at least for a
single program. In practice, not only are people fallible but also
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SemverHasLimits">people have a different understanding of what semantic versioning
means</a> because semantic versioning is ultimately
a social thing, not a technical one. Our field's history has shown
(sometimes vividly) that if software authors allow versions of
dependencies to move on them, soon or later things break and the
software author has to fix it.</p>

<p>(There's also the practical issue that not all dependencies even
claim or agree to follow semantic versioning in the first place.)</p>

<p>For distributors, once software authors start restricting versions
the distributor has both an upgrade problem and a distribution
problem. On the upgrade side, dealing with an issue in a program may now
require persuading it to accept a new version of a dependency. On the
distribution side, it's now likely that you'll have multiple programs
that have different version requirements for the same dependency. At the
very least this multiplies the packages involved.</p>

<p>(Many distributions also have package system design problems that
restricts the range of versions of things that they can have installed
at the same time. Even under <a href="http://semver.org/">Semantic Versioning</a>, this is a
problem for the distribution the moment that you have two programs
with conflicting version requirements that can't both be packaged and
installed at the same time.)</p>

<p>However, there's no free lunch here. What distributors want when
they ask for unbundled dependencies without version restrictions is
for software authors to do the work to accept any version of their
dependencies, or at least any version that falls within <a href="http://semver.org/">Semantic
Versioning</a>, and for dependencies to faithfully follow semver and
also make it possible to package and install different major versions
(at least) at the same time. <strong>Accepting a broad version range of your
dependencies is actual work</strong>, even apart from the limitations it may
impose on what your code and your software can do. Software authors and
the creators of software package ecosystems (like Go and Rust) are not
refusing to do this because they don't like distributions; they are
refusing to do this because they have found, over and over again, that
this doesn't really work and does cause problems for software authors
(and often users of programs) in the long run.</p>

<p>(The software community that's gone through this experience the
most visibly is Go, which started out with intrinsically unversioned
dependencies that were used universally across all your programs
by default and wound up switching to strongly versioned dependencies
after many people had many problems with that initial state. Go
experienced so many problems that <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/FallibleSemverAndMVS">they adopted an unusually strict
and software author friendly versioning scheme</a>.)</p>

<p>It's popular for people to argue that software authors should be doing
this work anyway even if the distributions weren't asking for it,
so them actually doing it is no big deal. This is quite convenient
for the people making the argument, but it doesn't make the argument
valid. Software authors don't owe anyone any work what so ever; they
do whatever work serves their needs and is interesting to them. With
limited time and interest, it's both rational and proper for software
authors to optimize for their own development.</p>

<p>PS: Generally distributions also want some combination of all software
to update to the latest version of their dependencies and for
dependencies to explicitly support older versions. This is also extra
work for software authors, especially when the distribution also wants
it to happen for older versions of programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210576</guid>
            <pubDate>Sun, 21 Feb 2021 03:36:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We live in an age of distractions, dealing with constant mental stimulus]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 93 (<a href="https://news.ycombinator.com/item?id=26207184">thread link</a>) | @iamsanteri
<br/>
February 20, 2021 | https://www.lostbookofsales.com/age-of-distractions/ | <a href="https://web.archive.org/web/*/https://www.lostbookofsales.com/age-of-distractions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.lostbookofsales.com/content/images/size/w300/2021/02/lbs-distractions-santeri-liukkonen.jpg 300w,
                            https://www.lostbookofsales.com/content/images/size/w600/2021/02/lbs-distractions-santeri-liukkonen.jpg 600w,
                            https://www.lostbookofsales.com/content/images/size/w1000/2021/02/lbs-distractions-santeri-liukkonen.jpg 1000w,
                            https://www.lostbookofsales.com/content/images/size/w2000/2021/02/lbs-distractions-santeri-liukkonen.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.lostbookofsales.com/content/images/size/w2000/2021/02/lbs-distractions-santeri-liukkonen.jpg" alt="Age of distractions">
            </figure>

            <section>
                <div>
                    <p>The book is exciting and the story is funny. In fact, I'm learning something new. So much so, that I keep writing down my ideas and shuffling their implications. And suddenly, I realize something. In the past 15-minutes, I've only managed to cover three pages and I'm already thinking about next things I'm supposed to do. Cleaning, picking-up the groceries, doing my excercises, writing a couple of lines of code, watching a movie... </p><p>Is this supposed to be my Saturday off work?</p><p>So I stop and think. When was the last moment that took longer than 10 seconds, where I didn't have an urge to check an app on my phone, see if I got new email, or impulsively do something else?</p><p>By now, where I live, it's been many months of nightly curfews and limitations on travel and social life. I consider myself a very fortunate person to have suffered a relatively small impact from the global pandemic. Nonetheless, I can't stop but think about why my mind feels so exhausted while at the same time requiring a constant stream of stimulus that results in overbearing distraction. </p><p>It was already before the pandemic that I heard my colleagues talking about "<a href="https://en.wikipedia.org/wiki/Digital_detox"><em>digital detox</em></a>" and discussing their efforts to break out of being constantly connected while trying to regain their energy and allowing for some rest. Thus, I surely know that I'm not alone with these thoughts. </p><p>Finally, after subscribing to <a href="https://amzn.to/3alEC3u">Audible</a> last summer, there only remains little time in my day when I am not stimulating my brain in one way or another. It was some sort of a panic that hit me when I realized that I am no longer able to enjoy a thing that I've always enjoyed so much, reading a great book at length. </p><p>Today I called with a good friend of mine and he said: </p><p><em>"Yeah right! It's like we must constantly be multitasking or something... Even when I get to playing a Playstation game and it starts to load, I just all the time have to unlock my phone and check what is going on..."</em></p><h2 id="to-observe-and-reflect">To observe and reflect</h2><p>I recently read <a href="https://www.lostbookofsales.com/notes/the-almanack-of-naval-ravikant-by-eric-jorgenson/amp/">a book where Naval describes</a> what meditation means for him, and I cannot help but agree with his way of putting it. </p><p>One only needs to stop and observe his thoughts in a calm state. Your mind is like a monkey in a room, misbehaving and throwing feces all over the walls. It is fascinating how you realize this while trying to focus on your breath and not let your thoughts wander. In a matter of seconds, however, you already catch yourself thinking about entirely something different. When practicing to focus your attention and letting your thoughts pass, this inner monkey seems to eventually calm down and let you achieve a little peace of mind. It is not so easy. </p><figure><img src="https://www.lostbookofsales.com/content/images/2021/02/santeri-drawing-LBS-1.jpg" alt=""><figcaption>One year into the global pandemic - SL 2020 (LBS)</figcaption></figure><p>After so many months of being limited with our social interactions, it feels like the scariest thing out there is to be left by ourselves. Especially us young people tend to handle this quite badly. Without typical distractions and mental stimulus available throughout our days, our mind starts to seek for something to occupy itself resulting in raised anxiety levels and stress. We are today forced to confront our inner selves like never before. </p><h2 id="so-what">So what?</h2><p>Billions of dollars are invested and brightest specialists are hired each year to engineer new distractions. They fight for every second of our limited attention spans, leading us further astray without us even noticing it. </p><p>When shortest breaks require distraction and only the rarest moments, such as taking a shower, offer a refuge from our electronic devices, how are we supposed to work towards our long-term goals? The type of goals that can only be achieved when managing to work in a state of sustained attention? Rarely do great things in life come in a form of neatly packaged gratification to which we are getting more and more accustomed to. </p><p>Reading reports and hearing on the radio that the general feeling and wellbeing in our societies during these challenging times is again on decline, constant distractions might truly be the enemy that stands in our way of what we ought to achieve.</p><h2 id="fighting-back">Fighting back</h2><p>At some point I read that <a href="https://qz.com/1476157/overworked-south-koreans-are-finding-solace-in-a-fake-prison/">South Koreans already pay to live in a hotel-like "prison"</a> to relieve themselves from digital devices. I'm not quite ready to go that far just yet. </p><p>Admittedly, a cottage in the middle of nowhere in Finland would be the way to go anyways.</p><figure><img src="https://www.lostbookofsales.com/content/images/2021/02/santeri-mikkeli-LBS.jpg" alt=""><figcaption>Late autumn lakeside view - Year 2016, Finland</figcaption></figure><p>Once upon a time before the pandemic I saw a colleague of mine use his phone as we were picking up lunch, and I couldn't help but ask why was the screen black and white? He told me he does it intentionally to make his handset less attractive, resulting in less tapping around. That struck me as bizarre. How odd, do we really need to resort to such approaches? </p><p>So what were some of the smaller changes I did to improve my wellbeing? </p><p>Unlike South Koreans with their voluntary confinement, or my friend with his greyscale screen, I started with some less drastic measures. These small changes proved enormously helpful. </p><p>First of all, I opened the screen-time function on my phone and looked through apps that sent me most notifications, proceeding to drastically dial them back. Today, most phones have a feature to limit the screen-time of apps, locking you out after a certain amount of time has passed. This function is plain useless for me or my friends whom I've seen to just enter their pin every single time they wanted to do something. What I did instead was that I just plain and simply uninstalled Instagram. </p><p>I had contemplated to delete it for a long time and almost did it, but instead always settled to just disable the notifications. When I finally did this however, two interesting realizations struck me. </p><p>First thing was that during the initial couple of weeks without the app I was totally surprised at how little I missed it. It literally had never provided me with anything of value, and I only used it to post an occasional update. Why didn't I uninstall it earlier? There was no feeling of missing out. Wow, this realization echoed a feeling that I had after uninstalling 9GAG many years earlier. </p><p>Second, I didn't even notice how those colorful icons on the home-screen invited me to tap on their respective apps as soon as I found myself aimlessly scrolling through my phone. I understood this in a particularly strong way after hiding another app, LinkedIn. Being an important tool for my work, all I did in addition to hiding it from the homescreen was to disable the last types of notifications I ever received from them. Lo' and behold, I now use this application significantly less and it makes a whole world of a difference. </p><p>Simple, easy and fast. Your life will be better for it, just try! Exponential returns of joy are expected if you have apps like Tiktok, Clubhouse, Snapchat, or other such platforms installed or bookmarked, that you can easily subject to the same fate and never look back.</p><p>So far, I'm mostly talking about my precious free time. But what could be some simple and small things that I could do when I'm working on my projects? </p><h2 id="focus-operate-and-enjoy-the-results">Focus, operate and enjoy the results</h2><p>I've written about doing <a href="https://www.lostbookofsales.com/why-to-do-lists-often-stink-and-how-do-the-truly-successful-people-maintain-their-productivity/">an experiment and turning myself into a productivity monster</a> back in 2017, and I've recently re-read the post and carefully re-implemented some of my learnings this year. But then again, it's not about going radical, but rather focusing on some small things that are easy to implement. </p><p>Kill the unnecessary Slack and Teams notifications now! Adjust the surprisingly good defaults that Slack provides and make sure none of them, except for the most important notifications, hit your phone after your working hours are over. </p><p>Use effective time-blocking techniques like <a href="https://alphaefficiency.com/20-minutes-pomodoro-weekly-experiment/">Pomodoro</a> for the less pleasant and repetitive, but still important tasks. This, like many other things, I've also learned from one of my colleagues using it in an effective manner.</p><p>Oh, and of course make sure to consider the following crazy important golden rule of life and the universe:<strong> </strong>don't do anything else while having a one-on-one interaction with someone. Just never do this. </p><p>I catch myself with this one sometimes and no matter how small of a signal, it can still tell something to my counterpart. Such mistakes during limited and valuable interactions in these pandemic-ridden times can eat away from our important professional relationships. When having conversations, focus on them fully and wholeheartedly. Multitask when the time is right. </p><p>Oh, and try drinking less coffee in the mornings while cutting alcohol in the evenings, but you've heard this a million times before. Additionally, to all of you who have small kids at home, I truly salute your efforts and patience getting through with this! </p><h2 id="the-most-desired-skill-of-the-future">The most desired skill of the future</h2><p>What if the most sought after and desired skill of the future will be the ability to best manage our constant distractions and maintain a sustained state of productive focus? </p><p>If we can't manage to control our whims, we won't be able to work effectively towards our long-term goals. I guess it's just that simple. </p><p>The first step is to stop and observe. </p><p>Reflection and brutal honesty with oneself while trying to understand what is happening is critical before driving corrections and adjustments into one's behavior. As our society adjusts to challenges posed by global pandemics, there is a chance for us to walk out of this stronger than before. This is a chance for us to learn more about ourselves than would've otherwise been possible, right? </p><p>I'm only trying to think about something positive in these pandemic-ridden times.</p><p>Now let's get back to work...</p><hr><p><em>Author's comment:</em></p><div><p><em>If you enjoyed this post, consider subscribing for an occasional update. Being hand-made, they'll only serve to make your life a little bit richer. Worst case, you'll be able to unsubscribe at any time </em>üòâ<em> </em></p><p><em>See you around! </em></p></div><p><em>-S</em></p>
                </div>
            </section>

                </article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lostbookofsales.com/age-of-distractions/">https://www.lostbookofsales.com/age-of-distractions/</a></em></p>]]>
            </description>
            <link>https://www.lostbookofsales.com/age-of-distractions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26207184</guid>
            <pubDate>Sat, 20 Feb 2021 19:49:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can you not be romantic about programming? (2020)]]>
            </title>
            <description>
<![CDATA[
Score 480 | Comments 328 (<a href="https://news.ycombinator.com/item?id=26206921">thread link</a>) | @joubert
<br/>
February 20, 2021 | https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>08 Sep 2020</p>

  <p>There‚Äôs <a href="https://www.youtube.com/watch?v=9rrAbLNePxU">a scene in Moneyball</a> in which Brad Pitt‚Äôs character, the
manager of the <a href="https://en.wikipedia.org/wiki/Oakland_Athletics">Oakland A‚Äôs</a>, is watching a recording of one of his
players trying so hard to run fast that he stumbles and falls. Lying on the
ground he‚Äôs angry at himself, because he doesn‚Äôt realize that right before he
started his run he hit a home run and scored the game-winning points. Watching
the scene, Pitt leans back, smiles a Brad Pitt smile and says: ‚Äúhow can you not
be romantic about baseball?‚Äù</p>

<p>There are moments in which I ask myself the same thing about programming.</p>

<p>We‚Äôre programming computers. We spend large parts of our days writing down
instructions for machines. Other parts of the day are spent making sure that we
chose the right instructions. Then we talk about those instructions: why and how
we picked the ones we picked, which ones we will consider in the future, what
those should do and why and how long it will probably take to write those down.</p>

<p>It can sound very serious and dry; a bureaucracy of computer instructions. And
yet.</p>

<p>And yet we, the ostensible bureaucrats, talk about magic as something that
exists ‚Äî&nbsp;the good <em>and</em> the bad kind. There are <a href="https://dl.acm.org/doi/book/10.5555/547625">wizards</a>. Instructions
are <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-9.html">‚Äúlike a sorcerer‚Äôs spells‚Äù</a>.</p>

<p>We don‚Äôt call them instructions, though, not when talking about what we produce
each day anyway. It‚Äôs code we write. Emotions are involved. Code, we say, can
be: neat, nice, clean, crafted, baroque, minimal, solid, defensive, hacky, <em>a
hack</em>, art, a piece of shit, the stupidest thing I‚Äôve ever read, beautiful, like
a poem.</p>

<p>Some lines of code are a riddle to anyone but their author and the name code
serves as a warning. Other times, strangely, it‚Äôs a badge of honor.</p>

<p>Fantastic amounts of code have been written, from beginning to end, by a single
person, typing away night after night after night, for years, until one day the
code is fed to a machine and, <em>abracadabra</em>, a brightly coloured <a href="https://en.wikipedia.org/wiki/RollerCoaster_Tycoon_(video_game)#Development">amusement
park</a> appears on screen. Other code has been written, re-written, torn
apart and stitched back together across time zones, country borders and decades,
not by a single person, but by hundreds or even thousands of different people.</p>

<p>This world of programming is held together by code. Millions and millions of
lines of code. Nobody knows how much there is. Some of it is more than 30 years
old, some less than a week, and chances are you used parts of both yesterday.
There are lines of code floating around on our computers that haven‚Äôt been
executed by a machine in years and probably won‚Äôt be for another lifetime.
Others are the golden threads of this world, holding it together at the seams
without no more than a dozen people knowing about it. Remove one of these and it
all comes crashing down.</p>

<p>If you haven‚Äôt been here long enough and try to guess how much there is and how
many generations are layered on top of each other ‚Äî you won‚Äôt even come close.
But stay around. After a while, more and more, you‚Äôll find yourself in moments
of awe, stunned by the size and fragility of it all; the mountains of work and
talent and creativity and foresight and intelligence and luck that went into it.
And you‚Äôll reach for the word ‚Äúmagic‚Äù because you won‚Äôt know how else to
describe it and then you lean back and smile, wondering how someone could not.</p>


</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26206921</guid>
            <pubDate>Sat, 20 Feb 2021 19:16:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New plant-based plastics can be chemically recycled with near-perfect efficiency]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 189 (<a href="https://news.ycombinator.com/item?id=26206513">thread link</a>) | @ColinWright
<br/>
February 20, 2021 | https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/ | <a href="https://web.archive.org/web/*/https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="articleBody"><p dir="ltr">  have developed two sustainable plastic alternatives to high-density polyethylene that can be chemically recycled more easily and nearly 10 times as efficiently, thanks to √¢‚Ç¨≈ìbreak points√¢‚Ç¨ÔøΩ engineered into their molecular structures.</p><p dir="ltr">Derived from plant oils, the new plastics were presented in a <a href="https://www.nature.com/articles/s41586-020-03149-9" target="_self">paper</a> published Wednesday in <em>Nature</em> as low-waste, environmentally friendly replacements to the conventional fossil fuel-based plastics that enter natural ecosystems at a rate of <a href="https://www.nationalgeographic.com/science/article/150212-ocean-debris-plastic-garbage-patches-science">millions of tons per year</a>.</p><p dir="ltr">Most recycling performed today is mechanical recycling, in which plastic is sorted and sliced into pellets that are then used to create new plastic materials. Chemical recycling, in contrast, involves breaking down the long polymer chains of plastic with heat or solvents to retrieve the material's initial monomer components.</p><p dir="ltr">One of the obstacles to developing chemical-recycling technology is also a reason why plastic is a useful material: the strong carbon-carbon bonds in its molecular structure. Polyethylene, the most common kind of plastic, requires at least 600 degrees Celsius to break those bonds to retrieve the monomers, and is chemically recycled at a rate lower than 10%.</p><p dir="ltr">√¢‚Ç¨≈ìStability of the hydrocarbon chains is rather a problem in that case,√¢‚Ç¨ÔøΩ said Stefan Mecking, the lead author of the study and the department chair of chemical materials science at the University of Konstanz in Germany. √¢‚Ç¨≈ìTo really break them down into small molecules needs high temperatures and is energy intensive, and also the yields are not that good.√¢‚Ç¨ÔøΩ</p><p dir="ltr">The plastic compounds created by Mecking and his colleagues had chemical bonds that could be more easily broken so chemically recycling them would be more effective.</p><p dir="ltr">Chemically recycling the two materials, which were forms of polyester and polycarbonate, required placing them in ethanol or methanol with a catalyst at only 120 degrees Celsius, or 150 degrees without the catalyst. The researchers then cooled and recrystallized the plastic before filtering it out. In the case of the polycarbonate, 96% of the initial material was recovered.</p><p dir="ltr">As demand in the recycling industry stalls and recyclable materials pile up in warehouses and landfills, chemical recycling has been offered as part of a solution to reduce plastic waste. The industry group American Chemistry Council has <a href="https://plastics.americanchemistry.com/what-is-advanced-recycling/">praised</a> the emerging technology for the significant role it could play in a circular economy by reducing plastic waste and repurposing it into new products.</p><p>Yet the method is not without pushback. A <a href="https://www.no-burn.org/wp-content/uploads/CR-Technical-Assessment_June-2020.pdf">2020 report</a> by the environmental organization Global Alliance for Incinerator Alternatives criticized a lack of research and reporting in current chemical-recycling technologies and said the process is energy-intensive and may emit hazardous chemicals. Chemical recycling also distracts from efforts to limit plastic production to reduce waste, the organization said.</p><p dir="ltr">In the new research, the chemists found that the recycling process worked when the plastic contained dye or fillers such as carbon fibers, both of which cause challenges in mechanical recycling. The plastics were also successfully recovered when pieces of other plastics were included in the alcohol solvent.</p><p dir="ltr">Plant oils were chosen as starting materials for synthesizing the plastics primarily because of their useful long chains. They are also more sustainably sourced than the crude oil and other fossil fuels used to produce most of the world√¢‚Ç¨‚Ñ¢s plastic material.</p><p dir="ltr">The new plastics were very similar to high-density polyethylene, the widely used plastic labeled as recycling number . Testing by the chemists found that the three materials had comparable properties such as structure, elasticity and molecular weights √¢‚Ç¨‚Äù though the polycarbonate and polyester had lower melting and crystallization points.</p><p dir="ltr">They were also better suited for 3D printing than polyethylene, and they retained their properties after recycling and reuse.</p><p dir="ltr">The one disadvantage of the new materials Mecking identified was their cost. Ethylene is the √¢‚Ç¨≈ìcheapest building block of the chemical industry,√¢‚Ç¨ÔøΩ he said, so, "Competing with conventional polyethylene at the current market and legal framework conditions is very difficult.√¢‚Ç¨ÔøΩ</p><p dir="ltr">Mecking and his colleagues are conducting ongoing research into using their new plastics for 3D printing, an initial application he said would be exciting for further developing the material and eventually scaling up its production.</p><p dir="ltr">These new plastics may also biodegrade in nature more quickly than common polymers because of their engineered break points, a line of inquiry that also interests the German chemist.</p><p dir="ltr"><em>The article, √¢‚Ç¨≈ìClosed-loop recycling of polyethylene-like materials,√¢‚Ç¨ÔøΩ was published Feb. 17 in Nature.√Ç&nbsp;</em><em>The authors of the study were Manuel , Marcel Eck, Dario Rothauer and Stefan Mecking, University of Konstanz. The lead author was Stefan Mecking.</em></p></div></div></div>]]>
            </description>
            <link>https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26206513</guid>
            <pubDate>Sat, 20 Feb 2021 18:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Swift achieved dynamic linking where Rust couldn't (2019)]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26205969">thread link</a>) | @zdw
<br/>
February 20, 2021 | https://gankra.github.io/blah/swift-abi/ | <a href="https://web.archive.org/web/*/https://gankra.github.io/blah/swift-abi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


    <header>
    
    <p>November 7th, 2019</p>
</header>
    <nav id="TOC"><ul>
<li><a href="#background">1 Background</a><ul>
<li><a href="#swift-tldr">1.1 Swift TLDR</a><ul></ul></li>
<li><a href="#what-is-abi-stability-and-dynamic-linking">1.2 What Is ABI Stability and Dynamic Linking</a><ul></ul></li>
<li><a href="#swifts-stable-abi">1.3 Swift's Stable ABI</a><ul></ul></li>
<li><a href="#resilience-and-library-evolution">1.4 Resilience and Library Evolution</a><ul></ul></li></ul></li>
<li><a href="#details">2 Details</a><ul>
<li><a href="#resilient-type-layout">2.1 Resilient Type Layout</a><ul></ul></li>
<li><a href="#polymorphic-generics">2.2 Polymorphic Generics</a><ul></ul></li>
<li><a href="#reabstraction">2.3 Reabstraction</a><ul></ul></li>
<li><a href="#materialization">2.4 Materialization</a><ul></ul></li>
<li><a href="#ownership">2.5 Ownership</a><ul></ul></li>
<li><a href="#opting-out-of-resilience">2.6 Opting Out of Resilience</a><ul></ul></li>
<li><a href="#esoterica">2.7 Esoterica</a><ul></ul></li></ul></li></ul></nav>
<p>For those who don't follow Swift's development, ABI stability has been one of its most ambitious projects and possibly it's defining feature, <a href="https://swift.org/blog/abi-stability-and-more/">and it finally shipped in Swift 5</a>. The result is something I find endlessly fascinating, because I think Swift has pushed the notion of ABI stability farther than any language without much compromise.</p>
<p>So I decided to write up a bunch of the interesting high-level details of Swift's ABI. This <strong>is not</strong> a complete reference for Swift's ABI, but rather an abstract look at its implementation strategy. If you really want to know exactly how it allocates registers or mangles names, look somewhere else.</p>
<p>Also for context on why I'm writing this, I'm just naturally inclined to compare the design of Swift to Rust, because those are the two languages I have helped develop. Also some folks like to complain that Rust doesn't bother with ABI stability, and I think looking at how Swift <em>does</em> helps elucidate why that is.</p>
<p>This article is broken up into two sections: background and details. Feel free to skip to the details if you're very comfortable with the problems inherent to producing a robust dynamically linked system interface.</p>
<p>If you aren't comfortable with the basic concepts of type layouts, ABIs, and calling conventions, I recommend reading the article I wrote on <a href="https://gankra.github.io/blah/rust-layouts-and-abis/">the basic concepts of type layout and ABI as they pertain to Rust</a>.</p>
<p>Also huge thanks to the Swift devs for answering all of the questions I had and correcting my misunderstandings!</p>

<p>I know a lot of people don't really follow Swift, and it can be hard to understand what they've really accomplished without some context of what the language is like, so here's a TL;DR of the language's shape:</p>
<ul>
<li>Exists to replace Objective-C on Apple's platforms, oriented at application development
<ul>
<li>natively interoperates with Objective-C</li>
<li>has actual classes and inheritance</li>
</ul>
</li>
<li>At a distance, very similar to Rust (but "higher-level")
<ul>
<li>interfaces, generics, closures, enums with payloads, unsafe escape hatch</li>
<li>no lifetimes; Automatic Reference Counting (ARC) used for complex cases</li>
<li>simple function-scoped mutable borrows (inout)</li>
<li>Ahead-Of-Time (AOT) compiled</li>
</ul>
</li>
<li>An emphasis on "value semantics"
<ul>
<li>structs/primitives ("values") are "mutable xor shared", stored inline</li>
<li>collections implement value semantics by being Copy-On-Write (CoW) (using ARC)</li>
<li>classes are mutably shared and boxed (using ARC), undermining value semantics (can even cause data races)</li>
</ul>
</li>
<li>An emphasis on things Just Working
<ul>
<li>language may freely allocate to make things Work</li>
<li>generic code may be polymorphically compiled</li>
<li>fields may secretly be getter-setter pairs</li>
<li>ARC and CoW can easily result in surprising performance cliffs</li>
<li>tons of overloading and syntactic sugar</li>
</ul>
</li>
</ul>
<p>Don't worry about fully understanding all of these, we'll dig into the really important ones and their implications as we go on.</p>
<h2 id="what-is-abi-stability-and-dynamic-linking"><a href="#what-is-abi-stability-and-dynamic-linking">1.2 What Is ABI Stability and Dynamic Linking</a></h2>
<p>When the Swift developers talk about "ABI Stability" they have exactly one thing in mind: they want native system APIs for MacOS and iOS to be written in Swift, and for you to dynamically link to them. This includes dynamically linking to a single system-wide copy of the Swift Standard Library.</p>
<p>Ok so what's dynamic linking? For our purposes it's a system where you can compile an application against some abstract <em>description</em> of an interface without providing an actual implementation of it. This produces an application that on its own will not work properly, as part of its implementation is missing.</p>
<p>To run properly, it must tell the system's <em>dynamic linker</em> about all of the interfaces it needs implementations for, which we call <em>dynamic libraries</em> (dylibs). Assuming everything goes right, those implementations get hooked up to the application and everything Just Works.</p>
<p>Dynamic linking is very important to system APIs because it's what allows the system's implementation to be updated without also rebuilding all the applications that run on it. The applications don't care about what implementation they get, as long as it conforms to the interface they were built against.</p>
<p>It can also significantly reduce a system's memory footprint by making every application share the same implementation of a library (Apple cares about this a lot on its mobile devices).</p>
<p>Since Swift is AOT compiled, the application and the dylib both have to make a bunch of assumptions on how to communicate with the other side long before they're linked together. These assumptions are what we call ABI (an Application's <em>Binary</em> Interface), and since it needs to be consistent over a long period of time, that ABI better be stable.</p>
<p>So dynamic linking is our goal, and ABI stability is just a means to that end.</p>
<p>For our purposes, an ABI can be regarded as 3 things:</p>
<ol>
<li><a href="https://gankra.github.io/blah/rust-layouts-and-abis/#layout">The layout of types</a></li>
<li><a href="https://gankra.github.io/blah/rust-layouts-and-abis/#calling-conventions">The calling convention of functions</a></li>
<li><a href="https://en.wikipedia.org/wiki/Name_mangling">The names of symbols</a></li>
</ol>
<p>If you can define these details and never break them, you have a stable ABI, and dynamic linking can be performed. (Ignoring trivial cases where both the dylib and application were built together and ABI stability is irrelevant.)</p>
<p>Now to be clear, ABI stability isn't technically a property of a programming language. It's really a property of a system and its toolchain. To understand this, let's look at history's greatest champion of ABI stability and dynamic linking: C.</p>
<p>All the major OSes make use of C for their dynamically linked system APIs. From this we can conclude that C "has" a stable ABI. But here's the catch: if you compile some C code for dynamic linking on Ubuntu, that compiled artifact won't work on MacOS or Windows. Heck, even if you compile it for 64-bit Windows it won't work on 32-bit Windows!</p>
<p>Why? Because ABI is something defined by the <em>platform</em>. It's not even something that necessarily needs to be documented. The platform vendor can just require you to use a particular compiler toolchain that happens to implement their stable ABI.</p>
<p>(As it turns out, this is actually the reality of Swift's Stabilized ABIs on Apple platforms. They're not actually properly documented, xcode just implements it and the devs will do their best not to break it. They're not opposed to documenting it, it's just a lot of work and shipping was understandably higher-priority. Thankfully I don't really care about the details, or the difference between the ABIs on MacOS and iOS, or implementations other than Apple's, so I can keep saying "Swift's ABI" and it won't be a problem.)</p>
<p>But if that's the case, why don't platform vendors provide stable ABIs for lots of other languages? Well it turns out that the language isn't completely irrelevant here. Although ABI isn't "part" of C itself, it <em>is</em> relatively friendly to the concept. Many other languages aren't.</p>
<p>To understand why C is friendly to ABI stability, let's look at its much less friendly big brother, C++.</p>
<p>Templated C++ functions cannot have their implementations dynamically linked. If I provide you with a system header that provides the following declaration, you simply can't use it:</p>
<pre><code>template &lt;typename T&gt;
bool process(T value);
</code></pre>
<p>This is because <em>it has no symbol</em>. C++ templates are monomorphically compiled, which is a fancy way of saying that the way to use them is to copy-paste the implementation with all the templates replaced with a particular value.</p>
<p>So if I want to call <code>process&lt;int&gt;(0)</code>, I need to have the implementation available to copy-paste it with <code>int</code> replacing <code>T</code>. Needing to have the implementation available at compile-time completely undermines the concept of dynamic linking.</p>
<p>Now perhaps the platform could make a promise that it has precompiled several monomorphic instances, so say symbols for <code>process&lt;int&gt;</code> and <code>process&lt;bool&gt;</code> are available. You could make that work, but then the function wouldn't really be meaningfully templated anymore, as only those two explicitly blessed substitutions would be valid.</p>
<p>There would be little difference from simply providing a header containing:</p>
<pre><code>bool process(int value);
bool process(bool value);
</code></pre>
<p>Now a header <em>could</em> just include the template's implementation, but what that would really be guaranteeing is that that particular implementation will <em>always</em> be valid. Future versions of the header could introduce new implementations, but a robust system would have to assume applications could using either, or perhaps even both at the same time.</p>
<p>This is no different from a C macro or <code>inline</code> function, but I think it's fair to say that templates are a little more important in C++.</p>
<p>For comparison, most platforms provide a dynamically linked version of the C standard library, and everyone uses it. On the other hand, C++'s standard library isn't very useful to dynamically link to; it's literally called the Standard <em>Template</em> Library!</p>
<p>In spite of this issue (and many others), C++ <em>can</em> be dynamically linked and used in an ABI-stable way! It's just that it ends up looking a lot more like a C interface due to the limitations.</p>
<p>Idiomatic Rust is similarly hostile to dynamic linking (it also uses monomorphization), and so an ABI-stable Rust would also end up only really supporting C-like interfaces. Rust has largely just embraced that fact, focusing its attention on other concerns.</p>

<p>I have now made some seemingly contradictory claims:</p>
<ul>
<li>Swift has similar features to Rust</li>
<li>Rust's features make it hostile to dynamic linking</li>
<li>Swift is great at dynamic linking</li>
</ul>
<p>The secret lies in where the two languages diverge: dynamism. Rust is a <em>very</em> static and explicit language, reflecting the sensibilities of its developers and early adopters. Swift's developers preferred a much more dynamic and implicit design, and so that's what they made.</p>
<p>As it turns out, hiding implementation details and doing more work at runtime is <em>really</em> friendly to dynamic linking. Who'd've ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gankra.github.io/blah/swift-abi/">https://gankra.github.io/blah/swift-abi/</a></em></p>]]>
            </description>
            <link>https://gankra.github.io/blah/swift-abi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26205969</guid>
            <pubDate>Sat, 20 Feb 2021 17:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26205418">thread link</a>) | @lukastyrychtr
<br/>
February 20, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we‚Äôll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We‚Äôll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a ‚Äúsmart machine-code buffer‚Äù that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is ‚Äústraight-line‚Äù code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift‚Äôs CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG‚Äôs end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it‚Äôs
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it‚Äôs usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn‚Äôt much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we‚Äôll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we‚Äôve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or ‚Äúlabel use‚Äù in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ¬±1 MB range,
and unconditional branches have a ¬±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ¬±128 byte range) or four-byte offset (allowing a ¬±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
‚Äúfixpoint problem‚Äù, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I‚Äôll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26205418</guid>
            <pubDate>Sat, 20 Feb 2021 16:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My history with Forth and stack machines (2010)]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26203518">thread link</a>) | @panic
<br/>
February 20, 2021 | https://yosefk.com/blog/my-history-with-forth-stack-machines.html | <a href="https://web.archive.org/web/*/https://yosefk.com/blog/my-history-with-forth-stack-machines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em><span><span><span><span><span><span>My VLSI tools take a chip from conception through testing. Perhaps 500 lines of source code. Cadence, Mentor Graphics do the same, more or less. With how much source/object code?</span></span></span></span></span></span></em></p>
<p><em>‚Äì <a href="http://www.colorforth.com/1percent.html">Chuck Moore</a>, the inventor of Forth</em></p>
<p>This is a personal account of my experience implementing and using the Forth programming language and the stack machine architecture. "Implementing and using" ‚Äì in that order, pretty much; a somewhat typical order, as will become apparent.</p>
<p>It will also become clear why, having defined the instruction set of a processor designed to run Forth that went into production, I don't consider myself a competent Forth programmer (now is the time to warn that my understanding of Forth is just that ‚Äì my own understanding; wouldn't count on it too much.)</p>
<p>Why the epigraph about Chuck Moore's VLSI tools? Because Forth is very radical. Black Square kind of radical. An approach to programming seemingly leaving out most if not all of programming:</p>
<blockquote><p>‚Ä¶Forth does it differently. There is no syntax, no redundancy, no typing. There are no errors that can be detected. ‚Ä¶there are no parentheses. No indentation. No hooks, no compatibility. ‚Ä¶No files. No operating system.</p></blockquote>
<p><img src="http://yosefk.com/img/n/black-square.jpg" alt="Black Square by Kazimir Malevich" width="220" height="218"></p>
<p>I've never been a huge fan of suprematism or modernism in general. However, a particular modernist can easily get my attention if he's a genius in a traditional sense, with superpowers. Say, he memorizes note sheets upon the first brief glance like Shostakovich did.</p>
<p>Now, I've seen chip design tools by the likes of Cadence and Mentor Graphics. Astronomically costly licenses. Geological run times. And nobody quite knows what they do. To me, VLSI tools in 500 lines qualify as a superpower, enough to grab my attention.</p>
<p>So, here goes.</p>
<p>***</p>
<p>I was intrigued with Forth ever since I read about it in Bruce Eckel's book on C++, a 198-something edition; he said there that "extensibility got a bad reputation due to languages like Forth, where a programmer could change everything and effectively create a programming language of his own". WANT!</p>
<p>A couple of years later, I looked for info on the net, which seemed somewhat scarce. An unusually looking language. Parameters and results passed implicitly on a stack. 2 3 + instead of 2+3. Case-insensitive. Nothing about the extensibility business though.</p>
<p>I thought of nothing better than to dive into the source of an implementation, <a title="Portable Forth in 'C'. Why do Forth programmers put C in quotes?" href="http://www.softsynth.com/pforth/">pForth</a> ‚Äì and I didn't need anything better, as my mind was immediately blown away by the following passage right at the top of <a href="http://pforth.googlecode.com/svn/trunk/fth/system.fth">system.fth</a>, the part of pForth implemented in Forth on top of the C interpreter:</p>
<blockquote>
<pre>: (   41 word drop ; immediate
( That was the definition for the comment word. )
( Now we can add comments to what we are doing! )</pre>
</blockquote>
<p>Now. we. can. add. comments. to. what. we. are. doing.</p>
<p>What this does is define a word (Forth's name for a function) called "(". "(" is executed at compile time (as directed by IMMEDIATE). It tells the compiler to read bytes from the source file (that's what the word called, um, WORD is doing), until a ")" ‚Äì ASCII 41 ‚Äì is found. Those bytes are then ignored (the pointer to them is removed from the stack with DROP). So effectively, everything inside "( ‚Ä¶ )" becomes a comment.</p>
<p><em>Wow.</em> Yeah, you definitely can't do that in C++. (You <a href="http://www.lispworks.com/documentation/lw51/CLHS/Body/f_set_ma.htm#set-macro-character">can</a> in Lisp but they don't teach you those parts at school. They teach the pure functional parts, where you <em>can't</em> do things that you <em>can</em> in C++. Bastards.)</p>
<p>Read some more and‚Ä¶</p>
<blockquote>
<pre><em> conditional primitives</em>
: IF     <em>( -- f orig )</em>  ?comp compile 0branch  conditional_key &gt;mark     ; immediate
: THEN   <em>( f orig -- )</em>  swap ?condition  &gt;resolve   ; immediate
: BEGIN  <em>( -- f dest )</em>  ?comp conditional_key &lt;mark   ; immediate
: AGAIN  <em>( f dest -- )</em>  compile branch  swap ?condition  &lt;resolve  ; immediate
: UNTIL  <em>( f dest -- )</em>  compile 0branch swap ?condition  &lt;resolve  ; immediate
: AHEAD  <em>( -- f orig )</em>  compile branch   conditional_key &gt;mark     ; immediate</pre>
</blockquote>
<p>Conditional <em>primitives</em>?! Looks like conditional primitives aren't ‚Äì they <em>define</em> them here. This COMPILE BRANCH business modifies the code of a function that uses IF or THEN, at compile time. THEN ‚Äì one part of the conditional ‚Äì writes (RESOLVEs) a branch offset to a point in code saved (MARKed) by IF, the other part of the conditional.</p>
<p>It's as if a conventional program modified the assembly instructions generated from it at compile time. What? How? Who? How do I wrap my mind around this?</p>
<p>Shocked, I read the source of pForth.</p>
<p>Sort of understood how Forth code was represented and interpreted. Code is this array of "execution tokens" ‚Äì function pointers, numbers and a few built-ins like branches, basically. A Forth interpreter keeps an instruction pointer into this array (ip), a data stack (ds), and a return stack (rs), and does this:</p>
<pre><strong>while</strong>(<strong>true</strong>) {
 <strong>switch</strong>(*ip) {
  <em>//arithmetics (+,-,*...):</em>
  <strong>case </strong>PLUS: ds.push(ds.pop() + ds.pop()); ++ip;
  <em>//stack manipulation (drop,swap,rot...):</em>
  <strong>case </strong>DROP: ds.pop(); ++ip;
  <em>//literal numbers (1,2,3...):</em>
  <strong>case </strong>LITERAL: ds.push(ip[1]); ip+=2;
  <em>//control flow:</em>
 &nbsp;<strong>case </strong>COND_BRANCH: <strong>if</strong>(!ds.pop()) ip+=ip[1]; <strong>else </strong>ip+=2;
 &nbsp;<strong>case </strong>RETURN: ip = rs.pop();
  <em>//user-defined words: save return address &amp; jump</em>
 &nbsp;<strong>default</strong>: rs.push(ip+1); ip = *ip;
 }
}</pre>
<p>That's it, pretty much. Similar, say, to the virtual stack machine used to implement Java. One difference is that compiling a Forth program is basically writing to the code array in a WYSIWYG fashion. COMPILE SOMETHING simply appends the address of the word SOMETHING to the end of the code array. So does plain SOMETHING when Forth is compiling rather than interpreting, as it is between a colon and a semicolon, that is, when a word is defined.</p>
<p>So</p>
<pre>: DRAW-RECTANGLE 2DUP UP RIGHT DOWN LEFT ;</pre>
<p>simply appends {&amp;2dup,&amp;up,&amp;right,&amp;down,&amp;left,RETURN} to the code array. Very straightforward. There are no parameters or declaration/expression syntax as in‚Ä¶</p>
<pre><strong>void </strong>drawRectangle(<strong>int </strong>width, <strong>int </strong>height) {
  up(height);
  right(width);
  down(height);
  left(width);
}</pre>
<p>‚Ä¶to make it less than absolutely clear how the source code maps to executable code. "C maps straightforwardly to assembly"? Ha! <em>Forth</em> maps straightforwardly to assembly. Well, to the assembly language of a virtual stack machine, but still. So one can understand how self-modifying code like IF and THEN works.</p>
<p>On the other hand, compared to drawRectangle, it is somewhat unclear what DRAW-RECTANGLE <em>does</em>. What are those 2 values on the top of the stack that 2DUP duplicates before meaningful English names appear in DRAW-RECTANGLE's definition? This is supposed to be ameliorated by stack comments:</p>
<pre>: DRAW-RECTANGLE <em>( width height -- )</em> ... ;</pre>
<p>‚Ä¶tells us that DRAW-RECTANGLE expects to find height at the top of the stack, and width right below it.</p>
<p>I went on to sort of understand CREATE/DOES&gt; ‚Äì a further extension of this compile-time self-modifying code business that you use to "define defining words" (say, CONSTANT, VARIABLE, or CLASS). The CREATE part says what should be done when words (say, class names) are defined by your new defining word. The DOES&gt; part says what should be done when those words are used. For example:</p>
<pre>: CONSTANT
  &nbsp;CREATE ,
  &nbsp;DOES&gt; @
;
<em>\ usage example:</em>
7 CONSTANT DAYS-IN-WEEK
DAYS-IN-WEEK 2 + . <em>\ should print 9</em></pre>
<p>CREATE means that every time CONSTANT is called, a name is read from the source file (similarly to what WORD would have done). Then a new word is created with that name (as a colon would have done). This word records the value of HERE ‚Äì something like sbrk(0), a pointer past the last allocated data item. When the word is executed, it pushes the saved address onto the data stack, then calls the code after DOES&gt;. The code after CREATE can put some data after HERE, making it available later to the DOES&gt; part.</p>
<p>With CONSTANT, the CREATE part just saves its input (in our example, 7) ‚Äì the comma word does this: *HERE++ = ds.pop(); The DOES&gt; part then fetches the saved number ‚Äì the @ sign is the fetch word: ds.push( *ds.pop() );</p>
<p>CONSTANT works somewhat similarly to a class, CREATE defining its constructor and DOES&gt; its single method:</p>
<pre>class Constant
  def initialize(x) @x=x end
  def does() @x end
end
daysInWeek = Constant.new(7)
print daysInWeek.does() + 2</pre>
<p>‚Ä¶But it's much more compact on all levels.</p>
<p>Another example is defining C-like structs. Stripped down to their bare essentials (and in Forth things tend to be stripped down to their bare essentials), you can say that:</p>
<pre><strong>struct </strong>Rectangle {
  <strong>int </strong>width;
  <strong>int </strong>height;
};</pre>
<p>‚Ä¶simply gives 8 (the structure size) a new name Rectangle, and gives 0 and 4 (the members' offsets) new names, width and height. Here's <a href="http://wiki.laptop.org/go/Forth_Lesson_18">one way to implement structs in Forth</a>:</p>
<pre>struct
  cell field width
  cell field height
constant rectangle

<em>\ usage example:</em>
<em>\ here CREATE is used just for allocation</em>
create r1 rectangle allot <em>\ r1=HERE; HERE+=8</em>
2 r1 width !
3 r1 height !
: area dup width @ swap height @ * ;
r1 area . <em>\ should print 6</em></pre>
<p>CELL is the size of a word; we could say "4 field width" instead of "cell field width" on 32b machines. Here's the definition of FIELD:</p>
<pre>&nbsp;: field <em>( struct-size field-size -- new-struct-size )</em>
    create over , +
    does&gt; @ +
&nbsp;;</pre>
<p>Again, pretty compact. The CREATE part stores the offset, a.k.a current struct size (OVER does ds.push(ds[1]), comma does *HERE++=ds.pop()), then adds the field size to the struct size, updating it for the next call to FIELD. The DOES&gt; part fetches the offset, and adds it to the top of the stack, supposedly containing the object base pointer, so that "rect width" or "rect height" compute &amp;rect.width or &amp;rect.height, respectively. Then you can access this address with @ or ! (fetch/store). STRUCT simply pushes 0 to the top of the data stack (initial size value), and at the end, CONSTANT consumes the struct size:</p>
<pre>struct <em>\ data stack: 0</em>
  cell <em>( ds: 0 4 )</em> field width  <em>( ds: 4 )</em>
  cell <em>( ds: 4 4 )</em> field height <em>( ds: 8 )</em>
constant rectangle <em>( ds: as before STRUCT )</em></pre>
<p>You can further extend this to support polymorphic methods ‚Äì METHOD would work similarly to FIELD, fetching a function pointer ("execution token") through a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yosefk.com/blog/my-history-with-forth-stack-machines.html">https://yosefk.com/blog/my-history-with-forth-stack-machines.html</a></em></p>]]>
            </description>
            <link>https://yosefk.com/blog/my-history-with-forth-stack-machines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26203518</guid>
            <pubDate>Sat, 20 Feb 2021 12:02:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw an iceberg and see how it would float in water]]>
            </title>
            <description>
<![CDATA[
Score 1514 | Comments 161 (<a href="https://news.ycombinator.com/item?id=26201160">thread link</a>) | @raldi
<br/>
February 19, 2021 | https://joshdata.me/iceberger.html | <a href="https://web.archive.org/web/*/https://joshdata.me/iceberger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://joshdata.me/iceberger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201160</guid>
            <pubDate>Sat, 20 Feb 2021 03:16:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Life in E-Ink]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 152 (<a href="https://news.ycombinator.com/item?id=26200630">thread link</a>) | @HaoZeke
<br/>
February 19, 2021 | https://rgoswami.me/posts/my-life-in-eink/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/my-life-in-eink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Collection of odds and ends relating to e-readers including personal reminisces</p></blockquote><h2 id="background">Background</h2><p>Reading has been a huge part of my life. The written word has had arguably more of an impact on my life than anything I have experienced in person. As a kid back in early 2000‚Äôs; this meant a lot of library trips and saving for paperbacks. I also caught the first wave of the e-ink revolution. Nothing beats a real book, in terms of textures and scents; but e-ink devices and the fantastic tools outlined here should make reading digital books much more palpable&nbsp;<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><p>I have been reading on my <a href="https://en.wikipedia.org/wiki/Kobo%5FAura%5FHD">Kobo Aura HD</a> for almost a decade now, ever since its release. This means my setup is about as stable as its going to get in the near future. As good a time as any to collect my thoughts&nbsp;<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The focus is on e-ink devices and auxiliary tools; not on all digital content; so there are no mentions of syncing or reading on the go (with a phone) or of monitors which are good for reading on.</p><h3 id="the-content">The Content</h3><p>In general; my e-ink reading habits can be broadly broken into the following categories:</p><dl><dt>Light Reading</dt><dd>Practically this includes <a href="https://www.goodreads.com/user/show/33462912-rohit-goswami">anything I review on Goodreads</a>; these are not often re-read; nor read very deeply; since they are read for pleasure. They are however, rarely deleted</dd><dt>Required Reading</dt><dd>Anything which typically requires me to take notes or practice / write out proofs; these are most often considered to be either coursework (for someone somewhere) or research monographs. These are typically large (in size) and unwieldy (in that they often lack TOCs) and are read multiple times; with a focus on highlights and notes</dd><dt>Active Research</dt><dd>These are the most ephemeral of my reading habits; and also the most numerous; I do not typically store these on my e-reader; and rarely need to make notes on the reader&nbsp;<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. These are often tiny; but require special work due to the metadata involved</dd></dl><table><thead><tr><th>Content Type</th><th>Software Stack</th><th>Deletion Rate</th></tr></thead><tbody><tr><td>Light Reading</td><td>Calibre</td><td>Rare</td></tr><tr><td>Required Reading</td><td>Calibre</td><td>Never</td></tr><tr><td>Active Research</td><td>Calibre + Zotero</td><td>Frequent</td></tr></tbody></table><p>Though I am a huge proponent of RSS feeds (with <a href="https://gitlab.com/news-flash/news%5Fflash%5Fgtk">Newsflash</a>) and read online content voraciously with both a <a href="https://app.getpocket.com/">Pocket</a> and <a href="https://www.diigo.com/user/rgoswami">Diigo</a> subscription<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>; I sincerely do not believe blog stuff or anything tailored for the web should have a presence on an e-ink device; so there shall be no mention of those parts of my reading habits<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><h2 id="hardware">Hardware</h2><p>My primary e-reader is still my <a href="https://www.kobo.com/koboaurahd?%5F%5F%5Fstore=au&amp;style=onestore">Kobo Aura HD</a> (complete with a snazzy <a href="https://www.amazon.com/Cover-Up-eReader-Natural-Cover-Function/dp/B00DZJ5VM0">hemp sleep-cover</a>), and has been my go to for almost a decade now since its release. Recently I have augmented my workflow with the <a href="https://remarkable.com/store/remarkable-2">reMarkable 2</a>; though I have yet to break it in very well; mostly because I tend to gravitate towards typing out my thoughts&nbsp;<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> instead of writing.</p><p>The Kobo Aura HD is still the pinnacle of reading technology to me; mostly because the firmware is easy to bypass; and there is a vibrant community of developers on the <a href="https://www.mobileread.com/forums/showthread.php?t=210800">MobileRead Forums</a>. Display and spec aside; the biggest reason for never replacing it has been been the simple fact that most modern e-readers no longer support SD cards; and much of my workflow depends on storing insane amounts of material offline&nbsp;<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/d393a91160884052b7717a31a565283336a03ccf/eb437/ox-hugo/2021-02-20_01-39-20_screenshot.png" alt="Figure 1: Primary reading device with Koreader"><figcaption><p>Figure 1: Primary reading device with Koreader</p></figcaption></figure><p>Personally, I never use Nickel (the default Kobo interface), and it would probably choke trying to scan my 200 GB of content; so I haven‚Äôt updated the firmware in forever. My interactions are almost always in <a href="https://koreader.rocks/">Koreader</a>; and my launching poison of choice is the now no longer developed <a href="https://www.mobileread.com/forums/showthread.php?t=293804">Kobo start menu</a>&nbsp;<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>.</p><h2 id="software">Software</h2><p>Broadly speaking; the main parts of the software pipeline from digital book to brain are simply the syncing mechanism and the UI/UX/OS of the device in question; though it is often best to consider pre-processing books for devices too. These are covered in the order used.</p><h3 id="k2pdfopt">k2pdfopt</h3><p>The thought of reflowing text for an optimal reading experience, especially given the slightly limited processing power of my primary reading device is an enticing prospect. <a href="https://www.willus.com/k2pdfopt/">K2pdfopt or the Kindle 2 PDF Optimizer</a> is as criminally underrated as it is fantastic. An approach which works well for my device involves setting up <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/docK2pdf">a simple shell script</a> (part <a href="https://github.com/HaoZeke/Dotfiles">of my Dotfiles</a>) for optimizing files on the fly before sending them through <code>calibre</code>.</p><div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Get a filename</span>
<span>case</span> <span>"</span><span>$#</span><span>"</span> in
0<span>)</span>
      <span>echo</span> <span>"No arguments, so enter the filename, WITH the extension"</span>
      <span>read</span> -p <span>'Document: '</span> docfile
      <span>;;</span>
1<span>)</span>
      <span>echo</span> <span>"OK, using the filename"</span>
      <span>docfile</span><span>=</span><span>"</span><span>$1</span><span>"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal number of parameters"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
<span># Get basename</span>
<span>basename</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>%.*</span><span>}</span><span>"</span>
<span>ext</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>##*</span><span>\.</span><span>}</span><span>"</span>
<span>echo</span> <span>"Basename </span><span>${</span><span>basename</span><span>}</span><span> with </span><span>$ext</span><span> from </span><span>$docfile</span><span>"</span>
<span>echo</span> <span>"Making a local store for the outputs"</span>
mkdir -p <span>"</span><span>$HOME</span><span>/auraHDopt"</span>

<span>case</span> <span>"</span><span>$ext</span><span>"</span> in
<span>"djvu"</span><span>)</span>
      <span>echo</span> <span>"Converting djvu to pdf via ps and running k2pdfopt"</span>
      djvups <span>"</span><span>${</span><span>basename</span><span>}</span><span>.djvu"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span>
      ps2pdf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span># The newline is for simulating the Enter key</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      rm -rf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.{ps,pdf}"</span>
      <span>;;</span>
<span>"pdf"</span><span>)</span>
      <span>echo</span> <span>"Converting pdf with gs and running k2pdfopt"</span>
      gs -sDEVICE<span>=</span>pdfwrite -dCompatibilityLevel<span>=</span>1.4 -dPDFSETTINGS<span>=</span>/screen <span>\
</span><span></span>              -dNOPAUSE -dQUIET -dBATCH -sOutputFile<span>=</span><span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      rm <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -rf
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal file type"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
</code></pre></div><p>The outputs can also be further processed with an <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/isOcr">OCR (Optical Character Recognition) script</a> if required, and then edited in <a href="https://code-industry.net/masterpdfeditor/">Master PDF Editor</a> or something similar to add the table of contents interactively as well.</p><div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span><span># Use as  find . -type f -name "*.pdf" -exec isOcr '{}' \;</span>

<span># Shamelessly kanged from here:</span>
<span># https://stackoverflow.com/questions/7997399/bash-script-to-check-pdfs-are-ocrd</span>
<span># Only searches for text on the first 5 pages</span>
<span># Modified to have red text. Also to possibly ocr the thing.</span>

<span># -*- mode: shell-script-mode -*-</span>

<span>MYFONTS</span><span>=</span><span>$(</span>pdffonts -l <span>15</span> <span>"</span><span>$1</span><span>"</span> <span>|</span> tail -n +3 <span>|</span> cut -d<span>' '</span> -f1 <span>|</span> sort <span>|</span> uniq<span>)</span>
<span>if</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>''</span> <span>]</span> <span>||</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>'[none]'</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"</span><span>$(</span>tput setaf 1<span>)</span><span>NOT OCR'ed: </span><span>$1</span><span>"</span>
    <span>if</span> <span>[[</span> -x <span>"</span><span>$(</span>which ocrmypdf<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
        <span>echo</span> <span>"Converting to </span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf with ocrmypdf"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 7<span>)</span><span>"</span>
        ocrmypdf --deskew --clean --rotate-pages <span>\
</span><span></span>            --jobs <span>4</span> -v --output-type pdfa <span>"</span><span>$1</span><span>"</span> <span>"</span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf"</span>
    <span>elif</span> <span>[[</span> -x <span>"</span><span>$(</span>which pypdfocr<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> Looking for config files at </span><span>$XDG_CONFIG_HOME</span><span>/pypdfocr/config.yml"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 3<span>)</span><span>"</span>
        <span>if</span> <span>[[</span> -e <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>]]</span><span>;</span> <span>then</span>
            <span>echo</span> <span>"Using configuration settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr -c <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>"</span><span>$1</span><span>"</span>
        <span>else</span>
            <span>echo</span> <span>"Using default settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr <span>"</span><span>$1</span><span>"</span>
        <span>fi</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> You might want to get pypdfocr"</span>
    <span>fi</span>
<span>else</span>
    <span>echo</span> <span>"</span><span>$1</span><span> is OCR'ed."</span>
<span>fi</span>
</code></pre></div><p>The end result is:</p><ul><li>A directory with perfectly <code>pdf</code> files re-flowed text<ul><li>Possibly OCR‚Äôed for string searches</li></ul></li></ul><p>TOC editing is still rather janky; but this is also because the OCR process is still rather spotty.</p><h3 id="calibre">Calibre</h3><p><a href="https://calibre-ebook.com/">Calibre</a> is an excellent library software, and there are very few alternatives which offer all the salient features:</p><dl><dt>Syncing</dt><dd>Apart from working well with a plethora of official devices, Koreader is also pretty well supported, and mounting folders allows for easy management of a secret library (e.g. <code>.Library</code>) on an SD card to prevent Nickel from reading and choking on large libraries</dd><dt>Multiple Libraries</dt><dd>I personally keep one for fiction, one for non-fiction, and one (transiently populated) one for papers</dd><dt>Good metadata collection</dt><dd>Nothing beats rich metadata, and with third party plugins, all the best content providers can be leveraged for blurbs; plus most purchased books come with metadata which <code>calibre</code> can read</dd></dl><p>It isn‚Äôt perfect, there are far better <a href="https://opds.io/">OPDS (Open Publication Distribution System)</a> servers like the fantastic <a href="https://github.com/seblucas/cops">COPS (Calibre OPDS)</a> project, and there have been <a href="https://anarc.at/software/desktop/calibre/">some security concerns in the past</a>, but it is really usable and is <a href="https://github.com/kovidgoyal/calibre">under active development</a>; plus it has a <a href="https://kovidgoyal.net/">fun developer</a>. I also personally find the file conversion lacking, compared to <code>k2pdfopt</code>, but as a library management system it is really good.</p><h3 id="zotero-sync">Zotero Sync</h3><p>Calibre provides a handy <a href="https://www.mobileread.com/forums/showthread.php?p=3339191#poststop">ZMI (Zotero Metadata Importer) plugin</a> which allows for exported papers to be imported into <code>calibre</code> and from then into the e-reader as expected. Combined with the folder mounts facilitated by <code>calibre</code> this allows for a painless way to ensure a quick export; optimize; sync; read and delete workflow.</p><h3 id="koreader">Koreader</h3><p>Koreader is probably the best thing to happen to e-ink devices since sliced bread. It replaces the need to use any cables with an e-reader; since newer versions have a nice SSH server, and can also update itself. Since this is mostly used as is; and all the information required is on the <a href="https://github.com/koreader/koreader/wiki">Github Wiki</a>, there‚Äôs not much else to say here.</p><p>It is probably worth noting that the in-built re-flow options do tend to cause major artifacts on older hardware, and is best avoided. Almost equivalently, and at a far lower cost in terms of performance, page contents can be fit to width and zoomed in automatically, which is almost as good as working with <code>k2pdfopt</code> in some special cases.</p><h2 id="conclusions">Conclusions</h2><p>Given my unfortunate separation from my library back home; it is likely that my e-ink devices will continue to be my primary source of reading material. Plus the long retarded color e-ink market finally seems to be moving out of its stupor&nbsp;<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>. The only possible addendum to this methodology would probably involve integrating <code>orgmode</code> and the reMarkable 2 sometime. E-ink is here to stay. This setup would probably need revisions involving <code>rclone</code> or <code>syncthing</code> if I ever gave ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rgoswami.me/posts/my-life-in-eink/">https://rgoswami.me/posts/my-life-in-eink/</a></em></p>]]>
            </description>
            <link>https://rgoswami.me/posts/my-life-in-eink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26200630</guid>
            <pubDate>Sat, 20 Feb 2021 01:46:53 GMT</pubDate>
        </item>
    </channel>
</rss>
