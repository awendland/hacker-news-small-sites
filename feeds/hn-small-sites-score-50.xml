<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 26 Nov 2020 16:40:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 26 Nov 2020 16:40:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I‚Äôm not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019‚Äì2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system‚Äôs internals very excited like we saw with Zen 3‚Äôs launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been ‚Äúperfectly fine‚Äù for the last decade. We‚Äôve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call ‚Äúrevolutionary‚Äù.</p>
<p>Before we proceed, it‚Äôs essential to set the context that I‚Äôve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a ‚ÄúPC/Android Guy‚Äù, I have to admit what I saw this week is something special. I believe it‚Äôll go down as a significant milestone in computing history on par with some industry-defining chips like Intel‚Äôs 8086, 386, 486, Pentium, Conroe or AMD‚Äôs K8, Zen, etc. I hope for the return of Moore‚Äôs law and awakening of the x86 manufacturers from their slumber as this will be the ‚Äú<em>slowest</em>‚Äù CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year‚Äôs Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year‚Äôs Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft‚Äôs struggles in emulating x86 Windows apps on ARM CPUs. Apple‚Äôs answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That‚Äôs what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That‚Äôs on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they‚Äôre not currently, and so on, x86_64 performance should be very very decent. I‚Äôm going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it‚Äôs all said and done, it doesn‚Äôt take much working backwards to figure where they‚Äôd need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple‚Äôs new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who‚Äôs spending their money on them. There have been plenty of real-world experiences that I‚Äôve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards üëè</p>‚Äî DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens ‚Äî even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. üëç</p></div>‚Äî JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>‚Äî Blake Scholl üõ´ (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don‚Äôt get near one! I have the 12.9‚Äù iPad Pro, new Max iPhone, older 13‚ÄùMBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it‚Äôs eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn‚Äôt even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It‚Äôs honestly the best purchase I‚Äôve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I‚Äôm holding a magical device that shouldn‚Äôt exist. Haven‚Äôt felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15‚Äù MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it‚Äôs been painful to say the least. It‚Äôs quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I‚Äôve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor‚Äôs resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I‚Äôm impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I‚Äôve ever owned. First computer that hasn‚Äôt had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I‚Äôm mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June‚Ä¶ fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven‚Äôt plugged in this M1 Mac in almost 2 days. It‚Äôs only half dead. lol. What is this sorcery? üîã </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>‚Äî Computer Clan (üìåÔ£øM1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% ü§Øü§Øü§Ø</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>‚Äî William Lex Ham ‚úäüèΩüß¢ #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P¬≤ quantile estimator ‚Äì estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its ‚Äúaverage‚Äù duration.
It‚Äôs not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It‚Äôs much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it‚Äôs a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it‚Äôs usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P¬≤ quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P¬≤ quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let‚Äôs say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nÍûå</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qÍûå</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qÍûå</span> <span>&amp;&amp;</span> <span>qÍûå</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qÍûå</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qÍûå</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P¬≤) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It‚Äôs time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P¬≤ quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It‚Äôs the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it ‚ÄúType 7‚Äù according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It‚Äôs my favorite option in real life for non-sequential cases because
it‚Äôs more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P¬≤ quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I‚Äôm pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P¬≤ quantile estimator allows estimating quantile values on a stream of numbers without storing individual ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I‚Äôm now the CTO. I
could‚Äôve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I‚Äôve worked on web apps that used libraries only‚Äîno frameworks‚Äîand all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team‚Äôs composition changed, managing these decisions was a constant tax.</p>

<p>‚Ä¶managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we‚Äôd hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don‚Äôt have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn‚Äôt matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don‚Äôt matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can‚Äôt
be used for ‚Äúserious‚Äù problems.  Those of us <em>with</em> Rails experience know this isn‚Äôt true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it‚Äôs obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails‚Äîand its ecosystem‚Äîtend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it‚Äôs still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That‚Äôs why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here ‚Äì On the absence of information in today‚Äôs media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today‚Äôs press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" ‚ÄîMartin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I‚Äôm fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype ‚Äì 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it‚Äôs a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it‚Äôs free to use!</p><p>We sometimes see it as an intimidating platform, but it‚Äôs not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don‚Äôt want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas‚Äô feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let‚Äôs say you create a tool for developers then I‚Äôd post to /r/webdev. You don‚Äôt need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don‚Äôt be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you‚Äôll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you‚Äôre ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I‚Äôd go with a small subreddit, and a super targeted one. Let‚Äôs say you created a no-code tool for startups, I‚Äôll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It‚Äôs a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of ‚Äúincremental launches‚Äù is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc‚Ä¶ It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it‚Äôs totally repeatable. As long as you can provide value you‚Äôll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I‚Äôll be happy to help ‚Üí <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn‚Äôt
include any sort of CSRF token and didn‚Äôt seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a ‚Äúpoor man‚Äôs CSRF token‚Äù, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski‚Äôs <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let‚Äôs examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let‚Äôs explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker‚Äôs site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn‚Äôt supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren‚Äôt there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn‚Äôt get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you‚Äôll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>‚ÄúDon‚Äôt make me think‚Äù is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today‚Äôs article, we‚Äôd like to look into enterprise design and its peculiarities. It‚Äôs essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug‚Äôs principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren‚Äôt inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn‚Äôt necessarily true of enterprise products.</p><p>Enterprise users are power users ‚Äî and it‚Äôs imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn‚Äôt inherently wrong. It allows users to work more efficiently once they‚Äôve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software ‚Äî most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they‚Äôll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We‚Äôre very well aware of the importance of keeping interfaces simple and obvious. However, it‚Äôs essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let‚Äôs envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren‚Äôt really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but‚Ä¶</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it‚Äôs not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be‚Ä¶ well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product ‚Äî it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They‚Äôve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don‚Äôt fix it if it‚Äôs not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn‚Äôt quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, ‚Äúreinventing the wheel‚Äù isn‚Äôt always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let‚Äôs go back to Excel once more ‚Äî imagine <a href="https://adamfard.com/blog/website-redesign">you‚Äôre trying to reinvent</a> a complex, spreadsheet-based product. You‚Äôre looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is ‚Äî why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we‚Äôve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of ‚Äúdon‚Äôt make me think‚Äù will most likely outlive us, it‚Äôs crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the ‚ÄúDon‚Äôt make me think‚Äù principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies‚Ä¶ that got me thinking about what you would see if you could pass iOS under X-Rays‚Ä¶</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>‚Ä¶</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, ‚Ä¶ are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, ‚Ä¶</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, ‚Ä¶</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, ‚Ä¶</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji ü§ü, News, iWork, Wallet, Shortcuts, ARKit, ‚Ä¶</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2Ôªø<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>Ôªø could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it‚Äôs injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world‚Äôs single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>üì© Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>üéô <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you‚Äôre serious about running software under Linux/Unix, you‚Äôre certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‚Äòbadness‚Äô (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I‚Äôve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I‚Äôve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>‚ÄúInvisible‚Äù OOMKills</h2> <p>For a brief moment, I‚Äôve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn‚Äôt see any alerts for it.</p> <p>At first, I wasn‚Äôt inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn‚Äôt even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I‚Äôve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container‚Äôs init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I‚Äôve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I‚Äôve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I‚Äôve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker‚Äôs events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I‚Äôve found was where I‚Äôve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‚Äòsee‚Äô what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I‚Äôve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‚ÄòJetstream‚Äô. This router is part of Walmart‚Äôs new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>‚ÄúThank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.‚Äù</p></blockquote>
<p>CyberNews researchers also discovered that ‚ÄòWavlink‚Äô branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee‚Äôs Report</a> on ‚ÄòWavlink‚Äô routers‚Äô backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>‚Äî Auriea Harvey &amp; Micha√´l Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>‚Äî @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>‚Äî Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>‚Äî Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>‚Äî Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann‚Äôs appraisal of Chopin‚Äôs preludes, defended their proportion in an interview: ‚ÄúMaybe [Chopin] felt like they were complete objects, but there wasn‚Äôt a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me ‚Ä¶ there is a lot that‚Äôs unspoken.‚Äù Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>‚Äî Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>‚Äî Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>‚Äî Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>‚Äî thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game ‚Äì can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 245 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There‚Äôs just something fascinating about getting to know what‚Äôs under the hood of other people‚Äôs businesses. It‚Äôs like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That‚Äôs why, in the same spirit as Jake Lazaroff‚Äôs <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it‚Äôs now my turn to do a short write up of the technologies I‚Äôm using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn‚Äôt bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I‚Äôd use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let‚Äôs Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There‚Äôs plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than ‚Äútop‚Äù if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the ‚Ä¶</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. ü§î</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
    </channel>
</rss>
