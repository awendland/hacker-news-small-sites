<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 14 Jan 2021 05:09:22 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 14 Jan 2021 05:09:22 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: Symmetrical Drawing Tool for Doodling]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25741895">thread link</a>) | @cowllin
<br/>
January 11, 2021 | https://www.aliciaunderhill.xyz/Andala/ | <a href="https://web.archive.org/web/*/https://www.aliciaunderhill.xyz/Andala/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section>
        <p>
          <h5>Choose and change your settings as you draw:</h5>
        </p>
        <div>
          <p>Your brush color</p>
          <ul>
            <li id="red-brush" data-color="#FA5858"></li>
            <li id="orange-brush" data-color="#FACC2E"></li>
            <li id="yellow-brush" data-color="#F4FA58"></li>
            <li id="green-brush" data-color="#81F79F"></li>
            <li id="blue-brush" data-color="#81F7F3"></li>
            <li id="purple-brush" data-color="#DA81F5"></li>
            <li id="pink-brush" data-color="#F781F3"></li>
            <li id="black-brush" data-color="black"></li>
            <li id="white-brush" data-color="white"></li>
            <li id="gray-brush" data-color="#A4A4A4"></li>
          </ul>
        </div>

        <div>
          <p>Your background color</p>
          <ul>
            <li id="black-background" data-background="black"></li>
            <li id="white-background" data-background="white"></li>
          </ul>
        </div>

        <div>
          <p>Your brush size</p>
          <ul>
            <li data-brushsize="1">Thin</li>
            <li data-brushsize="3">Medium</li>
            <li data-brushsize="6">Thick</li>
          </ul>
        </div>

        <div>
          <p>Your desired symmetry</p>
          <ul>
            <li id="radial-symmetry" data-symmetry="RADIAL">Radial</li>
              <label>Split by
                
              </label>
            <li data-symmetry="HORIZONTAL">Horizontal</li>
            <li data-symmetry="VERTICAL">Vertical</li>
          </ul>
        </div>
      </section>

      <section>
        
        <h3>Click anywhere and draw freely.</h3>
        <canvas id="andala-canvas" width="600" height="600"></canvas>
      </section>

      <section>
        
      </section>
    </div></div>]]>
            </description>
            <link>https://www.aliciaunderhill.xyz/Andala/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25741895</guid>
            <pubDate>Tue, 12 Jan 2021 03:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Internet's Own Boy: The Story of Aaron Swartz (2014)]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25738542">thread link</a>) | @tslocum
<br/>
January 11, 2021 | https://peertube2.cpy.re/videos/watch/04af977f-4201-4697-be67-a8d8cae6fa7a | <a href="https://web.archive.org/web/*/https://peertube2.cpy.re/videos/watch/04af977f-4201-4697-be67-a8d8cae6fa7a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://peertube2.cpy.re/videos/watch/04af977f-4201-4697-be67-a8d8cae6fa7a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25738542</guid>
            <pubDate>Mon, 11 Jan 2021 22:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My ISP Is Killing My Idle SSH Sessions]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 166 (<a href="https://news.ycombinator.com/item?id=25737611">thread link</a>) | @anderstrier
<br/>
January 11, 2021 | https://anderstrier.dk/2021/01/11/my-isp-is-killing-my-idle-ssh-sessions-yours-might-be-too/ | <a href="https://web.archive.org/web/*/https://anderstrier.dk/2021/01/11/my-isp-is-killing-my-idle-ssh-sessions-yours-might-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-100">
		<!-- .entry-header -->

	
	<div>
		
<p>tl;dr: My ISP’s CGNAT session timeout is too short, meaning TCP keepalives gets dropped. Test if your own NAT, or your ISP’s CGN, violates <a href="https://tools.ietf.org/html/rfc5382">RFC5382</a>‘s REQ-5 using this tool: <a href="https://github.com/AndersTrier/NAT-TCP-test">https://github.com/AndersTrier/NAT-TCP-test</a>.</p>



<p>I have been working from home more lately, where I have SSH sessions open to the servers that I’m working on. Often when I return to my computer, or switch to a SSH session that has been sitting idle for a while, the SSH connection is either dead or frozen. If the session is not already dead, the only way to gain control over my terminal again, is to send the ‘terminate connection’ <a href="https://lonesysadmin.net/2011/11/08/ssh-escape-sequences-aka-kill-dead-ssh-sessions/">ssh escape sequence</a> <strong>&lt;enter&gt;~.</strong> after which SSH errors like this:</p>



<pre><a href="https://anderstrier.dk/cdn-cgi/l/email-protection" data-cfemail="5d3c29321d30342f2f322f2e733932292e2f3e73322f3a">[email&nbsp;protected]</a>:~$ 
client_loop: send disconnect: Broken pipe</pre>



<p>This happened one day while I was transferring a VM image in the hundreds of gigabytes from one server to another using netcat like so:</p>



<pre><a href="https://anderstrier.dk/cdn-cgi/l/email-protection" data-cfemail="8feefbe0cfe7e0fcfbbd">[email&nbsp;protected]</a>:~$ nc -l 1337 &gt; hugefile 
<a href="https://anderstrier.dk/cdn-cgi/l/email-protection" data-cfemail="dbbaafb49bb3b4a8afea">[email&nbsp;protected]</a>:~$ nc -q 1 host2 1337 &lt; hugefile</pre>



<p>This transfer would take multiple hours, and when I checked in after it should have finished, my SSH connections had died yet again. And sshd had taken netcat down with it, killing the transfer midway.</p>



<p>That’s when I decided to investigate this problem.</p>



<p>The OpenBSD and OpenSSH developers are known for their extreme focus on code quality. The chances that this problem is caused by a bug in OpenSSH are very slim. (In the same line as “It is (almost) never a compiler error.”)</p>



<p>This is probably a network problem.</p>



<p>I connected my laptop directly to my ISP’s “customer-provided equipment”: a coax modem in bridge mode. Then I ran tcpdump both on my laptop and on the server, and opened a SSH connection. After leaving it idle for about 2 1/2 hours, this is the result:</p>



<figure><img loading="lazy" width="1680" height="1206" src="https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside.png" alt="" srcset="https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside.png 1680w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside-300x215.png 300w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside-1024x735.png 1024w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside-768x551.png 768w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-clientside-1536x1103.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Client side</figcaption></figure>



<figure><img loading="lazy" width="1705" height="1224" src="https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside.png" alt="" srcset="https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside.png 1705w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside-300x215.png 300w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside-1024x735.png 1024w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside-768x551.png 768w, https://anderstrier.dk/wp-content/uploads/2020/12/ssh-session-serverside-1536x1103.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Server side</figcaption></figure>



<p>A SSH session does not generate any traffic, unless there’s new output or input. The same is true for TCP. That is why, after the TCP and SSH sessions have been established, no more packages are sent for a long time.</p>



<p>First thing to note, is that my laptop gets an IP in the <a href="https://tools.ietf.org/html/rfc6598" data-type="URL" data-id="https://tools.ietf.org/html/rfc6598">Carrier-grade NAT address space 100.64.0.0/10</a>, which my ISP then translates to a public internet routable IP. (Because I don’t want to leak my public IP, I used the <a href="https://tcpreplay.appneta.com/wiki/tcprewrite">tcprewrite</a> tool to substitute that IP with one in <a href="https://tools.ietf.org/html/rfc5737">TEST-NET-3</a>).</p>



<p>Next thing to note, is that after about 2 hours, both the client and the server starts to send TCP-keepalive packages, but none of them come through to the other side.</p>



<p>Finally the client gives up on the TCP session, and sends a TCP reset package, which surprisingly goes through.</p>



<p>Lets see what we can find in the OpenSSH man pages about timeouts and keepalives (ssh_config(5)):</p>



<pre><strong>TCPKeepAlive</strong>
    Specifies whether the system should send TCP keepalive messages to the other side.&nbsp; If they are sent, death of the
 &nbsp;&nbsp;&nbsp;connection or crash of one of the machines will be properly noticed.&nbsp; This option only uses TCP keepalives (as op‐
 &nbsp;&nbsp;&nbsp;posed to using ssh level keepalives), so takes a long time to notice when the connection dies.&nbsp; As such, you proba‐
 &nbsp;&nbsp;&nbsp;bly want the ServerAliveInterval option as well.&nbsp; However, this means that connections will die if the route is down
 &nbsp;&nbsp;&nbsp;temporarily, and some people find it annoying.
 &nbsp;&nbsp;&nbsp;<strong>The default is yes</strong> (to send TCP keepalive messages), and the client will notice if the network goes down or the re‐
 &nbsp;&nbsp;&nbsp;mote host dies.&nbsp; This is important in scripts, and many users want it too.
 &nbsp;&nbsp;&nbsp;To disable TCP keepalive messages, the value should be set to no.&nbsp; See also ServerAliveInterval for protocol-level
 &nbsp;&nbsp;&nbsp;keepalives.
<strong>ServerAliveInterval</strong>
    Sets a timeout interval in seconds after which if no data has been received from the server, ssh(1) will send a mes‐
    sage through the encrypted channel to request a response from the server.&nbsp; <strong>The default is 0, indicating that these</strong>
    <strong>messages will not be sent to the server</strong>, or 300 if the BatchMode option is set (Debian-specific). </pre>



<p>So <strong>TCPKeepAlive</strong> enables keepalives handled by the TCP stack implementation (Linux in my case), whereas <strong>ServerAliveInterval</strong> enables protocol level keep-alives (handled by OpenSSH).</p>



<p>This explains the behavior we’re observing, but also raises new questions:</p>



<ol><li>Can I fix my problem by enabling the ssh protocol-level-keepalives? (ServerAliveInterval)</li><li>Why are the TCP keepalives only sent after 2 hours?</li><li>Why is my ISP dropping my TCP keepalive packages?</li></ol>



<p>I verified that by setting <strong>ServerAliveInterval</strong> to 300 (5 min), my problems disappeared. We could stop now that I found a workaround, but let’s keep digging.</p>



<p>The TCP keepalive interval on Linux is configured by <strong>net.ipv4.tcp_keepalive_time</strong>, which by default is set to 2 hours (7200).</p>



<pre><a href="https://anderstrier.dk/cdn-cgi/l/email-protection" data-cfemail="3a5b545e5f48497a4f584f544e4f175e5f49514e554a">[email&nbsp;protected]</a>:~$ sysctl net.ipv4.tcp_keepalive_time
net.ipv4.tcp_keepalive_time = 7200</pre>



<p>Why is it set to two hours? We find our answer in <a href="https://tools.ietf.org/html/rfc1122">RFC1122</a>:</p>



<pre>Keep-alive packets MUST only be sent when no data or
acknowledgement packets have been received for the
connection within an interval.  This interval MUST be
configurable and <strong>MUST default to no less than two hours</strong>.</pre>



<p>In the following DISCUSSION section, the RFC writers elaborate on why they (in 1989) think TCP keep-alives only should be sent infrequently:</p>



<pre>The TCP specification does not include a keep-alive mechanism because it could:
(1) cause perfectly good connections to break during transient Internet failures;
(2) consume unnecessary bandwidth ("if no one is using the connection, who cares if it is still good?"); and
(3) cost money for an Internet path that charges for packets.</pre>



<p>Today the Internet is different from what it was in 1989 when they published that RFC. Now we have NAT everywhere, which is a hack that was accepted on IPv4 because the IPv4 address space is too small. The real solution is IPv6 which has a much bigger address space (2^32 vs 2^128).</p>



<p>NAT (Network Address Translation) allows many computers on a network to share the same IP. This typically works by routing your packet to a device which translates/substitutes your private <a href="https://tools.ietf.org/html/rfc1918">RFC1918</a> IP (e.g 192.168.0.0/16) for a public one, and passes on the packet.</p>



<p>CGN (Carrier-grade NAT) is NAT run by an ISP. This allows for many customers to share a single public IP (because even with every household being assigned a single IPv4, we’re still running out). To avoid collisions with the <a href="https://tools.ietf.org/html/rfc1918">RFC1918</a> ranges, ISPs are told to use the 100.64.0.0/10 range. With this setup it is not uncommon to have 3 levels of NAT. Ex, CGN, CPE that also does NAT, and the customers own router.</p>



<p>A NAT device must keep track of which connections are made by the clients. This information is stored in the NAT table. Whenever a packet arrives from the Internet, it checks if the packet belongs to any connections in its NAT table, to figure determine which client to send the package to. If it doesn’t belong to any connections, it drops the packet.</p>



<p>This wouldn’t work if the NAT table only stored IP addresses – which client should the NAT device send the packet to if receiving a packet from a server two of its clients are connected to? That is why – unlike routers – NAT devices have to cross protocol boundaries, and look deeper inside the packet and find a “<a href="https://tools.ietf.org/html/rfc3022">transport identifier</a>“. For TCP and UDP the identifiers used are the source and destination port numbers, and for ICMP the Query <a href="https://tools.ietf.org/html/rfc792">Identifier</a> is usually used.</p>



<p>A NAT table looks something like this (we’ll ignore ICMP for now):</p>



<pre>PROTOCOL SRCIP       SRCPORT DSTIP          DSTPORT NEWSRCPORT IDLETIME
TCP      192.168.1.1 52264   130.225.254.99 22      52264      983
UDP      192.168.1.2 39252   8.8.8.8        53      39252      4</pre>



<p>This NAT hack unfortunately opened up Pandora’s box of problems that we are still dealing with today. For example, you can no longer initiate a connection to a computer behind NAT. The NAT device does not know which host to send the packet to. This is why NAT’ing is often equated with firewalling. It is not a feature as such. It is a side effect of the NAT hack.</p>



<p>Back when NAT was introduced, it was not uncommon for protocols to rely on the server establishing a second connection back to the client. In “Active FTP” for example, the server will initiate a new connection back to the client (the data channel) after the client has connected. For this to work the NAT must be even more protocol aware, and preemptively create a mapping for the requested port. This is the same for SIP (used for VoIP) and a few other protocols. This is why most NAT devices can be configured to be FTP and SIP aware. Exactly this feature was recently shown to be a huge security problem – you can trigger this functionality to create a mapping of your choosing from a visitors browser, and connect to any device behind the visitors NAT. Read more about the <a href="https://github.com/samyk/slipstream">NAT Slipstreaming attack here</a>.</p>



<p>For big data transfers, or latency sensitive connections (file sharing, VoIP, gaming etc) it is very much preferable to have a direct connection between hosts. But if both hosts are behind a NAT, this is not immediately possible. To solve this problem, a new hack was introduced: <a href="https://tools.ietf.org/html/rfc5389">NAT hole punching</a>, where you – by using a third-party – can trick your NAT devices to allow traffic directly between the hosts by creating a NAT table entry (“punching”) in both NATs simultaneously. It is only somewhat reliable, and works best with UDP in my experience.</p>



<p>NAT is also one of the reasons the new <a href="https://datatracker.ietf.org/doc/draft-ietf-quic-transport/?include_text=1">QUIC</a> protocol uses UDP packages instead of its own protocol. Too many devices will fail to handle the packet correctly if they introduced a new <a href="https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml">protocol number</a>. Where should the NAT device look for a transport identifier in an unknown protocol header?</p>



<p>Another problem that arises because of NAT is: when is it safe to remove an entry from the NAT table? Sometimes the answer is simple: when you see that the connection has been closed (e.g the TCP Normal Close Sequence). But when is it safe to remove an established TCP connection (were you haven’t yet seen the connection being closed) on which no packages have …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anderstrier.dk/2021/01/11/my-isp-is-killing-my-idle-ssh-sessions-yours-might-be-too/">https://anderstrier.dk/2021/01/11/my-isp-is-killing-my-idle-ssh-sessions-yours-might-be-too/</a></em></p>]]>
            </description>
            <link>https://anderstrier.dk/2021/01/11/my-isp-is-killing-my-idle-ssh-sessions-yours-might-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25737611</guid>
            <pubDate>Mon, 11 Jan 2021 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Signal]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 207 (<a href="https://news.ycombinator.com/item?id=25732956">thread link</a>) | @JustinGarrison
<br/>
January 11, 2021 | https://www.justingarrison.com/blog/2021-01-11-getting-started-with-signal/ | <a href="https://web.archive.org/web/*/https://www.justingarrison.com/blog/2021-01-11-getting-started-with-signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content"><p>You’ve discovered that <a href="https://signal.org/">Signal</a> can provide you with secure communication from your phone that is cross platform and free!</p><p><img src="https://www.justingarrison.com/img/signal-og-banner.png" alt=""></p><p>First of all you may be asking “who makes Signal?”
Signal Messenger LLC. is the company that makes the Signal app.
They are funded by the Signal Foundation which is a non-profit organization that relies on <a href="https://signal.org/donate/">your donations</a> to make the app free and not have ulterior motives with your data.</p><p>The foundation’s mission is</p><blockquote><p>To develop open source privacy technology that protects free expression and enables secure global communication.</p></blockquote><p>The Signal app is all <a href="https://github.com/signalapp">open source on GitHub</a> and their protocols are well documented and available <a href="https://signal.org/docs/">on their website</a>.</p><p>But that’s not why you’re here.
Let’s show you some tips to get the most out of your new secure messaging app.</p><h2 id="important-settings">Important settings</h2><p>Signal is great, but there are a few things you may want to change depending on how secure or private you want your communications.</p><h3 id="notifications">Notifications.</h3><p>You can disable what is shown in notifications to help with privacy.
Turn off whatever you don’t want shown.</p><p><img src="https://www.justingarrison.com/img/signal-notification-content.png" alt=""></p><p>You may also want to disable the notification you get when one of your contacts join Signal.
Especially ad the rapid pace people are joining.</p><p><img src="https://www.justingarrison.com/img/signal-contact-notifications.png" alt=""></p><h3 id="privacy">Privacy</h3><p>You can set the Signal app to lock when your phone locks under privacy.
It may also be a good idea to enable incognito keyboard which will ask your keyboard to remove personalization while typing.</p><p><img src="https://www.justingarrison.com/img/signal-privacy.png" alt=""></p><p>You can turn off read receipts, typing indicators, and automatic link previews under the communication settings.
Link previews only work on <a href="https://support.signal.org/hc/en-us/articles/360022474332-Link-Previews">sites that use <code>https://</code></a></p><p><img src="https://www.justingarrison.com/img/signal-communication-settings.png" alt=""></p><h3 id="chats-and-media">Chats and media</h3><p>In chats you can change when to auto-download files.
Some of these can be quite large so it may be a good idea to only automatically download on Wi-Fi.</p><p><img src="https://www.justingarrison.com/img/signal-media-download.png" alt=""></p><p>At the very bottom of Chats and media is a <a href="https://support.signal.org/hc/en-us/articles/360007059752-Backup-and-Restore-Messages">message backup option</a>.
The backup is encrypted and stored locally on your phone.
If you’re using a backup service for your phone they will also be backed up to the cloud which you may or may not want (even if it’s encrypted).</p><p><img src="https://www.justingarrison.com/img/signal-chat-backups.png" alt=""></p><h3 id="linked-devices">Linked devices</h3><p>You can use Signal from another device including tablets and laptops.
Install the Signal app on the other device and it will show a QR code.
Open the linked devices setting and click the + button at the bottom.
Scan the QR code and you’re all set.</p><p>If you tap on an existing linked device you have the option to remove it from being able to send or receive messages.
Be aware that any existing messages on the device may still be available and cached on the device.
This setting is not a “secure wipe.”</p><h2 id="chats-and-calls">Chats and calls</h2><p>Signal chats work similarly to traditional SMS messaging apps.
You can send text, emoji, and stickers, or attach pictures, gifs (searched from giphy), files, contacts, or locations.
You can record voice messages by holding the microphone.</p><p><img src="https://www.justingarrison.com/img/signal-message-attach.png" alt=""></p><p>You can also make audio or video calls when you select a contact and click the icons in the top banner.
All calls are encrypted and can optionally go through a relay server so you do not expose your IP address to the recipient.
You can enable the relay server in settings -&gt; privacy -&gt; communication.</p><p>A relay is a server that Signal controls that your call will go through.
Similar to a VPN in the way it would expose the server IP to the recipient without exposing your IP.
If you’re interested in the Signal server architecture you can check out <a href="https://sorincocorada.ro/signal-messanger-architecture/">this post</a>.</p><p><img src="https://www.justingarrison.com/img/signal-relay-calls.png" alt=""></p><p>A single hallow check box next to a message you sent means your message was sent.
Two check marks means the message was delivered.
Once the recipient reads the message the check marks will fill in.</p><p><img src="https://www.justingarrison.com/img/signal-double-checks-hallow.png" alt="">
<img src="https://www.justingarrison.com/img/signal-doublechecks-filled.png" alt=""></p><p>If you see a little person icon next to the person’s name in chat it means that person is in your contacts.
If you want their name to automatically be filled out you can go into your phone’s contacts and add the number to a contact.</p><p><img src="https://www.justingarrison.com/img/signal-contact.png" alt=""></p><p>If you open a chat you can look in settings and enable disappearing messages.
This is super helpful to prevent messages persisting.</p><p><img src="https://www.justingarrison.com/img/signal-disappearing.png" alt=""></p><p>You can—and should—verify a contact to make sure you’re really talking to them.
This verifies the encryption keys used at both ends of the conversation.
You can do that manually or automatically by scanning their QR code.</p><p>Ideally you will do this verification out-of-band from Signal either in person or through some other video/image sharing service.
Facetime, zoom, etc. are great options if you can’t meet in person.</p><p>Once you verify a contact you’ll see “Verified” text under their name.
If you manually mark the contact as verified it will show a message in the chat that you marked them verified.</p><h3 id="group-messages">Group messages</h3><p>You can create a group message from the main screen clicking the pencil and then “New group.”</p><p><img src="https://www.justingarrison.com/img/signal-new-group.png" alt=""></p><p>Add contacts to the group and you’re ready to go.</p><p>You have similar settings to 1:1 chats.
You can have a group video call with up to 8 people and a group chat with up to 150 people—RIP notifications!
If you want to have a group call without video you need to start a video call and disable your camera before you join.</p><p>You can change who can invite people to the group or make a group link easier for someone to share if they’re not in your contacts.</p><p>The links are public but an admin needs to approve members joining the group by default.</p><p><img src="https://www.justingarrison.com/img/signal-group-link.png" alt=""></p><p>Group video calls work the same way as 1:1 calls but groups don’t have audio only calls—although you can disable your video in a video call.</p><h2 id="other-things-to-consider">Other things to consider</h2><p>If you want to use signal without giving out your real phone number you can use a service like twilio that will provide you a forwarding number.</p><p>Check out <a href="https://mshelton.medium.com/using-signal-without-giving-your-phone-number-3a575580f652">this great guide</a> on how to set it up.</p><h3 id="your-safety-number-has-changed">Your safety number has changed</h3><p>If you see this seemingly scary message don’t be alarmed.
It likely just means the <a href="https://support.signal.org/hc/en-us/articles/360007060632-What-is-a-safety-number-and-why-do-I-see-that-it-changed-">person on the other end of the conversation</a> got a new phone or re-installed Signal.</p><p><img src="https://www.justingarrison.com/img/signal-safety-number.png" alt=""></p><p>You can still verify the persons safety number to make sure there is no man-in-the-middle attacks.
This is distinctly different than how iMessage and Telegram work because in both of those apps they store your private key.</p><h3 id="pins">Pins</h3><p>Pins are important because they will enable Signal to get rid of phone number requirements.</p><p>The <a href="https://support.signal.org/hc/en-us/articles/360007059792-Signal-PIN">support page</a> says it best</p><blockquote><p>Your Signal PIN is a code used to support features like non-phone number based identifiers. This means that your PIN can recover your profile, settings, contacts, and who you’ve blocked if you ever lose or switch devices. A PIN can also serve as an optional registration lock to prevent others from registering your number on your behalf.</p></blockquote><p>It hasn’t rolled out yet but has been in the works for a while.</p><p>If you want to stay up to date on signal news I highly recommend you follow the <a href="https://signal.org/blog/">Signal blog</a>.
They have lots of great technical and non-technical information on new features and news.</p></article></div>]]>
            </description>
            <link>https://www.justingarrison.com/blog/2021-01-11-getting-started-with-signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25732956</guid>
            <pubDate>Mon, 11 Jan 2021 18:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XTerm: It's Better Than You Thought]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25732862">thread link</a>) | @zdw
<br/>
January 11, 2021 | https://aduros.com/blog/xterm-its-better-than-you-thought/ | <a href="https://web.archive.org/web/*/https://aduros.com/blog/xterm-its-better-than-you-thought/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="js-article">
    <p>(Day 10 of <a href="https://aduros.com/blog/30-days-of-blogging">30 Days of Blogging</a>)</p>
<p>A couple months back I switched my terminal from xfce4-terminal to the venerable xterm. For some
reason I always put xterm in the same bucket as xclock, xmessage, or any other prehistoric command
starting with X that comes pre-installed on any graphical Linux distribution.</p>
<p>It was surprising to learn that xterm is still very much <a href="https://invisible-island.net/xterm/xterm.log.html">actively
developed</a>. Even more surprisingly, it turns out
xterm has <a href="https://lwn.net/Articles/751763/">incredibly low input latency</a> compared to modern
terminals. This is easy to test at home, try typing in xterm compared to any other terminal and feel
how much snappier it is.</p>
<p>The lower latency alone is worth the price of admission in my opinion, so I went about configuring
xterm as my default terminal. The configuration goes in <code>~/.Xresources</code> and you need to run <code>xrdb ~/.Xresources</code> after every change, or <a href="https://github.com/aduros/dotfiles/blob/eab476fc62e74e46cb41bb5c094cede7a28a014f/home/.config/nvim/options.vim#L27">make vim do
it</a>.</p>
<h2 id="basic-configuration">Basic Configuration</h2>
<p>Here are some “modern” sensible defaults I ended up landing on:</p>
<div><pre><code data-lang="text">! Sensible defaults
XTerm.vt100.locale: false
XTerm.vt100.utf8: true
XTerm.vt100.scrollTtyOutput: false
XTerm.vt100.scrollKey: true
XTerm.vt100.bellIsUrgent: true
XTerm.vt100.metaSendsEscape: true
</code></pre></div><p>And here are some visual styling options, not including colors:</p>
<div><pre><code data-lang="text">! Styling
XTerm.vt100.faceName: DejaVu Sans Mono
XTerm.vt100.boldMode: false
XTerm.vt100.faceSize: 11
XTerm.vt100.internalBorder: 16
XTerm.borderWidth: 0
</code></pre></div><p>XTerm supports key binding, but the syntax is non-obvious:</p>
<div><pre><code data-lang="text">XTerm.vt100.translations: #override \n\
    Ctrl Shift &lt;Key&gt;N: scroll-back(1, halfpage) \n\
    Ctrl Shift &lt;Key&gt;T: scroll-forw(1, halfpage) \n\
    Ctrl Shift &lt;Key&gt;C: copy-selection(CLIPBOARD) \n\
    Ctrl Shift &lt;Key&gt;V: insert-selection(CLIPBOARD)
</code></pre></div><p>This allows copying and pasting to the clipboard (not just the X selection) with shift-ctrl-C and V.
It also allows scrolling up and down with shift-ctrl-N and T (you can switch this to K and J to
match vim keys in Qwerty).</p>
<h2 id="url-handling">URL Handling</h2>
<p>So now we have a pretty usable setup, but there’s one more incredibly useful feature that was hard
to figure out: opening URLs in the browser. We could of course select the URL and copy-paste, but
there’s a better way.</p>
<p>XTerm has a configuration option called <code>printerCommand</code> which is a command that is piped all the
text currently visible in the terminal. As the name suggests, it’s meant to be used to implement
printing to physical paper, but we can save the trees and hijack it to instead scan the screen for
URLs and open the browser:</p>
<div><pre><code data-lang="sh"><span>#!/bin/sh -e
</span><span></span>
grep -Eo <span>'\bhttps?://\S+\b'</span> |
    uniq |
    ifne rofi -dmenu -i -p <span>"Open URL"</span> -auto-select |
    xargs xdg-open
</code></pre></div><p>This greps for URLs, removes consecutive duplicates with <code>uniq</code>, and displays a
<a href="https://github.com/davatorium/rofi">rofi</a> menu to choose between them if there were multiple URLs.
<code>ifne</code> is included in <a href="https://packages.debian.org/unstable/utils/moreutils">moreutils</a>. Put this
script in an executable file called <code>select-url</code> in your <code>$PATH</code> and then add this to <code>.Xresources</code>:</p>
<div><pre><code data-lang="text">XTerm.vt100.printerCommand: select-url

XTerm.vt100.translations: #override \n\
    ...
    Ctrl Shift &lt;Key&gt;W: print(noAttrs, noNewLine)
</code></pre></div><p>Now when you press shift-ctrl-W, any URL shown in the terminal will open in the browser. You don’t
have to select anything or use your mouse at all, nice!</p>
<p>Someday it would be great to improve <code>select-url</code> to also scan for email addresses. Maybe during the
next pandemic…</p>
<h2 id="peeking-at-the-alternate-screen">Peeking at the Alternate Screen</h2>
<p>Sometimes you open a fullscreen application like vim or a man page and you need to refer back to
some text on the shell. Use this keybind to toggle back and forth:</p>
<div><pre><code data-lang="text">XTerm.vt100.translations: #override \n\
    ...
    Ctrl Shift &lt;Key&gt;H: set-altscreen(toggle)
</code></pre></div><p>You can even use it view a previously opened vim or man page after you close out of it!</p>
<h2 id="opening-new-terminals-at-the-current-directory">Opening New Terminals at the Current Directory</h2>
<p>There’s a keybind action called <code>spawn-new-terminal()</code> that can be used for this, but even better is
using <a href="https://github.com/schischi/xcwd">xcwd</a> to get the working directory of any currently focused
window. Then you can put this in your i3 config for example:</p>
<div><pre><code data-lang="text">bindsym $mod+Return exec --no-startup-id cd "`xcwd`" &amp;&amp; xterm
</code></pre></div><h2 id="wish-list">Wish List</h2>
<p>XTerm is missing a few small features:</p>
<ul>
<li>Text reflow when the terminal is resized.</li>
<li>Fallback fonts don’t seem to always work. Maybe I’m missing a config option?</li>
<li>Transparency not natively supported. I don’t care about transparency but maybe it’s important to
some people.</li>
<li>Occasionally strange flickering with <a href="https://github.com/ibhagwan/picom">picom</a>, possibly a bug
with picom?</li>
</ul>
<p>In the end this wasn’t enough to stop me from using xterm, but the lack of text reflow still irks me
from time to time. Overall, I’ve been pleasantly surprised with xterm after taking the time to
configure it.</p>

  </section></div>]]>
            </description>
            <link>https://aduros.com/blog/xterm-its-better-than-you-thought/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25732862</guid>
            <pubDate>Mon, 11 Jan 2021 17:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China CCP to Nationalize Jack Ma's Alibaba and Ant Group – Report]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 339 (<a href="https://news.ycombinator.com/item?id=25732676">thread link</a>) | @masonhensley
<br/>
January 11, 2021 | https://www.ibtimes.sg/china-ccp-nationalize-jack-mas-alibaba-ant-group-54444 | <a href="https://web.archive.org/web/*/https://www.ibtimes.sg/china-ccp-nationalize-jack-mas-alibaba-ant-group-54444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure itemprop="associatedMedia video" itemscope="" itemtype="https://schema.org/VideoObject" data-v="3995"><div></div><p>
<figcaption>
<span>China sets path for President Xi to remain in power indefinitely</span>				</figcaption></p><meta itemprop="name" content="China sets path for President Xi to remain in power indefinitely"><meta itemprop="duration" content="T0M32S"><meta itemprop="thumbnailUrl" content="https://data.ibtimes.sg/en/full/21247/china-sets-path-president-xi-remain-power-indefinitely.jpg"><meta itemprop="contentURL" content="https://video.ibtimes.co.in/transcoder/480p/163/jingping2502.mp4"><meta itemprop="embedURL" content="https://www.ibtimes.sg/videos/embed/3995"><meta itemprop="uploadDate" content="2018-02-26T00:19:32+08:00"><meta itemprop="description" content="Chinas ruling Communist Party have proposed removing a clause in its constitution which limits presidencies to two five-year terms. The move would allow President Xi Jinping to remain as leader indefinitely.&nbsp;"><meta itemprop="height" content="414"><meta itemprop="width" content="736">  </figure>
<figure itemscope="" itemprop="image" itemtype="https://schema.org/ImageObject"><meta itemprop="url" content="https://data.ibtimes.sg/en/full/21247/china-sets-path-president-xi-remain-power-indefinitely.jpg"><meta itemprop="width" content="1280"><meta itemprop="height" content="720">
</figure></div><div itemprop="articleBody" id="v_main"><p>Reports from China indicate that the Chinese government may be working on a plan to nationalize Jack Ma's Alibaba and the Ant Group. China's ruling Chinese Communist Party (CCP) has gone further ahead with the antitrust investigation into e-commerce giant Alibaba.</p><p>"Based on tip-offs received by the State Administration for Market Regulation in recent days, the administration will be investigating Alibaba ... for suspected monopolistic activities," the government said.</p><p><strong><a href="https://www.ibtimes.sg/malaysias-mahathir-named-worlds-most-dangerous-extremists-list-alongside-isis-caliph-54749" target="_blank">ALSO READ: Malaysia's Mahathir Named in 'World's Most Dangerous Extremists' List Alongside ISIS Caliph</a></strong></p><p>The investigating agencies had set up an office at the Alibaba headquarters in November. Apart from the e-commerce giant, investigators are also probing social media giant Tencent and e-commerce company Meituan.</p><p>The news of the government's plan to enforce more curbs on Alibaba sent its stock spiraling down as much as 8 percent. Alibaba said in a statement it would cooperate with any investigation. "Today, Ant Group received a meeting notice from regulators," Alibaba said in a statement.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=736 736w"><source media="(min-width: 1024px)" sizes="980px" srcset="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=980 980w"><source media="(min-width: 768px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=736 736w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i489" src="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg?w=736" alt="China's Alibaba secures $3 billion loan to finance acquisition spree" title="China's Alibaba secures $3 billion loan to finance acquisition spree" width="736" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/489/chinas-alibaba-secures-3-billion-loan-to-finance-acquisition-spree.jpg"><meta itemprop="width" content="1200"><meta itemprop="height" content="795">
<figcaption>
<span itemprop="caption">A logo of Alibaba Group is pictured at its headquarters in Hangzhou, Zhejiang province, China, October 14, 2015.</span>
<span itemprop="copyrightHolder">Reuters</span>
</figcaption></div>
</figure><h3>Decision Taken at Highest Levels of CCP</h3><p>Meanwhile, sources have said the development is a proof of China's resolve to nationalize Alibaba. Song Qing, Internet finance industry insider, said the investigation is part of CCP plans to nationalize both Ant Group and Alibaba. "There will definitely be an outcome, now that they have started the investigation ... This is probably coming from the highest levels," he told Radio Free Asia.</p><p>The suggestions are that the plan to nationalize Alibaba has come from the very top of the ruling Communist Party structure. A few days ago, the People's Daily, the official mouthpiece of the CCP, said the government's "anti-monopoly work" will lead to "better development." The paper said the party Politburo thought 'anti-monopoly work' should be strengthened to prevent the disorderly expansion of capital.</p><p>Song Qing agrees with the view. "Just a couple of weeks ago, they set out plans to nationalize Ant Group and Alibaba; the timing was deliberate ... Those plans all came from the central leadership," he said.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=736 736w"><source media="(min-width: 1024px)" sizes="980px" srcset="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=980 980w"><source media="(min-width: 768px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=736 736w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i20672" src="https://data.ibtimes.sg/en/full/20672/alibaba.jpg?w=736" alt="Alibaba" title="Alibaba" width="736" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/20672/alibaba.jpg"><meta itemprop="width" content="1600"><meta itemprop="height" content="1066">
<figcaption>
<span itemprop="caption">Alibaba Group founder and executive chairman Jack Ma.</span>
<span itemprop="copyrightHolder">IANS</span>
</figcaption></div>
</figure><p>He also added that the government wants to make a lesson out of Alibaba. "These nationalizations are definitely happening, and [the antitrust investigation] will likely speed up that process ... It's also, I think, about making an example of [Ant and Alibaba]," <a href="https://www.rfa.org/english/news/china/alibaba-probe-12252020170303.html" rel="nofollow" target="_blank">he said</a>.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=736 736w"><source media="(min-width: 1024px)" sizes="980px" srcset="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=980 980w"><source media="(min-width: 768px)" sizes="736px" srcset="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=736 736w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i14121" src="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg?w=736" alt="Visitors use their smartphones underneath the logo of Tencent at the Global Mobile Internet Conference in Beijing May 6, 2014. REUTERS/Kim Kyung-Hoon/File Photo" title="Visitors use their smartphones underneath the logo of Tencent at the Global Mobile Internet Conference in Beijing May 6, 2014. REUTERS/Kim Kyung-Hoon/File Photo" width="736" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/14121/visitors-use-their-smartphones-underneath-the-logo-of-tencent-at-the-global-mobile-internet-conference-in-beijing-may-6-2014-reuters-kim-kyung-hoon-file-photo.jpg"><meta itemprop="width" content="1200"><meta itemprop="height" content="666">
<figcaption>
<span itemprop="caption">Visitors use their smartphones underneath the logo of Tencent at the Global Mobile Internet Conference in Beijing May 6, 2014. REUTERS/Kim Kyung-Hoon/File Photo</span>
<span itemprop="copyrightHolder">Reuters</span>
</figcaption></div>
</figure><p>As the antitrust probe progresses, the People's Bank of China, the China Banking Regulatory Commission, the China Securities Regulatory Commission and the State Administration of Foreign Exchange will also get involved in the investigation against Alibaba.</p><p>Xi Jinping, Chinese President and CCP general secretary, had said in October that the plan was to make China a more state-controlled economy based on domestic demand. Observers think China's political economy is poised to see major changes. Many believe that Xi will change the pattern of property ownership in the country.</p></div></div>]]>
            </description>
            <link>https://www.ibtimes.sg/china-ccp-nationalize-jack-mas-alibaba-ant-group-54444</link>
            <guid isPermaLink="false">hacker-news-small-sites-25732676</guid>
            <pubDate>Mon, 11 Jan 2021 17:47:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Anomaly Detection Using Plain SQL]]>
            </title>
            <description>
<![CDATA[
Score 388 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25731699">thread link</a>) | @harporoeder
<br/>
January 11, 2021 | https://hakibenita.com/sql-anomaly-detection | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-anomaly-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Many developers think that having a critical bug in their code is the worst thing that can happen. Well, there is something much worse than that: Having a critical bug in your code and <strong>not knowing about it!</strong></p>
<p>To make sure I get notified about critical bugs as soon as possible, I started looking for ways to find anomalies in my data. I quickly found that information about these subjects tend to get very complicated, and involve a lot of ad-hoc tools and dependencies.</p>
<p>I'm not a statistician and not a data scientist, I'm just a developer. Before I introduce dependencies into my system I make sure I really can't do without them. So, <strong>using some high school level statistics and a fair knowledge of SQL, I implemented a simple anomaly detection system <em>that works</em>.</strong></p>
<figure><img alt="Can you spot the anomaly?<br><small>Photo by <a href=&quot;https://unsplash.com/photos/KmKZV8pso-s&quot;>Ricardo Gomez Angel</a></small>" src="https://hakibenita.com/images/00-sql-anomaly-detection.png"><figcaption>Can you spot the anomaly?<br><small>Photo by <a href="https://unsplash.com/photos/KmKZV8pso-s">Ricardo Gomez Angel</a></small></figcaption>
</figure>
<details open="">
   <summary>Table of Contents</summary>

</details>
<hr>

<hr>
<h2 id="detecting-anomalies"><a href="#detecting-anomalies">Detecting Anomalies</a></h2>
<p>Anomaly in a data series is a significant deviation from some reasonable value. Looking at this series of numbers for example, which number stands out?</p>
<div><pre><span></span>2, 3, 5, 2, 3, 12, 5, 3, 4
</pre></div>


<p>The number that stands out in this series is 12.</p>
<figure><img alt="Scatter plot" src="https://hakibenita.com/images/00-sql-anomaly-detection-scatter-plot.png"><figcaption>Scatter plot</figcaption>
</figure>
<p>This is intuitive to a human, but computer programs don't have intuition...</p>
<p>To find the anomaly in the series we first need to define what a reasonable value is, and then define how far away from this value we consider a significant deviation. A good place to start looking for a reasonable value is the mean:</p>
<div><pre><span></span><span>SELECT</span> <span>avg</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>       avg</span>
<span>────────────────────</span>
<span>4.3333333333333333</span>
</pre></div>


<p>The mean is ~4.33.</p>
<p>Next, we need to define the deviation. Let's use <a href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener">Standard Deviation</a>:</p>
<div><pre><span></span><span>SELECT</span> <span>stddev</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>      stddev</span>
<span>────────────────────</span>
<span>3.0822070014844882</span>
</pre></div>


<p>Standard deviation is the square root of the <a href="https://en.wikipedia.org/wiki/Variance" rel="noopener">variance</a>, which is the average squared distance from the mean. In this case it's 3.08.</p>
<p>Now that we've defined a "reasonable" value and a deviation, we can define a <em>range</em> of acceptable values:</p>
<div><pre><span></span><span>SELECT</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
<span>FROM</span>
   <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>    lower_bound    │     upper_bound</span>
<span>───────────────────┼────────────────────</span>
<span>1.2511263318488451 │ 7.4155403348178215</span>
</pre></div>


<p>The range we defined is one standard deviation from the mean. Any value outside this range is considered an anomaly:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>bounds</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
   <span>n</span> <span>NOT</span> <span>BETWEEN</span> <span>lower_bound</span> <span>AND</span> <span>upper_bound</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>series</span><span>,</span>
   <span>bounds</span><span>;</span>

<span>n  │ is_anomaly</span>
<span>───┼────────────</span>
<span> 2 │ f</span>
<span> 3 │ f</span>
<span> 5 │ f</span>
<span> 2 │ f</span>
<span> 3 │ f</span>
<span><span>12 │ t</span>
</span><span> 5 │ f</span>
<span> 3 │ f</span>
<span> 4 │ f</span>
</pre></div>


<p>Using the query we found that the value 12 is outside the range of acceptable values, and identified it as an anomaly.</p>
<h3 id="understanding-z-score"><a href="#understanding-z-score">Understanding Z-Score</a></h3>
<p>Another way to represent a range of acceptable values is using a z-score. <a href="https://en.wikipedia.org/wiki/Standard_score" rel="noopener">z-score, or Standard Score</a>, is the number of standard deviations from the mean. In the previous section, our acceptable range was one standard deviation from the mean, or in other words, a z-score in the range ±1:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_mean</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
<span>   <span>(</span><span>n</span> <span>-</span> <span>series_mean</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>as</span> <span>zscore</span>
</span><span>FROM</span>
   <span>series</span><span>,</span>
   <span>stats</span><span>;</span>

<span>n  │         zscore</span>
<span>───┼─────────────────────────</span>
<span> 2 │ -0.75703329861022517346</span>
<span> 3 │ -0.43259045634870009448</span>
<span> 5 │  0.21629522817435006346</span>
<span> 2 │ -0.75703329861022517346</span>
<span> 3 │ -0.43259045634870009448</span>
<span>12 │      2.4873951240050256</span>
<span> 5 │  0.21629522817435006346</span>
<span> 3 │ -0.43259045634870009448</span>
<span> 4 │ -0.10814761408717501551</span>
</pre></div>


<p>Like before, we can detect anomalies by searching for values which are outside the acceptable range using the z-score:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  │         zscore          │ is_anomaly</span>
<span>───┼─────────────────────────┼────────────</span>
<span> 2 │ -0.75703329861022517346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span> 5 │  0.21629522817435006346 │ f</span>
<span> 2 │ -0.75703329861022517346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span><span>12 │      2.4873951240050256 │ t</span>
</span><span> 5 │  0.21629522817435006346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span> 4 │ -0.10814761408717501551 │ f</span>
</pre></div>


<p>Using z-score, we also identified 12 as an anomaly in this series.</p>
<h3 id="optimizing-z-score"><a href="#optimizing-z-score">Optimizing Z-Score</a></h3>
<p>So far we used one standard deviation from the mean, or a z-score of ±1 to identify anomalies. Changing the z-score threshold can affect our results. For example, let's see what anomalies we identify when the z-score is greater than 0.5 and when it's greater than 3:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
<span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>0.5</span> <span>AND</span> <span>0.5</span> <span>AS</span> <span>is_anomaly_0_5</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly_1</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>3</span> <span>AND</span> <span>3</span> <span>AS</span> <span>is_anomaly_3</span>
</span><span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  │         zscore          │ is_anomaly_0_5 │ is_anomaly_1 │ is_anomaly_3</span>
<span>───┼─────────────────────────┼────────────────┼──────────────┼──────────────</span>
<span> 2 │ -0.75703329861022517346 │ t              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span> 5 │  0.21629522817435006346 │ f              │ f            │ f</span>
<span> 2 │ -0.75703329861022517346 │ t              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span>12 │      2.4873951240050256 │ t              │ t            │ f</span>
<span> 5 │  0.21629522817435006346 │ f              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span> 4 │ -0.10814761408717501551 │ f              │ f            │ f</span>
</pre></div>


<p>Let's see what we got:</p>
<ul>
<li>When we decreased the z-score threshold to 0.5, we identified the value 2 as an anomaly in addition to the value 12.</li>
<li>When we increased the z-score threshold to 3 we did not identify any anomaly.</li>
</ul>
<p>The quality of our results are directly related to the parameters we set for the query. Later we'll see how using backtesting can help us identify ideal values.</p>
<hr>
<h2 id="analyzing-a-server-log"><a href="#analyzing-a-server-log">Analyzing a Server Log</a></h2>
<p>Application servers such as nginx, Apache and IIS write a lot of useful information to access logs. The data in these logs can be extremely useful in identifying anomalies.</p>
<p>We are going to analyze logs of a web application, so the data we are most interested in is the timestamp and the status code of every response from the server. To illustrate the type of insight we can draw from just this data:</p>
<ul>
<li><strong>A sudden increase in 500 status code</strong>: You may have a problem in the server. Did you just push a new version? Is there an external service you're using that started failing in unexpected ways?</li>
<li><strong>A sudden increase in 400 status code</strong>: You may have a problem in the client. Did you change some validation logic and forgot to update the client? Did you make a change and forgot to handle backward compatibility?</li>
<li><strong>A sudden increase in 404 status code</strong>: You may have an SEO problem. Did you move some pages and forgot to set up redirects? Is there some script kiddy running a scan on your site?</li>
<li><strong>A sudden increase in 200 status code</strong>: You either have some significant legit traffic coming in, or you are under a DOS attack. Either way, you probably want to check where it's coming from.</li>
</ul>
<h3 id="preparing-the-data"><a href="#preparing-the-data">Preparing the Data</a></h3>
<p>Parsing and processing logs is outside the scope of this article, so let's assume we did that and we have a table that looks like this:</p>
<div><pre><span></span><span>CREATE</span> <span>TABLE</span> <span>server_log_summary</span> <span>AS</span> <span>(</span>
   <span>period</span> <span>timestamptz</span><span>,</span>
   <span>status_code</span> <span>int</span><span>,</span>
   <span>entries</span> <span>int</span>
<span>);</span>
</pre></div>


<p>The table stores the number of entries for each status code at a given period. For example, our table stores how many responses returned each status code every minute:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>server_log_summary</span> <span>ORDER</span> <span>BY</span> <span>period</span> <span>DESC</span> <span>LIMIT</span> <span>10</span><span>;</span>

<span>        period         │ status_code │ entries</span>
<span>───────────────────────┼─────────────┼─────────</span>
<span>2020-08-01 18:00:00+00 │         200 │    4084</span>
<span>2020-08-01 18:00:00+00 │         404 │       0</span>
<span>2020-08-01 18:00:00+00 │         400 │      24</span>
<span>2020-08-01 18:00:00+00 │         500 │       0</span>
<span>2020-08-01 17:59:00+00 │         400 │      12</span>
<span>2020-08-01 17:59:00+00 │         200 │    3927</span>
<span>2020-08-01 17:59:00+00 │         500 │       0</span>
<span>2020-08-01 17:59:00+00 │         404 │       0</span>
<span>2020-08-01 17:58:00+00 │         400 │       2</span>
<span>2020-08-01 17:58:00+00 │         200 │    3850</span>
</pre></div>


<p>Note that the table has a row for every minute, even if the status code was never returned in that minute. Given a table of statuses, it's very tempting to do something like this:</p>
<div><pre><span></span><span>-- Wrong!</span>
<span>SELECT</span>
   <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>timestamp</span><span>)</span> <span>AS</span> <span>period</span><span>,</span>
   <span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>server_log</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span>
   <span>status_code</span><span>;</span>
</pre></div>


<p>This is a common mistake and it can leave you with gaps in the data. Zero is a value, and it holds a significant meaning. A better approach is to create an "axis", and join to it:</p>
<div><pre><span></span><span>-- Correct!</span>
<span>WITH</span> <span>axis</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>status_code</span><span>,</span>
       <span>generate_series</span><span>(</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()),</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()</span> <span>-</span> <span>interval</span> <span>'1 hour'</span><span>),</span>
           <span>interval</span> <span>'1 minute'</span> <span>*</span> <span>-</span><span>1</span>
       <span>)</span> <span>AS</span> <span>period</span>
   <span>FROM</span> <span>(</span>
       <span>VALUES</span> <span>(</span><span>200</span><span>),</span> <span>(</span><span>400</span><span>),</span> <span>(</span><span>404</span><span>),</span> <span>(</span><span>500</span><span>)</span>
   <span>)</span> <span>AS</span> <span>t</span><span>(</span><span>status_code</span><span>)</span>
<span>)</span>
<span>SELECT</span>
   <span>a</span><span>.</span><span>period</span><span>,</span>
   <span>a</span><span>.</span><span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>axis</span> <span>a</span>
   <span>LEFT</span> <span>JOIN</span> <span>server_log</span> <span>l</span> <span>ON</span> <span>(</span>
       <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>l</span><span>.</span><span>timestamp</span><span>)</span> <span>=</span> <span>a</span><span>.</span><span>period</span>
       <span>AND</span> <span>l</span><span>.</span><span>status_code</span> <span>=</span> <span>a</span><span>.</span><span>status_code</span>
   <span>)</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-anomaly-detection">https://hakibenita.com/sql-anomaly-detection</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-anomaly-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-25731699</guid>
            <pubDate>Mon, 11 Jan 2021 16:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My personal wishlist for a decentralized social network]]>
            </title>
            <description>
<![CDATA[
Score 340 | Comments 250 (<a href="https://news.ycombinator.com/item?id=25731419">thread link</a>) | @csande17
<br/>
January 11, 2021 | https://carter.sande.duodecima.technology/decentralized-wishlist/ | <a href="https://web.archive.org/web/*/https://carter.sande.duodecima.technology/decentralized-wishlist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
  Social networks are usually run by single central organizations.
  When you visit <a href="https://facebook.com/">Facebook</a>, for example, your computer talks to servers located in giant datacenters owned by a company called “Facebook, Inc.”.
  In addition to running all the servers and networking equipment, Facebook, Inc. also does things like control who’s allowed to use the website, pick trending topics, and tweak the algorithm that decides what shows up in your feed.
</p>
<p>
  Lately, though, there’s been some interest in <em>decentralized social networks</em>.
  These systems let lots of different people and groups run parts of the service.
  (Often, they’re set up so that anyone can join in just by running a special program on their computer.)
  I’ve been seeing projects like <a href="https://joinmastodon.org/">Mastodon</a>, <a href="https://joinpeertube.org/">PeerTube</a>,  and <a href="https://scuttlebutt.nz/">Scuttlebutt</a> get released and slowly gain in popularity over the past few years. If you want to stretch the definition of “social network”, there’s also <a href="https://ipfs.io/">IPFS</a>, <a href="https://dat.foundation/">Dat</a>, and <a href="https://urbit.org/">Urbit</a>.
</p>
<p>
  These kinds of projects are exciting to me because they could solve a lot of the problems with social networks.
  It’s a lot harder for decentralized networks to go down, or make user-hostile changes, or submit to pressure from authoritarian regimes.
  They’re also kind of cool from a technical perspective.
  Despite all this, I haven’t found a project that I personally want to use or recommend to people yet—every decentralized social network I’ve looked at is missing something or other.
</p>
<p>
  I think I’ve managed to boil down the things I want to see in a decentralized network into three key features:
</p>
<h2>Network-layer anonymity (like <a href="https://geti2p.net/en/">I2P</a> or <a href="https://2019.www.torproject.org/docs/onion-services.html.en">Tor Onion Services</a>)</h2>
<p>
  When your computer talks to a website, that website receives your IP address.
  There’s a very good technical reason for this: if you ask the website to send you some information, the website needs to know where to send it.
  (A bit like a return address on a letter.)
  But IP addresses can also reveal information about you.
  They usually indicate roughly where you live and who your Internet Service Provider is, and they can be used to connect multiple online accounts/posts/views back to the same person.
  Hackers can also use your IP address to send things like DDOS attacks your way.
  On centralized networks, though, this isn’t the biggest problem in the world—Facebook already has lots of information about you, and they probably aren’t going to DDOS their own users.
</p>
<p>
  But in some decentralized social networks, <em>random other users of the network</em> get your IP address and can link it to your activity.
  They can build websites like <a href="https://iknowwhatyoudownload.com/">iknowwhatyoudownload.com</a>, which lets you look up anyone’s BitTorrent activity if you know their IP address.
  These random people aren’t even bound by the flimsy privacy policies and PR considerations that Facebook is—they can do whatever they want with the information.
</p>
<p>
  Luckily, there are techniques that decentralized networks can use to avoid this.
  I’m not an expert on the subject, but systems like I2P or Tor seem to work by sending data through multiple other nodes in the network before it reaches its final destination.
  You can use encryption to make sure none of the intermediate nodes can see the data, and you can make sure that the destination only knows who the last intermediate node is and not who the original sender is.
</p><p>
  This doesn’t mean that the actual posts or users of the service have to be anonymous—you can definitely implement things like user profiles.
  It just means not leaking users’ IP addresses.
</p>
<h2>Grassroots content delivery (like <a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a> or <a href="https://ipfs.io/">IPFS</a>)</h2>
<p>
  Hosting data on the Internet isn’t free.
  You have to buy hard drives, and you have to pay for electricity and Internet access.
  Usually, whoever owns the website pays to host it; I spend a few dollars each month from my salary, and Facebook spends tens of millions of dollars that they get from <strike>secret backroom deals with the Illuminati</strike> advertising.
  But the whole point of decentralization is that no single person or company owns the website!
  So who pays for it?
</p>
<p>
  Some decentralized networks try to solve this problem with cryptocurrency schemes, but this means that anyone who wants to try out the network has to put their credit card information into a sketchy website and transfer money to a sketchy offshore bank account and do other sketchy cryptocurrency stuff.
  (Also, cryptocurrencies are usually outright scams.)
  Other decentralized networks have “instances” which one person pays for and a bunch of other people can use.
  But instances have a single point of failure: if the person who runs the instance decides to shut it down, all of the accounts and posts and stuff on that instance are gone forever.
</p>
<p>
  The solution I like the best is to let anyone host anything they want.
  If Bob really likes my posts and want to help keep them online, he can set up his own little server and copy all my posts to it.
  Then, when someone wants to view my posts, their computer will search for anyone who has them and ask for a copy.
  Could be me, could be Bob, could be the <a href="https://archive.org/">Internet Archive</a>.
  Their computer downloads the posts and uses cryptographic hashes/signatures to make sure no one tampered with them.
</p>
<p>
  This kind of “grassroots” system has some huge advantages.
  Posts that are more popular will get hosted more; if lots of people want to see something, there’ll be lots of network bandwidth available to show it to them.
  And all it takes is one person who cares to keep something alive on the network, even if the person who originally created it isn’t around anymore.
</p>
<h2>Customizable moderation (like <a href="https://github.com/gorhill/uBlock/wiki/Dashboard:-Filter-lists">uBlock Origin</a>)</h2>
<p>
  Social networks need some kind of moderation to make sure your feed isn’t filled with spam, or viruses, or other harmful content.
  Companies like Facebook handle this in two ways: by developing machine-learning algorithms to try and automatically detect bad stuff, and by hiring huge teams of human moderators to try and detect it manually.
  But both machine-learning algorithms and people make mistakes sometimes.
  And even if they don’t, they’re still a single point of failure—if Facebook, Inc. goes out of business, or doesn’t speak your language, or decides it’s not worth allowing memes that upset the Chinese government, you’re kind of outta luck.
</p>
<p>
  It might be tempting to try and solve these issues by going in the complete opposite direction: no moderation whatsoever.
  But then you’re stuck with the original problem of your feed being filled with harmful content!
  If a totally unmoderated platform isn’t overrun with spam yet, that just means it isn’t popular enough for spammers to notice it.
</p>
<p>
  Ad blockers are faced with a similar problem, and they’ve found a very good middle-ground solution.
  If you open uBlock Origin’s settings page, there’s a “Filter lists” tab where you can choose which people’s rules to use.
  (Each rule is the name of one specific website or advertisement to block.)
  There are some filter lists that almost everyone uses, like <a href="https://easylist.to/">EasyList and EasyPrivacy</a>, and there are some that are more niche or regional, like <a href="https://github.com/lassekongo83/Frellwits-filter-lists">Frellwit’s Swedish Filter</a> and <a href="https://github.com/olegwukr/polish-privacy-filters" lang="pl">Oficjalne polskie filtry przeciwko alertom o Adblocku</a>.
  You can also write your own rules, both to block things that EasyList missed and to <em>un</em>-block things that EasyList blocked by mistake.
</p>
<p>
  Content moderation on a social network could work in a very similar way, with different groups of moderators creating different lists of banned users and deleted posts.
  You could have lists almost everyone uses that block things like spam, and you could also have lists for more controversial stuff like adult content and criticism of the Chinese government.
  And sort of like how “shared blocklists” work on Twitter, smaller groups could create their own lists of users and posts to ban.
</p>
<p>
  But if someone really needed to see a post that had been deleted by a moderator—like if they were worried it contained their personal information or threats against them—they could manually override that block.
  (They’d be able to see it, but it wouldn’t affect anyone else.)
</p>
<hr>
<p>
  Put together, I think these three features would be really powerful for a decentralized social network.
  If you know of a project that offers all three of these, or you’re working on one, please let me know by emailing <a href="mailto:carter.sande@duodecima.technology">carter<wbr>.sande@<wbr>duodecima<wbr>.technology</a>.
  I’d be really excited to hear about it and try it out for myself!
  And hopefully, lots of other people would be too.
</p>
</div></div>]]>
            </description>
            <link>https://carter.sande.duodecima.technology/decentralized-wishlist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25731419</guid>
            <pubDate>Mon, 11 Jan 2021 16:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A bit on scaling chess.com's database]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25730778">thread link</a>) | @ikonic89
<br/>
January 11, 2021 | https://unstructed.tech/2021/01/11/your-legacy-database-is-outgrowing-itself/ | <a href="https://web.archive.org/web/*/https://unstructed.tech/2021/01/11/your-legacy-database-is-outgrowing-itself/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Do you feel your database is growing too big or too old? Hard to maintain? Well, I hope I might be able to help you a bit with that. The text you’re about to read is a real life experience of scaling a monolith database to be able to support a top 250-website (according to <a href="https://www.alexa.com/" target="_blank" rel="noreferrer noopener">alexa.com</a>). At the moment of writing this article, <a href="https://www.alexa.com/" target="_blank" rel="noreferrer noopener">alexa.com</a> ranked <a href="https://www.chess.com/" target="_blank" rel="noreferrer noopener">chess.com</a> at 215th place in the world. We’ve got over 4M unique daily users and over 7B queries hitting all our MySQL databases combined. Went from under 1M unique users a day a year ago to 1.3M in March, to over 4M at the moment, with over 8M games played each day. I know it’s no where near the biggest players on the market, but our experience could help you “fix” your monolith database, and scale it to new heights.</p>



<p>Disclosure: <em>This is my first ever article, and it’s too long as it is – but I had to cut probably as much text as you see here in order to make it actually readable. So, some things might be confusing or not well explained, and I’m sorry for that. Hit me up on <a href="https://www.linkedin.com/in/ikonic/" target="_blank" rel="noreferrer noopener">LinkedIn</a>, and we can get into a deeper discussion.</em></p>



<p>Update: after reading a lot of comments, I’d like to add/clarify a few things. We do use caching, extensively. If we didn’t we wouldn’t survive a day. We do use Redis, often pushing it to its extremes. We’ve tested MongoDB and Vitess, but they didn’t do it for us. </p>



<h2>The state in which we were just couple of years ago</h2>



<p>Somewhere mid-2019 we’ve started noticing that our main DB cluster is slowly growing a bit too big. We had three smaller and less used databases on the side, but everything was always added to the main one. Surprisingly, it was in a fairly decent state for a database that started its life over 12 years ago. Not many unused/redundant indexes, the ones that were there were mostly good. We constantly monitored and improved heavy/slow queries. A nice chunk of data was denormalized, as well. No foreign keys, many things were done in the code itself (filtering, sorting, etc, to make sure the DB only ever uses the most efficient indexes) running on the latest version of MySQL, etc, etc. It wasn’t neglected and it evolved over time into something that did a good job for us. </p>



<p>Disclaimer: I’m not recommending anyone to do these sorts of micro-optimizations. They are working for chess.com, on its scale. We benchmark almost anything we’ve never done before, and see how it turns out, before actually implementing it. We know these work <strong>for us</strong>.</p>



<div>
<p>The biggest problem we were facing at that point in time was that altering almost any table required taking half the hosts out of rotation, run the alter there, put it back in rotation, alter the other half, put them back in. We had to do it off-peak, as taking half the hosts out during the peak time would probably result in the other half crashing. As the website was growing, old features got new improvements, so we had to run alters a lot (if you’re in the business, you know how it goes). Altering would’ve been far less stressful if we could could pull just a small set of tables out of rotation, instead of the entire DB. So, we created a 5 year plan for our main cluster (and boy, were we wrong about our timeline), in which we were to split the database into many smaller ones, and that would make things easier to maintain (we were right about this, at least). The plan assumed ~25% yearly growth, which was what we were seeing in previous years.</p>



<div>
<figure><img loading="lazy" width="920" height="1000" src="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png" data-src="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png" alt="" data-srcset="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png 920w, https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1-276x300.png 276w, https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1-768x835.png 768w" data-sizes="(max-width: 920px) 100vw, 920px" srcset="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png 920w, https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1-276x300.png 276w, https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1-768x835.png 768w"><figcaption>Where we were ~2 years ago</figcaption></figure>
</div>
</div>



<h2>The REAL problem appears and our plan implodes</h2>



<p>You’re all familiar with COVID-19, and how all of that went. Guess what – we weren’t really ready (or we didn’t expect it to have the impact it had on or traffic). Interest in chess exploded when (most of) Europe went into a lockdown. Fun fact – we could tell which country went into a lockdown just by looking at our registrations by country – it was so clear. And numbers skyrocketed across the board. Funnily enough, all our databases were doing fine (not great, but they handled the traffic). But at the same time we noticed that our “reports” host was constantly struggling to keep up with the production hosts (i.e., it was often 30-60 seconds behind on replication), which prompted us to analyse our replication stream and its remaining capacity. And it was close to being full, at peak traffic reaching over 95% of the capacity. At that point we knew that USA (where most of our players are from) would also go into a lock down, soon, and that would mean that our replicas wouldn’t be able to keep up with all the writes going to the master (or even if we just keep growing slowly). This would mean the end of <a href="http://www.chess.com/" target="_blank" rel="noreferrer noopener">chess.com</a>, as the code isn’t ready to handle big replication delays when reading data from replicas, and sending all the selects to master would take it down. That made our goal clear: decrease number of writes going to the main cluster, and do it as quickly as possible! This was actually part of our aforementioned plan, but that plan stretched over 5 years. Now we had just one or two months to do that. </p>



<h2>The solution</h2>



<p>How to decrease number of writes to a single DB? Sounds simple – identify tables that are written the most and rip them away from the DB. That way the number of writes handled remains the same, but they are just split into two separate streams. These can be either tables that get a lot of inserts, or not as many inserts, but with records that are frequently updated. Store them elsewhere. How to do it with no downtime? As you’d imagine – not really that simple. </p>



<p>We first identified all the tables that had most updates (inserts, deletes or updates). Most of them were nicely grouped together based on the feature for which they were used (most of game related tables would be written at a similar pace, etc), and we managed to gather a list of 10-15 tables, for 3 different website features. As soon as we started investigating them, another problem was revealed – since we can’t “join” between databases on different hosts, we would need to move as many tables as the feature used to make the project simpler (we were already aware of this, since when “the plan” first came into place, we did something similar for 3 smaller, less used tables as a PoC, and it turned out fine). </p>



<p>The 3 features we identified as high-traffic were logs (not really a feature, and not really logs, they were just poorly named), games (like you’d expect on a chess gaming platform) and puzzles. For logs we’ve found just 3 very isolated tables, which meant not a lot query/code changes were required. Similar for games, as well. But puzzles had over 15 tables to move, and the queries on those tables had lots of joins towards tables that were to remain in the main database cluster. We’ve rallied our troops, pulled over half of our backend developers, split them into teams, and started pushing on all of these in parallel. </p>



<p>It took just one week to move logs into its dedicated database, running on two hosts, which gave us some breathing space, as those had the most writes, by far. One more month to move games (which was oh so scary, as any mistake there would be a disaster, considering that’s the whole point of the website), and puzzles took over 2 months. After these, we were well under 80% of the replication capacity in the peak, which meant we had time to regroup, and plan upcoming projects a bit better.</p>



<h2>The execution</h2>



<p>So, how did we do it? </p>



<p>As you might assume, there are two sides to a project like this – code and database, and both require a lot of work. On the code side, there are a few prerequisites for a project like this one. First of all, we need some sort of <a href="https://en.wikipedia.org/wiki/Feature_toggle" target="_blank" rel="noreferrer noopener">feature flag</a> (aka feature toggle) system, either internal or 3rd party. Ours is custom built, pretty extensive, and maybe a topic for another post. The bare minimum the feature flag system needs to provide is to allow or deny access to a percent of checks from 0 to 100 percent. Another really useful thing to have is a good test coverage. Our entire codebase was rewritten from scratch a few years ago, so we were lucky enough to have that, as it saved us a couple of times.</p>



<div>
<p>Between code changes and database changes, some things can be done in parallel and some require going by numbers. The easiest thing to start with is to set up the new database. All our new databases pulled from the main one (we call them partitions, and this process partitioning) end up on a 2-host setup (master and failover-master (replica)), but it can really be anything we want. On the partition cluster, we create a new database with identical schema to the one we’re trying to split (just name it according our needs, in this case the first one was named<code> logs</code>). Then a backup of the main database is imported, after which we hook up the master of the partition cluster to be a replica of the main master (this is why we need the identical schema and backup import). This way the new cluster becomes just like any main cluster replica, only with a differently named database. Then it just sits there, looking pretty, replicating traffic, and being up-to-date with the rest of the cluster while we work on the code side of this project.</p>



<div>
<figure><img loading="lazy" width="919" height="1024" src="http://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png" data-src="http://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png" alt="" data-srcset="https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png 919w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-269x300.png 269w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-768x855.png 768w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL.png 1160w" data-sizes="(max-width: 919px) 100vw, 919px" srcset="https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png 919w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-269x300.png 269w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL-768x855.png 768w, https://unstructed.tech/wp-content/uploads/2021/01/Before-DL.png 1160w"><figcaption>This is what the cluster looks like after adding new hosts</figcaption></figure>
</div>
</div>



<p>Before we started working on this project, we essentially had 2 connections open to the database from the code: read only connection hitting replicas and read/write connection pointing to the master. Both actually hitting HAProxy, to get where they need to go. First thing we did is to create a parallel set of connections, where read/write connection goes to the <code>Partition Master</code> and read-only connection to the <code>Partition Replica</code>.</p>



<p><em>Chess.com is written in PHP, so I’ll use PHP examples to illustrate the needed changes, but I’ll keep it pseudo enough so that anyone can understand what’s going on (you’d be surprised how many websites in the top 1k are written in PHP, and how easy it is to scale PHP to those heights. Maybe a topic for another post.). </em></p>



<p>Co…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unstructed.tech/2021/01/11/your-legacy-database-is-outgrowing-itself/">https://unstructed.tech/2021/01/11/your-legacy-database-is-outgrowing-itself/</a></em></p>]]>
            </description>
            <link>https://unstructed.tech/2021/01/11/your-legacy-database-is-outgrowing-itself/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25730778</guid>
            <pubDate>Mon, 11 Jan 2021 16:07:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steam's login method is kinda interesting]]>
            </title>
            <description>
<![CDATA[
Score 487 | Comments 214 (<a href="https://news.ycombinator.com/item?id=25730145">thread link</a>) | @zertrin
<br/>
January 11, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25730145</guid>
            <pubDate>Mon, 11 Jan 2021 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Experts Real?]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25730008">thread link</a>) | @tlb
<br/>
January 11, 2021 | https://fantasticanachronism.com/2021/01/11/are-experts-real/ | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2021/01/11/are-experts-real/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I vacillate between two modes: sometimes I think every scientific and professional field is genuinely complex, requiring years if not decades of specialization to truly understand even a small sliver of it, and the experts<span><a href="#fn5071682221" rel="footnote"><sup id="fnref5071682221">1</sup></a></span> at the apex of these fields have deep insights about their subject matter. The evidence in favor of this view seems pretty good, a quick look at the technology, health, and wealth around us ought to convince anyone.</p><p>But sometimes one of these masters at the top of the mountain will say something so obviously incorrect, something even an amateur can see is false, that the only possible explanation is that they understand very little about their field. Sometimes vaguely smart generalists with some basic stats knowledge objectively outperform these experts. And if the masters at the top of the mountain aren't real, then that undermines the entire hierarchy of expertise.</p><p>Some hierarchies are undeniably legitimate. Chess, for example, has the top players constantly battling each other, new players trying to break in (and sometimes succeeding), and it's all tracked by a transparent rating algorithm that is constantly updated. Even at the far right tails of these rankings, there are significant and undeniable skill gaps. There is simply no way Magnus Carlsen is secretly bad at chess.</p><p>Science would seem like another such hierarchy. The people at the top have passed through a long series of tests designed to evaluate their skills and knowledge, winnow out the undeserving, and provide specialized training: undergrad, PhD, tenure track position, with an armada of publications and citations along the way.</p><p>Anyone who has survived the torments of tertiary education will have had the experience of getting a broad look at a field in a 101 class, then drilling deeper into specific subfields in more advanced classes, and then into yet more specific sub-subfields in yet more advanced classes, until eventually you're stuck at home on a Saturday night reading an article in an obscure Belgian journal titled "Iron Content in Antwerp Horseshoes, 1791-1794: Trade and Equestrian Culture Under the Habsburgs", and the list of references carries the threatening implication of an entire literature on the equestrian metallurgy of the Low Countries, with academics split into factions justifying or expostulating the irreconcilable implications of rival theories. And then you realize that there's an equally obscure literature about every single subfield-of-a-subfield-of-a-subfield. You realize that you will never be a polymath and that simply catching up with the state of the art in one tiny corner of knowledge is a daunting proposition. The idea of exiting this ridiculous sham we call life flashes in your mind, but you dismiss it and heroically persist in your quest to understand those horseshoes instead.</p><p>It is absurd to think that after such lengthy studies and deep specialization the experts could be secret frauds. As absurd as the idea that Magnus Carlsen secretly can't play Chess. Right?</p><p>Imagine if tomorrow it was revealed that Magnus Carlsen actually doesn't know how to play chess. You can't then just turn to the #2 and go "oh well, Carsen was fake but at least we have Fabiano Caruana, he's the real deal"—if Carlsen is fake that also implicates every player who has played against him, every tournament organizer, and so on. The entire hierarchy comes into question. Even worse, imagine if it was revealed that Carlsen was a fake, but he still continued to be ranked #1 afterwards. So when I observe extreme credential-competence disparities in science or government bureaucracies, I begin to suspect the entire system.<span><a href="#fn5071682222" rel="footnote"><sup id="fnref5071682222">2</sup></a></span> Let's take a look at some examples.</p><h4 id="59"><a href="#59" title="59"></a>59</h4><p>In 2015, Viechtbauer et al. published <em>A simple formula for the calculation of sample size in pilot studies</em>, in which they describe a simple method for calculating the required N for an x% chance of detecting a certain effect based on the proportion of participants who exhibit the effect. In the paper, they give an <em>example</em> of such a calculation, writing that if 5% of participants exhibit a problem, the study needs N=59 for a 95% probability of detecting the problem. The actual required N will, of course, vary depending on the prevalence of the effect being studied.</p><p>If you look at the <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=2005&amp;sciodt=0%2C5&amp;cites=8563214002358604992&amp;scipsc=1&amp;q=59&amp;btnG=" target="_blank" rel="noopener">papers citing Viechtbauer et al.</a>, you will find dozens of them simply using N=59, regardless of the problem they're studying, and explaining that they're using that sample size because of the Viechtbauer paper! The authors of these studies are professors at real universities, working in disciplines based almost entirely on statistical analyses. The papers passed through editors and peer reviewers. In <a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">my piece on the replication crisis</a>, I wrote that I find it difficult to believe that social scientists don't know what they're doing when they publish weak studies; one of the most common responses from scientists was "no, they genuinely don't understand elementary statistics". It still seems absurd (just count the years from undergrad to PhD, how do you fail to pick this stuff up just by osmosis?) but it also appears to be true. How does this happen? Can you imagine a physicist who doesn't understand basic calculus? And if this is the level of competence among tenured professors, what is going on among the people below them in the hierarchy of expertise?</p><h4 id="Masks"><a href="#Masks" title="Masks"></a>Masks</h4><p>Epidemiologists have beclowned themselves in all sorts of ways over the last year, but this is one of my favorites. Michelle Odden, professor of epidemiology and population health at Stanford (to be fair she does focus on cardiovascular rather than infectious disease, but then perhaps she shouldn't appeal to her credentials):</p><p><img src="https://fantasticanachronism.com/images/experts_masks-097c3b01fdd318edec9f70415bc95d6b.jpg"></p><h4 id="Time-Diversification"><a href="#Time-Diversification" title="Time Diversification"></a>Time Diversification</h4><p>CalPERS is the largest pension fund in the United States, managing about $400 billion dollars. <a href="https://youtu.be/qFIcakrlowE?t=4743" target="_blank" rel="noopener">Here</a> is a video of a meeting of the CalPERS investment committee, in which you will hear Chief Investment Officer Yu Meng say two incredible things:</p><ol><li>That he can pick active managers who will generate alpha, and this decreases portfolio risk.</li><li>That infrequent model-based valuation of investments makes them <em>less risky</em> compared to those traded on a market, due to "time diversification".</li></ol><p>This is utter nonsense, of course. When someone questions him, he retorts with "I might have to go back to school to get another PhD". The appeal to credentials is typical when fake expertise is questioned. Can you imagine Magnus Carlsen appealing to a piece of paper saying he has a PhD in chessology to explain why he's good?<span><a href="#fn5071682223" rel="footnote"><sup id="fnref5071682223">3</sup></a></span></p><h4 id="Feedback-Loops"><a href="#Feedback-Loops" title="Feedback Loops"></a>Feedback Loops</h4><p>It all comes down to feedback loops. The optimal environment for developing and recognizing expertise is one which allows for clear predictions and provides timely, objective feedback along with a system that promotes the use of that feedback for future improvement. Capitalism and evolution work so well because of their merciless feedback mechanisms.<span><a href="#fn5071682224" rel="footnote"><sup id="fnref5071682224">4</sup></a></span></p><p>The basic sciences have a great environment for such feedback loops: if physics was fake, CPUs wouldn't work, rockets wouldn't go to the moon, and so on. But if social priming is fake, well...? There are other factors at play, too, some of them rather nebulous: there's more to science than just running experiments and publishing stuff. Mertonian, distributed, informal community norms play a significant role in aligning prestige with real expertise, and these broader social mechanisms are the keystone that holds everything together. But such things are hard to measure and impossible to engineer. And can such an honor system persist indefinitely or will it eventually be subverted by bad actors?<span><a href="#fn5071682225" rel="footnote"><sup id="fnref5071682225">5</sup></a></span></p><p>What does feedback look like in the social sciences? The norms don't seem to be operating very well. There's a small probability that your work will be replicated at some point, but really the main feedback mechanism is "impact" (in other words, citations). Since <a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/#or-Maybe-They-Don-39-t">citations in the social sciences are not related to truth</a>, this is useless at best. Can you imagine if fake crank theories in physics got as many citations as the papers from CERN? Notorious fraud Brian Wansink racked up 2500 citations in 2020, two years after he was forced to resign. There's your social science feedback loop!</p><p>The feedback loops of the academy are also predicated on the current credentialed insiders <em>actually being experts</em>. But if the N=59 crew are making such ridiculous errors in their <em>own</em> papers, they obviously don't have the ability to judge <em>other</em> people's papers either, and neither do the editors and reviewers who allow such things to be published—for the feedback loop to work properly you need both the cultural norms and genuinely competent individuals to apply them.</p><p>The candidate gene literature (of which <a href="https://slatestarcodex.com/2019/05/07/5-httlpr-a-pointed-review/" target="_blank" rel="noopener">5-HTTLPR</a> was a subset) is an example of feedback and successful course correction: many years and thousands of papers were wasted on something that ended up being completely untrue, and while a few of these papers still trickle in, these days the approach has been essentially abandoned and replaced by genome-wide association studies. <a href="https://slatestarcodex.com/2017/04/17/learning-to-love-scientific-consensus/" target="_blank" rel="noopener">Scott Alexander is rather sanguine</a> about the ability of scientific feedback mechanisms to eventually reach a true consensus, but I'm more skeptical. In psychology, the methodological deficiencies of today are the more or less same ones as those of the <a href="https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1959.10501497" target="_blank" rel="noopener">of the 1950s</a>, with no hope for change.</p><p>Sometimes we can't wait a decade or two for the feedback to work, the current pandemic being a good example. Being right about masks <em>eventually</em> isn't good enough. The loop there needs to be tight, feedback immediate. Blindly relying on the predictions of this or that model from this or that university is absurd. You need systems with built-in, automatic mechanisms for feedback and course correction, subsidized markets being the very best one. Tom Liptay (a superforecaster) has been <a href="https://www.maby.app/covid/" target="_blank" rel="noopener">scoring his predictions against those of experts</a>; naturally he's winning. And that's just one person, imagine hundreds of them combined, with a monetary incentive on top.</p><h4 id="Uniformity"><a href="#Uniformity" title="Uniformity"></a>Uniformity</h4><p>There's a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2021/01/11/are-experts-real/">https://fantasticanachronism.com/2021/01/11/are-experts-real/</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2021/01/11/are-experts-real/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25730008</guid>
            <pubDate>Mon, 11 Jan 2021 15:17:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Data Engineer in 2021]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25728198">thread link</a>) | @adilkhash
<br/>
January 11, 2021 | https://khashtamov.com/en/how-to-become-a-data-engineer/ | <a href="https://web.archive.org/web/*/https://khashtamov.com/en/how-to-become-a-data-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    
                    <p>The demand for data engineers is growing rapidly. According to <a href="http://hired.com/" target="_blank" rel="noopener noreferrer" data-token-index="1" data-reactroot="">hired.com</a> the <a href="https://hired.com/state-of-software-engineers" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">demand has increased by 45%</a> in 2019. The median salary for Data Engineers in SF Bay Area is around $160k. So the question is: how to become a data engineer?<!--StartFragment--></p>
<h2>What Data Engineering is</h2>
<p>Data engineering is closely related to data as you can see from its name. But if data analytics usually means extracting insights from existing data, data engineering means the process of building infrastructure to deliver, store and process the data. According to <a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007">The AI Hierarchy of Needs</a>, the data engineering proccess is located at the very bottom: Collect, Move &amp; Store, Data Preparation. So if your organization wants to be data/AI-driven then they should hire/train data engineers.</p>
<figure><img src="https://khashtamov.com/uploads/redactor/1_7IMev5xslc9FLxr9hHhpFw.png" data-image="1_7IMev5xslc9FLxr9hHhpFw.png"></figure>

<p>But what data engineers actually do? The amount of data is growing rapidly every single day. We are contemplating the new era where everybody can do a content from their mobile phone and other gadgets. Even small devices are connected to the Internet. Data engineers from the past were responsible for writing complex SQL queries, building ETL (extract, transform &amp; load) processes using big enterprise tools like Informatica ETL, Pentaho ETL, Talend etc. But now the market demands more broader skillset. If you want to work as a data engineer you need to have:</p>
<ul><li>Intermediate knowledge of SQL and Python</li><li>Experience working with cloud providers like AWS, Azure or GCP</li><li>The knowledge of Java/Scala is a big plus</li><li>Understading SQL/NoSQL databases (data modeling, data warehousing, performance optimization)</li></ul>
<p>The skillset is very similar to what Backend engineers usually know. In reality if an organization is growing in terms of data the ideal candidate to transform into data engineer is a backend engineer.</p>

<ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-3273608550190378" data-ad-slot="9434009847"></ins>


<p>The particular technologies and tools could differ due to company size, data volumes and data velocity. If we look at the FAANG for example, they usually require:</p>
<ul><li>Knowledge of Python, Java or Scala</li><li>Experience working with Big data tools like Apache Hadoop, Kafka and Spark</li><li>Solid knowledge of algorithms and data structures</li><li>Undestanding of distributed systems</li><li>Experience with Business Intelligence tools like Tableau, QlikView, Looker or Superset</li></ul>
<h2>Data Engineer's Skillset</h2>
<p>Data engineering is an engineering area that is why the knowledge of computer science fundamentals is required, especially the understanding of most popular algorithms and data structures (Hello Mr. Cormen!).</p>
<p>Because data engineers deal with the data on a daily basis understading how databases work is a huge plus. For example, the most popular SQL databases like SQLite, PostgreSQL, MySQL use B-Tree data structure under the hood.</p>
<h3>Algorithms &amp; Data Structures</h3>
<p>If you prefer video courses I would recommend to look at the <a href="https://www.coursera.org/specializations/data-structures-algorithms">Data Structures and Algorithms Specialization</a>. I took these courses and think they are quite good as a starting point.</p>
<p>Speaking about talks I would highly recommend take a look at Alex Petrov's presentation called <em>What Every Programmer has to know about Database Storage:</em></p>
<figure><iframe width="100%" height="497" src="https://www.youtube.com/embed/e1wbQPbFZdk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe></figure>
<p>Alex has a great series of posts related to databases:</p>
<ul>
<li><a href="https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017">On Disk IO, Part 1: Flavors of IO</a></li>
<li><a href="https://medium.com/databasss/on-disk-io-part-2-more-flavours-of-io-c945db3edb13">On Disk IO, Part 2: More Flavours of IO</a></li>
<li><a href="https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f">On Disk IO, Part 3: LSM Trees</a></li>
<li><a href="https://medium.com/databasss/on-disk-storage-part-4-b-trees-30791060741">On Disk IO, Part 4: B-Trees and RUM Conjecture</a></li>
<li><a href="https://medium.com/databasss/on-disk-io-access-patterns-in-lsm-trees-2ba8dffc05f9">On Disk IO, Part 5: Access Patterns in LSM Trees</a></li>
</ul>
<p>Courses, video presentations are good but what about books? I would recommend the only book by Thomas Cormen and friends called <a href="https://www.amazon.com/gp/product/0262033844/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0262033844&amp;linkCode=as2&amp;tag=adilkhash-20&amp;linkId=74742875db503b1a899ca35159749067">Introduction to Algorithms</a>. The most comprehensive reference on algorithms and data structures. To practice and strengthen your knowlegde go to <a href="http://leetcode.com/">leetcode.com</a> and start solving problems. Practice makes perfect.</p>
<p>Databases are great, Carnegie Mellon University uploads their lessons to Youtube:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=oeYBdghaIjc&amp;list=PLSE8ODhjZXjbohkNBWQs_otTrBTrjyohi">Introduction to Database Systems (Fall 2019)</a></li>
<li><a href="https://www.youtube.com/watch?v=SdW5RKUboKc&amp;list=PLSE8ODhjZXjasmrEd2_Yi1deeE360zv5O">Advanced Database Systems (Spring 2020)</a></li>
</ul>
<h3>SQL — the lingua franca for databases</h3>
<p>SQL was developed back in 70s and still is the most popular language to work with data. Periodically some experts claim that SQL is going to die very soon, but it is still alive despite many rumors. I think we will stick to SQL for another decade or two (or even more). If you look at the modern and popular databases you will see that almost all of them support SQL:</p>
<ul>
<li>PostgreSQL, MySQL, MS SQL Server, Oracle DB</li>
<li>Amazon Redshift, Apache Druid, Yandex ClickHouse</li>
<li>HP Vertica, Greenplum</li>
</ul>
<p>In a big data ecosystem there are many different SQL engines: Presto (Trino), Hive, Impala etc. I would highly recommend to invest some time to master SQL.</p>
<p>If you are new to SQL, start with the Mode's SQL guide: <a href="https://mode.com/sql-tutorial/introduction-to-sql/">Introduction to SQL</a>. If you feel comfortable you can continue with the <a href="https://bit.ly/2XrRH4i" target="_blank" rel="nofollow noopener noindex">DataCamp's interactive courses</a>. I would recommend these:</p>
<ul>
<li><a href="https://www.datacamp.com/courses/intermediate-sql?tap_a=5644-dce66f&amp;tap_s=1331588-6fc352&amp;utm_medium=affiliate&amp;utm_source=adylzhankhashtamov" target="_blank" rel="nofollow noopener noindex">Intermediate SQL</a></li>
<li><a href="https://www.datacamp.com/courses/joining-data-in-postgresql?tap_a=5644-dce66f&amp;tap_s=1331588-6fc352&amp;utm_medium=affiliate&amp;utm_source=adylzhankhashtamov" target="_blank" rel="nofollow noopener noindex">Joining Data in SQL</a></li>
<li><a href="https://datacamp.com/courses/postgresql-summary-stats-and-window-functions?tap_a=5644-dce66f&amp;tap_s=1331588-6fc352&amp;utm_medium=affiliate&amp;utm_source=adylzhankhashtamov" target="_blank" rel="nofollow noopener noindex">PostgreSQL Summary Stats and Window Functions</a></li>
</ul>
<p>The best resources on SQL are <a href="https://modern-sql.com/">Modern SQL</a> and <a href="https://use-the-index-luke.com/">Use The Index, Luke!</a> Practice makes perfect that is why go to <a href="https://leetcode.com/problemset/database/">Leetcode Databases problemset</a> and start practicing 💪 By the way, do not forget to read my article on <a href="https://khashtamov.com/en/sql-window-functions/">SQL window functions</a> as well.</p>
<h3>Programming: Python, Java and Scala</h3>
<p>Python is a very popular programming language to build web apps as well as for data analytics &amp; science. It has a very rich ecosystem and huge community. According to <a href="https://www.tiobe.com/tiobe-index/">TIOBE Index</a> Python is in the Top 3 widely used programming languages after C &amp; Java.</p>
<p>Speaking about other 2 languages, many big data systems are written in Java or Scala:</p>
<ul>
<li>Apache Kafka (Scala)</li>
<li>Hadoop HDFS (Java)</li>
<li>Apache Spark (Scala)</li>
<li>Apache Cassandra (Java)</li>
<li>HBase (Java)</li>
<li>Apache Hive, Presto in Java</li>
</ul>
<p>In order to undestand how these systems work I would recommend to know the language in which they are written. The biggest concern with Python is its poor performance hence the knowledge of a more efficient language will be a big plus to your skillset.</p>
<p>If you are interested in Scala, I would recommend to take a look at <a href="https://twitter.github.io/scala_school/">Twitter's Scala School</a>. The book <a href="https://www.amazon.com/gp/product/0981531687/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0981531687&amp;linkCode=as2&amp;tag=adilkhash-20&amp;linkId=69314619f1e546e3921eb97c72cf4850">Programming in Scala</a> by its creator is also a good starting point.</p>
<h3>The Big Data Tools</h3>
<p>There are lots of different technologies in a Big Data landscape. The most popular are:</p>
<ul>
<li><strong>Apache Kafka</strong> is the leading message queue/event bus/event streaming</li>
<li><strong>Apache Spark</strong> is the unified analytics engine for large-scale data processing</li>
<li><strong>Apache Hadoop</strong>, the big data framework which consists of different tools, libraries and frameworks including distributed file system (HDFS), Apache Hive, HBase etc.</li>
<li><strong>Apache Druid</strong> is a real-time analytics database</li>
</ul>
<p>It is really difficult to learn everything that is why focus on the most popular and learn fundamental concepts behind them. For example, back in 2013 Jay Kreps (co-founder of Apache Kafka) wrote the paper called <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">The Log: What every software engineer should know about real-time data's unifying abstraction</a>.</p>
<h3>Cloud Platforms</h3>
<p>Everything goes to the clouds. You should have experience working with at least one cloud provider. I would recommend go with the <strong>Amazon Web Services</strong> which is the leading cloud provider in the world. The second place goes to the <strong>Microsoft Azure</strong>, the third place takes <strong>Google Cloud Platform</strong>.</p>
<p>All providers have certifications. For example, the most suitable certification for a data engineer in AWS is <a href="https://aws.amazon.com/ru/certification/certified-data-analytics-specialty/">AWS Certified Data Analytics – Specialty</a>. If you decide to proceed with GCP the right choice is <a href="https://cloud.google.com/certification/data-engineer">Professional Data Engineer</a>, for MSA is <a href="https://docs.microsoft.com/en-us/learn/certifications/azure-data-engineer">Azure Data Engineer Associate</a>.</p>
<h3>Fundamentals of Distributed Systems</h3>
<p>The amount of data generated nowadays is tremendous. You cannot fit it into one computer. The data should be distributed across different nodes. If you want to be a good data engineer you have to understand the fundamentals of distributed systems. There are lots of resources where you can start your journey into this field:</p>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLrw6a1wE39_tb2fErI4-WkMbsvGQk9_UB">Distributed Systems</a> lectures from MIT by Robert Morris</li>
<li><a href="https://www.youtube.com/playlist?list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB">Distributed Systems</a> lectures by Martin Kleppmann</li>
<li><a href="https://www.youtube.com/playlist?list=PLNPUF5QyWU8O0Wd8QDh9KaM1ggsxspJ31">Distributed Systems</a> by Lindsey Kuper</li>
</ul>
<p>I would also highly recommend the book <a href="https://www.amazon.com/gp/product/1449373321/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449373321&amp;linkCode=as2&amp;tag=adilkhash-20&amp;linkId=e7e0e096aa5761066245eb90965ac849">Designing Data-Intensive Applications</a> by Martin Kleppmann. He has a <a href="https://martin.kleppmann.com/">blog</a>. Also if you prefer blogs I would recommend take a look at the <a href="https://medium.com/baseds">series of posts</a> about distributed systems by Vaidehi Joshi.</p>
<h3>Data Pipelines</h3>
<p>Building a data pipeline is one of the main responsibilities of a data engineer. Data pipeline is a process of data consolidation. Data engineer should be able to reliably deliver, load and transform data from multiple sources into a specific destination, usually it is central data warehouse or data lake. There are many tools which can help you build this process. Take a look at the <a href="https://khashtamov.com/en/introduction-to-apache-airflow/">Apache Airflow</a>, <a href="https://github.com/spotify/luigi">Luigi</a> from Spotify, <a href="https://www.prefect.io/">Prefect</a> or <a href="https://dagster.io/">Dagster</a>. If you prefer nocode solution <a href="https://nifi.apache.org/">Apache NiFi</a> is a way to go.</p>
<h2>Summary</h2>
<p>Data engineer is a team player who is working with data analysts, scientists, infrastructure engineers and other stakeholders. So do not forget about soft skills like empathy, understanding a business domain, open-mindedness etc.</p>
<p>If you want to add something feel free to add a comment down below.</p>




                    <section>
                        <h3>💌 Join the mailing list</h3>
                        <p>If you like the content I produce, please join my mailing list to stay tuned.</p>
                        
                    </section>
                </article></div>]]>
            </description>
            <link>https://khashtamov.com/en/how-to-become-a-data-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25728198</guid>
            <pubDate>Mon, 11 Jan 2021 12:49:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing Your Private YouTube Videos, One Frame at a Time]]>
            </title>
            <description>
<![CDATA[
Score 1147 | Comments 178 (<a href="https://news.ycombinator.com/item?id=25728175">thread link</a>) | @gbrown_
<br/>
January 11, 2021 | https://bugs.xdavidhu.me/google/2021/01/11/stealing-your-private-videos-one-frame-at-a-time/ | <a href="https://web.archive.org/web/*/https://bugs.xdavidhu.me/google/2021/01/11/stealing-your-private-videos-one-frame-at-a-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Back in December 2019, a few months after I started hacking on Google VRP, I was looking at YouTube. I wanted to find a way to get access to a <code>Private</code> video which I did not own.</p>

<p>When you upload a video to YouTube, you can select between 3 privacy settings. <code>Public</code>, which means that anyone can find and watch your video, <code>Unlisted</code>, which only allows users who know the video ID (the URL) to watch the video, and <code>Private</code>, where only you can watch the video, or other accounts you’ve explicitly given permission to do so.</p>

<p>First thing I did was to upload a video to my second testing account’s YouTube channel, and set the video’s privacy to <code>Private</code>, so I can use that video for testing. <em>(Remember, always only test against resources/accounts you own!)</em> If I can find a way to access that video with my first testing account, we have a bug.</p>

<p>With my first account, I started using YouTube, trying every feature, pressing every button I could find, and whenever I saw an HTTP request with a video ID in it, I changed it to the target <code>Private</code> video, hoping that I can leak some information about it, but I wasn’t really getting any success. The main YouTube site (at least the endpoints I have tested), seems to always check if the video was <code>Private</code> or not, and when trying to request info about the target <code>Private</code> video, they always returned errors such as <code>This video is private!</code>.</p>

<p>I needed to find another way.</p>

<p>A great thing to do in a situation like this, is to try to look for other products/services which are not your main target, but are somehow interacting with its resources internally. If they have access to its resources, it might be possible that they don’t have every level of protection that the main product has.</p>

<p>An interesting target which matched these requirements was Google Ads. This is the product which advertisers use to create ads across all Google services, <em>including YouTube</em>. So, the ads you get before YouTube videos are set up by advertisers here, on the Google Ads platform.</p>

<p>So I created a Google Ads account, and created a new advertisement, which would play a video of mine as a skippable ad for YouTube users. During the ad creation process, I also tried to use the target <code>Private</code> video’s ID wherever I could, but no success.</p>

<p>After creating the ad, I started looking at all of the different Google Ads features. The thing was huge, it had a bunch of different settings/tools. I was trying to find anything that could be YouTube-related.</p>

<p>There was a page called <code>Videos</code>, where I could see a list of videos used by my advertisements. Clicking on a video opened up an <code>Analytics</code> section for that specific video. It had an embedded player, some statistics, and an interesting feature called <code>Moments</code>. It allowed advertisers to “mark” specific moments of the video, to see when different things happen (such as the timestamp of when the company logo appears). To be honest I am not quite sure what advertisers use this feature for, nevertheless, it seemed interesting:</p>

<p><img src="https://bugs.xdavidhu.me/assets/posts/2021-01-11-stealing-your-private-videos-one-frame-at-a-time/ads-moments.gif" alt="The Moments feature on the Ads console"></p>

<p>Looking at the proxy logs, every time I “marked a moment”, a <code>POST</code> request was made to a <code>/GetThumbnails</code> endpoint, with a body which included a video ID:</p>

<div><div><pre><code><span>POST</span> <span>/aw_video/_/rpc/VideoMomentService/GetThumbnails</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>ads.google.com</span>
<span>User-Agent</span><span>:</span> <span>Internet-Explorer-6</span>
<span>Cookie</span><span>:</span> <span>[redacted]</span>

__ar={"1":"kCTeqs1F4ME","2":"12240","3":"387719230"}
</code></pre></div></div>

<p>Where in the <code>__ar</code> parameter, <code>1</code> was the ID of the video and <code>2</code> was the time of the moment in milliseconds. The response was a base64 encoded image, which was the thumbnail displayed by Ads.</p>

<p>I did what I did a bunch of times already, and replaced the ID to my second account’s <code>Private</code> video in the request, and to my surprise, <strong>it returned a base64 response</strong>!</p>

<p>I quickly Googled “base64 to image”, and pasted the base64 into the first decoder I found, and it <strong>displayed a thumbnail from the target <code>Private</code> video</strong>! It worked! I have found a working IDOR <em>(Insecure Direct Object Reference)</em> bug, where I could get a frame from any private video on YouTube!</p>

<p>But I was like “hm, that is just one frame”. We can do better.</p>

<p>I wanted to make a proof of concept Python script which generates an actual, moving “video”. I searched for some calculations, and figured out that if the video is in 24 FPS, one frame stays on the screen for <code>33</code> milliseconds. So I just have to download every image starting from <code>0</code> milliseconds, incrementing by <code>33</code> milliseconds every time, and then construct some kind of video using all of the images I have acquired.</p>

<p>I wrote a quick and dirty POC which downloaded the frames for the first 3 seconds of a video, decoded them, and then generated a GIF. To test it, I have ran it against an old video of mine, which I had previously privated due to, of course, the <em>high level of cringe</em>:</p>

<iframe width="100%" height="315px" src="https://www.youtube.com/embed/G3bNbYRTxZM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>And there you have it, using this bug, any private YouTube video could have been downloaded by a malicious attacker, which to me feels like a pretty cool impact. But of course, it had a few limitations I couldn’t overcome:</p>

<ul>
  <li>In the real world you would have to know the ID of the target video. Mass-leaking those would be considered a bug on its own.</li>
  <li>Since these are just images, you can’t access audio.</li>
  <li>The resolution is very low. (but it’s high enough to see what is happening)</li>
</ul>

<p>The takeaway from this bug is that situations where two different products interact with each other under the hood are always a good area to focus on, since both product teams probably only know their own systems best, and might miss important details when working with a different product’s resources.</p>

<p>Looking for an IDOR like this can be a very repetitive and manual task, and nowadays I try to avoid just blindly changing IDs everywhere and hoping for the best. After you test a product for a while and get a feel of how it works internally, it might be more effective (and more fun) to try to think about different unexpected actions that the developers maybe didn’t think about based on what you saw already, or focus on features that just got released, or to just do any other non-mindless task. You will probably enjoy it more in the long term. In my opinion, the more you understand a system, the more ideas about how to break it will just naturally come to mind.</p>

<p>But again, even in the most robust and well tested systems, there is the chance that just swapping an ID in a request will get you a critical bug.</p>

<p>Thank you for reading! See you <a href="https://twitter.com/xdavidhu" target="_blank">next Monday</a> ;)</p>

<h3 id="timeline">Timeline:</h3>
<p>[Dec 11, 2019] - Bug reported <br>
[Dec 12, 2019] - Initial triage <br>
[Dec 20, 2019] - Bug accepted (P4 -&gt; P1) <br>
[Jan 08, 2020] - Bug mitigated by temporarily disabling the <code>Moments</code> feature <br>
[Jan 17, 2020] - Reward of <a href="https://www.google.com/about/appsecurity/reward-program/" target="_blank">$5000</a> issued <br>
[??? ??, 2020] - <code>Moments</code> re-enabled, now it checks if you have access to the video</p>

    </div></div>]]>
            </description>
            <link>https://bugs.xdavidhu.me/google/2021/01/11/stealing-your-private-videos-one-frame-at-a-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25728175</guid>
            <pubDate>Mon, 11 Jan 2021 12:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting goals for 2021 – A brief guide about personal goal setting]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25727832">thread link</a>) | @jonmal
<br/>
January 11, 2021 | https://blog.doit.io/goal-setting/ | <a href="https://web.archive.org/web/*/https://blog.doit.io/goal-setting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

           <!-- 
            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2020/10/GoalSetting.jpg 300w,
                            /content/images/size/w600/2020/10/GoalSetting.jpg 600w,
                            /content/images/size/w1000/2020/10/GoalSetting.jpg 1000w,
                            /content/images/size/w2000/2020/10/GoalSetting.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="/content/images/size/w600/2020/10/GoalSetting.jpg"
                    alt="SMART and Simple: How to Set and Achieve Personal Goals"
                />
            </figure>
            -->

            <section>
                <div>
                    <p>Goal setting is not a new idea. We all know that we have a much better chance of getting what we want in life if we purposefully set goals. </p><p>The content available on the subject is downright prolific. There is so much information out there, in fact, that it can be overwhelming to pick a program, make a plan, and actually get into the business of goal setting and achievement. </p><figure><img src="https://blog.doit.io/content/images/2020/10/GoalSetting-1.jpg" alt="Goal Setting" srcset="https://blog.doit.io/content/images/size/w600/2020/10/GoalSetting-1.jpg 600w, https://blog.doit.io/content/images/size/w1000/2020/10/GoalSetting-1.jpg 1000w, https://blog.doit.io/content/images/2020/10/GoalSetting-1.jpg 1200w" sizes="(min-width: 720px) 720px"><figcaption>Goal Setting</figcaption></figure><p>The world is full of overwhelm. Figuring out how to go about setting and achieving your goals is <em>very</em> important, but that doesn't mean it has to be complicated. We aim to make life easier to manage. In honor of simplicity, we have researched goal setting for you and put together an easy-to-follow plan for setting and achieving your personal goals. We even included some tried-and-true tips and techniques that can be modified to fit your unique life. Let’s do it. </p><h2 id="goal-setting">Goal Setting</h2><ol><li><a href="#a-bit-of-background-what-are-personal-goals-do-we-need-them">What are personal Goals</a></li><li><a href="#setting-smart-goals">Setting SMART Goals</a></li><li><a href="#a-simple-system-for-goal-setting">A Simple System for Goal Setting</a></li><li><a href="#do-it-5-tips-and-tricks-for-goal-achievement">Do it: 5 Tips and Tricks for Goal Achievement</a></li></ol><h2 id="a-bit-of-background-what-are-personal-goals-do-we-need-them">A Bit of Background: What are Personal Goals? Do we Need Them?</h2><p>Personal goals are the things we want to accomplish in life. Plain and simple. In a sense, all goals are personal because they are created from within and attached to our greatest desires and aspirations. </p><p>Sometimes they are looked at separately from professional goals, which are specifically related to one’s professional or work life. That being said, personal goals can most certainly take into account goals related to work or career. Here we will focus on personal goal setting and achievement, with the understanding that the term is all encompassing. Make sense? </p><!--kg-card-begin: markdown--><blockquote>
<p><span>Personal goals are the things we want to accomplish in life. Plain and simple.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>Personal goals are unique to every individual because they are, well, personal! Seems obvious, right? Despite that characteristic, it can be helpful to see some examples of personal goals to get started. This can churn up ideas and open the mind to the endless possibilities. Here is an assortment.</p><ul><li>Work out 3-5 times each week.</li><li>Write in a journal every day.</li><li>Fully fund an emergency savings account equal to six months’ living expenses.</li><li>Walk the dog at least once per day.</li><li>Pay off the student loan in 18 months.</li><li>Take a hike 1-2 times per month.</li><li>Travel to a new destination twice each year.</li><li>Cook dinner at home 3 nights per week.</li><li>Fit into my old favorite jeans before my next birthday.</li><li>Stop working full time before 50.</li><li>Train the puppy 15 commands before his 2nd birthday. <br></li></ul><p>You get the idea. Goals can be big, small, long term, or short term. Personal goals can be about daily life, a lifetime, or anything in between. They are unique to <em>what </em>you want, <em>when</em> you want it. Personal goals do have this in common: they make life better, more meaningful, and focused. </p><!--kg-card-begin: markdown--><blockquote>
<p><span>Personal goals do have this in common: they make life better, more meaningful, and focused.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>We know what personal goals are but why do we need to set them? Isn’t it enough to have them floating around our heads? Experts say, definitely not! Setting goals sets your mind up for success. Making your goals explicit helps to focus your attention, time, and behavior towards achieving them. You will fail to achieve 100% of the goals you never set. And the very act of writing them down could make all the difference. </p><p>In fact, <a href="https://scholar.dominican.edu/cgi/viewcontent.cgi?article=1265&amp;context=news-releases">a study in 2015 by psychologist Gail Matthews</a> revealed that simply writing down goals increased the chances of achieving them by 33 percent compared to having goals that stayed locked inside one’s head. Can your life be purposeful, meaningful, and good without goal setting? Of course it can! But, you have a much greater chance of designing the life you <em>really</em> want by explicitly setting personal goals. </p><!--kg-card-begin: markdown--><blockquote>
<p><span>Simply writing down goals increased the chances of achieving them by 33 percent compared to having goals that stayed locked inside one’s head.</span></p>
</blockquote>
<!--kg-card-end: markdown--><h2 id="setting-smart-goals">Setting SMART Goals</h2><p>Not all goals are created equally. You will have a better chance of achieving goals that are carefully crafted. Many experts recommend setting something called SMART goals. SMART is a mnemonic device that stands for Specific, Measurable, Attainable, Relevant, and Time Bound. </p><ul><li><strong>S: Specific: </strong>Instead of setting a goal to “become wealthy” set a specific goal to “have $1 million invested in a mutual fund by the age of 50.”</li><li><strong>M: Measurable:</strong> The goal should be conducive to metrics. What would it look like to make progress and to fully achieve the goal?</li><li><strong>A: Attainable:</strong> Your goals should be big, but realistic. Aim high but be sure you can hit the target within a specified time frame.</li><li><strong>R: Relevant:</strong> Goals should reflect your values, desires, and abilities.</li><li><strong>T: Time Bound:</strong> Goals should have a deadline that will help organize your efforts and keep you motivated to move forward. <br></li></ul><h2 id="a-simple-system-for-goal-setting">A Simple System for Goal Setting</h2><ol><li>Set one big, huge, overarching goal.</li><li>Set a series of increasingly smaller goals that lead to that big goal.</li></ol><p>Jim Collins is recognized as one of the most influential business book writers of all time. His book <a href="https://www.amazon.com/Built-to-Last-Jim-Collins-audiobook/dp/B0813QCVN9/ref=sr_1_1?dchild=1&amp;keywords=built+to+last&amp;qid=1601575446&amp;sr=8-1"><em>Built to Last</em></a> was a follow up to the groundbreaking, and now classic, <a href="https://www.amazon.com/Good-Great-Some-Companies-Others/dp/0066620996/ref=sr_1_2?dchild=1&amp;keywords=good+to+great&amp;qid=1601575412&amp;sr=8-2"><em>Good to Great</em></a>. In it, he and co author Jerry I. Porras introduced a concept that is now widely applied in corporate goal setting. It’s called a <a href="https://www.jimcollins.com/concepts/bhag.html">BHAG</a>, pronounced bee-hag. </p><p>BHAG stands for Big Hairy Audacious Goal and it challenges corporations and organizations to set their sights on a super large, awe inspiring, borderline outlandish goal that will be the guidepost for decision making within the organization. The writer’s use President Kennedy’s moon landing proclamation as a prime example of a BHAG. </p><p>The author’s wrote, “Like the moon mission, a true BHAG is clear and compelling and serves as a unifying focal point of effort– often creating immense team spirit. &nbsp;It has a clear finish line, so the organization can know when it has achieved the goal; people like to shoot for finish lines. &nbsp;A BHAG engages people– it reaches out and grabs them in the gut. &nbsp;It is tangible, energizing, highly focused. &nbsp;People "get it" right away; it takes little or no explanation.”</p><p>There is no reason why BHAG success should be limited to businesses. That’s why we recommend starting by setting a BHAG for yourself. Think of one huge “clear and compelling” star of a dream goal that you can hook all of your efforts and focus onto. Shoot for the stars! Dream big. Make it “audacious.” Above all else, make it <em>yours</em> alone. Every personal BHAG will be unique, but here are a few examples:</p><ul><li>Retire debt free in Costa Rica.</li><li>Become a self-made millionaire.</li><li>Sell my business for enough to set up six-figure trusts for my children.</li><li>Finish in the top ten at the Boston Marathon.</li><li>Compete in three Olympic Games.</li><li>Publish a book that hits the New York Times bestseller list.</li><li>Own a ranch that houses a non-profit animal sanctuary for big cats. </li></ul><p>Write your BHAG down in private and highly visible places. Look at it often. Tell people about it and expect wide-eyed feedback. Your big goal should incite a riot of reactions. If it doesn’t, it may not be big, hairy, or audacious enough. </p><!--kg-card-begin: markdown--><blockquote>
<p><span>There is no reason why BHAG success should be limited to businesses. That’s why we recommend starting by setting a BHAG for yourself.</span></p>
</blockquote>
<!--kg-card-end: markdown--><p>Now that you have one giant goal to rule them all, you are ready to go to step two. It’s time to set a series of increasingly smaller goals that lead to the big one. Think of your BHAG as the final destination. Along the way, you have to cross a series of obstacles. These smaller goals will be the roads, stepping stones, or trails you will take and the tools and skills you will acquire that are necessary to get all the way there.</p><p>In her book <a href="https://www.amazon.com/Your-Goal-Guide-Planning-Achieving-ebook/dp/B07T3GZX1S/ref=sr_1_1_sspa?dchild=1&amp;keywords=your+goal+guide&amp;qid=1601577717&amp;sr=8-1-spons&amp;psc=1&amp;spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUFMWTdDQ1c5SjAyNDMmZW5jcnlwdGVkSWQ9QTA3NTI1ODExUkxDMTAxUkJFVkRSJmVuY3J5cHRlZEFkSWQ9QTA2MzU0Njg5NjBMUTg2UTFNR00md2lkZ2V0TmFtZT1zcF9hdGYmYWN0aW9uPWNsaWNrUmVkaXJlY3QmZG9Ob3RMb2dDbGljaz10cnVl"><em>Your Goal Guide</em></a>, author and goal-setting coach Debra Eckerling lays out a highly detailed plan for breaking a big ultimate goal into smaller goals that will keep you on the path to what she calls “GoalTopia.” She recommends that you first determine the long-term goals you will need to achieve in order to reach your final destination. Under each of those long term goals, you will list benchmarks or hurdles that you will need to clear to achieve those long-term goals. Under those benchmarks or hurdles, you will list tasks you need to take care of to clear the hurdles. </p><p>Let’s look at the debt-free retirement in Costa Rica for example. One long term goal might be to pay off an existing mortgage in fifteen years. Under that, you need a list of increasingly smaller goals that may look something like this:</p><p><strong>The Big Goal: Retire debt free in Costa Rica</strong></p><ol><li>Pay off the existing mortgage in fifteen years.</li><li>Make two payments per month equal to twice the required payment.</li><li>Create and stick to a monthly budget.</li><li>Eliminate credit card debt.</li><li>Pay off the car loan. </li></ol><p>Outlines, lists, diagrams, funnels, using <a href="https://doit.io/why-doit/">a digital tool like doit</a>, filling in a goal worksheet: the format you use is entirely up to you. The important thing is to go through the process of taking that one big goal and breaking it down into smaller and smaller bites that can be accomplished steadily as you make your way. </p><h2 id="do-it-5-tips-and-tricks-for-goal-achievement">Do it: 5 Tips and Tricks for Goal Achievement</h2><p>Making the effort to seriously consider and intentionally set personal goals for yourself is a massive step in the right direction. Checking them off your list and getting the work done is the next challenge. In short, it’s time to actually do it. Successful goal achievement is part psychology and part process. Set yourself up for success with some tips and tricks that <em>really</em> work. </p><ol><li><strong>The Psychology of Small Wins:</strong> There is real power in victories, no matter how small. Checking achievements off your goal list delivers a jolt of feel-good chemicals to your brain, such as dopamine. Your brain wants more of that, so you intrinsically become motivated to do it again and again. This is one of the reasons why breaking down goals into ever-smaller steps works so well. The more frequently you get that hit of pleasure, the more motivated you are to get back to work.<br></li><li><strong>Show Up:</strong> The act of simply showing up, no matter how you feel or …</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.doit.io/goal-setting/">https://blog.doit.io/goal-setting/</a></em></p>]]>
            </description>
            <link>https://blog.doit.io/goal-setting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25727832</guid>
            <pubDate>Mon, 11 Jan 2021 12:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ Haskell is our first choice for building production software systems]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 284 (<a href="https://news.ycombinator.com/item?id=25726588">thread link</a>) | @Albert_Camus
<br/>
January 11, 2021 | https://www.foxhound.systems/blog/why-haskell-for-production/ | <a href="https://web.archive.org/web/*/https://www.foxhound.systems/blog/why-haskell-for-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Haskell is the first programming language we reach for when we build production software systems. This likely seems unusual to anyone who only has a passing familiarity with the language. Haskell has a reputation for being an advanced language with a steep learning curve. It is also often thought of as a research language with limited practical utility.</p>
<p>While Haskell does have a very large surface area, with many concepts and a syntax that will feel unfamiliar to programmers coming from most other languages, it is unrivaled in the combination of developer productivity, code maintainability, software reliability, and performance that it offers. In this post I will cover some of the defining features of Haskell that make it an excellent, industrial-strength language that is well-suited for building commercial software, and why it is usually the first tool we consider using for new projects.</p>
<!--more-->
<h3 id="haskell-has-a-strong-static-type-system-that-prevents-errors-and-reduces-cognitive-load">Haskell has a strong static type system that prevents errors and reduces cognitive load</h3>
<p>Haskell has a very powerful static type system which serves as a programmer aid that catches and prevents many errors before code ever even runs. Many programmers encounter statically typed languages like Java or C++ and find that the compiler feels like an annoyance. By contrast, Haskell’s static type system, in conjunction with compile-time type checking, acts as an invaluable pair-programming buddy that gives instantaneous feedback during development.</p>
<p>There’s a far smaller cognitive load that needs to be maintained when writing Haskell than when writing in languages like Python, JavaScript, or PHP. Many concerns can be completely offloaded to the compiler rather than needing to be remembered by the programmer. For example, when writing Haskell, there’s no need to preemptively ask questions like:</p>
<ul>
<li>Do I need to check whether this field is null?</li>
<li>What if fields are missing from the request payload?</li>
<li>Has this string already been decoded to an integer?</li>
<li>What if this string can’t be decoded to an integer?</li>
<li>Will this operator implicitly convert this integer to a string?</li>
<li>Are these two values comparable?</li>
</ul>
<p>This is not to say that these are questions that never need answering in Haskell; it’s to say that the compiler will throw an error when you need to address one of these issues. For example, it’s possible that a Haskell program needs to handle values that are sometimes not present, but instead of setting any value to <code>NULL</code>, a Haskell programmer must use a <code>Maybe</code> type, which indicates that the value may not be there, and the compiler forces the programmer to explicitly handle the <code>Nothing</code> value; the case where the value is not present.</p>
<p>Haskell’s static type system also leads to other benefits. Haskell code uses type signatures that precede its functions and describe the types of each parameter and return value. For example, a signature like <code>Int -&gt; Int -&gt; Bool</code> indicates that a function takes two integers and returns a boolean value. Since these type signatures are checked and enforced by the compiler, this allows a programmer reading Haskell code to look only at type signatures when getting a sense of what a certain piece of code does. For example, one would not use the type signature above when looking for a function that manipulates strings, decodes JSON, or queries a database.</p>
<p>Type signatures can even be used to search through the entire corpus of Haskell code for a relevant function. Using <a href="https://hoogle.haskell.org/" target="_blank" rel="noopener">Hoogle</a>, Haskell’s API search, we can search for a type signature based off of functionality we know that we need. For example, if we need to convert an <code>Int</code> to a <code>Float</code>, we can search Hoogle for <code>Int -&gt; Float</code> (<a href="https://hoogle.haskell.org/?hoogle=Int+-%3E+Float" target="_blank" rel="noopener">search results</a>), which will point us to the aptly named <code>int2Float</code> function.</p>
<p>Haskell also lets us create polymorphic type signatures through the use of type variables, represented by lowercase type names. For example, a signature of <code>a -&gt; b -&gt; a</code> tells us that that the function takes two parameters of two arbitrary types, and returns a value that whose type is the same as the first parameter. Suppose we want to check whether an element is in a list. We’re looking for a function that takes an item to search for, a list of items, and returns a boolean. We don’t care about the type of the item, so long as the search item and the items in the list are of the same type. So we can search Hoogle for <code>a -&gt; [a] -&gt; Bool</code> (<a href="https://hoogle.haskell.org/?hoogle=a%20-%3E%20%5Ba%5D%20-%3E%20Bool" target="_blank" rel="noopener">search results</a>), which will point us to the <code>elem</code> function. Parametric types are an extremely powerful feature in Haskell and are what enable writing reusable code.</p>
<h3 id="haskell-enables-writing-code-that-is-composable-testable-and-has-predictable-side-effects">Haskell enables writing code that is composable, testable, and has predictable side-effects</h3>
<p>In addition to being statically typed, Haskell is a pure functional programming language. This is one of Haskell’s defining features and what the language is well known for, even amongst programmers that have only heard of Haskell but never used it. Writing in a pure functional style has many benefits, and is conducive to a well-organized code base.</p>
<p>The word “pure” in “pure functional programming” is significant. Purity in this sense means that the code we write is pure, or free of side-effects. Another term that describes this is <a href="https://en.wikipedia.org/wiki/Referential_transparency" target="_blank" rel="noopener">referential transparency</a>, or the property where any expression (e.g.&nbsp;a function call with a given list of parameters) can be replaced with its return value without changing the functionality of the code. This is only possible when such pure functions do not have side effects, such as creating files on the host system, running database queries, or making HTTP requests. Haskell’s type system imposes this sort of purity.</p>
<p>So does being pure mean that Haskell programs cannot have side effects? Certainly not—but it does mean that effects are pushed to the edge of our system. Any functions that perform I/O actions (such as querying a database or receiving HTTP requests) must have a return type that captures this. This means that type signatures like the ones we saw in the previous section (e.g.&nbsp;<code>Int -&gt; Float</code> or <code>a -&gt; [a] -&gt; Bool</code>) are indicators that the corresponding functions do not produce side effects, since <code>Float</code> and <code>Bool</code> are just primitive return types. For a contrasting example that includes a side effect, a function signature of <code>FilePath -&gt; IO String</code> indicates that the function takes a file path and performs an I/O action that returns a string (which is exactly what the <code>readFile</code> function does).</p>
<p>Another feature of a pure functional programming paradigm is higher-order functions, which are functions that take functions as parameters. One of the most commonly used higher-order functions is <code>fmap</code>, which applies a function to each value in a container (such as a list). For example, we can apply a function named <code>square</code>, which takes an integer and returns that integer multiplied by itself, to a list of integers to turn it into a list of squared integers:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>square ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb1-2">square x <span>=</span> x <span>*</span> x</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>fmap</span> square [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>,<span>5</span>] <span>-- returns [1,4,9,16,25]</span></span></code></pre></div>
<p>Code written in this style tends to be both composable and testable. This above example is trivial, but there are many applications of higher-order functions. For example, we can write a function like <code>renderPost</code> which takes a record of post data and returns the version of the post rendered in HTML. If we have a list of posts, we can run <code>fmap renderPost postList</code> to produce a list of rendered posts. Our <code>renderPost</code> function can be used in both the single case and the multi-post case without any changes, because composing it with <code>fmap</code> changes how we can apply it. We can also write tests for the <code>renderPost</code> function and compose it with <code>fmap</code> in our tests when validating the behavior for a list of posts.</p>
<h3 id="haskell-facilitates-rapid-development-worry-free-refactoring-and-excellent-maintainability">Haskell facilitates rapid development, worry-free refactoring, and excellent maintainability</h3>
<p>Through the combination of the aforementioned static types and pure functional style that Haskell has, developing software in Haskell tends to be very fast. One of the common development workflows we employ is relies on a tool called <a href="https://github.com/ndmitchell/ghcid" target="_blank" rel="noopener"><code>ghcid</code></a>, a simple command line tool that relies on the Haskell repl to automatically watch code for changes and incrementally recompile. This allows us to see any compiler errors in our code immediately after saving changes to a file. It’s not uncommon for us to open only a terminal with a text editor and <code>ghcid</code> while developing applications in Haskell.</p>
<p>While manually validating the results of our code is eventually necessary by refreshing a page in a browser or using a tool to validate a JSON endpoint, a lot of this can be deferred until the end of a programming session. Many of the would-be runtime errors a programmer would encounter when writing a web service in a language like Python or PHP are caught immediately and displayed as compiler errors by <code>ghcid</code>. This is a far cry from the need to switch to a browser window and refresh the page after making a change to some code, a development workflow that everyone who has worked on a web application is intimately familiar with.</p>
<p>Beyond the tight feedback loop during development, Haskell code is easy to refactor and modify. Like real world code written in any other language, such code written in Haskell is not write-only. It eventually will need to be maintained, updated, and extended, often by developers that are not the original authors of the code. With the aid of compile-time checking, many code refactors in Haskell become easy; a common refactoring workflow is to make a desired change in one location and then fix one compiler error at a time until the program compiles again. This is far easier than the equivalent changes in dynamically typed languages that offer no such assistance to the programmer.</p>
<p>Proponents of dynamically typed languages will often argue that automated tests supplant the need for compile-time type checking, and can help prevent errors as well. However, tests are not as powerful as type constraints. For tests to be effective, they must:</p>
<ol type="1">
<li>Actually be written, yet many real world code bases have limited testing</li>
<li>Make correct assertions</li>
<li>Be comprehensive (test a variety of inputs) …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.foxhound.systems/blog/why-haskell-for-production/">https://www.foxhound.systems/blog/why-haskell-for-production/</a></em></p>]]>
            </description>
            <link>https://www.foxhound.systems/blog/why-haskell-for-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726588</guid>
            <pubDate>Mon, 11 Jan 2021 09:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working Off-Grid Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25723819">thread link</a>) | @zdw
<br/>
January 10, 2021 | https://100r.co/site/working_offgrid_efficiently.html | <a href="https://web.archive.org/web/*/https://100r.co/site/working_offgrid_efficiently.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
        
        <ul>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#power">Power management</a></li>
            <li><a href="#internet">Internet</a></li>
            <li><a href="#data">Data storage</a></li>
            <li><a href="#software">Software</a></li>
            <li><a href="#hardware">Hardware</a></li>
            <li><a href="#conscientious">Conscientious living</a></li>
        </ul>
<h2 id="intro">Introduction</h2>

<img src="https://100r.co/media/blog/working/dworking5.jpg" loading="lazy">

<p>Our traveling studio has operated off-the-grid since 2016.</p>

<p>For the first 3 years we tested the limits of our space, and at first, it was difficult to create new things, as we had to make time to learn how to solve the underlying problems. Our boat was not just an office, it was also our house and transport. As for us, we were artists, but also had to be plumbers, deckhands, electricians, captains, janitors and accountants.</p>

<p>Our main problems as a studio were <b>internet scarcity</b>, <b>power management</b>, <b>data storage</b> as well as <b>hardware</b> and <b>software failures</b>. Overtime we found ways to balance work, pleasure and maintenance. Here are some of the lessons we learnt.</p>

<h2 id="power">Power management</h2>

<img src="https://100r.co/media/blog/working/dworking6.jpg" loading="lazy">

<p>Our work schedule is tied to the weather, as we depend on solar energy to power our computers. By looking at the forecast, we can determine when we will get the most work done: consecutive days of sun grant us enough power for video-editing, while overcast days are reserved for low-power work, like writing, coding and planning.</p>

<p>There are times when we must resort to secondary power sources, like our small generator or our engine's alternator, but we tend to prefer to <a href="https://www.youtube.com/watch?v=9ua_qxjbBTc">wait for the sun to return</a>. Waiting hasn’t affected our productivity, as we don't adhere to strict 8-hour workdays.</p>

<p>We tend to work only in the morning, leaving us time to pursue other interests in the afternoon. In our old life, we found that the 40-hour workweek ﻿<a href="https://www.raptitude.com/2010/07/your-lifestyle-has-already-been-designed/" target="_blank">kept free-time scarce</a>, resulting in us spending more for convenience, gratification and distraction.</p>

<p>Computers are generally power-sucking vampires. Choosing different softwares, operating systems, or working from machines with a lower draw (ARM) or even throttling the CPU, are some of the many things we do to lower our power requirements. The way that software is built has a substantial impact on the power consumption of a system, it is shocking how cpu-intensive modern programs can be.</p>

<p>Choosing software designed for low-end PCs is a good solution, it is also possible to throttle processes on your machine by using a ‘throttling controller’. The basic idea is like the throttle in a car, it allows to set the rate at which your system will operate and consume power. Another sure way to save battery is to limit multitasking. Disabling notifications, <a href="https://addons.mozilla.org/en-CA/firefox/addon/noscript/">scripts</a>, auto-playing videos or using internet browsers without opening multiple tabs at once are some of the many ways to achieve this.</p>

<p>Power consumption is also something to consider when choosing a computer. In evenings, if we need to work on light tasks, we switch to our low-power machines like the <a href="https://100r.co/site/raspberry_pi.html">Raspberry Pi</a>. To illustrate the difference in power draw, a Pi4 uses 2.85 W when idle, while a Macbook Pro uses 6-12 W. Raspberry Pis are backups to our main computers, as they are inexpensive and can run off small batteries.</p>

<h2 id="internet">Internet</h2>

<img src="https://100r.co/media/blog/working/dworking1.jpg" loading="lazy">

<p>Internet access is the woe of any working nomad. Internet is sometimes spotty, and data in some countries is slow, expensive, or limited to small blocks at a time. While circumnavigating the Pacific, we amassed sim cards, pocket WiFis, and have often used connections from businesses on land. Overtime, we found ways to lessen our dependence on internet, and to save on bandwidth.</p>

<p>With limited access, it is important to use online time wisely. Prior to connecting we make a list of tasks that we must do, such as pushing updates and making backups of our data online. It’s easy to get side-tracked on the internet, with websites designed to grab and keep our attention. When checking social media, we disable auto-playing videos and image previews to save bandwidth.</p>

<p>When we have a reliable internet connection, we gather copies of all the online material we will need. We keep offline versions of entire websites, writing guides, articles and even whole sections of Wikipedia. If we find ourselves without a connection, we can still solve our problems by using our offline mirrors. By the way, you can <a href="https://github.com/hundredrabbits/100r.co/archive/master.zip">download our entire website</a>.</p>

<p>We research our destinations ahead of time to make sure we’ll have a reliable connection when we need it. This means we’ll be spending less time in secluded areas, and more time in city centers near a cell tower or WiFi signal. With some planning it is possible to have both paradise and connectivity, we found such a place in <a href="https://100r.co/site/internet_in_paradise.html#internet">Huahine</a> in French Polynesia, and again in Fiji. Internet access will only get better as far-flung island nations gain purchasing power.</p>

<h2 id="data">Data storage</h2>

<img src="https://100r.co/media/blog/working/dworking2.jpg" loading="lazy">

<p>Hardware failure is common on boats due to the hostile environment. Saltwater is the kryptonite of electronics. This is why it is important to backup data often to avoid losing work. There are advantages and disadvantages with all methods of data storage, but I’ll outline the most useful ones:</p>

<p><b>Cloud storage:</b> For a fee, you can back up your data online and sync files from your desktop. This method doesn’t eliminate physical storage as data can’t be synced to the cloud without a connection. Offloading data storage to a centralized service is problematic in other ways, because services have rules and owners and processes which can complicate things. For instance, country politics have made it that Google restricts access to some of its business services in certain countries or regions, such as China, Crimea, Cuba, Iran, Sudan, and Syria. Whatever data you have stored with Google Drive, if traveling to any of these countries will not be accessible. As conflicts arise, more countries can end up on that list. We keep documents we don’t need regular access to on the cloud, with copies on hard disks.</p>

<p><b>Hard copies:</b> Paper is a stable and widely accessible material, unlike digital devices which are subject to breakages and obsolescence. There’s a good reason books and other documents from centuries ago are still readable today. We like to keep printed copies of websites and other online reference materials, such as grammar guides for writing, or language manuals for coding. Keeping data like this means we always have access and aren’t limited to our computer’s battery.</p>

<p><b>External hard drives:</b> A hard drive is the best balance of practical and reliable for storage. However, hard drives are rated for a limited number of read/write cycles, and can be expected to fail eventually. To prevent data loss due to HD failure, it’s a good idea to store the same data across multiple hard drives.</p>

<p><b>Offline databases:</b> Keeping an offline collection of websites on computers or HD ensures constant access, and reduces the energy associated with re-loading them repeatedly. It’s possible to save web pages with most browser by selecting File &gt; Save Page As. To access the page offline, click on the HTML file. Another option is to mirror entire web sites using <a href="https://www.gnu.org/software/wget/" target="_blank">command-line tools</a>. We keep offline databases full of notes on a variety of subjects to refer to when there’s no internet.</p>
<p>For those who need a vast quantity of reference materials, it's possible to setup an <a href="http://wiki.laptop.org/go/IIAB/FAQ#How_does_Internet-in-a-Box_.28IIAB.29_help.3F" target="_blank">internet in the box</a> on your boat. In short, it permits you to browse through the World’s Free Knowledge (Wikipedia, Khan Academy, OpenStreetMap, E-Books and many others) while offline. You can install an internet-in-a-box using very diverse hardware, like on a <a href="https://opensource.com/article/17/5/internet-in-a-box-raspberry-pi" target="_blank">Raspberri Pi</a> or on a terabyte HD with a built-in hotspot. This system was originally designed for students with restricted internet access and people in remote areas of the world not served by broadband. You can buy one, or better yet <a href="https://www.kiwix.org/en/" target="_blank">create a digital library</a> filled with content tailored to your needs. This might be especially useful for sailors who homeschool.</p>

<p>Keeping files on the cloud, on hard drives and hard copies gives our floating studio the redundancy required to ensure reliability.</p>

<h2 id="software">Software</h2>

<p>Software has a big impact on productivity, they need to be reliable and fast. Those that require heavy updates, that have a high CPU usage and that need frequent connectivity to function are problematic for working sailors.</p>

<p>Much of the software on the market is designed by people living on the grid with unlimited access to internet. Tools locking up at sea, asking for a connection to continue working don’t float on a boat. Adobe products are a good example, as they require an internet connection periodically for subscription validation. If away from big cities, you may open your computer in an atoll to find that you no longer have access to the tool you need to get things done. Choosing a tool that doesn’t require a subscription is <b>essential</b> for working nomads that don’t have a reliable connection.</p>

<p>In our first year, we struggled to download the frequent and mandatory 10GB software updates from Apple to release our software on their platform, while on slow Polynesian internet. Processor-intensive software or apps is a strain on limited power and bandwidth, but it doesn’t have to be that way. The way developers write them can affect the power consumption of the resulting product. Chat rooms and bare bones text editors aren’t supposed to be process-heavy, and yet the popular communication platform Slack requires <a href="https://josephg.com/blog/electron-is-flash-for-the-desktop/" target="_blank">outrageous amounts of ram and CPU</a> to function. This is because Slack is embedding the entirety of Google Chrome in their app. Making software this way is costly to off-grid users, or those on slow connections, but luckily there are <a href="https://github.com/mayfrost/guides/blob/master/ALTERNATIVES.md" target="_blank">many alternatives</a>.</p>

<p>Our computer batteries should not need to grow ever larger only to support these bloatwares, nor should we need to add extra solar to power them. Just as you would look at the nutritional content of food products at the grocery store, find out how much energy your apps are consuming.</p>

<h2 id="hardware">Hardware</h2>

<img src="https://100r.co/media/blog/working/working3.jpg" loading="lazy">

<p>Computers are subject to water intrusion and saltwater corrosion, but with some care they can survive in a normal marine environment. We solved most of the problems by cleaning external connections often, and by storing them in a sealed box with some desiccants after each use. The main issue with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://100r.co/site/working_offgrid_efficiently.html">https://100r.co/site/working_offgrid_efficiently.html</a></em></p>]]>
            </description>
            <link>https://100r.co/site/working_offgrid_efficiently.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723819</guid>
            <pubDate>Mon, 11 Jan 2021 02:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TV Tuner History]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25721804">thread link</a>) | @parsecs
<br/>
January 10, 2021 | https://www.maximus-randd.com/tv-tuner-history-pt1.html | <a href="https://web.archive.org/web/*/https://www.maximus-randd.com/tv-tuner-history-pt1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.maximus-randd.com/tv-tuner-history-pt1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25721804</guid>
            <pubDate>Sun, 10 Jan 2021 23:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering and exploring mmap using Go]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25720731">thread link</a>) | @brunoac
<br/>
January 10, 2021 | https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/ | <a href="https://web.archive.org/web/*/https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Recently I've come to know the concept of <strong>memory-mapped files</strong> while watching a lecture of the course <a href="https://15445.courses.cs.cmu.edu/fall2019/">Intro to Database Systems</a> of <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> on database storage. One of the main problems a database storage engine has to solve is <strong>how to deal with data in disk that is bigger than the available memory</strong>. At a higher level, the main purpose of a disk-oriented storage engine is to manipulate data files in a disk. But if we assume that the data in the disk will eventually get bigger than the available memory, we cannot simply load the whole data file into memory, do the change, and write it back to disk.</p><p>This is not a new problem in Computer Science. When operational systems were being developed in the early 1960s, a similar problem was faced: <strong>how can we run programs stored in disk that are larger than the available memory?</strong> A solution to this problem was made by a group in Manchester, implemented on the <a href="https://en.wikipedia.org/wiki/Atlas_(computer)">Atlas Computer</a>, in 1961. It was called <em>virtual memory</em>. The <em>virtual memory</em> gives a running program the illusion that it has big enough memory, despite the fact that the computer does not have enough.</p><p>We are not going to go deep on how <em>virtual memory</em> works. Just have in mind that when a program is accessing memory it is accessing the <em>virtual memory</em>. And maybe the data the program is trying to access is not actually in memory, but it does not matter. The operational system will make pretend that it is by going to disk, and putting it there, and replace an old chunk of memory that is not going to be used.</p><p>So, one of the ways a database storage engine can solve the larger than memory problem is to make use of <em>virtual memory</em> and the concept of <strong>memory-mapped files</strong>.</p><p>In Linux, we can make this use by using the system call <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a> that lets you map a file, no matter how big, directly into memory. If your program needs to manipulate the file, all it needs is to manipulate the memory. The operating system handles the writes to disk for you.</p><p>In some occasions, programmers find this method more convenient than the usual system calls: <a href="https://man7.org/linux/man-pages/man2/open.2.html">open</a>, <a href="https://man7.org/linux/man-pages/man2/read.2.html">read</a>, <a href="https://man7.org/linux/man-pages/man2/write.2.html">write</a>, <a href="https://man7.org/linux/man-pages/man2/lseek.2.html">lseek</a> and <a href="https://man7.org/linux/man-pages/man2/close.2.html">close</a>.</p><h3 id="a-simple-demonstration">A simple demonstration</h3><p>Here is a small example of how you can take advantage of this in Go using the package <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>:</p><pre><code>package main

import (
	"os"
	"fmt"
	"github.com/edsrzf/mmap-go"
)

func main() {
	f, _ := os.OpenFile("./file", os.O_RDWR, 0644)
	defer f.Close()
	
	mmap, _ := mmap.Map(f, mmap.RDWR, 0 )
	defer mmap.Unmap()
	fmt.Println(string(mmap))
	
	mmap[0] = 'X'
	mmap.Flush()
}</code></pre><figure><img src="https://asciinema.org/a/pRS8PvTRHksnCVQgSOWvPBF3a.svg" alt="asciicast"></figure><p>The beauty is that we could have a much bigger file, and the solution would still work. We would not have to worry about managing memory in order to avoid it filling up.</p><h3 id="detailing-mmap-capabilites">Detailing <em>mmap</em> capabilites</h3><p>We're going to explore more <em>mmap</em> functionalities from the point of view of the API provided by <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>. There are probably more features that the <a href="https://godoc.org/golang.org/x/sys/unix#Mmap">native syscall</a> provides that this library does not implement.</p><h4 id="the-prot-argument">The <code>prot</code> argument</h4><p>Here is the <code>mmap.Map</code> signature</p><pre><code>func Map(f *os.File, prot, flags int) (MMap, error) 
</code></pre><p>Let's look at <code>prot</code> first. The <code>prot</code> argument lets you specify the protection levels of your mapping: <code>RDONLY</code>, <code>RDWR</code>, <code>EXEC</code> are the options provided for <code>mmap-go</code>. These levels are pretty straightforward, <code>RDONLY</code> means you can only read from the mapping, <code>RDWR</code> means you can also write, and <code>EXEC</code> means you can execute code on that mapping. &nbsp;Here is the description of <code>prot</code> from the Linux <code>man</code>:</p><pre><code>The prot argument describes the desired memory protection of the
mapping (and must not conflict with the open mode of the file).
It is either PROT_NONE or the bitwise OR of one or more of the
following flags:

PROT_EXEC
    Pages may be executed.

PROT_READ
    Pages may be read.

PROT_WRITE
    Pages may be written.

PROT_NONE
    Pages may not be accessed.
</code></pre><p>In the <a href="https://godoc.org/golang.org/x/sys/unix">unix package</a>, those flags are: <code>unix.PROT_EXEC</code>, <code>unix.PROT_READ</code>, <code>unix.PROT_WRITE</code> and <code>unix.PROT_NONE</code>.</p><h4 id="experimenting-with-prot_exec-flag">Experimenting with <code>PROT_EXEC</code> flag</h4><p>I've become intrigued by the <code>EXEC</code> flag and wanted to see an example of how that works. I've Google and could not find any example. So I tried a search in Github by <code>PROT_EXEC</code> and found a good example in <code>C</code>: <a href="https://github.com/onesmash/MMapExecDemo">MMapExecDemo</a>. I replicated this example in <code>Go</code> using <code>mmap-go</code>.</p><p>The first step was to create a function that I wanted to be put in memory by <code>mmap</code> allocation, compile it, and get its assembly opcodes.</p><p>I created the <code>inc</code> function in <code>inc.go</code> file</p><pre><code>package inc

func inc(n int) int {
	return n + 1
}

</code></pre><p>compiled it with <code>go tool compile -S -N inc.go</code>, then got its assembly by calling <code>go tool objdump -S inc.o</code>.</p><pre><code>func inc(n int) int {
  0x22b                 48c744241000000000      MOVQ $0x0, 0x10(SP)
        return n + 1
  0x234                 488b442408              MOVQ 0x8(SP), AX
  0x239                 48ffc0                  INCQ AX
  0x23c                 4889442410              MOVQ AX, 0x10(SP)
  0x241                 c3                      RET
</code></pre><p>With this, we can build represent our function in bytes on our code</p><pre><code>code := []byte{
        0x48, 0xc7, 0x44, 0x24, 0x10, 0x00, 0x00, 0x00, 0x00,
		0x48, 0x8b, 0x44, 0x24, 0x08,
		0x48, 0xff, 0xc0,
		0x48, 0x89, 0x44, 0x24, 0x10,
		0xc3,
}
</code></pre><p>We allocate our memory with <code>mmap</code>.</p><pre><code>memory, err := mmap.MapRegion(nil, len(code), mmap.EXEC|mmap.RDWR, mmap.ANON, 0)
if err != nil {
    panic(err)
}
</code></pre><p>In this call, we're using a more complete function called <code>MapRegion</code> that lets you specify how much memory you are allocating (<code>Map</code> allocates the size of the underlying file) and the offset of the file.</p><p>In the beginning, we said that the main purpose of <code>mmap</code> was to create a mapping between a file and memory. But in this call we are not indicating any file. <code>mmap</code> can be used just a regular memory allocater by setting <code>nil</code> to the <code>*os.File</code> argument and <code>mmap.ANON</code> to the <code>flags</code> argument. We will talk about more <code>mmap.ANON</code>. Since we are not mapping any file, the offset is <code>0</code>.</p><p>So we have memory allocated with the same size of our code <code>len(code)</code>. Since we set the flag <code>mmap.RDWR</code>, we can copy our <code>code</code> to <code>memory</code>.</p><pre><code>copy(memory, code)
</code></pre><p>We have the code of our <code>inc</code> function in memory. In order to execute it, we have to cast that memory address to a function with a signature that matches the signature of our compiled <code>inc</code>.</p><pre><code>memory_ptr := &amp;memory
ptr := unsafe.Pointer(&amp;memory_ptr)
inc := *(*func(int) int)(ptr)
</code></pre><p>When we call <code>inc</code>, we are executing the code we put in memory. That only works because of the flag <code>mmap.EXEC</code>. If that flag was not set, a <code>segmentation violation</code> would occur.</p><pre><code>fmt.Println(inc(10)) // Prints 11
</code></pre><p>I don't know if this is a real use case. I just wanted to see what it meant to execute code that you put in memory. And there are probably other ways of achieving the same with regular memory allocation and calls to <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a>.</p><p>One question that may come up is: but the code is already in the <code>code</code> variable, can't we just execute it? No, because the memory static allocated to <code>code</code> is not executable. Can we make it executable? I've tried to use <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a> on it but still got <code>segmentation violation</code>.</p><p>Here is the full working <a href="https://gist.github.com/brunoac/b9ff4ad46c27926e5e4f078133d0de79">gist</a>.</p><h4 id="the-flags-argument">The <code>flags</code> argument</h4><p>We can have many processes mapping the same memory region. This argument lets us decide about the visibility of the updates happening in the mapping. There are many flags, and you can check them out at <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a>. The important ones are <code>unix.MAP_SHARED</code>, <code>unix.MAP_PRIVATE</code> and <code>unix.MAP_ANON</code>.</p><p><code>MAP_SHARED</code> means that changes to the mapping are visible to all processes and will also occur at the underlying mapped file, although we cannot control when.</p><p><code>MAP_PRIVATE</code> means the changes are private and other processes will not see them. And also, they are not carried through to the underlying file.</p><p><code>MAP_ANON</code> means that there is not going to be a mapped file. It is useful for sub-processes communication with shared memory.</p><p>I've got confused about the <code>mmap-go</code> library implementation. It only provides the <code>mmap.ANON</code> flag, that we used in the above example. If you want your mapping to be private, you can set the <code>mmap.COPY</code> flag to the <code>prot</code> argument. Anyways, you can always use the flags provided by the <code>unix</code> package implementation.</p><h4 id="locking-and-flushing">Locking and flushing</h4><p>Two other nice methods, <code>Lock</code> and <code>Flush</code>, are provided by the API of <code>mmap-go</code>. The <code>Lock</code> method calls the <a href="https://man7.org/linux/man-pages/man2/mlock.2.html">mlock</a> system call that prevents the mapping to be paged out to disk. And the <code>Flush</code> method calls the <a href="https://man7.org/linux/man-pages/man2/msync.2.html">msync</a> system call that forces the data in memory to be written to disk. This is a good way to trying to have more control over how and when data is flushed to disk.</p><h3 id="wrapping-up">Wrapping up</h3><p>I felt kind of stupid of knowing about <code>mmap</code> after so long. I don't remember it being brought in my college class. For some reason, I felt amazed by it and its capabilities and decided to dig deeper. I like databases and I'm aiming to get a better grasp of them. This means that <code>mmap</code> cannot go unnoticed from my learning. For future posts, I'll try to bring about the benefits and drawbacks of using <code>mmap</code>, which projects use it, and what kind of problems it is suited for.</p><p>Even though the <code>mmap</code> can be used to solve that database problem we stated in the beginning, and many modern databases use it, <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> advocates against it and have three lecture on how to databases, that don't use <code>mmap</code>, manage data.</p><p>If you like this kind of content, follow me on <a href="https://twitter.com/brunocalza">twitter</a>. You may find more related stuff there.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720731</guid>
            <pubDate>Sun, 10 Jan 2021 22:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Overview of Julia language [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25719454">thread link</a>) | @gurjeet
<br/>
January 10, 2021 | http://algorithmsbook.com/files/appendix-g.pdf | <a href="https://web.archive.org/web/*/http://algorithmsbook.com/files/appendix-g.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://algorithmsbook.com/files/appendix-g.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719454</guid>
            <pubDate>Sun, 10 Jan 2021 20:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cooking for Founders]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25719188">thread link</a>) | @tylertringas
<br/>
January 10, 2021 | https://tylertringas.com/cooking-for-founders/ | <a href="https://web.archive.org/web/*/https://tylertringas.com/cooking-for-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>With COVID-19 forcing many of us indoors and cooking more (yes, this post took a little longer to go live than I planned), there’s never been a better time to really learn how to cook. I grew up not learning much about how to cook and taught myself as an adult. Over the last 5-7 years I went from someone who could do the absolute bare minimum (boil pasta, cook chicken breast, etc) to genuinely quite a decent cook. I can easily whip up dinner for 4-6 friends without stressing, cook healthy dinners at home most nights of the week, run a barbecue for 12 people, and have a small quiver of fancy dishes to impress friends, family, and my wife from time to time. This post is mostly about what works for me, but I’m calling it Cooking For Founders because I think it will resonate with a lot of entrepreneurs who think like me.</p>
<p>The goal of this post is not to teach you how to cook but to provide fairly comprehensive, but also minimum viable, roadmap for going from a cooking noob to solid home chef.</p>
<h2>Why you should cook</h2>
<p>Until I was about 25 or so I really didn’t cook much. I lived in places like NYC and London where restaurants were always open and ubiquitous and especially in these cities, it’s a perfectly reasonable position to just not bother learning to cook well. But I want to make the case that even if you have world class restaurants and food delivery services on demand, you should learn to cook.</p>
<p><strong>Social: </strong>Home cooked meals are an awesome offer that people are very likely to take you up on and really appreciate. Cooking well is sexy and makes for an awesome date night. Dinner parties are fantastic well to meet new people and create a vibrant personal and professional network. Taking charge of a meal is a great way to bring your family together or impress your in-laws.</p>
<p><strong>Physical Health: </strong>Even if you aren’t bothering with any particular diet (low carb, paleo, etc), cooking at home is almost always going to be more nutritious than food from restaurants. Getting actually healthy food from restaurants/delivery is almost always expensive. Cooking at home is an affordable way to get great nutrition.</p>
<p><strong>Mental Health:&nbsp;</strong>This may be more specific to me, but I find cooking to be fantastic for my mental health. In my house I’m the one cooking about 90% of the time and I’m not into the mega meal prep strategies where you cook food for the whole week. So, most days, I’m cooking something fresh for dinner. The need to start cooking prep in time for a reasonable dinner puts a natural stopping point in my work day and then I get to switch to a very focused mono-tasking activity. This routine is, for me, a kind of meditation that separates the work day and let’s my brain process the events of the day.</p>
<h2>Meta-learning Tips for Learning to Cook</h2>
<p>Learning to cook is not exactly easy. There is an infinite amount of recipes, techniques, resources, diets, and on and on to consume. It can be overwhelming. Learning to cook is almost always laden with failures along the way. You’ll screw up some recipes, ruin some dishes, and get halfway through a complex recipe before realizing you’re missing some essential ingredient. Here are some lessons I’ve learned on how to learn.</p>
<p><strong>Find your YouTube &amp; TikTok muses</strong></p>
<p>There is an infinite amount of cooking content on the internet, but when you find a particular chef or channel that really speaks your language, subscribe and binge their entire backlog. Lots of channels out there will skip essential explanations, use overly exotic ingredients, or complex unnecessary techniques so when you find one that consistently speaks to you, lock it in. Some ones I like:</p>
<ul>
<li><a href="https://www.youtube.com/user/helenrennie" data-lasso-id="385">Helen Rennie (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/foodwishes" data-lasso-id="386">Food Wishes (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/SeriousEats" data-lasso-id="387">Serious Eats (YouTube)</a></li>
<li><a href="https://www.tiktok.com/@thatdudecancook?lang=en" data-lasso-id="388">@thatdudecancook (TikTok)</a></li>
<li><a href="https://www.tiktok.com/@sad_papi?lang=en" data-lasso-id="389">@sad_papi (TikTok)</a></li>
</ul>
<p><strong>Have a backup plan</strong></p>
<p>Learning to cook and feeding yourself can be two different things, especially when you are first starting out and failure rates are high. If you are going to try a new recipe for the first time on a busy week night that’s supposed to be your dinner that night (1) go for it! (2) have a frozen pizza or some other quick and easy back up plan ready in case you end up ruining the dish. It’s a really negative feedback loop to mess up a recipe and having to end up eating cereal for dinner, so have a backup plan.</p>
<p><strong>Read/watch the recipe several times well before cooking</strong></p>
<p>Read or watch your recipes <em>carefully,&nbsp;</em>several times, in preparation for trying a new recipe. It’s easy to miss, especially at first, that the recipe actually requires marinating over night, or needs buttermilk or some other ingredient you don’t typically have on hand. Don’t just plop open the recipe book at 7p and start with Step #1.</p>
<p><strong>Stick to a few core cookbooks</strong></p>
<p>Again, it’s easy to get overwhelmed by the millions of cookbooks out there. Like YouTube channels, I recommend finding a few comprehensive cookbooks that work for you and sticking to them for years until you get very confident with a wide variety of techniques. With cookbooks, Kindle will work but having the physical copy can also be really helpful (or honestly I usually get both). Here are some that I recommend:</p>
<ul>
<li><a href="https://www.amazon.com/Cook-Everything_Completely-Revised-Twentieth-Anniversary/dp/1328545431?tag=tyletrin-20" data-lasso-id="390" rel="nofollow noopener" target="_blank" data-lasso-name="How to Cook Everything">How To Cook Everything, Mark Bittman</a></li>
<li><a href="https://www.amazon.com/Cooking-Geeks-Science-Great-Cooks/dp/1491928050?tag=tyletrin-20" data-lasso-id="391" rel="nofollow noopener" target="_blank" data-lasso-name="Cooking for Geeks: Real Science, Great Cooks, and Good Food">Cooking For Geeks, Jeff Potter</a></li>
<li><a href="https://www.amazon.com/Salt-Fat-Acid-Heat-Mastering/dp/1476753830?tag=tyletrin-20" data-lasso-id="392">Salt, Fat, Acid, Heat, Samin Nosrat</a></li>
<li><a href="https://www.amazon.com/4-Hour-Chef-Cooking-Learning-Anything/dp/1328519163?tag=tyletrin-20" data-lasso-id="393">The Four Hour Chef, Tim Ferriss</a></li>
</ul>
<h2>Essential Concepts</h2>
<p>The books and channels above all have great introductions to all of these concepts so I’m not going to try to actually cover them here, but I think it’s useful have a few simple concepts to check off as you read/watch through the first few.</p>
<p><strong>What heat does (chemistry)</strong></p>
<p>Make sure you pay attention to the sections on the basic chemistry of heat. The vast majority of cooking is just different ways applying heat to food and it’s critical to understand what heat is doing to different kinds of foods. For the most part heat is either (1) denaturing proteins or (2) producing a Maillard Reaction. Denaturing proteins is the slow gradual cooking process that turns eggs from runny to scrambled or steak from rare to well done. Different foods have different kinds of proteins which denature at different temperatures and in different ways. The Maillard Reaction is browning (mostly on on meats and vegetables) and happens at very high heat and low moisture environments. Read up on these carefully. Cooking for Geeks covers these the best in my opinion.</p>
<p><strong>Different kinds of heat transfer (physics)</strong></p>
<p>Similarly to understanding what heat does, it’s really important to have a basic grasp of the various methods of applying heat to food. Baking, broiling, roasting, sautéing, braising, searing, sous vide, boiling, and so on, are all just different methods for applying heat. Some, like baking, use convection where the air is heated up around the food, and others, like searing in a pan, use conduction where the heat is transferred directly surface to surface. A cast iron pan takes a very long time to heat up and stays hot for a long time, whereas the air in your oven can dissipate its heat quickly. Understanding these basic concepts will give you the architecture for understanding for why you should keep the oven door closed as much as possible, dry your meat before searing, and pre-heat your heavy pans for longer than your light ones.</p>
<p><strong>Keep it simple</strong></p>
<p>When you are first learning to cook I recommend avoiding complex recipes in favor of simple two or three-part meals where each component is cooked individually. The vast majority of our home-cooked meals involve cooking (a) a protein like fish or meat (b) a vegetable cooked simply, like roasted in olive oil and (c) a starch like rice, potatoes, simple pasta. This let’s you build a healthy meal with simple individual components, master the same techniques with repeat practice, and minimize the risk of blowing up the whole dish.</p>
<p><strong>Make it taste good</strong></p>
<p>This may seem obvious, but it’s important that the food you cook actually taste good. Home-cooked food is almost always healthier than restaurant food, so don’t try to learn to cook and cook the healthiest possible version of each dish. Most veggies taste better roasted in a generous amount of olive oil than they do steamed, so roast them! Baste your chicken in butter. Salt your food generously. Learning to cook by producing dishes that just aren’t that tasty is a very bad feedback loop, so do what you need to to make it taste good.</p>
<p><strong>Don’t cook everything evenly</strong></p>
<p>This is a little more specific but I feel like it needs to be specifically counter-programmed. For some dumb reason a lot people (including myself 10 years ago) got the notion that food needs to be cooked&nbsp;<em>evenly</em>. That it’s really important to constantly turn and shake and rotate your food so that it’s cooked the same all the around and through. This is a great way to make gross food. Stop touching and turning your food. Most dishes are better with a substantial amount of difference in how cooked different sides of the food are: steak with a crunchy sear and medium rare inside, roasted potatoes with a waxy crust and fluffy inside, carrots or asparagus charred on side are all much tastier and mostly produced by having uneven cooking.</p>
<p><strong>Baking is really hard</strong></p>
<p>Really. Baking is much harder and less forgiving than any other kind of cooking. If you’re just starting to get into cooking, don’t start with baking.</p>
<h2>Essential Gear</h2>
<p>Okay, obviously you can spend and absolute fortune and fill a kitchen with mountains of cooking gear. That’s part of the fun of getting into cooking, let’s be honest. But if all you’ve got is a crappy 10-piece Wal-mart cooking set you got as a wedding gift or a hodge podge you inherited from your roommates, and you need to build your kitchen from scratch, this is the minimum kit I think you need. <em>(Disclosure: most of these are Amazon affiliates links. Don’t click them if that’s a thing that will make you mad).</em></p>
<p><strong>Pots and Pans</strong></p>
<p>The essential workhorses of cooking. Different kinds of pots and pans provide really different value for money, so I’ll specifically recommend below which ones I think it makes sense to invest in something …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tylertringas.com/cooking-for-founders/">https://tylertringas.com/cooking-for-founders/</a></em></p>]]>
            </description>
            <link>https://tylertringas.com/cooking-for-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719188</guid>
            <pubDate>Sun, 10 Jan 2021 20:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vuejs rejects close to 75% of outside contributions]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25719116">thread link</a>) | @gieksosz
<br/>
January 10, 2021 | https://merge-chance.info/target?repo=vuejs/vue | <a href="https://web.archive.org/web/*/https://merge-chance.info/target?repo=vuejs/vue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    
    <p><a></a>
        <span> of the PRs made by outsiders (not owners/members) get merged.</span>
    </p>
    
    
    <p><a></a>
        <i> * Based on most recent <strong> 272 </strong> outsiders' PRs </i>
    </p>
    <p><a></a>
        <i> * PRs open but not merged within 90 days are also treated as rejected </i>
    </p>
    
    
    <p><a></a>
        <span>
            Copy Markdown below to your README.md to get a Merge-Chance badge
        </span>
    </p>
<div>
    <pre>        <code>
            ![merge-chance-badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue)
            [merge-chance-link](https://merge-chance.info/target?repo=vuejs/vue)
        </code>
    </pre>
</div>
<p><a></a>
    <span> Like this one</span>
    <img alt="Custom badge" src="https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue">
</p>
<br>

<br>
<hr>




</div>]]>
            </description>
            <link>https://merge-chance.info/target?repo=vuejs/vue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719116</guid>
            <pubDate>Sun, 10 Jan 2021 20:10:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The M1 MacBook Air is the best computer I've ever owned]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 322 (<a href="https://news.ycombinator.com/item?id=25717727">thread link</a>) | @bouk
<br/>
January 10, 2021 | https://bou.ke/blog/macbouk-air/ | <a href="https://web.archive.org/web/*/https://bou.ke/blog/macbouk-air/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
  
  <p><span>Jan 2021</span></p>
  <p>I started a new job recently so I had the opportunity to get one of the new M1 MacBooks, I decided to go with the Air. The reviews have been very positive and I’m here to tell you: it is indeed an amazing device. The performance feels a lot better than my MacBook Pro 16”, which is only a year old and about 3x the price.</p>

<p>When I got the Mac I set out with the goal of avoiding Intel builds of software as much as possible and using native whenever possible unless it’s absolutely impossible.</p>

<h2 id="nix">Nix</h2>

<p>I have my <a href="https://github.com/bouk/b" target="_blank">whole system configuration</a> stored in <a href="https://bou.ke/blog/nix/">Nix</a>, which was the thing that I least expected to work and arm64 support is still a <a href="https://github.com/NixOS/nixpkgs/issues/95903" target="_blank">work in progress</a>. I could install the <code>x86_64</code> build of Nix and run it under Rosetta but wanted to avoid that, so I went back to my old pal;</p>

<h2 id="homebrew">Homebrew</h2>

<p>This was one of the first things I installed and got working, when I did it I had to install it into <code>/opt/homebrew</code> manually and install everything with the <code>--source</code> flag but… everything mostly worked? Lots of props to the Homebrew team for getting everything running so quickly, with some amazing <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank">open-source project management</a> the community worked together very quickly to support most of the software that Homebrew offers. There’s still some software that doesn’t work—notably neovim. But I’m sure that will be fixed soon.</p>

<p>The installer now installs into <code>/opt/homebrew</code> by default and there’s prebuilt bottles of most packages, so the Homebrew experience is great.</p>

<h2 id="go">Go</h2>

<p>A lot of my work involves Go, and I depend on a lot of tools written in Go. I was happy to see that the <a href="https://blog.golang.org/ports" target="_blank">Go team was on top of it</a> and released the 1.16 beta quite quickly, which is what is installed right now when you do <code>brew install go</code>. I’ve had no issues with it and am enjoying some of the new features like <a href="https://github.com/golang/go/issues/41191" target="_blank">file embedding</a>. GoLand was also <a href="https://blog.jetbrains.com/go/2020/12/30/goland-2020-3-1-is-out/" target="_blank">updated</a> to support M1 pretty quickly.</p>

<h2 id="terraform">Terraform</h2>

<p>Terraform I had the most issues with since using it depends on a bunch of plugins, which are generally only available for x86_64. This won’t change until Go 1.16 has been released. So here I had to resort to building for x86_64, which is easy to do:</p>

<div><div><pre><code>curl -L 'https://github.com/hashicorp/terraform/archive/v0.14.4.tar.gz' | tar -xzf-
cd terraform-0.14.4/
GOARCH=amd64 go build -o ~/bin/terraform
</code></pre></div></div>

<p>And now Terraform will just use plugin built for Intel. I assume that most Terraform plugins will support arm64 very quickly after Go 1.16 is out.</p>

<h2 id="rust-and-universal-binaries">Rust and Universal Binaries</h2>

<p>I use <a href="https://github.com/alacritty/alacritty" target="_blank">Alacritty</a> as my terminal. It supported <code>arm64</code> pretty quickly but the current build for it doesn’t include it, so I <a href="https://github.com/alacritty/alacritty/pull/4683" target="_blank">made a PR</a> that will build a universal binary. Creating a universal binary for Rust is quite easy:</p>

<div><div><pre><code>rustup target add x86_64-apple-darwin aarch64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>x86_64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>aarch64-apple-darwin
lipo target/<span>{</span>x86_64,aarch64<span>}</span><span>-apple-darwin</span>/release/alacritty <span>-create</span> <span>-output</span> alacritty
</code></pre></div></div>

<p>Running <code>file alacritty</code> will now show you something like:</p>

<div><div><pre><code>alacritty: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit executable x86_64] [arm64]
alacritty (for architecture x86_64):    Mach-O 64-bit executable x86_64
alacritty (for architecture arm64):     Mach-O 64-bit executable arm64
</code></pre></div></div>

<p>Now you can run it in either <code>x86_64</code> mode with <code>arch -x86_64 alacritty</code> or natively with <code>arch -arm64 alacritty</code> and the OS will automatically select the right binary.</p>

<p>Building a universal binary for a Go application is similarly easy:</p>

<div><div><pre><code>GOARCH=amd64 go build -o app_amd64 main.go
GOARCH=arm64 go build -o app_arm64 main.go
lipo app_{amd64,arm64} -create -output app
</code></pre></div></div>

<h2 id="windows-and-games">Windows and Games</h2>

<p>There’s a couple of <a href="https://en.wikipedia.org/wiki/Age_of_Mythology" target="_blank">games</a> I’ve been playing for a long time that I still need on any computer I get, but they’re 32-bit Windows-only. This was something that was surprisingly easy to get working:</p>

<ol>
  <li>Install the <a href="https://www.parallels.com/blogs/parallels-desktop-apple-silicon-mac/" target="_blank">Parallels Technical Preview</a></li>
  <li>Sign up for Windows Insider and download the <a href="https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewARM64" target="_blank">Windows 10 on ARM Insider Preview</a></li>
  <li>Install it into Parallels</li>
  <li>Done</li>
</ol>

<p>Now you can download Steam and basically install anything and it will probably work. Microsoft really did some amazing magic in getting both 32-bit and 64-bit x86 programs running on <code>arm64</code>.</p>

<p><img src="https://bou.ke/images/windows-solitaire.png" alt="" loading="lazy"></p><h2 id="conclusion">Conclusion</h2>

<p>Somehow Apple has created the best PC in every category at once. It is even the best Windows PC, despite the multiple layers of emulation that are happening. The battery life is incredible, I haven’t experienced any slowdowns, I don’t hear any fans spin up (because there are none). It’s hard not to be excited about this.</p>

<p>If Apple chose to go down this path, they could dominate the server space if they took their magic chips, put it in a <a href="https://en.wikipedia.org/wiki/Rack_unit" target="_blank">rack unit</a> and made it easy to install Linux onto it. Intel is completely screwed unless they come up with something better, fast.</p>

  <hr>
  <p>You should follow me on <a href="https://twitter.com/BvdBijl">Twitter</a>!</p>
</div>
</div></div>]]>
            </description>
            <link>https://bou.ke/blog/macbouk-air/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717727</guid>
            <pubDate>Sun, 10 Jan 2021 18:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Cargo Cult (2017)]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 111 (<a href="https://news.ycombinator.com/item?id=25717075">thread link</a>) | @dredmorbius
<br/>
January 10, 2021 | https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/ | <a href="https://web.archive.org/web/*/https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<p>Trump administration lies constantly but doesn’t even attempt to make it seem like they aren’t lying.</p>
<p>After the collapse of the Soviet Union, this kind of cynicism was referred to as the “reverse cargo cult” effect.</p>
<p>In a regular cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw, hoping for the same outcome. They don’t know the difference between a straw airstrip and a real one, they just want the cargo.</p>
<p>In a reverse cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw. But there’s a twist:</p>
<p>When they build the straw airstrip, it <em>isn’t</em> because they are hoping for the same outcome. They know the difference, and know that because their airstrip is made of straw, it certainly won’t yield any cargo, but it serves another purpose. They don’t lie to the rubes and tell them that an airstrip made of straw will bring them cargo. That’s an easy lie to dismantle. Instead, what they do is make it clear that the airstrip is made of straw, and doesn’t work, but then tell you that the other guy’s airstrip doesn’t work either. They tell you that <strong>no airstrips yield cargo</strong>. The whole <em>idea of cargo</em> is a lie, and those fools, with their fancy airstrip made out of wood, concrete, and metal is just as wasteful and silly as one made of straw.</p>
<p>1980s Soviets knew that their government was lying to them about the strength and power of their society, the Communist Party couldn’t hide all of the dysfunctions people saw on a daily basis. This didn’t stop the Soviet leadership from lying. Instead, they just accused the West of being equally deceptive. <em>“Sure, things might be bad here, but they are just as bad in America, and in America people are actually foolish enough to believe in the lie! Not like you, clever people. You get it. You know it is a lie.”</em></p>
<p>Trump’s supporters don’t care about being lied to. You can point out the lies until you’re blue in the face, but it makes no difference to them. Why? Because it is just a game to them. The media lies, bloggers lie, politicians lie, it’s just all a bunch of lies. Facts don’t matter because those are lies also. Those trolls on Twitter, 4Chan, T_D, etc. are just having a good laugh. They are congratulating each other for being so smart. We are fools for still believing in anything. There is no cargo, and probably never was.</p>
<p>Source: <a href="https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/">https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/</a></p>
					
					<p>
						Filed under: <a href="https://hanshowe.org/category/1100733/" rel="category tag">#!!#</a> |					</p>

				</div></div>]]>
            </description>
            <link>https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717075</guid>
            <pubDate>Sun, 10 Jan 2021 17:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We've been running a bootstrapped startup for a year]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25717006">thread link</a>) | @artembugara
<br/>
January 10, 2021 | https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways | <a href="https://web.archive.org/web/*/https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><h3>What is the value of this article? </h3><p>We are young, inexperienced, prone to fail: <strong>we’re 2 first time founders</strong>. I always prefer to learn from people who are just a few steps ahead of me. </p><h3>Who is this article for? </h3><p>If you’re a multi-time entrepreneur then you might not find this article interesting. <strong>If you’ve been thinking about starting your own startup then I’d recommend reading as many similar articles as possible.</strong></p><h2>Our Team</h2><p>Artem (author of this article):</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Quit the University after Masters 1 to get a job</p></li><li><p>Full-time since April 2020</p></li><li><p>CEO</p></li></ul><p>Maksym:</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Full-time since December 2020</p></li><li><p>CTO</p></li></ul><h2>Our Product - News API</h2><p>We provide instant access to news article data for hedge funds, market researchers, and PR software. </p><p><strong>In simple words: </strong></p><ol><li><p><strong>we crawl news websites, </strong></p></li><li><p><strong>detect news article URLs, </strong></p></li><li><p><strong>extract all possible information (title, published date, author, content, etc.), </strong></p></li><li><p><strong>index this data</strong></p></li></ol><p>Our main product is <a href="https://newscatcherapi.com/news-api">News API</a> which allows our clients to find structured news articles by any topic, country, language, website, or keyword. </p><p><a href="https://www.notion.so/newscatcherapi/News-API-46632a5cd61548919ff0132b15b0f0fa?p=2eff4d9b6e6b4a87a8e2230424aee4be">Example of News API JSON response</a>.</p><p>We’re B2B Data-as-a-Service.</p><h3>What I and my co-founder could achieve in 12 months</h3><ul><li><p>Monthly Recurring Revenue ~$3,000</p></li><li><p>Both co-founders work full-time</p></li></ul><blockquote>All things mentioned are purely personal. </blockquote><p><strong>1. Talk to your potential clients</strong></p><p>Talk to them even if you do not have a product. </p><p>Imagine you have the very best version of what you’re building. Go ahead and see what people say. </p><p>One more thing: <strong>CLIENTS</strong>. Not your friends, or some random people. Yeah, your friends will say “Great idea”. All of them. </p><p>What you really want to hear is “I like it. What’s the price? How can I buy it?”</p><p>People only vote with their pockets.</p><p><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">More read</a></p><p><strong></strong><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users"><strong></strong></a><strong>2. Do not think you/your product/your team/your approach are any different or unique</strong></p><p>We all want to be special. We all want to work for a company that will soon cost millions of dollars. We all want to be the first of our kind. </p><p>But, most likely, you, your team, your product is (below) average.</p><p>So, if you hear experienced people repeating the same thing to you then you should act. </p><blockquote><strong>Do not try to be “Yeah, but we’re…”</strong> </blockquote><p><strong>3. It’s almost impossible to raise money when you don’t have anything to show</strong></p><p>Do not expect investors to come and give you money. It’s a big gamble for you to start raising. Also, raising money is a full-time job!</p><p><strong>4. Start pitching investors as soon as possible</strong></p><p>Yes, do not expect them to give you money. However, there is a lot of things to do to raise money. You have to be prepared for when you’re ready. </p><blockquote>Pitch deck.  Pitching. Answering the questions. </blockquote><p>Do not spend much time on it. However, I would recommend to do it consistently. It will take months to come up with something consistent. So, you’d better start early.</p><p>Also, some investors will tell you why they will not give you money. Iterate, and work on these problems.</p><p><strong>5. Start small. Do things that do not scale. Be a consulting company</strong></p><p>Believe me or not but the only way to sell your scalable solution to millions of clients is to start by selling it one-by-one. In a non-scalable way. </p><p><a href="http://paulgraham.com/ds.html">More read</a></p><p><strong></strong><a href="http://paulgraham.com/ds.html"><strong></strong></a><strong>6. Do not be afraid to charge </strong></p><p>Charge for your service/product at a fair price. Yeah, you might lose some clients. But, how will you survive if you cannot get fair pay for your service? </p><p><strong>7. It’s a grind. Consistent one</strong></p><p>You have to repeat a lot of boring things over and over again. </p><p><strong>8. Only those who pay you money have to decide which features to add</strong></p><p>Do you think adding this feature is cool? Go ahead, and ask those who pay you. </p><p>Listen to what they say, and make a better product. </p><p><strong>9. Carefully choose co-founders</strong></p><p>We know each other for over 14 years. We knew well what to expect from each other.</p><p><strong>10. Help others &amp; Ask others for help</strong></p><p><strong>11. Things that no one actually cares about at the beginning</strong></p><ul><li>Logo</li><li>Name, website domain</li><li>Your background</li></ul><p><strong>12. Things that everyone cares about</strong></p><ul><li>Your value proposition</li></ul><p><strong>13. What is the definition of a “startup” for you? </strong></p><p>Can you give it? Maybe what you want to start is a small business. There’s nothing wrong with it. </p><p><strong>14. Do not afraid to take a step back</strong></p><p><strong>15. This list misses the other 100 points which we did not figure out yet! So, do not overlay on it</strong></p><p>All I’ve written here might be wrong/not applicable to you. But like I said, most likely you’re not different at all.</p></div></div></div></div>]]>
            </description>
            <link>https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717006</guid>
            <pubDate>Sun, 10 Jan 2021 17:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powerful Life Skills for the New Decade]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25716764">thread link</a>) | @neilkakkar
<br/>
January 10, 2021 | https://neilkakkar.com/powerful-life-skills.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/powerful-life-skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Over the past few years, I’ve noticed certain skills in people I admire, from Paul Graham, Vitalik Buterin, to Ender Wiggin.</p>

<p>These are rare skills, responsible for making them who they are. Most normal people, including me, don’t realise it. This makes the skills powerful - not everyone can see them, and very few people have mastered them.</p>

<p>However, I aim to change that. What follows below are 10 skills sourced from admirable people that I want to develop.</p>




<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<h2 id="learn-to-take-compounding-seriously">Learn to take compounding seriously</h2>

<p>It’s not just your wealth that compounds, but life experience and knowledge, too.</p>

<p>So, learn the most basic, most useful skills first. The longer you wait to learn skills like these, the less time there is for compounding magic. That’s what this entire list is about: powerful skills to learn and use for the rest of your life.</p>

<p>And even though you’ve heard about compounding, this item is first on the list, because <a href="https://neilkakkar.com/taking-ideas-seriously.html">taking ideas seriously is hard</a>.</p>

<p>A good way to figure out what compounds is <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">to figure out what’s a platform</a>.</p>

<h2 id="learn-to-develop-taste">Learn to develop taste</h2>

<p>Despite prevalent beliefs, taste isn’t subjective.</p>

<p>While it may seem like it on the outside, when you say “I just love this painting” or “I just love this coffee machine” - all it means is that the defining characteristics are illegible to you. And noticing this is the first step.</p>

<p>Let’s take a specific example. Say you’re designing a high quality clay pot - and you’ve never done this before.</p>

<p>What’s a good way to develop taste for quality here?</p>

<p>If you’ve heard this claypot parable, you know the answer: start by making lots of crap pots.</p>

<blockquote>
  <div><p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A,” forty pounds a “B,” and so on. Those being graded on “quality,” however, needed to produce only one pot—albeit a perfect one—to get an “A.”</p><p>

Well, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work—and learning from their mistakes—the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. - <a href="https://amzn.to/3o9o17A" target="_blank" rel="noopener">Art and Fear</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p></div>
</blockquote>

<p>Let others tell you what you’ve made is crap. Learn why. Notice when they tell you something is great. Figure out why.</p>

<p>This transfers to writing as well: Popular advice to get better is to write a lot of junk, do it a 100 times, and pay particular attention to what is received well. Here’s <a href="http://www.paulgraham.com/taste.html" target="_blank" rel="noopener">another example - developing taste for design</a>.</p>

<p>In effect, you bootstrap good taste by first learning what others consider good. Then, <a href="#learn-to-see-systems">you see the system behind it</a>. Then you break the rules and still manage to awe.</p>

<p>Then you’ve developed taste.</p>

<h2 id="learn-to-sequence-things-well">Learn to sequence things well</h2>

<p>Waking up when others are asleep and getting lots done is a super power. It’s born out of a system of <a href="https://neilkakkar.com/sequencing-things-in-the-right-order.html">learning to sequence things well</a>.</p>

<p>It means choosing the right time for that Netflix binge.</p>

<p>It means being prepared before the meeting, not scrambling to get things done after.</p>

<p>It means reading the coursebook before the lecture, not after.</p>

<h2 id="learn-to-see-what-others-see">Learn to see what others see</h2>

<p>How well can you understand other people? Can you sense their desires, their concerns, and what events lead to those desires and concerns?</p>

<p>If you can do this, you can understand them. But not before.</p>

<blockquote>
  <p>In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it’s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. - <a href="https://amzn.to/2KKe8Px" target="_blank" rel="noopener">Ender’s Game</a><sup id="fnref:1"><a href="#fn:1">2</a></sup></p>
</blockquote>

<p>It’s worth going this far because understanding is powerful. It helps you empathise. It helps you negotiate. It helps you figure out why you don’t have product-market fit. It helps you learn quickly: you can switch through personas and see what will and won’t work.</p>

<p>How do you do learn to see? I know no better way than to practice. Try it a 100 times. <a href="https://neilkakkar.com/subscribe">Come back next year</a>, and maybe I’ll have a better way once I’ve done it a 100 times.</p>

<h2 id="learn-to-make-and-execute-decisions-quickly">Learn to make and execute decisions quickly</h2>

<p>Most people have a bias towards analysis-paralysis versus getting shit done.</p>

<p>When decisions are reversible - and they mostly are - speed is a super power. Cultivating a habit of making decisions quickly, and then executing them is better than just thinking about it.</p>

<p>Training this skill begins as easily as deciding what to eat on a huge menu. It’s a small step, but over time, <a href="#learn-to-take-compounding-seriously">even the smallest steps compound</a>.</p>

<blockquote>
  <p>“Hesitation is always easy, rarely useful” - Prof. Quirrel alterego, <a href="http://www.hpmor.com/" target="_blank" rel="noopener">HPMOR</a></p>
</blockquote>

<p>Here’s an <a href="https://firstround.com/review/speed-as-a-habit/" target="_blank" rel="noopener">example in the context of business</a>. And a <a href="https://twitter.com/sama/status/1345140364995227648" target="_blank" rel="noopener">tweet from Sam Altman</a>.</p>

<h2 id="learn-to-spot-a-convex-or-concave-world">Learn to spot a convex or concave world</h2>

<p>In the world of viral infections, a 50% lockdown is worse than a 0% and a 100% lockdown, both. The virus isn’t contained, and businesses have to shut down, too.</p>

<p>In the world of immigration policies, letting some specific people in is better than letting no one or everyone in. The middle ground is better than the extremes.</p>

<p>When the best of both worlds is great, you’re in a concave disposition.</p>

<p>When the best of both worlds is worse than either, you’re in a convex disposition.</p>

<p>The world is sometimes concave, and sometimes convex. Knowing your topology can help you make better decisions.</p>

<p>I first noted this when <a href="https://vitalik.ca/general/2020/11/08/concave.html" target="_blank" rel="noopener">Vitalik Buterin explained it</a>. Read it for more concrete examples.</p>

<!-- ## Learn to do obvious things -->

<h2 id="learn-to-tell-stories">Learn to tell stories</h2>

<p>People donate more to charity when they know a single victim’s story, versus statistics of a thousand deaths. It’s called the <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a>, but it’s the power of stories over facts. The right framing gets you further than all the facts combined.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.”</p>
</blockquote>

<p>Ideas &amp; facts contextualised by stories are more powerful than either alone.</p>

<p><i></i><b>The Skill of Storytelling</b><br>
There’s lots to unpack here, and this is the first skill I’ve been working on for the past few months. Watch out for a long blogpost in 2 weeks!</p>

<h2 id="learn-to-dive-into-the-source-code-when-documentation-isnt-enough">Learn to dive into the source code when documentation isn’t enough</h2>

<p>Sometimes, there’s no precedent for what you want to do. Or the people who did it before didn’t write a manual.</p>

<p>In cases like these, figuring things out for yourself is powerful. Research papers and obscure books aren’t just for scientists. They’re freely available on the internet* for all of humanity to use. Learn to use it. Learn about resources like <a href="https://sci-hub.do/" target="_blank" rel="noopener">SciHub</a>, <a href="https://libgen.xyz/" target="_blank" rel="noopener">LibGen</a>, and hiring researchers. You’re allowed to hire people (specially graduate students!) to satisfy your research concerns.</p>

<p>… and when you’re done, <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html#writing-code">preserve context for future you</a>.</p>

<p>It’s a lot like trying to use an API that has no documentation. Would’ve been easy if there was documentation, but there isn’t. So you got to do it the hard way: read the source code and figure out what you need to make things work.</p>

<p>It’s also like <a href="https://neilkakkar.com/A-framework-for-First-Principles-Thinking.html">figuring out what you need to build rockets yourself</a> when existing ones are too expensive.</p>

<p><a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" target="_blank" rel="noopener">More resources here</a>.</p>

<h2 id="learn-to-be-specific">Learn to be specific</h2>

<p>Every time I gave an example above, I was training my specificity muscles.</p>

<p>Most of the time, most people don’t know what they’re talking about. Not being specific is a sign of that. The more abstract the word, the harder it is to pin down a meaning.</p>

<p>For example, “negative ramifications” doesn’t tell you what exactly happened, while “the sonic boom from the new supersonic jet destroyed windows in a 100m radius” is a lot more specific.</p>

<p>Learn to be specific, and learn to spot when others aren’t. <a href="https://www.lesswrong.com/posts/NgtYDP3ZtLJaM248W/sotw-be-specific" target="_blank" rel="noopener">Here’s how</a>.</p>

<h2 id="learn-to-see-systems">Learn to see systems</h2>

<p>There’s two kinds of people.</p>

<ul>
  <li>Bob, who will see this list, find some skills very interesting, and then go about honing those skills</li>
  <li>Alice, who will see this list, and wonder how I came up with these
<!-- - The Inspiration-Junkie, who will lurk and move on to the next inspiring post without changing anything -->
</li>
</ul>

<p>Alice would then try to understand the system that generated these ideas. Then, she’ll adopt the system, and come up with skills possibly more relevant to herself.</p>

<p>Having the option to do both is powerful. Since Bob is the default, <a href="https://neilkakkar.com/How-to-see-Systems-in-everyday-life.html">learn to be like Alice</a>. Choose <a href="https://neilkakkar.com/understanding-systems.html">systems when things are important</a> to you. Choose hacks when you need a quickfix.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>



    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/powerful-life-skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716764</guid>
            <pubDate>Sun, 10 Jan 2021 17:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weirdness of Kentucky Route Zero (2016)]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25716686">thread link</a>) | @olvy0
<br/>
January 10, 2021 | http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/ | <a href="https://web.archive.org/web/*/http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>In <a href="http://blog.joshhaas.com/2016/10/mr-robot-is-not-weird-enough/">my last post</a>, I took issue with the TV show <i>Mr. Robot</i> for not being weird enough. Although imaginative and compelling, its universe is well-ordered: everything happens for a reason.</p>
<div>

<p>If you’re looking for media to consume that doesn’t suffer from that problem, I recommend <a href="http://kentuckyroutezero.com/"><i>Kentucky Route Zero</i>.</a></p>
</div>

<p>I <a href="http://blog.joshhaas.com/2016/10/yet-another-review-of-the-trump-clinton-debate/">previously discussed</a> <i>Kentucky Route Zero</i> (<i>KR0</i> for short) in the context of the first Trump-Clinton debate. It’s relevant to that because it’s a tour through coal-country America, and it engages with the desolation there that’s fueling Trump’s support.</p>

<p>As a portrait of the region, it’s a Picasso or maybe a Goya, not a Velázquez. It has moments where it approaches documentary realism, but it mostly traverses an imaginary landscape reflecting its creators’ perceptions, inspired by their real-life travels in Kentucky.</p>

<p><i>KR0</i>’s medium is a computer game, but “game” is misleading. There’s no element of skill. It has the interface of an adventure game, but unlike other games in that genre, your progression through the story isn’t blocked by puzzles to solve. Rather, it’s more like a work of interactive fiction. The story is mainly told through dialogue, though the soundtrack and visuals are important pieces of the experience.</p>
<div>

<p>The medium is appropriate: it makes a better game than it would a book or a tv show. The ambition seems to be to create a world, and the ability to explore it freely is important. There’s a narrative, but the world is alive beyond the narrative, and there’s a lot to discover outside the main plot.</p>

</div>
<p>The three-person studio that produced <i>KR0</i>, Cardboard Computer, has been trying to erase the lines between their fictional universe and the real one. They’ve released a number of companion pieces to the game, including <a href="http://kentuckyroutezero.com/the-entertainment/">an experience for Occulus Rift or Mac / PC</a> where you participate as a cast member of a fictional 1973 production of a one-act play. The play appears to depict events that occur in a bar a few hours before the character you play in <i>KR0</i> visits the bar in the game, but the fictional set designer for the 1973 production — ie, a real person in the production’s fictional reality — is also a character in <i>KR0</i>. In case that wasn’t confusing enough, you can buy a <a href="http://www.lulu.com/shop/http://www.lulu.com/shop/lem-doolittle/the-entertainment/paperback/product-21312732.html">print copy of the script</a>, published under the name of the fictional author.</p>

<p>It’s not a bad play, either. As the script advertises, “The one-act play “A Reckoning,” set in a tavern in central Kentucky, is Doolittle’s take on the sort of barroom tragedy made popular by O’Neill, Gorky, etc.”, and I would say it stands on its own as a piece of theater, although the ending will have more resonance if you’ve played through <i>KR0</i>.</p>

<p>This almost pedantic accumulation of fictional detail, both inside and outside the game — names, biographies, places, events — lends believability and power to <i>KR0</i>’s magical realist plot-line. Because the production team took such great pains to create verisimilitude, the more fantastic elements of the game feel justified: hauntings, strange and implausible creatures, a whiskey company whose employees are all glowing skeletons, and the titular Route 0, a hidden underground highway through non-euclidean space.</p>

<p>The game’s plot is simple and unobtrusive compared to the sprawling, strange world it is set in. Conway, a truck driver for an antiques store, is trying to make a delivery to Dogwood Drive, a street that doesn’t show up on his maps. As he looks for it, he picks up some traveling companions, and we learn more about his and their pasts. <i>KR0</i> isn’t complete yet —the game is divided into five acts, and final one hasn’t been released — so I don’t know yet if Conway ever makes it to his destination.  In fact, I still don’t know what he’s delivering, or to whom.</p>

<p>As a player, the main way you exert agency is through your choice of dialogue options. Unusually for adventure-style games, your dialogue choices don’t seem to affect the plot. Rather, they affect the past: you can give the characters different backstories, influence their temperaments, change how they see the world and treat each other. It’s a limited degree of freedom: I haven’t flexed the game aggressively to see how divergent you can make it, but my understanding is that the basic outline of who the characters are always remains the same. It’s more of a matter of altering the shadings.</p>

<p>The net effect of the simple plot, the strange, expansive world, and the freedom to emphasize and explore different aspects of the characters is that playing the game doesn’t feel like you’re being told a story, with themes and a moral. Rather, it feels more like an invitation to you, the player, to interpret what you’re confronted with. The game gives you a lot of details to work with, and powerful images and emotions, but leaves you to decide what to think about it all.</p>

<p>At its heart, I think <i>Kentucky Route Zero</i> is a meditation on entropy. Certainly, entropy is the unifying characteristic of the game world. <i>KR0</i>’s setting is a Kentucky that’s been devastated by the collapse of the coal industry and by the 2008 housing crisis. Everything you encounter is in some state of falling apart. The gas station you refuel at has overdue electric bills. The bar can’t buy alcohol any more. The coal mine is abandoned. Conway’s dog looks like she’s seen better days. All the characters have various stories of poverty, alcoholism, loss, and debt.</p>

<p>Entropy has different facets. There are many different stances that one can take towards it. <i>KR0</i> seems to explore each of them in turn, weighing them, inviting you to partake.</p>

<p>The most basic stances are the emotional ones: despair, grief, and anger. There’s certainly plenty of that throughout the game. In one particularly powerful moment, you come across a memorial for coal miners who drowned when some tunnels were flooded in an accident a decade or so ago.  The memorial is a collection of hard-hats floating in an underground lake, accompanied by an angry, hand-written sign accusing the mining company of negligence. In another moment, you meet a team of engineers who spent their lives trying to build a computer system (called Xanadu, presumably a reference to the <a href="https://www.wired.com/1995/06/xanadu/">real world could-have-been internet competitor</a>), who are now just sitting around hopelessly, having given up on ever completing their lives’ work.</p>

<p>Another stance is simple momentum: keeping going on as long as you can. One character you meet is a switchboard technician, the last one on her team after all her coworkers were laid off by the phone company automating the systems. They couldn’t quite automate her, so she keeps plugging away, alone in a tunnel, connecting call after call. There’s also a church, relocated to a warehouse by some beauracrats, where the congregation all drifted away, the preacher left, and now it’s just a janitor who puts on pre-recorded sermons every Sunday.</p>

<p>Entropy and grief can also give rise to beauty. <i>KR0</i> has plenty of beautiful moments too. The game has a gorgeous soundtrack, mixing electronic music and ambience with bluegrass classics. The bluegrass pieces, performed by a mysterious wandering trio who occasionally wander across your path, are all explorations of loss and hardship, transmuted into folk songs and hymns. The visual palette of the game is mixture of blues and oranges, mostly subdued and minimalist, but occasionally spectacular. Everything has a satisfying organic, analog feel. Radio systems crackle, televisions hum, computers react to strange magnetic fluctuations.</p>

<p>Yet another approach to entropy is to consume and exploit it. At various points in the game, you encounter modern, structured institutions, that are in the process of channeling the breakdown toward their own ends. There’s a whiskey distillery that’s steadily acquiring the balance sheets and souls of the folks you meet. You get to take a tour of its expansive, industrially-clean factory in an amazing descent-into-hell sequence that feels like Dante meets OSHA. The local power company also seems to be on the march. There are also more highbrow institutions consuming the entropy. For instance, you visit the “Bureau of Reclaimed Space”, which seems to represent government, taking in weirdness and outputting paperwork. In another interlude, you find an entire town that’s been transplanted to be inside a museum, the residents still living in their houses, enclosed in a giant glass warehouse.</p>

<p>Somewhat related to high-brow consumption, there’s intellectualization of entropy. <i>KR0</i> has a steady stream of references to academia. You meet a number of characters who have spent time in the grad student / post-doc limbo space, and there’s a lot of art and math jargon. From an academic perspective, entropy is a source of phenomena to record, analyze, and write papers about — hopefully publishable ones. This content is a reflection of the game itself, which in many ways feels like a modern art project. <i>KR0</i> is obsessed with topology and imaginary spaces. Characters muse about space aloud, and as you move around the game, you explore a number of different spaces and means of navigating them: a driving map of Kentucky as navigated by truck, the same map as navigated by a bird, a bureaucratic office building where you ride an elevator up and down, a pure mathematical abstraction that you traverse by turning around at certain symbols, an endless underground river where you are swept along on a boat, among others. This self-conscious exploration invites you to see the entropy in <i>KR0’s</i> world as something to think about and study.</p>

<p>Finally, entropy gives rise to newness: the inadvertent creativity of random processes. Two of the more memorable characters you meet are a pair of androids that, in their telling, emerged from the mines as shapeless lumps, and transformed themselves into a pair of motorcycle-riding musicians, who are now <a href="https://killscreen.com/articles/kentucky-route-zeros-junebug-set-release-tktk-album-androids/">releasing an album outside the game</a>. Abandoned things in <i>KR0</i> tend to take on a life of their own.  A hobo sets up shop as an organist in a church converted into an office …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</a></em></p>]]>
            </description>
            <link>http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716686</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The many lies about reducing complexity part 2: Cloud]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 125 (<a href="https://news.ycombinator.com/item?id=25714822">thread link</a>) | @rapnie
<br/>
January 10, 2021 | https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/ | <a href="https://web.archive.org/web/*/https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The world has been getting a lot more complex, most people will agree to that. A major element in that rising complexity has been the <a href="https://ea.rna.nl/2020/02/11/a-tipping-point-in-the-information-revolution/">insanely huge amounts of machine logic we human species have been adding to the world</a>. Both that logic itself, as what it enables — think globalisation of trade and communication — has made most of our lives more complex and complicated in one way or another. And while it has brought us much, it also has a serious <a href="https://ea.rna.nl/2020/03/04/gossip-trust-and-the-information-revolution/">number of unwanted side-effects</a>.</p>



<p>We run into the boundaries of our ability to handle that complexity on a daily basis. Be it the large IT projects that invariably run late, cost too much, maybe even straight out fail. Or how we must try to stay secure in a digital world full of brittleness of logic and the weaknesses of humans.</p>



<p>[Note 1: This article is meant to be understandable (with a bit of effort) by non-specialists. There is quite a bit of jargon in it, but I try my best to explain all of it, including a table below with extensive explanation of a number of key terms. If I don’t explain a term, it is safe to ignore it if you don’t know what it is (e.g. when I mention a ‘tomcat server’ as an example), it is helpful for those that know, but not really necessary to know what it is to follow the story]</p>



<p>So, it isn’t a surprise that in IT, a constant drive over the last decennia has been the drive to reduce complexity. <em>‘Reducing complexity’ sells.</em> Especially managers in IT are sensitive to it as complexity generally is their biggest headache. Hence, in IT, people are in a perennial fight to make the complexity bearable. One method that has been popular for decennia has been standardisation and rationalisation of the digital tools we use, a basic “let’s minimise the number of applications we use”. This was actually part 1 of this story: <a href="https://ea.rna.nl/2016/01/10/a-tale-of-application-rationalization-not/">A tale of application rationalisation (not)</a>. That story from 2015 explains how many rationalisation efforts were partly lies. (And while we’re at it: enjoy <a rel="noreferrer noopener" href="http://dilbert.com/strip/2011-01-07" target="_blank">this Dilbert cartoon</a> that is referenced therein.) Most of the time multiple <em>applications</em> were replaced by a single <em>platform</em> (in short: a platform is software that can run other software) and the <em>applications</em> had to be ‘rewritten’ to work ‘inside’ that platform. So you ended up with one <em>extra</em> platform, the <em>same</em> number of applications and generally a few new <em>extra</em> ways of ‘programming’, specific for that platform. That doesn’t mean it is <em>all</em> lies. The new platform is generally dedicated to a certain type of application, which makes programming these applications simpler. But the situation is not as simple as the platform vendors argue. As Frederick Brooks had already told us in 1986: <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">There Is No Silver Bullet</a>.</p>



<p>Another drive has been to encapsulate (hide) complexity and access it through simpler interfaces. And a third has been to automate IT itself, creating complex ‘management IT’. All three play a role when we start to outsource IT to cloud services like Microsoft Azure or AWS.</p>



<p>[Note 2: This article has gotten out of hand. Totally. Quite long while I don’t digress a lot — as I often do. But exposing hidden complexity cannot be done without presenting it to you. And not understanding how complex the real IT world is leads to bad outcomes. When the software for supporting the Covid-19 vaccination campaign was a few weeks(!) late because testing wasn’t done yet, I read about a leading politician state something like “Come on, a bit of testing, how hard can it be?”. That is a cringeworthy display of not understanding how complex IT is. And that is partly why I write this. Because until our leaders actually start to understand this, they will create more and more disasters out of ignorance. Back to the story.]</p>



<p>Cloud services have generally been explained (sold) to us with a graphic like this:</p>



<figure><img data-attachment-id="172827" data-permalink="https://ea.rna.nl/xaas-orthodox-1/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg" data-orig-size="2519,1755" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-1" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Typical depiction of what is being outsourced when you move to the cloud</figcaption></figure>



<div>
<div>
<p>For non-technical people,  here is a basic explanation of terms used in the above figure and in the text.</p>



<p><span><strong>On Premises</strong></span>: Using your own hardware<br><span><strong>Application</strong></span>: Software that you use, e.g. Microsoft Word.<br><span><strong>Data</strong></span>: The data in your program, say your text in Word.<br><strong><span>Runtime</span>:</strong> Software that is required for other software to run, e.g. basic functionality for Java programs (‘Java runtime’). (Java is a programming language.)<br><span><strong>Middleware</strong></span>: More complex software that is required for other software to run but may also have its own function. E.g. a database.<br><span><strong>Operating System</strong></span>: The lowest layer of software that sits between the machine and all other software. Like Windows or macOS at home.<br><span><strong>Virtualisation</strong></span>: A way to turn one very big real ‘machine’ (computer) into many <em>virtual machines</em> by arranging multiple operating systems to share the big machine. Sharing increases efficiency because not all operating systems are busy at the same time. It also has other advantages.<br><span><strong>Server</strong></span>: The big ‘real’ machine. Like your computer at home but much bigger with multiple processors and lots of memory so it can be shared.<br><span><strong>Storage</strong></span>: Separate machine that is optimised to provide storage (disks), can be used by multiple servers. At home people sometimes have this too in the form of a NAS. These are generally ‘appliances’, that is specialised hardware (in this case with a lot of disks) with specialised software to manage them.<br><span><strong>Networking</strong></span>: Separate machine that enables data traffic between systems. Like your modem, router and Wifi Access Point at home. Again, an appliance with specialised hardware (in this case network interfaces such as wifi antennas and sockets for network cables) that has specialised software to manage these.</p>
</div>



<div>
<p>The suggestion is this: as we move away from our own IT ‘on-premises’ (which includes whatever co-hosting data center you use, in. this context it just means you own your own IT hardware) to more and more in the cloud, we are outsourcing more and more, we are responsible for less, <em>our life simplifies</em>. More cloud is cheaper, simpler and more flexible. What is there not to like?</p>



<p>What there is not to like is that this suggestion is for a large part a lie. And a nasty one.</p>



<p>Take for instance networking. According to the graphic, as soon as you move to the cloud, it’s no longer your responsibility. But that is a lie, except for the rightmost option (SAAS — more about this later). If you set up your IAAS or PAAS in the public cloud — say Microsoft Azure — you have to manage quite a bit of networking. In fact, while Microsoft runs the underlying <em>hardware</em>, much of what has to be managed, will be managed by you. You decide on segmenting, networking, VPNs (virtual private networks — a way to protect traffic between networks), routing firewalls, etc., you’re just using Azure tooling to set it up. It’s easier, but it’s far from all gone.</p>



<p>It is best explained by using an example. Suppose you open up some of your cloud-based systems to access from the public internet? You can do that. And suppose you shouldn’t have, because these systems contain sensitive data? And suppose this data is stolen in a very public breach? Who is to blame? Microsoft for providing you with enough rope to hang yourself, or you? It is clear that if this is a big news story, the heading will not be “Microsoft was lax with its security and management”, but “Company X was lax with its security and management <em>in the cloud</em>“.</p>








</div>
</div>



<p>So, the reality of the situation is therefore more like this:</p>



<figure><img data-attachment-id="172832" data-permalink="https://ea.rna.nl/xaas-orthodox-morerealistic-5/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg" data-orig-size="2541,1766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-morerealistic-5" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A slightly more realistic depiction of self-sourcing versus cloud outsourcing</figcaption></figure>



<p>The hardware — the iron — is indeed something that is completely handled by a cloud provider. This includes things like connecting the server to networks, power, etc., and replacing disk drives, fans, etc. In a fully self-sourced setup this actually turns out to be a limited affair. Most of the work is not hardware these days, it is software. Companies that run their own on-premises data centers don’t have a lot of data center hardware operators. Take the networking engineers. They may lay a few cables to a switch, but after that it is quickly moving to the management console and manage the appliance throughputs management interface — in other words: software work. Networking engineers, storage engineers, and compute engineers alike, their main tool is not a screwdriver, their main tool is a <em>keyboard</em>. Only the basic servers for virtual machines have little in terms of configuration. Networking and storage are <em>appliances</em>, specialised hardware with specialised software. The cloud provider has an interface on top of these that gives you that ‘enough rope to hang yourself with’, i.e. much of this is actually set up and maintained by you. Microsoft doesn’t create or manage your firewall settings, it only offers you an interface to create a virtual firewall running on their appliances and manage that <em>yourself</em>.  So it is a shared responsibility, and especially in networking: you do most of the work in much of the same way you would have to do when you were running your own appliances. Using a firewall in Azure is Microsoft spinning up a virtual appliance for you. And from that moment on, the work is all yours.</p>



<p>The only form of cloud where you really get rid of a lot of responsibility is Software-as-a-Service, or SAAS. That is because SAAS actually simplifies matters… …for the vendor. As explained in the EAPJ article <a href="http://eapj.org/vertical-integration-versus-horizontal-standardisation/">Vertical Integration versus (horizontal) standardisation</a>, the big advantage of SAAS is that the vendor of an application doesn’t need to support a myriad of technical landscapes out there, no myriad of different Linux versions, Java versions, as well as their configurations (security baselines, anyone?), just a single stack they fully manage themselves. That brings a huge standardisation for the vendor, and the advantage of that can be sold (in part) to the customer. Your responsibility is generally limited to a bit of Application tinkering (maybe add plugins, do some configuration) and of course your content. (And even the almost total outsourcing of SAAS is a little lie …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</a></em></p>]]>
            </description>
            <link>https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714822</guid>
            <pubDate>Sun, 10 Jan 2021 14:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teacher creates ingenious exam question to find cheaters and catches 14 students]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25713861">thread link</a>) | @ColinWright
<br/>
January 10, 2021 | https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848 | <a href="https://web.archive.org/web/*/https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><form data-mod="skinnySignup" data-json="{&quot;mailingListId&quot;:&quot;37995&quot;,&quot;displayName&quot;:&quot;daily&quot;,&quot;callToAction&quot;:&quot;<p>Get all the very latest news in Ireland straight to your email every single day</p>&quot;,&quot;buttonText&quot;:&quot;Sign up!&quot;,&quot;contentId&quot;:6321963,&quot;newsletterImage&quot;:&quot;https://i2-prod.irishmirror.ie/incoming/article22352084.ece/BINARY/1_Covid-19-Scenes90466558.jpg&quot;,&quot;endpointUrl&quot;:&quot;https://response.pure360.com/interface/list.php&quot;,&quot;profile&quot;:&quot;Irish_Mirror&quot;,&quot;isPure360NewsLetter&quot;:true,&quot;pure360MailingListId&quot;:&quot;Irish Mirror - Daily Newsletter&quot;,&quot;newsletterSiteName&quot;:&quot;Irish Mirror&quot;}"><div><div><div><p><span><span>When you subscribe we will use the information you provide to send you these newsletters. Sometimes theyâ€™ll include recommendations for other related newsletters or services we offer. Our</span><a href="https://www.irishmirror.ie/privacy-notice/">Privacy Notice</a><span>explains more about how we use your data, and your rights. You can unsubscribe at any time.</span></span></p></div></div><p><span>Invalid Email</span></p></div></form><!-- Article Start--><p>Students who assumed their teacher 'on the older side' wouldn't be familiar with the latest cheating methods were caught red handed when he devised a brilliant method to catch them out.</p> <p>A pupil in the engineering class explained that when they all sat down to take their final exam, about half the class left the room to use the bathroom during the test - far more than the usual.</p> <p>The student said they assumed the vast majority were looking up answers on their phone, which 'irritated me' but they stayed focused and made their way through the paper.</p> <p>After leaving the exam hall, the pupil remembered there was one particular question that wasn't related to what they had all been taught in class, which had two parts - the Mirror UK reports.</p> <p>Part A was 'fairly easy' but they had no idea how to do part B, so they simply left it blank as it only accounted for 5 marks out of 100.</p> <figure data-mod="image" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="410">
<div>

<p><img data-src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" alt="" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
</p>
</div>
<figcaption>
<span itemprop="author"> (Image: Tetra images RF)</span>
</figcaption>
</figure> <p>When all the exams had been marked, their teacher sent all the university students an email to explain his diabolical plan to catch out those who had given themselves some outside help.</p> <p>Many of the pupils used the internet to find answers to exam and homework questions.</p> <p>Their teacher decided to use it against them after becoming fed up with students using the bathroom as an excuse to look up answers on their phones.</p> <section data-embed-group="read-more" data-embed-items="2" data-ad-dockable="true">   </section> <p>The student wrote on Reddit: "He purposely made part B impossible to solve, and about a month before the final he got a teaching assistant to ask the exact question [online], which was distinctly worded to be unique.</p> <p>"He then created his own account and answered the question with a bulls*** solution that seems right at first glance but is actually fundamentally flawed and very unlikely that someone would make the same assumptions and mistakes independently."</p> <p>From the 99 exams handed in, 14 of them fell for the trick and gave the exact answer their own teacher had posted online.</p> <p>All were given an overall score of zero and reported to the university for violating the academic honor pledge they had signed.</p> <p>Their names were also circulated to all the other teachers in the department as known cheaters - and all the other students who hadn't cheated were given full marks for the bogus question.</p> <p>Others were impressed with cunning plan, with one replying: "This is Amazing! I've seen some stories like this and it always makes me glad I don't use [the internet] for tests.</p> <p>"Honestly if you're cheating on a proctored test you deserve to get caught. Study like everyone else."</p> <p>A second wrote: "Honey pot the cheating site. Genius!"</p><!-- Article End--></div></div>]]>
            </description>
            <link>https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713861</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Using flamegraphs to read big HN threads]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25713858">thread link</a>) | @trungdq88
<br/>
January 10, 2021 | https://trungdq88.github.io/hn-big-threads/index.html | <a href="https://web.archive.org/web/*/https://trungdq88.github.io/hn-big-threads/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        Loading... https://news.ycombinator.com/item?id=25706993
      </p>
    </div></div>]]>
            </description>
            <link>https://trungdq88.github.io/hn-big-threads/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713858</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Polar Vortex collapse sequence has begun]]>
            </title>
            <description>
<![CDATA[
Score 258 | Comments 187 (<a href="https://news.ycombinator.com/item?id=25713704">thread link</a>) | @makepanic
<br/>
January 10, 2021 | https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/ | <a href="https://web.archive.org/web/*/https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><strong>A Polar Vortex collapse sequence has begun in late December 2020, with a major Sudden Stratospheric Warming event on January 5th, 2021. We will look at the sequence of these events, and how they can change the weather in Europe and the United States in the coming weeks.</strong></p>
<p>The main “player” in these weather events, is of course the <strong>Polar Vortex</strong>. It connects the bottom of the atmosphere (our weather) with the stratosphere above it. A strong exchange of energy between these two layers can heavily disrupt the weather development across the Northern Hemisphere.</p>
<h5><span><strong>WHAT IS THE POLAR VORTEX?</strong></span></h5>
<p>Since knowledge is the key, we will do a quick recap of what exactly is the Polar Vortex.</p>
<p>All of the clouds (and the weather that we feel) are found in the lowest part of the atmosphere called the <span><strong>troposphere</strong></span>. It reaches up to around 8 km (5 miles) altitude over the polar regions and up to around 14-16 km (9-10 miles) over the tropics.</p>
<p>Above it, there is a much deeper layer called the <span><strong>stratosphere</strong></span>. This layer is around 30 km thick and is very dry. We can see the layers of the atmosphere on the image below, with the <span>stratosphere</span> in green hues, and the <span>troposphere</span> in blue at the bottom.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-image-id="21664" data-title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-stratosphere-weather-warming-atmospheric-layers" title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" width="475" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20475%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Every year as we head into autumn, the north pole starts to cool. But the atmosphere further south is still relatively warm as it is still receiving energy from the Sun. The north pole receives very little sunlight and thermal energy, cooling at a faster rate.</p>
<p>The reduction in temperature also means a gradual pressure drop over the north pole. In the stratosphere, the process is the same. As the temperature drops over the pole and the temperature difference towards the south increases, a low-pressure area starts to develop across the stratosphere.</p>
<p>The image below shows a typical example of the Polar Vortex at around 30km altitude (10mb level) in the middle stratosphere.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-over-north-pole-winter.jpg" data-image-id="21663" data-title="polar-vortex-over-north-pole-winter" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-over-north-pole-winter" title="polar-vortex-over-north-pole-winter" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>It is almost like a very large cyclone, covering the whole north pole, down to the mid-latitudes. The polar vortex is present at all levels, almost from the ground up. The image below shows the polar vortex at different altitudes. The closer to the ground we get, the more deformed it gets, due to the complex terrain and the many weather fronts and systems.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-winter-weather-warming-north-hemisphere.png" data-image-id="21666" data-title="polar-vortex-winter-weather-warming-north-hemisphere" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-winter-weather-warming-north-hemisphere" title="polar-vortex-winter-weather-warming-north-hemisphere" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We produced a high-resolution video for you below, which very nicely shows the Polar Vortex spinning over the Northern Hemisphere. It covers the period from December 2020 to January 2021, made from NASA GEOS-5 data.</p>
<p>Video shows the 10mb level (30km altitude) potential vorticity parameter, which overly simplified means, that it shows the energy of the polar vortex. Be aware of how the energy is being taken away from the polar vortex by the invisible polar Anticyclones (having a different kind of power), spinning in the opposite direction.</p>


<h5><span><strong>SUDDEN STRATOSPHERIC WARMING</strong></span></h5>
<p>&nbsp;<br>
As a general reference, we usually look at the polar vortex in the stratosphere at the 10mb level. That is around 28-32km (17-20 miles) altitude. This is considered to be around the middle stratosphere, and thus a good representation of the general dynamics of the polar vortex.</p>
<p>The strength of the polar vortex is most often measured by the power of the winds inside it. Usually, this is done is by measuring the zonal (west to east) wind speeds around the polar circle (60°N latitude).</p>
<p>Below we have an analysis from the NASA monitoring system, where we can see a very interesting progression. In early December, the polar vortex was at a quite strong level, reaching 40m/s zonal wind speeds. Problems began towards the mid-month, and especially towards late December when the stratospheric warming began. All graphics below are at the 10mb level (~30km altitude).</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-image-id="21665" data-title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Below is an image from the video we showed you earlier in the article, and it shows a quite healthy polar vortex in early December. It has a nice shape and a healthy spinning core.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-image-id="21669" data-title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" data-description="" target="_self">
 <img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-early-december" title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Towards mid-December, the pressure from the North Pacific was rising, with an Anticyclonic presence there gaining strength. The anticyclonic circulation was slowly getting stronger, starting to drain some energy away from the polar vortex, and changing its shape.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-image-id="21672" data-title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>By late December, the Pacific/East Asian Anticyclone became quite a force, now draining a lot of energy from the Polar Vortex and actually becoming visible.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-image-id="21670" data-title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-late-december" title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At a similar time in late December, a warming sequence began, from Europe over into central Asia. It was starting to engulf the outside layers of the polar vortex. The cold-core of the polar vortex is still rather intact at this point, holding temperatures colder than -80°C in the center over Greenland.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-image-id="21673" data-title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Just two days later, the warming wave reached a local peak over Siberia, with maximum temperatures in the wave reaching up to +5°C or higher.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-image-id="21674" data-title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>On January 5th, the preliminary date of the Sudden Stratospheric Warming event was marked, as the winds around the polar circle have reversed. We can see how massive and strong the Anticyclone has now become, pushing strongly against the polar vortex (bright white). Together with the warming wave, the strong Anticyclonic system has deformed the once circular polar vortex into a banana-shaped feature.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-image-id="21668" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The warming wave has crawled over the entire North Pole in the stratosphere, effectively splitting the cold-core of the polar vortex into two parts. One over North America and one over the European sector. At this point, this does not have much to do directly with the weather on the surface, as it is at 30km altitude, but we will get to weather effects soon.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-image-id="21675" data-title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Looking quickly at the forecast, we can see that the stratospheric Anticyclone will hold stable and move further over the North Pole. It will continue pushing against the very broken polar vortex.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-image-id="21671" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At this point, a new warming wave is also forecasted to start, which should temporarily prevent any quick reorganization and strengthening of the stratospheric circulation.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-image-id="21676" data-title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Taking a look at the <a href="https://ozonewatch.gsfc.nasa.gov/meteorology/NH.html">NASA</a> temperature analysis for the stratosphere, we can see the large temperature spike at the 10mb (30km) level, which is in the middle stratosphere. The second image shows the temperature analysis in the lower stratosphere at 50mb (20km) level, also having a very clear temperature spike.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-image-id="21679" data-title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-image-id="21678" data-title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Looking even lower, we have the 150mb level, which is kinda the boundary or the “buffer zone” between the stratosphere and the troposphere. Here we can also see the temperature spike, meaning the warming event was fairly robust and fast.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-image-id="21677" data-title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<h5><span><strong>HISTORICAL WEATHER, FOR THE FUTURE</strong></span></h5>
<p>&nbsp;<br>
Before looking closer at the weather forecasts and their relation to the polar vortex, we need to look at some historic examples of similar events. History can sometimes be the best teacher for the future, and in science, this can be true more often than not.</p>
<p>Below we have 2 images, which both are quite simple to read and understand. They show time from left to right, and altitude from bottom to top. Colors show the temperature anomaly, with red being warmer than normal and blue was colder than normal. We can nicely track the progress of stratospheric warming events over time and altitude.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-image-id="21683" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-image-id="21681" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We can see the progression of warming from the top of the stratosphere, going downwards over time. The first image shows the 2004 stratospheric warming event and the second graphic shows the 2013 event.</p>
<p>The important takeaway is that the warming progresses quite fast down into the troposphere and can start to quickly affect our weather. But it usually stops around 100mb or 150mb level (12-15km). That is normal, due to the fact that we can see a lot of strong weather systems in our troposphere, which can in some cases deflect/reverse any incoming effects from the stratosphere.</p>
<p>Below we have similar two images, but with pressure anomalies instead of temperature. But here you can actually see the connecting points between high pressure coming downwards and the surface layer in the polar region. In both cases, the final effect was seen as individual connections to the bottom levels over time, interfering with the weather development. This indicates that the influence from the Polar Vortex collapse events is periodically interfering with the weather development on a sub-seasonal scale, kinda like waving or resonating.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-image-id="21680" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-image-id="21682" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We don’t yet have the same graphic for 2021, for obvious reasons, since we still need more data to be gathered. But we can look at the forecast data in a similar image below.</p>
<p>What we are seeing is a very similar pattern as in 2004 and 2013. The negative values in this image represent higher pressure. So we can see the descending high-pressure, making individual contacts with the lower layers. This means that the influence is not a constant every time, but rather periodic.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-image-id="21689" data-title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG" alt="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG">
</a>
</p>
<p>We also decided to look at the weather patterns prior to the 2004 and 2013 events. And we can see in the images below. We can see on the first image for 2004, that the pattern was already positioned for colder weather over Europe, thanks to the strong high-pressure system in the North Atlantic. The United States was generally milder, with southerly flow dominating much of the CONUS.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-image-id="21688" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif-nggid0521688-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>In 2013, the picture was kinda the opposite. The pattern over the United States was generally colder than in 2004, while Europe was mild to warm even at this point.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-image-id="21686" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif-nggid0521686-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>This winter, the pattern is kinda a combination of both. We have another cooler/colder episode over Europe like in 2004, thanks to the high-pressure systems in the North Atlantic. At the same time, we also heed a few decent cold episodes over the United States as well.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-image-id="21692" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif-nggid0521692-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>But after the Polar Vortex breakdown and the stratospheric warming event, the pressure patterns changed quite importantly in 2004 and also in 2013. The image below is the pressure pattern one month after the Polar Vortex collapse in 2004. The strong high pressure in the North Atlantic has been replaced by a strong deep low-pressure system, and the high-pressure has moved into the Arctic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</a></em></p>]]>
            </description>
            <link>https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713704</guid>
            <pubDate>Sun, 10 Jan 2021 11:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Prosody developers spent 2020]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25713679">thread link</a>) | @upofadown
<br/>
January 10, 2021 | https://blog.prosody.im/2020-retrospective/ | <a href="https://web.archive.org/web/*/https://blog.prosody.im/2020-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
  


  <div>

    

    
    <div>
      <p><small>
        <p><time datetime="2021-01-08T00:00:00Z">
          2021-01-08
        </time> by The Prosody Team
         
        <br>
        
        </p>
        

        
        
        <br>

      </small></p>
    </div>
    <p>Nobody here knew quite what a year 2020 was going to be! However despite
pandemics and lockdowns, we have continued to work on Prosody. This post
is a summary of how the project is doing, and what we’ve been up to in
the past year.</p>

<p>One quick note before we begin… Prosody is an independent open-source
project and exists only because the developers have been fortunate enough
to be in a position to work on it. A couple of core team members are
currently looking for freelance work. If you have projects in need of a
Prosody expert, check the bottom of this post for more details!</p>

<h2 id="more-users-than-ever-before">More users than ever before</h2>

<p>Prosody does not “phone home” in any way, which means we do not have a
lot of insight into how many people are using Prosody. But there are
some indicators that we can use to see at least the growth of the project.</p>

<p>Many years ago, circa 2014, I was filling out a form that asked how
many users the project had. I thought long and hard, but with no idea how
to measure, I wrote down an estimate of “500” based on nothing but a gut
feeling. Only a few weeks later I learned that the <a href="https://xmpp.net/">XMPP Observatory</a>
had already seen <strong>over 2200 domains</strong> submitted that were running Prosody.
As most deployments were unlikely to have been submitted to xmpp.net, my
estimate was clearly far out. These days I jump at any chance for even a
vague estimate of our userbase. It helps us to know that people are out
there!</p>

<p>One useful tool is <a href="https://shodan.io/">Shodan</a>. This project scans the
entire internet, just to see what it can find, and it records the results.
Often used by academics and security researchers, a free account can also
be used by anyone to run simple queries over the data they collect.</p>

<p>A Shodan search in 2017 turned up nearly 7000 Prosody deployments. The
same search 8 months later returned over 16000. Today we’re at <strong>over 52000
Prosody servers!</strong> And this only counts instances using port 5269 and
accessible to the internet. There are also many private/internal deployments
of Prosody that are not included in these numbers. Unfortunately we
didn’t run a report in 2019, but here’s a graph of the previous
reports we have run:</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-shodan-2020.svg" alt="Graph of Prosody server counts in previous paragraph"></p>

<p>Shodan reports over 85000 federating XMPP servers on port 5269 in total.
Based on this, Prosody makes up 44% of the public XMPP network. That’s
quite an achievement!</p>

<p>Another handy insight into one sector of Prosody deployments is via Debian’s
<a href="https://popcon.debian.org/">“popularity contest”</a> service. This is an
automated survey that administrators of Debian servers can choose to opt
into. It reports anonymously to Debian what software packages are installed
and in use. Although it reflects only a small slice of even Debian
installations, it is useful to see trends.</p>

<p>March 2020 marked an unprecedented spike in Prosody installations!</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-popcon-20201231.png" alt="Graph of Debian popularity contest data for prosody"></p>

<p>Although we don’t know for certain, we suspect this was caused by an surge
of interest in the self-hosted video conferencing software, <a href="https://jitsi.org/jitsi-meet/">Jitsi Meet</a>. Jitsi Meet integrates with Prosody, which is used to power the
authentication, signaling and chat of the video conferences. Jitsi’s <a href="https://jitsi.org/jitsi-videobridge/">Videobridge</a> component handles the media routing. Together they make
a very powerful and flexible communication system, and it is hardly surprising
that interest has spiked this year when there has been a massive shift to
remote work, and online meetings have replaced physical ones.</p>

<h2 id="the-code-counts">The code counts</h2>

<p>Now let’s look at some stats about the Prosody codebase itself.</p>

<table>
<thead>
<tr>
<th>Language</th>
<th>Files</th>
<th>Code</th>
<th>Comment</th>
<th>Comment %</th>
<th>Blank</th>
<th>Total</th>
</tr>
</thead>

<tbody>
<tr>
<td>Lua</td>
<td>295</td>
<td>48358</td>
<td>3536</td>
<td>6.8%</td>
<td>6483</td>
<td>58377</td>
</tr>

<tr>
<td>C</td>
<td>13</td>
<td>2613</td>
<td>346</td>
<td>11.7%</td>
<td>643</td>
<td>3602</td>
</tr>

<tr>
<td>Other (build tools, etc.)</td>
<td>11</td>
<td>1551</td>
<td>22</td>
<td>6.3%</td>
<td>138</td>
<td>1711</td>
</tr>

<tr>
<td>————————-</td>
<td>——</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———</td>
</tr>

<tr>
<td>Total</td>
<td>323</td>
<td>54760</td>
<td>3909</td>
<td>6.7%</td>
<td>7265</td>
<td>65934</td>
</tr>
</tbody>
</table>

<h3 id="changes-in-2020">Changes in 2020</h3>

<p>In 2020 (looking at the development branch) we added 597 commits, changing
191 files. The changes added 9872 lines of code, and 3637 lines of code
were removed.</p>

<p>A significant portion of the new lines were in our unit and integration
tests (2200 lines, about 22%) which we have been working hard to expand
over the past couple of years.</p>



<p>If you use Prosody, you know we have an emphasis on modularity and
extensibility. We like to make <a href="https://prosody.im/doc/developers/modules">developing plugins for Prosody</a> as easy as possible, whether it’s for integration with other
systems or crazy experiments.</p>

<p>Here’s a random selection of the 363 modules currently in the repository:</p>

<dl>
<dt><a href="https://modules.prosody.im/mod_muc_eventsource">mod_muc_eventsource</a></dt>
<dd>Receive messages from MUC rooms with 4 lines of Javascript</dd>
<dt><a href="https://modules.prosody.im/mod_log_ringbuffer.html">mod_log_ringbuffer</a></dt>
<dd>Send debug logs to RAM unless they are needed.</dd>
<dt><a href="https://modules.prosody.im/mod_component_client">mod_component_client</a></dt>
<dd>Allow a Prosody server to run as a (XEP-0114) external component of
another (Prosody or not) XMPP server.</dd>
<dt><a href="https://modules.prosody.im/mod_firewall">mod_firewall</a></dt>
<dd>Powerful rules-based scripts for filtering and redirecting XMPP traffic.</dd>
<dt><a href="https://modules.prosody.im/mod_minimix">mod_minimix</a></dt>
<dd>An <strong>experiment</strong> in making MUC joins persistent (like MIX).</dd>
</dl>

<p>During 2020 we saw 37 new modules published in the <a href="https://modules.prosody.im/">community repository</a>,
and 499 commits from 19 contributors. Together they added over 10,000
lines of code (and removed 728 lines). This makes it our most active
year apart from 2018!</p>

<p>Outside of the Prosody dev team, the most active contributor was
<a href="https://wiki.xmpp.org/web/Severino_Ferrer_de_la_Pe%C3%B1ita_Application_2020">Seve</a>, who also made their first contribution this year and added a total of four new modules.
Welcome aboard!</p>

<h2 id="features">Features</h2>

<p>But the most important part… what features have we been working on? All
these things are scheduled for the 0.12 release (more on that in a bit).</p>

<h3 id="plugin-installer">Plugin installer</h3>

<p>We have been applying further polish to, and setting up the infrastructure
for the plugin installer. This was a Google Summer of Code project by
<a href="https://gsoc-prosody-2019.blogspot.com/">João Duarte</a>. It utilizes the
Lua package manager, LuaRocks, to download, install and manage community
modules.</p>

<p>Although the the installer was completed in 2019, to make it generally
usable we also had to ensure every module in the <a href="https://modules.prosody.im/">community repository</a>
could be packaged and served in an automated way by our server. We now
have this working.</p>

<h3 id="bye-bye-telnet-hello-prosodyctl-shell">Bye bye telnet, hello prosodyctl shell!</h3>

<p>The telnet console is one of the best things about Prosody, and we’ve
been working on its successor. An early version of <code>prosodyctl shell</code> is
already available to try out in trunk nightly builds.</p>

<p>Using prosodyctl allows us to more easily support advanced features such
as line editing and history (previously attainable using a third-party
utility, rlwrap). It also allows for some richer UIs and is more secure
on shared servers (it uses a unix socket instead of TCP).</p>

<h3 id="dns-improvements">DNS improvements</h3>

<p>Since Prosody needs to resolve special DNS record types (such as SRV
records) and in an asynchronous manner, the built-in operating system APIs
are generally inadequate.</p>

<p>For a long time we’ve been using an adopted library simply known as
‘dns.lua’ combined with our own asynchronous wrapper around it. Although
it hasn’t been terrible, it has a few issues, especially in some uncommon
environments. It also doesn’t support many advanced features such as DNSSEC.</p>

<p>Now we are migrating to libunbound, part of the <a href="https://github.com/coredns/unbound">unbound</a>
project. This is one of the leading DNS implementations, and will be a
big improvement over our current DNS library. To try it out, you can
simply install <a href="https://www.zash.se/luaunbound.html">luaunbound</a> (already
available in luarocks, Debian testing, AUR and others - poke your distro
maintainers if you don’t have it yet!).</p>

<h3 id="http-server-upload-performance">HTTP server upload performance</h3>

<p>We didn’t set out to write a HTTP server, but we ended up with one anyway!
Originally added so that we could natively support BOSH (XMPP over HTTP)
clients, it grew to support websockets, and various modules now provide
HTTP APIs for integration between Prosody and other systems.</p>

<p>One big problem is that the original implementation was designed for only
small amounts of data. Since the widespread of adoption of
<a href="https://xmpp.org/extensions/xep-0363.html">XEP-0363</a> people now want to
be able to upload files, pictures and videos using Prosody’s internal
HTTP server. We have limits in place to protect against denial of service
attacks, but those same limits prevent large uploads from trusted users.</p>

<p>We’ve put some work into supporting “streaming uploads”, where incoming
data can be saved directly to disk instead of RAM. This means it will be
safe to increase file upload limits without opening up your server to
increase RAM usage and denial of service attacks.</p>

<p>In general though, we do recommend using a real external HTTP server in
a production or high traffic deployment (using <a href="https://modules.prosody.im/mod_http_upload_external">mod_http_upload_external</a>).</p>

<h3 id="beyond-passwords">Beyond passwords</h3>

<p>Passwords are the fundamental means of authenticating to your server in
XMPP today. XMPP is quite good at this, adopting strong standard authentication
mechanisms such as SCRAM far earlier than the rest of the industry. But
the rest of the industry is also moving away from passwords in many places.
We’re aiming to follow this movement also. Not that we are scrapping passwords
entirely, but making it easier to offer alternatives.</p>

<p>Prosody actually has a number of non-password authentication modules already,
such as <a href="https://modules.prosody.im/mod_auth_oauthbearer">mod_auth_oauthbearer</a> (OAuth2 tokens),
 <a href="https://modules.prosody.im/mod_auth_ccert">mod_auth_ccert</a> (client certificates) and
 <a href="https://modules.prosody.im/mod_auth_token">mod_auth_token</a> (HMAC-based
 tokens).
But most of the modules have limitations and are not well integrated
(e.g. you can set up Prosody to accept passwords, or set it up to accept
tokens, but you can’t offer both methods at the same time).</p>

<p>An important related aspect is authorization. In most systems authentication
via a token also provides <em>limited access to the account</em> (e.g. if a password
is associated with an account, a session that logged in using a token
should not be allowed to reset the password).</p>

<p>We’ve been working on two things. Firstly, a built-in authorization system
(more flexible than the current <code>admins</code> configuration option) where users
and sessions can be associated with specific permissions and roles.</p>

<p>Secondly we’re using this authorization layer to add built-in support
for OAuth2-style authentication and authorization.</p>

<p>This is exciting for a number of reasons. It will allow, for example,
specialized clients to request and receive (when granted by the user)
limited …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.prosody.im/2020-retrospective/">https://blog.prosody.im/2020-retrospective/</a></em></p>]]>
            </description>
            <link>https://blog.prosody.im/2020-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713679</guid>
            <pubDate>Sun, 10 Jan 2021 11:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Is Drowning the World]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25713631">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://jamesabley.com/software-is-drowning-the-world/ | <a href="https://web.archive.org/web/*/https://jamesabley.com/software-is-drowning-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>One of the many upsides I’ve had from working at lots of organisations
is that you get to see what’s common. Are things like this everywhere?
Frequently, the answer is yes!</p>

<p>An example of this is tech debt.</p>

<p>I see organisations which are running to stand still, and I’m not
sure they realised they’re doing that.</p>

<p>What do I mean by this?</p>

<p>Every time you decide to solve a problem with code, you are committing
part of your future capacity to maintaining and operating that code.
Software is never done.</p>

<p>Here’s a few examples of demonstrating what I mean:</p>

<h2 id="security">Security</h2>

<ol>
  <li>You write a networked service to solve a business problem. Say
it has an HTML web UI</li>
  <li>It has no known security issues</li>
  <li>Time passes</li>
  <li>You now have security issues with your code, and you should assess
 whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>Humans are terri-bad at writing secure code. And given enough time,
other humans will discover the security holes in your service.</p>

<p>This applies both to code your organisation writes, and the libraries
they use, or the operating systems, or web servers, or …</p>

<h3 id="security-examples">Security Examples</h3>

<p>Take your pick from browsing a CVE database, or use
<a href="https://snyk.io/">Snyk</a> or similar to look at your current codebases.</p>

<ul>
  <li>TLS / SSL issues:
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/POODLE">POODLE</a></li>
      <li><a href="https://blog.zoller.lu/2011/09/beast-summary-tls-cbc-countermeasures.html">BEAST</a></li>
      <li><a href="https://en.wikipedia.org/wiki/CRIME">CRIME</a></li>
      <li><a href="https://en.wikipedia.org/wiki/BREACH">BREACH</a></li>
      <li><a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a></li>
    </ul>
  </li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=15183&amp;product_id=31286&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=20&amp;sha=97513f3fa07a803c5507b2cf550af9877acd90f2">Spring</a></li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=45&amp;product_id=6117&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=70&amp;sha=5369e34293062ebe460c99e6878e0792ac23944c">Struts</a></li>
</ul>

<h3 id="legislation">Legislation</h3>

<ol>
  <li>You write a networked service to solve a business problem. Say
 it has an HTML web UI</li>
  <li>It has no known legal compliance issues</li>
  <li>Time passes</li>
  <li>You now have legal compliance issues with your code, and you should
 assess whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>The <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">General Data Protection Regulation</a>
addressed organisations not handling data very well.</p>

<p>Privacy and Electronic Communications Regulations – mostly known
for mandating cookie policy.</p>

<p>The Equality Act 2010 (UK) and the Americans with Disabilities Act
1990 (2010 update) for website accessibility. Yes, there was a time
when people didn’t consider accessibility when building web sites.</p>

<p>Brexit has meant a lot of changes for businesses in the EU and UK.
Software has been rewritten to manage the new trading relationships.
This will continue to happen for a while countries establish new
relationships.</p>

<h3 id="3rd-parties">3rd parties</h3>

<ol>
  <li>You write a service to solve a business problem</li>
  <li>You can build and release it when necessary</li>
  <li>Time passes</li>
  <li>You are now unable to build and release the service</li>
</ol>

<p>WAT?</p>

<p>3rd parties will change their APIs, or how things work. They may
do this for any number of reasons: performance, or security among
them. Older versions become deprecated, and unsupported. And these
older versions will still have new security issues reported against
them. So you need to upgrade, and adapt your code to use the new
API.</p>

<p>People building code libraries will strive to maintain backward
compatibility. But we still get <a href="https://semver.org/">semver</a> major
version changes, and breaking API changes.</p>

<h2 id="implications">Implications</h2>

<p>Most software needs constant maintenance. Building and operating
software has a cost which you should always factor in when deciding
to solve problems in that way.</p>

<p>A team working in a particular way can only be responsible for a
fixed amount of software. The amount of software should be managed,
otherwise the team will grind to a halt.</p>

<h2 id="proposition">Proposition</h2>

<blockquote>
  <p>A team working in a particular way</p>
</blockquote>

<p>What if we change how they work?</p>

<p>Well yes, there are options there.</p>

<p>I’ve got a separate post (currently brewing) about Dunbar’s numbers,
but for this post, different sized organisations might have different
options. At a certain size, it makes sense to have people dedicated
to developer productivity and creating tools which improve the
capacity of other teams.</p>

<p>You can choose higher-level languages, and use technology stacks
from SaaS vendors which need less time from your people.</p>

<p>There is one option I had planned to spend researching last year
(but I ended up getting a job instead). This feels like potentially
a big market. I’ve seen lots of organisations with decade-old
codebases which are still running unsupported versions of dependencies
or frameworks.</p>

<p>As a developer, I’m familiar with a hammer, and was curious if I
could use it.</p>

<p>Can we have tooling that automates keeping software up-to-date?</p>

<p>I see this problem in every organisation I’ve ever worked in, with
all aspects.</p>

<p>Web applications/APIs written in any language. As mentioned above,
there are many reasons that software rots if left unattended. Mobile
apps also have this. Migrating versions of Android, or iOS, or …</p>

<p>Configuration/manifests for Infrastructure as Code aslo suffer from
this. Terraform hasn’t yet released 1.x, but there have been many
changes over the years. If you’re using Cloud Foundry or Kubernetes,
you’ll <a href="https://github.com/doitintl/kube-no-trouble">have experienced
changes</a> which mean
you need to do work.</p>

<p>Automating the changes needed in YAML for upgrading from Kubernetes
<code>n</code> to <code>n+1</code> feels like a widely useful tool.</p>

<h2 id="current-state">Current State</h2>

<p>There are some commercial things which do related work.</p>

<p>Snyk, <a href="https://github.com/renovatebot/renovate">Renovate</a>,
<a href="https://dependabot.com/">Dependabot</a> and other things exist which
can make pull requests to update dependencies. Mpost languages have
a package tool and bumping numbers is pretty straightforward. These
things tend to not be able to manage breaking API changes though.
Bumping a patch or minor dependency upgrade is fine, but a major
one with breaking API changes tends to need a human to get involved.</p>

<p>Why? Could we have a tool that solves this? When a new version of
<a href="https://spring.io/">Spring</a> is released, could it include an
accompanying set of transformations which will allow the entire
ecosystem to safely and rapidly upgrade?</p>

<p>Having a minor interest in compilers (and having worked on a
commercial interpreter), I tend to think of code editing operations
as transformations, rather than characters. There’s been <a href="https://www.facebook.com/notes/kent-beck/prune-a-code-editor-that-is-not-a-text-editor/1012061842160013">some
research in transformation-based
editors</a>,
but I’ve not seen a lot else.</p>

<p>Major version upgrades could potentially be similarly expressed in
terms of transformations, which similarly might be composed. So if
a class has been removed between major versions of a dependency,
the required transformation might be composed of:</p>

<ol>
  <li>Insert new class <code>my.Y</code></li>
  <li>Implement interface <code>spring.new.Z</code></li>
  <li>Adapt method <code>A</code> from old class <code>my.Z</code> onto method <code>B</code> in new
 class <code>my.Y</code></li>
  <li>Adapt parameters from adapted method – a <code>Context</code>
 used to be obtained from <code>ApplicationSingleton</code> but is now passed
 in explicity</li>
  <li>etc</li>
</ol>

<p>And then you would need a serialisation format and publishing
mechanism for these sets of transformations.</p>

<p>The closest I’ve seen to this is where Google actually did that in
the same target langauge. They <a href="https://blog.golang.org/introducing-gofix">published a tool with for the
language Go</a>, named
<a href="https://golang.org/cmd/fix/"><code>fix</code></a>. It automated upgrades of
existing code before 1.x was released, and since then, they’ve had
<a href="https://golang.org/doc/go1compat">the Go 1 compatibility document</a>.</p>

<p>Sadly, <code>fix</code> appears to have been mostly inactive since then?</p>

<p>I’m interested (academically as well as commercially) in producing
a tool which looked something similar, but much more widely applicable.</p>

<p>So having something that can take code/configuration, generate an
Abstract Syntax Tree (AST), and then apply a set of transformations.
Transformations compose. A large one might be <strong>Upgrade Framework
<code>n</code> to <code>n+1</code></strong> involvings lots of smaller transformations. For each
transformation, you’d need to query the AST for usages of the old
API, then try to apply the transformation which maps the old API
to the new API.</p>

<p>I’ve found <a href="https://dl.acm.org/doi/10.1145/1103845.1094832">one related paper</a>.
Given that it’s not gone further, was it too hard, or not viable, or
the wrong time?</p>

<h2 id="summary">Summary</h2>

<p>So I think this would be the next evolution in automated upgrades.
It’s seems like a big market – how many companies would pay for you
to solve this problem for them and allow them to concentrate on
business logic rather than plumbing concerns?</p>

<p>But I didn’t take the time off I planned to confirm the potential
market and see how hard a problem it would be solve :)</p>

<h2 id="further-reading">Further Reading</h2>

<p><strong>Update</strong> I originally published this without a list of references.
I should have done the hard work to include them. Mostly that meant
mining my browser history and Pinboard from February and March 2019
when I spent a chunk of time first looking at this
<strong>for absolutely no reason at all, clients of the time</strong>.</p>

<ul>
  <li><a href="https://dl.acm.org/doi/10.1145/1103845.1094832">Refactoring support for class library migration</a></li>
  <li><a href="https://ercim-news.ercim.eu/en88/special/automatic-upgrade-of-java-libraries">Automatic Upgrade of Java Libraries</a>
which linked to <a href="http://web.archive.org/web/20170409031849/http://kenai.com/projects/refactoringng">a defunct Netbeans plugin</a></li>
  <li><a href="http://autorefactor.org/">Autorefactor</a></li>
  <li><a href="http://walkmod.com/">Walkmod</a></li>
  <li><a href="https://github.com/Netflix-Skunkworks/rewrite">Rewrite</a>
    <ul>
      <li>This has now become <a href="https://docs.openrewrite.org/">OpenRewrite</a>
and might be what I’m after, for Java and YAML at least. There is
an example which (when complete) is supposed to migrate from
Spring Boot 1.5.x to Spring Boot 2.x.</li>
    </ul>
  </li>
</ul>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://jamesabley.com/software-is-drowning-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713631</guid>
            <pubDate>Sun, 10 Jan 2021 11:31:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CTO day 2: downsizing the team]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25712771">thread link</a>) | @delebe
<br/>
January 10, 2021 | https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/ | <a href="https://web.archive.org/web/*/https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="entry-summary">On your first day as newly appointed CTO you are working on your hiring strategy, the second day your organization asks you to downsize the team.</p><div><p>A very important project that was a done deal, and that will secure the organization’s future for the next five years, failed to happen.</p><p>Not winning this project meant that the organization was forced to <em>“focus”</em> and reduce costs.</p><p>It never crossed my mind that one of the first things that I would be asked to do as an inexperienced CTO would be to fire part of the team.</p>
<p>when such bad news becomes public, host an open door day where the team can openly talk about the situation, share their feelings, see each other, feel connected, and be listened to. It would not stop the gossiping but it will help.</p><h2>Cuts and team principles</h2><p>The Dev team slice of the <em>“focus”</em> meant cutting cost by 10 to 15%. In human terms, firing two to four people (out of 17).</p><p>After some failed attempts to approach this task, this is what worked for me.</p><p>I started by listing some principles: </p>
<ul>
  <li>For each product, we need to cover the following disciplines: Frontend, Backend, Architecture, Operations, Mobile, UX, Design, QA, Leadership, and Product Management.</li>
  <li>There are broadly 3 experience levels:
  <ul>
    <li>Senior: creates the plan.</li>
    <li>Mid-level: follows the plan.</li>
    <li>Junior: needs to be taught to follow the plan.</li>
  </ul></li>
  <li>No number of junior people can do some work a senior person can do.</li>
  <li>Not having a senior person in a discipline will mean that the product quality will suffer:
  <ul>
    <li>If a senior creates a plan, a team of mid-level+juniors can follow the plan for some time (2-3 years?) before the product becomes a big mess.</li>
    <li>To get out of a big mess, we need senior people.
    <ul>
      <li>We are already in a big mess with Product A and Product B.</li>
      <li>With the current team, it feels Product A is getting out of the mess.</li>
    </ul></li>
  </ul></li>
  <li>Independent (cross-functional) teams are more efficient:
  <ul>
    <li>More focus.</li>
    <li>No handoffs, faster feedback.</li>
    <li>No shared “resource” contention.</li>
  </ul></li>
  <li>People working in multiple products/teams are less efficient.</li>
  <li>Multidisciplinary (generalist) people:
  <ul>
    <li>Can cover the need for several of the disciplines.</li>
    <li>They can be junior in one discipline and senior in another.</li>
    <li>Allow focusing on any priority, without creating artificially important work for single-disciplined members.</li>
  </ul></li>
  <li>Max team size: 2 pizza teams 6-8.</li>
</ul><p>The ideal team would be one that has all disciplines covered at a senior level with multidisciplinary people working in just one team, and with enough overlap to avoid a <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> of one. Additional people will bring additional capacity.</p><h2>Inverse Conway’s maneuver</h2><p>We have been working on bringing three of the products together for some time. They were already under the same product manager, but they were still three teams working on their own priorities. Merging them into one team, in a classic <a href="https://danlebrero.com/2020/01/08/do-i-need-a-gateway-api-team-dynamics/#content">inverse Conway’s maneuver</a> would hopefully accelerate the integration between the products.</p><p>One of the other products was small enough that for this task I decided to temporarily ignore it.</p><p>Following the principles above and the product considerations, the plan was to move the previous team setup from:</p><p><img src="https://danlebrero.com/images/blog/cto/day2/old-team-structure.jpg" alt="old team structure"> </p><p>To something like (boxes represent skills, not people):</p><p><img src="https://danlebrero.com/images/blog/cto/day2/new-team-structure.jpg" alt="new team structure"> </p><p>So two products, two cross-functional teams. Platforms and design teams will be reshuffled inside those two teams.</p><h2>Which parent do you love most? A computer will tell</h2><p>With a clear plan for the team, the next step was to <em>“just”</em> pick up who will work on each team, and who we will need to let go. The most painful decision in my career. </p>
<blockquote><p><a href="https://danlebrero.com/2019/11/27/becoming-a-technical-leader-book-notes/#content">People with a strong technical background can convert any task into a technical task, thus avoiding work they don’t want to do.</a> <cite>Jerry Weinberg, Becoming a Technical Leader</cite></p>
</blockquote><p>And I didn’t want to do the task so, consciously ignoring Mr. Weinberg, I transformed the ordeal into an optimization problem, for which I wrote an application to help me with.</p><h3>The app</h3><p>The application took as input the amount of $$$ to cut, the list of people, their salary, and the skill level on each discipline mentioned above, and outputted the possible two teams that would be within budget and match the minimum requirements, sorted by a scoring system.</p><p>The minimum requirements and scoring system configuration looked like:</p>
<pre><code>{
"FE" [at-least-senior sum-skills]
"PM" [senior-plus-somebody-else (fix-points 5)]
"Design" [two-mid-or-senior (senior-better 6 2)]
...
}
</code></pre><p>The first function filters out invalid teams while the second scores the valid ones.</p><p>In the example we say that the team has to have:</p>
<ul>
  <li>At least one senior FE developer. The more FE developers, the better team score.</li>
  <li>At least one senior product manager and one mid or junior one. Only one senior is not enough. No matter how many PMs the team has, the score for this discipline is 5. A team with loads of FE devs will score higher than one with loads of PMs.</li>
  <li>At least a senior designer or two mid-level designers, but we prefer one senior designer (6 points) instead of two mid-level ones (2 points).</li>
</ul><h3>The result</h3><p>As heartless as this may seem:</p>
<ul>
  <li>It removed some bias. There is still bias on the skill level evaluation and in the team scoring system.</li>
  <li>I was part of the people on that list. To be honest, little consolation here. Big bias.</li>
  <li>It forced me to be very very precise on what a “functioning team” meant.</li>
  <li>It allowed me to see what different scoring systems would output.</li>
  <li>I noticed some people would never show in the output, and had to dig into why. It was enlightening.</li>
  <li>It allowed me to analyze tens of thousands of different team combinations, with different scoring systems.</li>
  <li>Programming gave me a respite from the task. This was the first time, but now I embrace more regularly “keep my sanity” programming days.</li>
</ul><p>Most important, the application gave me a few starting points. Of those, I still had to consider the team dynamics, existing teams, personalities, seniority, potential, personal situation, future needs, …</p>
<p>yes, I still have the code. No, I am not going to share it publicly. It would kill me to find there is a bug.</p><h2>Delivering the bad news</h2><p>Once the decision was made, it was time to swallow the last bitter pill.</p><p>Some tips:</p>
<ul>
  <li>Ensure that the people affected are the first ones to know.</li>
  <li>Warn beforehand:
  <ul>
    <li>Do not use your regular one-to-one meeting slot.</li>
    <li>In your message, give a strong hint: “HR person will be in the meeting”, “Really bad news”.</li>
    <li>Give them time to get ready for the meeting.</li>
  </ul></li>
  <li>You don’t need to do it alone. Our HR manager was present and was a huge support for both of us.</li>
  <li>Treat people like adults.</li>
  <li>At the meeting, follow Nadia van der Vlies’ <a href="https://danlebrero.com/2020/04/01/no-nonsense-leadership-summary/#bad-news">advice</a>:
  <ul>
    <li>Deliver the blow:
    <ul>
      <li>Go straight to the bad news.</li>
      <li>Give one or two reasons.</li>
    </ul></li>
    <li>Manage the reaction:
    <ul>
      <li>Be understanding. Do not justify yourself.</li>
      <li>Give space. Do not fill silences.</li>
    </ul></li>
    <li>Solution, explanation, follow-up appointment:
    <ul>
      <li>Wait for the employee to be ready. When she starts asking “why” or “what now”.</li>
      <li>Reiterate reasons.</li>
    </ul></li>
  </ul></li>
  <li>In a couple of days follow up with another more informal meeting. The news would have sunk, and the conversation would be more forward-thinking and productive.</li>
</ul>
<hr><p>A slap in the face to awaken me from the dream that a CTO role is mostly about technology.</p></div></div>]]>
            </description>
            <link>https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712771</guid>
            <pubDate>Sun, 10 Jan 2021 09:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noise Planets]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25712767">thread link</a>) | @atulvi
<br/>
January 10, 2021 | https://avinayak.github.io/art/2021/01/09/noise-planets.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/art/2021/01/09/noise-planets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://avinayak.github.io/uploads/erporydxmaarwcd.png" alt=""></p>

<p>I recently found this piece of art (LINES 2A (2017)) created by <a href="https://twitter.com/tylerxhobbs">Tyler Hobbs</a>. This picture kinda looked very hand drawn, but it’s completely generative. Something about this drawing and it’s texture kind of resonated with me, so I wanted to try to study and replicate (or make something inspired by this work) using p5js.</p>

<p>I started out by plotting a bunch of random points within a circle like so.</p>

<div><div><pre><code>w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4');
}

function draw() {
  x = random(w)
  y = random(w)
  if (pow(w/2 - x, 2) + pow(w/2 - y, 2) &lt; 7e4) {
    point(x,y)
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-25.png" alt=""></p>

<p>This is a painfully slow process to generate random points in a circle. I found a better way to do this later. What I wanted to do next was to generate flow fields, but restricted to the circular region.</p>

<p>It’s super easy to generate flow field patterns using perlin noise.</p>

<ol>
  <li>Choose a random point <code>&lt;x,y&gt;</code></li>
  <li>Plot <code>&lt;x,y&gt;</code></li>
  <li>Calculate <code>n = noise(x,y)</code></li>
  <li>Do <code>x+=cos(n * 2 * PI)</code> and <code>y+=sin(n * 2 * PI)</code></li>
  <li>Repeat 2.</li>
</ol>

<p>We’re going to plot flow fields inside the circle. Let’s try this.</p>

<div><div><pre><code>const is_in_circle = (x, y) =&gt; 
  (pow(w / 2 - x, 2) + pow(w / 2 - y, 2) &lt; 7e4)

function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y)) {
      n = noise(x, y)
      x += sin(n * TAU)
      y += cos(n * TAU)
      point(x, y)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-28.png" alt=""></p>

<p>OK, not very good. The noise at this level is pretty rough. we’re going to zoom in to the noise function (by dividing the <code>x,y</code> inputs by some constant value) and probably use <code>circle(x ,y ,0.3)</code> to plot points instead if point function, because I feel it looks way smoother. Also, I’m adding a <code>random() &gt; 0.01</code> condition in the loop so that we also get short lines that are not trimmed away by the edge of the circle.</p>

<div><div><pre><code>function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y) &amp;&amp; random() &gt; 0.01) {
      n = noise(x / 500, y / 500)
      x += sin(n * TAU)
      y += cos(n * TAU)
      circle(x, y, .3)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-27.png" alt=""></p>

<p>Actually.. not bad. I think we manage almost replicate the original texture. The inverted version also looks pretty good.</p>

<p><img src="https://avinayak.github.io/uploads/download-19.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/ppanets.png" alt=""></p>

<p>I went ahead and made a つぶやきProcessing version of this.</p>

<blockquote><p lang="en" dir="ltr">function setup(){createCanvas(w=1e3,w),background("<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a>")}function draw(){if(g(x=random(w),y=random(w)))for(;g(x,y)&amp;&amp;random()&gt;.01;)n=noise(x/500,y/500),x+=sin(n_TAU),y+=cos(n_TAU),circle(x,y,.3)}g=((n,o)=&gt;pow(w/2-n,2)+pow(w/2-o,2)&lt;w*w/16); <a href="https://t.co/iVZTMtCn3i">pic.twitter.com/iVZTMtCn3i</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347903013042622467?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="going-further-animations">Going Further: Animations</h2>

<p>The code we wrote right now technically is animated. The animation however is not very smooth.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_03-52-31.mp4" type="video/mp4"> </video>

<p>To make smooth animations, we need to generate new points in the circle, keep track of these points outside the <code>draw()</code> function. I found this neat <a href="https://stackoverflow.com/a/50746409">technique</a>, to find random points in a circle where a random radius <code>r</code> and angle <code>theta</code> are chosen and the <code>x,y</code> points are obtained as <code>x = centerX + r * cos(theta)</code> and <code>y = centerY + r * sin(theta)</code></p>

<p>Let’s try that first.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

function setup() {
  createCanvas((w = 1e3), w);
  background(255)
  k = w / 2
  m = (Array(w).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    circle(x, y, .3);
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-01-10-04-51-20.png" alt=""></p>

<p>and now we apply flow fields and try to move these points.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

const w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4')
  k = w / 2
  points = (Array(k).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    x += sin(n = noise(x / 400, y / 400) * TAU) * h
    y += cos(n) * h
    stroke(i%255)
    circle(x, y,.3)
    if (pow(k - x, 2) + pow(k - y, 2) &lt; 7e4)  // if point is in circle
      points[i] = [x, y, t]
    else points[i] = random_point() // replace with new point if not
  }
}
</code></pre></div></div>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_04-56-11.mp4" type="video/mp4"> </video>

<p>And a つぶやきProcessing version of course..</p>

<blockquote><p lang="cy" dir="ltr">t=0,p=i=&gt;\[k+(r=random(w/4))_cos(t+=.1),k+r_sin(t)\],setup=i=&gt;{createCanvas(w=1e3,w),m=Array(k=w/2).fill(0).map(p)},draw=r=&gt;{for(i=k;--i;)\[x,y\]=m\[i\],x+=sin(n=noise(x/k,y/k)_TAU),y+=cos(n),stroke(i%4_85),point(x,y),k_w+x_x+y_y-w_(x+y)&lt;7e4?m\[i\]=\[x,y\]:m\[i\]=p()};//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/xVhCBNUltL">pic.twitter.com/xVhCBNUltL</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347930637227855874?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="adding-colors">Adding Colors</h2>

<p>There are many strategies to colorizing this sketch. One is by just giving each particle a random initial color.</p>

<p><img src="https://avinayak.github.io/uploads/download-21.png" alt=""></p>

<p>However, I found that maintaining the initial x or y position in the particle array and using that to derive the hue information gives us some nice Jupiter/gaseous planet vibes.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-18-19.mp4" type="video/mp4"> </video>

<p>The fringing at the sides can be avoided by moving 50% of the points in the reverse direction.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-28-03.mp4" type="video/mp4"> </video>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_08-43-25.mp4" type="video/mp4"> </video>

<p>More color variations</p>

<p><img src="https://avinayak.github.io/uploads/untitled.png" alt=""></p>

<p>And that’s it. Hope this was educational!</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/art/2021/01/09/noise-planets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712767</guid>
            <pubDate>Sun, 10 Jan 2021 09:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Breakthrough in Measuring the Building Blocks of Nature]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25712475">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/18082_ad5db5924e3e97ed8a387a499efa9fa0.jpg" width="733" alt=""><figcaption><span><i>An artistic rendering of the quarks and gluons that make up a proton.</i></span><span>Illustration by D. Dominguez / CERN</span></figcaption></figure><p><span>I</span>n a recent experiment done at the Max Planck Institute for Quantum Optics, in Germany, physicist Alexey Grinin and his colleagues came a step closer to resolving one of the more significant puzzles to have arisen in particle physics over the past decade. The puzzle is this: Ordinarily, when you set about measuring the size of something, you’d expect to get the same answer no matter what you use to measure it—a soda can has the diameter it does whether you measure it with a tape measure or callipers (provided these are properly calibrated, of course). Something must be amiss if your attempts to measure the can return different answers depending on the equipment, yet this is precisely what’s happened over multiple attempts to measure the spatial extent of a proton. What’s potentially at stake is our understanding of the building blocks of reality: the <a href="https://science.sciencemag.org/content/370/6520/1061.abstract" target="_blank">differing measurements</a> could be heralding the existence of new forces or particles.</p><p>What does it mean for a subatomic particle to have a measurable “size”? Mathematically, fundamental particles are idealized as point particles, which is to say that, as far as we can tell, they have no meaningfully discernible spatial extent, or substructure, at all. True, all fundamental particles are associated with a quantum mechanical wave packet, which does have a spatial extent that depends on the energy of the particle. Yet these basic bits of Lego are entities whose wave packets you can, in principle, pack into as small a region as you’d like before the very notion of continuum geometry starts, at the Planck scale, to lose meaning. Fundamental particles organize into something analogous to a mini periodic table—consisting of the various force carrying particles, such as photons and gluons (the carrier particles of the strong nuclear force), along with three generations of quarks and leptons and the mass-generating Higgs boson—and can stack together in different combinations to form a zoo of so-called composite particles.</p><blockquote><p>There is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p> </blockquote><p>Perhaps the most familiar and ubiquitous of these is the proton. With at least one in every kind of element, it’s made up of two up quarks and a down quark that dance around each other in a tightly bound orbit maintained by exchanging gluons. This exchange process is so energetic that most of the mass of the proton (or for that matter, most of the material that makes us up) derives from the energy contained in these gluons—a consequence, as Einstein informed us, of <i>E</i> being equal to <i>mc</i><sup>2</sup>.&nbsp;<br></p><figure data-alt=""><img src="http://static.nautil.us/18083_78b8d6620afcd434a4b7fb41b22e595b.png" width="733" alt=""><figcaption><span><i>Fundamental particles organize into something analogous to a mini periodic table (above).</i></span><span>CERN</span></figcaption></figure><p>So it’s not meaningless to ask what the “size” of the proton is. The study by Grinin’s team highlights the fact that defining this notion remains a rather tricky affair. And, as we’ll see, their results serve to sharpen the mystery as to why other measurement methods researchers have used previously disagree.<br></p><p>A physicist can reasonably infer a proton’s size from the “charge radius”—roughly the averaged spatial extent of quark orbits inside. This quantity is probed in slightly different ways by electrons and muons (another sort of fundamental particle), when you probe their orbital configurations as they form “bound states” with the proton—atomic hydrogen in the case of electrons, muonic hydrogen in the case of muons. Because muons are about 200 times heavier than electrons, their lowest energy orbital configurations are much more tightly bound around the proton than are electrons in atomic hydrogen. Consequently, the differences in the energies of various orbitals in muonic hydrogen are much more sensitive to the proton’s size as well as being more “high pitched” than that of regular atomic hydrogen.&nbsp;</p><p>In other words, similar to how plucking a guitar string at a given tension produces a much higher note were we to fret it open, or at 1/200th its open length, the typical frequencies of the radiation emitted by transitions in muonic hydrogen are about 200 times higher than that in atomic hydrogen. These frequencies relate to something called the Rydberg constant—the tension of the guitar string in the analogy—which appears to be one of the potentially more significant sources of uncertainty proton size-wise. Orbital energy levels depend on both this constant and the charge radius of the proton.</p><p>Proton-size measurements didn’t conflict for decades. Different methods—like measuring the radius by observing electrons orbit within hydrogen atoms, or by scattering energetic electrons off of unbound protons—had converged on a value of 0.875 (give or take 0.006) femtometers. That’s a little less than a trillionth of a millimeter. That convergence was disrupted in 2010, when a paper came out titled, “The size of the proton.” As the researchers reported, <a href="http://www.quantum.physik.uni-potsdam.de/teaching/ss2015/pqt/Pohl2010.pdf" target="_blank">measurements</a> involving orbital configurations in muonic hydrogen returned a value of 0.842, give or take 0.001 femtometers. This may not seem like much of a difference, but it’s the accompanying error bars that matter. The measurements are, individually, so precise that their disagreement is over seven standard deviations—there is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p><p>There are only two possibilities for the anomalous result if the equipment used in the experiments and their calibrations all check out after careful scrutiny. Either some combination of physical constants, which researchers assume in order to experimentally infer the proton charge radius, isn’t known as accurately as we thought, or there is something different about the way muons interact with protons, compared to electrons, that renders particle physics incomplete.</p><p>The latter possibility, if substantiated, would, of course, cause a flurry of excitement among theoretical physicists to say the least, as it could imply the existence of new forces and particles. Not only would it reshape our understanding of the universe, it would represent a throwback to the days when physicists discovered particles (<a href="https://timeline.web.cern.ch/anderson-and-neddermeyer-discover-muon" target="_blank">such as the muon itself</a>) using equipment that could fit on a proverbial tabletop.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>Over the past few years, various teams have been attempting to get to the bottom of the matter by looking at different orbital transitions in atomic hydrogen that are sensitive to different combinations of the Rydberg constant and the charge radius. A 2019 <a href="https://science.sciencemag.org/content/365/6457/1007" target="_blank">measurement</a> by a group of researchers at York University in Canada looked at a particular orbital transition that was independent of the value of this constant, finding a value of 0.833 ± 0.010 femtometers, consistent with the smaller value obtained in muonic hydrogen.&nbsp;</p><p>Grinin’s team went a step further. They used a technique known as frequency comb spectroscopy. It involves pulses of laser light that are a superposition of equally spaced frequencies—a ruler in frequency space if you will—that allowed them to look at two different orbital transitions in atomic hydrogen sensitive to two different combinations of the proton size and the Rydberg constant. This permitted them to determine both with unprecedented accuracy. The technique reduced, to only about one part in ten trillion, the observational uncertainties in the frequency of light these transitions emitted—a staggering degree of accuracy by any standard.&nbsp;</p><p>Not only did Grinin’s team find a value for the charge radius of the proton consistent with the value obtained in muonic hydrogen, they inferred a much more precise value for the Rydberg constant. This accounted for some part of the discrepancy seen in other measurements in atomic hydrogen (which presumed a less accurate value).</p><p>It thus appears that the experimental value of the proton charge radius Grinin’s team obtained in atomic hydrogen is converging on the smaller values for the proton charge radius other researchers initially obtained in muonic hydrogen. The smaller value has by now even been adopted as the <a href="https://physics.nist.gov/cgi-bin/cuu/Value?rp" target="_blank">official value</a> on the National Institute of Standards and Technology <a href="https://www.nist.gov/programs-projects/codata-values-fundamental-physical-constants" target="_blank">CODATA</a> list of recommended physical constants—the official almanac for nuclear and atomic chemists and physicists.&nbsp;</p><p>Although this convergence, based on the continued refinement of experimental techniques, did not deliver the new physics some may have been hoping for, even the most despondent theoretical physicist can acknowledge the experimental artistry that seems to be bringing the matter closer to conclusion. What remains unresolved is the reason why measurements, relying on different spectroscopic methods in atomic hydrogen, return different values for the charge radius of the proton. The mystery, and along with it, the diminishing hope of particle physicists, endures for the time being.&nbsp;</p><p>This was enough motivation for a team of theoretical physicists, led by Cliff Burgess at the Perimeter Institute, in Canada, to systematically catalogue all possible sources of theoretical uncertainty in atomic spectroscopy over a <a href="https://inspirehep.net/literature?sort=mostrecent&amp;size=25&amp;page=1&amp;q=find%20a%20burgess,%20c%20and%20a%20zalavari" target="_blank">series of papers</a>. By isolating the ways in which new forces and particles might leave a tell-tale signature, they’ve thrown the gauntlet firmly back to the experimentalists. Future experiments, as always, will be the ultimate arbiter in this matter.&nbsp;</p><p><i>Subodh Patil is an assistant professor at the Lorentz Institute for Theoretical Physics at Leiden University. He tweets on occasion at @_subodhpatil.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712475</guid>
            <pubDate>Sun, 10 Jan 2021 08:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platform Is the Enemy]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25708099">thread link</a>) | @nomdep
<br/>
January 9, 2021 | https://danielbmarkham.com/the-platform-is-the-enemy/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/the-platform-is-the-enemy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The premise of the movie "Idiocracy" is simple: in the future mankind has de-evolved into morons. Technology does so much for everybody that nobody knows how it all works anymore. &nbsp;If we can't fix it, we're all going to die.</p><p>One character asks the other what he likes, The answer is money.</p><p>"I can't believe you like money too!" the first character says without irony, "We should hang out!"</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/JRJcXbeoSOlkRRzbC7HJ_idiocracy.jpg" alt=""></figure><p>The gag here is that of course, most everybody likes money. If you reduce all of your life enough, it's just food, sex, money, and looking cool. But who would want to do that? Over the centuries, humans have created massively-complex societies because everybody has different things they like doing and thinking about, but all of that complexity can be reduced to, well, an idiocracy if you try hard enough.</p><p>The movie, however, is just a joke, right? We would never allow that to happen, of course, because that's not the goal of technology. Technology's goal is to make us better, not dumber.</p><p>Wait one. Is that true? What <em>is</em> the goal of technology, anyway? Has anybody ever clearly stated it?</p><p>Recently I've heard two goals:</p><ol><li>The goal of technology is to become a <strong>brain extension</strong>, <em>helping you to decide what to do</em> and then helping you get it done.</li><li>The goal of technology is to become a <strong>hand-held power tool</strong>, helping you accomplish the things you've <em>already decided to do</em></li></ol><p>That's not the same thing. It turns out the difference is critical.</p><p>The old goal was much simpler: make something people want. I like that goal! It boils down the job of creating technology to the most important parts, need and ability. But was that sustainable? At the end of the day, don't we always end up making some combination of stuff that either helps us <em>make decisions</em> or helps us <em>implement decisions</em> we've already made? And aren't the two fundamentally incompatible in a future society?</p><p>Yelp tells you which restaurant to go to. Your GPS automatically takes you there. These are not just different problems, they're different <em>kinds of problems</em>. Getting from point A to point B is a matter of math and geometry. Which restaurant is the best tonight? You could spend hours debating that with friends.</p><p>If you reduce anything down enough it becomes idiotic. Each piece of technology we deploy can have the goal of helping us do what we've already decided or helping us decide what to do. The first option leaves the thinking up to us. The second option "helps" us think.</p><figure><iframe width="267" height="200" src="https://www.youtube.com/embed/sZHCVyllnck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>You like money too? Wow! I like money! We should hang out!</p><p>Human brains are not computers. Brains are designed to help us survive and pass on our genes using the minimum amount of energy available. If the GPS takes me where I'm going, I don't need to know how to use maps anymore. So I stop knowing how to use maps. Dump those neurons, they're not needed. If Yelp picks the restaurants for me enough, I stop having nuanced preferences about restaurants. That energy expenditure is no longer needed for survival and reproduction. Dump those neurons. Over time people stop caring about the tiny details of what the difference is between a good and a great restaurant. Yelp handles that.</p><p>For some folks, who cares? It's food. Go eat it. For other folks, picking the right place can be a serious undertaking, worthy of heavy thought and consideration. But if over the years apps like Yelp boil all of that down to four or five stars, then our collective brain is not going to bother with it. Human brains are not computers. If computers do the work for us, we turn off those neurons and save energy.</p><p>Meanwhile, on social media there's currently this huge discussion. One bunch of folks says that social media is being overbearing in its censorship of fringe and sometimes hateful opinions. The other bunch of folks says social media is a festering sore full of people who are ugly, hateful, and abusive to those weakest among us. The community has to set standards.</p><p>There doesn't have to be a right and wrong here. I think the crucial thing to to understand that both sides can be entirely correct. We are dealing with the same kind of question.</p><p>All three of these topics -- whether humanity is becoming idiots or not, what the ultimate goal of technology is or should be, and how social media should work -- are intricately related. They're related because of this: <em>the platform is the enemy</em>.</p><p>The minute we create a platform for something, whether it's rating movies, tracking projects, or chatting with friends about work, as that platform takes over mindshare, <em>the assumption becomes that this is a solved problem</em>.</p><p>The telephone was great. Once we had the telephone, people didn't have to worry about how to talk to people far away anymore. Just pick up the phone. Solved problem.</p><p>Facebook is great. Once we had Facebook, people didn't have to worry about how to interact with their friends in a social setting anymore. Just click on the little FB notification (Which seems to be always flashing for some reason to get my attention) Solved problem?</p><p>But these are entirely different things! With the phone, I know who I want to call and why. I push buttons and we are connected. The tech helps me do what I've already decided to do. With Facebook, on the other hand, they get paid to show me things in a certain order. The premise is that I'm waiting (or "exploring" if you prefer) until I find something to interact with. The phone is a tool for me to use. I am the tool Facebook is using. I am no longer acting. I am reacting.</p><p>And even if they weren't paid, interacting with friends socially is an extremely complex affair. What kind of mood are they in? What's their life history? What things are bad to bring up? How does their body language look? Facebook's gimmick is "Hey, we've reduced all of this to bits and bytes, and we'll even show you what bits and bytes to look at next!"</p><p>Solved problem.</p><p>Many, many people do not use the internet, the internet uses them. And this percentage is constantly growing.</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/9EBNeUmSy6TMDUpKTLL6_terminator-robot.jpg" alt=""></figure><p>Just like the restaurant example, maybe that's fine. I have friends, I have opinions, who cares? It's all idle chat anyway.</p><p>That logic can be true for a bunch of things, but can't be true for <em>everything</em>. Otherwise, at some point 100 years from now, we're comparing our life values and end up saying something like "I like money too". Everything can't all be reduced down to the lowest common denominator. If it does, we all die.</p><p>Life is not a bit or byte, a number to be optimized. It's meaning we define ourselves, in ways we should not quantize.</p><p>Platforms, by their very nature, constantly send out the subtle message: <em>This is a solved problem. No further effort on your part is required here. No thinking needed.</em> Platforms resist change. They resist their own evolution by subtly poisoning the discussion before it even starts.</p><p>Are restaurant choices more or less important than which movie to watch tonight? There's no right or wrong answer to these questions. We have nice categories like restaurants and movies because currently people consider those things to be different kinds of choices. But why? If the algorithm is king, why shouldn't an algorithm determine both of those things for me? And if it does, why should I bother with worrying about which category is which?</p><p>Human brains are not computers. Let the platform decide. Energy not needed. Dump those neurons.</p><p>This is the more important point. It's not that the platforms turn what might be complex things into simple numbers, or even that they monetize attention. It's that by turning everything into numbers, over time they destroy the distinction between the categories entirely. Platforms are the enemy because they resist analysis in the areas they dominate.</p><p>Platforms turn into settled fact things that should be open for debate, like whether or not Taco Bell is a Mexican restaurant, or whether Milo is an artist with something useful to tell us. (I'm going with "no" and "no" for both of these.) More dangerously, they do the work of deciding <em>what categories various things go into</em>. This category over here is important. That category over there is not. We all make these decisions, and they're all different, and the categories each of us pays careful attention to and loves obsessing about are all different, and because we all have different viewpoints and priorities humankind advances in thousands of directions simultaneously. We survive. We evolve.</p><p>Twitter has to decide whether PERSON_X can speak or not because on the Twitter platform, that question has to have a yes or no answer based on the person. Twitter's category for deciding who can speak is "who is that?" Is that the right category for social conversations? For political conversations? For conversations about philosophy? Math? Who knows? Who cares? Twitter has decided. Solved problem.</p><p>Everybody has different things they like doing and thinking about. Different conversations and audiences have different criteria. Some problems should never be solved. Or rather more directly, some problems should never have a universal answer.</p><p>An aside: We see the same thing in programming. One bunch of folks creates various platforms in order to do the thinking for another bunch of folks. Sometimes these platforms take off and become industry standards. That's quite rare, however. Most of the time we end up training morons who can weakly code against the platform but can't reason effectively about the underlying architecture or reason for the platform to exist in the first place. In our desire to help, we harm the very people we're trying to assist -- by subtly giving them the impression that this is a solved problem. Programmers are just a decade or so ahead of the rest of us.</p><p>Popular platforms aren't just a danger economically because they control commerce. They're not just a danger politically because they selectively control and amplify political discourse. They're an extinction-level, existential danger to humans because they prevent people from seriously considering what kinds of categories are important in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielbmarkham.com/the-platform-is-the-enemy/">https://danielbmarkham.com/the-platform-is-the-enemy/</a></em></p>]]>
            </description>
            <link>https://danielbmarkham.com/the-platform-is-the-enemy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708099</guid>
            <pubDate>Sun, 10 Jan 2021 02:23:19 GMT</pubDate>
        </item>
    </channel>
</rss>
