<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 29 Jul 2020 08:18:41 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 29 Jul 2020 08:18:41 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[GnuTLS audit: passive cleartext recovery attack]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23962840">thread link</a>) | @masklinn
<br/>
July 27, 2020 | https://anarc.at/blog/2020-06-10-gnutls-audit/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-06-10-gnutls-audit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>So <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> came out while I wasn't looking last week. The
GnuTLS advisory (<a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">GNUTLS-SA-2020-06-03</a>) is pretty opaque so I'll
refer instead to <a href="https://twitter.com/FiloSottile/status/1270061316368224256">this tweet</a> from <a href="https://twitter.com/FiloSottile">@FiloSottile</a> (Go team
security lead):</p>

<blockquote><p>PSA: don't rely on GnuTLS, please.</p>

<p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> Whoops, for the past 10 releases most TLS 1.0–1.2
connection could be passively decrypted and most TLS 1.3 connections
intercepted. Trivially.</p>

<p>Also, <a href="https://blog.filippo.io/we-need-to-talk-about-session-tickets/">TLS 1.2–1.0 session tickets are awful</a>.</p></blockquote>

<p>You are reading this correctly: supposedly encrypted TLS connections
made with affected GnuTLS releases are vulnerable to <em>passive</em>
cleartext recovery attack (and active for 1.3, but who uses that
anyways). That is extremely bad. It's pretty close to just switching
everyone to HTTP instead of HTTPS, more or less. I would have a lot
more to say about the security of GnuTLS in particular -- and security
in general -- but I am mostly concerned about patching holes in the
roof right now, so this article is not about that.</p>

<p>This article is about figuring out what, exactly, was exposed in our
infrastructure because of this.</p>






<p>Assuming you're running Debian, this will show a list of packages that
<code>Depends</code> on GnuTLS:</p>

<pre><code>apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u
</code></pre>

<p>This assumes you run this only on hosts running Buster or
above. Otherwise you'll need to figure out a way to pick machines
running GnuTLS 3.6.4 or later.</p>

<p>Note that this list only <em>first level</em> dependencies! It is perfectly
possible that another package uses GnuTLS without being listed
here. For example, in the above list I have <code>libcurl3-gnutls</code>, so the
be really thorough, I would actually need to recurse down the
dependency tree.</p>

<p>On my desktop, this shows an "interesting" list of targets:</p>

<ul>
<li><code>apt</code></li>
<li><code>cadaver</code> - AKA WebDAV</li>
<li><code>curl</code> &amp; <code>wget</code></li>
<li><code>fwupd</code> - another attack on top of <a href="https://github.com/justinsteven/advisories/blob/master/2020_fwupd_dangling_s3_bucket_and_CVE-2020-10759_signature_verification_bypass.md">this one</a></li>
<li><code>git</code> (through the <code>libcurl3-gnutls</code> dependency)</li>
<li><code>mutt</code> - all your emails</li>
<li><code>weechat</code> - your precious private chats</li>
</ul>


<p>Arguably, fetchers like <code>apt</code>, <code>curl</code>, <code>fwupd</code>, and <code>wget</code> rely on HTTPS for
"authentication" more than secrecy, although <code>apt</code> has its own
OpenPGP-based authentication so that wouldn't matter anyways. Still,
this is truly distressing. And I haven't mentioned here things like
<code>gobby</code>, <code>network-manager</code>, <code>systemd</code>, and others - the scope of this is
broad. Hell, even good old <code>lynx</code> links against GnuTLS.</p>

<p>In our infrastructure, the magic command looks something like this:</p>

<pre><code>cumin -o txt -p 0  'F:lsbdistcodename=buster' "apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u" | tee gnutls-rdepds-per-host | awk '{print $NF}' | sort | uniq -c | sort -n
</code></pre>

<p>There, the result is even more worrisome, as those important packages seem to rely on GnuTLS for their transport security:</p>

<ul>
<li><code>mariadb</code> - all MySQL traffic and passwords</li>
<li><code>mandos</code> - full disk encryption</li>
<li><code>slapd</code> - LDAP passwords</li>
</ul>


<p><code>mandos</code> is especially distressing although it's probably not
vulnerable because it seems it doesn't store the cleartext -- it's
encrypted with the client's OpenPGP public key -- so the TLS tunnel
never sees the cleartext either.</p>

<p><a href="https://twitter.com/jedisct1/status/1270078914996682753">Other reports</a> have also mentioned the following servers link
against GnuTLS and could be vulnerable:</p>

<ul>
<li><code>exim</code></li>
<li><code>rsyslog</code></li>
<li><code>samba</code></li>
<li>various <code>VNC</code> implementations</li>
</ul>




<p>Those programs are not affected by this vulnerability:</p>

<ul>
<li><code>apache2</code></li>
<li><code>gnupg</code></li>
<li><code>python</code></li>
<li><code>nginx</code></li>
<li><code>openssh</code></li>
</ul>


<p>This list is not exhaustive, naturally, but serves as an example of
common software you don't need to worry about.</p>

<p>The vulnerability only exists in GnuTLS, as far as we know, so
programs linking against other libraries are not vulnerable.</p>

<p>Because the vulnerability affects session tickets -- and those are set
on the server side of the TLS connection -- only users of GnuTLS as a
server are vulnerable. This means, for example, that while <code>weechat</code>
uses GnuTLS, it will only suffer from the problem when acting as a
server (which it does, in relay mode) or, of course, if the remote IRC
server also uses GnuTLS. Same with apt, curl, wget, or git: it is
unlikely to be a problem because it is only used as a client; the
remote server is usually a webserver -- not git itself -- when using
TLS.</p>



<p>Keep in mind that it's not because a package links against GnuTLS that
it <em>uses</em> it. For example, I have been told that, on Arch Linux, if
both GnuTLS and OpenSSL are available, the <code>mutt</code> package will use the
latter, so it's not affected. I haven't confirmed that myself nor have I
checked on Debian.</p>

<p>Also, because it relies on session tickets, there's a time window
after which the ticket gets cycled and properly initialized. But that
is <a href="https://twitter.com/__agwa/status/1270054740559384576">apparently 6 hours by default</a> so it is going to protect only
really long-lasting TLS sessions, which are uncommon, I would argue.</p>

<p>My audit is limited. For example, it might have been better to walk
the shared library dependencies directly, instead of relying on Debian
package dependencies.</p>



<p>It seems the vulnerability might have been introduced in <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/695">this merge
request</a>, itself following a (entirely reasonable) <a href="https://gitlab.com/gnutls/gnutls/-/issues/184">feature request
to make it easier to rotate session tickets</a>. The merge request was
open for a few months and was thoroughly reviewed by a peer before
being merged. Interestingly, the vulnerable function
(<code>_gnutls_initialize_session_ticket_key_rotation</code>), explicitly says:</p>

<pre><code> * This function will not enable session ticket keys on the server side. That is done
 * with the gnutls_session_ticket_enable_server() function. This function just initializes
 * the internal state to support periodical rotation of the session ticket encryption key.
</code></pre>

<p>In other words, it thinks it is not responsible for session ticket
initialization, yet it is. Indeed, the <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275/">merge request fixing the
problem</a> unconditionally does this:</p>

<pre><code>memcpy(session-&gt;key.initial_stek, key-&gt;data, key-&gt;size);
</code></pre>

<p>I haven't reviewed the code and the vulnerability in detail, so take
the above with a grain of salt.</p>

<p>The <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275.patch">full patch is available here</a>. See also the <a href="https://gitlab.com/gnutls/gnutls/-/issues/1011">upstream issue
1011</a>, the <a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">upstream advisory</a>, the <a href="https://security-tracker.debian.org/tracker/CVE-2020-13777">Debian security
tracker</a>,
and the <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1843723">Redhat Bugzilla</a>.</p>



<p>The impact of this vulnerability depends on the affected packages and
how they are used. It can range from "meh, someone knows I downloaded
that Debian package yesterday" to "holy crap my full disk encryption
passwords are compromised, I need to re-encrypt all my drives",
including "I need to change all LDAP and MySQL passwords".</p>

<p>It promises to be a fun week for some people at least.</p>

<p>Looking ahead, however, one has to wonder whether we should follow
<a href="https://twitter.com/FiloSottile">@FiloSottile</a>'s advice and stop using GnuTLS altogether. There are
at least a few programs that link against GnuTLS because of the
<a href="https://en.wikipedia.org/wiki/OpenSSL#Licensing">OpenSSL licensing oddities</a> but that has been first announced in
2015, then <a href="https://www.openssl.org/blog/blog/2017/03/22/license/">definitely and clearly resolved in 2017</a> -- or <a href="https://opensource.com/article/19/2/top-foss-legal-developments">maybe
that was in 2018</a>? Anyways it's fixed, pinky-promise-I-swear,
except if you're one of those weirdos still using GPL-2, of
course. Even though OpenSSL isn't the simplest and secure TLS
implementation out there, it could preferable to GnuTLS and maybe we
should consider changing Debian packages to use it in the future.</p>

<p>But then again, the last time something like this happened, it was
<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a> and GnuTLS wasn't affected, so who knows... It is
likely that people don't have OpenSSL in mind when they suggest moving
away from GnuTLS and instead think of other TLS libraries like
<a href="https://tls.mbed.org/">mbedtls</a> (previously known as PolarSSL), <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a>, <a href="https://boringssl.googlesource.com/boringssl/">BoringSSL</a>,
<a href="https://www.libressl.org/">LibreSSL</a> and so on. Not that those are totally sinless either...</p>

<p>"This is fine", as they say...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            <div>
            <p><span>Created <time datetime="2020-06-11T15:47:35Z" pubdate="pubdate" title="Thu, 11 Jun 2020 11:47:35 -0400">tard dans la matinée de Thursday, June 11th, 2020</time>.</span>
            <span>
            
            <a href="http://source.anarcat.wiki.orangeseeds.org/?p=source.git;a=history;f=blog/2020-06-10-gnutls-audit.mdwn">Edited <time datetime="2020-06-11T16:18:48Z" title="Thu, 11 Jun 2020 12:18:48 -0400">Thursday, à l'heure du déjeuner, June 11th, 2020</time>.</a>
            
            </span>
            </p></div>

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-06-10-gnutls-audit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962840</guid>
            <pubDate>Mon, 27 Jul 2020 07:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACCC alleges Google misled consumers about expanded use of personal data]]>
            </title>
            <description>
<![CDATA[
Score 265 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23961881">thread link</a>) | @Khaine
<br/>
July 26, 2020 | https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div property="content:encoded"><p><em>Correction: An earlier version of this media release used a hypothetical example that suggested that Google used information about users’ health to personalise or target advertisements. Google says that it does not show personalised ads based on health information. This example has been removed from the media release.</em></p>

<p>The ACCC has launched Federal Court proceedings against Google LLC (Google), alleging Google misled Australian consumers to obtain their consent to expand the scope of personal information that Google could collect and combine about consumers’ internet activity, for use by Google, including for targeted advertising.</p>

<p>The ACCC alleges Google misled consumers when it failed to properly inform consumers, and did not gain their explicit informed consent, about its move in 2016 to start combining personal information in consumers’ Google accounts with information about those individuals’ activities on non-Google sites that used Google technology, formerly DoubleClick technology, to display ads.</p>

<p>This meant this data about users’ non-Google online activity became linked to their names and other identifying information held by Google. Previously, this information had been kept separately from users’ Google accounts, meaning the data was not linked to an individual user.</p>

<p>Google then used this newly combined information to improve the commercial performance of its advertising businesses.</p>

<p>The ACCC also alleges that Google misled consumers about a related change to its privacy policy.</p>

<p>“We are taking this action because we consider Google misled Australian consumers about what it planned to do with large amounts of their personal information, including internet activity on websites not connected to Google,” ACCC Chair Rod Sims said.</p>

<p>“Google significantly increased the scope of information it collected about consumers on a personally identifiable basis. This included potentially very sensitive and private information about their activities on third party websites. It then used this information to serve up highly targeted advertisements without consumers’ express informed consent,” Mr Sims said.</p>

<p>“We allege that Google did not obtain explicit consent from consumers to take this step.”</p>

<p>“The use of this new combined information allowed Google to increase significantly the value of its advertising products, from which it generated much higher profits.”</p>

<p>“The ACCC considers that consumers effectively pay for Google’s services with their data, so this change introduced by Google increased the “price” of Google’s services, without consumers’ knowledge,” Mr Sims said.</p>

<p><strong>“I agree” notification</strong></p>

<p>The conduct is alleged to have impacted millions of Australians with Google accounts.</p>

<p>From 28 June 2016 until at least December 2018, Google account holders were prompted to click “I agree” to a pop-up notification from Google that purported to explain how it planned to combine their data, and sought the consumers’ consent for this.</p>

<blockquote>
	<p><em>Some new features for your Google Account</em></p>

	<p><em>We’ve introduced some optional features for your account, giving you more control over the data Google collects and how it’s used, while allowing Google to show you more relevant ads.</em></p>
</blockquote>

<p>The notification also stated,&nbsp;<em>“More information will be available in your Google Account making it easier for you to review and control”</em>; and&nbsp;<em>“Google will use this information to make ads across the web more relevant for you.”</em></p>

<p>Before June 2016, Google only collected and used, for advertising purposes, personally identifiable information about Google account users’ activities on Google owned services and apps like Google Search and YouTube.</p>

<p>After June 2016, when consumers clicked on the “I agree” notification, Google began to collect and store a much wider range of personally identifiable information about the online activities of Google account holders, including their use of third-party sites and apps not owned by Google.</p>

<p>Previously, this additional data had been stored separately from a user’s Google account.</p>

<p>Combined with the personal data stored in Google accounts, this provided Google with valuable information with which to sell even more targeted advertising, including through its Google Ad Manager and Google Marketing Platform brands.</p>

<p>The ACCC alleges that the “I agree” notification was misleading, because consumers could not have properly understood the changes Google was making nor how their data would be used, and so did not - and could not - give informed consent.</p>

<p>“We believe that many consumers, if given an informed choice, may have refused Google permission to combine and use such a wide array of their personal information for Google’s own financial benefit,” Mr Sims said.</p>

<p><strong>Privacy policy change</strong></p>

<p>Before 28 June 2016, Google stated in its privacy policy that it&nbsp;<em>“will not combine DoubleClick cookie information with personally identifiable information unless we have your opt-in consent.”</em></p>

<p>On 28 June 2016, Google deleted this statement and inserted the following statement:<em>&nbsp;“[d]epending on your account settings, your activity on other sites and apps may be associated with your personal information in order to improve Google’s services and the ads delivered by Google.”</em></p>

<p>Google’s privacy policy also states:&nbsp;<em>“[w]e will not reduce your rights under this Privacy Policy without your explicit consent.”</em></p>

<p>The ACCC alleges that Google did not in fact obtain consumers’ explicit consent for this change to the privacy policy, and that Google’s statement that it would not reduce consumers’ rights without their explicit consent was therefore misleading.</p>

<p>“Google made a clear representation about how it would protect users’ privacy. The ACCC alleges that Google made changes without obtaining the explicit consent it had promised consumers it would obtain before altering how it protected their private information,” Mr Sims said.</p>

<p><strong>DoubleClick</strong></p>

<p>In 2008, Google acquired DoubleClick, a supplier of ad-serving technology services to publishers and advertisers.</p>

<p>Google now supplies DoubleClick’s services through its Google Ad Manager and Google Marketing Platform brands, which are the leading suppliers of ad-tech intermediary services.</p>

<p>These services track users’ internet activity on third-party sites that display ads through the use of DoubleClick’s advertising technology.</p>

<p>Google’s acquisition of DoubleClick required approval by competition authorities including the US Federal Trade Commission and the European Commission. The ACCC also reviewed and cleared this transaction.</p>

<p>FTC and EC cleared the acquisition, and in doing so considered submissions from Google that it would not be able to combine DoubleClick’s data on consumers’ internet activity with its own data about consumers’ activity on Google services because, at the time, DoubleClick’s contracts with its users prevented Google from doing so.</p>

<p>The agencies did not, however, rely on these submissions in clearing the acquisition.</p>

<p>Before 28 June 2016, Google collected and stored this information on a non-personally identifiable basis, as stated in its privacy policy.</p>

<p>On 28 June 2016, it changed its privacy policy by removing the term explaining how it would treat this DoubleClick data.</p>

<p><strong>Images</strong></p>

<p>Depending on the device and Google service being used by the consumer, the notification published by Google from 28 June 2016 was presented in a variety of ways. A copy of the notification in the form published to consumers using desktop devices is provided below for reference.</p>





<p><em>Source: Provided to the ACCC by Google Australia Pty Ltd</em></p>

<p>The relevant changes to Google’s Privacy Policy made on 28 June 2016 are also shown below for reference:</p>



<p>Source: Accessed from https://policies.google.com/privacy/archive?hl=en-US on 24 June 2020</p>

<p><strong>Background</strong></p>

<p>Google LLC (Google) is a multinational company incorporated in the United States with its headquarters in Mountain View, California. It is a subsidiary of Alphabet Inc.</p>

<p>Google supplies a range of services to consumers in Australia including Google Search, Google Maps, Gmail, YouTube, Google Play and Google Chrome.</p>

<p>Google also provides advertising services and analytics services to individuals and businesses. Advertising services are provided on Google services, such as Google Search, Google Maps and YouTube, as well as on websites and mobile device based applications not published or controlled by Google that partner with Google to display advertisements.</p>

<p>Google derives the majority of its revenue from its advertising and analytics services.</p>

<p><strong>Note:</strong> The concise statement has not been attached as it has been filed on a confidential basis pending claims by Google.</p>
</div></div></div></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961881</guid>
            <pubDate>Mon, 27 Jul 2020 02:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Hard-to-Read Gravestones (2014)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 20 (<a href="https://news.ycombinator.com/item?id=23961343">thread link</a>) | @vinnyglennon
<br/>
July 26, 2020 | https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/ | <a href="https://web.archive.org/web/*/https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961343</guid>
            <pubDate>Mon, 27 Jul 2020 00:50:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Warren Buffett 1997 Email Exchange on Microsoft [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23961036">thread link</a>) | @breck
<br/>
July 26, 2020 | http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf | <a href="https://web.archive.org/web/*/http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961036</guid>
            <pubDate>Sun, 26 Jul 2020 23:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Eng, the Master of the “Impossible Bottle”]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 59 (<a href="https://news.ycombinator.com/item?id=23960735">thread link</a>) | @fortran77
<br/>
July 26, 2020 | https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm | <a href="https://web.archive.org/web/*/https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="780">
  <tbody><tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot00.jpg" width="250" height="440"></td>
    <td colspan="2"><div>
      <h3>Harry Eng the Master Bottle Filler.</h3>
      <p>Harry was born in 1932 and died in 1996. He was  a school teacher, educational consultant, inventor, and magician. 
        A web search will tell you a little about his many talents but in summary: </p>
      <p><strong>Everything he did was intended to teach you to think. </strong></p>
      <p>Here are some of his bottles that are in the Puzzle Museum.</p>
      
      <p>This bottle contains his "Trademark" knot. It is, as always, too large to come out of the bottle, but also the stick  plus cord is too wide for the neck of the bottle.</p>
    </div></td>
  </tr>
  <tr>
    <td colspan="2"><p>One evening Harry was in a London hotel and decided to visit the Puzzle Museum the next morning. When he and his friends had finished their bottle of wine, he took the bottle up to his room. He then filled it with a book of matches, menu, and the pack of cards as a gift for us. This is a particular favourite as he assured us that the only tools he had were  a pencil and rubber bands. </p>
    <p>G135(AMB-POBJ) </p></td>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot01.jpg" width="250" height="622"></p></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot02.jpg" width="250" height="529"></p></td>
    <td colspan="2" rowspan="2">This is a "Loaded Deck". The deck is loaded with 6 shots. </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2">This incredible bottle has a bolt through 3 packs of playing cards. It is so tightly packed that there appears to be no room to get the nut on or off . </td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot03.jpg" width="250" height="523"></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot04.jpg" width="250" height="491"></p></td>
    <td colspan="2"><p>Our venerable curator has gone nearly blind with a magnifying glass but has failed to find any sign of breaks or glue in this plank. It is a One Gallon Bottle and the plank measures about 14 cm x 12.5 cm x 1.8 cm thick.</p>
    <p>Even if one could use the key that is loose in the bottom of the bottle, the padlock on the bottom of the plank is too large to fit through the neck of the bottle.</p>
    <p>The plank is engraved with Harry's "Think" Logo. </p></td>
  </tr>
  <tr>
    <td colspan="2"><p>This was Harry's favourite. Made in 1991. The label records how it was made:</p>
    <p>"Find a piece of wood from the High Chaparral (Manginita wood). Drill Deck. Put case in bottle. Put cards in case. Put rope through deck. Tie knot. Put nut, bolt, and lock parts into bottle. Hold bolt with a magnet - screw nut on with dental floss. Assemble and lock padlock. Finally sign the pack of cards". </p></td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot05.jpg" width="250" height="436"></td>
  </tr>
  <tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot06.jpg" width="380" height="444"></td>
    <td colspan="2"><p>This is Harry's ship in a bottle. <br>For details see<br> 
      <a href="https://www.puzzlemuseum.com/month/picm06/200608cutter.htm">Puzzle of the Month for August 2006</a> </p>
    </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></div></div>]]>
            </description>
            <link>https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23960735</guid>
            <pubDate>Sun, 26 Jul 2020 22:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small mail server best current practices]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 133 (<a href="https://news.ycombinator.com/item?id=23958599">thread link</a>) | @ebcase
<br/>
July 26, 2020 | https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/ | <a href="https://web.archive.org/web/*/https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <main>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
        <header>
          
          <time itemprop="datePublished" datetime="2020-07-24">July 24, 2020</time>
        </header>
        <p><em>(This post was originally written as a reply on the mailop mailing-list, but
a friend asked me to turn it into a blog post.  I've edited it, mostly
adding more links to elsewhere, but there are some additions here.)</em></p>
<p><em>Context: someone with a mail-server hosted in a German facility with a
poor reputation for handling abuse reports was asking for help on
sending email to their Gmail-using friends; they had SPF and didn't see
the point of DKIM; they had TLS setup for their mail-server, using a
certificate from CACert.</em></p>
<p>There's a PDF from Google from 2006 which is still worth reading:
<a href="https://research.google.com/pubs/archive/45.pdf">https://research.google.com/pubs/archive/45.pdf</a>, entitled
“Sender Reputation in a Large Webmail Service” by Bradley Taylor.
Anyone running a mail-server today needs to read that document.</p>
<p>If you don't send much email, then the only IP-based reputation which
Google can assess you on is the reputation of your address-block, so
being in a “troublesome” hosting provider will score heavily against
you.  At that point, if not moving away, you need to try to balance out
that negative score with enough positives that any of the large
providers using reputation scoring will accept the mail.</p>
<p>Working forward-and-reverse paired DNS is even more important for IPv6
than for IPv4; for better or worse, some of the large providers have
decided that exemptions in old standards for old behavior should not
apply when folks deploy standards which are far newer.  So you
absolutely need an <code>MX</code> record, you must not just rely upon
address-records (<code>A</code> and <code>AAAA</code>).</p>
<p>With a poor IP-based reputation, you need to see if you can score a
better domain-based reputation.  This is where DKIM comes into play:
once you can provably link a message to really be from a given domain,
then even if you don't send much mail you can benefit from stuff like
“not on day-old-bread domain-lists”.  But having DKIM and then a DMARC
record does help (and <a href="https://bridge.grumpy-troll.org/2014/04/dmarc-stance/">I'm no fan of DMARC</a>).</p>
<p>For the mail-server's TLS: for that to count in your favor instead of
being a wash, I strongly suspect that it needs to be a certificate which
senders can verify.  For those people scoring up for “better TLS”, those
senders using DANE will be happy with a TLSA record in DNSSEC for your
CACert anchor.  But the large webmail providers are Resistant to having
to deploy DNSSEC verification, so instead have pushed out an alternative
called MTA-STS.  With MTA-STS, you're tied into “whichever subset of CAs
all the large senders you care about will trust”, and then using that CA
for the certificates both for the MTA-STS web-server and for your
mail-server.  Note that you don't need to implement the client logic for
MTA-STS (and I think it's antithetical to an open federated platform)
but do need to just publish the static information for those senders who
do use it. At that point, CACert is not going to cut it.  You'd need to
try Let's Encrypt instead.</p>
<p>The ongoing natural tendency from larger providers is to favor
supporting what the majority of their users want the majority of the
time.  With so many people using larger providers, they naturally tilt
towards stuff which works with the larger senders, and requiring more
hoops.  Those additional hoops create more work for smaller providers
and self-hosters doing thing manually.</p>
<p>We need better automation tools around all of this.  The below will make
it clearer why.</p>
<p>So, here is my current understanding of the best current practices here,
in reality not IETF idealism.  This includes making mandatory stuff
which some folks insist must be optional, because realistically to send
to some large providers it's not optional.  This list includes features
to make you compatible with ongoing trends in the EU (particularly
Germany) to strongly disfavor allowing clear-text SMTP.</p>
<p>This assumes that you are <em>not</em> a large sender who should also be
setting up feedback loops, learning how to “warm” IPs, considering BIMI,
postmaster tooling domain verification, etc.</p>
<h3 id="deliverability-fixes">Deliverability fixes</h3>
<ol>
<li>reverse DNS with matching forward DNS; the name used should not
pattern-match anything generic and ideally would include a DNS label
of <code>mail</code> or <code>mx</code> or the like in it.</li>
<li>MX record, always.</li>
<li>Accurate SPF;
<ul>
<li>ideally not too broad; pay attention to SPF's query limits.</li>
<li>avoid <code>-all</code> at the end because, with the sole exception of “this
domain never sends email” records, the larger operators have metrics to
show that using <code>-all</code> <em>tends</em> to be a sign of over-enthusiasm rather
than reality, so it will slightly count against you;</li>
<li>remember to have an SPF record for your <code>HELO</code> hostname, because
when you send a “bounce” rejection, this is the thing which will be
looked up (since there's no domain in <code>&lt;&gt;</code>).</li>
</ul>
</li>
<li>DKIM set up, with thought towards the selector namespace.
<ul>
<li>RSA2048 key is effectively a hard-requirement
<ul>
<li>DNS TXT records consist of one or more DNS strings, each of which
is limited to 255 ASCII characters.  For a key of this size, you
will end up needing two DNS strings in the zonefile.</li>
</ul>
</li>
<li>Ed25519 keys are not yet widely supported, but by now are not
likely to actively break and make things worse for you, if you
dual-sign.  This needs to be a different selector.</li>
<li>Note that for various good reasons you should design this to be
something you routinely rotate.
<ul>
<li>Some folks use yearly, some monthly</li>
<li>I rotate every three months.</li>
</ul>
</li>
</ul>
</li>
<li>DMARC record; see <a href="https://tools.ietf.org/html/rfc7489" title="Domain-based Message Authentication, Reporting, and Conformance (DMARC)">RFC 7489</a>
<ul>
<li>But for domains which humans send from <em>don't</em> use
<code>p=quarantine</code> or <code>p=reject</code>;</li>
<li>Do consider setting up a receiver for reports, just so that you can
see how much of a privacy breach DMARC reporting is when you send
to mailing-lists which don't re-sign. :-/</li>
</ul>
</li>
<li>TLS certificate from a CA in the main trust anchor bundles;
<ul>
<li>Just use Let's Encrypt.</li>
</ul>
</li>
<li>MTA-STS web-server with HTTPS certificate from the same CA, and the
relevant MTA-STS txt file in place; add the DNS record when it's up
and happy.  See <a href="https://tools.ietf.org/html/rfc8461" title="SMTP MTA Strict Transport Security (MTA-STS)">RFC 8461</a>.
<ul>
<li>See <a href="https://esmtp.email/tools/mta-sts/">https://esmtp.email/tools/mta-sts/</a> for a testing validation tool
(with thanks to Luis Muñoz for the pointer).</li>
</ul>
</li>
<li>For the independent mail providers using the stuff broadly supported
in open source MTAs, you should look at DNSSEC, because the patterns
here are less susceptible to rent-seeking pressures:
<ul>
<li>DNSSEC-signed zone for your own domain
<ul>
<li>Use whichever signing algorithm CloudFlare are currently using:
this should be both current for cryptography and widely enough
supported that if it's not supported by someone's resolver, then
they have bigger problems than just your domain.</li>
</ul>
</li>
<li>DNSSEC validating resolver for you to look up records of others
(consider <a href="https://nlnetlabs.nl/projects/unbound/about/">Unbound</a> or <a href="https://www.knot-resolver.cz/">Knot Resolver</a>)</li>
<li>DANE records for your own domain (TLSA records in DNS)
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc7672" title="SMTP Security via Opportunistic DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS)">RFC 7672</a> for the SMTP details.</li>
<li>See <a href="https://tools.ietf.org/html/rfc6698" title="The DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS) Protocol: TLSA">RFC 6698</a> for the base spec with <a href="https://tools.ietf.org/html/rfc7218" title="Adding Acronyms to Simplify Conversations about DNS-Based Authentication of Named Entities (DANE)">RFC 7218</a> for some common
acronyms which make talking about it easier.</li>
<li>See <a href="https://tools.ietf.org/html/rfc7671" title="The DNS-Based Authentication of Named Entities (DANE) Protocol: Updates and Operational Guidance">RFC 7671</a> for the updates and operational guidance.</li>
<li>There are other RFCs, for SRV records and for OpenPGP, etc.</li>
</ul>
</li>
<li>Tell your mail-server to obey DANE stuff, so that if there's a TLSA
record in DNSSEC-verified DNS then the mail-server can disable
fallback to cleartext for delivery to MX (and ideally also then
verify the TLS connection has a cert chain which is anchored in one
of the TLSA records)</li>
<li><a href="https://dnsviz.net/">https://dnsviz.net</a> is your friend</li>
</ul>
</li>
<li><code>_smtp._tls</code> record so you can get reports of TLS failures sending to
you</li>
<li>Seeing if you can get your IP onto one of the open DNS-based
allow-lists (also called “whitelists” but some folks are moving away
from that term), such as <a href="https://www.dnswl.org/">https://www.dnswl.org/</a> or Spamhaus's SWL.</li>
<li>Periodically check if you appear in any DNS-based deny-lists.</li>
<li>Make sure you're not sending from “ISP residential address-space”; if
need be route your mail outbound via a host in better address-space
(and update SPF etc to match)</li>
<li>Don't do sender call-out verification to SMTP servers which aren't
yours.</li>
<li>For your own sanity, do make sure you set up <a href="https://www.fail2ban.org/">fail2ban</a>, or something
like it, scanning your mail-server logs, because SMTP AUTH online
cracking is widespread.  If they ever get in, your deliverability
will be negatively impacted by their spam campaign through your
mail-server.</li>
</ol>
<h3 id="convenience-stuff">Convenience Stuff</h3>
<p>Outside of “Phil's BCP” above, additional non-deliverability but
convenience options include:</p>
<ol>
<li>DNS SRV records for submission(s)/imap(s)/pop3(s)/sieve, even if just
to say with «<code>0 0 0 .</code>» that it's not supported.</li>
<li>If your communications base includes people using OpenPGP with email,
then set up WKD to publish OpenPGP keys for your domain too.
<ul>
<li>This is just a fixed schema for laying out keys for HTTPS retrieval.</li>
<li>See the <a href="https://datatracker.ietf.org/doc/draft-koch-openpgp-webkey-service/?include_text=1" title="OpenPGP Web Key Directory">WKD draft</a> for details.</li>
<li>I wrote <a href="https://github.com/PennockTech/openpgpkey-control">https://github.com/PennockTech/openpgpkey-control</a> as a
management framework for an organization; the
<code>other/standalone-update-website</code> script is designed to be
embeddable into an existing site-building workflow without anything
else from the repository.</li>
<li>The GnuPG project has tooling available which manages the WKD layout as
an email-integrated workflow, for people to update their own keys.</li>
</ul>
</li>
<li>If your communications base includes people using S/MIME then set up
SMIMEA records in your DNSSEC-signed DNS.
<ul>
<li>They look a lot like TLSA records; both are trust anchors in DNS.</li>
<li>See <a href="https://tools.ietf.org/html/rfc8162" title="Using Secure DNS to Associate Certificates with Domain Names for S/MIME">RFC 8162</a> for details.</li>
</ul>
</li>
<li>The moment you start specifying “must be TLS-secured” it's worth
adding <code>CAA</code> records into DNS, so that Certificate Authorities which
are broadly trusted will refuse to issue for your domain unless you
list them.
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc8659" title="DNS Certification Authority Authorization (CAA) Resource Record">RFC 8659</a> for details</li>
<li>The values checked by each Certificate Authority as indicating they
have permission are required to be listed in their Certification
Practice Statement, as part of the CA/Browser forum's Baseline
Requirements.  If it's missing, then browsers are not supposed to
be trusting that CA.</li>
<li>For domain-validation CAs such as Let's Encrypt, consider adding
account information to those records to tie it to your specific
account.  See <a href="https://tools.ietf.org/html/rfc8657" title="Certification Authority Authorization (CAA) Record Extensions for Account URI and Automatic Certificate Management Environment (ACME) Method Binding">RFC 8657</a> for details.</li>
<li>Beware that at time of writing, Let's Encrypt only honors the
<code>accounturi</code> restriction in their staging environment, not their
production setup; this will likely change.</li>
<li>Remember that DNS zonefiles support comments.  You'll want them</li></ul></li></ol></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</a></em></p>]]>
            </description>
            <link>https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23958599</guid>
            <pubDate>Sun, 26 Jul 2020 17:31:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signing .jars is not worth the effort]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 74 (<a href="https://news.ycombinator.com/item?id=23957663">thread link</a>) | @nurettin
<br/>
July 26, 2020 | https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html | <a href="https://web.archive.org/web/*/https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <figure>
<picture>


<source srcset="https://quanttype.net/images/path.jpg.webp" type="image/webp">

<img src="https://quanttype.net/images/path.jpg" alt="Duckboards make a serpentine curve over a marsh.">

</picture>
</figure>

<p>If you try to deploy a new release of Clojure library with
<a href="https://leiningen.org/">Leiningen</a>, it prompts you to sign the .jar file with GPG. This step
often causes confusion and breaks. I believe that it’s not worth the effort to
make it work.</p>
<p>As far as I know, <em>nobody ever verifies the signatures</em> in a systematic way.
There are a bunch of obstacles:</p>
<ul>
<li>It’s unclear if any tools for verifying the signatures actually work. For
example, I just tried to run <code>lein deps :verify</code> against a couple of projects
and it reported every dependency as <code>:unsigned</code>. I know that some of those
dependencies are signed and I verified that the <code>.asc</code> files exist on
repo.clojars.org.</li>
<li>It’s hard to find the public keys for the library maintainers. Sometimes they
upload them on the keyservers, sometimes not.</li>
<li>There’s no established way of communicating that which public keys should be
trusted. If there’s a new release and it has been made with a new key, your
best bet is to e-mail the maintainer and ask what is up.</li>
</ul>
<p>It’s hard to get any security benefits from the signatures in practice. Thus
it’s okay to set <a href="https://github.com/technomancy/leiningen/blob/998d373ae06d17234efffde761fae93242c736fa/sample.project.clj#L111"><code>:sign-releases</code></a> to <code>false</code> in your
project.clj even if Leiningen’s manual does not recommend it.</p>
<hr>
<p>In princple, the systematic checking of signatures could provide security
against a dangerous supply-chain attack: weak or leaked passwords for package
manager accounts. For example, <a href="https://arstechnica.com/information-technology/2019/08/the-year-long-rash-of-supply-chain-attacks-against-open-source-is-getting-worse/">several RubyGems</a> have been attacked
this way. Most likely the signing keys would not be compromised at the same
time.</p>
<p>There are alternative solutions, though, such as disallowing publishing packages
without multi-factor authentication. Using Clojars’s <a href="https://groups.google.com/forum/#!topic/clojure/GmAU4XwnRpw">deploy tokens</a>
helps a bit as well.</p>
<p>Right now we place a lot of trust on Clojars and Maven Central. If either of
them got compromised, we all would be screwed. Package signing could be a part
of a solution to mitigate that risk, but a comprehensive solution would be
something like using <a href="https://theupdateframework.io/">The Update Framework</a>. Go’s <a href="https://blog.golang.org/module-mirror-launch">checksum
database</a> is also worth taking look at.</p>
<p>Finally, if you’re moved to do something about this, please do not build
anything new using PGP. To quote Latacora: <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">PGP is bad and needs to go
away</a>.</p>
<hr>
<p>I’ve written this post in part to be proven wrong. I’m eagerly waiting for posts
from y’all about how you do, in fact, systematically verify the signatures.</p>

    </article></div>]]>
            </description>
            <link>https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957663</guid>
            <pubDate>Sun, 26 Jul 2020 15:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorize Your CLI]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23957325">thread link</a>) | @danyspin97
<br/>
July 26, 2020 | https://danyspin97.org/blog/colorize-your-cli/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/colorize-your-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danyspin97.org/blog/colorize-your-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957325</guid>
            <pubDate>Sun, 26 Jul 2020 14:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote work is not necessarily a good thing for the worker]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 233 (<a href="https://news.ycombinator.com/item?id=23957278">thread link</a>) | @rbanffy
<br/>
July 26, 2020 | https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/ | <a href="https://web.archive.org/web/*/https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.seanblanda.com/content/images/size/w300/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 300w,
                            https://www.seanblanda.com/content/images/size/w600/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 600w,
                            https://www.seanblanda.com/content/images/size/w1000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 1000w,
                            https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg" alt="Our remote work future is going to suck">
            </figure>

            <section>
                <div>
                    <p>As COVID-19 continues to alter the way we live, there is a scramble to predict what our “new normal” will look like. After the virus fades away or, God help us, becomes a constant in our day-to-day life for years to come, which change brought on by the pandemic will stick? </p><p>There is one consensus prediction that is emerging, especially among knowledge workers and those in tech: The distributed workforce is here to stay. And, furthermore, this change is a good thing for workers and welcomed by all.</p><p>To which I say: Um, have you ever worked remotely?</p><p>I have understood and enjoyed the perks of working remotely before. From 2009 to 2016 I wrote about entrepreneurs and creatives, many of whom were early proponents of remote work. And from 2017 to 2019, I worked remotely for a small, privately-owned e-learning company and then a 1000-employee SaaS company. </p><p>While the upsides to remote work are true, for many people remote work is a poison pill — one where you are given “control” in the name of productivity in exchange for some pretty nasty long-term effects.</p><p><strong>In reality, remote work makes you vulnerable to outsourcing, reduces your job to a metric, creates frustrating change-averse bureaucracies, and stifles your career growth.</strong> The lack of scrutiny our remote future faces is going to result in frustrated workers and ineffective companies.</p><p>Let’s tackle these issues one at a time. </p><h2 id="remote-work-democratizes-talent-for-everyone-even-you-">Remote work “democratizes talent” for everyone. Even you.</h2><p>In May 2020, <a href="https://blogs.gartner.com/manjunath-bhat/2020/05/03/remote-work-is-the-next-big-equalizer/" rel="noreferrer nofollow noopener">a Gartner blog post</a> summarized a common argument in favor of remote work: “Democratizing access to resources lowers the barriers to innovation and enables everybody to partake in the ensuing prosperity.” Not everyone can (or wants to) live in an urban commercial hub. Remote work, the thinking goes, allows people to live in whatever environment they’d like — depending on their own circumstances.</p><p>These remote technology jobs don’t just go to a version of you living on a cute farm in the Hudson Valley. Those jobs go to <em>anyone, anywhere.</em> </p><p>This is good for global prosperity and perhaps arguably inevitable. However, if you’re working in technology today as an American, you have tremendous earning potential. This earning potential may not be possible forever. It’s baffling to me that American workers would cheer an acceleration of this trend that would place downward pressure on their wages.</p><p>When you, the American worker, share this belief you are being blinded by an erroneous belief in American exceptionalism. When your company goes all-remote, it is starting a clock that ends in you eventually competing with the global talent market — especially if travel and visas continue to be restricted by the federal government.</p><p>A tech optimist will likely (and correctly) point out that more innovation and new technologies will replace any outsourced jobs. While my academic brain wants that to be true, I can’t help but see the devastating effects globalization had to our manufacturing workers and communities — many of which have never recovered or benefited from new innovations.</p><p>Innovation in the American economy didn’t get transferred one-to-one. Every manufacturing worker did not suddenly receive a tech job. Every technology worker outsourced will not receive the benefit of the next wave of innovation directly. </p><h2 id="remote-enables-you-to-be-forgotten">Remote enables you to be forgotten</h2><p>Remote work advocates often praise the focus that remote work enables. No longer will you be judged by the time you spend at the office, they say, you’ll instead be judged and rewarded on whether you “get things done.” </p><p>These “benefits” are always used to sell remote work to an imagined audience of Dilbert-like cubicle dwellers who are imprisoned and subjected by annoying coworkers and an oppressive boss. The key to freedom, they say, is to work remotely. Basecamp co-founder Jason Fried <a href="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html" rel="noreferrer nofollow noopener">writes in <em>Remote</em></a>:</p><!--kg-card-begin: html--><blockquote darkmode="" data-title="Working%20From%20Home%20Boosts%20The%20Quality%20Of%20The%20Work" data-author="Jason Fried&nbsp;" cite="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html">
                      <p>What you're left with is "what did this person actually do today?" Not "when did they get in?" or "how late did they stay?" Instead it's all about the work produced. So instead of asking a remote worker "what did you do today?" you can now just say, "Show me what you did today." As a manager, you can directly evaluate the work--the thing you're paying this person for--and ignore all the stuff that doesn't actually matter.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>First, being more productive isn’t the only goal of working, but let’s put that to the side. Second, Fried is right, you do gain a bit of freedom from your boss (which doubles as a loss of a mentor, but we’ll get to that). You also gain “freedom” from your colleagues and collaborators. Which means you’re effectively on your own. </p><p>This is empowering to some, but the isolation can mean your contributions are easily overlooked or misunderstood. As a result, I’ve noticed a disturbing trend at (especially larger) remote companies: Some managers often have no clue what their direct reports are doing and how they are doing it. </p><p>Performance reviews are difficult enough under normal circumstances. But how do you judge someone when you can only see their output and never their process? Marketers, project managers, product managers, growth marketers, and others spend their days supporting or maintaining existing things. &nbsp;</p><p>This a difficult problem that predates any shift to remote work. But when applied to remote work, a manager loses several of the inputs needed to judge a direct report’s output — including, yes, who is physically (and mentally) present when actual work is being done. But also: Do the other team members appear to enjoy working with this person? And, if they are struggling, is it due to a lack of effort/focus or something outside of their control? </p><p>Employees who “do the right thing” spending extra time and energy supporting their teammates receive absolutely no recognition for doing the little things needed for a smooth-running, collaborative organization. It’s usually a quantifiable fact whether a sales departments reaches their goals. It’s not as clear that the social media manager had a good quarter.</p><p>With the removed context of a real-life office, your team’s output is difficult to individualize for your manager — especially if work is done in private DMs or one-on-one Zoom calls. The manager sees the end product with no visibility as to who did what, who pulled their weight, who made tough choices, and who made things more difficult. This has a nasty side effect of the leader viewing you less as a person who they have to empathize with and understand — and more as a talking head on a Zoom call or Slack who does things for them. </p><p>This will cause your work to “flatten.” Whatever soft skills you bring to the table will be minimized when working remotely. This will lead to companies and processes relying less on things like creativity and collaboration and more on simple inputs and outputs. Which, again, makes your work easier to outsource.</p><p>We bemoan the loss of empathy and context created by solely getting our news and interacting via social media … and we then turn around and set up our working lives in their image.</p><p>This has a pronounced effect in large organizations.</p><h2 id="remote-work-breaks-large-companies">Remote work breaks large companies</h2><p>Remote work supporters often return to the “interruption culture” at an IRL office as an argument for distributed work. First, clearly people that believe remote work creates an interruption-free zone have never used Slack or email. Second, those interruptions often exist for a reason: They often communicate information that ensures everyone is working on the right thing.</p><p>For companies that have strong product/market fit, have reached scale, and have a clear product roadmap, remote works swimmingly. A distraction-free environment means everyone can focus on “what matters” because “what matters” has been clear and consistent. &nbsp;</p><p>But what happens when “what matters” changes? </p><p>Because it will. Eventually, the market shifts. There’s a competitor or a Black Swan-style event in the industry (like, say, a global pandemic). Suddenly the well-oiled machine needs to adapt and change course. For companies larger than 100 people, this is tremendously difficult in an in-person environment. Working remote, it’s damn near impossible. Twice-a-year in-person meetups are not enough to disseminate brand new strategies. </p><p>And I'd bet that as formerly IRL companies go remote, it will have a negative effect on their ability to iterate and adjust to market conditions making them vulnerable for a smaller, co-located upstart.</p><h2 id="remote-work-can-stifle-your-career-growth">Remote work can stifle your career growth</h2><p>Think back to your first job in your current field. I’d bet there is a person or group of people who were tremendously important in shaping your career. They gave you candid advice and were able to passively observe and critique your behavior.</p><p>When you work remotely, mentorship is stifled because there is no learning via osmosis. You can’t model your behavior on your successful teammates because you only see them on Zoom and in Slack. Whatever process they are using to achieve their results is opaque to you. </p><p>Much of the language used around remote work (and remote events) assumes that one is in the mid-to-late stages of their career. When you’re young, you don’t need “focus” or to “get things done.” You need exposure to new ideas and people. You need the serendipitous fortune of sitting in on the right meeting, attending the right happy hour, or earning the respect of the right observer.</p><p>All of the above is more difficult in a remote environment. As a result, we are in danger of having a generation of new knowledge workers who are never properly onboarded and hastily told to work remotely with nothing but an OKR to chase. They have no context for how to do all of the messy office-ready skills like building consensus, having productive disagreements, and advocating for their ideas.</p><p>Additional…</p></div></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</a></em></p>]]>
            </description>
            <link>https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957278</guid>
            <pubDate>Sun, 26 Jul 2020 14:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Gene Cernan's Missing Moon Camera]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23956771">thread link</a>) | @uptown
<br/>
July 26, 2020 | https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera | <a href="https://web.archive.org/web/*/https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5e5ee63acb9e965b95a34c71" data-item-id="5e5ee63acb9e965b95a34c71">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1583277661007" id="item-5e5ee63acb9e965b95a34c71"><div><div><div data-aspect-ratio="100.80906148867315" data-block-type="5" id="block-yui_3_17_2_1_1583276156349_38578"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image-dimensions="1920x1981" data-image-focal-point="0.5,0.5" alt="Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17." data-load="false" data-image-id="5e5ff5accacd55785de67f35" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594000429895_118575"><div><h2>The mystery of its location</h2><p>It’s often repeated how most of the cameras that landed on the moon stayed on the moon. Astronaut Gene Cernan had been telling the story of how<a href="https://petapixel.com/2012/12/06/the-last-man-to-walk-on-the-moon-left-his-camera-for-a-long-term-gear-test/" target="_blank"> he left his camera</a> on the lunar rover<a href="https://www.telegraph.co.uk/news/science/space/9728289/Apollo-17-commander-left-camera-on-moon-40-years-ago.html" target="_blank"> for years</a>, recounting the tale in interviews:</p><blockquote><p>"I left my Hasselblad camera there with the lens pointing up at the zenith, the idea being someday someone would come back and find out how much deterioration solar cosmic radiation had on the glass. So, going up the ladder, I never took a photo of my last footstep. How dumb! Wouldn’t it have been better to take the camera with me, get the shot, take the film pack off and then (for weight restrictions) throw the camera away?"</p></blockquote><p>It’s easy to accept Cernan at his word - he’s an American hero who flew to space three times, twice to the moon - so as far as everyone was concerned, including the press, the camera was right where he said he left it. Plus, a quick scan of the Apollo 17 stowage list reveals no mention of a lunar surface camera splashing down with the command module. So why the mystery? </p><p>Looking closer, there’s a sprinkling of evidence in photos and transcripts that suggest his camera did in fact return to earth, contradicting both the 1972 NASA inventory and the astronaut. No, don’t cue the dramatic music… there’s no mischief or intentional deception here. I believe Gene Cernan did leave a camera on the lunar rover, just not “his.”&nbsp;Memory can be a fickle thing, even for heroes, and that rings especially true in this case&nbsp;when the story involves not one camera, but three.</p><h2>A tale of three cameras</h2><p>When you’re going to the moon, you’re assigned a camera with a 60mm lens that gets strapped to your chest to document samples, experiments, and the lunar terrain. Both astronauts get their own, clearly labeled with a sticker on the side: “CDR” for commander and “LMP” for lunar module pilot, but they weren’t mutually exclusive, often being swapped throughout the mission based on what film they were shooting with. On Apollo 17, Jack Schmitt - LMP and geologist extraordinaire - was set up with the black &amp; white film. When he needed color, he’d grab Cernan’s camera and vice versa. </p><p>A third Hasselblad camera was also to be used on the mission; it was a bit of a beast really, boasting a 500mm telephoto lens meant to capture distant lunar features for, you know… science. Of the two astronauts, Cernan got stuck looking down the barrel of the 500mm the most, so it’s entirely possible that <em>this</em> is the camera he remembers leaving on the rover. In fact, the post-flight analysis of the transcript pretty much confirms it. But what happened with the other two?</p><h2>The stowage list says they stayed </h2><p>A little background. As each Apollo mission launched, NASA prepared a final stowage list that documented all the equipment aboard, detailing what was to be transferred between each spacecraft before and after landing on the moon. This list was then revised in real time as plans changed due to time or weight restrictions. In the latest revision of the <a href="https://www.hq.nasa.gov/alsj/a17/a17stowage.pdf" target="_blank">Apollo 17 LM Lunar Launch Stowage List</a>, dated December 12th, 1972, the three cameras that went down in the LM are all marked as “offloaded,” meaning they were left on the surface. The problem is, they launched from the moon on December 13th! So if extra items were brought onboard, it’s not recorded. At least not in what’s available online.</p></div></div><div><div><div data-aspect-ratio="55.70987654320988" data-block-type="5" id="block-yui_3_17_2_1_1594649779919_85920"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Two Hasselblad Data Cameras with 60mm lenses marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1594000429895_28896"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>One Lunar Surface Camera with 500 lens marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594649779919_62191"><div><h2>The <a href="https://www.hq.nasa.gov/alsj/a17/a17.clsout3.html#1702716" target="_blank">audio</a> says otherwise</h2><p>The next logical step was to check the transcripts to see if it was possible to follow the cameras by listening to what was happening. As you read the following excerpt, Cernan and Schmitt are both standing by the final resting place of the lunar rover at the end of their last EVA.</p><blockquote><p>169:29:44<strong>&nbsp;Parker [Mission Control]:</strong> ...and, Jack, <strong>we're making plans here, to change the camera usage at the end of EVA here.</strong> And we're going to let you take Commander's camera out to the ALSEP and take a few photos which people think we need. And Gene's going to take your camera out and document the geophone, when he deploys it. We will not deploy it for the long-term experiment, however. <strong>And we'll bring both (cameras) back, and carry them to the ETB when we get done.</strong></p><p>169:30:17&nbsp;<strong>Cernan:</strong> Okay.</p><p><em>[When he said "document the geophone", Bob may have been referring to documentary photos of the seismic charge Gene will deploy near the VIP site. "When he deploys it" probably refers to the charge and the phrase "we will not deploy it for the long-term experiment" refers to a planned deployment of the camera on the Rover seat as indicated on checklist page&nbsp;</em><a href="https://www.hq.nasa.gov/alsj/a17/a17eva3_cdr30.gif" title="image" target="new"><em>CDR-3</em></a><em>2. </em><strong><em>Specifically, the checklist calls out "Pos(ition) LMP cam(era) vert(ically) on seat."</em></strong><em> Gene remembers that he did put the camera on the seat, with the lens pointed at the zenith. Presumably, the intent was to recover the camera at some future date to get information of long-term exposure to the lunar environment.]</em></p><p>[Cernan - "Parker said 'We'll bring them both (that is, both cameras) back,' but I know what I did with that camera. I left it on the Rover pointed straight up. <strong>That's what I planned to do and that's what I did. </strong>I can remember specifically wedging it - I don't remember exactly where - somewhere up between our seats."]</p></blockquote><p><em>&gt;&gt;&gt;&gt; Fast forward to where the astronauts are now back at the LM &gt;&gt;&gt;&gt;</em></p><blockquote><p>170:39:59&nbsp;<strong>Parker [Mission Control]: </strong>Okay, and we gather an ETB coming up with two cameras in it.</p><p>170:40:04&nbsp;<strong>Schmitt:</strong> ETB's next. (Pause) (To Gene) Got an ETB? Yeah. (Pause) ETB has two cameras.</p></blockquote></div></div><div data-aspect-ratio="94.44444444444444" data-block-type="5" id="block-yui_3_17_2_1_1594747724966_190880"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image-dimensions="378x380" data-image-focal-point="0.5,0.5" alt="CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera" data-load="false" data-image-id="5f0f1cf80254b81fb47dba1f" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594747724966_196522"><div><p>Ok, let’s unpack this:</p><ol data-rte-list="default"><li><p>NASA deviates from the flight plant requesting the astronauts swap cameras:<strong> Schmitt is to return to the LM with Cernan’s CDR camera</strong>, and Cernan is to use Schmitt’s LMP camera at the rover.</p></li><li><p>When they’re done, both CDR and LMP cameras<strong> are to be brought back into the LM</strong> using the equipment transfer bag (ETB). </p></li><li><p>On Gene’s cuff checklist was an item to “Position the LMP camera facing up on the seat of the rover,” leaving it behind, but because NASA had just asked for that camera to be returned, Gene, following the checklist, positions the 500mm in its place, returning to the lunar module with the LMP in hand.</p></li><li><p>Two cameras, the CDR and LMP, are then confirmed in the ETB going up to the LM.</p></li></ol><p><em>&gt;&gt;&gt;&gt; Fast forward again to the astronauts inside the LM after a rest period &gt;&gt;&gt;&gt;</em></p><blockquote><p>183:40:17&nbsp;<strong>Fullerton [Mission Control]:</strong> Challenger, Houston. One update for the post-sleep procedure. I understand you brought in the LMP's camera, and we want to be sure you get that into the&nbsp;<a href="https://www.hq.nasa.gov/alsj/alsj-JettBag.html" target="new">jett bag</a>&nbsp;before the final jettison here. And, by the way, you're Stay for that final jettison.</p><p>183:40:39&nbsp;<strong>Schmitt: </strong>Okay, Gordy. It's already in the jett bag, thank you. (Pause)</p><p><em>[</em><strong><em>Cernan </em></strong><em>- "Obviously, I did not leave the LMP's camera on the Rover pointed at the zenith. But I swear I put something there. It's possible it could have been the 500 lens, because we didn't bring it back and I mentioned it was under the seat. I know that I did something with a camera. Now, it could have been a lens. And I stuck it between the seats, sort of wedged it in somewhere, and pointed the lens toward the zenith."]</em></p><p>[<strong>Schmitt </strong>- "Houston wanted us to jettison the camera because they didn't want us to take pictures of Ron Evans' EVA. They had decided it was too cumbersome and too risky. But, we were going to ignore them, and we figured out how we could do it. But we needed a camera. Ron had a camera, but it was not EVA-qualified."]</p><p>[<strong>Cernan</strong> - "We had made up our minds we were going to take pictures of Ron."]</p><p>[<strong>Schmitt </strong>- "And we needed a lunar-surface camera to do it."]</p><p><strong>[Cernan - "Now, we did put the LMP's camera in the jett bag, so we must have had mine."]</strong></p></blockquote><p>*Click*. Finally, we have some clarity. One 500mm camera stays behind, and of the two that go up into the LM, the LMP camera gets jettisoned back to the surface before launch. Cernan’s camera leaves with them as they blasted off live on TV and in color.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1594997167739_70248"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image-dimensions="1721x1721" data-image-focal-point="0.5,0.5" alt="At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover." data-load="false" data-image-id="5f11ba2ee9f8df4e02356918" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594997167739_107441"><div><h2>The photos confirm it</h2><p>Every lunar camera has a unique serial number, usually etched into a piece of glass that’s pressed against the film plane. It’s known as the Réseau plate, used to help scientists both accurately measure objects in view, and identify what camera took what image.&nbsp;By simply <a href="https://tothemoon.ser.asu.edu/gallery/Apollo/17/Hasselblad%20500EL%20Data%20Camera%2070%20mm" target="_blank">looking through the …</a></p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</a></em></p>]]>
            </description>
            <link>https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956771</guid>
            <pubDate>Sun, 26 Jul 2020 13:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Surprise AWS Bill]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 287 (<a href="https://news.ycombinator.com/item?id=23956671">thread link</a>) | @oaf357
<br/>
July 26, 2020 | https://chrisshort.net/the-aws-bill-heard-around-the-world/ | <a href="https://web.archive.org/web/*/https://chrisshort.net/the-aws-bill-heard-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><h2 id="scene">Scene</h2><p>It was a bright, Saturday morning, July 4, 2020. I had just gotten Max all situated with breakfast and cartoons (Mighty Mike, if you’re curious). Julie was sleeping in like she usually does on every day I have off. I’m an early riser and this is a cherished part of our co-parenting. It gives Max and I time to bond (when he’s not stuffing his face and laughing at cartoons). I sat down with my laptop to plow through the week’s personal email.</p><h3 id="the-e-mail">The e-mail</h3><p>“Oh look, the AWS bill, I should have a laugh at that,” I thought to myself. Until recently, it had been pennies a month for some very light SES usage. In February, I moved off Google Cloud back to AWS. The primary motivation was that Google had so intertwined GSuite and GCP IAM that it became overly confusing.</p><p>Along with that migration came the CDN for this web site (cdn.chrisshort.net). I mean <a href="https://chrisshort.net/low-cost-content-delivery-network-cdn/">a Cloudflare fronted S3 bucket that holds assets deemed too big for git</a> when I say CDN. It’s not even <a href="https://chrisshort.net/">chrisshort.net</a> itself, as it is hosted on Netlify’s CDN and every other static site I own or manage. I’ve been a Cloudflare user for a long time. The CDN is less than 300 files and has existed for over five years on various clouds. Moving it back to AWS from GCP bumped the AWS bill to an average of $23/month. Not too bad given the <a href="https://app.usefathom.com/share/suwvjwwc/chrisshort.net">site’s traffic</a>.</p><h3 id="the-shock">The shock</h3><p>Not on this Saturday morning, nope. June 2020’s AWS bill was a heart palpitation causing <strong>$2,657.68</strong> (<a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/invoice498711077_redacted.jpg">JPG</a>). I audibly gasped, “Keep your shit together.” I thought to myself. Max was leaned up against me drinking his milk. I know he could tell something was wrong because he looked at the laptop screen. I only assume when he saw letters and numbers, he thought, “Adult stuff… These cartoons and this Cinnamon Toast Crunch tho.” 2020 being the year that it is and my military history being what it is, I’ve been diagnosed with a panic disorder (on top of the PTSD and physical injuries).</p><h3 id="the-panic">The panic</h3><blockquote data-dnt="true"><div lang="en" dir="ltr"><p>Good morning, $2700 AWS bill!</p><p>Holy shit...</p></div>— Chris Short (@ChrisShort) <a href="https://twitter.com/ChrisShort/status/1279406322837082114?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><p>I immediately began having a panic attack. As I took the mental steps to mitigate the onset of the panic attack, I started forming a battle plan. Yes, I can switch back to emergency mode, like back in the old days, when something would go bang or boom, and I’d run towards it (it’s not helpful overall, trust me).</p><p>First, Max: Maslow’s Hierarchy of Needs? Check.<br>Next, me: As if it was destined, my alert for morning medications went off.</p><p>“Daddy’s gotta grab his meds, bud.” Instinctively, Max leans off me (wow… okay… he’s used to hearing that reminder and statement shortly after that; my brain is now in overdrive). I take everything I need to conquer this while still being able to function cognitively. I refill my coffee and grab a laptop charger.</p><h2 id="incident-response">Incident response</h2><p>Check the source of truth.</p><p>What’s diverged?</p><p>How do we get things back to normal?</p><p>I login to the AWS console, hoping I got some output that was uniquely off this month. Weirder stuff has happened (like <a href="https://aws.amazon.com/message/41926/">S3 going down</a>). This bill couldn’t be more out of the norm than ever. This AWS bill is several hundred dollars more than our mortgage! I hit the AWS Billing page and am deeply saddened by what I see:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/1f2dd17bc5d8e1407c22b84f7f981a7ad9888eba/8e235/the-aws-bill-heard-around-the-world/aws-bill-landing-page.png" alt="AWS Billing landing page showing a $2,657.68 balance"></p><p>There it was. <strong>$2,657.68</strong>, staring at me. “This can’t be legit.” Drilling down even further, it looks like it is indeed legitimate traffic from the cdn.chrisshort.net S3 bucket in us-east-2. In total, <strong>more than 30.6 terabytes of traffic</strong> had moved out of that one S3 bucket. WHEN?!? Did this just happen? Nope.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/3373f05e910b0938aeed4a2975b4b4f48922fdc0/2e223/the-aws-bill-heard-around-the-world/aws-june-2020-data-transfer.png" alt="AWS data transfer billing break down"></p><p><img src="https://d33wubrfki0l68.cloudfront.net/46294144a86a5d64df074d306386b3024b7d882a/af2d6/the-aws-bill-heard-around-the-world/june-23-24-2020-s3-breakdown.png" alt="S3 Activity"></p><p><strong>30.6 TB?!?!</strong> how is that even possible???<br>$1,011.59 on 23 June 2020.<br>$1,639.07 on 24 June 2020.</p><p>I immediately open a ticket with AWS Support frantically wondering what broke? How is this even possible? Did someone bypass Cloudflare? What the hell is Cloudflare saying?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/6cd3322753f262dc51bbca44a07fef6b19b381e9/52aec/the-aws-bill-heard-around-the-world/cloudflare_june_22_2020.png" alt="Cloudflare 22 June 2020"><br>Oh cool, Cloudflare let those 2,700 requests passthrough completely uncached? How is that not anomaly detected as a DDoS??? How is it that barely a fraction of the traffic is cached (more on that later)?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a0f7d1526c44cb74baba13f749f3d5a886bbdadb/6d2b1/the-aws-bill-heard-around-the-world/cloudflare_june_23_2020.png" alt="Cloudflare 23 June 2020"><br>Oh, another 4,400 requests the next day… Sweet, baby Jesus. Oh, but you served 9 GB from cache. Thanks, Cloudflare.</p><h2 id="help-arrives">Help Arrives</h2><p>Apparently, when you tweet something crazy af, like a $2700 AWS bill, it gets a lot of attention on a quiet holiday morning. A quarter-million people saw the tweet and a third of them interacted with it. It was enough attention that the AWS Support Twitter account was on it before, <a href="https://twitter.com/QuinnyPig/status/1186319925901586432">my friend</a> and <a href="https://www.duckbillgroup.com/">cloud economist</a>, Corey Quinn.</p><blockquote data-dnt="true"><p lang="en" dir="ltr">Oh no! 😰 Sorry to hear about this unpleasant Saturday morning surprise, Chris. Please create a support case so our agents can help get to the bottom of this: <a href="https://t.co/weTUnSYLRU">https://t.co/weTUnSYLRU</a>. 🕵️‍♀️ ^HG</p>— AWS Support (@AWSSupport) <a href="https://twitter.com/AWSSupport/status/1279424879566163970?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>Praise Twitter for at least its ability to draw attention to things. I am not sure this would’ve ended up as well as it did without it.<blockquote data-dnt="true"><p lang="und" dir="ltr"><a href="https://t.co/tUrNnXqWMY">pic.twitter.com/tUrNnXqWMY</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1279446759664611329?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>I forwarded the bill to Corey almost immediately after seeing it at pre-dawn west coast time. I am forever thankful to Corey for his analysis. When he was ready, Corey sent me a list of things he needed to do an analysis (instead, I created him a regular IAM account with the proper perms 😉 and yes I cleaned up after).<p>Corey encouraged me to apply a bucket policy that would only allow Cloudflare IP addresses to access anything from the bucket. The theory here is that someone could have been bypassing Cloudflare somehow. But, thankfully, <a href="https://www.cloudflare.com/ips/">Cloudflare publishes their IP blocks</a> and they don’t change all that often. The Cloudflare support article, <a href="https://support.cloudflare.com/hc/en-us/articles/360037983412-Configuring-an-Amazon-Web-Services-static-site-to-use-Cloudflare#77nNxWyQf69T1a78gPlCi9">Configuring an Amazon Web Services static site to use Cloudflare</a> gives you an example bucket policy to do exactly that. This should become a standard practice for folks. However, it wouldn’t have mattered in this case; more on that later.</p><p>Corey Quinn’s thread on the topic covers what happened on the AWS side pretty well:</p><blockquote data-dnt="true"><p lang="en" dir="ltr">That's right--it's threading time!<a href="https://twitter.com/ChrisShort?ref_src=twsrc%5Etfw">@chrisshort</a>'s surprise <a href="https://twitter.com/awscloud?ref_src=twsrc%5Etfw">@awscloud</a> bill of $2700 looks S3 driven... <a href="https://t.co/VnXufn24iA">https://t.co/VnXufn24iA</a> <a href="https://t.co/tKLWv5rHtW">pic.twitter.com/tKLWv5rHtW</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1280280727133642753?ref_src=twsrc%5Etfw">July 6, 2020</a></blockquote><ul><li>”…it’s almost entirely due to us-east-2 data transfer out…”</li><li>“Now, what caused this? Nobody knows!”</li><li>“Chris Short isn’t some random fool…” (Might be the nicest thing Corey’s every said about anyone he’s not related to)</li><li>”‘Surprise jackhole, your mortgage isn’t your most expensive bill this month, guess you shoulda enabled billing alarms!’ is crappy, broken, and WOULD NOT HAVE SOLVED THE PROBLEM!”</li><li><a href="https://twitter.com/QuinnyPig/status/1280289410844471296?s=20">“I want to be explicitly clear here: Chris Short didn’t do anything wrong!”</a></li></ul><h2 id="but-wait-there-s-more">But wait! There’s more!</h2><p>I had tickets in with Cloudflare (1918916) and AWS (7153956931). Cloudflare was the least helpful service I could have imagined given the circumstances. A long term user and on and off customer thinks they were attacked for two days and you don’t lift a finger? If I didn’t have reason enough to move off of Cloudflare, I do now. That’ll be an update for a later blog post. But, if you work for a CDN company and you’re relatively painless to get up and running, I’m interested in hearing from you.</p><p>After a very chaotic morning, I take Corey’s advice, disconnect, and enjoy the holiday weekend.</p><h2 id="more-help-arrives">More Help Arrives</h2><p>On July 8th, an astute AWS employee starts doing some digging around and reaches out to me. Because they see this as bafflingly as Corey and I do. How did so few requests generate so much traffic so quickly and then as soon as it appears, it’s gone again? It doesn’t seem like something intentionally malicious either because Cloudflare and AWS let it right on through.</p><h3 id="here-s-the-theory">Here’s the theory</h3><p>In hindsight, I made a poor decision to distribute a trial Windows 2019 SQL Server virtual machine images (fully patched with all necessary drivers and VM extensions) in the form of a qcow2 file. Someone became aware of the existence of this VM image. They then stood up hundreds, potentially thousands, of copies this VM using the internet accessible URL. This is, in theory, possible, with something like <a href="https://chrisshort.net/tags/kubernetes/">Kubernetes</a> and <a href="https://kubevirt.io/">Kubevirt</a>. Given that the disk image becomes a volume mount in the corresponding VMs pod. Spin up enough copies of the VM, a single YAML file can create infinite copies of a VM. If the YAML definition directly referenced the Cloudflare or S3 URL and not a locally cached copy, you can rack up the number of times you pull down an image real quick. The qcow2 image, in this case, was 13.7 GB. But it’s trickier than that.</p><h3 id="the-sharp-edge-of-the-cloud">The sharp edge of the cloud</h3><p>File this under, “Things I should’ve known but didn’t.” Did you know that “The maximum file size Cloudflare’s CDN caches <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files."><strong>is 512MB</strong></a> for Free, Pro, and Business customers and 5GB for Enterprise customers.” That’s right, Cloudflare saw requests for a 13.7 GB file and sent them straight to origin every time <em>BY DESIGN</em>. <strong>Ouch!</strong></p><p>I suspected these files immediately on July 4 and moved them to an internal work GDrive for the time being. If you need the images, let me know, you’re also a suspect if you ask for them, be warned.</p><p>If you’re sitting at home doing the math, something might not be adding up. The bandwidth cost is off, there was indeed some legitimate traffic to the bucket in June, of course, But, as it turns out the intrepid AWS employee discovered that 3655 partial GETs to the object might have actually been delivered as full file requests and Cloudflare might have ever done anything with them. Yes, this is a bug somewhere and folks are looking into it. I also suggested that object size limits be a tunable S3 bucket policy. This way, I wouldn’t have even been able to upload the files to the bucket, to begin with.</p><h2 id="the-resolution">The Resolution</h2><p>As I mentioned, I’ve removed the multiple gigabyte files from the bucket the day I got the bill (July 4). <a href="https://twitter.com/QuinnyPig/status/1280282363461726208">Corey pointed that out here</a>. That might have hindered the investigation from the AWS side. I won’t be so quick to delete in the future. I will lock files down though. But, let’s face it. Now that I’m aware of the <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files.">512 MB file limit at Cloudflare</a>, I am moving other larger files in that bucket to <a href="https://archive.org/">archive.org</a> for now (and will add them to my supported <a href="https://chrisshort.net/causes/">Causes</a>).</p><p>Long term, I won’t want to store files in …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/">https://chrisshort.net/the-aws-bill-heard-around-the-world/</a></em></p>]]>
            </description>
            <link>https://chrisshort.net/the-aws-bill-heard-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956671</guid>
            <pubDate>Sun, 26 Jul 2020 12:40:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying MLsub – The Simple Essence of Algebraic Subtyping]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23956315">thread link</a>) | @panic
<br/>
July 26, 2020 | https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html | <a href="https://web.archive.org/web/*/https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong><em>Note: this web article is an older version of a paper which has now been published as an ICFP Pearl. You can find a preprint of that paper <a href="https://lptk.github.io/simple-sub-paper">here</a>.</em></strong></p> <p><strong><em>It’s probably better to read the paper rather than this post, as the paper contains more material, is more up to date, and is better explained!</em></strong></p> <p><strong>Algebraic subtyping</strong> is a new approach to global type inference in the presence of subtyping. It extends traditional Hindley-Milner type inference while preserving the principal type property — that is, it can always infer <em>the</em> most general type for any given expression. This approach was developed by <a href="http://stedolan.net/about/">Stephen Dolan</a> as part of his PhD thesis, along with Alan Mycroft.</p> <p>Algebraic subtyping was implemented in <a href="https://www.cl.cam.ac.uk/~sd601/mlsub/">the <strong>MLsub</strong> type inference engine</a>. However, the design of MLsub seems significantly more complex than the simple unification algorithms used for traditional ML languages. MLsub has proven harder to grasp, even for people already familiar with compilers and type systems, such as myself.</p> <p>Dissatisfied with this state of affairs, I wanted to get to the bottom of the algebraic subtyping approach. What really is special about it, beyond the formalism? What are the simple concepts that hide behind the strange notions of <em>biunification</em> and <em>polar types</em>?</p> <p>This article is an answer to those questions. I propose an alternative algorithm for algebraic subtyping, called <strong>Simple-sub</strong>. Simple-sub can be implemented <strong>efficiently</strong> in <strong>under 500 lines of code</strong> (including parsing, simplification, and pretty-printing), and I think it is much more familiar-looking and easier to understand than MLsub.</p> <h4 id="---you-can-try-simple-sub-online-here---"><strong>⇨ ⇨ ⇨ <em><a href="https://lptk.github.io/simple-sub/">You can try Simple-sub online here!</a></em> ⇦ ⇦ ⇦</strong></h4> <p>This article is meant to be light in formalisms and easy to consume for prospective designers of new type systems and programming languages.</p> <p><a href="https://github.com/LPTK/simple-algebraic-subtyping">The complete source code of Simple-sub is available on Github.</a></p>   <h2 id="summary">Summary</h2> <ol> <li> <p><strong><a href="#intro">Introduction</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-mlsub">Algebraic Subtyping in MLsub</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-simple-sub">Algebraic Subtyping in Simple-sub</a></strong></p> </li> <li> <p><strong><a href="#simplifying-types">Simplifying Types</a></strong></p> </li> <li> <p><strong><a href="#conclusions">Conclusions</a></strong></p> </li> </ol> <hr>  <p>The ML family of languages, which encompasses Standard ML, OCaml, and Haskell, have been designed around a powerful “global” approach to type inference, rooted in the work of <a href="https://doi.org/10.2307%2F1995158">Hindley</a> and <a href="https://doi.org/10.1016%2F0022-0000%2878%2990014-4">Milner</a>, later closely formalized by <a href="https://dl.acm.org/doi/10.1145/582153.582176">Damas</a>. In this approach, the type system is designed to be simple enough that types can be unambiguously inferred from terms without the help of any type annotations. That is, for any unannotated term, it is always possible to infer a <em>principal type</em> which subsumes all other types that can be assigned to this term. For instance, the term $\lambda{x}. {x}$ can be assigned types $\mathsf{bool} \to \mathsf{bool}$ and $\mathsf{int} \to \mathsf{int}$, but both of these are subsumed by the polymorphic type $\forall a.\ a \to a$, also written <code>'a -&gt; 'a</code>, which is the principal type of this term.</p> <p><strong><em>Hindley-Milner</em></strong> (HM) type inference contrasts with more restricted “local” approaches to type inference, found in languages like Scala and C#, which often require the types of variables to be annotated explicitly by programmers. On the flip side, abandoning the principal type property allows these type systems to be more expressive and to support features such as object orientation and first-class polymorphism. Note that in practice, even ML languages like OCaml and Haskell have adopted expressive type system features which, when used, break the principal type property.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p> <p><strong><em>Subtyping</em></strong> is an expressive feature allowing types to be structured into hierarchies (usually a subtyping <a href="https://en.wikipedia.org/wiki/Lattice_(order)"><em>lattice</em></a>) with the property that types can be <em>refined</em> or <em>widened</em> transparently following this hierarchy. This lets us express the fact that some types are more precise (contain more information) than others, but still have a compatible runtime representation, so that no coercions between them are needed. For instance, in a system where the type <code>nat</code> is a subtype of <code>int</code>, one can transparently use a <code>nat list</code> in place where an <code>int list</code> is expected, without having to apply a coercion function on all the elements of the list. Subtyping can be emulated using somewhat heavy type system machinery (which both OCaml and Haskell occasionally do<sup id="fnref:2"><a href="#fn:2">2</a></sup>), but first-class support for subtyping gives the benefit of simpler type signatures and better type inference.</p> <p>For a long time, it was widely believed that pervasive implicit subtyping got in the way of satisfactory global type inference. Indeed, previous approaches to inferring subtypes failed to support principal types or resulted in the inference of large, unwieldy typing schemes which included sets of complex constraints, making their understanding by programmers difficult.</p> <p><strong><em>Algebraic subtyping</em></strong> was introduced by Dolan and Mycroft as an ML-style type system supporting subtyping and global type inference, while producing compact principal types. Here, <em>compact</em> refers to the fact that the inferred types are relatively simple type expressions without any visible constraints, making them easy to understand by programmer. This was achieved by carefully designing the syntax and semantics of the underlying subtyping lattice, allowing for simplifying assumptions in to be made the constraint resolution process of the type inference algorithm.</p> <p>However, <em>biunification</em>, the algorithm proposed by Dolan in order to implement algebraic subtyping, has been quite difficult to understand for many experts and non-experts alike. Indeed, on the surface it looks quite different from the usual <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Algorithm_J"><em>Algorithm J</em></a> traditionally used for Hm type systems: it requires several additional concepts, such as bisubstitution and polar types, making it look more complicated.</p> <p>Thankfully, it turns out that algebraic subtyping admits a type inference algorithm, which I called <em>Simple-sub</em>, that is very similar to the familiar Algorithm J, and also much more efficient than biunification (or at least, than the basic syntax-driven form of biunification.<sup id="fnref:3"><a href="#fn:3">3</a></sup> In this article, I show that inferring algebraic subtypes is actually extremely easy, and can be done in under 300 lines of Scala code. Most of the complexity actually comes from simplifying the inferred type representations, which we will get to later.</p> <p>While the implementation we present is written in Scala, it is straightforward to translate into any other functional programming language.</p> <p><strong><em>The goal of this article</em></strong> is to recast algebraic subtyping into a simpler mold, allowing more prospective designers of type systems and programming languages to benefit from the great insights that this approach offers.</p> <hr>  <p>Let’s start by briefly reviewing what algebraic subtyping and MLsub are and what they are not, and by trying to assess their expressiveness.</p> <h2 id="term-language">Term Language</h2> <p>The term syntax of MLsub is given below. I have omitted boolean literals and if-then-else, as they can easily be typed as primitive combinators. I also used only one form of variables $x$, which will be sufficient for our use (Dolan’s MLsub formalism distinguishes lambda-bound variables from let-bound variables for technical reasons).</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>variable</td> <td>$x$</td> <td><code>x</code></td> </tr> <tr> <td>lambda</td> <td>$\lambda{x}. {e}$</td> <td><code>fun x -&gt; e</code></td> </tr> <tr> <td>application</td> <td>$e\ e$</td> <td><code>e e</code></td> </tr> <tr> <td>record creation</td> <td>$\{\ l_0 = e \,;\; … \,;\; l_n = e\ \}$</td> <td><code>{ l_0 = e; ...; l_n = e }</code></td> </tr> <tr> <td>field selection</td> <td>$e.l$</td> <td><code>e.l</code></td> </tr> <tr> <td>let bindings</td> <td>$\mathsf{let}\ x = e\ \mathsf{in}\ e$</td> <td><code>let x = e in e</code></td> </tr> </tbody> </table> <h2 id="type-language">Type Language</h2> <p>The type syntax of MLsub, summarized below, consists in booleans, function types, record types, type variables, top $\top$ (the type of all values — supertype of all types), bottom $\bot$ (the type of no values — subtype of all types), type union $\sqcup$, type intersection $\sqcap$, and recursive types $\mu{\alpha}. {\tau}$.</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>primitives</td> <td>$\mathsf{bool}$, $\mathsf{int}$, …</td> <td><code>bool</code>, <code>int</code>, …</td> </tr> <tr> <td>function</td> <td>$\tau \to \tau$</td> <td><code>t -&gt; t</code></td> </tr> <tr> <td>record</td> <td>$\set{\ l_0: \tau \,,\; … \,,\; l_n: \tau\ }$</td> <td><code>{ l_0: t, ..., t_n: t }</code></td> </tr> <tr> <td>variable</td> <td>$\alpha $</td> <td><code>'a</code></td> </tr> <tr> <td>top</td> <td>$\top$</td> <td><code>⊤</code></td> </tr> <tr> <td>bottom</td> <td>$\bot$</td> <td><code>⊥</code></td> </tr> <tr> <td>union</td> <td>$\tau \sqcup \tau$</td> <td><code>∨</code></td> </tr> <tr> <td>intersection</td> <td>$\tau \sqcap \tau$</td> <td><code>∧</code></td> </tr> <tr> <td>recursive</td> <td>$\mu\alpha. \tau$</td> <td><code>t as 'a</code></td> </tr> </tbody> </table> <h2 id="informal-semantics-of-types">Informal Semantics of Types</h2> <p>While most MLsub type forms are usual and unsurprising, two kinds of types require our special attention: set-theoretic types (more specifically union and intersection types), and recursive types.</p> <h3 id="set-theoretic-types">Set-Theoretic Types</h3> <p>To a first approximation, union and intersection types can be understood in set-theoretic terms: the type term $\tau_0 \sqcup \tau_1$ (resp. $\tau_0 \sqcap \tau_1$) represents the type of values that are <em>either</em> (resp. <em>both</em>) of type $\tau_0 $ <em>or</em> (resp. <em>and</em>) of type $\tau_1$.</p> <p>MLsub uses these types to indirectly constrain inferred type variables; for instance, one type inferred for term $\lambda{x}. {\set{l = x - 1 \,;\; r = x}}$ could be $\alpha \sqcap \mathsf{int} \to \set{l: \mathsf{int} \,,\; r: \alpha}$. This type reflects the fact that the original argument, of type $\alpha$, is returned in the $r$ field of the result record, as the input type $\alpha$ ends up in that position, but also that this argument should be able to be treated as an $\mathsf{int}$, expressed via the type intersection $\alpha \sqcap \mathsf{int}$ on the left-hand side of the function type. Keeping track of the precise argument type $\alpha$ is important: it could be later substituted with a more specific type than $\mathsf{int}$, such as $\alpha = \mathsf{nat}$, which would give us $\mathsf{nat} \to \set{l: \mathsf{int} \,;\; r: \mathsf{nat}}$.</p> <p>On the other hand, there may be type signatures where some $\alpha$ becomes undistinguishable from $\mathsf{int}$. For instance, consider the term $\lambda{x}. {\mathsf{if}\ \mathsf{true}\ \mathsf{then}\ {x - 1}\ \mathsf{else}\ {x}}$, whose simplified inferred type would be just $\mathsf{int} \to \mathsf{int}$, as the seemingly-more precise type $\alpha \sqcap \mathsf{int} \to \alpha \sqcup \mathsf{int}$ does not actually contain more information (see the MLsub paper for details).</p> <p>The beauty of algebraic subtyping is that this sort of reasoning scales to arbitrary flows of variables and higher-order functions; for instance, the previous example can be generalized by passing in a function $f$ to stand for the $\cdot - 1$ operation, as in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</a></em></p>]]>
            </description>
            <link>https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956315</guid>
            <pubDate>Sun, 26 Jul 2020 11:38:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to effectively evade the GDPR and the reach of the DPA]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 186 (<a href="https://news.ycombinator.com/item?id=23955596">thread link</a>) | @thierryzoller
<br/>
July 26, 2020 | https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html | <a href="https://web.archive.org/web/*/https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is a post in a series of posts :</p>
<br>
<div><p>
As my regular readers know I reluctantly trust anything that isn't tested and battle proof. In the last 2 years, I applied the same logic that I apply to vulnerability research to the Data Privacy environment and proceeded to test a broad range of Data Subject Rights. Expect a few disclosures following this one.</p><p>

In true Information Security Fashion (insiders will understand) have attributed this weakness the ID :</p><ul>
<li><b>CDPWE-0001 - Does not designate a Representative in the European Union</b></li>
</ul>
<h3>
Introduction</h3>
<br></div>
<p>
When I searched Google for my name an interesting website came up in the results. A company called "Rocket Reach" allowed others to buy access to my personal data. I was intrigued as I have never given any consent for Rocketreach to store (or even sell) my data and I saw no other legal basis for RocketReach processing of my data.</p>
<div>

<p>
"Rocket Reach" a data broker that describes it's service as :</p>
<blockquote>
<p>
"Connect directly with the right decision makers, using the world's largest and most accurate database of emails and direct dials.&nbsp;Real-time verified data for 430 million professionals across 17 million companies, worldwide.Trusted by over 5.0 million users — powering sales, recruiting, and marketing at companies large and small.</p>
<p>
Prospect, connect and converse with your leads at scale."</p>
</blockquote>
</div>
<p>



<h3>
Issuing a DSAR</h3>
</p>
<p>
On the <b>5th of April&nbsp; 2019</b>, I asked Rocketreach access to my personal data (Data Subject Access Request) and asked for the purpose and the legal basis of processing. Instead of giving me access to my data and reply adequately, RocketReach decided to <b>delete/remove all traces of it </b>and informed me that it did so the same day.</p>

<p>
While it might be surprising to some, this is actually a common reaction to DSARs when the Data Controller realizes the data they have may have no real legal basis.</p>
<br>
<h3>
Filing a complaint&nbsp;</h3>
<p>
On the <b>05th of April 2019</b>, I filed a complaint with the Luxemburgish Data Protection Agency (CNPD). The reference for this complaint is #3018 (For those that want to request information/documents from the CNPD).</p>

<h3>
Waiting for roughly a year</h3>
<br>
<h3>
"We agree with you but we can't do anything, sorry, move on"</h3>
<p>
On the <b>6th of March 2020</b>&nbsp;(<span>1 year!</span>) the CNPD responded as follows (Original Version on top, the Translated version at the bottom).</p>
<br>
<blockquote>
<p><span lang="FR">Monsieur Zoller,<o:p></o:p></span></p>
<p><span lang="FR">La
 Commission nationale pour la protection des données (CNPD) se permet de
 revenir vers vous concernant votre réclamation du 5 avril 2019 à 
l’encontre de la société RocketReach.<o:p></o:p></span></p>
<p><span lang="FR">Dans le cadre de l’instruction de votre réclamation, la 
société RocketReach nous a communiqué qu’elle considère que ce sont les 
utilisateurs de ses services, et non elle-même, qui sont les 
responsables du traitement pour ce qui concerne les
 données à caractère personnel traitées sur son site internet. <o:p></o:p></span></p>
<p><span lang="FR">Par ailleurs, il ressort également de cette instruction 
que la société RocketReach est une société située aux Etats-Unis 
d’Amérique <b>ne disposant pas d’un représentant dans l’Union au sens de 
l’article 27 du règlement général sur la protection
 des données (RGPD). </b><o:p></o:p></span></p>
<p><span lang="FR">Au sujet des responsables du traitement établis dans des
 pays tiers, comme les Etats-Unis d’Amérique, nous souhaitons attirer 
votre attention sur le considérant (116) du RGPD qui précise que:</span></p>
<p>
«&nbsp;<i>Lorsque
 des données à caractère personnel franchissent
 les frontières extérieures de l'Union, cela peut accroître le risque 
que les personnes physiques ne puissent exercer leurs droits liés à la 
protection des données, notamment pour se protéger de l'utilisation ou 
de la divulgation illicite de ces informations.
 De même, les autorités de contrôle peuvent être confrontées à 
l'impossibilité d'examiner des réclamations ou de mener des enquêtes sur
 les activités exercées en dehors de leurs frontières. Leurs efforts 
pour collaborer dans le contexte transfrontalier peuvent
 également être freinés par les pouvoirs insuffisants dont elles 
disposent en matière de prévention ou de recours, par l'hétérogénéité 
des régimes juridiques et par des obstacles pratiques tels que le manque
 de ressources.&nbsp;»</i></p>
<p><span lang="FR">Dans le cas de votre réclamation cela signifie que, <b>bien
 que nous ne partagions pas le point de vue de RocketReach et que nous 
sommes au contraire d’avis que cette société est bien à considérer comme
 responsable du traitement pour les traitements
 de données à caractère personnel effectués sur son site internet, il 
nous est impossible de poursuivre plus en avant le traitement de votre 
réclamation</b>. En effet, nous ne disposons pas des pouvoirs de mener des 
enquêtes et de faire appliquer les décisions
 que nous serions amenés à prendre sur le territoire des Etats-Unis 
d’Amérique.<o:p></o:p></span></p>
<p><span lang="FR">Nous sommes dès lors au regret de vous informer que nous
 considérons qu’il nous est impossible de poursuivre de façon effective 
le traitement de votre dossier.&nbsp;
<o:p></o:p></span></p>
<p><span lang="FR">Veuillez agréer, Monsieur Zoller, l’expression de nos sentiments distingués.<o:p></o:p></span></p>

</blockquote>
<blockquote><b>English Translation</b><p>
Mr. Zoller, </p><p>The National Commission for Data Protection (CNPD) would like to get back to you regarding your complaint of 5 April 2019 against the company RocketReach. </p><p>Rocket Reach has informed us that <b>it considers that it is the users of its services, and not itself, who are responsible for processing personal data processed on its website</b>.  Furthermore, it also emerges from this instruction that RocketReach is a company located in the United States of America that does not have a representative in the Union within the meaning of Article 27 of the General Regulation on Data Protection (RGPD).&nbsp;</p> <p>As regards data controllers established in third countries, such as the United States of America, we would like to draw your attention to recital (116) of the DPMR which states that: 'When personal data crosses the external borders of the Union, this may increase the risk that individuals may not be able to exercise their data protection rights, in particular to protect themselves against unlawful use or disclosure of such information.</p><p>Similarly, supervisory authorities may be faced with the impossibility to investigate complaints or activities outside their borders. Their efforts to work together in the cross-border context may also be hampered by insufficient preventive or remedial powers, heterogeneous legal regimes and practical obstacles such as lack of resources. »&nbsp;</p> <p>In the case of your complaint, this means that, although <b>we do not share RocketReach's view and to the contrary believe <span>that RocketReach is the data controller</span> </b>for the processing of personal data on its website, <b>we are unable to take any further action in relation to your complaint.</b> We do not have the authority to investigate and enforce any decision we would have to take in the United States of America.&nbsp;</p> <p><b>We regret to inform you that we consider it impossible for us to proceed with the processing of your case.</b></p></blockquote>
<div><p>In Summary -&nbsp; Rocketreach has <b>not met the requirement</b> of the GDPR to name an EU representative (Art27) to account for the processing of European Personal Data. <b>In their answer, the CNPD makes it sound like it is optional, it isn't.</b> Instead of pursuing Rocketreach locally on that basis alone, the CNPD just gives up arguing it has no jurisdiction in the US.</p></div>

<p><span>In other words, just don't designate a representative in Europe, build your business model around the exploitation of data from millions of European data subjects and you are fine?</span></p>

<p>
I&nbsp; am fully aware that I could engage in legal procedures myself.&nbsp; That's not in my interest (in this case). The overall question you should ask is: Do we need a European Institution that handles extra-territorial investigations and fines? <b>Why should it take the time, money, and energy from an individual when the DPA is supposed to defend the rights of the data subjects</b>?</p>
<p>
What the CNPD could have done according to [1]</p><ul>
<li><span><span>to impose a temporary or definitive limitation including a ban on processing;</span></span></li>
<li><span><span>to order the suspension of data flows to a recipient in a third country or to an international organisation.</span></span></li>
<li><span><span>to impose an administrative fine pursuant to Article 83, in addition to, or instead of measures referred to in this paragraph, depending on the circumstances of each individual case;</span></span></li>
<li><span><span>to order the controller or processor to bring processing operations into compliance with the provisions of this Regulation, where appropriate, in a specified manner and within a specified period;</span></span></li>
</ul>
<p>
[1]&nbsp;<a href="https://cnpd.public.lu/en/commission-nationale/pouvoirs.html">https://cnpd.public.lu/en/commission-nationale/pouvoirs.html</a></p><p>
Instead, Rocketreach just continues to sell the personal data of millions of European data subjects like nothing ever happened. Including all of the below :</p><p><a href="https://1.bp.blogspot.com/-z6piNinfp7c/Xs-0S2Xm-rI/AAAAAAAAA0Q/1YXUi3ANINEUhF9UJebPzPAUW8Oa2U80QCLcBGAsYHQ/s1600/trophy1.PNG"><img data-original-height="886" data-original-width="1542" height="227" src="https://1.bp.blogspot.com/-z6piNinfp7c/Xs-0S2Xm-rI/AAAAAAAAA0Q/1YXUi3ANINEUhF9UJebPzPAUW8Oa2U80QCLcBGAsYHQ/s400/trophy1.PNG" width="400"></a></p>
<p><span>
Members of the CNPD</span></p>

<p><a href="https://1.bp.blogspot.com/-KTvsmbvPPwA/Xs-0sPl_y5I/AAAAAAAAA0Y/3XeiS_j0L6EOxtVkLI2ajjTlyDiKADDIwCLcBGAsYHQ/s1600/trophy2.PNG"><img data-original-height="798" data-original-width="1521" height="208" src="https://1.bp.blogspot.com/-KTvsmbvPPwA/Xs-0sPl_y5I/AAAAAAAAA0Y/3XeiS_j0L6EOxtVkLI2ajjTlyDiKADDIwCLcBGAsYHQ/s400/trophy2.PNG" width="400"></a></p>
<p><span>
Members of the European Data Protection Board</span></p>

<p><a href="https://1.bp.blogspot.com/-LeEhjvJtgmk/Xs-1KUiVvjI/AAAAAAAAA0g/4pXoPjpjssceaGi6UJAOna8guxKQam1EACLcBGAsYHQ/s1600/trophy3.PNG"><img data-original-height="690" data-original-width="1534" height="178" src="https://1.bp.blogspot.com/-LeEhjvJtgmk/Xs-1KUiVvjI/AAAAAAAAA0g/4pXoPjpjssceaGi6UJAOna8guxKQam1EACLcBGAsYHQ/s400/trophy3.PNG" width="400"></a></p>

<p><span>
CNIL</span></p>






</div></div>]]>
            </description>
            <link>https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955596</guid>
            <pubDate>Sun, 26 Jul 2020 09:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebGL Fluid Simulation]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23955527">thread link</a>) | @maxraz
<br/>
July 26, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955527</guid>
            <pubDate>Sun, 26 Jul 2020 08:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Montreal is taxing churches (2017)]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 295 (<a href="https://news.ycombinator.com/item?id=23954846">thread link</a>) | @seesawtron
<br/>
July 25, 2020 | https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
	Churches in Montreal are becoming concerned about hosting community groups after being hit with bills for municipal taxes.</p>
<p>
	Joel Coppetiers, the Minister at the Cote des Neiges Presbyterian church, was shocked when his institution first received a municipal tax bill in early 2015.</p>
<p>
	It was "the first indication that something had changed," said Coppetiers.</p>
<p>
	Provincial law exempts churches and manses from paying municipal taxes but Coppetiers was told that if a manse is vacant for several months between ministers, it's taxable.</p>
<p>
	Following that, city officials arrived for an inspection of every room in the church and how they were used.</p>
<p>
	"The indication is there's not an exemption for the church as a whole, there's only an exemption for those areas used for public worship and things directly related to it," said Coppetiers.</p>
<p>
	As a result, many churches in Montreal that host community groups, such as food banks, or Girl Guides or Boy Scouts, are facing mounting tax bills.</p>
<p>
	Coppetiers says the city has changed how it interprets the law.</p>
<p>
	"We're there to care and serve the community and this is part of it," said Coppetiers.</p>
<p>
	Coppetiers says taxes are due even when services are suspended for renovations.</p>
<p>
	The amount owed in taxes can increase swiftly if a church closes its doors.</p>
<p>
	When <a href="http://montreal.ctvnews.ca/trinity-memorial-church-in-ndg-closes-its-doors-1.3302321">Trinity Memorial Church in NDG </a>closed earlier this year, the city started enacting taxes immediately following the last service.</p>
<p>
	As a result churches feel pressured to sell swiftly, with Trinity Memorial being sold to Stanford Properties Group within two months.</p>
<p>
	The issue of places of worship owing taxes and fighting the city's exemptions office came as a surprise to city politicians, including Councillor Peter McQueen.</p>
<p>
	"Already our churches are in danger, they're having a number of financial problems and this is a further low blow," said McQueen.</p>
<p>
	The NDG councillor said his party, Projet Montreal, will study the exemption issue, but he said Montreal's Executive Committee needs to step up.</p>
<p>
	"If we don't do something you're going to see churches closed, churches possibly torn down, heaven forbid, certainly converted away from community use," said McQueen.</p>
<p>
	Meanwhile churches across the island are praying that the city will cease surprising them with taxes they can't afford.</p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954846</guid>
            <pubDate>Sun, 26 Jul 2020 06:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running DOS Apps on Windows]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 47 (<a href="https://news.ycombinator.com/item?id=23954234">thread link</a>) | @bluedino
<br/>
July 25, 2020 | https://gekk.info/articles/dosapps.html | <a href="https://web.archive.org/web/*/https://gekk.info/articles/dosapps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tr><td>
	<div>
	<p>It's worth discussing <em>how</em> all this works so you understand the 
	challenges that are being overcome here. The ability to run multiple DOS 
	programs at once is a pretty neat trick, given that this software heralds 
	from an era of computing that was <em>just barely</em> ahead of what the 
	Apple ][ was doing in 1978. If you want to skip this, <a href="#Windows_1.0">go ahead</a>.</p>
	<p>The root of the problem is that the IBM PCs basic architecture 
	crystallized a very long time ago, in 1981. In a world where ten kilobytes of RAM counted for 
	about what a gig does now, there was not a lot of room for "overhead" and 
	the idea that you would run two programs simultaneously was generally 
	unrealistic except at the high end of the computing world, which most PC 
	buyers were nowhere near. You needed every bit (<em>ha</em>) of memory you could get, and when 
	memory became more affordable a few years later, it was too late 
	to change anything.</p>
	<p>After just a couple years on the market, MS-DOS had become the 
	unquestioned OS of choice for the PC<a href="#footnote1">*</a> 
	and developed a monumental stable of software, every bit of which<em> </em>
	was essential to someone, somewhere, and could not be easily replaced. Thus 
	began one of the longest tails in technology history, as the PC industry and 
	Microsoft began contorting themselves to try not to 
	break compatibility with old software while still moving forward with advanced 
	functionality.<br>
	<sub><a name="footnote1">*</a>(specifically, since there were MS-DOSes for 
	other architectures, and other OSes for the PC)</sub></p>
	<p>Because DOS was developed under constraints very similar to those 
	in the 
	late '70s that gave us the "bitty boxes" (C64, Apple ][, ZX 
	Spectrum, etc.) it was not built with any kind of "supervision" in mind. In 
	other words, there was no abstraction level above the current running program. 
	DOS was more like a set of tools than what we think 
	of as an operating system now - specifically, it had no "process management"; no concept of "processes" at all, in fact.</p>
	<h2><strong>DOS</strong></h2>
	<p>When the machine booted, the part of DOS that was considered "the OS" - 
	the code for accessing disk drives, writing text to screen, etc. - was copied 
	into memory, and then execution was handed off to the command interpreter, COMMAND.COM, 
	which was an application like any other, at which point you could begin 
	entering commands to use the computer.</p>
		<p>At this point, DOS was no longer "running" in 
	any meaningful way. The code was "resident," meaning it was present in the 
		computer's memory, but 
	the processor wasn't&nbsp; executing any of it. Instead, the CPU was busy executing 
	whatever the current program was - if you were at the command prompt, then 
		all the code the PC was executing was part of COMMAND.COM. When you launched another application, COMMAND.COM was 
	vacated and replaced by that other application.</p>
	<p>In other words, while an application was running, DOS was almost totally out of 
	the picture. The only time execution returned to DOS itself was when the 
	application requested a "service" from DOS, like accessing a disk drive, at 
	which point it would tell the CPU to go execute one of DOS' stored routines 
	for this, and when that routine was done, control would return to the 
	application. This meant that,<em> generally speaking</em>,<em> </em>the current 
	program 
	had absolute control of the PCs execution and it's memory. It could in fact choose to 
	overwrite DOS itself, obliterating it out of memory, and DOS couldn't do a damn thing about it.</p>
	<p>The currently running app also had the option to speak directly to hardware. 
	The 
	whole purpose of DOS was to abstract things like that so programs wouldn't 
	need to know the details of the system they were running on, but since the 
	IBM PC was <em>extremely</em> consistent hardware-wise in its early 
	incarnations, it was entirely 
	optional for developers to take advantage of that, and often 
	there were reasons - of performance, perhaps - to bypass DOS and do things 
	directly.</p>
		<p>DOS provided disk access routines, 
	but the app could blow right by them and shoot commands straight to the 
	floppy drive if it wanted. DOS provided routines for printing text and clearing the 
	screen, but the app could just write directly to video memory. I can't speak to how common this kind of behavior actually was, but it 
	certainly wasn't rare, and it speaks to a larger problem - DOS apps simply 
	expect total control over the system.</p>
		<p>If you run two DOS apps at once, they're 
	going to stomp on each other, because each one thinks it's in charge of the 
		whole machine. The first one would store data in the same spot that the 
		second one stored program code, and thus one would overwrite the other 
		and crash it. So DOS was a single-tasking operating system - you could 
		run one program at a time, and when you wanted to run another, you had 
		to exit, return to the command prompt, and then launch your other app.</p>
		<p>Consequently, if you were working on something 
	in Microsoft Multiplan and wanted to go look up some data in dBase, you had to quit completely 
	out of Multiplan and then start dBase, which would take over the system and totally 
	overwrite the previous app. To get back to where you were you'd have to exit 
		dBase, restart Multiplan, load your document and find your place again - 
		in the process, totally forgetting what you were there to do in the 
		first place, because it's so many steps and takes so long.</p>
	<p>Right from the get-go, PC users wanted to be able to look at one program, then rapidly 
	switch to another. On its face this seems to mean "run two programs at once," 
	which is what we do now, but that's not quite the full story. Let's touch on how 
	that works nowadays, however.</p>
	<h2><strong>Multiprocessing</strong></h2>
	<p>To be clear, you <em>cannot</em> run two programs "at once" on a 
	computer. Some would call this semantics, but it's important in a very real 
	way, <em>especially</em> when talking about 80s-era PCs.</p>
		<p>Modern multicore CPUs get very close to true parallel processing by 
		letting separate programs run on separate cores, but of course, nobody has a CPU so big 
	that they have one core per process. And even if you did, programs still 
		have to share other 
	resources - the system bus, hard drives, and so on. Access to these 
	resources has to be carefully managed so that only one application can use 
		them at a time, and each one has to be cleaned up after before another 
		one can use the same resources. Otherwise, one program could leave the 
		hardware in a state where the commands that the next program sends put 
		it in an unusable state and crash the machine, or corrupt data.</p>
	<p>Even with all our modern pipelined cleverness, you have the 
	fundamental problem that a CPU, and a computer in general, has a limited 
	amount of physical hardware and can't dedicate some to each individual 
	program that's running. When you have more processes running than you have silicon, the only option left is to share 
	resources by dividing up the amount of time that each process gets to use the hardware 
	- this is one of the oldest concepts in computing, and goes back to the late '50s.</p>
	<p>The fundamentals of this process are simple: At 
	any given moment, one program has near-total control of the entire 
	system, to execute its code and use all the resources, and then after it 
	executes for a bit, it goes into a paused state and control is handed off to 
	the next program, which does its work and then hands off to the next. This 
	continues in a round-robin fashion, so that every program gets to use the 
	hardware for a certain portion of every second.</p>
	<p>Modern implementations take this to a fever pitch with all the complex 
	machinations used to make this process efficient, but the fundamentals have 
	never changed; this is how your PC is operating right now.</p>
	<p>One big hurdle to overcome in implementing this is that programs don't just execute 
	instructions in a vacuum. As code is executed, there are side 
	effects. Some are values internal to the CPU, like the&nbsp; status of CPU registers and the current 
	position of the instruction pointer. This is called "CPU state," amd is specific to 
	each running program. When you switch from one program to another, you have to 
	save that information - called "context switching" - and restore it when you 
	come back. Storing this info takes extra time and memory.</p>
		<p>Another hurdle is the state of other hardware. If two programs are 
		talking to the hard drive, you can't let them both just blindly issue 
		commands every time they get control of the CPU. The first process might 
		start a data read that the second process interrupts with a data write, 
		confusing the hard drive controller. So when switching from one process 
		to another, you also have to save the state of these other hardware 
		resources - and possibly even delay switching tasks until those hardware 
		requests are complete.</p>
	<p>If you have enough RAM to store this state, and if your apps don't need too many cycles per second to appear responsive, you can do all this and the user 
	will feel like they're "running multiple programs at 
	once."</p>
	<p>Now, in business applications - the 
	driving force behind the first couple decades of computing - actual 
	"multiprocessing" of this type is not as important as simple usability - users 
	just don't want to have to close one program in order to open another, as they 
	did throughout the DOS days. That, ultimately, is the goal: it 
	doesn't matter if the computer is perfectly speedy, or if programs can run 
	simultaneously, it just matters that 
	users not have to lose all their work in one program simply in order to look 
	at another.</p>
	<h2>Multitasking</h2>
	<p>This desire was of course tremendous right from the start of computing. Who wants to 
	be stuck in one program at a time? So, almost from the 
	earliest days of the IBM PC, software was created to enable task switching 
	with various degrees of success.</p>
		<h3>Early Attempts</h3>
		<p><a data-lity="" href="https://gekk.info/articles/images/doswin/dos4_taskswitch.png">
		<img alt="Multitasking DOS 4" height="177" src="https://gekk.info/articles/images/doswin/dos4_taskswitch_small.png" width="320"><!-- MSComment="autothumbnail" xthumbnail-orig-image="file:///C:/Users/dthom/Documents/My Web Sites/images/doswin/dos4_taskswitch.png" --></a></p>
	<p>Microsoft actually released a version of DOS with true multitasking 
	support, but it …</p></div></td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gekk.info/articles/dosapps.html">https://gekk.info/articles/dosapps.html</a></em></p>]]>
            </description>
            <link>https://gekk.info/articles/dosapps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954234</guid>
            <pubDate>Sun, 26 Jul 2020 03:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[D3js Tree of Wittgenstein's Tractatus]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23953857">thread link</a>) | @motohagiography
<br/>
July 25, 2020 | https://pbellon.github.io/tractatus-tree/#/ | <a href="https://web.archive.org/web/*/https://pbellon.github.io/tractatus-tree/#/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pbellon.github.io/tractatus-tree/#/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23953857</guid>
            <pubDate>Sun, 26 Jul 2020 02:07:18 GMT</pubDate>
        </item>
    </channel>
</rss>
