<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 23 Feb 2021 01:07:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 23 Feb 2021 01:07:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Modern software controls dependencies because it helps software authors]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26210576">thread link</a>) | @todsacerdoti
<br/>
February 20, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Modern software controls dependencies because it helps software authors</h2>

	<p><small>February 20, 2021</small></p>
</div><div><p>Over on Twitter <a href="https://twitter.com/thatcks/status/1363196953065099265">I had a hot take</a>:</p>

<blockquote><p>Hot take: Every distribution packager who's saying "you shouldn't
bundle dependencies" is implicitly telling software authors "you
should do more work for us and limit the features (and reliability) of
your software".</p>
</blockquote>

<p>(This was sparked by reading <a href="https://blogs.gentoo.org/mgorny/2021/02/19/the-modern-packagers-security-nightmare/">The modern packager√¢‚Ç¨‚Ñ¢s security
nightmare</a>,
<a href="https://lobste.rs/s/zb1c4k/modern_packager_s_security_nightmare">via</a>.
I'm not exactly on one side or the other, but <a href="https://twitter.com/thatcks/status/1363263921960980485">I do think distributions
should be honest about what they're asking for</a> and I
don't think they're going to get it.)</p>

<p>This hot take is a bit too narrow. What really matters is software
authors and modern software systems restricting the versions of
dependencies (for both maximum and minimum versions). Explicit or
implicit bundling on top of that just makes the problem slightly worse
for distributions.</p>

<p>For software authors, restricting the versions of dependencies that
they work with reduces the amount of work that they have to do,
both to test against a range of versions and to either forever chase
after whatever changes those dependencies like to make or to forever
limit what features of dependencies they use to ones available in
old versions (and sometimes both at once). In theory, both testing
and chasing after changes would be dealt with by <a href="http://semver.org/">Semantic Versioning</a> (if everyone followed it), at least for a
single program. In practice, not only are people fallible but also
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SemverHasLimits">people have a different understanding of what semantic versioning
means</a> because semantic versioning is ultimately
a social thing, not a technical one. Our field's history has shown
(sometimes vividly) that if software authors allow versions of
dependencies to move on them, soon or later things break and the
software author has to fix it.</p>

<p>(There's also the practical issue that not all dependencies even
claim or agree to follow semantic versioning in the first place.)</p>

<p>For distributors, once software authors start restricting versions
the distributor has both an upgrade problem and a distribution
problem. On the upgrade side, dealing with an issue in a program may now
require persuading it to accept a new version of a dependency. On the
distribution side, it's now likely that you'll have multiple programs
that have different version requirements for the same dependency. At the
very least this multiplies the packages involved.</p>

<p>(Many distributions also have package system design problems that
restricts the range of versions of things that they can have installed
at the same time. Even under <a href="http://semver.org/">Semantic Versioning</a>, this is a
problem for the distribution the moment that you have two programs
with conflicting version requirements that can't both be packaged and
installed at the same time.)</p>

<p>However, there's no free lunch here. What distributors want when
they ask for unbundled dependencies without version restrictions is
for software authors to do the work to accept any version of their
dependencies, or at least any version that falls within <a href="http://semver.org/">Semantic
Versioning</a>, and for dependencies to faithfully follow semver and
also make it possible to package and install different major versions
(at least) at the same time. <strong>Accepting a broad version range of your
dependencies is actual work</strong>, even apart from the limitations it may
impose on what your code and your software can do. Software authors and
the creators of software package ecosystems (like Go and Rust) are not
refusing to do this because they don't like distributions; they are
refusing to do this because they have found, over and over again, that
this doesn't really work and does cause problems for software authors
(and often users of programs) in the long run.</p>

<p>(The software community that's gone through this experience the
most visibly is Go, which started out with intrinsically unversioned
dependencies that were used universally across all your programs
by default and wound up switching to strongly versioned dependencies
after many people had many problems with that initial state. Go
experienced so many problems that <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/FallibleSemverAndMVS">they adopted an unusually strict
and software author friendly versioning scheme</a>.)</p>

<p>It's popular for people to argue that software authors should be doing
this work anyway even if the distributions weren't asking for it,
so them actually doing it is no big deal. This is quite convenient
for the people making the argument, but it doesn't make the argument
valid. Software authors don't owe anyone any work what so ever; they
do whatever work serves their needs and is interesting to them. With
limited time and interest, it's both rational and proper for software
authors to optimize for their own development.</p>

<p>PS: Generally distributions also want some combination of all software
to update to the latest version of their dependencies and for
dependencies to explicitly support older versions. This is also extra
work for software authors, especially when the distribution also wants
it to happen for older versions of programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210576</guid>
            <pubDate>Sun, 21 Feb 2021 03:36:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We live in an age of distractions, dealing with constant mental stimulus]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 93 (<a href="https://news.ycombinator.com/item?id=26207184">thread link</a>) | @iamsanteri
<br/>
February 20, 2021 | https://www.lostbookofsales.com/age-of-distractions/ | <a href="https://web.archive.org/web/*/https://www.lostbookofsales.com/age-of-distractions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.lostbookofsales.com/content/images/size/w300/2021/02/lbs-distractions-santeri-liukkonen.jpg 300w,
                            https://www.lostbookofsales.com/content/images/size/w600/2021/02/lbs-distractions-santeri-liukkonen.jpg 600w,
                            https://www.lostbookofsales.com/content/images/size/w1000/2021/02/lbs-distractions-santeri-liukkonen.jpg 1000w,
                            https://www.lostbookofsales.com/content/images/size/w2000/2021/02/lbs-distractions-santeri-liukkonen.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.lostbookofsales.com/content/images/size/w2000/2021/02/lbs-distractions-santeri-liukkonen.jpg" alt="Age of distractions">
            </figure>

            <section>
                <div>
                    <p>The book is exciting and the story is funny. In fact, I'm learning something new. So much so, that I keep writing down my ideas and shuffling their implications. And suddenly, I realize something. In the past 15-minutes, I've only managed to cover three pages and I'm already thinking about next things I'm supposed to do. Cleaning, picking-up the groceries, doing my excercises, writing a couple of lines of code, watching a movie... </p><p>Is this supposed to be my Saturday off work?</p><p>So I stop and think. When was the last moment that took longer than 10 seconds, where I didn't have an urge to check an app on my phone, see if I got new email, or impulsively do something else?</p><p>By now, where I live, it's been many months of nightly curfews and limitations on travel and social life. I consider myself a very fortunate person to have suffered a relatively small impact from the global pandemic. Nonetheless, I can't stop but think about why my mind feels so exhausted while at the same time requiring a constant stream of stimulus that results in overbearing distraction. </p><p>It was already before the pandemic that I heard my colleagues talking about "<a href="https://en.wikipedia.org/wiki/Digital_detox"><em>digital detox</em></a>" and discussing their efforts to break out of being constantly connected while trying to regain their energy and allowing for some rest. Thus, I surely know that I'm not alone with these thoughts. </p><p>Finally, after subscribing to <a href="https://amzn.to/3alEC3u">Audible</a> last summer, there only remains little time in my day when I am not stimulating my brain in one way or another. It was some sort of a panic that hit me when I realized that I am no longer able to enjoy a thing that I've always enjoyed so much, reading a great book at length. </p><p>Today I called with a good friend of mine and he said: </p><p><em>"Yeah right! It's like we must constantly be multitasking or something... Even when I get to playing a Playstation game and it starts to load, I just all the time have to unlock my phone and check what is going on..."</em></p><h2 id="to-observe-and-reflect">To observe and reflect</h2><p>I recently read <a href="https://www.lostbookofsales.com/notes/the-almanack-of-naval-ravikant-by-eric-jorgenson/amp/">a book where Naval describes</a> what meditation means for him, and I cannot help but agree with his way of putting it. </p><p>One only needs to stop and observe his thoughts in a calm state. Your mind is like a monkey in a room, misbehaving and throwing feces all over the walls. It is fascinating how you realize this while trying to focus on your breath and not let your thoughts wander. In a matter of seconds, however, you already catch yourself thinking about entirely something different. When practicing to focus your attention and letting your thoughts pass, this inner monkey seems to eventually calm down and let you achieve a little peace of mind. It is not so easy. </p><figure><img src="https://www.lostbookofsales.com/content/images/2021/02/santeri-drawing-LBS-1.jpg" alt=""><figcaption>One year into the global pandemic - SL 2020 (LBS)</figcaption></figure><p>After so many months of being limited with our social interactions, it feels like the scariest thing out there is to be left by ourselves. Especially us young people tend to handle this quite badly. Without typical distractions and mental stimulus available throughout our days, our mind starts to seek for something to occupy itself resulting in raised anxiety levels and stress. We are today forced to confront our inner selves like never before. </p><h2 id="so-what">So what?</h2><p>Billions of dollars are invested and brightest specialists are hired each year to engineer new distractions. They fight for every second of our limited attention spans, leading us further astray without us even noticing it. </p><p>When shortest breaks require distraction and only the rarest moments, such as taking a shower, offer a refuge from our electronic devices, how are we supposed to work towards our long-term goals? The type of goals that can only be achieved when managing to work in a state of sustained attention? Rarely do great things in life come in a form of neatly packaged gratification to which we are getting more and more accustomed to. </p><p>Reading reports and hearing on the radio that the general feeling and wellbeing in our societies during these challenging times is again on decline, constant distractions might truly be the enemy that stands in our way of what we ought to achieve.</p><h2 id="fighting-back">Fighting back</h2><p>At some point I read that <a href="https://qz.com/1476157/overworked-south-koreans-are-finding-solace-in-a-fake-prison/">South Koreans already pay to live in a hotel-like "prison"</a> to relieve themselves from digital devices. I'm not quite ready to go that far just yet. </p><p>Admittedly, a cottage in the middle of nowhere in Finland would be the way to go anyways.</p><figure><img src="https://www.lostbookofsales.com/content/images/2021/02/santeri-mikkeli-LBS.jpg" alt=""><figcaption>Late autumn lakeside view - Year 2016, Finland</figcaption></figure><p>Once upon a time before the pandemic I saw a colleague of mine use his phone as we were picking up lunch, and I couldn't help but ask why was the screen black and white? He told me he does it intentionally to make his handset less attractive, resulting in less tapping around. That struck me as bizarre. How odd, do we really need to resort to such approaches? </p><p>So what were some of the smaller changes I did to improve my wellbeing? </p><p>Unlike South Koreans with their voluntary confinement, or my friend with his greyscale screen, I started with some less drastic measures. These small changes proved enormously helpful. </p><p>First of all, I opened the screen-time function on my phone and looked through apps that sent me most notifications, proceeding to drastically dial them back. Today, most phones have a feature to limit the screen-time of apps, locking you out after a certain amount of time has passed. This function is plain useless for me or my friends whom I've seen to just enter their pin every single time they wanted to do something. What I did instead was that I just plain and simply uninstalled Instagram. </p><p>I had contemplated to delete it for a long time and almost did it, but instead always settled to just disable the notifications. When I finally did this however, two interesting realizations struck me. </p><p>First thing was that during the initial couple of weeks without the app I was totally surprised at how little I missed it. It literally had never provided me with anything of value, and I only used it to post an occasional update. Why didn't I uninstall it earlier? There was no feeling of missing out. Wow, this realization echoed a feeling that I had after uninstalling 9GAG many years earlier. </p><p>Second, I didn't even notice how those colorful icons on the home-screen invited me to tap on their respective apps as soon as I found myself aimlessly scrolling through my phone. I understood this in a particularly strong way after hiding another app, LinkedIn. Being an important tool for my work, all I did in addition to hiding it from the homescreen was to disable the last types of notifications I ever received from them. Lo' and behold, I now use this application significantly less and it makes a whole world of a difference. </p><p>Simple, easy and fast. Your life will be better for it, just try! Exponential returns of joy are expected if you have apps like Tiktok, Clubhouse, Snapchat, or other such platforms installed or bookmarked, that you can easily subject to the same fate and never look back.</p><p>So far, I'm mostly talking about my precious free time. But what could be some simple and small things that I could do when I'm working on my projects? </p><h2 id="focus-operate-and-enjoy-the-results">Focus, operate and enjoy the results</h2><p>I've written about doing <a href="https://www.lostbookofsales.com/why-to-do-lists-often-stink-and-how-do-the-truly-successful-people-maintain-their-productivity/">an experiment and turning myself into a productivity monster</a> back in 2017, and I've recently re-read the post and carefully re-implemented some of my learnings this year. But then again, it's not about going radical, but rather focusing on some small things that are easy to implement. </p><p>Kill the unnecessary Slack and Teams notifications now! Adjust the surprisingly good defaults that Slack provides and make sure none of them, except for the most important notifications, hit your phone after your working hours are over. </p><p>Use effective time-blocking techniques like <a href="https://alphaefficiency.com/20-minutes-pomodoro-weekly-experiment/">Pomodoro</a> for the less pleasant and repetitive, but still important tasks. This, like many other things, I've also learned from one of my colleagues using it in an effective manner.</p><p>Oh, and of course make sure to consider the following crazy important golden rule of life and the universe:<strong> </strong>don't do anything else while having a one-on-one interaction with someone. Just never do this. </p><p>I catch myself with this one sometimes and no matter how small of a signal, it can still tell something to my counterpart. Such mistakes during limited and valuable interactions in these pandemic-ridden times can eat away from our important professional relationships. When having conversations, focus on them fully and wholeheartedly. Multitask when the time is right. </p><p>Oh, and try drinking less coffee in the mornings while cutting alcohol in the evenings, but you've heard this a million times before. Additionally, to all of you who have small kids at home, I truly salute your efforts and patience getting through with this! </p><h2 id="the-most-desired-skill-of-the-future">The most desired skill of the future</h2><p>What if the most sought after and desired skill of the future will be the ability to best manage our constant distractions and maintain a sustained state of productive focus? </p><p>If we can't manage to control our whims, we won't be able to work effectively towards our long-term goals. I guess it's just that simple. </p><p>The first step is to stop and observe. </p><p>Reflection and brutal honesty with oneself while trying to understand what is happening is critical before driving corrections and adjustments into one's behavior. As our society adjusts to challenges posed by global pandemics, there is a chance for us to walk out of this stronger than before. This is a chance for us to learn more about ourselves than would've otherwise been possible, right? </p><p>I'm only trying to think about something positive in these pandemic-ridden times.</p><p>Now let's get back to work...</p><hr><p><em>Author's comment:</em></p><div><p><em>If you enjoyed this post, consider subscribing for an occasional update. Being hand-made, they'll only serve to make your life a little bit richer. Worst case, you'll be able to unsubscribe at any time </em>üòâ<em> </em></p><p><em>See you around! </em></p></div><p><em>-S</em></p>
                </div>
            </section>

                </article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lostbookofsales.com/age-of-distractions/">https://www.lostbookofsales.com/age-of-distractions/</a></em></p>]]>
            </description>
            <link>https://www.lostbookofsales.com/age-of-distractions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26207184</guid>
            <pubDate>Sat, 20 Feb 2021 19:49:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can you not be romantic about programming? (2020)]]>
            </title>
            <description>
<![CDATA[
Score 480 | Comments 328 (<a href="https://news.ycombinator.com/item?id=26206921">thread link</a>) | @joubert
<br/>
February 20, 2021 | https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>08 Sep 2020</p>

  <p>There‚Äôs <a href="https://www.youtube.com/watch?v=9rrAbLNePxU">a scene in Moneyball</a> in which Brad Pitt‚Äôs character, the
manager of the <a href="https://en.wikipedia.org/wiki/Oakland_Athletics">Oakland A‚Äôs</a>, is watching a recording of one of his
players trying so hard to run fast that he stumbles and falls. Lying on the
ground he‚Äôs angry at himself, because he doesn‚Äôt realize that right before he
started his run he hit a home run and scored the game-winning points. Watching
the scene, Pitt leans back, smiles a Brad Pitt smile and says: ‚Äúhow can you not
be romantic about baseball?‚Äù</p>

<p>There are moments in which I ask myself the same thing about programming.</p>

<p>We‚Äôre programming computers. We spend large parts of our days writing down
instructions for machines. Other parts of the day are spent making sure that we
chose the right instructions. Then we talk about those instructions: why and how
we picked the ones we picked, which ones we will consider in the future, what
those should do and why and how long it will probably take to write those down.</p>

<p>It can sound very serious and dry; a bureaucracy of computer instructions. And
yet.</p>

<p>And yet we, the ostensible bureaucrats, talk about magic as something that
exists ‚Äî&nbsp;the good <em>and</em> the bad kind. There are <a href="https://dl.acm.org/doi/book/10.5555/547625">wizards</a>. Instructions
are <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-9.html">‚Äúlike a sorcerer‚Äôs spells‚Äù</a>.</p>

<p>We don‚Äôt call them instructions, though, not when talking about what we produce
each day anyway. It‚Äôs code we write. Emotions are involved. Code, we say, can
be: neat, nice, clean, crafted, baroque, minimal, solid, defensive, hacky, <em>a
hack</em>, art, a piece of shit, the stupidest thing I‚Äôve ever read, beautiful, like
a poem.</p>

<p>Some lines of code are a riddle to anyone but their author and the name code
serves as a warning. Other times, strangely, it‚Äôs a badge of honor.</p>

<p>Fantastic amounts of code have been written, from beginning to end, by a single
person, typing away night after night after night, for years, until one day the
code is fed to a machine and, <em>abracadabra</em>, a brightly coloured <a href="https://en.wikipedia.org/wiki/RollerCoaster_Tycoon_(video_game)#Development">amusement
park</a> appears on screen. Other code has been written, re-written, torn
apart and stitched back together across time zones, country borders and decades,
not by a single person, but by hundreds or even thousands of different people.</p>

<p>This world of programming is held together by code. Millions and millions of
lines of code. Nobody knows how much there is. Some of it is more than 30 years
old, some less than a week, and chances are you used parts of both yesterday.
There are lines of code floating around on our computers that haven‚Äôt been
executed by a machine in years and probably won‚Äôt be for another lifetime.
Others are the golden threads of this world, holding it together at the seams
without no more than a dozen people knowing about it. Remove one of these and it
all comes crashing down.</p>

<p>If you haven‚Äôt been here long enough and try to guess how much there is and how
many generations are layered on top of each other ‚Äî you won‚Äôt even come close.
But stay around. After a while, more and more, you‚Äôll find yourself in moments
of awe, stunned by the size and fragility of it all; the mountains of work and
talent and creativity and foresight and intelligence and luck that went into it.
And you‚Äôll reach for the word ‚Äúmagic‚Äù because you won‚Äôt know how else to
describe it and then you lean back and smile, wondering how someone could not.</p>


</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26206921</guid>
            <pubDate>Sat, 20 Feb 2021 19:16:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New plant-based plastics can be chemically recycled with near-perfect efficiency]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 189 (<a href="https://news.ycombinator.com/item?id=26206513">thread link</a>) | @ColinWright
<br/>
February 20, 2021 | https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/ | <a href="https://web.archive.org/web/*/https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="articleBody"><p dir="ltr">  have developed two sustainable plastic alternatives to high-density polyethylene that can be chemically recycled more easily and nearly 10 times as efficiently, thanks to √¢‚Ç¨≈ìbreak points√¢‚Ç¨ÔøΩ engineered into their molecular structures.</p><p dir="ltr">Derived from plant oils, the new plastics were presented in a <a href="https://www.nature.com/articles/s41586-020-03149-9" target="_self">paper</a> published Wednesday in <em>Nature</em> as low-waste, environmentally friendly replacements to the conventional fossil fuel-based plastics that enter natural ecosystems at a rate of <a href="https://www.nationalgeographic.com/science/article/150212-ocean-debris-plastic-garbage-patches-science">millions of tons per year</a>.</p><p dir="ltr">Most recycling performed today is mechanical recycling, in which plastic is sorted and sliced into pellets that are then used to create new plastic materials. Chemical recycling, in contrast, involves breaking down the long polymer chains of plastic with heat or solvents to retrieve the material's initial monomer components.</p><p dir="ltr">One of the obstacles to developing chemical-recycling technology is also a reason why plastic is a useful material: the strong carbon-carbon bonds in its molecular structure. Polyethylene, the most common kind of plastic, requires at least 600 degrees Celsius to break those bonds to retrieve the monomers, and is chemically recycled at a rate lower than 10%.</p><p dir="ltr">√¢‚Ç¨≈ìStability of the hydrocarbon chains is rather a problem in that case,√¢‚Ç¨ÔøΩ said Stefan Mecking, the lead author of the study and the department chair of chemical materials science at the University of Konstanz in Germany. √¢‚Ç¨≈ìTo really break them down into small molecules needs high temperatures and is energy intensive, and also the yields are not that good.√¢‚Ç¨ÔøΩ</p><p dir="ltr">The plastic compounds created by Mecking and his colleagues had chemical bonds that could be more easily broken so chemically recycling them would be more effective.</p><p dir="ltr">Chemically recycling the two materials, which were forms of polyester and polycarbonate, required placing them in ethanol or methanol with a catalyst at only 120 degrees Celsius, or 150 degrees without the catalyst. The researchers then cooled and recrystallized the plastic before filtering it out. In the case of the polycarbonate, 96% of the initial material was recovered.</p><p dir="ltr">As demand in the recycling industry stalls and recyclable materials pile up in warehouses and landfills, chemical recycling has been offered as part of a solution to reduce plastic waste. The industry group American Chemistry Council has <a href="https://plastics.americanchemistry.com/what-is-advanced-recycling/">praised</a> the emerging technology for the significant role it could play in a circular economy by reducing plastic waste and repurposing it into new products.</p><p>Yet the method is not without pushback. A <a href="https://www.no-burn.org/wp-content/uploads/CR-Technical-Assessment_June-2020.pdf">2020 report</a> by the environmental organization Global Alliance for Incinerator Alternatives criticized a lack of research and reporting in current chemical-recycling technologies and said the process is energy-intensive and may emit hazardous chemicals. Chemical recycling also distracts from efforts to limit plastic production to reduce waste, the organization said.</p><p dir="ltr">In the new research, the chemists found that the recycling process worked when the plastic contained dye or fillers such as carbon fibers, both of which cause challenges in mechanical recycling. The plastics were also successfully recovered when pieces of other plastics were included in the alcohol solvent.</p><p dir="ltr">Plant oils were chosen as starting materials for synthesizing the plastics primarily because of their useful long chains. They are also more sustainably sourced than the crude oil and other fossil fuels used to produce most of the world√¢‚Ç¨‚Ñ¢s plastic material.</p><p dir="ltr">The new plastics were very similar to high-density polyethylene, the widely used plastic labeled as recycling number . Testing by the chemists found that the three materials had comparable properties such as structure, elasticity and molecular weights √¢‚Ç¨‚Äù though the polycarbonate and polyester had lower melting and crystallization points.</p><p dir="ltr">They were also better suited for 3D printing than polyethylene, and they retained their properties after recycling and reuse.</p><p dir="ltr">The one disadvantage of the new materials Mecking identified was their cost. Ethylene is the √¢‚Ç¨≈ìcheapest building block of the chemical industry,√¢‚Ç¨ÔøΩ he said, so, "Competing with conventional polyethylene at the current market and legal framework conditions is very difficult.√¢‚Ç¨ÔøΩ</p><p dir="ltr">Mecking and his colleagues are conducting ongoing research into using their new plastics for 3D printing, an initial application he said would be exciting for further developing the material and eventually scaling up its production.</p><p dir="ltr">These new plastics may also biodegrade in nature more quickly than common polymers because of their engineered break points, a line of inquiry that also interests the German chemist.</p><p dir="ltr"><em>The article, √¢‚Ç¨≈ìClosed-loop recycling of polyethylene-like materials,√¢‚Ç¨ÔøΩ was published Feb. 17 in Nature.√Ç&nbsp;</em><em>The authors of the study were Manuel , Marcel Eck, Dario Rothauer and Stefan Mecking, University of Konstanz. The lead author was Stefan Mecking.</em></p></div></div></div>]]>
            </description>
            <link>https://academictimes.com/new-plant-based-plastics-can-be-chemically-recycled-with-near-perfect-efficiency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26206513</guid>
            <pubDate>Sat, 20 Feb 2021 18:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Swift achieved dynamic linking where Rust couldn't (2019)]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26205969">thread link</a>) | @zdw
<br/>
February 20, 2021 | https://gankra.github.io/blah/swift-abi/ | <a href="https://web.archive.org/web/*/https://gankra.github.io/blah/swift-abi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


    <header>
    
    <p>November 7th, 2019</p>
</header>
    <nav id="TOC"><ul>
<li><a href="#background">1 Background</a><ul>
<li><a href="#swift-tldr">1.1 Swift TLDR</a><ul></ul></li>
<li><a href="#what-is-abi-stability-and-dynamic-linking">1.2 What Is ABI Stability and Dynamic Linking</a><ul></ul></li>
<li><a href="#swifts-stable-abi">1.3 Swift's Stable ABI</a><ul></ul></li>
<li><a href="#resilience-and-library-evolution">1.4 Resilience and Library Evolution</a><ul></ul></li></ul></li>
<li><a href="#details">2 Details</a><ul>
<li><a href="#resilient-type-layout">2.1 Resilient Type Layout</a><ul></ul></li>
<li><a href="#polymorphic-generics">2.2 Polymorphic Generics</a><ul></ul></li>
<li><a href="#reabstraction">2.3 Reabstraction</a><ul></ul></li>
<li><a href="#materialization">2.4 Materialization</a><ul></ul></li>
<li><a href="#ownership">2.5 Ownership</a><ul></ul></li>
<li><a href="#opting-out-of-resilience">2.6 Opting Out of Resilience</a><ul></ul></li>
<li><a href="#esoterica">2.7 Esoterica</a><ul></ul></li></ul></li></ul></nav>
<p>For those who don't follow Swift's development, ABI stability has been one of its most ambitious projects and possibly it's defining feature, <a href="https://swift.org/blog/abi-stability-and-more/">and it finally shipped in Swift 5</a>. The result is something I find endlessly fascinating, because I think Swift has pushed the notion of ABI stability farther than any language without much compromise.</p>
<p>So I decided to write up a bunch of the interesting high-level details of Swift's ABI. This <strong>is not</strong> a complete reference for Swift's ABI, but rather an abstract look at its implementation strategy. If you really want to know exactly how it allocates registers or mangles names, look somewhere else.</p>
<p>Also for context on why I'm writing this, I'm just naturally inclined to compare the design of Swift to Rust, because those are the two languages I have helped develop. Also some folks like to complain that Rust doesn't bother with ABI stability, and I think looking at how Swift <em>does</em> helps elucidate why that is.</p>
<p>This article is broken up into two sections: background and details. Feel free to skip to the details if you're very comfortable with the problems inherent to producing a robust dynamically linked system interface.</p>
<p>If you aren't comfortable with the basic concepts of type layouts, ABIs, and calling conventions, I recommend reading the article I wrote on <a href="https://gankra.github.io/blah/rust-layouts-and-abis/">the basic concepts of type layout and ABI as they pertain to Rust</a>.</p>
<p>Also huge thanks to the Swift devs for answering all of the questions I had and correcting my misunderstandings!</p>

<p>I know a lot of people don't really follow Swift, and it can be hard to understand what they've really accomplished without some context of what the language is like, so here's a TL;DR of the language's shape:</p>
<ul>
<li>Exists to replace Objective-C on Apple's platforms, oriented at application development
<ul>
<li>natively interoperates with Objective-C</li>
<li>has actual classes and inheritance</li>
</ul>
</li>
<li>At a distance, very similar to Rust (but "higher-level")
<ul>
<li>interfaces, generics, closures, enums with payloads, unsafe escape hatch</li>
<li>no lifetimes; Automatic Reference Counting (ARC) used for complex cases</li>
<li>simple function-scoped mutable borrows (inout)</li>
<li>Ahead-Of-Time (AOT) compiled</li>
</ul>
</li>
<li>An emphasis on "value semantics"
<ul>
<li>structs/primitives ("values") are "mutable xor shared", stored inline</li>
<li>collections implement value semantics by being Copy-On-Write (CoW) (using ARC)</li>
<li>classes are mutably shared and boxed (using ARC), undermining value semantics (can even cause data races)</li>
</ul>
</li>
<li>An emphasis on things Just Working
<ul>
<li>language may freely allocate to make things Work</li>
<li>generic code may be polymorphically compiled</li>
<li>fields may secretly be getter-setter pairs</li>
<li>ARC and CoW can easily result in surprising performance cliffs</li>
<li>tons of overloading and syntactic sugar</li>
</ul>
</li>
</ul>
<p>Don't worry about fully understanding all of these, we'll dig into the really important ones and their implications as we go on.</p>
<h2 id="what-is-abi-stability-and-dynamic-linking"><a href="#what-is-abi-stability-and-dynamic-linking">1.2 What Is ABI Stability and Dynamic Linking</a></h2>
<p>When the Swift developers talk about "ABI Stability" they have exactly one thing in mind: they want native system APIs for MacOS and iOS to be written in Swift, and for you to dynamically link to them. This includes dynamically linking to a single system-wide copy of the Swift Standard Library.</p>
<p>Ok so what's dynamic linking? For our purposes it's a system where you can compile an application against some abstract <em>description</em> of an interface without providing an actual implementation of it. This produces an application that on its own will not work properly, as part of its implementation is missing.</p>
<p>To run properly, it must tell the system's <em>dynamic linker</em> about all of the interfaces it needs implementations for, which we call <em>dynamic libraries</em> (dylibs). Assuming everything goes right, those implementations get hooked up to the application and everything Just Works.</p>
<p>Dynamic linking is very important to system APIs because it's what allows the system's implementation to be updated without also rebuilding all the applications that run on it. The applications don't care about what implementation they get, as long as it conforms to the interface they were built against.</p>
<p>It can also significantly reduce a system's memory footprint by making every application share the same implementation of a library (Apple cares about this a lot on its mobile devices).</p>
<p>Since Swift is AOT compiled, the application and the dylib both have to make a bunch of assumptions on how to communicate with the other side long before they're linked together. These assumptions are what we call ABI (an Application's <em>Binary</em> Interface), and since it needs to be consistent over a long period of time, that ABI better be stable.</p>
<p>So dynamic linking is our goal, and ABI stability is just a means to that end.</p>
<p>For our purposes, an ABI can be regarded as 3 things:</p>
<ol>
<li><a href="https://gankra.github.io/blah/rust-layouts-and-abis/#layout">The layout of types</a></li>
<li><a href="https://gankra.github.io/blah/rust-layouts-and-abis/#calling-conventions">The calling convention of functions</a></li>
<li><a href="https://en.wikipedia.org/wiki/Name_mangling">The names of symbols</a></li>
</ol>
<p>If you can define these details and never break them, you have a stable ABI, and dynamic linking can be performed. (Ignoring trivial cases where both the dylib and application were built together and ABI stability is irrelevant.)</p>
<p>Now to be clear, ABI stability isn't technically a property of a programming language. It's really a property of a system and its toolchain. To understand this, let's look at history's greatest champion of ABI stability and dynamic linking: C.</p>
<p>All the major OSes make use of C for their dynamically linked system APIs. From this we can conclude that C "has" a stable ABI. But here's the catch: if you compile some C code for dynamic linking on Ubuntu, that compiled artifact won't work on MacOS or Windows. Heck, even if you compile it for 64-bit Windows it won't work on 32-bit Windows!</p>
<p>Why? Because ABI is something defined by the <em>platform</em>. It's not even something that necessarily needs to be documented. The platform vendor can just require you to use a particular compiler toolchain that happens to implement their stable ABI.</p>
<p>(As it turns out, this is actually the reality of Swift's Stabilized ABIs on Apple platforms. They're not actually properly documented, xcode just implements it and the devs will do their best not to break it. They're not opposed to documenting it, it's just a lot of work and shipping was understandably higher-priority. Thankfully I don't really care about the details, or the difference between the ABIs on MacOS and iOS, or implementations other than Apple's, so I can keep saying "Swift's ABI" and it won't be a problem.)</p>
<p>But if that's the case, why don't platform vendors provide stable ABIs for lots of other languages? Well it turns out that the language isn't completely irrelevant here. Although ABI isn't "part" of C itself, it <em>is</em> relatively friendly to the concept. Many other languages aren't.</p>
<p>To understand why C is friendly to ABI stability, let's look at its much less friendly big brother, C++.</p>
<p>Templated C++ functions cannot have their implementations dynamically linked. If I provide you with a system header that provides the following declaration, you simply can't use it:</p>
<pre><code>template &lt;typename T&gt;
bool process(T value);
</code></pre>
<p>This is because <em>it has no symbol</em>. C++ templates are monomorphically compiled, which is a fancy way of saying that the way to use them is to copy-paste the implementation with all the templates replaced with a particular value.</p>
<p>So if I want to call <code>process&lt;int&gt;(0)</code>, I need to have the implementation available to copy-paste it with <code>int</code> replacing <code>T</code>. Needing to have the implementation available at compile-time completely undermines the concept of dynamic linking.</p>
<p>Now perhaps the platform could make a promise that it has precompiled several monomorphic instances, so say symbols for <code>process&lt;int&gt;</code> and <code>process&lt;bool&gt;</code> are available. You could make that work, but then the function wouldn't really be meaningfully templated anymore, as only those two explicitly blessed substitutions would be valid.</p>
<p>There would be little difference from simply providing a header containing:</p>
<pre><code>bool process(int value);
bool process(bool value);
</code></pre>
<p>Now a header <em>could</em> just include the template's implementation, but what that would really be guaranteeing is that that particular implementation will <em>always</em> be valid. Future versions of the header could introduce new implementations, but a robust system would have to assume applications could using either, or perhaps even both at the same time.</p>
<p>This is no different from a C macro or <code>inline</code> function, but I think it's fair to say that templates are a little more important in C++.</p>
<p>For comparison, most platforms provide a dynamically linked version of the C standard library, and everyone uses it. On the other hand, C++'s standard library isn't very useful to dynamically link to; it's literally called the Standard <em>Template</em> Library!</p>
<p>In spite of this issue (and many others), C++ <em>can</em> be dynamically linked and used in an ABI-stable way! It's just that it ends up looking a lot more like a C interface due to the limitations.</p>
<p>Idiomatic Rust is similarly hostile to dynamic linking (it also uses monomorphization), and so an ABI-stable Rust would also end up only really supporting C-like interfaces. Rust has largely just embraced that fact, focusing its attention on other concerns.</p>

<p>I have now made some seemingly contradictory claims:</p>
<ul>
<li>Swift has similar features to Rust</li>
<li>Rust's features make it hostile to dynamic linking</li>
<li>Swift is great at dynamic linking</li>
</ul>
<p>The secret lies in where the two languages diverge: dynamism. Rust is a <em>very</em> static and explicit language, reflecting the sensibilities of its developers and early adopters. Swift's developers preferred a much more dynamic and implicit design, and so that's what they made.</p>
<p>As it turns out, hiding implementation details and doing more work at runtime is <em>really</em> friendly to dynamic linking. Who'd've ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gankra.github.io/blah/swift-abi/">https://gankra.github.io/blah/swift-abi/</a></em></p>]]>
            </description>
            <link>https://gankra.github.io/blah/swift-abi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26205969</guid>
            <pubDate>Sat, 20 Feb 2021 17:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26205418">thread link</a>) | @lukastyrychtr
<br/>
February 20, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we‚Äôll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We‚Äôll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a ‚Äúsmart machine-code buffer‚Äù that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is ‚Äústraight-line‚Äù code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift‚Äôs CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG‚Äôs end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it‚Äôs
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it‚Äôs usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn‚Äôt much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we‚Äôll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we‚Äôve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or ‚Äúlabel use‚Äù in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ¬±1 MB range,
and unconditional branches have a ¬±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ¬±128 byte range) or four-byte offset (allowing a ¬±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
‚Äúfixpoint problem‚Äù, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I‚Äôll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26205418</guid>
            <pubDate>Sat, 20 Feb 2021 16:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My history with Forth and stack machines (2010)]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26203518">thread link</a>) | @panic
<br/>
February 20, 2021 | https://yosefk.com/blog/my-history-with-forth-stack-machines.html | <a href="https://web.archive.org/web/*/https://yosefk.com/blog/my-history-with-forth-stack-machines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em><span><span><span><span><span><span>My VLSI tools take a chip from conception through testing. Perhaps 500 lines of source code. Cadence, Mentor Graphics do the same, more or less. With how much source/object code?</span></span></span></span></span></span></em></p>
<p><em>‚Äì <a href="http://www.colorforth.com/1percent.html">Chuck Moore</a>, the inventor of Forth</em></p>
<p>This is a personal account of my experience implementing and using the Forth programming language and the stack machine architecture. "Implementing and using" ‚Äì in that order, pretty much; a somewhat typical order, as will become apparent.</p>
<p>It will also become clear why, having defined the instruction set of a processor designed to run Forth that went into production, I don't consider myself a competent Forth programmer (now is the time to warn that my understanding of Forth is just that ‚Äì my own understanding; wouldn't count on it too much.)</p>
<p>Why the epigraph about Chuck Moore's VLSI tools? Because Forth is very radical. Black Square kind of radical. An approach to programming seemingly leaving out most if not all of programming:</p>
<blockquote><p>‚Ä¶Forth does it differently. There is no syntax, no redundancy, no typing. There are no errors that can be detected. ‚Ä¶there are no parentheses. No indentation. No hooks, no compatibility. ‚Ä¶No files. No operating system.</p></blockquote>
<p><img src="http://yosefk.com/img/n/black-square.jpg" alt="Black Square by Kazimir Malevich" width="220" height="218"></p>
<p>I've never been a huge fan of suprematism or modernism in general. However, a particular modernist can easily get my attention if he's a genius in a traditional sense, with superpowers. Say, he memorizes note sheets upon the first brief glance like Shostakovich did.</p>
<p>Now, I've seen chip design tools by the likes of Cadence and Mentor Graphics. Astronomically costly licenses. Geological run times. And nobody quite knows what they do. To me, VLSI tools in 500 lines qualify as a superpower, enough to grab my attention.</p>
<p>So, here goes.</p>
<p>***</p>
<p>I was intrigued with Forth ever since I read about it in Bruce Eckel's book on C++, a 198-something edition; he said there that "extensibility got a bad reputation due to languages like Forth, where a programmer could change everything and effectively create a programming language of his own". WANT!</p>
<p>A couple of years later, I looked for info on the net, which seemed somewhat scarce. An unusually looking language. Parameters and results passed implicitly on a stack. 2 3 + instead of 2+3. Case-insensitive. Nothing about the extensibility business though.</p>
<p>I thought of nothing better than to dive into the source of an implementation, <a title="Portable Forth in 'C'. Why do Forth programmers put C in quotes?" href="http://www.softsynth.com/pforth/">pForth</a> ‚Äì and I didn't need anything better, as my mind was immediately blown away by the following passage right at the top of <a href="http://pforth.googlecode.com/svn/trunk/fth/system.fth">system.fth</a>, the part of pForth implemented in Forth on top of the C interpreter:</p>
<blockquote>
<pre>: (   41 word drop ; immediate
( That was the definition for the comment word. )
( Now we can add comments to what we are doing! )</pre>
</blockquote>
<p>Now. we. can. add. comments. to. what. we. are. doing.</p>
<p>What this does is define a word (Forth's name for a function) called "(". "(" is executed at compile time (as directed by IMMEDIATE). It tells the compiler to read bytes from the source file (that's what the word called, um, WORD is doing), until a ")" ‚Äì ASCII 41 ‚Äì is found. Those bytes are then ignored (the pointer to them is removed from the stack with DROP). So effectively, everything inside "( ‚Ä¶ )" becomes a comment.</p>
<p><em>Wow.</em> Yeah, you definitely can't do that in C++. (You <a href="http://www.lispworks.com/documentation/lw51/CLHS/Body/f_set_ma.htm#set-macro-character">can</a> in Lisp but they don't teach you those parts at school. They teach the pure functional parts, where you <em>can't</em> do things that you <em>can</em> in C++. Bastards.)</p>
<p>Read some more and‚Ä¶</p>
<blockquote>
<pre><em> conditional primitives</em>
: IF     <em>( -- f orig )</em>  ?comp compile 0branch  conditional_key &gt;mark     ; immediate
: THEN   <em>( f orig -- )</em>  swap ?condition  &gt;resolve   ; immediate
: BEGIN  <em>( -- f dest )</em>  ?comp conditional_key &lt;mark   ; immediate
: AGAIN  <em>( f dest -- )</em>  compile branch  swap ?condition  &lt;resolve  ; immediate
: UNTIL  <em>( f dest -- )</em>  compile 0branch swap ?condition  &lt;resolve  ; immediate
: AHEAD  <em>( -- f orig )</em>  compile branch   conditional_key &gt;mark     ; immediate</pre>
</blockquote>
<p>Conditional <em>primitives</em>?! Looks like conditional primitives aren't ‚Äì they <em>define</em> them here. This COMPILE BRANCH business modifies the code of a function that uses IF or THEN, at compile time. THEN ‚Äì one part of the conditional ‚Äì writes (RESOLVEs) a branch offset to a point in code saved (MARKed) by IF, the other part of the conditional.</p>
<p>It's as if a conventional program modified the assembly instructions generated from it at compile time. What? How? Who? How do I wrap my mind around this?</p>
<p>Shocked, I read the source of pForth.</p>
<p>Sort of understood how Forth code was represented and interpreted. Code is this array of "execution tokens" ‚Äì function pointers, numbers and a few built-ins like branches, basically. A Forth interpreter keeps an instruction pointer into this array (ip), a data stack (ds), and a return stack (rs), and does this:</p>
<pre><strong>while</strong>(<strong>true</strong>) {
 <strong>switch</strong>(*ip) {
  <em>//arithmetics (+,-,*...):</em>
  <strong>case </strong>PLUS: ds.push(ds.pop() + ds.pop()); ++ip;
  <em>//stack manipulation (drop,swap,rot...):</em>
  <strong>case </strong>DROP: ds.pop(); ++ip;
  <em>//literal numbers (1,2,3...):</em>
  <strong>case </strong>LITERAL: ds.push(ip[1]); ip+=2;
  <em>//control flow:</em>
 &nbsp;<strong>case </strong>COND_BRANCH: <strong>if</strong>(!ds.pop()) ip+=ip[1]; <strong>else </strong>ip+=2;
 &nbsp;<strong>case </strong>RETURN: ip = rs.pop();
  <em>//user-defined words: save return address &amp; jump</em>
 &nbsp;<strong>default</strong>: rs.push(ip+1); ip = *ip;
 }
}</pre>
<p>That's it, pretty much. Similar, say, to the virtual stack machine used to implement Java. One difference is that compiling a Forth program is basically writing to the code array in a WYSIWYG fashion. COMPILE SOMETHING simply appends the address of the word SOMETHING to the end of the code array. So does plain SOMETHING when Forth is compiling rather than interpreting, as it is between a colon and a semicolon, that is, when a word is defined.</p>
<p>So</p>
<pre>: DRAW-RECTANGLE 2DUP UP RIGHT DOWN LEFT ;</pre>
<p>simply appends {&amp;2dup,&amp;up,&amp;right,&amp;down,&amp;left,RETURN} to the code array. Very straightforward. There are no parameters or declaration/expression syntax as in‚Ä¶</p>
<pre><strong>void </strong>drawRectangle(<strong>int </strong>width, <strong>int </strong>height) {
  up(height);
  right(width);
  down(height);
  left(width);
}</pre>
<p>‚Ä¶to make it less than absolutely clear how the source code maps to executable code. "C maps straightforwardly to assembly"? Ha! <em>Forth</em> maps straightforwardly to assembly. Well, to the assembly language of a virtual stack machine, but still. So one can understand how self-modifying code like IF and THEN works.</p>
<p>On the other hand, compared to drawRectangle, it is somewhat unclear what DRAW-RECTANGLE <em>does</em>. What are those 2 values on the top of the stack that 2DUP duplicates before meaningful English names appear in DRAW-RECTANGLE's definition? This is supposed to be ameliorated by stack comments:</p>
<pre>: DRAW-RECTANGLE <em>( width height -- )</em> ... ;</pre>
<p>‚Ä¶tells us that DRAW-RECTANGLE expects to find height at the top of the stack, and width right below it.</p>
<p>I went on to sort of understand CREATE/DOES&gt; ‚Äì a further extension of this compile-time self-modifying code business that you use to "define defining words" (say, CONSTANT, VARIABLE, or CLASS). The CREATE part says what should be done when words (say, class names) are defined by your new defining word. The DOES&gt; part says what should be done when those words are used. For example:</p>
<pre>: CONSTANT
  &nbsp;CREATE ,
  &nbsp;DOES&gt; @
;
<em>\ usage example:</em>
7 CONSTANT DAYS-IN-WEEK
DAYS-IN-WEEK 2 + . <em>\ should print 9</em></pre>
<p>CREATE means that every time CONSTANT is called, a name is read from the source file (similarly to what WORD would have done). Then a new word is created with that name (as a colon would have done). This word records the value of HERE ‚Äì something like sbrk(0), a pointer past the last allocated data item. When the word is executed, it pushes the saved address onto the data stack, then calls the code after DOES&gt;. The code after CREATE can put some data after HERE, making it available later to the DOES&gt; part.</p>
<p>With CONSTANT, the CREATE part just saves its input (in our example, 7) ‚Äì the comma word does this: *HERE++ = ds.pop(); The DOES&gt; part then fetches the saved number ‚Äì the @ sign is the fetch word: ds.push( *ds.pop() );</p>
<p>CONSTANT works somewhat similarly to a class, CREATE defining its constructor and DOES&gt; its single method:</p>
<pre>class Constant
  def initialize(x) @x=x end
  def does() @x end
end
daysInWeek = Constant.new(7)
print daysInWeek.does() + 2</pre>
<p>‚Ä¶But it's much more compact on all levels.</p>
<p>Another example is defining C-like structs. Stripped down to their bare essentials (and in Forth things tend to be stripped down to their bare essentials), you can say that:</p>
<pre><strong>struct </strong>Rectangle {
  <strong>int </strong>width;
  <strong>int </strong>height;
};</pre>
<p>‚Ä¶simply gives 8 (the structure size) a new name Rectangle, and gives 0 and 4 (the members' offsets) new names, width and height. Here's <a href="http://wiki.laptop.org/go/Forth_Lesson_18">one way to implement structs in Forth</a>:</p>
<pre>struct
  cell field width
  cell field height
constant rectangle

<em>\ usage example:</em>
<em>\ here CREATE is used just for allocation</em>
create r1 rectangle allot <em>\ r1=HERE; HERE+=8</em>
2 r1 width !
3 r1 height !
: area dup width @ swap height @ * ;
r1 area . <em>\ should print 6</em></pre>
<p>CELL is the size of a word; we could say "4 field width" instead of "cell field width" on 32b machines. Here's the definition of FIELD:</p>
<pre>&nbsp;: field <em>( struct-size field-size -- new-struct-size )</em>
    create over , +
    does&gt; @ +
&nbsp;;</pre>
<p>Again, pretty compact. The CREATE part stores the offset, a.k.a current struct size (OVER does ds.push(ds[1]), comma does *HERE++=ds.pop()), then adds the field size to the struct size, updating it for the next call to FIELD. The DOES&gt; part fetches the offset, and adds it to the top of the stack, supposedly containing the object base pointer, so that "rect width" or "rect height" compute &amp;rect.width or &amp;rect.height, respectively. Then you can access this address with @ or ! (fetch/store). STRUCT simply pushes 0 to the top of the data stack (initial size value), and at the end, CONSTANT consumes the struct size:</p>
<pre>struct <em>\ data stack: 0</em>
  cell <em>( ds: 0 4 )</em> field width  <em>( ds: 4 )</em>
  cell <em>( ds: 4 4 )</em> field height <em>( ds: 8 )</em>
constant rectangle <em>( ds: as before STRUCT )</em></pre>
<p>You can further extend this to support polymorphic methods ‚Äì METHOD would work similarly to FIELD, fetching a function pointer ("execution token") through a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yosefk.com/blog/my-history-with-forth-stack-machines.html">https://yosefk.com/blog/my-history-with-forth-stack-machines.html</a></em></p>]]>
            </description>
            <link>https://yosefk.com/blog/my-history-with-forth-stack-machines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26203518</guid>
            <pubDate>Sat, 20 Feb 2021 12:02:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw an iceberg and see how it would float in water]]>
            </title>
            <description>
<![CDATA[
Score 1514 | Comments 161 (<a href="https://news.ycombinator.com/item?id=26201160">thread link</a>) | @raldi
<br/>
February 19, 2021 | https://joshdata.me/iceberger.html | <a href="https://web.archive.org/web/*/https://joshdata.me/iceberger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://joshdata.me/iceberger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201160</guid>
            <pubDate>Sat, 20 Feb 2021 03:16:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Life in E-Ink]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 152 (<a href="https://news.ycombinator.com/item?id=26200630">thread link</a>) | @HaoZeke
<br/>
February 19, 2021 | https://rgoswami.me/posts/my-life-in-eink/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/my-life-in-eink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Collection of odds and ends relating to e-readers including personal reminisces</p></blockquote><h2 id="background">Background</h2><p>Reading has been a huge part of my life. The written word has had arguably more of an impact on my life than anything I have experienced in person. As a kid back in early 2000‚Äôs; this meant a lot of library trips and saving for paperbacks. I also caught the first wave of the e-ink revolution. Nothing beats a real book, in terms of textures and scents; but e-ink devices and the fantastic tools outlined here should make reading digital books much more palpable&nbsp;<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><p>I have been reading on my <a href="https://en.wikipedia.org/wiki/Kobo%5FAura%5FHD">Kobo Aura HD</a> for almost a decade now, ever since its release. This means my setup is about as stable as its going to get in the near future. As good a time as any to collect my thoughts&nbsp;<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The focus is on e-ink devices and auxiliary tools; not on all digital content; so there are no mentions of syncing or reading on the go (with a phone) or of monitors which are good for reading on.</p><h3 id="the-content">The Content</h3><p>In general; my e-ink reading habits can be broadly broken into the following categories:</p><dl><dt>Light Reading</dt><dd>Practically this includes <a href="https://www.goodreads.com/user/show/33462912-rohit-goswami">anything I review on Goodreads</a>; these are not often re-read; nor read very deeply; since they are read for pleasure. They are however, rarely deleted</dd><dt>Required Reading</dt><dd>Anything which typically requires me to take notes or practice / write out proofs; these are most often considered to be either coursework (for someone somewhere) or research monographs. These are typically large (in size) and unwieldy (in that they often lack TOCs) and are read multiple times; with a focus on highlights and notes</dd><dt>Active Research</dt><dd>These are the most ephemeral of my reading habits; and also the most numerous; I do not typically store these on my e-reader; and rarely need to make notes on the reader&nbsp;<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. These are often tiny; but require special work due to the metadata involved</dd></dl><table><thead><tr><th>Content Type</th><th>Software Stack</th><th>Deletion Rate</th></tr></thead><tbody><tr><td>Light Reading</td><td>Calibre</td><td>Rare</td></tr><tr><td>Required Reading</td><td>Calibre</td><td>Never</td></tr><tr><td>Active Research</td><td>Calibre + Zotero</td><td>Frequent</td></tr></tbody></table><p>Though I am a huge proponent of RSS feeds (with <a href="https://gitlab.com/news-flash/news%5Fflash%5Fgtk">Newsflash</a>) and read online content voraciously with both a <a href="https://app.getpocket.com/">Pocket</a> and <a href="https://www.diigo.com/user/rgoswami">Diigo</a> subscription<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>; I sincerely do not believe blog stuff or anything tailored for the web should have a presence on an e-ink device; so there shall be no mention of those parts of my reading habits<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><h2 id="hardware">Hardware</h2><p>My primary e-reader is still my <a href="https://www.kobo.com/koboaurahd?%5F%5F%5Fstore=au&amp;style=onestore">Kobo Aura HD</a> (complete with a snazzy <a href="https://www.amazon.com/Cover-Up-eReader-Natural-Cover-Function/dp/B00DZJ5VM0">hemp sleep-cover</a>), and has been my go to for almost a decade now since its release. Recently I have augmented my workflow with the <a href="https://remarkable.com/store/remarkable-2">reMarkable 2</a>; though I have yet to break it in very well; mostly because I tend to gravitate towards typing out my thoughts&nbsp;<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> instead of writing.</p><p>The Kobo Aura HD is still the pinnacle of reading technology to me; mostly because the firmware is easy to bypass; and there is a vibrant community of developers on the <a href="https://www.mobileread.com/forums/showthread.php?t=210800">MobileRead Forums</a>. Display and spec aside; the biggest reason for never replacing it has been been the simple fact that most modern e-readers no longer support SD cards; and much of my workflow depends on storing insane amounts of material offline&nbsp;<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/d393a91160884052b7717a31a565283336a03ccf/eb437/ox-hugo/2021-02-20_01-39-20_screenshot.png" alt="Figure 1: Primary reading device with Koreader"><figcaption><p>Figure 1: Primary reading device with Koreader</p></figcaption></figure><p>Personally, I never use Nickel (the default Kobo interface), and it would probably choke trying to scan my 200 GB of content; so I haven‚Äôt updated the firmware in forever. My interactions are almost always in <a href="https://koreader.rocks/">Koreader</a>; and my launching poison of choice is the now no longer developed <a href="https://www.mobileread.com/forums/showthread.php?t=293804">Kobo start menu</a>&nbsp;<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>.</p><h2 id="software">Software</h2><p>Broadly speaking; the main parts of the software pipeline from digital book to brain are simply the syncing mechanism and the UI/UX/OS of the device in question; though it is often best to consider pre-processing books for devices too. These are covered in the order used.</p><h3 id="k2pdfopt">k2pdfopt</h3><p>The thought of reflowing text for an optimal reading experience, especially given the slightly limited processing power of my primary reading device is an enticing prospect. <a href="https://www.willus.com/k2pdfopt/">K2pdfopt or the Kindle 2 PDF Optimizer</a> is as criminally underrated as it is fantastic. An approach which works well for my device involves setting up <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/docK2pdf">a simple shell script</a> (part <a href="https://github.com/HaoZeke/Dotfiles">of my Dotfiles</a>) for optimizing files on the fly before sending them through <code>calibre</code>.</p><div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Get a filename</span>
<span>case</span> <span>"</span><span>$#</span><span>"</span> in
0<span>)</span>
      <span>echo</span> <span>"No arguments, so enter the filename, WITH the extension"</span>
      <span>read</span> -p <span>'Document: '</span> docfile
      <span>;;</span>
1<span>)</span>
      <span>echo</span> <span>"OK, using the filename"</span>
      <span>docfile</span><span>=</span><span>"</span><span>$1</span><span>"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal number of parameters"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
<span># Get basename</span>
<span>basename</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>%.*</span><span>}</span><span>"</span>
<span>ext</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>##*</span><span>\.</span><span>}</span><span>"</span>
<span>echo</span> <span>"Basename </span><span>${</span><span>basename</span><span>}</span><span> with </span><span>$ext</span><span> from </span><span>$docfile</span><span>"</span>
<span>echo</span> <span>"Making a local store for the outputs"</span>
mkdir -p <span>"</span><span>$HOME</span><span>/auraHDopt"</span>

<span>case</span> <span>"</span><span>$ext</span><span>"</span> in
<span>"djvu"</span><span>)</span>
      <span>echo</span> <span>"Converting djvu to pdf via ps and running k2pdfopt"</span>
      djvups <span>"</span><span>${</span><span>basename</span><span>}</span><span>.djvu"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span>
      ps2pdf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span># The newline is for simulating the Enter key</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      rm -rf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.{ps,pdf}"</span>
      <span>;;</span>
<span>"pdf"</span><span>)</span>
      <span>echo</span> <span>"Converting pdf with gs and running k2pdfopt"</span>
      gs -sDEVICE<span>=</span>pdfwrite -dCompatibilityLevel<span>=</span>1.4 -dPDFSETTINGS<span>=</span>/screen <span>\
</span><span></span>              -dNOPAUSE -dQUIET -dBATCH -sOutputFile<span>=</span><span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      rm <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -rf
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal file type"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
</code></pre></div><p>The outputs can also be further processed with an <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/isOcr">OCR (Optical Character Recognition) script</a> if required, and then edited in <a href="https://code-industry.net/masterpdfeditor/">Master PDF Editor</a> or something similar to add the table of contents interactively as well.</p><div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span><span># Use as  find . -type f -name "*.pdf" -exec isOcr '{}' \;</span>

<span># Shamelessly kanged from here:</span>
<span># https://stackoverflow.com/questions/7997399/bash-script-to-check-pdfs-are-ocrd</span>
<span># Only searches for text on the first 5 pages</span>
<span># Modified to have red text. Also to possibly ocr the thing.</span>

<span># -*- mode: shell-script-mode -*-</span>

<span>MYFONTS</span><span>=</span><span>$(</span>pdffonts -l <span>15</span> <span>"</span><span>$1</span><span>"</span> <span>|</span> tail -n +3 <span>|</span> cut -d<span>' '</span> -f1 <span>|</span> sort <span>|</span> uniq<span>)</span>
<span>if</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>''</span> <span>]</span> <span>||</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>'[none]'</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"</span><span>$(</span>tput setaf 1<span>)</span><span>NOT OCR'ed: </span><span>$1</span><span>"</span>
    <span>if</span> <span>[[</span> -x <span>"</span><span>$(</span>which ocrmypdf<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
        <span>echo</span> <span>"Converting to </span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf with ocrmypdf"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 7<span>)</span><span>"</span>
        ocrmypdf --deskew --clean --rotate-pages <span>\
</span><span></span>            --jobs <span>4</span> -v --output-type pdfa <span>"</span><span>$1</span><span>"</span> <span>"</span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf"</span>
    <span>elif</span> <span>[[</span> -x <span>"</span><span>$(</span>which pypdfocr<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> Looking for config files at </span><span>$XDG_CONFIG_HOME</span><span>/pypdfocr/config.yml"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 3<span>)</span><span>"</span>
        <span>if</span> <span>[[</span> -e <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>]]</span><span>;</span> <span>then</span>
            <span>echo</span> <span>"Using configuration settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr -c <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>"</span><span>$1</span><span>"</span>
        <span>else</span>
            <span>echo</span> <span>"Using default settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr <span>"</span><span>$1</span><span>"</span>
        <span>fi</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> You might want to get pypdfocr"</span>
    <span>fi</span>
<span>else</span>
    <span>echo</span> <span>"</span><span>$1</span><span> is OCR'ed."</span>
<span>fi</span>
</code></pre></div><p>The end result is:</p><ul><li>A directory with perfectly <code>pdf</code> files re-flowed text<ul><li>Possibly OCR‚Äôed for string searches</li></ul></li></ul><p>TOC editing is still rather janky; but this is also because the OCR process is still rather spotty.</p><h3 id="calibre">Calibre</h3><p><a href="https://calibre-ebook.com/">Calibre</a> is an excellent library software, and there are very few alternatives which offer all the salient features:</p><dl><dt>Syncing</dt><dd>Apart from working well with a plethora of official devices, Koreader is also pretty well supported, and mounting folders allows for easy management of a secret library (e.g. <code>.Library</code>) on an SD card to prevent Nickel from reading and choking on large libraries</dd><dt>Multiple Libraries</dt><dd>I personally keep one for fiction, one for non-fiction, and one (transiently populated) one for papers</dd><dt>Good metadata collection</dt><dd>Nothing beats rich metadata, and with third party plugins, all the best content providers can be leveraged for blurbs; plus most purchased books come with metadata which <code>calibre</code> can read</dd></dl><p>It isn‚Äôt perfect, there are far better <a href="https://opds.io/">OPDS (Open Publication Distribution System)</a> servers like the fantastic <a href="https://github.com/seblucas/cops">COPS (Calibre OPDS)</a> project, and there have been <a href="https://anarc.at/software/desktop/calibre/">some security concerns in the past</a>, but it is really usable and is <a href="https://github.com/kovidgoyal/calibre">under active development</a>; plus it has a <a href="https://kovidgoyal.net/">fun developer</a>. I also personally find the file conversion lacking, compared to <code>k2pdfopt</code>, but as a library management system it is really good.</p><h3 id="zotero-sync">Zotero Sync</h3><p>Calibre provides a handy <a href="https://www.mobileread.com/forums/showthread.php?p=3339191#poststop">ZMI (Zotero Metadata Importer) plugin</a> which allows for exported papers to be imported into <code>calibre</code> and from then into the e-reader as expected. Combined with the folder mounts facilitated by <code>calibre</code> this allows for a painless way to ensure a quick export; optimize; sync; read and delete workflow.</p><h3 id="koreader">Koreader</h3><p>Koreader is probably the best thing to happen to e-ink devices since sliced bread. It replaces the need to use any cables with an e-reader; since newer versions have a nice SSH server, and can also update itself. Since this is mostly used as is; and all the information required is on the <a href="https://github.com/koreader/koreader/wiki">Github Wiki</a>, there‚Äôs not much else to say here.</p><p>It is probably worth noting that the in-built re-flow options do tend to cause major artifacts on older hardware, and is best avoided. Almost equivalently, and at a far lower cost in terms of performance, page contents can be fit to width and zoomed in automatically, which is almost as good as working with <code>k2pdfopt</code> in some special cases.</p><h2 id="conclusions">Conclusions</h2><p>Given my unfortunate separation from my library back home; it is likely that my e-ink devices will continue to be my primary source of reading material. Plus the long retarded color e-ink market finally seems to be moving out of its stupor&nbsp;<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>. The only possible addendum to this methodology would probably involve integrating <code>orgmode</code> and the reMarkable 2 sometime. E-ink is here to stay. This setup would probably need revisions involving <code>rclone</code> or <code>syncthing</code> if I ever gave ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rgoswami.me/posts/my-life-in-eink/">https://rgoswami.me/posts/my-life-in-eink/</a></em></p>]]>
            </description>
            <link>https://rgoswami.me/posts/my-life-in-eink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26200630</guid>
            <pubDate>Sat, 20 Feb 2021 01:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request for Pinboard old-timers]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 164 (<a href="https://news.ycombinator.com/item?id=26199676">thread link</a>) | @Alex3917
<br/>
February 19, 2021 | https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/ | <a href="https://web.archive.org/web/*/https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199676</guid>
            <pubDate>Fri, 19 Feb 2021 23:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F‚Äô: Flight Software and Embedded Systems Framework]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26199346">thread link</a>) | @zeristor
<br/>
February 19, 2021 | https://nasa.github.io/fprime/ | <a href="https://web.archive.org/web/*/https://nasa.github.io/fprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p>F¬¥ is a software framework for rapid development and deployment of embedded systems and spaceflight applications.
Originally developed at NASA‚Äôs Jet Propulsion Laboratory, F¬¥ is open source software that has been successfully deployed
for several space applications. It has been used for, but is not limited to, CubeSats, SmallSats, instruments, and
deployables.</p>

<p>F¬¥ has the following features:</p>
<ul>
  <li>Component architecture with well-defined interfaces</li>
  <li>C++ framework providing core capabilities like queues, threads, and operating-system abstraction</li>
  <li>Tools for designing systems and automatically generating code from systems design</li>
  <li>A standard library of flight-worthy components</li>
  <li>Testing tools for unit and system-level testing</li>
</ul>

<table>
  <thead>
    <tr>
      <th>F¬¥ Resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Features</td>
      <td><a href="https://nasa.github.io/fprime/features.html">Features</a></td>
    </tr>
    <tr>
      <td>Projects</td>
      <td><a href="https://nasa.github.io/fprime/projects.html">Projects</a></td>
    </tr>
    <tr>
      <td>Installation</td>
      <td><a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a></td>
    </tr>
    <tr>
      <td>Tutorials</td>
      <td><a href="https://nasa.github.io/fprime/Tutorials/README.html">Tutorials</a></td>
    </tr>
    <tr>
      <td>User Guide</td>
      <td><a href="https://nasa.github.io/fprime/UsersGuide/guide.html">User Guide</a></td>
    </tr>
    <tr>
      <td>Repository</td>
      <td><a href="https://github.com/nasa/fprime">https://github.com/nasa/fprime</a></td>
    </tr>
    <tr>
      <td>Community Forum and Mailing List</td>
      <td><a href="https://groups.google.com/d/forum/fprime-community">https://groups.google.com/d/forum/fprime-community</a></td>
    </tr>
    <tr>
      <td>Community GitHub Organization</td>
      <td><a href="https://github.com/fprime-community">https://github.com/fprime-community</a></td>
    </tr>
    <tr>
      <td>Standard Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">Ref</a></td>
    </tr>
    <tr>
      <td>Raspberry PI Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">RPI</a></td>
    </tr>
    <tr>
      <td>Architecture Overview</td>
      <td><a href="https://nasa.github.io/fprime/Architecture/FPrimeArchitectureShort.pdf">Architecture</a></td>
    </tr>
  </tbody>
</table>

<h2 id="f-system-requirements">F¬¥ System Requirements</h2>

<p>In order to develop applications with F¬¥, the following requirements of the user‚Äôs system must be met.</p>

<ol>
  <li>Linux or Mac OS X operating system (or Windows Subsystem for Linux on Windows)</li>
  <li>CMake <a href="https://cmake.org/download/">https://cmake.org/download/</a> available on the system path</li>
  <li>Bash or Bash compatible shell</li>
  <li>CLang or GCC compiler</li>
  <li>Python 3 and PIP <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
</ol>

<h2 id="quick-installation-guide">Quick Installation Guide</h2>

<p>F¬¥ can be quickly installed and ready to use by cloning the GitHub repository, installing Python code (typically in a
virtual environment), and building on of our reference applications. For full install instructions please see:
<a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a>.</p>

<p><strong>Clone and Install</strong></p>
<div><div><pre><code>git clone https://github.com/nasa/fprime.git
cd fprime
pip install --upgrade wheel setuptools pip
pip install Fw/Python Gds/
</code></pre></div></div>
<p><strong>Build the Ref Application</strong></p>
<div><div><pre><code>cd Ref
fprime-util generate
fprime-util install
</code></pre></div></div>
<p><strong>Run the Ref Application</strong></p>


<h2 id="further-references">Further References</h2>

<p>Full information on the code and F¬¥ are available at our Github page:
<a href="http://github.com/nasa/fprime">http://github.com/nasa/fprime</a>.</p>

<p>To start with, follow the <a href="https://nasa.github.io/fprime/INSTALL.html">installation guide</a>. Then inspect
either the <a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">reference application</a>, 
<a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">rapberry pi reference</a>, or the
<a href="https://nasa.github.io/fprime/Tutorials/README.html">tutorials</a>.</p>

      </section>
    </div></div>]]>
            </description>
            <link>https://nasa.github.io/fprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199346</guid>
            <pubDate>Fri, 19 Feb 2021 23:16:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IDOM ‚Äì It's React, but in Python]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26199008">thread link</a>) | @xdze2
<br/>
February 19, 2021 | https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/ | <a href="https://web.archive.org/web/*/https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article><a download="" href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/article.pdf" title="PDF Export"><svg style="height: 1.2rem; width: 1.2rem;" viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg></a>
              
                
                
                
<p><a href="https://github.com/idom-team/idom" target="_blank">IDOM</a> is a new declarative Python
package for building highly interactive user interfaces.</p>
<ul>
<li><a href="https://github.com/idom-team/idom"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></span> https://github.com/idom-team/idom</a></li>
<li><a href="https://idom-docs.herokuapp.com/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"></path></svg></span> https://idom-docs.herokuapp.com</a></li>
<li><a href="https://github.com/idom-team/idom/discussions"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zM262.655 90c-54.497 0-89.255 22.957-116.549 63.758-3.536 5.286-2.353 12.415 2.715 16.258l34.699 26.31c5.205 3.947 12.621 3.008 16.665-2.122 17.864-22.658 30.113-35.797 57.303-35.797 20.429 0 45.698 13.148 45.698 32.958 0 14.976-12.363 22.667-32.534 33.976C247.128 238.528 216 254.941 216 296v4c0 6.627 5.373 12 12 12h56c6.627 0 12-5.373 12-12v-1.333c0-28.462 83.186-29.647 83.186-106.667 0-58.002-60.165-102-116.531-102zM256 338c-25.365 0-46 20.635-46 46 0 25.364 20.635 46 46 46s46-20.636 46-46c0-25.365-20.635-46-46-46z"></path></svg></span> https://github.com/idom-team/idom/discussions</a></li>
</ul>
<p><a href="https://github.com/idom-team/idom"><img alt="idom logo" src="https://github.com/idom-team/idom/raw/929d07ff4a643320a6148336613621242284f8d2/docs/source/branding/idom-logo.png"></a></p>
<p>IDOM takes inspiration from <a href="https://reactjs.org/" target="_blank">React</a>, and wherever
possible, attempts to achieve parity with the features it copies more directly. Nowhere
is this more evident than the version of React's often lauded
<a href="https://reactjs.org/docs/hooks-intro.html" target="_blank">"Hooks"</a> that IDOM
implements in Python.</p>
<p>At a glance, the similarities between IDOM and React are rather striking. Below is a
React component which defines a simple <code>Counter</code> displaying the number of times a button
has been clicked:</p>
<div><pre><span></span><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>useState</span> <span>}</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>

<span>function</span> <span>Counter</span><span>()</span> <span>{</span>
  <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>);</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)}&gt;</span><span>Click</span> <span>me</span><span>!</span><span>&lt;/</span><span>button</span><span>&gt;</span>
      <span>&lt;</span><span>p</span><span>&gt;{</span><span>`Click count: </span><span>${</span><span>count</span><span>}</span><span>`</span><span>}&lt;/</span><span>p</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>Counter</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span>
</code></pre></div>

<p>And this is the same component implemented in Python using IDOM:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>Counter</span><span>():</span>
    <span>count</span><span>,</span> <span>set_count</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>0</span><span>)</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>button</span><span>(</span>
            <span>{</span><span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>set_count</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)},</span>
            <span>"Click me!"</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>p</span><span>(</span><span>f</span><span>"Click count: </span><span>{</span><span>count</span><span>}</span><span>"</span><span>)</span>
    <span>)</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>Counter</span><span>)</span>
</code></pre></div>

<p>Which, when displayed in your browser, should look something like this:</p>
<p><img alt="click-counter-example" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/click-counter.gif"></p>
<h2 id="why-do-we-need-idom">Why Do We Need IDOM?</h2>
<p>Over the <a href="https://www.npmtrends.com/react-vs-angular-vs-vue" target="_blank">past 5
years</a> front-end
developers seem to have concluded that programs written with a
<a href="https://www.youtube.com/watch?v=yGh0bjzj4IQ" target="_blank">declarative</a> style or
framework tend to be easier to understand and maintain than those done imperatively. Put
more simply, mutable state in programs can quickly lead to unsustainable complexity.
This trend is largely evidenced by the
<a href="https://gist.github.com/tkrotoff/b1caa4c3a185629299ec234d2314e190" target="_blank">rise</a>
of Javascript frameworks like <a href="https://vuejs.org/" target="_blank">Vue</a> and
<a href="https://reactjs.org/" target="_blank">React</a> which describe the logic of computations
without explicitly stating their control flow.</p>
<p><img alt="npm download trends" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/npm-download-trends.png"></p>
<p>So what does this have to do with Python and IDOM? Well, because browsers are the de
facto "operating system of the internet", even back-end languages like Python have had
to figure out clever ways to integrate with them. While standard
<a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST</a> APIs are well
suited to applications built using HTML templates, modern browser users expect a higher
degree of interactivity than this alone can achieve.</p>
<p>A variety of Python packages have since been created to help solve this problem:</p>
<ul>
<li><a href="https://github.com/jupyter-widgets/ipywidgets" target="_blank">IPyWidgets</a> - Adds
  interactive widgets to <a href="https://jupyter.org/" target="_blank">Jupyter Notebooks</a></li>
<li><a href="https://plotly.com/dash/" target="_blank">Dash</a> - Allows data scientists to produces
  enterprise-ready analytic apps</li>
<li><a href="https://www.streamlit.io/" target="_blank">Streamlit</a> - Turns simple Python scripts
  into interactive dashboards</li>
<li><a href="https://docs.bokeh.org/" target="_blank">Bokeh</a> - An interactive visualization
  library for modern web browsers</li>
</ul>
<p>However they each have drawbacks that can make them difficult to use.</p>
<ol>
<li>
<p><strong>Restrictive ecosystems</strong> - UI components developed for one framework cannot be
   easily ported to any of the others because their APIs are either too complex,
   undocumented, or are structurally inaccesible.</p>
</li>
<li>
<p><strong>Imperative paradigm</strong> - IPyWidgets and Bokeh have not embraced the same declarative
   design principles pioneered by front-end developers. Streamlit and Dash on the
   otherhand, are declarative, but fall short of the features provided by React or Vue.</p>
</li>
<li>
<p><strong>Limited layouts</strong> - At their initial inception, the developers of these libraries
   were driven by the visualization needs of data scientists so the ability to create
   complex UI layouts may not have been a primary engineering goal.</p>
</li>
</ol>
<p>A future article will address specific comparisons to each of the projects mentioned
above, but for now, we'll just focus on IDOM and its solutions to these problems.</p>
<h2 id="ecosystem-independence">Ecosystem Independence</h2>
<p>IDOM has a flexible set of core abstractions that allow it to interface with its peers.
At the time of writing, both Jupyter and Dash are supported, while Streamlit and Bokeh
are in the works:</p>
<ul>
<li><a href="https://github.com/idom-team/idom-jupyter" target="_blank">idom-jupyter</a> (try it now
  with
  <a href="https://mybinder.org/v2/gh/idom-team/idom-jupyter/main?filepath=notebooks%2Fintroduction.ipynb" target="_blank">Binder</a>)</li>
<li><a href="https://github.com/idom-team/idom-dash" target="_blank">idom-dash</a></li>
</ul>
<p>By providing well defined interfaces and straighforward protocols, IDOM makes it easy to
swap out any part of the stack with an alternate implementation if you want to. For
example, if you need a different web server for your application, IDOM already has 3
options to choose from or, use as blueprints to create your own:</p>
<ul>
<li><a href="https://github.com/sanic-org/sanic" target="_blank">Sanic</a></li>
<li><a href="https://github.com/pallets/flask" target="_blank">Flask</a></li>
<li><a href="https://github.com/tornadoweb/tornado" target="_blank">Tornado</a></li>
</ul>
<p>You can even target your usage of IDOM in your production-grade applications with IDOM's
Javascript <a href="https://github.com/idom-team/idom-client-react" target="_blank">React client library</a>. Just install
it in your front-end app and connect to a back-end websocket that's serving up IDOM
models. IDOM's own
<a href="https://idom-docs.herokuapp.com/docs/index.html" target="_blank">documentation</a> acts as
a prime example for this targeted usage - most of the page is static HTML, but embedded
in it are interactive examples that feature live views being served from a web socket:</p>
<p><img alt="live-examples-in-docs" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/live-examples-in-docs.gif"></p>
<h2 id="declarative-components">Declarative Components</h2>
<p>IDOM, by adopting the hook design pattern from React, inherits many of its aesthetic and
functional characteristics. For those unfamiliar with hooks, user interfaces are
composed of basic <a href="https://en.wikipedia.org/wiki/HTML_element" target="_blank">HTML elements</a> that are
constructed and returned by special functions called "components". Then, through the
magic of hooks, those component functions can be made to have state. Consider the
component below which displays a basic representation of an
<a href="https://en.wikipedia.org/wiki/AND_gate" target="_blank">AND-gate</a>:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>AndGate</span><span>():</span>
    <span>input_1</span><span>,</span> <span>toggle_1</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>input_2</span><span>,</span> <span>toggle_2</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_1</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_2</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>pre</span><span>(</span><span>f</span><span>"</span><span>{</span><span>input_1</span><span>}</span><span> AND </span><span>{</span><span>input_2</span><span>}</span><span> = </span><span>{</span><span>input_1</span> <span>and</span> <span>input_2</span><span>}</span><span>"</span><span>),</span>
    <span>)</span>

<span>def</span> <span>use_toggle</span><span>():</span>
    <span>state</span><span>,</span> <span>set_state</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>False</span><span>)</span>

    <span>def</span> <span>toggle_state</span><span>():</span>
        <span>set_state</span><span>(</span><span>lambda</span> <span>old_state</span><span>:</span> <span>not</span> <span>old_state</span><span>)</span>

    <span>return</span> <span>state</span><span>,</span> <span>toggle_state</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>AndGate</span><span>)</span>
</code></pre></div>

<p><img alt="and-gate-demo" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/and-gate.gif"></p>
<p>Here's a very high level summary of how it works... the first time a view of the
component above is rendered, the <code>AndGate</code> function is called where its initial <code>state</code>
for <code>input_1</code> and <code>input_2</code> is <code>False</code>. The function then returns a series of HTML
elements with callbacks that respond to client-side events. Machinery behind the scenes
subsequently realizes that declaration and displays two checkbox buttons with the text
<code>False AND False = False</code>. Later, when a user clicks the now visible checkbox buttons,
client-side events are triggered, the associated callbacks respond by inverting the old
<code>state</code> from <code>False</code> to <code>True</code>, and a re-render of the component is scheduled. When
re-rendering, the function is again called, this time though, where <code>input_1</code> and
<code>input_2</code> have been updated to reflect the new <code>state</code>, thus causing the displayed text
to change.</p>
<p>In the code above, consider the fact that it never explicitely describes how to evolve
the frontend view when events occur. Instead, it declares that, given a particular
state, this is how the view should look. It's then IDOM's responsibility to figure out
how to bring that declaration into being. This behavior of defining outcomes without
stating the means by which to achieve them is what makes components in IDOM and React
"declarative". For comparison, a hypothetical, and a more imperative approach to
defining the same interface might look similar to the following:</p>
<div><pre><span></span><code><span>layout</span> <span>=</span> <span>Layout</span><span>()</span>

<span>def</span> <span>make_and_gate</span><span>():</span>
    <span>state</span> <span>=</span> <span>{</span><span>"input_1"</span><span>:</span> <span>False</span><span>,</span> <span>"input_2"</span><span>:</span> <span>False</span><span>}</span>
    <span>output_text</span> <span>=</span> <span>html</span><span>.</span><span>pre</span><span>()</span>
    <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>def</span> <span>toggle_input</span><span>(</span><span>index</span><span>):</span>
      <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span> <span>=</span> <span>not</span> <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span>
      <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>return</span> <span>html</span><span>.</span><span>div</span><span>(</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>1</span><span>)}</span>
        <span>),</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>2</span><span>)}</span>
        <span>),</span>
        <span>output_text</span>
    <span>)</span>

<span>def</span> <span>update_output_text</span><span>(</span><span>text</span><span>,</span> <span>state</span><span>):</span>
    <span>text</span><span>.</span><span>update</span><span>(</span>
        <span>children</span><span>=</span><span>"</span><span>{input_1}</span><span> AND </span><span>{input_2}</span><span> = </span><span>{output}</span><span>"</span><span>.</span><span>format</span><span>(</span>
            <span>input_1</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>],</span>
            <span>input_2</span><span>=</span><span>state</span><span>[</span><span>"input_2"</span><span>],</span>
            <span>output</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>]</span> <span>and</span> <span>state</span><span>[</span><span>"input_2"</span><span>],</span>
        <span>)</span>
    <span>)</span>

<span>layout</span><span>.</span><span>add_element</span><span>(</span><span>make_and_gate</span><span>())</span>
<span>layout</span><span>.</span><span>run</span><span>()</span>
</code></pre></div>

<p>In this imperative incarnation there are several disadvantages:</p>
<ol>
<li>
<p><strong>Refactoring is difficult</strong> - Functions are much more specialized to their
   particular usages in <code>make_and_gate</code> and thus cannot be easily generalized. By
   comparison, <code>use_toggle</code> from the declarative implementation could be applicable to
   any scenario where boolean indicators are toggled on and off.</p>
</li>
<li>
<p><strong>No clear static relations</strong> - There is no one section of code through which to
   discern the basic structure and behaviors of the view. This issue is exemplified by
   the fact that we must call <code>update_output_text</code> from two different locations. Once in
   the body of <code>make_and_gate</code> and again in the body of the callback <code>toggle_input</code>.
   This means that, to understand what the <code>output_text</code> might contain, we must also
   understand all the business logic that surrounds it.</p>
</li>
<li>
<p><strong>Referential links cause complexity</strong> - To evolve the view, various callbacks must
   hold references to all the elements that they will update. At the outset this makes
   writing programs difficult since elements must be passed up and down the call stack
   wherever they are needed. Considered further though, it also means that a function
   layers down in the call stack can accidentally or intentionally impact the behavior
   of ostensibly unrelated parts of the program.</p>
</li>
</ol>
<h2 id="virtual-document-object-model">Virtual Document Object Model</h2>
<p>To communicate between their back-end Python servers and Javascript clients, IDOM's
peers take an approach that aligns fairly closely with the
<a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller" target="_blank">Model-View-Controller</a>
design pattern - the controller lives server-side (though not always), the model is
what's synchronized between the server and client, and the view is run client-side in</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</a></em></p>]]>
            </description>
            <link>https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199008</guid>
            <pubDate>Fri, 19 Feb 2021 22:43:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koo, India‚Äôs free-speech Twitter alternative]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 189 (<a href="https://news.ycombinator.com/item?id=26196588">thread link</a>) | @donohoe
<br/>
February 19, 2021 | https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p>It hasn‚Äôt been a quiet few weeks on Twitter in India. The country‚Äôs capital city has seen over four months of protest after Prime Minister Narendra Modi‚Äôs government enacted agricultural laws that would adversely affect farmers across India. <a href="https://www.bbc.com/news/world-asia-india-55899754">The farmer protests</a>, as the movement has come to be known, has taken to social media platforms like Twitter and Facebook to make the cause heard globally ‚Äî and it‚Äôs worked. Earlier this month, celebrities like <a href="https://www.dw.com/en/greta-thunberg-under-fire-for-tweeting-about-indian-farmers-toolkit/a-56458306">Greta Thunberg</a> and <a href="https://www.bbc.com/news/world-asia-india-55931894">Rihanna</a> weighed in with their tweets of support. Backlash <a href="https://www.bbc.com/news/world-asia-india-55931894">soon followed</a>.&nbsp;</p>



<p>But the government‚Äôs ire against global critics of Modi‚Äôs Hindu nationalist party has turned to Twitter itself. Citing threats to public order, on February 1, Indian authorities <a href="https://www.buzzfeednews.com/article/pranavdixit/indian-government-block-critics">appeared to have requested Twitter to suspend or remove</a> dozens of accounts on its platform. Twitter briefly complied but, after public outcry, reinstated the accounts and then <a href="https://www.cjr.org/the_media_today/twitter-stands-up-to-india-and-refuses-to-block-journalists.php">refused to remove</a> hundreds more.</p>



<p>It‚Äôs in the middle of this battle that Aprameya Radhakrishna‚Äôs 10-month-old social media platform was thrust into the spotlight. Soft-spoken and studious, Radhakrishna is a serial entrepreneur: in 2015, <a href="https://economictimes.indiatimes.com/magazines/panache/taxiforsure-founder-aprameya-radhakrishnas-life-after-sell-off/articleshow/48078627.cms">he sold his first company</a>, a ride-sharing app called TaxiForSure, to local giant Ola for $200 million. His latest venture is an app called Koo, <a href="https://www.kooapp.com/">a microblogging platform similar to Twitter</a> but for local-language speakers in India, a country with more than 20 languages and over 700 dialects.&nbsp;</p>



<p>After weeks of battling with Twitter, some of India‚Äôs most prominent Hindu nationalist politicians took to their social accounts and instructed their followers to leave Western social networks for Koo, a local, free-speech platform. ‚ÄúI am now on Koo,‚Äù <a href="https://twitter.com/PiyushGoyal/status/1359058583934013442">tweeted</a> India‚Äôs minister of commerce and industry, Piyush Goyal. ‚ÄúConnect with me on this Indian micro-blogging platform for real-time, exciting and exclusive updates.‚Äù Many of his <a href="https://twitter.com/PiyushGoyal">9.6 million followers</a> obliged. More right-wing politicians <a href="https://twitter.com/rsprasad/status/1360067772571545606?s=20">followed suit</a>, as did some of <a href="https://twitter.com/KanganaTeam/status/1361421114220576768">Bollywood</a>‚Äôs biggest stars.&nbsp;</p>



<p>Overnight, the platform went from a relatively obscure app to <a href="https://timesofindia.indiatimes.com/business/india-business/koo-lines-up-indian-investors-as-popularity-surges/articleshow/80867206.cms">headline news</a> and bagged <a href="https://economictimes.indiatimes.com/tech/funding/microblogging-platform-koo-bags-4-1-million-in-funding/articleshow/80685024.cms">$4.1 million in series A funding</a>.&nbsp;</p>



<p>Radhakrishna and his platform are in a curious position. The founder insists he‚Äôs apolitical ‚Äî he‚Äôs appeared in both <a href="https://www.ndtv.com/video/news/news/koo-app-everything-you-need-to-know-about-koo-the-indian-alternative-to-twitter-575160">left-leaning</a> and <a href="https://www.opindia.com/2021/02/rahul-roushan-aprameya-radhakrishna-koo-co-founder-twitter-alternative-made-in-india-interview/">right-wing</a> outlets in the days since Koo has found the limelight ‚Äî but is happily embracing the sudden rush to his app: Koo crossed <a href="https://www.livemint.com/technology/apps/koo-sees-10-fold-increase-in-downloads-this-week-crosses-3-million-users-11613038170243.html">3 million users </a>this month, fueled in large part by Modi‚Äôs party.&nbsp;</p>



<p>And while it‚Äôs unclear whether Koo will follow in the path of other social platforms <a href="https://www.usatoday.com/story/tech/2020/11/11/parler-mewe-gab-social-media-trump-election-facebook-twitter/6232351002/">that espouse ‚Äúfree speech‚Äù ideology</a>, it‚Äôs likely more Indian apps like Radhakrishna‚Äôs will follow. Prominent among Modi‚Äôs mantras for his vision of India is <em>Atmanirbhar Bharat: </em>a self-sufficient India. That vision <a href="https://restofworld.org/2021/indias-hashtag-war/">extends to the internet and social media</a>.&nbsp;</p>



<p>Six months before prominent right-wing politicians began heralding his app as India‚Äôs Twitter, Radhakrishna and his team submitted Koo to a government <em>atmanirbhar </em>social media challenge, <a href="https://navbharattimes.indiatimes.com/business/business-news/koo-app-wins-pm-modi-aatm-nirbhar-app-innovation-challenge/articleshow/77432196.cms">and won</a>.</p>



<p>Radhakrishna spoke to <em>Rest Of World </em>over Google Meet from Bangalore. This conversation has been edited for length and clarity.</p>



<hr>



<h4><strong>Tell me a bit about how you came up with the idea for Koo.&nbsp;</strong></h4>



<p>We started building it in November 2019 and launched it in March 2020. The idea behind it was that Twitter is existing in English in India, but the language speakers of India are not on Twitter. Let‚Äôs build a deeper experience for the language speakers. And because we built a deeper experience for the language speakers, we were able to make a very localized community.&nbsp;</p>



<p>We started with Kannada, then we did Hindi, then Telugu, Marathi, then Tamil: we launched all of these languages. Then, we started noticing Twitter was getting into trouble in the U.S. We said, Maybe we should just have English as well as the local languages, if ever Twitter gets into trouble or users want a separate option.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-40x71.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-400x711.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1067.jpg 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="Aprameya Radhakrishna, a serial entrepreneur sold his first company, a ride-sharing app called TaxiForSure, for $200 million.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Aprameya Radhakrishna</span>
			</figcaption>
		</figure>


<h4><strong>When you started Koo, how soon were you approached by government officials who saw the </strong><a href="http://www.makeinindia.com/about"><strong>‚ÄúMake in India‚Äù</strong></a><strong> potential for the app?&nbsp;</strong></h4>



<p>We were a two-month-old app when we applied to the <a href="https://innovate.mygov.in/app-challenge/">[<em>Atmanibhar Bharat</em>]</a> challenge. We got into that challenge at the last minute, almost. Nobody approached us or anything. We applied just like any other startup ‚Äî there were something like 7,000 social media startups that applied. We won that challenge, so that put us into the limelight: Oh, there‚Äôs an alternative microblogging platform that promotes local language<em>.&nbsp;</em></p>



<h4><strong>Walk me through how the last two or three weeks have been for you. Did you know that Piyush Goyal and the Ministry of Electronics and Technology would be encouraging their followers on Twitter to move to Koo en masse?&nbsp;</strong></h4>



<p>No. It‚Äôs been totally surreal for us. It‚Äôs totally welcome at Koo. We as a company are benefiting from the love that users who are shifting [from Twitter] are showing us. We weren‚Äôt expecting it, but it‚Äôs a pleasant surprise. We‚Äôre happy this move is happening.&nbsp;</p>



<h4><strong>Were you prepared for the sudden influx of users on the back end?&nbsp;</strong></h4>



<p>Not at all. Scaling 10x suddenly, in a week, is a challenge for any company, especially a 10-month-old startup. But we‚Äôve come through it; we are able to scale faster.&nbsp;</p>



<h4><strong>What were the user numbers like? Can you tell me how quickly they grew after the events of this month?&nbsp;</strong></h4>



<p>We were very small, we were sub-100,000 DAU [daily active users]. Now we‚Äôre close to a million DAU. Close, not a million yet but close.&nbsp;</p>



<h4><strong>By virtue of chance, or deliberate action, there‚Äôs an ideological framework under which Koo has been positioned. You don‚Äôt seem bothered by the fact that Koo is heralded </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>as the right-wing‚Äôs answer to Twitter</strong></a><strong>. Politics has played a role in the sudden attention that Koo has received. Have you considered the risks of embracing the way your app has been politicized?&nbsp;</strong></h4>



<p>It depends on the actions on the app. That first community [we built] in Kannada was built in a slower manner, and it has people from all parties in Karnataka.&nbsp;</p>



<p>What we are seeing is that India wants to be more self-reliant. India includes everybody. Our app doesn‚Äôt understand ‚Äúleft‚Äù or ‚Äúright.‚Äù <em>I </em>don‚Äôt understand ‚Äúleft‚Äù or ‚Äúright.‚Äù I‚Äôm an entrepreneur; I‚Äôm extremely apolitical. And I‚Äôm all for the development of the country. If Koo as a statement can make us self-reliant on our own social networks and technology, then we should be cheering for it. We shouldn‚Äôt unnecessarily politicize it.</p>



<h4><strong>Social media is shaped by its users and early adopters. Most of Koo‚Äôs early video content partnerships with, say, Republic TV [a channel </strong><a href="https://www.theguardian.com/media/2020/dec/23/indian-news-channel-fined-in-uk-for-hate-speech-about-pakistan"><strong>notorious for its allegiance</strong></a><strong> with the ruling Hindu nationalist party] or Mitron [a short-form video app that Modi supporters </strong><a href="https://www.techradar.com/news/mitron-app-gives-tiktok-a-challenge-will-it-sustain-though"><strong>have embraced after the ban on TikTok</strong></a><strong>] have come to associate the app with a particular ideology. Are you worried Koo might get too polarized too quickly?&nbsp;</strong></h4>



<p>Not at all. In Karnataka, we have everybody [on Koo], as I said. As a business, we keep looking for partners to grow our business. Now, the partners who come aggressively and see the vision that we‚Äôre seeing as a free-expression platform and embrace the platform, we‚Äôre happy to welcome them. Why would I say no to somebody who wants to use our platform? Republic [TV] came first, that doesn‚Äôt mean I don‚Äôt want everybody else.&nbsp;</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone1-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone3-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone4-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone2-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>On Koo‚Äôs Hindi language setting, it‚Äôs easy to find the accounts of several of India‚Äôs biggest Hindu nationalist politicians next to celebrities and right-leaning media channels. The majority of the app‚Äôs top trending hashtags in Hindi are pro-Modi.</figcaption>
    </figure>


<h4><strong>In a recent BBC report about your app, there‚Äôs a rhetorical question, </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>‚ÄúIs Koo India‚Äôs Parler?‚Äù</strong></a><strong> What do you make of that comparison?&nbsp;</strong></h4>



<p>Each platform comes into being for different reasons. I‚Äôve already explained my story. We were doing this irrespective of whether Twitter existed, got banned, got into trouble, or flourished in India.&nbsp;</p>



<p>We started in November 2019 because we said the voice of the Indian user who doesn‚Äôt speak English is not there. We are building an inclusive social media network for India. So what was your question?&nbsp;</p>



<h4><strong>My question was what do you make of Parler and‚Äî</strong></h4>



<p>Parler came into existence because there was an anti-Trump thing, and they wanted to do a pro-Trump thing. We don‚Äôt exist because of some anti or pro thing. We are existing today irrespective of whether Twitter gets into trouble or not, irrespective of one ideology being there or not. We exist because we want to give a voice to every Indian. The purpose of our existence is very different from what a Parler is.&nbsp;</p>



<h4><strong>What do you make of the ‚ÄúMake in India‚Äù push, considering Facebook and Twitter have </strong><a href="https://www.nytimes.com/2021/01/14/technology/trump-facebook-twitter.html"><strong>an undeniable influence</strong></a><strong> in our current political discourse?</strong></h4>



<p>Every social media [platform] has to be responsible, to a certain extent, of what they bring into a country because it defines a lot of things in the country, like youth culture or how citizens of a country react to a situation.&nbsp;</p>



<p>When a company is registered elsewhere and doesn‚Äôt take into consideration the nuances of the local culture, I think it can be dangerous. Indian entrepreneurs building for Indian cultural nuances is better than somebody who doesn‚Äôt understand the cultural nuances trying to build for India.</p>



<figure><blockquote><p>‚ÄúIndian entrepreneurs building for Indian cultural nuances is better than somebody who doesn‚Äôt understand the cultural nuances trying to build for India.‚Äù</p></blockquote></figure>



<h4><strong>The way Indian internet is shaping, </strong><a href="https://restofworld.org/2021/indias-hashtag-war/"><strong>an extreme version of ‚ÄúIndian apps for India‚Äù</strong></a><strong> is an entire separate internet for India, the way China has Weibo and its own social network. Do you think that kind of internet would be a good thing for India as a whole?&nbsp;</strong></h4>



<p>Absolutely, we should have our own <em>atmanirbhar</em> platforms. We ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196588</guid>
            <pubDate>Fri, 19 Feb 2021 18:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cleaner parallel curves with Euler spirals]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26196470">thread link</a>) | @raphlinus
<br/>
February 19, 2021 | https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!-- I should figure out a cleaner way to do this include, rather than cutting and pasting. Ah well.-->




<p><img src="https://raphlinus.github.io/assets/euler-parallel-flower.svg" alt="Many parallel curve of an Euler spiral, resembling a flower"></p>

<p>Determining <a href="https://en.wikipedia.org/wiki/Parallel_curve">parallel curves</a> is one of the basic 2D geometry operations. It has obvious applications in graphics, being the basis of creating a stroke outline from a path, but also in computer aided manufacturing (determining the path of a milling tool with finite radius) and path planning for robotics. There are plenty of solutions in the literature by now, but in this post I propose a cleaner solution.</p>

<p>A good survey paper is <a href="https://www.semanticscholar.org/paper/Comparing-Offset-Curve-Approximation-Methods-Elber-Lee/9ac1978746ec54bdd555b906e2ea1eb922cd6ffd">Comparing Offset Curve Approximation Methods</a>. The main difference between these approaches is the choice of curve representation. An example of a curve representation highly specialized for deriving parallel curves is the <a href="https://www.semanticscholar.org/paper/Pythagorean-hodographs-Farouki-Sakkalis/e20aeb60de908061797b6eaf3af79fdc7e5acdd7">Pythagorean Hodograph</a>. This parallel curve of a Pythagorean Hodograph is an exact parametric polynomial curve, but approximation techniques are still needed in practice, both to convert the source curve into the representation, and because the resulting curves are higher order rational polynomials, which require further approximation to convert into, say, cubic B√©ziers.</p>

<p>Specifically, this blog proposes piecewise Euler spirals as a curve representation particularly well suited to the parallel curve problem.</p>

<p>There‚Äôs an implementation of many of these ideas (currently still in PR stage) in <a href="https://github.com/linebender/kurbo/pull/169">kurbo</a>. I also used a colab notebook to explore a bunch of the math, and I‚Äôve made a <a href="https://github.com/raphlinus/raphlinus.github.io/blob/master/assets/Euler_spiral_scratchpad.ipynb">copy of that available</a> as well.</p>

<h2 id="the-cusp">The cusp</h2>

<p>One of the things that makes parallel curves special is that cusps often appear. In particular, a cusp appears whenever the radius of curvature of the source curve matches the offset. This is classified as an <a href="https://en.wikipedia.org/wiki/Cusp_(singularity)">ordinary cusp</a> and is a feature of many curve families ‚Äì we‚Äôll quantify that a bit more below.</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-cusp.svg" alt="Parallel curve of an Euler spiral, showing the cusp"></p>

<p>A common feature of algorithms for computing parallel curves is identifying the location of the cusp, and subdividing there. That basically means solving for the specific value of curvature (the reciprocal of the offset distance). If the source curve is a cubic B√©zier, there can be up to four such cusps, and finding them requires some nontrivial numerical solving.</p>

<h2 id="curvature-as-a-function-of-arclength">Curvature as a function of arclength</h2>

<p>A theme of my approach to parallel curves (and much of my curve work in general, including my <a href="https://www.levien.com/phd/phd.html">thesis</a>), is to consider the relationship of curvature to arclength. A concrete intuition is that it is the position of the steering wheel as a car drives along the curve at constant speed. For some curves, curvature can be represented as a closed-form analytical formula as a function of arclength (the <a href="https://en.wikipedia.org/wiki/Ces%C3%A0ro_equation">Ces√†ro equation</a>), but in general determining the relation requires numerical techniques. For example, in the <a href="https://levien.com/euler_explorer/">Euler explorer</a>, there‚Äôs a plot of curvature as a function of arclength below the interactive cubic B√©zier. Experimenting with that is an excellent way to develop intuition.</p>

<p>One curve that <em>does</em> have an especially simple Ces√†ro equation is the Euler spiral. An Euler spiral segment has this formula:</p><p>

\[\kappa(s) = \kappa_0 + \kappa_1 s\]

</p><p>(A note for those trying to follow along with the detailed math and code: most of the math and numerical code uses $-0.5 \leq s \leq 0.5$ because it helps exploit even/odd symmetries, but the convention for parametrized curves, including the <a href="https://docs.rs/kurbo/0.8.0/kurbo/trait.ParamCurve.html">ParamCurve</a> trait in kurbo, is $0 \leq s \leq 1$. Thus, you‚Äôll frequently see offsets of 0.5. Similarly, you‚Äôll see various scaling to the actual arc length, while the parametrized curve convention assumes an arc length of 1. In this blog, we‚Äôll skim over such details, as the goal is to provide intuition without too much clutter from details.)</p>

<h2 id="the-parallel-curve-of-an-euler-spiral">The parallel curve of an Euler spiral</h2>

<p>In general, most curves do not have a simple formula for their parallel curve. The obvious exception is a circular arc, for which the parallel curve is another circular arc. Another curve family with tractable representation for its parallel curve is Pythagorean Hodographs.</p>

<p>Thanks to its exceptionally simple formulation as a Ces√†ro equation, the Euler spiral is one of the rare curves with a simple closed-form equation for its parallel curve. That equation was first published in a 1906 paper by Heinrich Wieleitner, <a href="https://books.google.com/books?id=UvpZAAAAYAAJ&amp;pg=PA373&amp;lpg=PA373&amp;dq=%22Die+Parallelkurve+der+Klothoide%22&amp;source=bl&amp;ots=fuY39VdPpd&amp;sig=K0AbL03rXAm_g4J9KsheQbbxyaA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiUrcD1poTfAhVvFjQIHVthBPoQ6AEwAnoECAMQAQ#v=onepage&amp;q=%22Die%20Parallelkurve%20der%20Klothoide%22&amp;f=false">Die Parallelkurve der Klothoide</a>. For those who don‚Äôt read German, <a href="https://github.com/Rahix">Rahix</a> has kindly provided a translation into English: <a href="https://raphlinus.github.io/assets/clothoids.pdf">PDF</a>, <a href="https://raphlinus.github.io/assets/clothoids.text">TeX source</a>.</p>

<p>Going over this math, I see Wieleitner missed an opportunity for further simplification. The style at the time was to write the Ces√†ro equation in terms of the <em>radius</em> of curvature (the reciprocal of curvature), but especially for the Euler spiral and its parallel curve, using curvature directly yields a much simpler equation. With the cusp located at $s_0$, the equation is gratifyingly simple:</p><p>

\[\kappa(s) = \frac{c}{\sqrt{s - s_0}} + \frac{1}{l}\]

</p><p>The equation is graphed below, and clicking on it links to a <a href="https://www.desmos.com/calculator/qznzk9xnac">Desmos calculator graph</a> with sliders for the parameters.</p>

<p><a href="https://www.desmos.com/calculator/qznzk9xnac"><img src="https://raphlinus.github.io/assets/euler-spiral-parallel-cesaro.png" width="400" height="400"></a></p>

<p>Here $c$ is a coefficient dependent on the parameters of the spiral. To connect it to the notation in the Wieleitner paper, $c = a / \sqrt{2 l^3}$, and $s_0 = -a^2/{2l}$. I‚Äôve also made a <a href="https://www.desmos.com/calculator/imvqywsb8o">Desmos calculator graph</a> that interactively demonstrates the equivalence of this equation and the more involved one from the Wieleitner paper.</p>

<p>There are a number of other curves that have a cusp similar to the above, with characteristic inverse-square root curvature. The clearest connection is the <a href="https://en.wikipedia.org/wiki/Involute">circle involute</a>, which is the same but without the $1/l$ term, or in other words the Euler spiral parallel curve approaches the circle involute as the offset goes to infinity. This provides intuition for the fact that a circle involute is its own parallel curve. The circle involute is perhaps most famous as the optimized profile for meshing <a href="https://ciechanow.ski/gears/">gear</a> teeth, transferring force smoothly with no slop or friction.</p>

<p>Other curves with a similar cusp include the <a href="https://en.wikipedia.org/wiki/Cycloid">cycloid</a> (as well as its many variants including epicycloid, hypocycloid, astroid, deltoid, cardioid, and nephroid), as well as the <a href="https://en.wikipedia.org/wiki/Semicubical_parabola">semicubical parabola</a>. The latter is of particular interest because it can be exactly represented as a case of a cubic B√©zier (it is when the control arms form a symmetrical X).</p>

<p><img src="https://raphlinus.github.io/assets/semicubical_parabola.svg" alt="semicubical parabola"></p>

<p>The parallel curve of the Euler spiral is perfectly cromulent, and, following the tradition of Pythagorean Hodograph curves and their higher-order rational polynomials, we could simply require everything downstream to simply deal with them. But to make that downstream processing easier, we will convert back to piecewise Euler spirals, a more tractable representation.</p>

<h2 id="geometric-hermite-interpolation">Geometric Hermite interpolation</h2>

<p><a href="https://en.wikipedia.org/wiki/Hermite_interpolation">Hermite interpolation</a> is a well known technique. In its simplest form, it is used to generate a piecewise polynomial approximation to some function, where the parameters for each polynomial segment are determined from the values and derivatives of the endpoints. For example, in cubic Hermite interpolation, a cubic polynomial is determined from the values and first derivatives at the endpoints ‚Äì four values, corresponding to four coefficients for the polynomial. The result is C1 continuous as the derivatives exactly match (and are equal to the source curve).</p>

<p>In 2D, there is a distinction between C1 and G1 (geometric) continuity. In C1 continuity, the full derivatives must match, both direction and magnitude. For applications such as animating motion curves, the magnitude is important (it represents speed of motion), but for curves, it is not. G1 continuity requires that the tangents match, but does not specify the magnitude of the derivatives.</p>

<p>In these applications, geometric Hermite interpolation is more efficient, as all parameters of the curve are available to make the shape fit. The Euler spiral is especially well suited to geometric Hermite interpolation, and there is literature on this topic. For reasonable assumptions of smoothness (excluding fractal curves but including simple cusps), the accuracy scales as $O(n^4)$ ‚Äì a doubling of the number of subdivisions reduces the error by a factor of 16. This scaling is the same as cubic Hermite interpolation of a 1D function, not surprising as an Euler spiral segment approximates a cubic polynomial when $y$ values are small.</p>

<p>Section 8.2 of my <a href="https://www.levien.com/phd/phd.html">thesis</a> provides a secant method for determining the Euler spiral parameters from the G1 Hermite constraints, and that‚Äôs implemented in the <code>fit_euler</code> method in the <a href="https://github.com/linebender/kurbo/pull/169">kurbo PR</a>. That‚Äôs a good technique and its convergence is excellent (quadratic, as typical for Newton-style solvers for near-linear problems), but I‚Äôve also been experimenting with ways to do it better. The linked notebook explores a polynomial approximation (based on 2D Taylor‚Äôs series) that is much faster ‚Äì 7ns vs 240ns in my measurements, and should be very accurate over a wide range of parameters. I‚Äôm not quite done making the error bounds rigorous, but this approach should help make the overall algorithm lightning-fast.</p>

<p>Geometric Hermite interpolation works well to approximate the parallel curve of an Euler spiral segment with another Euler spiral segment:</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-approx.svg" alt="Approximation of the parallel curve of an Euler spiral segment"></p>

<p>The true parallel curve is in blue, and the approximation in red. It has the same rough shape, but bulges out in the middle. We need to be able to estimate that error in order to make a more accurate approximation.</p>

<h3 id="a-simple-accurate-error-metric">A simple, accurate error metric</h3>

<p>The most common approach to approximation given a target error bound is adaptive subdivision: approximate the error, and if it exceeds the target, subdivide. Evaluating the error is not always easy; most generally, it‚Äôs based on numerical techniques such as evaluating the curve at several points along its length and testing how near those points lie to the source curve.</p>

<p>Fortunately, for approximating an Euler spiral parallel curve using an Euler spiral, there is an extremely simple formula for the error. In fact, it‚Äôs possible to avoid the adaptive subdivision altogether, and precisely predict how many subdivisions are needed to meet an error bound, as well as analytically place the subdivisions so each segment has the same error.</p>

<p>Normalized to a chord length of 1, where the arc ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196470</guid>
            <pubDate>Fri, 19 Feb 2021 18:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Researchers looking for mRNA were ridiculed by colleagues]]>
            </title>
            <description>
<![CDATA[
Score 423 | Comments 179 (<a href="https://news.ycombinator.com/item?id=26196372">thread link</a>) | @fortran77
<br/>
February 19, 2021 | https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/ | <a href="https://web.archive.org/web/*/https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sixty years ago, the scientists who were pioneering the technology that would make today's COVID-19 vaccines possible were mocked and dismissed</p><div>
																		<p>A few days before Christmas, Matthew Meselson, a 90-year-old professor at Harvard, called his university‚Äôs health service to inquire about being vaccinated against COVID-19. He was eager for his shot. Meselson felt imprisoned in his Cambridge apartment, just blocks from the campus where he‚Äôd worked for six decades. He‚Äôd officially retired from teaching at the beginning of 2020, but continued his research as much as possible throughout the pandemic, wearing a K95 mask to work in his lab.</p>
<p>He longed to re-engage in the world around him. He missed his weekly date with close friends over lunch at Boston‚Äôs best French restaurant; they‚Äôd switched to Zoom, but staring into a computer screen is no replacement for lingering at linen-covered tables. He longed for his wife of 32 years, Jeanne Guillemin, who died from cancer late in 2019. Meselson was still figuring out how his world worked without her, and isolation made this hard task harder.</p>
<p>The person on the other end of the phone apologized to the professor. ‚ÄúWe don‚Äôt have a vaccine schedule yet,‚Äù she told him.</p>
<p>The first two COVID-19 vaccines to be approved for use in North America were developed, tested and delivered into freezers before many jurisdictions figured out how to administer them. The vaccines from Pfizer-BioNTech and Moderna are the first approved vaccines ever to employ modified mRNA, which is delivered sealed in a lipid shell. The mRNA slips into our cells, carrying instructions to make antibodies that target SARS-CoV-2. The vaccines function almost like a wanted poster: if you see these guys, get ‚Äôem. Then, the mRNA degrades, leaving no trace.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/covid-19-vaccines-curbing-pandemic-vaxx-populi/">How quickly will the COVID-19 vaccines start curbing the pandemic in Canada?</a></strong></p></blockquote>
<p>The fact that mRNA is the basis of these vaccines contributed to their rapid development. In November, the <em>New York Times</em> reported that within two days of China releasing the genetic sequence of SARS-CoV-2, scientists at Moderna Inc., a 10-year-old company headquartered not far from Meselson‚Äôs home in Cambridge, ‚Äúplugged that data into its computers and came up with a design for an mRNA vaccine.‚Äù Meanwhile, BioNTech, a small biotech company in Germany that had been working on mRNA flu vaccines with the pharmaceutical powerhouse Pfizer, soon similarly turned its resources to generating an mRNA COVID vaccine.</p>
<p>But these fastest vaccines in history have been decades in the making. They‚Äôre the product of generations of scientists who built on one idea after another, and kept at it despite failed experiments, rejections, threats of deportation, a lack of funding and skepticism from contemporaries. They were inspired by the discovery of DNA: in 1951, a young English physical chemist named Rosalind Franklin took X-ray photographs that captured DNA‚Äôs helical shape; two years later, James Watson and Francis Crick of Cambridge University published the first report describing DNA‚Äôs double helix, for which they received the Nobel Prize. (Franklin died of ovarian cancer in 1958; her contributions were largely overlooked in her lifetime.) And they were driven not by a race to halt a raging pathogen or by the chance to patent a multi-billion-dollar drug, but by one big, irresistible question: What makes life?</p>
<p>‚ÄúThese weren‚Äôt people who wanted to solve little problems,‚Äù says Meselson. ‚ÄúThese were people who wanted to solve a great big problem.‚Äù</p>
<p>He was one of them.</p>
<p>***</p>
<p>Born in Colorado in 1930, Meselson zipped through the sciences at a young age. By 16, he enrolled at the University of Chicago. In 1957, while doing post-doctoral work at the California Institute of Technology (Caltech), Meselson and Frank Stahl demonstrated how DNA replicates itself, a model that had been suggested but never shown. Science historian Frederic Lawrence Holmes later characterized their work as ‚Äúthe most beautiful experiment in biology,‚Äù having revealed how life worked.</p>
<p>But many unanswered questions remained about what happens inside our cells. Meselson and colleagues knew that DNA resides in the nucleus, a compartment barricaded off from the rest of the cell by a membrane. On the other side of the membrane is the cytoplasm, a gelatinous liquid that fills the remainder of the cell. This is the home of tiny granules called ribosomes, which house RNA.</p>
<p>Around the same time that Meselson and Stahl published their groundbreaking work on DNA, French scientists discovered that cells made proteins through the ribosomes. DNA, despite holding the critical codes for life, is a relatively passive molecule. Ribosomes do the busy labour, building proteins to carry out the biological processes of survival. The question was how?</p>
<p>One of the French scientists, Dr. Fran√ßois Jacob, theorized that there must be an ‚Äúunstable intermediary‚Äù that went between the DNA and the RNA‚Äîsending messages from the DNA to the RNA, and then disappearing.</p>
<p>Jacob, a physician who‚Äôd been forced from medical school when Germany invaded France in 1940 and spent the war years fighting with Charles de Gaulle‚Äôs Free French Forces, called this theoretical intermediary ‚ÄúX.‚Äù Other researchers ‚Äúrolled their eyes in horror‚Äù when he presented his theory, Jacob recalled in his memoir, <em>The Statue Within</em>. ‚ÄúWith a little encouragement, my audience would have jeered and left,‚Äù he wrote.</p>
<div id="attachment_1216833"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/MATTHEW-MESELSON-DNA-FRANGOU-FEB02-766x431.jpg" alt="Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)" width="766" height="431"></p><p>Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)</p></div>
<p>In spring 1960, Jacob wrote to Meselson with a proposal: he and Sydney Brenner, a South African biologist at the University of Cambridge, would meet at Meselson‚Äôs lab at Caltech to find X. Meselson, who was in his first year on faculty, had developed a technique to track smaller molecules inside a cell. Jacob believed this technique would help identify X. That summer, with Jacob and Brenner in his lab, Meselson set up initial cultures and tests. Brenner took over the operations, while Jacob sat in a chair taking notes‚Äîpain from bomb fragments in his legs was worsened by the California humidity, says Meselson. For three weeks, they met with one failure after another. The ribosomes kept falling apart. Other scientists poked their heads in periodically and asked sarcastically for news of X. Jacob wrote that they ‚Äúcame to visit as one would visit the zoo.‚Äù On the trio‚Äôs very last scheduled day in the lab, Meselson, having given up on X, left. He flew to Boston to propose to his first wife.</p>
<p>Dejected, Jacob and Brenner went to Malibu Beach. The duo lay on the beach, watching huge waves of the Pacific crashing onto the sand and contemplating where their idea had gone wrong. Jacob wrote in his memoir: ‚ÄúSuddenly, Sydney gives a hoot. He leaps up, yelling, ‚ÄòThe magnesium! It‚Äôs the magnesium!‚Äô ‚Äù They raced back to the lab to run the experiment one last time, with additional magnesium. The result was spectacular. X existed.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/theres-a-new-strain-of-covid-19-will-the-vaccines-work-against-it/">There‚Äôs a new strain of COVID-19. Will the vaccines work against it?</a></strong></p></blockquote>
<p>The pair gave a seminar the same day at Caltech to demonstrate X. Even then, no one believed them. They contacted Meselson in Boston that night to tell him. He was delighted. ‚ÄúIt didn‚Äôt occur to me that they would figure out what was going wrong on the very last day,‚Äù he says. When the trio published their findings in 1961, they renamed X as messenger RNA.</p>
<p>They did not imagine that their finding would be used for therapeutics or a vaccine. Their questions were more philosophical. Meselson says, ‚ÄúWe wondered what is it that allows you to put together the atoms of the ordinary periodic chart and end up with something that‚Äôs alive?‚Äù</p>
<p>Their work became the central tenet of molecular biology: DNA makes RNA makes protein makes life. It took another generation of scientists to find a way to harness RNA to treat and prevent illness.</p>
<p>***</p>
<p>As a kid in Kis√∫jsz√°ll√°s, Hungary, Katalin Karik√≥ watched her father, a butcher, dismember the carcasses of pigs. It was her first introduction to science. In the 1970s, while studying biochemistry at the University of Szeged, Karik√≥ heard about a new report from London: interferon, a type of protein made by the body to trigger a defence against a virus, was mediated by an RNA called 2-5A. Karik√≥ remembers a mentor talking to her about the discovery and being thrilled by the possibilities. He suggested to her that if they could make a synthetic version of a 2-5A molecule, they might be able to treat cancer or viral disease. ‚ÄúI immediately thought that what I was doing was tremendously important,‚Äù she says. It was the start of a 40-year quest to make synthetic RNA that could cure illness.</p>
<p>But she couldn‚Äôt secure funding in Hungary. Married with a two-year-old daughter, Karik√≥ saw no way to continue her work in her home country. She wrote to professors throughout Europe about joining their labs, but no one could hire her. In 1985, she received an offer from Temple University in Philadelphia. If she could get to the United States, a job was waiting for her.</p>
<p>At the time, Hungarian money could not legally be converted to another currency and taken out of the country. Worried about how their family would survive until her first paycheque, Karik√≥ and her husband, Bela Francia, sold their Russian-made car and converted the proceeds on the black market for a total of 900 British pounds. They sewed the money into their daughter‚Äôs teddy bear to smuggle it out of the country. The teddy bear‚Äôs owner, their daughter, Susan Francia, grew up to become a two-time Olympic gold medallist for the United States in rowing.</p>
<div id="attachment_1216834"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/KATALIN-KARIKO-MRNA-COVID-19-FRANGOU-FEB02.jpg" alt="Karik√≥ at home in Pennsylvania (Rachel Wisniewski)" width="820" height="547"></p><p>Karik√≥ at home in Pennsylvania (Rachel Wisniewski)</p></div>
<p>In their new home, things did not go as planned. Karik√≥‚Äôs bosses changed, she couldn‚Äôt get funding and she lost her job. Her supervisor cited her for deportation. Desperate to stay in the United States as her daughter entered first grade, Karik√≥ accepted a researcher post in Bethesda, Maryland. She commuted from Philadelphia every Monday morning at 3 a.m. and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</a></em></p>]]>
            </description>
            <link>https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196372</guid>
            <pubDate>Fri, 19 Feb 2021 18:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyan Cat on the Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 92 (<a href="https://news.ycombinator.com/item?id=26196027">thread link</a>) | @awaxman11
<br/>
February 19, 2021 | https://foundation.app/NyanCat/nyan-cat-219 | <a href="https://web.archive.org/web/*/https://foundation.app/NyanCat/nyan-cat-219">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Nyan Cat is the name of an animation uploaded on April 2 2011, and became a viral internet sensation. The design of Nyan Cat was inspired by my cat Marty, who crossed the Rainbow Bridge but lives on in spirit.</p><p>I am the original artist behind the iconic GIF and have remastered the image for its 10 year anniversary.  Owning this piece grants the following stats:</p><p>Charisma +10<br>Luck +10<br>Happiness +15</p><hr><p>1400x1400 - 12 Frames</p></div></div>]]>
            </description>
            <link>https://foundation.app/NyanCat/nyan-cat-219</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196027</guid>
            <pubDate>Fri, 19 Feb 2021 18:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brave Browser leaks your Tor / Onion service requests through DNS]]>
            </title>
            <description>
<![CDATA[
Score 356 | Comments 85 (<a href="https://news.ycombinator.com/item?id=26194764">thread link</a>) | @todsacerdoti
<br/>
February 19, 2021 | https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through | <a href="https://web.archive.org/web/*/https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div lang="en" dir="ltr"><p>Edit: (Since this is gaining traction elsewhere.) I'm not trying to shit on Brave. I'm just wanting to help protect end-users who may use Brave for it's Tor feature to do stuff over Tor that should only be done with the actual Tor browser. If you're using Brave you probably use it because you expect a certain level of privacy/anonymity. Piping .onion requests through DNS where your ISP or DNS provider can see that <em>you</em> made a request for an .onion site defeats that purpose.</p>
<p>I'm also no NetSec expert but you don't have to be to replicate this. I'm just a dude with some websites and projects and I'm not certain I would have taken notice of this if it wasn't reported to me by a partner on another project who witnessed this behavior when monitoring his local requests leaving his network. He'll be doing his own write-up and is more equipped to discuss this in length than me.</p>
<hr><p>Testing out something that was noted a week or so ago, and wanting to replicate it for the purpose of this post.</p>
<p>Some of you know I'm working on an ad, tracker, and other BS blocking VPN service for an unrelated project to this site. Go to <a href="https://ramble.pw/f/incoghost">/f/incoghost</a> (<a href="https://incog.host/" rel="nofollow">website</a>) for more because I try to keep these things separated.</p>
<p>Anyhow, it was reported by a partner that Brave was leaking DNS requests for onion sites and I was able to confirm it at the time. Decided to spin up a VM with Brave and test with this site's Onion service (though it will do this for any .onion)</p>
<p>Example:</p>
<pre><code> Feb 18 12:02:25: query[A] rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion from 104.244.xx.xxx
</code></pre>
<p>What this entry shows (simply) is that the request made for the domain rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion made it to the DNS server and is tagged with the IP of the requester, which in this case is just the test / dev VPN. This shouldn't happen. There isn't any reason for Brave to attempt to resolve a .onion domain through traditional means as it would with a regular clearnet site.</p>
<p>This is especially worrisome for those of you who use Brave browser from your normal residential IP and (for whatever reason) use the Tor feature built into the browser to access Tor sites. Your ISP or DNS provider <em>will</em> know that a request made to a specific Tor site was made by <em>your</em> IP. With Brave, your ISP would know that you accessed <em>somesketchyonionsite.onion</em> .</p>
<p>TL;DR: If you're going to use Tor, use the Tor Browser and not Brave. The Tor browser itself doesn't leak these requests like Brave does.</p>
<hr><p>Edit: To clarify, the VPN service we're working on is no-logging but during this dev and testing period we're logging DNS requests while we work out the kinks in the blocklists. This has also allowed us to witness .onions being passed through which is a fault of Brave.</p>
<hr><p>Edit 2: Screenshot: <a href="https://images2.imgbox.com/98/46/1i084PbC_o.png" rel="nofollow">https://images2.imgbox.com/98/46/1i084PbC_o.png</a></p>
<p>That was me loading duckduckgo in a different container, with brave, while live fetching DNS requests made to the DNS server. I blurred out the non-onion requests. (Different VPN test location than in the above example so 209.x.x.x IP instead of the 104.x.x.x one in the original example.</p>
<hr><h3>EDIT 2: The mods of /r/privacy won't let this be posted. They say:</h3>
<blockquote>
<p>While we (vastly) prefer the Tor Browser over the Brave one, you'll need a better source than the one you found. Can you find something from a more widely recognized NetSec expert? Something along the lines of Bruce Schneier's blog or something at that level of credibility?</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The problem with screenshots is that they can be faked, trivially. There are also a host of approaches that credible writers/reporters do in the NetSec space do before a line of text appears in print. It's this kind of journalism that we have to trust, since we humble Mods don't have the time or resources to vet. So, we'll need something better sourced. Sorry!</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are new posts everyday "warning" people of things that aren't legitimate, hence the caution. This is not a "security" subreddit. A moderator's job is to ensure that the subreddit doesn't devolve into conspiracy theories and misinformation. Security announcements should be vetted and confirmed, not independent claims that the mods have no time to independently verify.</p>
<blockquote>
<p>I can post the steps on how to easily replicate this by using pi-hole on their local networks. Anyone is capable of verifying this.</p>
</blockquote>
<p>Great. Please do so on r/brave, r/netsec, r/infosec, and other places where this is both directly relevant and appropriate to seek others confirmation. Once vetted by the community (and republished by professionals), you're welcome to post those official responses.</p>
</blockquote>
<p>/r/brave is private, invite only. I posted on netsec and infosec so we'll see. I guess /r/privacy must love Brave and not allow anything against it since it's so god damned easy to verify this...</p>
<p>All you have to do to VERIFY that this is happening is A.) Use Brave B.) Go to an Onion site C.) Observe DNS traffic. Install Pi-Hole on a Raspberry Pi or in a Virtual Machine on your desktop and run your DNS requests through it for ease of use and you can verify it. Not sure why they're so hesitant to inform their subscribers of this.</p>
<hr><p>Edit 3: Tested on both a Debian 10 and Ubuntu desktop. I'm not esteemed NetSec researcher and I'm not setting up a 100 different scenarios.</p>
</div>
            </div></div>]]>
            </description>
            <link>https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through</link>
            <guid isPermaLink="false">hacker-news-small-sites-26194764</guid>
            <pubDate>Fri, 19 Feb 2021 16:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are starting to operate our CNC machines remotely]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 99 (<a href="https://news.ycombinator.com/item?id=26193769">thread link</a>) | @Sharapolas
<br/>
February 19, 2021 | https://1d.works/how-we-started-operating-our-cnc-machines-remotely/ | <a href="https://web.archive.org/web/*/https://1d.works/how-we-started-operating-our-cnc-machines-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h2 id="introduction"><strong>Introduction</strong></h2><p>Not only COVID-19 has brought many challenges to our daily lives, but it also has inspired a lot of change in how we work and do things. Some professions transitioned to remote work more easily than others. Factory workers and machine operators have been less lucky in this regard and that also applies to us in our CNC-based micro-factory.</p><p>Allowing more people to work remotely opens up many opportunities for businesses. Not only you can bring talent from anywhere in the world, but also you have more choices where to house the hardware allowing to optimise on cost. Furthermore, reaction times can be reduced if travel to the worksite can be eliminated. Quite a few IT professionals have been doing a good job from spectacular locations and we should strive to let more people experience that.</p><p>Another important aspect of structuring work such that it can be done remotely is that it is the first step to automating it. Local to remote, and remote to autonomous allows for a smoother transition than local to autonomous straight away. In the future, we plan on coupling our remote system to AI so if you‚Äôre interested, make sure to follow us on LinkedIn or Facebook!</p><p><strong>WARNING! </strong>Running machinery unsupervised is dangerous and must be avoided. This article is elaborating on how to operate machines more efficiently with more staff working remote, but does not suggest running machines without supervision or people on-site.</p><h2 id="how-corona-showed-us-an-opportunity"><strong>How Corona showed us an opportunity</strong></h2><p>Before the COVID-19 hit our workflow for a CNC job has been as follows:</p><ol><li>Make CAD/ CAM in the office;</li><li>Finalise CAM in the shop;</li><li>Run CNC jobs in the shop.</li></ol><p>However, during the quarantine at times it has become difficult to proceed this way because of the travel restrictions ( our CNC lab and office are based in different districts and district travel is cumbersome during quarantine ). We took up this challenge and used it as an opportunity to do the first step towards our micro-factory automation by doing more of the shop work remotely.</p><h2 id="the-cnc-lab-problem"><strong>The CNC lab problem</strong></h2><p>Running a CNC job required:</p><ol><li>Prepare the CAD/CAM files;</li><li>Setup the CNC machine for the job;</li><li>Loop: place the material, run the program, take out the cut parts, clean the table</li></ol><p>In our team, a single person has been doing all of these things. However, is it wise to use a skilled designer/ operator to be in charge of moving material and parts? Not really, because those skills could be invested in something with a much better return on investment (ROI).</p><p>Why don‚Äôt we have an unskilled person doing that work? Because CNC jobs are prone to small and costly mistakes, so to ensure high quality and safe operation, that person has to have some skills. Those skills need to either be brought in or be taught and as soon as a person has those skills we are back at having a skilled person doing a large amount of unskilled work.</p><h3 id="iteration-1">Iteration 1</h3><p>Our first step towards a solution was finding an unskilled person to be at the shop while we remote into the PC which controls the CNC machine. This has greatly improved our ROI and created a truly win-win situation because not only we are more efficiently using our time resources, but also created a new job position.</p><p>Still, there were issues to be solved. Coordination was done by phone and in order to operate the machine safely, we had to do multiple repeated questions making sure that it is safe to run the machine. Setup was particularly tricky because misunderstandings led to tool breakage and material waste. Lastly, making sure that the operation is proceeding smoothly was tricky as well since it required experienced evaluation and experience we did not have on-site.</p><h3 id="iteration-2">Iteration 2</h3><p>Having drawn conclusions from iteration 1, we‚Äôve decided to upgrade the CNC lab with a camera for more efficient and higher quality feedback. And it is surprising how much easier work became then!</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ukzIoHs74MRrQd9Xu3ZBJQ.png" alt=""><figcaption>Figure 1. CNC shop&nbsp;camera</figcaption></figure><p>Much less coordination was required and we were much more confident operating the CNC machine knowing that the site was safe for operation. Setups became easier because we could verify that the right measurements were made.</p><p>Soon enough we‚Äôve found many things that could be improved:</p><ul><li>Running cameras in one window and remoting in on another tended to be inconvenient on a single screen workstation;</li><li>Although monitoring was much better, the single-camera setup did not allow to evaluate the quality of the finish or how smoothly the work was progressing;</li><li>When we were executing tool adjustments (eg. changing a bit in the tool chuck ) it was still hard to be sure that the right tool was where it needed to be;</li><li>It has become very apparent that some of the tasks could be semi-automated using feedback from the on-site worker. For example, at the beginning of each session, the machine needs to be initialised by moving it to reference and calibrating all the tools which involved checking if the site was clear for action and then going through a sequence of clicks;</li><li>Measurements still took a while to explain and then took a while to do properly.</li></ul><h3 id="iteration-3">Iteration 3</h3><p>Taking into account the inefficiencies we‚Äôve identified, we‚Äôve decided to work on a cohesive platform with an intuitive dashboard which would merge all the systems we have and provide the base for automation to be built upon.</p><p>First, was the network setup. We needed to merge multi-site networks into a mesh topology network where all the nodes could be interconnected which was solved using a hub and spoke topology VPN. Although, it does have its own drawbacks it had a good cost-benefit ratio when it comes to setup and deployment and is working for us for now.</p><p>Next, was building the dashboard which not only required the making of the UI but required figuring out how we‚Äôre going to expose and manage resources in our shop network. We decided to build the backend in the spirit of Kubernetes, so it is easy to manage at scale with the addition of new sensors, machines and full-blown sites themselves.</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*JYyqKIXsBTgfg8A-ENR-xw.png" alt=""><figcaption>Figure 2. CNC shop dashboard prototype</figcaption></figure><p>For the GUI we choose to go with Python‚Äôs Tkinter package in order to be able to rapidly iterate and once it reaches a stable state we‚Äôre planning to move it into a web app for easy access from any device. The dashboard is set up such that one could interface with the embedded CNC software by just doing the relevant actions on the dashboard.</p><h3 id="conclusions">Conclusions</h3><p>Based on our experience using the shop dashboard, it has helped us improve our process in the CNC shop by a mile. We are significantly more confident running remote jobs, have more oversight and control and the process is much more efficient with time.</p><p>It has also opened the possibility to (semi)-automate processes involved in running a CNC shop, which we are continuing to work with and will be posting later. We have a few ideas on how to couple the camera and control system with AI and that is an exciting prospect!</p><p>One key feature that the system requires is being able to remotely access the CNC control software. We are lucky to have it running on a PC which we can easily remote-in, but in case of embedded software, some middleware might be needed to control it remotely.</p><p>Allowing the machine operator to work remote adds value to our business as we could easier relocate the shop to cheaper areas, further from the cities or have talented engineers from nearly anywhere in the world away from work with us. That is why we will continue on this journey and will share it with you as we go!</p><hr><h3 id="check-out-more-">Check out more:</h3><ol><li><a href="https://1d.works/welcome-to-1d-works-cnc-lab/" rel="noopener">Welcome to 1D.works CNC Lab</a></li><li><a href="https://1d.works/object-oriented-computer-assisted-machining/" rel="noopener">Simplifying CAM workflow with Fusion 360</a></li><li><a href="https://1d.works/unique-products-at-scale-with-ai-infused-cad/" rel="noopener">Unique products at scale with AI-infused CAD</a></li></ol><p>and more in our <a href="https://1d.works/blog/" rel="noopener">blog</a></p><hr><h3 id="connect-">Connect!</h3><p>At <a href="https://1d.works/" rel="noopener nofollow noopener noopener">1D.works</a> we‚Äôre excited about the potential of AI to improve businesses and people‚Äôs lives. CAD and CAM are two of the largely unexplored territories we‚Äôre invested in. If you think you can benefit from a decade-long experience of applying machine learning to business processes, <a href="https://1d.works/" rel="noopener nofollow noopener noopener">get in touch</a>!</p><hr><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ZttLaS6wTmFLgKZ6_9LeeA.png" alt=""></figure>
                </div>
            </section></div>]]>
            </description>
            <link>https://1d.works/how-we-started-operating-our-cnc-machines-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193769</guid>
            <pubDate>Fri, 19 Feb 2021 14:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúI will slaughter you‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 538 | Comments 235 (<a href="https://news.ycombinator.com/item?id=26192025">thread link</a>) | @ingve
<br/>
February 19, 2021 | https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might know that I‚Äôve posted funny emails I‚Äôve received on my blog several times in the past. The kind of emails people send me when they experience problems with some device they own (like a <a href="https://daniel.haxx.se/blog/2018/02/16/why-is-your-email-in-my-car/" data-type="post" data-id="10856">car</a>) and they contact me because my email address happens to be visible somewhere.</p>



<p>People sometimes say I should get a different email address or use another one in the curl license file, but I‚Äôve truly never had a problem with these emails, as they mostly remind me about the tough challenges the modern technical life bring to people and it gives me insights about what things that run curl.</p>



<p>But not all of these emails are ‚Äúfunny‚Äù.</p>



<h2>Category: not funny</h2>



<p>Today I received the following email</p>



<pre>From: Al Nocai &lt;[redacted]@icloud.com&gt;
Date: Fri, 19 Feb 2021 03:02:24 -0600
Subject: I will slaughter you</pre>



<p>That subject.</p>



<p>As an open source maintainer since over twenty years, I know flame wars and personal attacks and I have a fairly thick skin and I don‚Äôt let words get to me easily. It took me a minute to absorb and realize it was actually meant as a direct physical threat. It found its ways through and got to me. This level of aggressiveness is not what I‚Äôm prepared for.</p>



<p>Attached in this email, there were seven images and no text at all. The images all look like screenshots from a phone and the first one is clearly showing <a href="https://github.com/curl/curl/blob/master/include/curl/multi.h">source code I wrote</a> and my copyright line:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png"><img loading="lazy" width="295" height="640" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png" alt=""></a></figure></div>



<p>The <a href="https://daniel.haxx.se/al/">other images</a> showed other source code and related build/software info of other components, but I couldn‚Äôt spot how they were associated with me in any way.</p>



<p>No explanation, just that subject and the seven images and I was left to draw my own conclusions.</p>



<p>I presume the name in the email is made up and the email account is probably a throw-away one. The time zone used in the <code>Date:</code> string might imply US <a href="https://www.timeanddate.com/time/zones/cst">central standard time</a> but could of course easily be phony as well. </p>



<h2>How I responded</h2>



<p>Normally I don‚Äôt respond to these confused emails because the distance between me and the person writing them is usually almost interplanetary. This time though, it was so far beyond what‚Äôs acceptable to me and in any decent society I couldn‚Äôt just let it slide. After I took a little pause and walked around my house for a few minutes to cool off, I wrote a really angry reply and sent it off.</p>



<blockquote><p>This was a totally and completely utterly unacceptable email and it hurt me deep in my soul. You should be ashamed and seriously reconsider your manners.</p><p>I have no idea what your screenshots are supposed to show, but clearly something somewhere is using code I wrote. Code I have written runs in virtually every Internet connected device on the planet and in most cases the users download and use it without even telling me, for free.</p><p>Clearly you don‚Äôt deserve my code.</p></blockquote>



<p>I don‚Äôt expect that it will be read or make any difference.</p>



<p>Update below, added after my initial post.</p>



<h2>Al Nocai‚Äôs response</h2>



<p>Contrary to my expectations above, he responded. It‚Äôs not even worth commenting but for transparency I‚Äôll include it here.</p>



<p><em>I do not care. Your bullshit software was an attack vector that cost me a multimillion dollar defense project.</em></p>



<p><em>Your bullshit software has been used to root me and multiple others. I lost over $15k in prototyping alone from bullshit rooting to the charge arbitrators.</em></p>



<p><em>I have now since October been sandboxed because of your bullshit software so dipshit google kids could grift me trying to get out of the sandbox because they are too piss poor to know shat they are doing.</em></p>



<p><em>You know what I did to deserve that? I tried to develop a trade route in tech and establish project based learning methodologies to make sure kids aren‚Äôt left behind. You know who is all over those god damn files? You are. Its sickening. I got breached in Oct 2020 through federal server hijacking, and I owe a great amount of that to you.</em></p>



<p><em>Ive had to sit and watch as i reported:</em></p>



<ol><li><em>fireeye Oct/2020</em></li><li><em>Solarwinds Oct/2020</em></li><li><em>Zyxel Modem Breach Oct/2020</em></li><li><em>Multiple Sigover attack vectors utilizing favicon XML injection</em></li><li><em>JS Stochastic templating utilizing comparison expressions to write to data registers</em></li><li><em>Get strong armed by $50billion companies because i exposed bullshit malware</em></li></ol>



<p><em>And i was rooted and had my important correspondence all rerouted as some sick fuck dismantled my life with the code you have your name plastered all over. I cant even leave the country because of the situation; qas you have so effectively built a code base to shit all over people, I dont give a shit how you feel about this.</em></p>



<p><em>You built a formula 1 race car and tossed the keys to kids with ego problems. Now i have to deal with Win10 0-days because this garbage.</em></p>



<p><em>I lost my family, my country my friends, my home and 6 years of work trying to build a better place for posterity. And it has beginnings in that code. That code is used to root and exploit people. That code is used to blackmail people.</em></p>



<p><em>So no, I don‚Äôt feel bad one bit. You knew exactly the utility of what you were building. And you thought it was all a big joke. Im not laughing. I am so far past that point now.</em></p>



<p><em>/- Al</em></p>



<h2>Al continues</h2>



<p>Nine hours after I first published this blog post , Al replied again with two additional emails. His third and forth emails to me.</p>



<h3>Email 3:</h3>



<p><em><a href="https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/">https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/</a><br>Step up. You arent scaring me. What led me here? The 5th violent attempt on my life. Apple terms of service? gtfo, thanks for the platform.</em></p>



<p>Amusingly he has found a blog post about my blog post.</p>



<h3>Email 4:</h3>



<p><em>There is the project: MOUT Ops Risk Analysis through Wide Band Em Spectrum analysis through different fourier transforms.<br>You and whoever the fuck david dick rider is, you are a part of this.<br>Federal server breaches-<br>Accomplice to attempted murder-<br>Fraud-<br>just a few.</em></p>



<p><em>I have talked to now: FBI FBI Regional, VA, VA OIG, FCC, SEC, NSA, DOH, GSA, DOI, CIA, CFPB, HUD, MS, Convercent, as of today 22 separate local law enforcement agencies calling my ass up and wasting my time.</em></p>



<p><em>You and dick ridin‚Äô dave are respinsible. I dont give a shit, call the cops. I cuss them out wheb they call and they all go silent.</em></p>



<p>I‚Äôve kept his peculiar formatting and typos. In email 4 there was also a PDF file attached named <code>BustyBabes 4.pdf</code>. It is apparently a 13 page document about the ‚ÄúNERVEBUS NERVOUS SYSTEM‚Äù described in the first paragraph as ‚ÄúNerveBus Nervous System aims to be a general utility platform that provides comprehensive and complex analysis to provide the end user with cohesive, coherent and ‚Äúreal-time‚Äù information about the environment it monitors.‚Äù. There‚Äôs no mention of curl or my name in the document.</p>



<p>Since I don‚Äôt know the status of this document I will not share it publicly, but here‚Äôs a screenshot of the front page:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png" alt="" width="358" height="462"></a></figure></div>



<h2>Related</h2>



<p>This topic on <a href="https://news.ycombinator.com/item?id=26192025">hacker news</a> and <a href="https://www.reddit.com/r/programming/comments/lnhcrc/i_will_slaughter_you_daniel_stenberg_got_a_quite/">reddit</a>.</p>



<p>I have reported the threat to the Swedish police (where I live).</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192025</guid>
            <pubDate>Fri, 19 Feb 2021 11:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be more productive without forcing yourself]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 123 (<a href="https://news.ycombinator.com/item?id=26191516">thread link</a>) | @vitabenes
<br/>
February 19, 2021 | https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/work_bad_rect.png" referrerpolicy="no-referrer" alt="How to be more productive without forcing yourself"></p><p>Imagine you could work more and be wildly productive. And the best thing about it? You wouldn‚Äôt need to force yourself to work.</p><p>There are people exactly like that who sit down and work without pushing themselves to do it. They even look forward to working. The good news is that you can learn to do it too.</p><p>Let‚Äôs get to it.</p><p>Most people have a negative mindset about work. People see work as an annoyance that keeps them from doing whatever they really want to do. They also think that resting and having nothing to do is an ideal state they‚Äôd like to be in forever. This leads to thinking that you need to push yourself to work. You need to use willpower to get yourself to do it.</p><p>It‚Äôs simple to understand where this attitude comes from:</p><ol><li>People usually want things they don‚Äôt have and think that grass is greener on the other side.</li><li>Everyone talks about how work is hard.</li><li>In comparison to dead-end or corporate jobs without impact or freedom, neverending leisure looks like paradise.</li></ol><p>In reality, most people who try to be in this nothing-to-do state for a long time become unhappy, depressed, and bored. Rich people who ‚Äúmade it‚Äù report how soon they become restless again.&nbsp;<a href="https://www.reddit.com/r/StopGaming/">People who game all the time</a>&nbsp;realize how empty it feels. Too much leisure isn‚Äôt satisfying for long.</p><p>On the other hand, there is a certain group of people who work a lot and enjoy it. Let‚Äôs call this group&nbsp;<em>producers</em>. By this, we don‚Äôt mean workaholics who escape from their whole life by working all the time. Producers have a healthy work-life balance. So what do they do that people who hate work don‚Äôt?</p><p>First, they tend to think about work differently.</p><p>For them, work is&nbsp;<a href="https://www.deprocrastination.co/blog/what-is-a-positive-feedback-loop-and-why-it-matters">a virtuous cycle of positive feedback loops</a>. Producers see&nbsp;<strong>work as a source of meaning and satisfaction</strong>. They see work as something that allows them to savor deserved leisure. They see rest as something that increases their life happiness and fuels their motivation towards work.</p><p>Second, their work is usually:</p><ul><li>Interesting</li><li>Meaningful</li><li>Well-defined</li></ul><p>If you check at least 1 or 2 boxes somehow, something magical happens:</p><p><strong>You don‚Äôt have to push yourself towards work anymore.</strong></p><p>Well-defined, meaningful, and especially interesting work is easy to look forward to.</p><p>Non-producers often think that these producers are lucky because they stumbled upon work like this. In reality, producers often go a long way to make their work fun.</p><h2>How to make work more interesting</h2><p>This is the crucial factor in whether work gets done.</p><p>You don‚Äôt have to see any meaning in your work for it to be interesting.</p><p>Even if the task is totally undefined, complex, and difficult, curiosity can carry you to its completion.</p><p>So how can you develop this curiosity towards work?</p><p>You have to give the work a chance to become interesting. How? By combining these 3 steps:</p><h3>1. Have less exposure towards super fun things</h3><p>Video games, surfing the internet, porn, alcohol, and drugs etc. make work significantly more difficult. Why?</p><p>They establish a certain standard of mental stimulation. Anything that‚Äôs not super fun will seem boring.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_standard.png" referrerpolicy="no-referrer" alt="We develop a Stimulation Standard"></p><p>Unfortunately, work often falls in the ‚Äúfeels bad‚Äù category. In comparison to games or social media, work can feel uninteresting or annoying.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_distractions.png" referrerpolicy="no-referrer" alt="Switching from distractions to work is hard"></p><p>You might argue that there are people who work just fine even while drinking alcohol, playing video games etc.</p><p>However, consider that there are two types of people: ones who can moderate their consumption and others who can‚Äôt. The latter society often describes as addicts.</p><p>Basically, if you‚Äôre addicted to any of the high-dopamine, low-effort activity, please quit it. At least temporarily so you can reestablish a healthy relationship to work. The more experienced we‚Äôre about the topic, the more obvious this is. There is no other way than to temporarily quit the addiction. If your vice is gaming, we‚Äôve covered&nbsp;<a href="https://www.deprocrastination.co/blog/should-i-quit-video-games">video gaming addiction here</a>.</p><p>Some can have a healthy relationship with, for example, gaming.</p><p>However, for some people gaming is kryptonite. Here are some signs that super-fun activities have a detrimental effect on your work:</p><ol><li>You rush and half-ass everything else in order to get to your super-fun activity.         When I (Mat) was addicted to gaming, everything during the day was half-assed so I could finally start playing.</li><li>You keep postponing or forgetting everything that isn‚Äôt urgent in order to get to your super fun activity. You have this book that you want to read but you never get to actually reading it.</li><li>Your orderliness suffers once you start with the super fun activity.        Most people who come back to gaming report how their sense of orderliness starts to depreciate rather quickly. Their room gets messy, they start skipping workouts, stop meal-prepping, start eating more junk food, stop organizing their days.</li></ol><p>If the points above describe you, it might be time to quit your super fun activity. At least for a while.</p><p>Once your brain is not constantly hyper-stimulated, it‚Äôs easier to find mundane activities like work or tidying more interesting.</p><h3>2. Get bored more often</h3><p>When you get bored, everything else becomes more interesting.</p><p>Don‚Äôt believe us? Try this little experiment. Turn everything off. Set a timer for 15 minutes. Sit on a chair and stare at a wall. Don‚Äôt move. Don‚Äôt consume any information. Don‚Äôt talk. Don‚Äôt write anything down. Just stare at the wall.</p><p>Except for zen masters, most of us will become restless after a few minutes. Often, our brain starts dreaming and imagining things. For the first few minutes, you might feel alright, thinking about your day. However, after 5 or 10 minutes, you‚Äôll be itching to do something, anything really. Suddenly, creating a website, writing an article, or drawing a picture sounds like more interesting, more fun.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_boredom.png" referrerpolicy="no-referrer" alt="Switching from boredom to work is easier"></p><p>If you feel like you never stop scrolling and consume content all the time, schedule a 15 minute boredom window for tomorrow right before you want to start working.&nbsp;<a href="https://www.deprocrastination.co/blog/how-to-use-boredom-to-procrastinate-less">Use boredom strategically.</a></p><h3>3. Dive deep into a topic</h3><p>It‚Äôs fun when we can connect the dots. When we can draw new connections between ideas, we get a rush.&nbsp;<em>Oh, I can see how this historical event contributed to an uprising‚Ä¶</em></p><p>The more connections we can draw within a topic, the more interested we become. This is what curiosity is all about.</p><p>If you take the time to watch a documentary related to what you‚Äôre working on, read a book about it, or find a couple relevant articles. You‚Äôll collect more dots to connect. You‚Äôll see how everything fits together.</p><p>When you do feel like watching something or have a free evening, instead of watching random videos or reruns of old TV shows, steer your attention to something related to what you need to do.</p><p>Give yourself time to develop an interest.</p><h2>How to make work more meaningful</h2><p>It's hard to feel motivated when you don't have a personal reason to do something.</p><p>However, ‚Äúmeaningful work‚Äù has become something of a buzzword.</p><p>Everyone is trying to find meaning in their work. This can be wasted energy, especially if you work in a corporate or a dead-end job. We say this so you don‚Äôt dwell on it and don‚Äôt feel frustrated because you can‚Äôt figure out how to save the world by doing what you do.</p><p>In any case, whatever your work is, you can make it meaningful enough to start.</p><p>Let‚Äôs say you have to study for an exam. You don‚Äôt find this particular class enjoyable. If you remind yourself why you chose to take the class and why studying is important for you, you will have an easier time persuading yourself to push through.</p><p>The fact is that some things simply need to be done. It's better if you find a compelling and personal reason to do them and get them over with as soon as possible, instead of putting them off forever.</p><p>When something is boring, ask yourself: Why do I need to do this? Find and reinforce the why behind the work.</p><h2>How to make work well-defined</h2><p>If you have a recipe that tells you step-by-step how to cook a meal, it is usually quite easy to follow. You know exactly where to start and how.</p><p>In today‚Äôs creative work, this often isn‚Äôt the case. There are no recipes for the work we need to do, or they don‚Äôt make the work any easier because the recipe would be too complex to understand.</p><p>Additionally, we often hamper our enthusiasm towards work by ourselves. How often do you find yourself with vague and unhelpful to-dos like ‚Äúwrite the essay‚Äù or ‚Äúmake a video.‚Äù</p><p>There are so many steps in ‚Äúmake a video‚Äù that this vague task definition only causes anxiety and procrastination.</p><p>We always say that it‚Äôs more difficult to start working than to keep working. Therefore we should make starting easier by defining well&nbsp;<em>how</em>&nbsp;to begin and&nbsp;<em>what</em>&nbsp;to begin with.</p><p>The better you can define how to start working, the easier it‚Äôll be to actually do it.</p><p>Basically, you do this in 3 steps:</p><h3>1. Always define exactly where you‚Äôll start</h3><p>This means you write down the next physical action to take.</p><p>Do you need to write an essay?</p><p>The next physical action is: Open the scientific study and start reading</p><p>Or: Create a document ‚Üí Create a rough draft in the next 15 minutes</p><p>Do you want to start learning coding?</p><p>The next physical action should be: Open freecodecamp.org ‚Üí Start solving the first challenge</p><p>It might sound silly to define the next physical action, but it isn‚Äôt. Finding it is easy, and you can do it immediately.</p><p>What‚Äôs the next physical action you need to take?</p><h3>2. Start with only having to work for 5/15 minutes</h3><p>You probably don't feel like creating a 20 slide presentation right now from scratch, and then presenting it in 2 hours.</p><p>You don't feel like writing a whole final thesis on a topic you barely know.</p><p>You don't feel like running a marathon.</p><p>But you might feel like looking up a couple pictures or articles for the presentation.</p><p>Or feel like writing a paragraph or two before lunch break.</p><p>Or feel like taking a 1km walk.</p><p>Those are the small steps along the longer journey.</p><p>We often underestimate the power of small steps, but they are essential because they help us get into the right routine.</p><p>If you start running a couple miles every other day, you'll get familiar with the routine and then you'll naturally want to start increasing the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</a></em></p>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191516</guid>
            <pubDate>Fri, 19 Feb 2021 10:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust (2020)]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 190 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. You√¢‚Ç¨‚Ñ¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesn√¢‚Ç¨‚Ñ¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean √¢‚Ç¨≈ìimplement one in the first place√¢‚Ç¨ÔøΩ.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart through√¢‚Ç¨¬¶.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field of√¢‚Ç¨¬¶mh√¢‚Ç¨¬¶experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> or√¢‚Ç¨¬¶</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and don√¢‚Ç¨‚Ñ¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you need√¢‚Ç¨¬¶.<em>SIX YEARS? Are you serious?</em>√¢‚Ç¨¬¶ahem, sorry√¢‚Ç¨¬¶Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. √¢‚Ç¨≈ìInput file XY not found in your √¢‚Ç¨Àúcounting words√¢‚Ç¨‚Ñ¢ program√¢‚Ç¨ÔøΩ).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>√¢‚Äù≈ì√¢‚Äù‚Ç¨ init()
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ read_auxv()
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù≈ì√¢‚Äù‚Ç¨ open(format!("/proc/{}/auxv", self.pid))
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_parsing()
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ ...
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ enumerate_mappings()
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù≈ì√¢‚Äù‚Ç¨ open(format!("/proc/{}/maps", self.pid))
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_parsing()
√¢‚Äù‚Äö   √¢‚Äù‚Äö
√¢‚Äù‚Äö   √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_more_checks()
√¢‚Äù‚Äö      √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
√¢‚Äù‚Äö
√¢‚Äù‚Äù√¢‚Äù‚Ç¨ dump()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::header::write()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::thread_list_stream::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::mappings::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ elf_identifier_for_mapping()
   √¢‚Äù‚Äö     √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::app_memory::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù‚Äù√¢‚Äù‚Ç¨ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which is√¢‚Ç¨¬¶.<em>(Throws a stack of papers from the desk)</em>√¢‚Ç¨¬¶short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesn√¢‚Ç¨‚Ñ¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldn√¢‚Ç¨‚Ñ¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the ‚Ä¶</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 491 | Comments 233 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ü§Ø trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a ‚Ä¶</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
    </channel>
</rss>
