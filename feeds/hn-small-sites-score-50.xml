<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 06 Oct 2020 20:26:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 06 Oct 2020 20:26:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Applying “make invalid states unrepresentable”]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24685772">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://kevinmahoney.co.uk/articles/applying-misu/ | <a href="https://web.archive.org/web/*/https://kevinmahoney.co.uk/articles/applying-misu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="applying-make-invalid-states-unrepresentable">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">02 October 2020</time></p>

<p>Here are some real life cases of applying one of my
<a href="https://kevinmahoney.co.uk/articles/my-principles-for-building-software/">favourite principles</a>.</p>

<p>I’ll try to update this as I come across good examples.</p>

<h2 id="case-1-contiguous-time-periods">Case 1: Contiguous Time Periods</h2>

<p>A straightforward way to represent a period of time is by its start
and end dates (<code>(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c1.png"></p>

<p>If we need to represent a timeline split in to contiguous periods, it
may be tempting to represent this as a sequence of periods (e.g. <code>List
(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c2.png"></p>

<p>However, with this representation there can be both gaps in the
timeline and overlapping periods:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c3.png"></p>

<h3 id="improved-representation">Improved Representation</h3>

<p>We can improve this representation so that the contiguous and
non-overlapping constraints always hold, and we can do this in a way
that may remind you of database normalisation - by removing
redundancy.</p>

<p>In a well formed contiguous timeline, the joint start/end
of the adjacent periods are redundant. Contiguous, non-overlapping
splits can simply be represented by a set of dates (<code>Set Date</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c4.png"></p>

<p>You can begin to see how this representation simplifies the system
when you consider how to make a further split in the timeline. In the
list representation, splitting a period requires carefully modifying
the data-structure and ensuring constraints aren’t violated. In the
‘set of dates’ representation you simply add a date to the set.</p>

<p>It is sometimes still useful to represent the periods as a sequence of
start and end dates. It is trivial to project the set of dates in to
this form. As long as the canonical representation is the set, the
constraints will still hold.</p>

<h2 id="case-2-default-contracts">Case 2: Default Contracts</h2>

<p>In this system, a customer pays us a recurring rent based upon a contract.
Contracts last for a fixed amount of time, and when they expire we fall back to
a ‘default contract’. The customer can have many fixed contracts, and can
sign new contracts at any time.</p>

<p>This was represented as:</p>
<ul>
  <li>A ‘customers’ table storing
    <ul>
      <li>The customer start date.</li>
      <li>An optional end date, should the customer leave.</li>
    </ul>
  </li>
  <li>A ‘contracts’ table storing
    <ul>
      <li>The contract start date.</li>
      <li>An optional end date, for default contracts that don’t end.</li>
      <li>If it was a ‘fixed’ or ‘default’ contract.</li>
    </ul>
  </li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f1.png"></p>
<p>Customer and contract timelines</p>

<p>This representation allows for some undesirable states that are trivial to prevent:</p>
<ul>
  <li>The customer may have gaps in their contracts.</li>
  <li>A fixed contract may not have an end date.</li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f2.png"></p>
<p>Contract gaps</p>

<p>To make matters worse, the API for these contracts allowed you to
modify each individual contract, fixed or default, without guarding against
these states. This shows how a poor choice of
representation propagates itself through the design of a system.</p>

<p>This poor choice was not just a theoretical problem -
gaps in contracts were found on more than one occasion, requiring
hours of engineering effort to hunt down and fix.</p>

<h3 id="improved-representation-1">Improved Representation</h3>

<p>This is easily improved by removing the ‘default’ contracts from the
contract table. If the customer doesn’t have a fixed contract, it is
assumed they are on a default contract:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f3.png"></p>
<p>Inferred default contracts</p>

<p>Now there can no longer be any gaps, and 
the end date of a contract no longer needs to be optional as it only represents fixed contracts.</p>

<p>It’s worth reiterating that this representation can be projected in to the previous
representation using a database view if that form is more convenient. What is
important is that the underlying representation enforces these constraints, it
is not important how you view the data.</p>

<p>As with the first case, a better representation makes the manipulation
of the data structure simpler. In this case, adding a new fixed contract is
greatly simplified. There is no need to create or modify default contracts, or ensure
that the contracts are contiguous.</p>

<h3 id="the-influence-of-object-oriented-thinking">The Influence of Object-Oriented Thinking</h3>

<p>If this improvement seems obvious to you, you may wonder how the
original design happened in the first place.</p>

<p>I think this happens because of atomistic, object-oriented thinking.</p>

<p>In this mindset, the fixed contracts are <em>objects</em>, the default contracts are
<em>objects</em>, and each of these concepts must be reified as a row in a table and
never inferred.
There is a distrust of using any features the database
offers beyond storing or retrieving <em>objects</em>.</p>

<p>This approach is antithetical to quality relational design and
the principle of making invalid states unrepresentable.</p>

<p>It may feel “simpler” on some level, as you don’t really need
to think about your design.
However, as we see here, this lack of forethought inevitably
leads to complexity.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://kevinmahoney.co.uk/articles/applying-misu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685772</guid>
            <pubDate>Mon, 05 Oct 2020 08:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking static website hosting providers]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24683403">thread link</a>) | @rencire
<br/>
October 4, 2020 | https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/ | <a href="https://web.archive.org/web/*/https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Static websites are still a hot topic. They are fast, and they’re incredibly secure because there isn’t a CMS to hack. Once you build a static website, however, the question becomes: Where do I host?</p>

<p>In other words: what is the fastest static website hosting provider in 2020? Well, let’s find out!</p>

<!--more-->

<p>I did <a href="https://www.savjee.be/2017/10/Static-website-hosting-who-is-fastest/">a similar test in 2017</a>, so it will be curious to see if the hosting providers have been improving.</p>

<h2 id="test-setup">Test setup</h2>
<p>Just like in 2017, I created a simple webpage that I could host on many services. I opted to use my own homepage, including all the images, CSS, and JS files. I then uploaded these files to the following hosting providers:</p>

<ul>
  <li>
<strong>Pay-as-you-go</strong>
    <ul>
      <li>
<a href="https://aws.amazon.com/s3/" target="_blank" data-no-instant="data-no-instant">AWS S3</a> (Region: <code>eu-west-1</code>, Ireland)</li>
      <li><a href="https://aws.amazon.com/cloudfront/" target="_blank" data-no-instant="data-no-instant">AWS CloudFront</a></li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (regional bucket, <code>europe-west1</code>, Belgium)</li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (multi-region bucket)</li>
      <li>
<a href="https://workers.cloudflare.com/sites" target="_blank" data-no-instant="data-no-instant">Cloudflare Workers Sites</a> ($5/month)</li>
    </ul>
  </li>
  <li>
<strong>Freemium (some parts free)</strong>
    <ul>
      <li><a href="https://firebase.google.com/docs/hosting" target="_blank" data-no-instant="data-no-instant">Firebase Hosting</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Cloudflare CDN</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Netlify</a></li>
    </ul>
  </li>
  <li>
<strong>Free</strong>
    <ul>
      <li><a href="https://pages.github.com/" target="_blank" data-no-instant="data-no-instant">GitHub Pages</a></li>
    </ul>
  </li>
</ul>

<p><em>Quick note</em>: I did not test Microsoft Azure, because I couldn’t sign up for it with my <a href="https://revolut.com/referral/xavierh5x" target="_blank" data-no-instant="data-no-instant">Revolut Visa card</a>. Thanks, Microsoft!</p>

<p>To check the performance, I used Pingdom and <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>. Pingdom measures uptime and response times from <a href="https://my.pingdom.com/probes/feed" target="_blank" data-no-instant="data-no-instant">their worldwide network of probe servers</a> while Oh Dear is located in a single location.</p>

<p>Some other things to keep in mind:</p>

<ul>
  <li>I tested the HTTPS endpoints for all services</li>
  <li>I added <code>index.html</code> to all URL’s, meaning no time wasted resolving the index document</li>
  <li>The services were probed <strong>once every minute</strong> for <strong>10 days</strong>
</li>
  <li>Oh Dear did not only track response times, but also DNS lookup time,  TCP connection time, content download time, and more. Pretty cool! All of the raw data is available at the end of this post.</li>
</ul>

<p><strong>Note:</strong> Pingdom or Oh Dear did NOT sponsor this blog post in any way! <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>, however, gave me a free trial with enough slots for all the test sites. Thanks a lot!</p>

<h2 id="expectations">Expectations</h2>
<p>My expectations are pretty much aligned to when I did this last time around:</p>

<ul>
  <li>I expect paid services to do better than free servers. There must be a reason for the prices they charge, right?</li>
  <li>Firebase and Google Cloud belong to the same company, so I expect them to perform similarly.</li>
  <li>I use CloudFront for my website, so hopefully they don’t come out as a bad option. Otherwise, there’s some additional homework for me ;)</li>
  <li>Netlify performed quite inconsistently last time around. With a few years passing, I hope they were able to address those issues.</li>
  <li>Last time, I didn’t have Cloudflare in the benchmark. I expect them to be a strong contender, given how popular they are and how many edge locations they have.</li>
</ul>

<h2 id="results">Results</h2>
<p>Here’s a screenshot from the Pingdom dashboard after 10 days of testing:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-overview.png" alt="Overview of the Pingdom dashboard">
<em>Overview of the Pingdom dashboard</em></p>

<p>At first glance, it seems that all services perform very consistently, with CloudFront, GitHub Pages, and Google Cloud, leading the pack. But let’s not jump to conclusions.</p>

<h3 id="uptime">Uptime</h3>
<p>Let’s start with uptime. All of these services had 100% uptime, except for Firebase. Pingdom detected 1 minute of downtime. One check returned, “Network is unreachable,” and the other returned “Invalid certificate.”</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-error-log.png" alt="Firebase downtime as reported by Pingdom">
<em>Firebase downtime as reported by Pingdom</em></p>

<p>This was not detected by Oh Dear, so I’m willing to give Firebase the benefit of the doubt and say that this was an issue on Pingdom’s side.</p>

<h3 id="response-times">Response times</h3>
<p>Let’s start with some basic statistics: the median, and average response time of each service (including standard deviation):</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times.png" alt="Median response times, measured by Pingdom">
<em>Median response times as reported by Pingdom</em></p>

<p>A few things might catch your attention:</p>

<ul>
  <li>CloudFront &amp; GitHub Pages are speedy and consistent. They have the lowest median, average, and deviation. Interesting because one is a paid service, while the other is completely free.</li>
  <li>AWS S3 is the slowest of them all (but performs consistently). It is kind of expected from a hosting provider that is located only in a single region (in this case Ireland, <code>eu-west-1</code>)</li>
  <li>Google Cloud’s regional and multi-regional buckets perform fairly alike. Interestingly, both are much faster than S3, which is a comparable service. Is Google doing some caching behind the scenes?</li>
  <li>I expected Cloudflare to be much more competitive with the top rankings, but somehow both their CDN and Workers aren’t the top performers. Their Workers product does, however, perform slightly better than their CDN.</li>
</ul>

<p>Since I used both Pingdom and Oh Dear, let’s check the difference in median response times:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-pingdom-oh-dear.png" alt="Pingdom vs Oh Dear (median response times)">
<em>Pingdom vs Oh Dear (median response times)</em></p>

<p>Interestingly, Oh Dear is reporting much faster response times compared to Pingdom. This is probably related to the fact that they only test from a single (apparently very well connected) location.</p>

<p>Pingdom is testing from various locations around the world, some of which aren’t as well connected, which increases the response times.</p>

<p>Some additional findings:</p>

<ul>
  <li>Somehow, AWS S3 is the fastest performer, even though the content is only hosted in a single location. It also outperformed Amazon’s CDN! Wherever Oh Dear is hosted, it must be somewhere in the EU with good connections to the Ireland region of AWS.</li>
  <li>The difference between CloudFront, S3, Firebase, GitHub Pages, and Google Cloud Storage is minimal. Once more, showing that free and paid services compete quite closely with one another.</li>
</ul>

<h3 id="time-to-first-byte">Time to first byte</h3>
<p>Oh Dear also kept track of other metrics like how long it took for the first bytes to start being transferred. This can give us an indication of how responsive the webserver is (how long does it need to think before being able to fulfill a request).</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-time-to-first-byte.png" alt="Time to first byte: measures responsiveness of web servers">
<em>Time to first byte: measures responsiveness of web servers</em></p>

<ul>
  <li>The “simple” storage services like S3 and Google Cloud Storage are doing very well.</li>
  <li>Once again, GitHub Pages, Firebase, and CloudFront are great performers, delivering the first byte in under 40ms.</li>
  <li>Surprisingly, Cloudflare is taking quite a while to start delivering the first bytes. Maybe this is due to all of their protection services?</li>
</ul>

<h3 id="compared-to-2017">Compared to 2017</h3>
<p>Comparing this new data with the one from 2017 reveals that not much has changed. Note that here I’m comparing the data from Pingdom:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-2017-vs-2020.png" alt="Benchmark from 2017 vs 2020: median response times">
<em>Benchmark from 2017 vs 2020: median response times</em></p>

<p>All providers (except GitHub Pages) have become slightly slower. Most noticeably AWS S3 (+13%) and Firebase (+31%). The others are so close to their 2017 performance that I would consider these differences to be in the margin of error.</p>

<p>Netlify has a slower median response time in 2020 compared to 2017. But it did improve massively on its consistency. Last time around, they had weird spikes in performance but not anymore. Nice!</p>

<p>This could be explained by Pingdom having added additional test servers located in areas that are further away from these providers.</p>

<h3 id="trying-to-find-edge-cases">Trying to find edge cases</h3>
<p>A scatter plot reveals that there aren’t many outliers, and no service is suffering from regular spikes in performance. There are some outliers here and there, but I wouldn’t look into them too much:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-scatter-response-times.png" alt="Scatter plot of all response times">
<em>Scatter plot of all response times</em></p>

<p>If we visualize the response times with a box plot, we see something interesting:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-boxplot-response-times.png" alt="Box plot of response times, showing some high spikes">
<em>Box plot of response times, showing some high spikes</em></p>

<p>All services, except for AWS, GitHub Pages, and Firebase, have weird spikes. Last time around, this was only limited to Netlify. Not sure what to make of these, but I’m guessing it’s more related to Pingdom’s tests than to the services themselves.</p>

<h2 id="conclusions">Conclusions</h2>
<p>Time to draw some conclusions:</p>

<p>The best all-around performer is <strong>AWS CloudFront</strong>, followed closely by <strong>GitHub Pages</strong>. Not only do they have the fastest response times (median), they’re also the most consistent.</p>

<p>They are, however, closely followed by Google Cloud Storage. Interestingly, there is very little difference between a regional and multi-regional bucket. The only reason to pick a multi-regional bucket would be the additional uptime guarantee.</p>

<p><strong>Cloudflare</strong> didn’t perform as well I would’ve expected. It’s certainly faster than a standard S3 bucket but falls away when compared to other CDN’s like CloudFront. Their Workers product is slightly faster than their CDN, but it’s hard to recommend it when it costs $5 a month, and free products like GitHub Pages perform better.</p>

<p>Netlify has improved big time; the spikes in performance are gone and performs in line with Google Cloud and Firebase hosting.</p>

<h2 id="which-should-you-choose">Which should you choose?</h2>
<p>If you want a fast website without breaking the bank, go for GitHub Pages. It’s completely free and super fast. It does, however, require you to open source your site.</p>

<p>If that’s not doable, CloudFront is a good alternative, but its price depends on how much bandwidth you push around. For most personal sites, CloudFront won’t cost more than a couple of dollars per month. The same thing goes for Google Cloud Storage.</p>

<p>Netlify and Firebase Hosting are pretty solid choices as well. While they don’t perform as well as CloudFront or GitHub Pages, they make up for it with excellent development tools. Everything works out-of-the-box with no configuration required on your end. Just push your website live with their easy to use CLI tools.</p>

<h2 id="download-the-data">Download the data</h2>
<p>The raw CSV data <a href="https://github.com/Savjee/static-website-hosting-benchmark" target="_blank" data-no-instant="data-no-instant">is available on GitHub</a>. Both of 2017 and 2020. Feel free to do your analysis and let me know if you find other interesting things in the dataset. Definitely check out the detailed statistics from Oh Dear!</p>

    </div></div>]]>
            </description>
            <link>https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683403</guid>
            <pubDate>Mon, 05 Oct 2020 00:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whitworth 3 plates method: How to make flat surfaces from scratch]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24683158">thread link</a>) | @ethanwillis
<br/>
October 4, 2020 | https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method | <a href="https://web.archive.org/web/*/https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-597e8ac1bf629a06939204a8" data-item-id="597e8ac1bf629a06939204a8">

  <!--SPECIAL CONTENT-->

  
     
  

  
  <!--POST HEADER-->
    
  <header>
    
    
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1501467179009" id="item-597e8ac1bf629a06939204a8"><div><div><div data-block-type="2" id="block-fbbf397e596a02c81f90"><div><p>A key contribution to precision machine tools was the understanding of the importance of flatness, and the development of processes that are used to make surfaces very flat.&nbsp;Henry Maudslay invented the first machine that could cut standard screw threads and contributed to the invention of the now-common surface plate, which serves an important role in metrology today. A classic book called Foundations of Mechanical Accuracy described this and other concepts in detail. It’s available as a PDF <a href="http://frank.villaro-dixon.eu/public_upload/Foundations%20of%20Mechanical%20Accuracy%20by%20Wayne%20R%20Moore%20-%201970.pdf">here</a> and in print <a href="https://www.amazon.com/gp/product/B0006CAKT8/ref=as_li_tl?camp=1789&amp;creative=9325&amp;creativeASIN=B0006CAKT8&amp;ie=UTF8&amp;linkCode=as2&amp;linkId=9a3b69c12fefcdb4c52fac9cb6d7d37d&amp;tag=eweinhoffer-20">here</a>.</p><p>Typically made of granite, surface plates act as a datum, or the basis upon which precise measurements and movements can be made. They can be finished to a variety of grades of flatness, based on their intended use, and can even be used to <a href="https://youtu.be/sFrVdoOhu1Q?t=378" target="_blank">build up precise structures</a>&nbsp;(that whole video is a must-watch, btw). When dealing with such flat surfaces, tiny imperfections or gradual wear can have drastic effects: using a gauge over the same spot on a surface plate, or leaving it in a space where the temperature varies by more than a few degrees, can negatively affect their flatness. Due to this, calibrating and conditioning your plate is important. The process is really neat, partially because it requires an autocollimator and an incredibly precise repeat-o-meter. Watch a great video from Tom Lipton about the process <a href="https://www.youtube.com/watch?v=EWqThb9Z1jk">here</a>.</p><p>The neat thing about surface plates is that they do not require precision tools to create. By using the “three plate method”, developed by Joseph Whitworth, flat surfaces can be created by using gravity and a simple hand-scraping tool, or by lapping the plates against each other. By starting with three plates of relative flatness, rubbing the plates against each other in alternating pairs to remove the high spots can yield fantastic results.&nbsp;</p><p>The process can be completed in six steps, and then repeated until the desired level of flatness is achieved. In this visual explanation, the surface finishes of the three plates are exaggerated. Before beginning this process, the three plates (Red, Green and Blue) should be machined or ground to as flat a surface as possible, to remove all unnecessary lapping work. In addition, a fine abrasive compound is often used between plates to assist in material removal. Tom also has <a href="https://youtu.be/rHmsQEAx16o" target="_blank">a great video series</a> about this, which includes some compound and technique recommendations.</p><h3><strong>STEP 1</strong></h3><p>To begin, the Red and Green plates are lapped against each other in an alternating manner. That is, one plate remains stationary while the other is lapped against it, and then the opposite is performed:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_27886"><div><p>At the completion of this step, the Red and Green plates “agree with” each other, but that is all.</p><h3><strong>STEP 2</strong></h3><p>Next, the Red plate acts as the control (it remains stationary) while the Blue plate is lapped against it:</p></div></div><div data-aspect-ratio="61" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_70590"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image-dimensions="641x461" data-image-focal-point="0.5,0.5" alt="Step2.PNG" data-load="false" data-image-id="597e90dfe6f2e130978984d8" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_70867"><div><p>At the end of this step, both the Green and Blue plates have picked up the error from the Red plate. They do not agree with each other, however.</p><h3><strong>STEP 3</strong></h3><p>Next, the Green and Blue plates are lapped against each other in an alternating manner:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_77200"><p>Since both of these plates picked up the error of the Red plate from the first two steps, lapping them together removes some of the error from the Red plate, bringing them closer to flat. At this point, the Green and Blue plates are more flat than the Red plate:</p></div><div data-aspect-ratio="33.111111111111114" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_88664"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image-dimensions="669x316" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e913f1e5b6c655dc59803" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_92197"><div><h3><strong>STEP 4</strong></h3><p>Next, the Green plate acts as the control and the Red plate is lapped against it:</p></div></div><div data-aspect-ratio="46.33333333333333" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_94647"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image-dimensions="659x381" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e91bd893fc0db647a42a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_94925"><p>At the completion of this step, all three plates are of roughly equal flatness, but one (Green) is convex and the other two are concave:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_121764"><div><h3><strong>STEP 5</strong></h3><p>Next, move back to an alternating pattern and lap the two concave plates against each other:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_152855"><p>This results in two fairly flat plates. At this point, only the Green plates needs to be brought to the same level of flatness as the other two.</p></div><div data-aspect-ratio="31.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_165836"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image-dimensions="658x331" data-image-focal-point="0.5,0.5" alt="Step5_result.PNG" data-load="false" data-image-id="597eb313be6594cef6b0bcbd" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_166114"><div><h3><strong>STEP 6</strong></h3><p>Finally, the single convex plate is lapped against the Blue control plate:</p></div></div><div data-aspect-ratio="38.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_192139"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image-dimensions="670x342" data-image-focal-point="0.5,0.5" alt="Step6.PNG" data-load="false" data-image-id="597eb4151b631b24fd8c15c9" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_192416"><p>And the result is three plates that are in agreement with each other!</p></div><div data-aspect-ratio="46.666666666666664" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_200838"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image-dimensions="667x386" data-image-focal-point="0.5,0.5" alt="Step6_result.PNG" data-load="false" data-image-id="597eb43ae58c621d0696f9cf" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_201115"><div><p>It’s also worth noting that, although this yields great precision “from nothing”, Joseph Whitworth later improved upon the technique by utilizing engineer’s blue and hand scraping, as mentioned previously. Engineer’s blue alone would be an instrumental improvement over using no indicator - with the blue, it’s easy to see which areas have, and haven’t been, scraped.</p><p>Let me know if you’ve tried this yourself or have any comments about how I can improve the instruction. Most of what I know about the original Three Plates Method came from <a href="https://etshare.pbworks.com/f/Chapter%2014%20Reference%20Planes.pdf" target="_blank">this PDF</a>.</p></div></div><div data-block-type="44" id="block-yui_3_17_2_1_1571515799694_114027"><p><span data-preserve-html-node="true" size="2"><span data-preserve-html-node="true"><span data-preserve-html-node="true" color="#d6d6d6">Note: ericweinhoffer.com is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.com.</span></span></span></p></div></div></div></div></div>
      
  <!--POST FOOTER-->
    
  
  

</article>




<!--PAGINATION-->
  

  




<!-- COMMENTS -->


      </div>

      
        
      

      </section>
      </div></div>]]>
            </description>
            <link>https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683158</guid>
            <pubDate>Sun, 04 Oct 2020 23:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire's nearly divisionless random number generator]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24682483">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. It’s well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, I’ve always felt that code readability is undervalued so I figured I’d put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemire’s nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and they’re in this blog post, but there’s more to this story.</p><p>I didn’t know it at the time but I’d end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldn’t). When people got stuck, we’d whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemire’s Algorithm, with a twenty-to-one comment to code ratio (that’s a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say “sort of” because you really have a ridiculously enormous struggle to find a case where it’s going to be practical to exploit. But it still surprised me, and you probably can’t use Lemire’s algorithm in Vegas.</p><h4>Why Lemire’s Algorithm?</h4><p>I chose Lemire’s algorithm because it is brilliant. When I read Lemire’s code I get that kind of brain-tingling and gawk at the sheer “How on earth did someone think of this” of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable you’ll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemire’s algorithm is a solution to the problem “Give me a random number between 0 and N, not including N itself”. For simulating a dice, N would be 6 and you’d get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results you’d get on a real dice. I’ve worked on random number generators and written quite a few. In 20 years of doing that, I’d never come across a solution as cool as Lemire’s.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. It’s the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number “space” and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemire’s algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I don’t mean them. To the average reader, myself included, it’s not clear what’s going on and why.</p><p>Lemire’s reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemire’s blog, you’ll find several misunderstandings of the code. That’s within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemire’s accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and I’m not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is “N” sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise there’s a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemire’s algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that it’s correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. That’s true when you’re doing a code review and it’s even more true when you’re adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesn’t do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. We’re serious about it, and I wasn’t going to try and use Lemire’s algorithm in s2n without a very readable implementation.</p><p>Working in software development I’ve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I don’t think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the “real world” part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the “science” part of that. Some science is needed, but there’s a shallow limit. Just as a civil engineer doesn’t need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and that’s what matters. </p><h4>The contest</h4><p>One of the reasons I’ve been so tardy about this blog post is that the contest didn’t go as I’d expected. </p><p>Let’s start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemire’s code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as “s”, “t”, “l” which seemingly don’t correspond to much. In such a short piece of code, this actually isn’t too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but it’s absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so that’s who I’ll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrod’s implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity I’ll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons I’ve taken this long to write. It doesn’t feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemire’s algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemire’s original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. I’m sure given more time they could fully understand everything, but that wasn’t the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value “m” and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then there’s also the question of why are we doing this truncation? I’ll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682483</guid>
            <pubDate>Sun, 04 Oct 2020 21:43:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple sues Canadian recycling firm for reselling 100k devices, not destroying]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 124 (<a href="https://news.ycombinator.com/item?id=24680870">thread link</a>) | @geuis
<br/>
October 4, 2020 | https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p><a href="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png"><img src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png" alt="" width="696" height="488" srcset="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png 696w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-350x245.png 350w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-640x449.png 640w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-660x463.png 660w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-560x393.png 560w" sizes="(max-width: 696px) 100vw, 696px"></a></p>
<p>According to <a href="https://thelogic.co/news/exclusive/apple-sues-ontario-electronics-recycling-firm-claiming-it-stole-nearly-100000-products-for-resale/"><em>The Logic</em></a>, an Ontario electronics recycling firm is being sued by Apple, alleging the company stole and resold iOS and watchOS devices instead of destroying them.</p>	
	
	
	
<p>GEEP Canada is being accused of reselling 100,000 iPhones, iPads and Apple Watches, according to Apple’s lawsuit.</p>
<p>Apple says Barrie-based GEEP and members of its senior management team were aware of its activity. GEEP denies all wrongdoing and says when it discovered the reselling ring, it shut it down immediately.</p>
<p>As for damages, Apple is seeking $31 million from GEEP, plus proceeds made from selling iPhones, iPads and Apple Watches.</p>
<p>GEEP was hired by Apple back in the fall of November 2014 to assist in recycling old products instead of being discarded into landfills.</p>
<p>Apple says it sent 531,966 iPhones, 25,673 iPads and 19,277 Apple Watches to GEEP to be recycled from the start of 2015 to the end of 2017, according to lawsuit, seen by <em>The Logic</em>.</p>
<p>“At least 11,766 pounds of Apple devices left GEEP’s premises without being destroyed – a fact that GEEP itself confirmed. These misappropriated devices were then subsequently sold at a significantly higher price than other recycled materials to downstream vendors who refurbished and resold the devices to consumers,” explains Apple’s suit, filed in January.</p>
<p>Apple discovered GEEP was moving devices into areas not under camera surveillance after auditing the Ontario company’s warehouse. The iPhone maker found 18% of devices shipped to GEEP were active on wireless carrier networks.</p>
<p>While some devices like Wi-Fi iPads won’t show up on carrier networks, which Apple says makes the total number of stolen products higher.</p>
<p>GEEP says the reselling ring was due to three “rogue” employees, Roger Micks, Edward Cooper and Steven White, who sold the devices to Fu Yuan Yang at Whitby Recycling. Yang then sold these Apple devices to people in China.</p>
<p>GEEP’s third-party claim from July says it wants these employees, Yang and Whitby Recycling to pay damages if Apple wins, plus cover its legal fees.</p>
<p>The Ontario recycler says it has suffered “extensive business losses” due to the incident and its reputation, to go with Apple cancelling its contract.</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680870</guid>
            <pubDate>Sun, 04 Oct 2020 17:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sonos is spying on me (and you)]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24680614">thread link</a>) | @gingerlime
<br/>
October 4, 2020 | https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2630">
		<!-- .entry-header -->

	
	<div>
		
<p>I recently decided to get a wireless speaker for our Kitchen. Sonos seems like an obvious choice these days. The sound quality and aesthetics were very appealing. So I ordered a Sonos One SL speaker.</p>



<p>In terms of sound quality and looks, I was very pleased. I’m not an audiophile but the sound quality seemed superb and the speaker just looks fantastic. A very clean and unassuming look.</p>



<div><figure><img loading="lazy" width="768" height="1024" src="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg" alt="" srcset="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg 768w, https://blog.gingerlime.com/assets/IMG_6571-1-225x300.jpg 225w, https://blog.gingerlime.com/assets/IMG_6571-1.jpg 1024w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"><figcaption>what’s hiding underneath ?</figcaption></figure></div>



<p><strong>As I later discovered, a dirty beast hides under the cool exterior.</strong></p>



<p>My concerns started to grow almost immediately as I was setting up the new speaker. I downloaded the app, and started the setup process, soon to realize that I need to register with my email just to set up the device on my network… And of course, I had to accept the terms and conditions …. hmmm… ok, I guess.</p>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg" alt="" width="236" height="420" srcset="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg 576w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-169x300.jpeg 169w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1.jpeg 750w" sizes="(max-width: 236px) 100vw, 236px"></figure></div>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png" alt="" width="203" height="361" srcset="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png 375w, https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1-169x300.png 169w" sizes="(max-width: 203px) 100vw, 203px"></figure></div>



<p>I was then asked to allow sharing my location as well, which raised another alarm bell. <strong>Why does my speaker need my location?</strong> I’m not 100% sure, but if I recall, I had to allow it to access my location, or else I couldn’t continue.</p>



<p>Once the device was finally set up, I went through the settings, to explore and see what else is there. I was rather disappointed to find that <strong>“Additional usage data” was turned on by default</strong>. I live in Europe, and I thought that the EU regulations should prevent this kind of behaviour. They should explicitly ask my permission to track my usage, especially if it isn’t necessary for the device to function.</p>



<p>I could opt-out of it luckily, but it didn’t feel right to me.</p>



<h2>What data is Sonos collecting, and why?</h2>



<p>Digging into the <a href="https://www.sonos.com/en/legal/privacy" target="_blank" rel="noreferrer noopener nofollow">Sonos privacy policy</a> made my hair stand… </p>



<div><div>
<h5>Functional Data:</h5>



<div><p>This data is absolutely necessary for your Sonos Product or Service, including Sonos Radio, to perform its basic functions in a secure way and <strong>you will not be able to opt out from this data collection, sharing, and/or processing</strong> if you want to continue to use your Sonos Products.</p><p><strong>We collect:</strong></p></div>



<p><strong>Registration data.</strong> This data includes your email address, location, language preference, Product serial number, IP address, and Sonos account login information (as described above).<br><strong>System data.</strong> This data includes things like Product type, controller device type, controller operating system, software version, content source (audio line in), signal input (e.g. whether your TV outputs a specific audio signal such as Dolby to your Sonos system), information about WiFi antennas, system settings (such as equalisation or stereo pair), Product orientation, names of the music service(s) you added/enabled on your Sonos product, the names you have given your Sonos Product in different rooms, whether your Product has been tuned using Sonos Trueplay technology, system performance metrics (e.g. the temperature of your Product or WiFi signal strength) and error information.</p>
</div></div>



<p>(emphasis not mine)</p>



<p>So this is <em>just</em> the data that you <strong><em>cannot</em></strong> opt-out of. The data <strong>absolutely necessary to perform basic functions.</strong>  And in case you wonder why they track this data, here’s what the privacy policy says</p>



<div><p><strong>Why we collect Functional Data:</strong> We collect this information to help ensure that your Products are working properly, to provide you with customer support, to honour your audio preferences, and to guide product improvement and customer support decisions. We also collect this information to guide product improvement and customer support decisions which is <strong>our legitimate interest</strong>.</p></div>



<p>emphasis mine… we’ll go back to what <em><strong>legitimate interest</strong></em><strong> </strong>actually means later on.</p>



<p>I’m not sure what basic functions for a speaker might be, that they require to share so much data with Sonos. And if this not enough, there’s also the (optional) Usage data that Sonos happily collects, by default, without asking for permission</p>



<div><div>
<div><div>
<h5>Additional Usage Data:</h5>



<p>In order to improve your experience with Sonos Products and to offer better, personalised Sonos Products and Services, including Sonos Radio, that meet the needs and expectations of our customers, we collect the following Additional Usage Data. The processing of this information is in our legitimate interest as further set out below (under Why). You can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#data-opt-out" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p>



<p><strong>We collect:</strong></p>



<ul><li><strong>Performance Information.</strong> This includes things like the temperature of your Product, WiFi information like signal strength, how often you use music services you have connected to your Sonos system (including, for some services, your login username, but not password), information about how often you use the Sonos app versus other control mechanisms, flow of interactions within the Sonos app, how often you use the physical controls on the unit, the flow of interactions within the Sonos app, duration of Sonos Product use, and, as required for certain Services, location-based data using GPS (or similar technology, where available) and crowdsourced WiFi access points and cell tower locations collected from your third party device when the Sonos app is in use.</li><li><strong>Activity Information.</strong> This includes duration of music service use, Product or room grouping information, command information (such as play, pause, change volume, or skip tracks), information about playlist or station container data including listening history (‘Recently Played’), and Sonos playlist or Sonos favourites information; each correlated to individual Sonos Products and your interactions with them. If you enable voice control or use Sonos Radio, we will additionally collect information about track data when using those features.</li></ul>



<blockquote><p><strong>Why:</strong> We collect this information so that we can help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Products. Additionally, to provide Sonos Radio, we collect location-based information for licensing and reporting purposes. <strong>Collecting this data is our legitimate interest</strong> to support a user-friendly experience that meets your needs and help you with issues you may experience. It is your choice if you want us to collect this information, and therefore you can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#rights-choices" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p><p><strong>Note:</strong> personalisation services (e.g. Recently Played), Sonos Radio, Voice Control, and Direct Control functionality require Additional Usage Data to function. If you decide to use any of these features and/or Services, the <a href="https://www.sonos.com/en/legal/privacy#additional-data" target="_blank" rel="noreferrer noopener nofollow">Additional Usage Data</a> becomes functional. You can always clear all Recently Played by following the instructions in the Sonos app.</p></blockquote>
</div></div>
</div></div>



<p>Again, the legitimate interest emphasis is mine…</p>



<p>If you read their privacy policy further, you could spot the real incentives and potential uses of the data, but I won’t dive into it here. I do recommend reading it though.</p>



<h2>(il)legitimate interest</h2>



<p>So what is this all about? Well, if you’re familiar with the General Data Protection Regulation (GDPR), you might guess the answer. I’m not a lawyer, so without going into too much detail, here’s my brief understanding of it.</p>



<p>First off, the GDPR is the regulation that aims to protect the privacy of all EU citizens. It’s meant to reduce privacy invasive practices, force companies to protect private data, and encourage companies to treat private data with care and respect.</p>



<p>But what’s “legitimate interest”, and why is it important?</p>



<p>Essentially, companies aren’t simply allowed to store any customer data they want. They need a “good reason” to do so. Or in other words, they need to have a legitimate interest in storing such data. Otherwise, they’re simply not allowed to store it at all.</p>



<p>So now, can I just ask someone who accesses my website “What’s your home address”? and store it, if they give it to me. I need to have a real reason to ask for this address. It can be my legitimate interest to ask it if, for example, I’m going to send you a free gift. I obviously can’t send you a gift without knowing your address.</p>



<p>As you can imagine, “legitimate interest” can be interpreted in many different ways. Is it legitimate interest to ask for an email address in order to send marketing emails? well, actually it might be. There’s no black and white answer here.</p>



<h2>Putting it to the test</h2>



<p>There are <a href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/legitimate-interests/what-is-the-legitimate-interests-basis/#balancing_test" target="_blank" rel="noreferrer noopener">3 tests for “legitimate interest”</a>:</p>



<div><div>
<div><div>
<ul><li><strong>Purpose test</strong> – is there a legitimate interest behind the processing?</li><li><strong>Necessity test</strong> – is the processing necessary for that purpose?</li><li><strong>Balancing test</strong> – is the legitimate interest overridden by the individual’s interests, rights or freedoms?</li></ul>
</div></div>



<p>Whilst Sonos tries very hard to meet those first two tests with their policies (but in my opinion, have a very weak position there), I think it clearly fails the balancing test. Sonos blatantly violates its customer privacy by excessively tracking, analysing and making use of very detailed information about them. They capture their listening preferences, their location, neighbouring Wifi access points and lots more. And worse of all, they do it without asking for explicit consent. It’s all hidden in the privacy policy, and set to expose all this data by default.</p>



<p>What’s the <strong>purpose</strong> of collecting all this data? Sonos claims that their purpose is “[To] help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Products”. This seems fairly clear as a purpose. Still rather widespread and invasive, but there’s a purpose.</p>



<p>But is collecting all this data <strong>necessary</strong> to meet this purpose? I don’t think so. I think they collect far too detailed information, and they could meet the same purpose with far less data, or by using non-private / anonymised data. </p>



<p>For example: how does the IP address of the customer help with any of those stated purposes? Or why do they need to map neighbouring Wifi access …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680614</guid>
            <pubDate>Sun, 04 Oct 2020 17:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I left my tenured academic job]]>
            </title>
            <description>
<![CDATA[
Score 345 | Comments 192 (<a href="https://news.ycombinator.com/item?id=24680154">thread link</a>) | @adamnemecek
<br/>
October 4, 2020 | https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/ | <a href="https://web.archive.org/web/*/https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time datetime="2020-10-03T09:00:00+0200">Sat, Oct 3, 2020</time></p>

    <p>RSS: </p> <p><a href="https://reyammer.io/blog/index.xml"><img src="https://reyammer.io/rss.png" width="23px"></a></p>

  <p>The <a href="https://twitter.com/reyammer/status/1311338230139232258" target="_blank">news is out</a>: I left France, I'm no longer a professor at EURECOM, I joined the Malware Research Team at CISCO Talos, and I moved to beautiful Vienna. Big change :-)</p>
<p>I have been a professor for a bit more than three years, but I have had contrasting feelings about the "prof job" for a long time (even before finishing my PhD), it took me a couple of years to realize that I would eventually have needed to move on, and it took even more (mental) effort to actually make the call and leave. Despite being <em>very</em> excited for what's next, oh boy, this was tough :-) But independently of the concrete next step, it was time to move on. Even if Talos realizes the mistake and kicks me out next week, I'm still confident that moving on was the right call.</p>
<p>Especially when it comes to take big decisions, I tend to obsess about trying to stay rational, and I spent years collecting notes on the various pros/cons. Many of these thoughts often started surfacing as "feeling something is not right", without consciously understanding what was going on. But by keep thinking and writing notes down, patterns of thoughts started to emerge and I was eventually able to pinpoint some more defined thoughts on what kept me on the current job and what pushed me to change. Once these reasons were clear, it was much easier to take the decision.</p>
<p>This is a very long blog post, and I don't expect more than a very few people to actually read it. I wrote it mostly for selfish reasons: before changing to a new life, I wanted to wrap up all these notes in something more structured. I can't be certain I took a good decision, but systematizing these thoughts allowed me to move on with enough confidence to know I'm likely making a step forward.</p>
<p>With that being said, I know that someone may be actually interested in hearing these thoughts and my experience. When I was a PhD student and I needed to take the notorious academia vs. industry decision, I would have paid big bucks to read more thoughts on the various pros/cons. One of the stupidest things you can do is to take big decisions based on what other people do and think, but reading about other people's thought process has helped me a lot. It is time I do my part.</p>
<p>The target audience for this post is, other than myself, PhD students / postdocs that are about to decide what to do next and junior profs that somehow feel that "something is wrong". I also expect some senior academics and industry people to read this post, but I guess they will find themselves skipping directly to the academic rant part and mostly agree with much I have to say :-) Anyways, I tried to stay away from the "very known things" (e.g., 👀-level BS when writing proposals, generally "more limited" immediate impact of your work, different compensation level, etc.), and I tried to focus on thoughts I have not seen much discussed around (at least not in this depth).</p>
<p>So, if you feel clueless and you want to hear more from an equivalently clueless random dude on the Internet, here we are :-) If you think this is <em>the</em> blog post that will make everything clear, I have a bad news for you: it's all about tradeoffs and in my opinion there is no clear-cut winner. And, unfortunately, the problem with tradeoffs and balancing many aspects is that figuring out which one to weigh more is yet another very personal decision in its own way. So, you will not find any answer in this post and you will eventually need to figure this thing out on your own, but I hope this will help you forming your own opinion.</p>
<p>This post is organized in three parts:</p>
<ul>
<li><a href="#part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</a></li>
<li><a href="#part-2-the-bad-mdash-what-pushed-me-to-leave-the-job">Part 2: The Bad — What pushed me to leave the job</a></li>
<li><a href="#part-3-the-bye-bye-mdash-the-decision-to-leave">Part 3: The Bye Bye — The decision to leave</a></li>
</ul>
<p>Enjoy!</p>
<p><em>Mandatory disclaimer: I have no idea what I'm talking about, and these are personal takes/opinions anyways. Unless you are a bad person, please don't take anything personal. Please feel free to reach out, ping me on twitter, or shoot me an email: I'm of course happy to share more thoughts if you have any question. And if you disagree with something, bring it on! I love to argue, especially with people with strong and different opinions :-)</em></p>
<br>
<h2 id="part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</h2>
<p>Before I discuss why I left, I want to touch on what pushed me to keep the job. I want to make sure it's a balanced post despite the upcoming mega rant, so that my overall opinion is more closely reflected. And I really don't want to discourage anyone to take this path, I still think it is a great one.</p>
<p>Note that some of my "reasons to stay" are good, but some are bad. Also note that many of these refer to my personal situation at EURECOM, working in the field of systems security, and not all these points can be generalized to all universities. As they say, your mileage may vary.</p>
<h3 id="its-a-very-good-job">It's a very good job</h3>
<p>The first pros is... 🥁: "it's a very good job". At first, I was shocked to find out that it's an actual job. When I joined this prof thingy I thought that this would be a "job" (note the double quotes). But, while it's true that you don't have a direct boss that tells you what to do, at the end of the day you need to deliver, and you actually work very hard: If your PhD students are in trouble or you teaching sucks, you will run into problems. This doesn't necessarily mean "they kick out", but if you value being a professional (and I do), failing at your core tasks will make you feel bad, even without additional pressure from your superior, and even if you have tenure.</p>
<p>And now that we got this "it's an actual job" out of the way, I can tell you: it's a very good one. There is <em>a lot</em> of freedom in what you do and how you structure your time. Research-wise I felt very free (but you eventually work on what your students like to work on — as it should be), and the department values the right things (I've heard some BS in other schools where, in the context of systems security research, they pressure you to "publish more journal papers..." 🤦‍♂️). I really like teaching and mentoring, and there were many opportunities to do so. They let me create and teach my own class on mobile security, <a href="https://mobisec.reyammer.io/" target="_blank">MOBISEC</a>, and the teaching load is overall very low (1 or 1.5 classes per year). I love playing CTFs and I was even <em>encouraged</em> to spend time and push for NOPS, the EURECOM CTF team (after winning <a href="https://ctftime.org/event/647" target="_blank">HXP CTF 2018</a> and after being referred to as "<a href="https://youtu.be/j0taw78tCYs?t=968" target="_blank">probably a top team</a>" we are mostly enjoying our eternal and well-deserved glory).</p>
<p>The environment is extremely relaxed, informal, and friendly. You are surrounded by top-skilled colleagues and humans, from MS students to profs. I felt in a family from day 1. Last very good point: since in France positions come with tenure, there were not even problems in terms of pre-tenure stress, a real luxury. And on this aspect, EURECOM delivered: I never felt any sort of pressure (but: I did work my ass off... so if you stop doing anything, bad things may happen :-)).</p>
<p>[BTW, EURECOM is frantically trying to replace me, you should apply :-)]</p>
<h3 id="you-are-surrounded-by-students">You are surrounded by students</h3>
<p>When I took my decision to remain in academia, my top reason was for teaching and mentorship. Probably the best perk of the job is that you are surrounded by people eager to learn, from MS to PhD students to postdocs. It is extremely fulfilling and rewarding. Working with my students has been the highlight of my time at EURECOM, from traditional teaching, to suffering through the various rejections, to celebrating defeats of Reviewer #2, to cluelessly getting CTF-close in many stego CTF challenges. I feel very lucky that during these years we found enough interesting ideas that we enjoyed working on together, and that my next job will allow me to keep advising them until they graduate. As a prof, I believe the net output of my work is to see students becoming independent researchers, not the actual papers — I can't wait to see the bright careers I'm sure they will have :-)</p>
<h3 id="i-have-deep-respect-for-the-role-of-profs-in-society-and-it-felt-great-to-be-one">I have deep respect for the role of "profs" in society, and it felt great to be one</h3>
<p>I somehow have a profound admiration for the role that professors have in society and that had in my life. For their hard work, knowledge, passion, patience, and ultimately their service to the community. I'm referring to all teachers and mentors (from elementary schools to universities), who spend their life helping others, while at the same time often being asked to do many useless things and being massively underpaid. I admire and deeply respect these efforts: my most sincere thank you to all past, present, and future profs!</p>
<p>And, to be frank, it felt great to be one. I have been in love with the idea of being a prof for many years. In part, I think it is because some of the people who impacted me the most are professors, and I wanted to do my part in helping others. And after all the uncertainties that one has during a PhD, I think I was even more in love with the idea of having finally found my place in society. [Narrator: LOL, this clueless dude did not find his place. [Answer to narrator: But I've surely found it <em>now</em>!!1!]]</p>
<p>Overcoming all these positive emotions and feelings attached to this job was likely the biggest challenge I faced in coming to terms with the several problems and cons I did have during these three years. As mentioned, I have no intention to give up on this teaching/mentoring thing (taking the time for this long blog post is part of this!), but it will surely not be the same thing. I'm very grateful I had a chance to try this job out. Thanks to all who made it possible, from family to advisors, colleagues, and students ❤️. I owe you big time.</p>
<p>[Of course, being a prof does not necessarily make you a smart or great person. Some profs I know are some of the dumbest people I have ever met (by far) and they would not survive one day in the real world. And some profs I know are the most asshole, selfish, egomaniac, and delusional humans I have ever heard of (Are you pushing your students to stay in the lab …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</a></em></p>]]>
            </description>
            <link>https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680154</guid>
            <pubDate>Sun, 04 Oct 2020 16:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a Unix-like OS on a home-built CPU with a home-built C compiler]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24680109">thread link</a>) | @abc_tkys
<br/>
October 4, 2020 | https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/ | <a href="https://web.archive.org/web/*/https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>It’s been two years since I started working as a software engineer.
I sometimes tell my colleagues about a student project I did in my junior year of university,
and it’s so well-received that I’m writing this post.
<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Now, let me ask you a question. Have you ever designed your own ISA, built a processor of that ISA on FPGA, and built a compiler for it?
Furthermore, have you run an operating system on that processor?
Actually, we have.</p>
<p>In this post, I’m going to talk about my undergraduate days in 2015,
our four months of building a home-built CPU of a home-built RISC ISA,
building a home-built C toolchain, and porting Xv6, a Unix-like OS, to that CPU.</p>
<h2 id="cpu-experiment-at-the-university-of-tokyo">CPU Experiment at the University of Tokyo</h2>
<p>It was all done as a student experiment project called CPU Experiment.
So, let’s start with what is CPU experiment.</p>
<p>CPU experiment is a little famous exercise held in the winter of the junior year in my department,
the Department of Information Science at the University of Tokyo.
In the experiment, students are divided into groups of four or five students.
Each group designs an own CPU architecture, implements it on an FPGA,
builds an OCaml subset compiler for that CPU, and then runs a given ray-tracing program on the CPU.
Typically, one or two people are responsible for each of the CPU, FPU, CPU simulator and compiler.
I was in charge of the CPU in my group, Group 6.</p>
<p>This exercise is well known for the high expectation of self learning.
The instructor only asks the students to “take this ray-tracing program written in OCaml and run it on your CPU implemented on an FPGA”, and the class ends.
He/she doesn’t tell much about the concrete steps of how to write CPU and compilers.
The students learn for themselves how to embody the general knowledge of CPUs and compilers learned in previous lectures to the level of real circuits and code.
Well, this is a very tough exercise, but very exciting and educational.</p>
<h2 id="lets-run-operating-system-on-our-own-cpu">Let’s run Operating System on our own CPU.</h2>
<p>As some of you may have noticed, I didn’t talk about operating system at all.
I’ll add a little explanation.</p>
<p>Typically, the experiment proceeds as follows.
First, you make a CPU that works reliably, no matter how slow it is.
If you can make a working CPU and successfully run the ray-tracing program, you can earn the credit of the experiment.
After that, your team has a free time.
The traditional way to spend this free time is to further speed up their CPU.
In past experiments, students have made out-of-order CPU, VLIEW CPU, multi-core CPU, or even superscalar CPU, which is amazing.</p>
<p>However, some teams put more energy into doing fun such as running games or playing music by connecting a speaker with their CPU.
Group 6, to which I belonged, was a group of such people who loved entertainment,
and we decided to run an OS as our team goal.</p>
<p>As a result of other groups showing interest in this idea, a joint group of about 8 people, Group X,
was formed, and their goal was “Let’s run an OS on our own CPU!”</p>
<p>Although I was in charge of creating a CPU in Group 6,
this time I chose to be the leader of the OS team in the Group X.
So this post is written primarily from the perspective of the OS team,
but of course I also introduce the overall group’s results.</p>
<h2 id="xv6">Xv6</h2>
<p>As the OS to be ported, we chose Xv6, a simple Unix v6-inspired OS created by MIT for educational purposes.
Xv6 is written in ANSI C, unlike Unix v6, and it runs on x86.
Xv6 is an educational OS, so its features are a bit poor, but it has sufficient features as a simple Unix-like OS.
You can find more information of Xv6 on <a href="https://en.wikipedia.org/wiki/Xv6" target="_blank">Wikipedia</a>

 or <a href="https://github.com/mit-pdos/xv6-public" target="_blank">the GitHub repository</a>

.</p>
<h2 id="challenges">Challenges</h2>
<p>In porting xv6, there are a lot of challenges on the software side alone because we were trying to create everything from scratch.</p>
<p><strong>1. C Compiler and tool chain for Xv6</strong></p>
<p>In the CPU experiment, we usually create an ML compiler. Naturally, you can’t compile C codes of Xv6.</p>
<p><strong>2. What kind of CPU features required for operating system?</strong></p>
<p>Privilege protections? Virtual address? Interrupt?
Yes, we had overall understanding of what operating system does by lectures,
but we didn’t have solid enough understanding to explain what specific CPU features could make that happen at that time.</p>
<p><strong>3. What about the simulator?</strong></p>
<p>We had a simulator made in the core part of CPU experiment,
but it was a simple one that executes one instruction by instruction,
and there was no interruption or no virtual address conversion.</p>
<p><strong>4. Low portability of xv6</strong></p>
<p>Xv6 was not very portable.
For example, it assumes the <code>char</code> is 1 byte and <code>int</code> is 4 bytes, and manipulates the stack heavily.
Well, the name “Xv6” I guess comes from x86 and Unix “v6”, so it’s kind of natural.</p>
<p>We had a lot of concerns, but started the Group X’s OS porting project in December.<br>
From here I’m going to write about what we did in roughly chronological order.
It’s a little bit long, so if you want to look at our final products quickly, <a href="#march---xv6-runs">please jump to March</a>

.</p>
<h2 id="late-november---starting-the-compiler">Late November - Starting the compiler</h2>
<p>The first problem that we saw the answer to was the compiler and tool chain.
To be surprise, our decision was to build the C89 compiler from scratch.
To be honest, I hadn’t imagined that we would choose this way.
I remember I talked with Yuichi, who became in charge of CPU of Group X, about doing a gcc or llvm port at first.</p>
<p>However, one of the team members, Keiichi, suddenly said he had written a C compiler and showed us a prototype of a compiler with a simple parser and emitter.
It seemed more fun to write the toolchain from scratch, so we decided to write a compiler by ourselves.</p>
<p>Yuichi and Wataru from Group 3, who had already finished the core part of the experiment that year, joined Keiichi, and the Group X compiler team was born.
We later named our compiler Ucc.</p>
<h2 id="mid-december---the-os-team-is-up">Mid-December - The OS team is up!</h2>
<p>At the beginning of December, I completed my CPU, and Group 6 completed the core part of the CPU experiment.
So, we moved on to the fun part, Group X’s OS porting task.
At this time, myself and Shohei from Group 6 started working in Group X and became the OS team. Masayoshi joined it at the same time.</p>
<h3 id="core-part-of-the-experiment-writing-a-cpu">Core part of the experiment: Writing a CPU</h3>
<p>By the way, I guess not so many software engineers have ever written a CPU, so let me talk a little bit about making a CPU as well.</p>
<p>Nowadays, making a CPU doesn’t mean wiring every single jump wire on a breadboard; you write the circuitry in Hardware Description Language.
Then you synthesize that HDL into a real circuit using Vivado or Quartus.
This process is called logic synthesis, not compilation.</p>
<p>HDL and programming language are similar but different.
Think of it like writing a function that maps the signal state of registers to another signal state, triggered by a clock or input signal.
If you want to experience real reactive programming, I suggest you try writing an HDL.
Please also remember to write HDLs, always worrying about whether the signal propagation of the HDLs you write really ends up in one clock.
Otherwise, the behavior of your circuits would be incomprehensible to humans.</p>
<!-- You'd write a CPU state machine that decodes the machine instructions each time the clock rises, and then performs ALUs and branches accordingly, and updating the state of the exposed registers as an interface to the assembly. -->
<p>The hardest part of the actual development was that this logic synthesis took a ridiculous amount of time.
It was not uncommon for us to have to wait up to 30 minutes after starting the synthesis,
so once I started the synthesis,
I was often playing Smash Bros. Melee with the other CPU guys who were also waiting for the synthesis to finish.
FYI, my character was Sheik.</p>
<h2 id="late-december-to-mid-january---learn-by-porting-xv6-to-mips">Late December to mid-January - Learn by porting Xv6 to MIPS</h2>
<p>We began to find the answer to “What kind of CPU features required for operating system?”</p>
<p>After the OS team was born, we started weekly rounds of Xv6 source code reading.</p>
<p>At the same time, I started porting Xv6 to MIPS.
This was partly to learn how an OS works at the implementation level, and partly because there appeared to be no Xv6 port to MIPS.
I completed the port until the process scheduler started in about a week.
I did a lot of research on MIPS during this porting process,
and on x86 to understand how xv6 works.
Thanks to that, I understood mechanisms around interrupts and MMU at the implementation level.
At this stage I got a solid understanding of the CPU functionality required for Xv6.</p>
<p>Also, in mid-January, we worked hard to compile the entire Xv6 code by commenting out the various parts.
As a result, Xv6 on the simulator of our homebrew architecture showed the first message of the boot sequence,</p>
<pre><code>xv6...
cpu0: starting...
</code></pre><p>At the same time, this meant that by this time Ucc had already grown enough to compile most of xv6, which was awesome.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<h2 id="february---our-cpu-gaia-was-born">February - our CPU, GAIA was born!</h2>
<p>In the MIPS port, I completed the initialization of the PIC, which was a real pain,
and also completed the implementation of the interrupt handler.
As a result, the porting of Xv6 to MIPS was completed until just before the first user program started.</p>
<p>Based on this experience, I made the draft specifications of the interrupt and virtual address translation for our homebrew CPU.
In order to keep it simple, we decided to omit hardware privilege mechanisms like Ring protection.
For virtual address translation, we decided to use a hardware page-walking method, just like x86.
It may seem difficult to implement in hardware, but we thought it was cheaper if we sacrificed the speed and omit TLB implementation.
After all, Yuichi made an excellent CPU core later, and it installed TLB from the beginning though.</p>
<p>Yuichi completed the overall design of the ISA of our CPU.
He named our CPU GAIA.
In typical CPU experiment projects, we don’t implement interrupt nor MMU.
However, Yuichi started to implement them for Xv6, based on the refactored version of the CPU of Group 3.</p>
<p>I’ll note the weekly records as the rapid progress begins from then on!</p>
<h2 id="1st-week">1st Week</h2>
<p>Instead of just commenting boot sequences out, Masayoshi started implementing actual initialization of our CPU,
and Shohei rewrote the x86 assembly of Xv6 into our homebrew architecture’s.
I added interrupt simulation capability to our simulator which Wataru had made …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</a></em></p>]]>
            </description>
            <link>https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680109</guid>
            <pubDate>Sun, 04 Oct 2020 16:17:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fibers, Oh My]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24679740">thread link</a>) | @zdw
<br/>
October 4, 2020 | https://graphitemaster.github.io/fibers/ | <a href="https://web.archive.org/web/*/https://graphitemaster.github.io/fibers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Written by Dale Weiler, last updated Oct 5th, 2020</p>
<ul>
<li>
  <a href="https://twitter.com/actualGraphite">Twitter</a></li>
<li>
  <a href="https://github.com/graphitemaster">GitHub</a></li>
</ul>
<p>It’s been brought to the attention of many people in the game development industry that you can use fibers to parallelize your engines and games. This one presentation in particular:
  <a href="http://twvideo01.ubm-us.net/o1/vault/gdc2015/presentations/Gyrling_Christian_Parallelizing_The_Naughty.pdf">Parallelizing the Naughty Dog engine using fibers</a> has been a talking point since it came out in 2015. However, it doesn’t quite go into the details enough to really explain why fibers are a good fit or how to actually implement them. In my pursuit to educate myself and take a stab at implementing them, I’ve concluded that there’s a distinctive lack of good information online. In response to the lack of literature on this topic, I’ve decided to explain it from multiple angles, and provide less known information on the subject. This document serves as a
  <a href="https://en.wikipedia.org/wiki/Sourcebook">Sourcebook</a> for those who really want to determine if it’s a right fit for them and how to go about actually doing it.</p>
<h2 id="disambiguation-of-terms">
  Disambiguation of terms.
  <a href="#disambiguation-of-terms">#</a>
</h2>
<p>Before we get started I want to define three distinctive terms.</p>
<ul>
<li>OS-thread (the thread given to us by the OS)</li>
<li>Hardware-thread (the actual physical thread on a CPU)</li>
<li>Fiber-thread (the thread of execution that is our fiber)</li>
</ul>
<h2 id="what-are-fibers">
  What are fibers?
  <a href="#what-are-fibers">#</a>
</h2>
<p>Fibers are a lightweight thread of execution similar to OS threads. However, unlike OS threads, they’re cooperatively scheduled as opposed to preemptively scheduled. What this means in plain English is that fibers <em>yield</em> themselves to allow another fiber to run. You may have used something similar to this in your programming language of choice where it’s typically called a <em>coroutine</em>, there’s no real distinction between coroutines and fibers other than that coroutines are usually a language-level construct, while fibers tend to be a systems-level concept.</p>
<p>Other names for fibers you may have heard before include:</p>
<ul>
<li>green threads</li>
<li>user-space threads</li>
<li>coroutines</li>
<li>tasklets</li>
<li>microthreads</li>
</ul>
<p>There are very few and minor differences between fibers and the above list. For the purposes of this document, we should consider them equivalent as the distinctions don’t quite matter.</p>
<h2 id="scheduling">
  Scheduling
  <a href="#scheduling">#</a>
</h2>
<p>At any given moment the OS is running multiple processes all with their own OS threads. All of those OS threads need to be making forward progress. There’s two classes of thought when it comes to how you solve this problem.</p>
<ul>
<li>
  <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">Cooperative scheduling</a></li>
<li>
  <a href="https://en.wikipedia.org/wiki/Preemption_%28computing%29">Preemptive scheduling</a></li>
</ul>
<p>It’s important to note that while you may observe that all processes and OS threads are running in parallel, scheduling is really providing the <em>illusion</em> of that. Not all threads are running in parallel, the scheduler is just switching between them quickly enough that it appears everything is running in parallel. That is they’re <em>concurrent</em>. Threads start, run, and complete in an <em>interleaved</em> fashion.</p>
<blockquote>
<p>It is possible for multiple OS threads to be running in parallel with
  <a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">symmetric multiprocessing</a> (SMP) where they’re mapped to multiple hardware threads, but only as many hardware threads as the CPU physically has.</p>
</blockquote>
<h3 id="premptive-scheduling">
  Premptive scheduling
  <a href="#premptive-scheduling">#</a>
</h3>
<p>Most people familiar with threads know that you don’t have to <strong>yield</strong> to other threads to allow them to run. This is because most operating systems (OS) schedule threads <strong>preemptively</strong>.</p>
<p>The points at which the OS may decide to preempt a thread include:</p>
<ul>
<li>IO</li>
<li>sleeps</li>
<li>waits (seen in locking primitives)</li>
<li>interrupts (hardware events mostly)</li>
</ul>
<p>The first three in particular are often expressed by an application as a
  <a href="https://en.wikipedia.org/wiki/System_call">system call</a>. These system calls cause the CPU to cease executing the current code and execute the OS’s code registered for that system call. This allows the OS to service the request then resume execution of your application’s calling thread, or another thread entierly.</p>
<p>This is possible because the OS will decide at one of the points listed above to save all the relevant state of that thread then resume some other thread, the idea being that when this thread can run again, the OS can reinstate that thread and continue executing it like nothing ever happened. These transition points where the OS switches a thread are called
  <a href="https://en.wikipedia.org/wiki/Context_switch">context switches</a>.</p>
<p>There’s a cost associated with this context switching and all modern operating systems have made great deals of effort to reduce this cost as much as possible. Unfortunately, that overhead begins to show itself when you have <em>a lot</em> of threads. In addition, recent cache
  <a href="https://en.wikipedia.org/wiki/Side-channel_attack">side channel attacks</a> like:
  <a href="https://en.wikipedia.org/wiki/Spectre_%28security_vulnerability%29">Spectre</a>,
  <a href="https://en.wikipedia.org/wiki/Meltdown_%28security_vulnerability%29">Meltdown</a>,
  <a href="https://en.wikipedia.org/wiki/Spoiler_%28security_vulnerability%29">Spoiler</a>,
  <a href="https://en.wikipedia.org/wiki/Foreshadow_%28security_vulnerability%29">Foreshadow</a>, and
  <a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a> on modern processors has led to a series of both user-space and kernel-space mitigation strategies, some of which increased the overhead of context switches significantly.</p>
<blockquote>
<p>You can read more about context switching overhead in
  <a href="https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf">this paper</a>.</p>
</blockquote>
<h3 id="cooperative-scheduling">
  Cooperative scheduling
  <a href="#cooperative-scheduling">#</a>
</h3>
<p>This idea of fibers yielding to each other is what is known as cooperative scheduling. Fibers effectively move the idea of context switching from kernel-space to user-space and then make those switches a fundamental part of computation, that is, they’re a deliberate and explicitly done thing, by the fibers themselves. The benefit of this is that a lot of the previously mentioned overhead can be entierly eliminated while still permitting an excess count of threads of execution, just in the form of these fibers now.</p>
<h2 id="the-problem-with-multi-threading">
  The problem with multi-threading
  <a href="#the-problem-with-multi-threading">#</a>
</h2>
<p>There’s many problems related to multi-threading, most obviously that it’s difficult to get right. Most proponents of fibers make false claims about how this problem goes away when you use fibers because you don’t have parallel threads of execution. Instead, you have these cooperatively scheduled fibers which yield to each other. This means it’s not possible to
  <a href="https://en.wikipedia.org/wiki/Race_condition">race data</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock">dead lock</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock#Livelock">live lock</a>, etc. While this statement is true when you look at fibers as a N:1 proposition, the story is entierly different when you introduce M:N.</p>
<h3 id="n1-and-what-it-means">
  N:1 and what it means
  <a href="#n1-and-what-it-means">#</a>
</h3>
<p>Most documentation, libraries, and tutorials on fibers are almost exclusively based around using a single thread given to you by the OS, then sharing it among multiple fibers that cooperatively yield and run all your asynchronous code. This is called N:1 (“N to one”). <code>N</code> fibers to <code>1</code> thread, and it’s the most prevalent form of fibers. This is how Lua coroutines work, how Javascript’s and Python’s async/await work, and it’s <strong>not what you’re interested in</strong> doing if you actually want to take advantage of hardware threads. What you’re interested in is M:N, (“M to N”) <code>M</code> fibers to <code>N</code> threads.</p>
<h3 id="mn-and-what-it-means">
  M:N and what it means
  <a href="#mn-and-what-it-means">#</a>
</h3>
<p>The idea behind M:N is to take the model given to us by N:1 and map it to multiple actual OS threads. Just like we’re familiar to the concept of thread pools where we execute tasks, here we have a pool of threads where we execute fibers and those fibers get to yield more of themselves on that thread.</p>
<blockquote>
<p>I should stress that M:N fibers have all the usual problems of multi-threading. You still need to syncronize access to resources shared between multiple fibers because there’s still multiple threads.</p>
</blockquote>
<h2 id="the-problem-with-thread-pools">
  The problem with thread pools
  <a href="#the-problem-with-thread-pools">#</a>
</h2>
<p>A lot of you may be wondering how this is different from traditional task based parallelism choices seen in many game engines and applications. The model where you have a fixed-size pool of threads you queue tasks on to be executed at some point in the future by one of those threads.</p>
<h3 id="locality-of-reference">
  Locality of reference
  <a href="#locality-of-reference">#</a>
</h3>
<p>The first problem is <em>locality of reference</em>. The data-oriented / cache-aware programmers reading this will have to mind my overloading of that phrase because what I’m really talking about is the resources that a job needs access to are usually local. The job isn’t going to be executed immediately, but rather when the thread pool has a chance to. Any resource that job needs access to, needs to be available for the job at some point in the future. This means local values need their lifetime’s extended for an undefined amount of time.</p>
<p>There’s many ways to solve this lifetime problem, except they all have overhead. Consider this trivial example where I want to asynchronously upload a local file to a webserver</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>upload_file</span>(<span>const</span> String<span>&amp;</span> filename) {
  thread_pool<span>-&gt;</span>add_job([<span>&amp;</span>] {
    <span>auto</span> file <span>=</span> open_file(filename);
    <span>auto</span> data <span>=</span> read_file(file);
    post_binary_data(data);
  });
}
</code></pre></div><p>Do you see the bug?</p>
<p>The issue is that the string passed to <code>upload_file</code>, i.e the local <code>filename</code>, only has a lifetime of the body of the function. When this function returns, <code>filename</code> no longer is a valid string. However, at some point this lambda function will be executed and try to access <code>filename</code> in it’s local context and it’ll be a dangling reference by then.</p>
<p>This can be surprsing to those more familiar with dynamic languages, since they support this functionality with something called a closure. The closure will actually extend the lifetime of <code>filename</code>. In native languages like C or C++ though, this isn’t the case and all lifetime extension needs to be done explicitly with obvious runtime which introduces overhead.</p>
<p>What you could do is <strong>copy</strong> the string. The copy will then have the lifetime of the lambda. However, if we had a much larger resource to share with this job that couldn’t be as cheaply copied, we would have to use something like a <strong>reference count</strong> instead. As you can see, the solutions to the resource problem involve a great deal of overhead in many cases and requires you to really think and reason about lifetimes here when you didn’t have to, nor should you have to.</p>
<p>We’re experiencing a lot of friction here already and it’s only a few lines of code. My personal rule of thumb is if you find yourself experiencing friction like this, it’s usually indicative of bad design and the problem needs to be rethought.</p>
<h3 id="nested-induced-deadlocks">
  Nested induced deadlocks
  <a href="#nested-induced-deadlocks">#</a>
</h3>
<p>The other significant problem with thread pools is what I call <em>nested induced deadlocks</em>. No matter how you slice and dice it, jobs are going to want to schedule other jobs and need the result before they themselves can continue.</p>
<p>Let me set up a real world example because it’s easier to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphitemaster.github.io/fibers/">https://graphitemaster.github.io/fibers/</a></em></p>]]>
            </description>
            <link>https://graphitemaster.github.io/fibers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679740</guid>
            <pubDate>Sun, 04 Oct 2020 15:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Put a Raspberry Pi in a Rocket]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24679435">thread link</a>) | @johnjones4
<br/>
October 4, 2020 | https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/ | <a href="https://web.archive.org/web/*/https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://news.ycombinator.com/item?id=24679435">Q&amp;A on Hacker News about this project</a></p>
<p>As we're driving out to our launch site in Leesburg, VA, my wife turns to me and asks, "did you intentionally wear a yellow and blue striped rugby shirt to match your yellow and blue striped rocket?" I look down, and realize that, yes I had indeed accidentally dressed exactly like my rocket. I wonder if that ever happens to Elon?</p>
<h2>Launches</h2>
<p><img src="https://johnjonesfour.com/images/rocket/launch.jpg" alt="Launch images"></p>
<p>Very special thank you to my exceptionally patient wife who tagged along, captured these great pictures, and ended up actually having a lot of fun with her very nerdy husband.</p>
<p>Ida Lee Park in Leesburg, VA allows rocket launches up to 400 feet with a permit, so I applied earlier in September for an October 3rd launch and received fast approval. With the day upon us, my wife and I made the 40 minute drive to Leesburg (apparently in uniform?), set up in our designated part of the park, and got to work.</p>
<h3>Launch 1</h3>
<p><img src="https://johnjonesfour.com/images/rocket/telemetry.gif" alt="Telemetry"></p>
<p><img src="https://johnjonesfour.com/images/rocket/launch1.png" alt="Launch 1"></p>
<p>The first launch was a huge success. The rocket reached 110.3 meters (~362 feet), which beat my simulation's prediction of 90 meters, and it reached a peak velocity of 41.69 meters per second (~93 mph) at 1.44 seconds into the flight. We can see the rocket started to descend very quickly after apogee, and the chute deployed successfully 7.5 seconds into the flight. From there, the chute allowed for a linear rate of descent to a gentle field landing.</p>
<h3>Launch 2</h3>
<p><img src="https://johnjonesfour.com/images/rocket/launch2.png" alt="Launch 2"></p>
<p>Launch 2 was less of a success. While the ascent went smoothly, telemetry was lost 4.57 seconds into flight and the ejection charge ripped the shock cord causing the two rocket components to separate with no parachute to slow their descent. This incident also knocked out the battery cable causing inboard video and data capture to also fail. Unfortunately no video data could be recovered.</p>
<h2>Next Steps</h2>
<p><img src="https://johnjonesfour.com/images/rocket/recovery.jpg" alt="Rocket after launch"></p>
<p>The second launch revealed three major issues that need to be resolved: </p>
<ol>
<li>The shock cord is not strong enough to absorb the force caused by separation, likely because of how heavy the payload is. In a future upgrade I will need to double-up the cords OR use two parachutes for each component to let them descend separately.</li>
<li>When the payload section hit the ground, it drove the coupler way into the body tube. Upon impact, the battery bracket absorbed the force and shattered. However all of the electronics survived. Part of the coupler also broke off when I attempted to pull the it out of the payload section, so this will all need to be redesigned to better absorb hard landings.</li>
<li>There must be a buffer that holds a certain amount of camera footage before saving it to disk. Because the battery disconnected in-flight, no flight video saved. I'd like to figure out how to write video data more frequently in case the battery issue happens again.</li>
</ol>
<p>In addition to those major issues, I'd also like to make the following improvements:</p>
<ol>
<li>The software performed well, but I'd still like to increase the data capture rate. There are Adafruit libraries for the components I'm using in C++, so I'm considering rewriting <code>air.py</code> in C++, but I'd really love it if someone talked me out of that.</li>
<li>Between launches I manually rebooted the ground computer so that it would clear the visualizations and start logging to a new file. To make this easier, I plan to add the option to the dashboard to start new "capture sessions" without needing to restart the system.</li>
</ol></div></div>]]>
            </description>
            <link>https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679435</guid>
            <pubDate>Sun, 04 Oct 2020 14:48:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[French bar owners arrested for offering free WiFi but not keeping logs]]>
            </title>
            <description>
<![CDATA[
Score 659 | Comments 310 (<a href="https://news.ycombinator.com/item?id=24678702">thread link</a>) | @seigando
<br/>
October 4, 2020 | https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/ | <a href="https://web.archive.org/web/*/https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1007">
														
							
														
							
														
							<div>
															<div>
									<p>At least five bar owners in Grenoble, France have been arrested for providing WiFi at their businesses without keeping logs. The bar owners were arrested under a 2006 law that technically classifies WiFi hotspot providing establishments as ISPs, and requires them to store one year’s worth of logs or connection records for anti-terrorism purposes. This requirement is in place even if the WiFi network is password protected.</p>
<p>The law No. 2006-64&nbsp;<a href="https://www.bfmtv.com/economie/des-patrons-de-bars-en-garde-a-vue-a-cause-du-wi-fi-offert-a-leurs-clients_AN-202009290142.html" target="_blank" rel="noopener noreferrer">extends</a>&nbsp;the traditional ISP logging requirements “to all persons who, in respect of an activity primary or secondary professional, offer the public a connection allowing on-line communication via network access, including free of charge.” Violating this crime means that the owner of a small cafe that offers WiFi to patrons could face up to one year in prison and up to a 75,000 euro fine.</p>
<h2>All businesses in France providing WiFi to the public are required to log</h2>
<p>That all public WiFi hotspots in France are required by law to be logging shouldn’t be too surprising.&nbsp;<a href="https://www.bfmtv.com/economie/des-patrons-de-bars-en-garde-a-vue-a-cause-du-wi-fi-offert-a-leurs-clients_AN-202009290142.html" target="_blank" rel="noopener noreferrer">BFM Business</a>&nbsp;noted that most large providers of free WiFi like hotels, conference centers, airports, and such do so with business packages that include this logging. However, it seems that most people aren’t aware that even small businesses like bars, cafes, nightclubs, and restaurants that offer WiFi to their patrons are faced with these logging requirements. One of the arrested bar owners noted that the relevant organization, Umih, never noted this requirement when renewing his license:</p>
<blockquote><p>“Nobody, not even the professionals of Umih who provide compulsory training as part of a license IV resumption, to me never said I should keep this history.”</p></blockquote>
<p>In response to questions by BFM Business, Umih admitted that the training doesn’t mention WiFi logging but noted that Umih members should have known about this important requirement because it was mentioned in a newsletter.</p>
<p>If anything, this piece of dystopian news highlights the state of surveillance in France and the desperate need for online privacy there, as well. Small business owners in France need to make sure that they are in compliance with the laws; similarly, public WiFi users in France need to make sure they never connect without a VPN.</p>
																	</div>
														</div>
														

																				</article></div>]]>
            </description>
            <link>https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678702</guid>
            <pubDate>Sun, 04 Oct 2020 12:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Ways of DevOps]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24678055">thread link</a>) | @kiyanwang
<br/>
October 4, 2020 | https://ermetic.com/whats-new/blog/the-three-ways-of-devops/ | <a href="https://web.archive.org/web/*/https://ermetic.com/whats-new/blog/the-three-ways-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			
				<article>
			<header>
				<img src="https://ermetic.com/wp-content/uploads/2020/09/DevOps-header_933x300.jpg" alt="">				
				
				<p>By Tanya Janca, CEO and Founder of WeHackPurple, September 30, 2020</p>
				<p>
	share:
	<a target="blank" href="http://twitter.com/home/?status=The%20Three%20Ways%20of%20DevOps%20-%20https://ermetic.com/?p=1310%20via%20@kenmata" title="Tweet this!"><span></span></a>
	<a target="blank" href="http://www.facebook.com/sharer.php?u=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20https://ermetic.com/?p=1310" title="Share on Facebook!"><span></span></a>
		<a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20%20https://ermetic.com/?p=1310;source=LinkedIn" title="Share on LinkedIn!"><span></span></a>
</p>			</header>
			<section><p>In this article we will explore applying the security concept of least privilege to your cloud instances, within a DevOps environment, without adding bulk and delays to your pipeline.</p>
<p>DevOps is not a tool that you buy, or the act of using pipeline software to release your code, it is so much more. Let’s define DevOps, then the three ways, then letâ€™s apply least privilege.</p>
<p><em>Although there are many different definitions of exactly what DevOps is, the most popular definition is from the Phoenix project and the DevOps Handbook. We will follow this definition in this article.</em></p>
<p>DevOps is a way of developing software, as well as a culture within a software development shop, and a mixture of processes and tooling that helps you get there.</p>
<h3>In Order to do DevOps, You Must Follow the Three Ways of DevOps</h3>
<p><em>The first way of DevOps</em> is to emphasize the speed and efficiency of the entire system, instead of just your part. Sometimes this means that you have to help another team do their work, rather than your own, because that will make the entire system so much better. Sometimes this means, asking for help from other teams. Often, automation helps with this, which is why we use a DevOps pipeline software, in order to release and deploy our code quickly and efficiently. Automation generally results in fewer errors, and it almost always results in much faster results. This is the first way of DevOps.</p>
<p><em>The second way of DevOps</em> is fast feedback. This means getting feedback to the correct person or people, in a timely manner. It also means the feedback needs to be accurate, because feedback that is inaccurate is not only unhelpful, it is potentially harmful. We add security testing, and all sorts of other quality tests, to our pipeline software in order to ensure the code that we are creating is high quality, and so that we get very fast feedback. That said, a pipeline is not the only way that you can get feedback, we will talk about this when we apply least privilege.</p>
<p><em>The third way of DevOps</em> is continuous learning. This means setting time aside on a regular basis to improve your daily work. Sometimes this means training. Sometimes this means tuning your tools or doing a proof of concept of several new tools that you are considering ensuring that the one you choose is the absolute best for your specific business needs. Sometimes this means introducing artificial intelligence and machine learning into your systems or tooling, to ensure that it is continuously learning. The point being that you want to be in a constant state of striving for improvement.</p>
<p>Quite often when people think of DevOps, they assume that every single tool or test must go into the pipeline. This is not true. We need to abide by the three ways of DevOps, and that definitely means using pipeline software and putting security tests inside of it, but our work is not done with just that. We cannot possibly complete all of our security requirements within a pipeline.</p>
<h3>Least Privilege and the Three Ways</h3>
<p>Let’s look at how we can implement the concept of <em>least privilege</em> to our cloud processes within a DevOps environment, and how it relates to each of the three ways.</p>
<p>Now we could attempt to put some tests for least privilege in our DevOps pipeline, however, what would we test for? If a permission is included in the pipeline, it’s likely because the software developer assumed that they would need it. What test could we put in a pipeline that would clarify whether or not a permission was actually required? To see if it is in use, or not? This means, it is unlikely we can test for this in our pipeline.</p>
<p>Instead of putting a test in the pipeline, we could set up monitoring in our systems of new processes, to watch which permissions are actually being used and which are not. Whichever permissions are not being used, could be removed, in order to implement<em> least privilege</em>. Now, let’s look at how we can apply this to <em>the three ways</em> of DevOps.</p>
<p>The first of the three ways, to repeat, is speed and efficiency of the entire system. By not putting a tool like this in the pipeline, this would not slow the pipeline down, and that would increase the speed of the system. Instead, we could create automation outside the pipeline, to ensure that this work was done quickly and efficiently, that would obey the first rule for instance, if we had a monitoring tool that did this for us. Letâ€™s take this imaginary monitoring system with us to the next way.</p>
<p>The second way is fast, accurate and timely feedback. Letâ€™s say our automated monitoring system that is watching all of our processes to see which permissions are being used, it gives feedback quickly and to the right people [the security team], that would be a very handy tool. If it could automate removing unused permissions, tell us if someone tries to use a removed permission, and shows us reports of both, that would certainly fit well into the second way. Having it also automate sending alerts and creating tickets would be a cherry on top of all of this; feedback going directly to who needs it.</p>
<p>The third way involves continuous learning. If our automated monitoring system, itself, can learn continuously from the traffic, access, and behavior of our cloud activity and users, then that respects the third way. A system that can train itself, learn when to remove permissions, when to replace permissions, and when to block access, not only respects the third way, it makes for a fantastic least privilege security tool. With enough learning (monitoring), a tool can even start to recommend which access policies would be the best option, given specific situations and previous decisions.</p>
<p>Although many people seem to think that DevOps tools need to go in a pipeline, this article makes it clear that you can still respect the three ways of DevOps and work within DevOps processes, without having your tool in the pipeline. And gain fantastic security results to boot!</p>
<p><a href="https://l.ermetic.com/get-a-demo" target="_blank" rel="noopener noreferrer">Find out how Ermetic can help you continually enforce least privilege access in your cloud environment.</a></p>
<p><strong>About the Guest Author</strong></p>
<p>Tanya Janca, also known as <a href="https://shehackspurple.ca/" target="_blank" rel="noopener noreferrer">SheHacksPurple</a>, is the author of â€˜Alice and Bob Learn Application Securityâ€™. She is also the founder of <a href="https://wehackpurple.com/" target="_blank" rel="noopener noreferrer">We Hack Purple</a>, an online learning academy, community and weekly podcast that revolves around teaching everyone to create secure software. Tanya has been coding and working in IT for over twenty years, won numerous awards, and has been everywhere from startups to public service to tech giants (Microsoft, Adobe, &amp; Nokia). She has worn many hats; startup founder, pentester, CISO, AppSec Engineer, and software developer. She is an award-winning public speaker, active blogger &amp; streamer and has delivered hundreds of talks and trainings on 6 continents. She values diversity, inclusion and kindness, which shines through in her countless initiatives.</p>
<p>Founder: We Hack Purple (Academy, Community and Podcast), WoSEC International (Women of Security), OWASP DevSlop, OWASP Victoria, #CyberMentoringMonday</p>
</section>
			
		</article>
				</div></div>]]>
            </description>
            <link>https://ermetic.com/whats-new/blog/the-three-ways-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678055</guid>
            <pubDate>Sun, 04 Oct 2020 11:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda Calculus Diagrams (2015)]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24677614">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://tromp.github.io/cl/diagrams.html | <a href="https://web.archive.org/web/*/https://tromp.github.io/cl/diagrams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


Lambda Diagrams are a graphical notation for closed lambda terms,
in which abstractions (lambdas) are represented by horizontal lines,
variables by vertical lines emanating down from their binding lambda,
and applications by horizontal links connecting the leftmost variables.
In the alternative style, applications link the nearest deepest variables,
for a more stylistic, if less uniform, look.
<p>

The following table shows diagrams of identity, the booleans, some standard combinators,
some Church numerals, the predecessor function on Church numerals, and Omega.

<table>
<tbody><tr> <td>term</td><td>definition</td> <td>diagram</td> <td>alternative</td> </tr>
<tr> <td>I/1</td> <td> λx.x</td>
  <td><img src="https://tromp.github.io/img/cl/I.gif"></td><td> </td></tr>
<tr> <td>K/true</td> <td> λx.λy.x</td>
  <td><img src="https://tromp.github.io/img/cl/K.gif"></td><td> </td></tr>
<tr> <td>false/0</td> <td> λx.λy.y</td>
  <td><img src="https://tromp.github.io/img/cl/false.gif"></td><td> </td></tr>
<tr> <td>S</td> <td> λx.λy.λz.(x z)(y z)</td>
  <td><img src="https://tromp.github.io/img/cl/S.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/S.alt.gif"></td> </tr>
<tr> <td>Y</td> <td> λf.(λx.x x)(λx.f(x x))</td>
  <td><img src="https://tromp.github.io/img/cl/Y.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Y.alt.gif"></td> </tr>
<tr> <td>2</td> <td> λf.λx.f(f x)</td>
  <td><img src="https://tromp.github.io/img/cl/2.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/2.alt.gif"></td> </tr>
<tr> <td>3</td> <td> λf.λx.f(f(f x))</td>
  <td><img src="https://tromp.github.io/img/cl/3.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/3.alt.gif"></td> </tr>
<tr> <td>4</td> <td> λf.λx.f(f(f(f x)))</td>
  <td><img src="https://tromp.github.io/img/cl/4.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/4.alt.gif"></td> </tr>
<tr> <td>pred</td> <td> λn.λf.λx.n(λg.λh.h(g f))(λu.x)(λu.u)</td>
  <td><img src="https://tromp.github.io/img/cl/pred.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/pred.alt.gif"></td> </tr>
<tr> <td>fac</td> <td> λn.λf.n(λf.λn.n(f(λf.λx.n f(f x))))(λx.f)(λx.x)</td>
  <td><img src="https://tromp.github.io/img/cl/fac.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fac.alt.gif"></td> </tr>
<tr> <td>fib</td> <td> λn.λf.n(λc.λa.λb.c b(λx.a (b x)))(λx.λy.x)(λx.x)f</td>
  <td><img src="https://tromp.github.io/img/cl/fib.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fib.alt.gif"></td> </tr>
<tr> <td>Ω</td> <td> (λx.x x)(λx.x x)</td>
  <td><img src="https://tromp.github.io/img/cl/Omega.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Omega.alt.gif"></td> </tr>
</tbody></table>
Curiously, the alternative Omega diagram somewhat resembles an (upside-down) Omega.
</p><p>
And here, on a larger scale, is a prime number sieve (alternative style): </p><p>
<img src="https://tromp.github.io/img/cl/primes.alt.gif">
</p><p>
which reduces to an infinite list of booleans that starts out as
</p><p>
<img src="https://tromp.github.io/img/cl/primebits.gif">

</p><h2>Dimensions and complexity</h2>

In terms of pixels, a diagram's width is one less than 4 times the number of variables
(vertical lines),
and its height is one more than twice the maximum number of nested abstractions and applications
(one less for alternaitve diagrams with multiple variables).
<p>
The size of the binary encoding of a term is closely related to
the graphical complexity: it is exactly twice the number of lines
plus the number of (4-way) intersections.

</p><h2>Reduction</h2>

Beta-reduction on lambda diagrams can be shown in several steps, as demonstrated in this reduction
from Y=λf.(λx.x x)(λx.f(x x)) to λf.(λx.f(x x))(λx.f(x x))

<table>
<tbody><tr><td>initial term</td><td><img src="https://tromp.github.io/img/cl/Y.gif"></td></tr>
<tr><td>show application of abstraction</td><td><img src="https://tromp.github.io/img/cl/Y0.gif"></td></tr>
<tr><td>show bound variables and argument</td><td><img src="https://tromp.github.io/img/cl/Y1.gif"></td></tr>
<tr><td>expand function body</td><td><img src="https://tromp.github.io/img/cl/Y2.gif"></td></tr>
<tr><td>to make room for substitution</td><td><img src="https://tromp.github.io/img/cl/Y3.gif"></td></tr>
<tr><td>substitute argument for variables</td><td><img src="https://tromp.github.io/img/cl/Y4.gif"></td></tr>
<tr><td>final term</td><td><img src="https://tromp.github.io/img/cl/Y5.gif"></td></tr>
</tbody></table>

In the third frame, we show only the part of bound variables below abstractions, e.g. when
applying <img src="https://tromp.github.io/img/cl/applied.gif">, the function body x(λy.x) shows as <img src="https://tromp.github.io/img/cl/bound.gif">.

<h2>Diagrams In Motion</h2>

Paul Brauner has produced some awesome <a href="https://www.youtube.com/playlist?list=PLi8_XqluS5xc7GL-bgVrxpA2Uww6nK0gV">videos</a> of beta reductions, produced with this <a href="https://github.com/polux/lambda-diagrams">software</a>.
 
<h2> Related work</h2>
<a href="http://dkeenan.com/">Dave Keenan</a> has a comprehensive online paper
<a href="http://dkeenan.com/Lambda/">To Dissect a Mockingbird:
A Graphical Notation for the Lambda Calculus with Animated Reduction</a>,
which partly inspired this page.
<p>
In his <a href="http://bntr.planet.ee/lambda/work/visual_lambda.pdf">Master thesis</a>, Viktor Massalõgin discusses 4 existing graphical notations before introducing his own "bubble" notation. Figure 3 on page 10 shows 4 depictions of the fixpoint combinator (which differs from Y above in one beta reduction), while the bubble form is in Figure 5 on page 13.

</p><h3>Note</h3>

The diagram in the title, produced by the postscript code below, is a slightly deformed alternative Y diagram made to look like a Y.
<pre>%!PS-Adobe-2.0 EPSF-2.0
%%BoundingBox:0 0 118 110
/m{moveto}def/l{lineto}def/c{concat 6 m 0 6 l 7 8 m 0 8 l l l 3 6 l 2 6 m 7 6 l
3 4 m 6 4 l 6 6 l stroke}def 3 0 0 0 1[-8 4 0 8 60 9]c 3 2 0 2 2[-1 1 0 1 0 0]c
</pre>

<hr>
Back to my <a href="http://tromp.github.io/cl/cl.html">Binary Lambda Calculus page</a>. <br>


</div>]]>
            </description>
            <link>https://tromp.github.io/cl/diagrams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677614</guid>
            <pubDate>Sun, 04 Oct 2020 09:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dual licensing GPL for fame and profit]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24677481">thread link</a>) | @george3d6
<br/>
October 4, 2020 | https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-10-04</p>
        
<p>Dual licensing with GPL is the idea that if I own a certain piece of GPL code, I can also relicense it as a proprietary library. This is how Oracle licenses Java and how QT licenses QT.</p>
<h2>I - All rights for me but not for thee</h2>
<p>But my general feeling is that there is some stigma associated with this practice, to quote <a href="https://www.gnu.org/licenses/gpl-faq.en.html#ReleaseUnderGPLAndNF">gnu.org</a>:</p>
<blockquote>
<p>To release a nonfree program is always ethically tainted, but legally there is no obstacle to your doing this. If you are the copyright holder for the code, you can release it under various different non-exclusive licenses at various times.</p>
</blockquote>
<p>The "ethically tainted" doesn't resonate with me, I think this licensing model should be encouraged.</p>
<p>I will admit I am kind of biased on this because I work on a for-profit GPL-license project. But it strikes me as silly that this business model is shunned by the open-source community in favor of licensing under MIT/BSD.</p>
<p>Dual licensing is a way in which the "owner" of the code ends up in an advantageous position compared to other users.</p>
<p>That is to say, a user must abide by the strict rules of the GPL license:</p>
<ul>
<li>Release all modifications.</li>
<li>Potentially (depending on the specifics of the GPL license) have to release other projects that are used "in relation" to the library.</li>
<li>Not ship the code under a different license.</li>
</ul>
<p>The "owner" of the code abides by none of these and can thus benefit in ways that the users can't.</p>
<p>In the open-source utopia, where resources are aplenty for everyone, everything is open source and nothing is for sale, so dual-licensing doesn't fit that particular utopia. But we live in the real world, where money makes things a bit more complicated, and in the long term, dual-licensing might be better than equal-rights open licenses.</p>
<p>Well, developers have to eat.</p>
<p>Even worst, good software is made by good developers, developers which can get six-figure salaries designing skinner boxes. On the contingency that those developers aren't ideal altruists, they have to get way-above-subsistence salaries to work on useful open source projects instead of skinner boxes.</p>
<p>So if dual-licensing provides a middle ground for that which is better than the current situation where a lot of good software is proprietary, what's the harm?</p>
<p>Some would say it's a middle ground that will hamper the development of truly free software. But who release said truly free software anyway?</p>
<h2>II - Who release fully-free projects</h2>
<p>When it comes to license like MIT and BSD, that impose no restrictions upon usage, where the "owner" doesn't exist, it's interesting to look at who release projects under those licenses:</p>
<p>a) Students or hobbyists, people creating software for fun, notoriety, and experience.</p>
<p>b) Very large companies (Facebook, Google, Amazon, Uber) or government &amp; donation founded organizations (Universities, Public Research centers, software foundations such as GNU, Apache, and LSF)</p>
<p>The first group is one I don't wish to dismiss, I think a lot of important programs stem from here. But their end goal is not to work for free for their whole life. Usually, they moonlight for their open-source projects and work a paid gig to earn money. A small minority can be funded by donations, but it's a small minority.</p>
<p>The project I use for allowing comments on this website (<a href="https://github.com/umputun/remark42">remark42</a>), has 2.3k stars on GitHub and <a href="https://www.patreon.com/remark42/posts">earns 9$/month from donations</a>. The <a href="https://github.com/mindsdb/mindsdb">project I work on</a> has 2.9k stars on Github and an operating budget of <a href="https://venturebeat.com/2020/04/16/mindsdb-raises-3-million-for-open-source-automated-machine-learning/">a few million</a> dollars.</p>
<p>You can certainly get to a point where you are funded by donations, but the reality is that it's not a good enough incentive. Doubly so since the developers working on these projects are usually the "creme de la creme", releasing and maintaining truly useful software usually requires expertise only a small fraction of engineers have.</p>
<p>The second group, the corporation and government-funded teams can only exist because of the scale.</p>
<p>Why can Facebook develop PyTorch?</p>
<ul>
<li>Because Facebook hires so many ML engineers that in the cost-benefit analysis it's cheaper to have your internal framework be popular enough such that you can get already-trained people from day 1. The &lt; 100 people working full time on PyTorch save months of training for every single one of the thousands of ML people facebook hires, since it can hire people that already know PyTorch.</li>
<li>Because Facebook doesn't dominate by having better ML models, it dominates by having thousands of times more data than anyone else. It's in facebook's interest to keep research open since it's objective is not to get ahead, but just to stay even, or at least not fall significantly behind.</li>
</ul>
<p>Why can Nvidia assign engineers to dozens of open source ML and game-engine projects?</p>
<ul>
<li>Because Nvidia makes hundreds of billions each year selling GPUs. The little work they put into those libraries to make sure it works ideally with their GPUs is insignificant to the revenue they get from those markets.</li>
</ul>
<p>Why can Google develop TensorFlow?</p>
<ul>
<li>For about the same reasons as Facebook.</li>
<li>Because they can make a lot more money from selling/renting TensorFlow optimized hardware.</li>
</ul>
<p>And that's on the happier side of the spectrum. On the "shadier" end of the scale, one could argue projects like Flutter and Angular might be worth their investment because they make spyware-free browsers like Firefox send-class citizens in the war for the web, not to mention easier integration into internet-monopolizing schemas like AMP.</p>
<p>You've also got, I will admit, projects that seem to be open source purely for flexing. To my knowledge, Yandex might have well never released Clickhouse and the column-store database landscape would have been set back 10+ years for it. Why did they do it? Maybe just because few dozens of people working on it wanted to showcase how good they are.</p>
<p>But at the end of the day, this is not a reliable model</p>
<h2>III - Profit motives</h2>
<p>So would it not be nice for open source if one can bring profit motives into the whole thing?</p>
<p>Even better, profit from the people that don't support or contribute to open source, but not from those that do.</p>
<p>It seems to me like double-licensing with GPL achieves just that. One can release a project and charge large companies for using it, at the risk of breaking the license if they don't pay. Even if a lot of them will use the software illegally, as is the case now, the threat of lawsuits will end up deterring some or most heavy-users from doing so.</p>
<p>On the other hand, people using the project in an open-source project of their own have nothing to worry about.</p>
<p>The only problem that remains here is the fact that you can't chain GPL projects. That is to say, one can't use GPL code in their own double-licensed GPL code, but there are workarounds for that (e.g. isolating the GPL dependency and open-sourcing the changes to that alone). Still, this seems like the kind of problem that could be fixed by an off-shoot of the GPL meant for just this use-case.</p>
<p>This model keeps all the advantages of GPL, in that it incentives your users to open-source their product. It doesn't force them to do so, like a purely-GPL licensed software might, but it's not like GPL is working as intended, outside of a few cases where enough money was at stake to sue (e.g. TiVo), violations of the GPL go unpunished.</p>
<p>Currently, a company that wants to include GPL into their project has two options:</p>
<ul>
<li>Use the code in such a way that GPL won't force you to open source the rest of your code.</li>
<li>Use the code and break the license.</li>
</ul>
<p>Since the wording of GPL is not that clear, it could often be argued that companies go for alternative nr 2. After all, who will ever know?</p>
<p>But what if the "pay the maintainer a small sum" option was available. Wouldn't the liability afraid giants look towards this much more favorably than either of the other 2 options? Wouldn't this, in the long run, give an edge to open source projects which don't have to worry about these fees ?</p>
<hr>
<p>Thus I think I come in squarely on the side of open-source companies dual-licensing GPL on their product[s]. A model that already exists and often enough has great success (see MariaDB and Aerospike).</p>
<p>It's a nice compromise for moving towards a more open world, without having to live in Stallman's utopia. It's an amazingly pragmatic solution and anyone who reads this blog knows I'm a fan of those.</p>

      </div></div>]]>
            </description>
            <link>https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677481</guid>
            <pubDate>Sun, 04 Oct 2020 09:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A modular, extensible DIY NAS]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24677407">thread link</a>) | @ggeorgovassilis
<br/>
October 4, 2020 | https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/ | <a href="https://web.archive.org/web/*/https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This post was extensively <a href="https://news.ycombinator.com/item?id=24677407">discussed on Hacker News</a>.</p>



<p>I’ve been running for a decade a self-built NAS at home, so I thought I’d write down my experience so that others might gloat over my many failures and gasp in awe at my few triumphs.</p>



<figure><img data-attachment-id="1780" data-permalink="https://blog.georgovassilis.com/img_20200929_210932458_hdr/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg" data-orig-size="1728,2304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;moto x4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1601413773&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.519&quot;,&quot;iso&quot;:&quot;763&quot;,&quot;shutter_speed&quot;:&quot;0.071428571428571&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20200929_210932458_hdr" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" src="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768 768w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=1536 1536w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=113 113w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>The HP Proliant microsever gen8 is affordable, compact and runs on Ubuntu</figcaption></figure>



<p>The NAS is <strong>perfect</strong> because it is simple, safe, modular and extensible and it is <strong>cheap </strong>because it is built of second hand, commodity parts.</p>



<p>The NAS mostly stores files (documents and media) on a software RAID 6 and serves them over Windows shares to the local network. I’m staying away from proprietary NAS solutions because a hardware failure would make data recovery hard to impossible without the exact same hardware replacement. Every piece of hardware,  from the hard disks to the case and motherboard have been switched out for something else in this decade, sometimes more than once, so the focus on modularity paid for itself. Since long-term data integrity and robustness is a concern, the NAS should run some sort of redundant RAID level.</p>



<h2>Goals</h2>



<figure><table><tbody><tr><td><strong>Goal</strong></td><td><strong>Description</strong></td><td><strong>Solution</strong></td></tr><tr><td>Function</td><td>The NAS serves as a <strong>network attached file system</strong> for home use; the NAS operates a few hours a day and is either off or in standby most of the time </td><td>Commodity hardware, open source software, modularity, keep it simple</td></tr><tr><td>Interoperability</td><td>Commonly used computer platforms should be able to access files on the NAS. Commodity hardware should be able to connect to the NAS.</td><td>Samba (aka Windows shares) on Ubuntu, USB, SATA. Connect LAN to Wifi router, does name resolution and time server. Access and manage with SSH.</td></tr><tr><td>Modularity</td><td>Hardware and software components should be <strong>interchangeable </strong>without redesigning the entire system  </td><td>x86 PC platform, Linux, Docker</td></tr><tr><td>Control</td><td>I want to control <strong>which software is installed</strong> on the NAS and what it does </td><td>Ubuntu 18.04 LTS</td></tr><tr><td>Data integrity</td><td>Files of arbitrary <strong>size </strong>(within reason) and content should be stored on the NAS and not <strong>corrode or lose integrity</strong> over time </td><td>RAID 6 with 4 hard drives, ext4fs with checksumming, scrubbing, manually assembled RAID, ECC RAM. Sign archives with par2.</td></tr><tr><td>Noise</td><td>Noise should be low and tolerable </td><td>HDDs in standby, SSD as primary OS disk, write-mostly, lots of RAM, passive cooling</td></tr><tr><td>Cost</td><td>Use commodity hardware and free, open source software </td><td>2nd-hand commodity hardware, hard disks instead of SSDs</td></tr><tr><td>Low maintenance</td><td>Avoid time critical maintenance</td><td>ufw firewall accepting connections only from internal network, no auto-updates, limited software, Docker, not accessible from the Internet.</td></tr><tr><td>Data safety</td><td>In case of hardware loss or theft unauthorised parties shouldn’t be able to access the data</td><td>dmcrypt with key on external device</td></tr><tr><td>Low power consumption</td><td>Power consumption should be in line with the server’s function</td><td>Components in stand-by most of the time, SSD, RAID in write-mostly</td></tr><tr><td>Compact</td><td>Physical NAS dimensions should be small; no space wasted</td><td>2nd hand HP proliant microsever gen8 </td></tr></tbody></table></figure>



<h2>Non-goals</h2>



<ul><li>Typical media-server tasks: streaming, encoding, transcoding etc</li><li>Bitcoin mining</li><li>Torrenting</li><li>Everything else 🙂</li></ul>



<h2>Getting the Hardware</h2>



<p>Getting the right hardware is the hard-(pun)-est part as it is the platform for modularity, price, energy consumption, size and many other goals I’m interested in. There are many second-hand, cheap proprietary NAS servers around, but I don’t like the idea of closed hardware and software systems. Eg, if a hardware RAID controller stores data in a proprietary format on the hard drives I would need the exact same replacement controller to recover that data in case of a controller failure.</p>



<p>Space is also an issue, so the server should be compact while allowing running Linux on it; that is quite hard to find as most compact NAS’ out there are proprietary systems and don’t allow installing your own OS. There are plenty of used x86 PCs and servers, but they are mostly too big or don’t have enough drive bays or SATA ports. Connecting drives over USB is also not an option because of the low speed, higher power consumption and space requirements. The first couple of my NAS revisions around 2010 used a compact barebone and later a mini tower case around which had 3 or 4 hard disk bays, but I find those box formats harder to come by these days. Lucky you if you get one at an affordable price!</p>



<p>I came across a used <a href="https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-c03793258">HP proliant microserver</a> gen8 and haven’t regretted it ever since. The base model came with 2GB ECC RAM, a Celeron 2-core CPU and no hard drives for about 100€. There’s an excellent review of that server on <a href="https://louwrentius.com/zfs-performance-on-hp-proliant-microserver-gen8-g1610t.html">Louwrentius</a>. The server is extremely compact (about 26cm each dimension), reasonably low noise (although not silent) in standby, has a passively cooled CPU, two GBit ethernet ports, four 3,5″ hard drive bays and a somewhat hidden proprietary format slot for a fifth low-profile 2,5″ disk which I use for an SSD. The drive bays can directly receive SATA disks while the 5th slot requires a 4 pin FDD male-to-SATA adapter and a SATA cable to connect a 2.5″ SSD to the motherboard, which requires an FDD 4 pin (male)-to-SATA connector. As an added bonus, the server features <a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO</a> which allows remote access to the server with a web browser – so no need for a keyboard or screen!</p>



<p>I admit that the server isn’t 100% commodity parts; eg. a motherboard or CPU failure would require ordering the exact same spare parts (which is probably going to be expensive) or building a completely new server on a different platform. However RAM, network and storage are fairly standard, I run Ubuntu on it and the benefits outlined earlier weigh enough to take that risk. About 6 years later the server still runs without any issues; barring <a href="https://en.wikipedia.org/wiki/Survivorship_bias">survivor bias</a>, I think that approach worked well.</p>



<p>The server I purchased had firmware from 2014 and HP thankfully started publishing updates for free recently, the last one from late 2019 which I flashed the microserver with for a slick HTML5 management UI.</p>



<p>The server underwent various upgrades over the years; from a RAID5 array of three 2TB hard disks to the current setup of 3x6TB + 1x8TB + 1x 512MB SSD and a CPU upgrade to a Xeon model and a RAM upgrade to 16GB ECC. I almost exclusively repurpose external USB hard drives (after opening , extracting the HDD and kissing the warranty goodbye) which are cheaper than internal ones… at first that is surprising considering the extra hardware (case, USB-to-SATA adapter, cables, power supply) they come with; however the warranty and technical specs are significantly inferior to those of internal drives which explains the price difference. Since the server runs a RAID 6 (the entire point of which is to survive disk failures) I think that is an ok risk to take.</p>



<p>The server is connected over an Ethernet cable to the home Wifi router; network speeds are close to 100mb/s which is ok, the USB3 ports can do around 40mb/s.</p>



<h2>Installation</h2>



<p><a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO </a>makes setting up the server easy even without a physical keyboard and screen. I started with Ubuntu server LTS 14.04, switched over to 16.04 and am currently running 18.04. The upgrades never worked in place, in each case a fresh installation was required. </p>



<p>I recommend installing a VM (like VirtualBox) on your workstation, booting Ubuntu Server 18.04 from a live image and installing Ubuntu on a USB harddisk. I couldn’t get the Proliant microserver to boot with UEFI, so a traditional grub BIOS installation is required. </p>



<p>The four hard disks are partitioned according to the schema below: a 1MB partition at the beginning for the GRUB boot loader, a 50GB partition for Ubuntu and a 5.5TB partition for the RAID.</p>



<p>I used the Ubuntu Server 18.04 alternative installer to set up the Ubuntu partitions as a RAID 1 which mirrors that partition over all hard disks. The installer is able to install Ubuntu into that RAID 1 and GRUB is able to boot from it. In case of a hard disk failure, just removing that hard disk will allow the server to boot again.</p>



<pre><code>+-------------------+
| 1MB bios_grub     |
|                   |
+-------------------+
| 50GB Ubuntu ext4  |
| RAID 1            |
+-------------------+
| 5.5TB Data        |
| RAID 6            |
+-------------------+</code></pre>



<p>For the installer to work, there need to be at least two disks in the RAID. More disks can be <a href="https://raid.wiki.kernel.org/index.php/Growing">added later</a>. Just make sure to install the GRUB bootloader on all disks with:</p>



<pre><code>grub-install /dev/sdX</code></pre>



<p>In my first experiments Ubuntu was able to boot fine, but wouldn’t activate the ethernet cards. This requires some fiddling with netplan.</p>



<p> <strong>/etc/netplan/01-netcfg.yaml</strong> </p>


<pre title="">network:
  version: 2
  ethernets:
    eno1:
      dhcp4: true
      dhcp6: true
      optional: true
    eno2:
      dhcp4: true
      dhcp6: true
      optional: true
</pre>


<h2>Boot RAID considerations</h2>



<p>As discussed in “installation”, Ubuntu boots from a RAID 1. md mirrors changes to all boot partitions, which is awesome. The boot RAID is mapped under /dev/md0 – I didn’t find a way to assign a name to it, but I found the device name to be stable. Unfortunately Ubuntu will constantly access the boot drive during normal operation, which in my case means that four drives are always spinning. I tried various things like remapping log directories to a ram disk and pre-loading files, but the resulting jungle of scripts is impossible to maintain. The solution turned out to be quite simple and elegant, after a hack: I installed an SSD in the 5th hard disk bay and added it to the boot RAID 1. While mirroring worked, the Proliant (gen8) BIOS won’t boot from the 5th bay if it finds hard disks somewhere else. The solution is a script which runs after boot and fails all mechanical hard disks in the RAID:</p>



<pre><code>mdadm --manage /dev/md0 --fail /dev/sda2 /dev/sdb2 /dev/sdc2 /dev/sdd2</code></pre>



<p>The script is a bit more complex than that as device names are not stable and various error conditions need to be taken into account (eg. the RAID shouldn’t be touched if a harddisk is failing) – but that is a topic for a different post. MD will forget that the disks have been marked as failed after a reboot, which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</a></em></p>]]>
            </description>
            <link>https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677407</guid>
            <pubDate>Sun, 04 Oct 2020 09:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Gzip Format (2011)]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24676831">thread link</a>) | @WoodenChair
<br/>
October 3, 2020 | http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001 | <a href="https://web.archive.org/web/*/http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tbody><tr><td><div id="main">
<p>
In this article I describe the DEFLATE algorithm that GZIP implements and depends on. The DEFLATE algorithm uses a combination of LZ77, Huffman codes and run-length-encoding; this article describes each in detail by walking through an example and developing source code to implement the algorithm. My aim is to implement readable rather than efficient or extensible code. I'll focus here on unzipping, rather than zipping, but by the end of the article, the zipping process should be clear.
</p>
<p>
Material intended for human consumption tends to be highly redundant, from an information processing perspective. Because of the mysterious human mind, we need to have the same thing repeated to us in different ways in order for it to be processed correctly. Natural language, for example, is inefficient - the English language phrase "I am going to the store" could easily be abbreviated "I go store". If the subject of conversation has already been established as "me", it could be further abbreviated unambiguously as "go store". This is how children communicate until they are taught proper grammar - but as we mature, we like/want/need the redundancy.
</p>
<p>
Computers are no better when it comes to demanding redundancy. Computer programs repeat the same instructions over and over again, and program source code is verbose, even when the programmer isn't concerned about using readable variable names (you know who you are). Computer storage, on the other hand, is a scarce resource. It becomes less and less scarce every day, but every time capacity increases, we seem to find a way to run out of it. I'm sure that someday, my children will be complaining that their thumbnail computer devices can "only store four holodeck simulations!"
</p>
<p>
Computer scientists have been studying ways to use computer storage more efficiently since the 1960s. In 1977, Abraham Lempel and Jacob Ziv published "A Universal Algorithm for Sequential Data Compression " [1] which described what is now referred to as the "LZ77" compression algorithm. Conceptually, LZ77 is pretty straightforward - read the source document, and, for each sequence of bytes encountered, search backward through the document to see if the same sequence occurs previously. If so, rather than outputting the sequence, output a back pointer to the first occurrence of the sequence.
</p>
<p>
To get a sense of just how redundant English text is, take a look at figure 1 and figure 2. Figure 1 contains the first few verses of the Bible's book of Genesis and figure 2 shows all of the places where text from a prior point in the document is repeated. LZ77 does a very good job of exploiting that redundancy and making efficient use of available storage.
</p>
<p>
<img src="http://www.infinitepartitions.com/genesis.gif">
</p><p>Figure 1: Uncompressed ASCII text</p>

<p>
<img src="http://www.infinitepartitions.com/genesis_compressed.gif">
</p><p>Figure 2: LZW compression</p>

<p>
The first 17 verses, with LZ77 compression applied, is shown below. The &lt;#,#&gt; brackets indicate backpointers in the form &lt;distance, length&gt;. So, the first backpointer &lt;25,5&gt; indicates that, to uncompress the document, search backward 25 characters, and reproduce the five characters you find there. As you can see, the first sentence is mostly uncompressed, but by the middle of the text, there's almost no uncompressed text.
</p>
<p>
001:001 In the beginning God created&lt;25, 5&gt;heaven an&lt;14, 6&gt;earth.
0&lt;63, 5&gt;2 A&lt;23, 12&gt; was without form,&lt;55, 5&gt;void;&lt;9, 5&gt;darkness&lt;40, 4&gt;
&lt;0, 7&gt;upo&lt;132, 6&gt;face of&lt;11, 5&gt;deep.&lt;93, 9&gt;Spirit&lt;27, 4&gt;&lt;158, 4&gt;mov&lt;156, 3&gt;&lt;54, 4&gt;&lt;67, 9&gt;&lt;62, 16&gt;w&lt;191, 3&gt;rs&lt;167, 9&gt;3&lt;73, 5&gt;&lt;59, 4&gt;said, Let&lt;38, 4&gt;r&lt;248, 4&gt; light:&lt;225, 8&gt;re&lt;197, 5&gt;&lt;20, 5&gt;&lt;63, 9&gt;4&lt;63, 11&gt;w&lt;96, 5&gt;&lt;31, 5&gt;,&lt;10, 3&gt;at &lt;153, 3&gt;&lt;50, 4&gt;good&lt;70, 6&gt;&lt;40, 4&gt;divid&lt;323, 6&gt;&lt;165, 9&gt;&lt;52, 5&gt; from&lt;227, 6&gt;&lt;269, 7&gt;&lt;102, 9&gt;5&lt;102, 9&gt;call&lt;384, 7&gt;&lt;52, 6&gt;Day,&lt;388, 9&gt;&lt;326, 9&gt;&lt;11, 3&gt;&lt;41, 6&gt;&lt;98, 9&gt;N&lt;183, 5&gt;&lt;406, 10&gt;&lt;443, 3&gt;&lt;469, 4&gt;&lt;57, 8&gt;mor&lt;15, 5&gt;w&lt;231, 4&gt;&lt;308, 5&gt;irst&lt;80, 3&gt;y&lt;132, 9&gt;6&lt;299, 28&gt;a&lt;48, 4&gt;mamen&lt;246, 3&gt;&lt;437, 6&gt;midst&lt;375, 7&gt;&lt;134, 9&gt;&lt;383, 6&gt;&lt;177, 6&gt;le&lt;290, 5&gt;&lt;272, 6&gt;&lt;413, 11&gt;&lt;264, 10&gt;&lt;429, 15&gt;7&lt;129, 9&gt;mad&lt;166, 9&gt;&lt;117, 6&gt;&lt;82, 6&gt;&lt;348, 11&gt;&lt;76, 8&gt;which&lt;215, 5&gt;&lt;600, 10&gt;nder&lt;62, 14&gt;&lt;115, 16&gt;&lt;54, 11&gt; ab&lt;599, 3&gt;&lt;197, 13&gt;&lt;54, 9&gt;&lt;470, 6&gt;&lt;487, 7&gt;so&lt;169, 9&gt;8&lt;432, 20&gt;&lt;108, 10&gt;H&lt;827, 5&gt;&lt;397, 25&gt;&lt;103, 9&gt;&lt;405, 17&gt;seco&lt;814, 5&gt;&lt;406, 10&gt;9&lt;406, 22&gt;&lt;199, 8&gt;&lt;235, 10&gt;&lt;944, 7&gt;&lt;428, 3&gt;ga&lt;439, 5&gt;&lt;540, 10&gt;toge&lt;18, 4&gt;&lt;45, 3&gt;to one pl&lt;820, 3&gt;&lt;422, 10&gt;&lt;604, 5&gt;ry l&lt;16, 4&gt;app&lt;981, 3&gt;&lt;250, 8&gt;&lt;474, 11&gt;&lt;258, 12&gt;10&lt;258, 20&gt;&lt;67, 9&gt;E&lt;1046, 4&gt;;&lt;638, 9&gt;&lt;145, 6&gt;&lt;234, 4&gt;&lt;138, 8&gt;&lt;86, 9&gt;&lt;952, 13&gt;&lt;75, 8&gt;&lt;1018, 4&gt;eas&lt;853, 10&gt;&lt;894, 6&gt;&lt;883, 14&gt;&lt;138, 9&gt;1&lt;290, 23&gt;&lt;1179, 6&gt;b&lt;119, 5&gt;&lt;1173, 3&gt;&lt;11, 3&gt;grass,&lt;302, 7&gt;rb&lt;132, 9&gt;yield&lt;38, 4&gt;seed&lt;879, 10&gt;fru&lt;111, 3&gt;tree&lt;33, 10&gt;&lt;19, 6&gt;af&lt;174, 3&gt; hi&lt;1229, 10&gt;kin&lt;57, 3&gt;whose&lt;69, 5&gt; is&lt;809, 4&gt;itself,&lt;1260, 10&gt;&lt;148, 5&gt;&lt;599, 23&gt;1&lt;1367, 16&gt;brou&lt;1082, 5&gt;&lt;189, 12&gt;&lt;58, 4&gt;&lt;189, 4&gt;&lt;181, 14&gt;&lt;136, 9&gt;&lt;154, 9&gt;&lt;146, 7&gt;&lt;204, 8&gt;&lt;198, 19&gt;&lt;175, 13&gt;&lt;138, 4&gt;i&lt;1369, 10&gt;&lt;184, 8&gt;&lt;78, 14&gt;&lt;401, 39&gt;3&lt;1160, 42&gt;thir&lt;753, 13&gt;14&lt;1460, 33&gt;s&lt;1155, 8&gt;&lt;882, 10&gt;&lt;1159, 15&gt;&lt;780, 7&gt;&lt;749, 3&gt;&lt;1150, 11&gt;&lt;100, 3&gt;&lt;1031, 10&gt;n&lt;72, 4&gt;;&lt;769, 12&gt;m&lt;95, 4&gt;&lt;361, 3&gt;&lt;68, 9&gt;sign&lt;367, 7&gt;&lt;22, 3&gt;&lt;293, 3&gt;aso&lt;16, 12&gt;&lt;79, 3&gt;&lt;13, 7&gt;y&lt;430, 3&gt;s:&lt;192, 8&gt;&lt;1486, 6&gt;&lt;85, 15&gt;&lt;185, 31&gt;&lt;177, 10&gt;&lt;126, 9&gt;giv&lt;1541, 8&gt;&lt;573, 38&gt;6&lt;1343, 15&gt;wo&lt;562, 3&gt;&lt;2001, 3&gt;&lt;122, 7&gt;;&lt;906, 6&gt;&lt;2019, 5&gt;&lt;142, 7&gt;&lt;288, 4&gt;rul&lt;1277, 14&gt;d&lt;1650, 12&gt;l&lt;1646, 3&gt;&lt;45, 20&gt;&lt;319, 6&gt;:&lt;937, 4&gt;&lt;1452, 9&gt;st&lt;261, 3&gt;&lt;647, 10&gt;l&lt;154, 11&gt;&lt;1498, 10&gt;s&lt;278, 8&gt;&lt;264, 33&gt;&lt;256, 11&gt;&lt;2099, 18&gt;&lt;264, 5&gt;,
</p>
<p>
Example 1: LZ77 compressed representation of the first 17 verses of Genesis
</p>
<p>
This relatively short document is compressed at just over 3:1 - and the compression ratio generally improves as documents get longer.
</p>
<p>
Of course, when discussing computer formats, it's not enough to talk about concepts - a concrete representation must be agreed upon. The decoder/decompressor must have a way to distinguish which input bytes are literals, and which input bytes are backpointers. One simple, naive representation might be to introduce an "escape code" - say, 0x255, to distinguish backpointers from literals. Of course, a literal escape code would need to be similarly escaped.
</p>
<p>
Unfortunately, all of these escape codes end up defeating the purpose of compressing in the first place. As it turns out, there's a better way to encode these backpointers and still allow them to be correctly distinguished from literals: variable length codes. In ordinary byte-oriented data, each code is a fixed length (typically 8 bits). Variable length codes remove this restriction. Some codes can be shorter and some can be longer. Once there's no need to restrict yourself to eight-bit bytes, you can define an arbitrarily-sized "alphabet", which is exactly what GZIP does. The first 255 characters in this alphabet are the literal codes - the 8-bit bytes that were read from the input stream. The 256th character is a "stop code" that tells the decode when to stop decoding. The 257-285th codes indicate the length of the matched range (followed immediately by a distance code).
</p>
<p>
Now, if there are only 285-257=28 length codes, that doesn't give the LZ77 compressor much room to reuse previous input. Instead, the deflate format uses the 28 pointer codes as an indication to the decompressor as to how many extra bits follow which indicate the actual length of the match. This logic is complex but important for compatibility; I'll cover it in more detail below.
</p>
<p>
In a fixed-length world, this 285-symbol alphabet would require 9 bits per symbol, but would use only a little more than half of the available 512 bytes that 9 bits can encode. This alphabet can be encoded much more efficiently by assigning the symbols variable-length codes. However, the problem with variable length codes is that the decoder needs to know where one code ends and the other begins. This isn't a problem with fixed-length codes such as ASCII - the decoder reads 8 bits, decodes them, and then reads another 8 bits. To ensure that the encoder can unambiguously interpret the variable length codes, you have to be careful how you assign these codes. Imagine that you were dealing with a four-character "alphabet" with four variable-length codes:
</p>
<pre>1. A: 1
2. B: 0
3. C: 10
4. D: 11
</pre>
<p>
Example 2: Invalid variable-length code assignment
</p>
<p>
The problem with this assignment is that the codes are ambiguous. The decoder can't tell if the input sequence "10" is an A followed by a B, or a C by itself.
</p>
<p>
The solution is to assign prefix codes. With prefix codes, once you use a prefix to delineate a range of codes, it can't be used by itself as a code. So if the character "A" is assigned the 1-bit code "1", no other code can start with "1". If "B" is assigned the code "01", no other code can start with "01". A valid Huffman coding of the four-character alphabet above, then, is:
</p>
<pre>1. A: 1
2. B: 01
3. C: 001
4. D: 000
</pre>
<p>
Example 3: Valid prefix-coding variable-length code assignment
</p>
<p>
This means that there can only be one 1-bit code, one two-bit code, two three-bit codes, four four-bit codes, etc. You may deal with prefix codes on a regular basis - the country calling codes that allow you to make international phone calls are assigned using prefix code rules. Prefix codes are usually referred to as Huffman codes [2] after the inventor of a provably optimal algorithm for generating them when symbol probabilities are known. These Huffman codes are often represented as trees, where each leaf is a symbol, and each branch is a bit value.
</p>
<p>
<img src="http://www.infinitepartitions.com/huffman_tree_1.gif">
</p><p>Figure 3: a prefix code tree</p>

<p>
Once such a tree structure has been constructed, decoding is simple - start at the top of the tree and read in a bit of data. If the bit is a 0, follow the left-branch of the tree; if 1, follow the right-branch. When a leaf node is hit, stop; a symbol has been completely read. Output the symbol and return to the top of the tree.
</p>
<p>
Listing 1 illustrates a tree structure for representing Huffman codes in memory:
</p>
<pre>typedef struct huffman_node_t
{
  int code; // -1 for non-leaf nodes
  struct huffman_node_t *zero;
  struct huffman_node_t *one;
}
huffman_node;
</pre>
<p>Listing 1: Huffman tree structure</p>
<p>
Once constructed, reading …</p></div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</a></em></p>]]>
            </description>
            <link>http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676831</guid>
            <pubDate>Sun, 04 Oct 2020 06:02:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open-source self-hosted comments systems for static websites]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24676152">thread link</a>) | @nuker
<br/>
October 3, 2020 | https://lisakov.com/projects/open-source-comments/ | <a href="https://web.archive.org/web/*/https://lisakov.com/projects/open-source-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This comparison table is inspired by
<a href="http://staticsitegenerators.net/">staticsitegenerators.net</a>. Contribute at
<a href="https://github.com/pozitron57/open-source-comments">github</a> —
add the missing data. Github-related data (stars, open issues + PR, etc.)
are updated daily automatically. Want different columns? Noted a bug? Submit
an <a href="https://github.com/pozitron57/open-source-comments/issues/new">issue</a>.</p>
<h2>What’s wrong with Disqus</h2>
<p>Disqus loads absurd amount of tracking services, which exposes your visitors’
personal data and significantly increases loading time. See, e.g., 
<a href="http://donw.io/post/github-comments/#what-s-wrong-with-disqus">this post</a>.</p>
<h2>What’s not covered here</h2>
<p>For a static website, one usually wants a lightweight commenting server with
as little dependencies as possible. Few commenting engines listed on the page
are provided by heavy applications (e.g.,
<a href="https://github.com/discourse/discourse">discourse</a>,
<a href="https://github.com/debiki/talkyard">talkyard</a>), but the majority are
relatively lightweight applications designed specifically to provide 
comments for the static pages.</p>
<p>This page prioritizes information on self-hosted comments. However, there
are other open-source solutions, including implementations of third-party
services (e.g., Github issues, such as
<a href="https://github.com/imsun/gitment">[1]</a>,
<a href="https://github.com/gitalk/gitalk">[2]</a>,
<a href="https://github.com/Blankj/awesome-comment">[3]</a>,
<a href="https://github.com/utterance/utterances">[4]</a>).</p>
<h2>Stars vs. time</h2>
<p>The figure below shows some of the top competitors except for Discourse (as it's not
just a light commenting server like others). The figure is useful to
indirectly estimate how active the project is.</p>
<p><a href="https://lisakov.com/projects/open-source-comments/stars-v-date.png">
<img src="https://lisakov.com/projects/open-source-comments/stars-v-date.png" alt="Plot stars vs. time" width="800px">
</a></p>
<h2>Choose columns to show</h2>
</div></div>]]>
            </description>
            <link>https://lisakov.com/projects/open-source-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676152</guid>
            <pubDate>Sun, 04 Oct 2020 02:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A web of trust for NPM]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24673917">thread link</a>) | @tao_oat
<br/>
October 3, 2020 | https://www.btao.org/2020/10/02/npm-trust.html | <a href="https://web.archive.org/web/*/https://www.btao.org/2020/10/02/npm-trust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In 1984 the co-inventor of Unix, Ken Thompson, delivered a seminal speech in which he highlighted that <em>you can’t trust code that you did not totally create yourself</em> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. For a while, this lesson was largely ignored as open-source package registries like RubyGems, PyPI and npm grew rapidly. However, as we’re seeing <a href="https://blog.reversinglabs.com/blog/mining-for-malicious-ruby-gems" target="_blank" rel="noopener noreferrer">more</a> <a href="https://blog.npmjs.org/post/185397814280/plot-to-steal-cryptocurrency-foiled-by-the-npm" target="_blank" rel="noopener noreferrer">and</a> <a href="https://snyk.io/blog/a-post-mortem-of-the-malicious-event-stream-backdoor/" target="_blank" rel="noopener noreferrer">more</a> supply-chain attacks through software dependencies, the risks of using unvetted dependencies are becoming clearer.</p>

<p>The risks are particularly great for JavaScript applications. Veracode found that the average JavaScript project relies on 377 dependencies – compared with just 16 for Python projects, or 43 in the Java ecosystem<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. Whenever a developer pulls in a new dependency, they are implicitly trusting the maintainers of that dependency. Often, this trust is awarded on the basis of popularity – we assume that a popular library will be more carefully vetted, or that since many others trust the maintainers, we can too. Other times, this trust relationship and the risks involved are not considered at all.</p>

<p><a href="https://sambleckley.com/writing/npm.html" target="_blank" rel="noopener noreferrer">Some have argued</a> that the ill health of the npm registry is a social, rather than a technical problem, and suggest a human-compiled set of packages in order to separate the wheat of maintained, healthy packages from the chaff of abandoned toy projects with no documentation. <a href="https://medium.com/@dpc_96143/cargo-crev-and-rust-2019-fearless-code-reuse-b75d58398cb8" target="_blank" rel="noopener noreferrer">Another suggestion from the Rust world</a> involves creating a manual web of trust from maintainers cryptographically signing each other’s projects. Either way, there are challenges: webs of trust have rarely taken off (outside of Debian), and compiling a vetted set of packages from scratch is a massive undertaking. I propose something in the middle: bootstrapping a web of trust using existing npm dependency relationships, and building from that foundation.</p>

<h2 id="existing-trust-relationships-in-npm">Existing trust relationships in npm</h2>

<p>Creating a web of trust from existing npm dependencies is, admittedly, somewhat problematic. As stated earlier, choosing to use a particular dependency is not always a well-considered decision based on researching its code and maintainers, and the trust relationship is merely implied. Similarly, there is no cryptographic verification of this weak trust, nor does npm currently have the infrastructure for such tools<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. What I am suggesting is an imperfect starting point to demonstrate the need for, and potential of, stronger trust measures in open source.</p>

<p>To construct this initial web, we can model npm’s maintainerships as a graph. If we let each node be a maintainer, then the edges between them are the trust relationship arising from using a dependency. In other words, if Alice maintains a package A, and A depends on package B maintained by Bob, then there is a directed edge from Alice to Bob. We can even weigh these edges by the number of Alice’s packages in which she implies trust of Bob.</p>

<h2 id="exploring-the-graph">Exploring the graph</h2>

<p>This simple model exhibits a power-law-like pattern in terms of trust: the vast majority of users are trusted by few or no others, and a very small number of users are highly trusted. This type of pattern is common in social networks: you see a similar thing emerge when plotting follower counts on Twitter. Such power laws often lead to a rich-get-richer feedback process in which the inequality (in terms of trust, in this case) gets more pronounced over time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/efe1a929e64ebeeb021e79f341b35faa4baf1397/c0643/static/img/maintainer-wot-in-degrees.png" alt="Scatter plot of in-degree vs. number of users. Shows a roughly power-law relationship."></p>

<p>Who are these highly-trusted users? They’re who you’d expect: bots for large projects (e.g. <code>types</code>), corporate accounts (e.g. <code>fb</code>), and the maintainers of extremely popular open-source libraries (e.g. <code>sindresorhus</code>, who maintains e.g. <code>string-length</code>).</p>

<p>Perhaps more interestingly, this web of trust exhibits some useful structures. A number of <a href="https://en.wikipedia.org/wiki/Strongly_connected_component" target="_blank" rel="noopener noreferrer">strongly connected components</a> emerge – groups of users that, roughly speaking, all trust each other according to the web of trust principles (i.e. if I trust Alice, and Alice trusts Bob, then I trust Bob, too). All of these connected components are small, with the exception of a single one that’s home to over 11,000 users<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. This core component – we’ll call it the <strong>strong set</strong> – could provide a starting point for a measure of trust in the npm ecosystem.</p>



<p>We can quantify trust in a slightly more nuanced way than simply looking at the in-degree of each npm user. The PageRank algorithm provides such a measure that takes into account the trustworthiness of the people who trust me. For example, I may only be trusted by one user, but if that user is <code>isaacs</code> (the creator of npm) then that trust relationship counts for a lot! After running PageRank, the 10 “most-trusted” users are:</p>

<ol>
  <li><code>types</code></li>
  <li><code>sindresorhus</code></li>
  <li><code>angular</code></li>
  <li><code>m1tk4</code></li>
  <li><code>tjholowaychuk</code></li>
  <li><code>google-wombot</code></li>
  <li><code>fb</code></li>
  <li><code>isaacs</code></li>
  <li><code>gaearon</code></li>
  <li><code>yyx990803</code></li>
</ol>

<p>Many of these are unsurprising. However, <code>m1tk4</code> stands out: they only maintain two rarely-downloaded libraries. Because one of these libraries is used by the BBC, <code>m1tk4</code> is implicitly trusted by a large number of relatively trustworthy BBC employees who maintain other, more popular projects. This demonstrates how PageRank diffuses trust across the social network of npm maintainers. In fact, <code>m1tk4</code> is not a member of the strong set mentioned earlier – but many of the users who trust them <em>are</em>. <code>m1tk4</code> just doesn’t trust those users back!</p>

<p>While PageRank gives a fun measure of trust, it’s a very rough model for the reasons mentioned earlier: it’s based on a pretty weak indication of real trust. However, it might be useful in detecting suspicious behaviours in npm, which is something we – or registry maintainers – need to do proactively if we want to stop supply-chain attacks. For example, it might be a red flag if a highly-trusted user suddenly starts using a library by someone with a PageRank-based-trust of close to 0. And regardless, the strong set comes merely from observing which dependencies people choose to use without applying any complex calculations.</p>

<p>How might we want to use the strong set to create a stricter trust (or reputation) system? I think that formalizing such a system is unlikely if it requires large-scale buy-in from npm users. Instead, we might create a simple wrapper for npm that checks if you’re about to install something from a developer outside of the strong set, similar to Liran Tal’s excellent <a href="https://github.com/lirantal/npq" target="_blank" rel="noopener noreferrer">npq</a>. Or perhaps security researchers could use the npm web of trust as an additional data point when deciding whether a suspicious package warrants further investigation. Either way, the state of trust within the npm ecosystem is not great. This model gives us a starting point.</p>

<p><em>Do you think I’ve got it all wrong? Or do you have further suggestions on how we can improve the state of trust in open source? <a href="https://www.btao.org/contact">Get in touch</a>.</em></p>

<p><em>A final note: this analysis is based on data from June 2020, which I collected for my Master’s thesis. I believe you’d reach similar numbers if you ran the analysis on data from today.</em></p>

<h3 id="footnotes">Footnotes</h3>



</div></div>]]>
            </description>
            <link>https://www.btao.org/2020/10/02/npm-trust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24673917</guid>
            <pubDate>Sat, 03 Oct 2020 18:51:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Starter Kit 2020]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24671403">thread link</a>) | @psxuaw
<br/>
October 3, 2020 | https://wiki.alopex.li/RustStarterKit2020 | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/RustStarterKit2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>People were arguing about Rust’s std lib recently, so I went through the <code>Cargo.toml</code> of all the Rust projects I’ve written since 2015 and picked out the choice tools that get used over and over again. Up to date as of October 2020.</p>
<p>Also see <a href="https://wiki.alopex.li/RustCrates" title="Go to wiki page">RustCrates</a>, though that’s old. There’s also <a href="https://christine.website/blog/rust-crates-go-stdlib-2020-09-27">this</a>, which is narrower but deeper, and <a href="https://github.com/rust-unofficial/awesome-rust">awesome-rust</a>, which is shallower and broader, and the various <a href="https://www.arewewebyet.org/">more</a> <a href="https://arewegameyet.rs/">specific</a> <a href="https://areweasyncyet.rs/">websites</a> <a href="https://www.areweguiyet.com/">for various</a> <a href="https://areweideyet.com/">topics</a>.</p>

<p>I need to set up a new Rust dev environment, what do I install?</p>
<h2 id="linting-clippy">Linting – <code>clippy</code></h2>
<p>The one, the only, the great Rust style and correctness linter. Want to learn how to write “idiomatic” Rust, or just learn more about handy little corners of the language and library? Run <code>clippy</code> regularly. It’s distributed with the compiler via <code>rustup</code> now, so you have no excuse not to.</p>
<h2 id="build-cache-sccache">Build cache – <code>sccache</code></h2>
<p>Or, “how to make a full rebuild 70% faster”. <code>sccache</code> is a build artifact cache similar to <code>icecream</code> or <code>ccache</code>, except it’s actually trivial to just use. <code>cargo install sccache</code>, add a single line in a home dir config file, and you’re ready to go. Pretty much handles most crate and compiler versioning issues for you, so it Just Works if you update crates or install a new version of <code>rustc</code> or something. I think I’ve had to force-clear the cache due to some build weirdness a grand total of once. Looks like it has enough features to use in a professional context as well, at least on a small-to-medium scale.</p>
<h2 id="dependency-viewer-cargo-tree">Dependency viewer – <code>cargo-tree</code></h2>
<p>The best way to view what dependencies you are using, and what dependencies they are using, and so on. Best way to start cracking down on flabby dependencies.</p>
<h2 id="benchmarking-criterion">Benchmarking – <code>criterion</code></h2>
<p>Basically the best benchmark system out there. Incredibly simple to use, informative, and statistically sound. Doesn’t really do profiling, but it’s a good start for understanding your program’s performance, and better for proving that your implementation of X is faster than someone else’s.</p>
<h2 id="other-things">Other things</h2>
<p>Stuff that is less general purpose but occasionally very useful for the meta-programming process of choosing libraries, evaluating them, etc.</p>
<ul>
<li><code>cargo-geiger</code> – Measures how much unsafe code is in a codebase, and its dependencies</li>
<li><code>cargo-crev</code> – A <a href="https://wiki.alopex.li/ActuallyUsingCrev">very neat tool</a> for authoring and verifying distributed code reviews.</li>
<li>Various tools maintained by <a href="https://github.com/EmbarkStudios/rust-ecosystem">Embark Studios</a>, useful for production/company purposes like checking licenses, pinning specific versions of crates, etc.</li>
</ul>

<p>The cool stuff Real Computer Scientists write about.</p>
<h2 id="hashing">Hashing</h2>
<p>No specific crates here. There’s no single crate that provides All The Hash Algorithms, just lots of little ones that generally provide a single algorithm each. Just type the name of the algorithm you want into <code>crates.io</code> and you’ll get at least a couple options, choose the one with 8 million downloads or whatever. <code>sha2</code>, <code>md5</code>, <code>crc</code>, etc. Lots of them are written by the Rust core team.</p>
<h2 id="compression">Compression</h2>
<p>Same as the hashing category. Type <code>zip</code> or <code>bzip2</code> or whatever into crates.io and you’ll get what you need. <code>flate2</code> might be the one crate that’s not quite trivial to find. Again, many of them are written by the Rust core team.</p>
<h2 id="encryption">Encryption</h2>
<p>I have little actual experience or authority on this topic, so I’m going to punt on this one.</p>
<h2 id="pseudorandom-number-generator">Pseudorandom number generator</h2>
<p>Use <code>oorandom</code>. (Disclaimer, I wrote <code>oorandom</code>, but people besides me seem to like it.) More usually you’ll see the <code>rand</code> crate in use. If you’re doing Real Science and need to generate <a href="https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html">fancy probabilities</a>, then <code>rand</code> is the right tool, but most people aren’t doing that. Otherwise <code>rand</code> is complicated and has lots of features, while <code>oorandom</code> is very simple and has about two features, and I expect 80% of code to use at least one of them. <code>rand</code> has had several major breaking changes in its history that the rest of the ecosystem still hasn’t caught up with, while I intend <code>oorandom</code>’s API to change maybe twice in my lifetime. (Its version number, while obeying semver, is mostly a joke.)</p>
<p>There’s other lightweight PRNG crates that are just fine; see <code>oorandom</code>’s readme for a list of some others and choose one you like. Whatever you choose, use the <code>getrandom</code> crate to produce Real Random Seeds for it.</p>

<p>“I just need to solve this ooooooone common problem, but it needs to be solved WELL…”</p>
<h2 id="logging-log">Logging – <code>log</code></h2>
<p>Need to output log messages in your code? Why, use the <code>log</code> crate. Where do the log messages go? <code>log</code> provides only an interface, and that interface compiles to nothing if it isn’t used. You can write your own system for it to actually output the logs to, which is pretty easy, or use one of the small plethora of crates for it. My preferred one is <code>pretty_env_logger</code>, but <code>fern</code>, <code>slog</code> and others are all good too.</p>
<h2 id="parallel-data-crunching-rayon">Parallel data crunching – <code>rayon</code></h2>
<p>Ever have some computation where you have a big list of STUFF and want to process it in parallel, farming out jobs to as many threads as you have CPU’s? That’s what <code>rayon</code> does, and it does it really, really well. You still <a href="https://aspenuwu.me/posts/rust-optimization.html">have to know what you’re doing</a>, but changing a single <code>.iter()</code> into <code>.par_iter()</code> and watching your CPU-bound data-crunching run 8x faster is pretty magical. Now your CPU can help keep you warm this winter!</p>
<p>Please never use it in a library. It’s rude to spawn threads in library code, unless that’s specifically what the library is for.</p>
<h2 id="regexes-regex">Regexes – <code>regex</code></h2>
<p>To quote the inestimable <a href="https://www.jwz.org/blog/">jwz</a>:</p>
<blockquote>
<p>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</p>
</blockquote>
<p>On the other hand, <a href="https://xkcd.com/208/">somebody’s gotta save the day</a>. So, use the <code>regex</code> crate. Also use <a href="https://crates.io/crates/ripgrep">anything else</a> <a href="https://crates.io/crates/xsv">written by BurntSushi</a>. BurntSushi is a paragon of Rust program design, and also just a great <del>human being</del> charred cuisine in general.</p>
<h2 id="threadsafe-globals-lazy_static">Threadsafe globals – <code>lazy_static</code></h2>
<p>“I know globals are evil,” you say, “but I just need one. I’ll only use it for good, I promise.” <code>lazy_static</code> has your back.</p>
<p>May eventually be superseded by <code>once_cell</code>, which looks like its <a href="https://github.com/rust-lang/rfcs/pull/2788">headed for inclusion into <code>std</code></a>.</p>
<h2 id="serializationdeserialization-serde">Serialization/deserialization – <code>serde</code></h2>
<p>Ever have a struct and just wanted to turn it into JSON, CBOR, XML, or some other engine of woe and devastation designed to be written to an I/O stream? Or had a blob of random JSON and wanted to just stuff it into a struct matching it? Sure you have. <code>serde</code> lets you do this with a single <code>#[derive]</code>. <code>serde</code> is without a doubt one of Rust’s killer libraries. It is better than any other serialization system I have ever used.</p>
<p>What data formats does it support? Anything; the actual reading and writing is done via plugin library. There’s a <a href="https://serde.rs/#data-formats">wide selection of them</a>, of varying quality, and writing your own is a little tedious but not terribly difficult.</p>
<h2 id="error-handling">Error handling</h2>
<p>This spot deliberately left blank.</p>
<p>Rust’s <code>Result&lt;T,E&gt;</code> type is one of the best setups for lightweight, transparent error handling I’ve seen, but it doesn’t do everything. How do you easily write your own error type without a bunch of boilerplate? What if you have multiple different error types from different libraries you want to coalesce together? How do you collect a backtrace of every function an <code>Err</code> is returned through, so you can find the root cause of where it came from? Can we do all this without allocating anything unnecessarily? And so on.</p>
<p>There have been various crates to try to solve these problems. First in 2015 there was <code>error_chain</code>, which was complicated and not very convenient. Then in 2017 there was <code>failure</code>, which was simpler but not very flexible, and which took an irritatingly long time to compile. Then in 2019 there was <code>anyhow</code>, which was about the time I stopped paying attention. Now apparently the new kid on the block is <code>eyre</code>, and I’m sure that in another year or two there will be something else.</p>
<p>So, I just write the boilerplate and make my errors descriptive enough I don’t need a backtrace. When I want to get fancy I implement the built-in <a href="https://doc.rust-lang.org/std/error/trait.Error.html"><code>Error</code></a> trait, which used to be kinda useless but is now more helpful. And in another five years it’ll still work just fine.</p>
<h2 id="byte-mucking-bytemuck">Byte mucking – <code>bytemuck</code></h2>
<p>For the rare occasions you need to turn a structure into arbitrary <code>&amp;[u8]</code> or back. Doing this using unsafe pointers is quite easy, and also makes it very easy to screw up horribly with Undefined Behavior galore. (Did you know that changing the value of padding bytes in a struct in UB? You do now.) <code>bytemuck</code> lets you muck around with bytes a little more responsibly.</p>
<h2 id="human-dates-and-times-chrono">Human dates and times – <code>chrono</code></h2>
<p>Rust’s <code>std::time</code> doesn’t really handle calendar or wall-clock times, just arbitrary, monotonic <code>Instant</code>’s and measurable <code>Duration</code>’s between them. Nice, pure, computationally-robust time measurement. For all the nasty human calendar and timezone stuff, you use <code>chrono</code>. (And maybe <code>humantime</code>, but I personally reach for <code>chrono</code> first, just out of habit.)</p>
<h2 id="bit-flags-bitflags">Bit flags – <code>bitflags</code></h2>
<p>Defining type-safe bit-masks in a reasonably convenient way. Not always worth the trouble, but sometimes pretty convenient.</p>

<p>“I have to create or read a…”</p>
<h2 id="pngjpeggifetc-image">PNG/JPEG/GIF/etc – <code>image</code></h2>
<p>General-purpose loading and saving and images, which can handle a lot of formats. Can do some amount of image manipulation as well, such as cropping, smoothing, etc. but that will hopefully be pulled out into its own library at some point soon.</p>
<h2 id="small-data-things-uuid-base64-csv-semver">Small data THINGS – <code>uuid</code>, <code>base64</code>, <code>csv</code>, <code>semver</code>…</h2>
<p>Exactly what it says on the tin.</p>

<p>Not aware of any great encoders, but there’s plenty of <em>decoders</em> for common audio formats. <code>lewton</code> for Ogg Vorbis, <code>hound</code> for .wav, <code>minimp3</code> for MP3, <code>claxon</code> for FLAC. Video, I haven’t used enough to have an opinion on.</p>
<h2 id="config-files-toml">Config files – <code>toml</code></h2>
<p>For all your config file format needs. Works with <code>serde</code>, naturally.</p>
<h2 id="markdown-pulldown-cmark">Markdown – <code>pulldown-cmark</code></h2>
<p>There’s several good Markdown readers and writers, <code>pulldown-cmark</code> is my favorite. It supports CommonMark, it’s simple to use, and it’s pure Rust.</p>
<h2 id="templating-askama">Templating – <code>askama</code></h2>
<p>There’s several quite good text templating engines, but <code>askama</code> IMO rises above them all by compiling your templates into Rust code and type-checking your templates at compile time. Sometimes this isn’t what you want, but it is a great feature surprisingly often. This also makes it super fast, for when you really need to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/RustStarterKit2020">https://wiki.alopex.li/RustStarterKit2020</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/RustStarterKit2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671403</guid>
            <pubDate>Sat, 03 Oct 2020 12:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The truth about ferrites]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24671225">thread link</a>) | @lightlyused
<br/>
October 3, 2020 | https://qrm.guru/the-truth-about-ferrites/ | <a href="https://web.archive.org/web/*/https://qrm.guru/the-truth-about-ferrites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1430">
          
         <!-- .entry-header -->
         
       <!-- /.entry-header -->
       
       
       <div>
        <p><em><strong>These tests and experiments were performed by Ian Jackson VK3BUF in the QRM Guru test lab.</strong></em></p>
<div class="page" title="Page 1">
<div>
<p>Much has been said about the importance of applying ferrite clamps, rings and beads to radios and other domestic products to fight QRM.</p>
</div>
</div>
<p>Articles on the correct placement of ferrite noise suppressors are common, but little has been written about the different options and where to buy them. &nbsp;In Australia, there are only a limited number of suppliers that carry stock.&nbsp; Ferrite size, shape and cost varies significantly.&nbsp; The information provided can be minimal or non-existent.&nbsp; Part numbers for ferrites listed in international catalogues are not generally available in Australia and buying these can entail long lead times and high freight costs.</p>
<p>Often we don’t really know what we’re getting and how effective they will work for us when they finally arrive.&nbsp; From this perspective, buying and using ferrite filters seems to have more in common with black magic than the application of radio science.</p>
<ul>
<li>How do I know if the ferrites I purchased are good, bad or totally ineffective?</li>
<li>Do I get what I pay for? &nbsp;Are expensive ferrites much better than cheap ones?</li>
<li>How can I tell if one ferrite is enough?&nbsp; Are 2 or 3 together really worthwhile?</li>
<li>What are the advantages of clamps over beads and rings?</li>
<li>Are big and heavy ferrites better than lightweight and small ones?</li>
<li>How far up the radio spectrum are these things going to work for me?</li>
</ul>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-3.jpg" alt="" width="243" height="218" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-3.jpg 832w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-300x270.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-768x690.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-60x54.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-150x135.jpg 150w" sizes="(max-width: 243px) 100vw, 243px">Ferrites are a type of ceramic made from iron and other oxides and come moulded into different shapes.&nbsp; The material combination &nbsp;is called a ‘mix’.</p>
<p>The characteristics of these mixes determine where and how they should be used.&nbsp;&nbsp; When a wire passes through or near ferrite materials, it effectively adds resistance to that wire at radio frequencies, but this resistance effect varies with the frequency applied to the wire.</p>
<p>Every ferrite has its own characteristic impedance curve allowing it to absorb unwanted RF currents before reaching your receiver or appliance.</p>
<p>Unfortunately, you can’t tell what that working curve is going to be just by looking at it.</p>
<p>For this experiment, we purchased sample ferrites from the Australian retailers Jaycar and Altronics.&nbsp; We compared these with samples of similar size from the QRM Guru ferrite kits, then further compared all of these with some cheap ‘no-name’ ferrites purchased from eBay.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-4.jpg" alt="" width="800" height="460" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-4.jpg 800w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-300x173.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-768x442.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-60x35.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-150x86.jpg 150w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>Testing methodology is important.&nbsp; We used a spectrum analyser with a tracking generator.&nbsp; The spectrum analyser shows gain or loss of radio frequencies between any two points on the radio spectrum.&nbsp; Our unit has capability to scan the radio spectrum from 10KHz to 1.5 GHz, but in this trial, we profiled these ferrite devices between 100KHz and 450MHz.</p>
<p>The tracking generator creates a small signal that regularly sweeps between two frequencies we are monitoring at a very controlled level.&nbsp; We are then able to couple from the tracking generator to the spectrum analyser via a small brass rod, which will become our test wire.&nbsp; First we&nbsp; ‘<strong>normalise’</strong> to compensate for any stray capacitance and inductance around our test area.&nbsp; A flat yellow line represents zero dB.&nbsp; This line becomes our reference point before filtering is added.&nbsp; When any unknown ferrite is added to the test conductor, we measure a clear plot showing the unique characteristics of that item.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-5.jpg" alt="" width="985" height="509" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-5.jpg 985w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-300x155.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-768x397.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-60x31.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-150x78.jpg 150w" sizes="(max-width: 985px) 100vw, 985px"></p>
<p>With this arrangement we examined a graphic plot of each sample, then recorded five unique values which identify its effectiveness.&nbsp; We looked at :</p>
<ul>
<li>(<strong>A</strong>) The <strong>lowest</strong> frequency where the item drops below the -3dB (half-signal) point.</li>
<li>(<strong>B</strong>) The <strong>highest</strong> frequency where the curve crosses the -3dB point</li>
<li>(<strong>C</strong>) The frequency (<strong>MHz</strong>) where the greatest attenuation takes place</li>
<li>(<strong>D</strong>) The maximum degree of <strong>attenuation</strong> (peak –dB) that takes place.</li>
<li>(<strong>E</strong>)&nbsp; The <strong>weight</strong> of each ferrite item.&nbsp; (in grams)</li>
</ul>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-7.jpg" alt="" width="932" height="360" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-7.jpg 932w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-300x116.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-768x297.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-60x23.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-150x58.jpg 150w" sizes="(max-width: 932px) 100vw, 932px"></p>
<p><strong>Not all characteristics are being tested here</strong></p>
<p>It should be noted that this article is focused on using ferrites for noise reduction only.&nbsp; In this role the energy being absorbed is not great.&nbsp; Where ferrites are used in high-current environments, such as in a transmitter balun, there will be an RF power threshold where they can no longer effectively absorb energy and their characteristics will begin to distort.</p>
<p>The overheating and saturation effects of high current applications are not a part of this study.</p>
<h2><strong>Study Results</strong></h2>
<p>The table below contains the raw results of our assessment, grouped in order of supplier, then size. &nbsp;The figures can be difficult to digest in this form, but we can take away some very important findings from this test data.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-8.jpg" alt="" width="900" height="459" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-8.jpg 900w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-300x153.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-768x392.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-60x31.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-150x77.jpg 150w" sizes="(max-width: 900px) 100vw, 900px"></p>
<h2><strong>Branding vs Price</strong></h2>
<p>The first significant observation is that they all worked.&nbsp; Regardless of the source, none of the samples tested were fake or defective.&nbsp; They were all capable of suppressing radio frequencies to a greater or lesser degree. &nbsp;This is reassuring, as you can never prove authenticity just by looking at a ferrite.</p>
<p>From these samples, we can surmise that regardless of their source, all of these clamp-on ferrites will provide at least some degree of effectiveness in the shack.</p>
<h2><strong>Ferrite Mixture Type</strong></h2>
<p>The next observation (with the exception of the Altronics Iron Core ring) is that all of these materials are composed from a similar mix of ferrite material.&nbsp; The absorption curves were all a reasonable match to <strong>Mix 43</strong>.&nbsp; This indicates that their application is appropriate for HF and low VHF frequencies.&nbsp;&nbsp; (The Altronics ring L4534A was purchased with the rest of the ferrites, but it does not qualify as a ferrite device.&nbsp; It is a powdered iron object with different characteristics.&nbsp; We left it in the test for contrast and will provide separate comment on these devices.)</p>
<h2><strong>Size vs weight correlation of ferrite clamps</strong></h2>
<p>Clamp-on ferrite devices come in a variety of different physical sizes and shapes.&nbsp; It is reasonable to think that bigger ferrites work better than smaller ones, but is this actually the case?&nbsp; We sorted our samples by weight and plotted this chart to see how closely the degree of absorption of RF energy followed the physical weight of each sample.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-9.jpg" alt="" width="874" height="242" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-9.jpg 874w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-300x83.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-768x213.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-60x17.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-150x42.jpg 150w" sizes="(max-width: 874px) 100vw, 874px"></p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-10.jpg" alt="" width="326" height="267" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-10.jpg 481w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-300x246.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-60x49.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-150x123.jpg 150w" sizes="(max-width: 326px) 100vw, 326px">The answer appears to be”partially yes”.&nbsp; Generally, heavier ferrites will out-perform lighter versions, but there were a couple of exceptions that did very well.</p>
<p>The <strong>Altronics</strong> solid ring <strong>L4534A (A3) </strong>outperformed clamps of similar weight, as did the <strong>Jaycar</strong> <strong>LF1294 (J2)</strong>.&nbsp; Both are circled in red in the chart above.</p>
<p>There is a correlation between ferrite effectiveness and wall thickness.&nbsp; Both circled examples had a relatively small internal wire opening, which made for a thicker clamp wall.&nbsp; This equates to a higher density of ferrite material around the single conductor, giving superior performance.</p>

<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-11.jpg" alt="" width="321" height="203" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-11.jpg 425w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-300x190.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-60x38.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-150x95.jpg 150w" sizes="(max-width: 321px) 100vw, 321px">Conversely, sample <strong>E1</strong> from eBay was a physically large clamp, but it catered for a thick 12mm cable.&nbsp; This thinner wall thickness reduced effectiveness, as seen by the data point circled in yellow on the chart above.</p>
<p>This effect is not as bad as it first seems, so don’t necessarily shop only for thick-walled clamps.&nbsp; Examine some of the following sections in this article which explore the most effective ways to use ferrite clamps.</p>
<p>The final comment on the size of clamps was the observation that the very small clamp-on ferrites don’t have sufficient mass for good performance.&nbsp; The smallest of the eBay clamps (<strong>E5</strong>) didn’t even reach -3dB.&nbsp; Unless a friend gives you a lot of them for nothing, there is a lot to be said for aiming straight for medium and large clamps, or the results could be disappointing.</p>
<h2><strong>Are solid ferrite rings better than split rings?</strong></h2>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-12.jpg" alt="" width="335" height="209" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-12.jpg 552w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-300x188.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-60x38.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-150x94.jpg 150w" sizes="(max-width: 335px) 100vw, 335px">This turned out to be an easy question to answer.&nbsp; Two rings of similar weight, hole-size and ferrite mix were compared.&nbsp; One was solid and the other was split.</p>
<p>The results were almost identical when tested.&nbsp; This tells us that shopping for solid cores have no real advantage over split cores.&nbsp; However, the split ferrites can be applied to cables without having to remove connector plugs and this makes them a more practical purchase.</p>
<h2><strong>What’s the best way to use ferrites?</strong></h2>
<p>An important question to answer is “<em>what is the optimum configuration for the application of ferrite clamps</em>“.&nbsp; It’s easy to imagine that two clamps are better than one, but how much better?</p>
<p>For this exercise we focused our attention on the QRM Guru clamps (<strong>Q2</strong>) designed for 8mm wire.</p>
<p>Compare the following screen captures and images of one and two clamps:</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-13.jpg" alt="" width="1173" height="435" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-13.jpg 1173w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-300x111.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-1024x380.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-768x285.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-60x22.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-150x56.jpg 150w" sizes="(max-width: 1173px) 100vw, 1173px"></p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-14.jpg" alt="" width="1164" height="429" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-14.jpg 1164w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-300x111.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-1024x377.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-768x283.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-60x22.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-150x55.jpg 150w" sizes="(max-width: 1164px) 100vw, 1164px"></p>
<p>Unsurprisingly, doubling up on the clamps gives an additional 3dB of RF absorption.&nbsp; At <strong>55 MHz</strong> the peak absorption jumped from <strong>-4.40 dB</strong> to <strong>-7.54 dB</strong>.&nbsp;&nbsp; This tells us that if one clamp on its own does not quite do the job, then add another for improved performance.&nbsp; Be aware that to achieve a further 3dB, you must double again from two to four units.</p>
<p>Next, we explore the effectiveness of looping a wire through a clamp more than once.&nbsp; This can only work where there is sufficient slack in the cable, and where the hole in the core is large enough to accept additional turns.</p>
<p>Here is what happens:</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-15.jpg" alt="" width="1151" height="458" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-15.jpg 1151w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-300x119.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-1024x407.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-768x306.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-60x24.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-150x60.jpg 150w" sizes="(max-width: 1151px) 100vw, 1151px"></p>
<p>This is a very interesting result showing that the single extra turn through the core increases absorption from -4.4dB to a huge -12.41 dB.&nbsp;&nbsp; This 8 dB increase makes a single clamp provide the same effectiveness of around six such clamps on the same wire.</p>
<p>Want to see some case studies covering off the use of ferrites?&nbsp; Click on the links below</p>
<h2><strong>Why adding turns makes ferrites much more effective</strong></h2>
<p>This effect is not really a mystery when we break down what’s happening.&nbsp; When we add ferrite to a wire, we are effectively adding series resistance to that wire, but this resistance effect varies with frequency.&nbsp; At steady DC, the ferrites have no effect, but as an AC signal is applied a resistance is developed within the wire surrounded by the ferrite material.&nbsp; The higher the frequency, the greater the increased resistance.&nbsp; This resistance is also affected by the type of ferrite material, its volume, and its distance from the wire concerned.</p>
<p>When we …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qrm.guru/the-truth-about-ferrites/">https://qrm.guru/the-truth-about-ferrites/</a></em></p>]]>
            </description>
            <link>https://qrm.guru/the-truth-about-ferrites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671225</guid>
            <pubDate>Sat, 03 Oct 2020 11:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case for building a SETI observatory on the moon]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24670960">thread link</a>) | @pseudolus
<br/>
October 3, 2020 | https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>On Monday, a group of researchers sponsored by Breakthrough Listen, the world’s largest SETI program, </span><a href="http://seti.berkeley.edu/lunarseti/" rel="noopener noreferrer" target="_blank">submitted a paper</a><span> to National Academy of Sciences’ Planetary Science and Astrobiology Decadal Survey that makes the case for establishing a SETI radio observatory on the farside of the moon. The decadal survey establishes scientific priorities for the next ten years and the new paper addresses one of the biggest problems facing the search for extraterrestrial intelligence today: The overwhelming amount of radio interference.&nbsp;</span></p></div><div><p><span>Our planet has become so “loud” in the part of the radio spectrum observed by SETI that it threatens to drown out any signal sent from an intelligent civilization. Not only would a lunar radio telescope not have to deal with terrestrial radio interference, it could also significantly increase our chances of hearing from ET by opening up parts of the radio spectrum that are blocked by Earth's atmosphere. While the idea of using the moon for radio astronomy is decades old, the researchers make the case that technological advancements have finally made a lunar SETI observatory truly feasible.</span></p></div><div><div><p><span>
says Eric Michaud, an intern at the SETI Berkeley Research Center and the first author of the paper. “Maybe not today, but I think it’s going to get more and more feasible as time goes on.”&nbsp;</span></p></div></div><div><p><span>Radio interference has been a problem for SETI from the very beginning. In the spring of 1960, the planetary scientist Frank Drake trained the massive radio telescope at Green Bank Observatory in West Virginia on Tau Ceti and Epsilon Eridani, two stars a mere 12 light years from Earth. That summer, Drake spent his days studying the signals picked up by Green Bank’s giant mechanical ear in the hopes of receiving a message broadcast by an alien civilization orbiting those stars. Known as Project Ozma, Drake’s experiment marked the beginning of SETI, the scientific search for extraterrestrial intelligence.&nbsp;</span></p></div><div><p><span>Shortly after Drake started his observations, he was surprised to find what appeared to be a signal of intelligent origin. After days of watching a needle drift lazily over a spool of paper recording the random undulations of cosmic static, Drake and his colleagues were jolted awake when the machine started recording the frantic pulses of a strong radio signal picked up by the telescope. The timing and magnitude of the pulses clearly marked them as artificial; there was nothing in the natural world that could produce such a frenetic radio profile. It would have been an astounding stroke of luck to pick up an alien message after only a few hours of observation, but it was hard to argue with the data.&nbsp;</span></p></div><div><p><span>“None of us had ever seen anything like it,” Drake recalled in </span><em>Is Anyone Out There?</em><span>, his autobiographical book about the early days of SETI. “We looked at each other wide-eyed. Could discovery be this easy?”</span></p></div><div><div><p><span>

It was a letdown, but the false detection turned out to be a portent for the future of SETI. In the 60 years since Drake’s pioneering experiment, researchers have conducted dozens of SETI searches across thousands of stars and turned up empty-handed. At the same time, the sources of radio interference on Earth—military radars, TV towers, cell phones, and satellites—have exponentially increased, which greatly increases the chances that an extraterrestrial signal will be lost among the noise.&nbsp;</span></p></div></div><div><p><span>Earth was never a particularly great place to do any kind of radio astronomy due to our thick atmosphere blocking a large portion of the radio spectrum. The proliferation of radio communication technologies has only made things harder. The moon, by comparison, has no atmosphere and its nights last for weeks on end, which limits radio noise from the sun. And as&nbsp;NASA discovered through a spate of lunar orbiter missions in the late 1960s, the moon also acts as a natural shield that blocks radio signals emanating from Earth. As the planetary astronomer Phillipe Zarka has put it, “the farside of the moon during the lunar night is the most radio-quiet place in our local universe.” It’s exactly the sort of peace and quiet you want if you’re searching for faint radio signals from solar systems that might be hundreds of light years away.&nbsp;</span></p></div><div><p><span>The new Breakthrough Listen paper proposed two main approaches to a lunar SETI observatory: an orbiter and a telescope on the surface. The basic idea behind a SETI lunar orbiter would be to scan for signals as it passed over the lunar farside and relay data back to Earth as it passed over the near side. One of the main advantages of an orbiter is cost. The proliferation of small satellites that are capable of accurate tracking combined with low-cost small launch providers like Rocket Lab means that a SETI orbiter could conceivably be sent to the moon </span><a href="https://www.nasa.gov/press-release/nasa-awards-contract-to-launch-cubesat-to-moon-from-virginia/#:~:text=The%20firm%2Dfixed%2Dprice%20launch,Tyvak%20Nano%2DSatellite%20Systems%20Inc." rel="noopener noreferrer" target="_blank">for less than $20 million</a><span>. This would be a valuable pathfinder mission that could pave the way for a more ambitious observatory on the surface, but without the risk and cost.&nbsp; As the </span><a href="https://www.supercluster.com/editorial/the-supercluster-podcast-water-bears-might-now-occupy-the-moon" rel="noopener noreferrer" target="_blank">ill-fated Israeli Beresheet lander mission</a><span> reminded us, landing on the moon is extremely challenging even when the mission is backed by $100 million.&nbsp;</span></p></div><div><p><span>But a SETI lunar orbiter would also come with a lot of compromises. It would only be able to conduct observations during the brief stretches when it was on the lunar farside, which would make a sustained observation campaign more challenging. The upshot is that an orbiter would have access to the full sky, whereas a telescope on the surface would be constrained by the moon’s rotation. The biggest downside of an orbiter is that it might lose a lot of the shielding benefits of the moon and be more vulnerable to radio interference from Earth since it would be orbiting high above the lunar surface.&nbsp;</span></p></div><div><p><span>“The first SETI observations that are done from the lunar farside will be done from orbit, there’s no question about that,” says Andrew Siemion, the director of the Berkeley SETI Research Center and the second author on the paper. “I think eventually we absolutely want to do something on the surface because we want to build a very large aperture telescope, but even when we’re at that point I don’t think that would negate the utility of doing things from orbit as well.”&nbsp;</span></p></div><div><p><span>So what would a SETI observatory on the moon look like? One idea is to use the naturally parabolic lunar crater as a radio dish, much like the Arecibo telescope in Puerto Rico and </span><a href="https://www.supercluster.com/editorial/chinas-massive-telescope-is-the-next-great-seti-hope" rel="noopener noreferrer" target="_blank">the FAST telescope in China</a><span>, which are built into natural depressions in the land. This idea was </span><a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/RS012i005p00845" rel="noopener noreferrer" target="_blank">first considered</a><span> back in the late 1970s by a group of scientists at the radio physics lab at the Stanford Research Institute. Their idea was to recreate Arecibo on the moon by suspending an antenna from the lip of a crater and using the basin as a reflector. The reduced gravity on the moon would allow for a radio telescope far larger than any on Earth, which could significantly enhance the sensitivity of SETI searches. Ultimately the researchers concluded that a lunar radio observatory was too expensive compared to SETI telescopes that could be built on Earth.&nbsp;</span></p></div><div><p><span>But 40 years later, Michaud says that building a radio dish in a lunar crater may finally be cheap enough to pull off. One of the main drivers of this cost reduction is the advent of commercial launch providers like SpaceX and Rocket Lab, which have </span><a href="https://www.supercluster.com/editorial/cheaper-rockets-growing-the-human-family-in-space" rel="noopener noreferrer" target="_blank">dramatically lowered the cost of space access</a><span>. Another driver is NASA’s push to establish a permanent human presence on the moon, which has subsidized the development of a fleet of commercial lunar exploration vehicles. “There’s so much interest in going back to the moon,” says Michaud, who cited Blue Origin’s lunar lander and Rocket Lab’s Photon Lunar satellite as examples of technologies enabled by </span><a href="https://www.supercluster.com/editorial/nasas-first-puerto-rican-born-director-aims-for-a-moonshot" rel="noopener noreferrer" target="_blank">NASA’s Artemis program</a><span>.&nbsp;</span></p></div><div><p><span>A crux of the original vision for lunar SETI observatories was that it would require a human settlement on the moon to build and operate the radio dish. But robotic systems have improved enough that it may be possible to take humans out of the equation. This was clearly demonstrated in 2019 when China’s Chang’e 4 rover landed autonomously on the farside of the moon. These advancements in autonomous navigation have laid the foundation for a lunar radio observatory that is built entirely by robots.&nbsp;</span></p></div><div><p><span>It sounds like science fiction, but earlier this year NASA’s Advanced Innovative Concepts program </span><a href="https://www.nasa.gov/directorates/spacetech/niac/2020_Phase_I_Phase_II/lunar_crater_radio_telescope/" rel="noopener noreferrer" target="_blank">awarded one of it’s prestigious grants to Saptarshi Bandyopadhyay, a researcher at the Jet Propulsion Laboratory, to figure out a way to make it happen</a><span>. His idea is to use rovers to deploy wire mesh in a crater on the lunar farside and suspend a receiver over the dish. NIAC is all about funding high risk, high reward missions, and there’s no guarantee that Bandyopadhyay’s proposal will ever come to fruition. Still, addressing the technical problems associated with building a radio receiver on the farside of the moon is an important first step.</span></p></div><div><p><span>And Bandyopadhyay isn’t the only NASA-backed researcher contemplating a lunar radio observatory. Jack Burns, a radio astronomer at the University of Colorado, has also received a grant to study a mission concept for a radio telescope array called </span><a href="https://www.colorado.edu/project/lunar-farside/dr-jack-burns" rel="noopener noreferrer" target="_blank">FARSIDE</a><span>. Instead of using a crater as a dish, FARSIDE would deploy several smaller antennas across the lunar surface that would collectively form a large radio telescope. Both NASA studies are focused on radio astronomy rather than SETI, but Siemion sees the two disciplines as natural allies in the quest to establish an observatory on the lunar farside. SETI has piggybacked on other radio astronomy projects in the past—SERENDIP, for instance, opportunistically searched for ET signals during radio observation campaigns at a variety of telescopes—and it seems plausible that a similar arrangement could be made with an observatory on the moon.&nbsp;</span></p></div><div><p><span>Siemion acknowledged that there were certain technical challenges that would arise in a collaboration on a lunar radio observatory. The biggest issue, he says, is that a lot of radio astronomy is done at frequencies that don’t really require an observatory on the moon. “Radio …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670960</guid>
            <pubDate>Sat, 03 Oct 2020 10:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding Worry Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24670483">thread link</a>) | @gfysfm
<br/>
October 3, 2020 | https://www.seangoedecke.com/worry-driven-development/ | <a href="https://web.archive.org/web/*/https://www.seangoedecke.com/worry-driven-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header></header><section><p>Sofware dysfunction is more often motivated by anxiety, fear, worry and embarassment than it is by a lack of technical skill. Engineers avoid work that needs doing because they’re afraid of becoming entangled with a nightmarish task, or because they’re afraid of looking stupid, or harming their career by spending time on grungy work. The task itself is rarely that difficult; it just seems so, which is enough of a barrier to discourage anyone from picking it up. One of the highest-leverage things you can do as an engineer is to recognize this emotional reaction in yourself and work to counter it. If you’re working on a single task, doing this can make your implementation significantly cleaner. If you’re a senior engineer with responsibility for a whole system, this can help you address high-impact architectural or operational issues.</p>
<p>You can see this in the common advice to sleep on a problem and come back to it in the morning. A bug that seems impossible when you’re tired and frustrated is far more approachable when you’re well-rested and caffeinated. Tedious investigative tasks (like scanning the logs for a bug or tracing all the possible code paths in a function) are still tedious in the morning, but infinitely more doable. You can knock it out in half an hour while drinking your morning coffee, rather than spending hours the night before avoiding the tedious work and hoping for a flash of inspiration.</p>
<p>Necessary work avoided becomes a haunted forest in the codebase. One engineer’s avoidant emotions turn into dangerous team habits as engineers teach each other to avoid touching certain files, or to pass odd-looking production bugs to the operations team. “This network behaviour is dark magic, let them handle it!” What began as a single engineer’s worry is now a team’s dysfunction, and can eventually metastasize into actively blocking engineers from working on the original technical problems: if you’re avoiding working on a worrying problem, it can feel threatening when someone else comes along and tries to solve it. What if they succeed, or worse still succeed easily? That would reveal that you weren’t good enough to solve the problem.</p>
<p>Just because you’re touching a scary part of the system doesn’t mean you’re facing scary work calmly and rationally. Engineers often approach thorny work like they’re going through a haunted house: either trudging through with eyes half-closed, or rushing through at full speed trying to get out as quickly as possible. Both tactics aim to take in as little of the frightening environment as possible, and neither tactic is a good way of solving real problems in technical systems. If you’ve ever just tweaked setings or frantically moved code around until it worked, you’ve done this.</p>
<p>From the inside, this doesn’t feel like emotionally-driven avoidance. It feels like working on legacy code, sharing friendly complaints about it with other engineers on your team. This is in part because a fear of hard technical problems can be a rational fear. Untangling messy parts of the codebase, identifying and removing dead code, cleaning up build, deploy and monitoring systems - these tasks often feel overwhelming because they can overwhelm you, sucking up days for no real gain. It can harm your career to spend time on this work in an org that mainly values shipping features. (I haven’t seen the other common worry - looking stupid - really be an issue in practice myself.) The trouble comes when you don’t recognise that part of your response is emotional, and therefore overrate the actual difficulty or risk.</p>
<p>How can you distinguish a rational response to a too-difficult task from a learned emotional reaction to a task that is merely worrying? This is a hard problem. I think it is the hardest problem that almost all engineers will regularly face. One approach is to avoid trying to tell the difference at all, and allot a certain amount of time to looking at randomly-chosen neglected parts of the system. Things that reduce stress in general are also good ways to reduce stress and worry about work. Good sleep, eating well, exercise, therapy, and working in an emotionally safe team all have a significant positive effect on the quality of engineering work. Once you start doing this, the difference is usually obvious in hindsight: if the task that worried you for six months took an hour or two of work when you finally mustered up the effort to look at it, you know your worry was unfounded. Dealing with worry is a virtuous cycle. Each difficult task you do makes you less scared of the next one.</p>
<p>Tackling a series of worrying tasks is one of the quickest ways I know to have massive impact in your engineering org. This is because once you understand a thorny piece of code, or a neglected system, you will usually see how to make obvious improvements. In any other part of the system these improvements would have been made already, but since you are the first person to really wrap your head around it in a long time, you get to make them here! Occasionally, you will see the opportunity to completely remove the worrying part of the system, which for me is one of the most satisfying things you can do as a software engineer. Removing things that cause your team stress has compounding benefits to your team, to the systems you work on, and to your engineering org in general.</p></section><hr></article></div>]]>
            </description>
            <link>https://www.seangoedecke.com/worry-driven-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670483</guid>
            <pubDate>Sat, 03 Oct 2020 08:23:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Honest Review of Gatsby]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24670252">thread link</a>) | @ehfeng
<br/>
October 3, 2020 | https://cra.mr/an-honest-review-of-gatsby/ | <a href="https://web.archive.org/web/*/https://cra.mr/an-honest-review-of-gatsby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We decided to adopt Gatsby for <a href="https://docs.sentry.io/">Sentry’s customer-facing documentation</a> - well, I should say that <em>I</em> decided. We were already using it successfully for a variety of static marketing content, and I knew it had a lot of hype, so after a brief proof-of-concept it seemed like a safe choice.</p>
<p>To help contextualize everything I’m about to say, it’s important to understand the scope of our usage. Sentry’s documentation is not as straightforward as you might think - in fact, there are over 3,000 pages as of writing. We have a large amount of templated content designed to render language-specific examples, as well as a variety of different types of documentation (user guides, help desk-y articles, code-rich technical docs). Originally we had extended Jekyll to support a lot of this, but Ruby isn’t widely used at Sentry (approximately 0% of the engineering team knows Ruby), and it had become a big mess of spaghetti code with slow build times.</p>
<p>I also want to note that while this blog post is primarily focusing on the flaws of Gatsby as a framework, I’m not here to tell you that it’s not good for your use case. That said, I was not able to discover many of these short comings easily when evaluating Gatsby, and many things you read on the internet don’t stem out of real-world usage. My hope here is that Gatsby continues to improve over time, and that, as a user, you can be more informed about if it’s the right choice for you.</p>
<h2>Adopting Gatsby</h2>
<p>So, enter Gatsby. It seemed fast, was built on React (we’re experts on that here, with our gigabyte-sized Sentry frontend app), and had a huge adoption (assumed future existence and stability). While we didn’t have the desire to use MDX, it also seemed like a positive outcome given we could more easily deal with some of the rich aspects of our docs site, without having to resort to 2010-era JavaScript. We assumed a bunch of the other features of Gatsby had value-add, but we didn’t have an immediate need. These were things like dynamic source data - thus the need for a GraphQL engine at all - as well as the large plug-in ecosystem.</p>
<p>We started by iteratively converting sections of the Jekyll site into Gatsby - running them side by side for a time. At one point we eventually bulk converted pages, and ripped off the band aid. At this point though it was becoming clear build times were a problem. You’d spend at least 5 minutes on image optimization alone, with no way to even disable that. Slowly but surely we were depleting the ozone later on re-optimizing images which had already been pre-optimized. Oh yeah, and we were crippling our iteration speed as well, since the build cache would invalidate under a variety of situations in early development.</p>
<p>Making this worse was how we deployed Gatsby. We started off leveraging what we had already done: deploying Jekyll with Docker onto our own infrastructure - effectively just proxied via a CDN. We continued that for a period of time, but deploy times were far too long - upwards of 30-40 minutes for everything to build. Eventually we moved over to <a href="https://vercel.com/">Vercel</a> which dropped it down closer to 10 minutes, but ultimately it can’t fix what it doesn’t control.</p>
<p>The build and deploy times were the first of many woes, and they represent what would become a continued frustration: a problem without a clear solution.</p>
<h2>Enter MDX</h2>
<p>Rewind time a little bit - this actually wasn’t our first project converting documentation to Gatsby. The proof-of-concept I mentioned earlier was actually our <a href="https://develop.sentry.dev/">developer documentation</a>, which I had migrated out of Notion to make public. While doing that we had gotten our hands dirty with some initial MDX usability and extensions - like our code samples which support toggling between different languages. This was one of the many things we needed to solve for, but MDX made it look like it’d be seemingly easy. No more jQuery DOM manipulation, just clean, encapsulated React components. Or so we thought.</p>
<p>Almost immediately we hit rough spots with MDX. We were coming from Jekyll - which was Liquid-rendered (a template engine) markdown - to MDX - a strange offspring of Markdown and JSX, attempting all of the benefits of both, but missing by a fairly large margin. Let’s illustrate the crux of the issue with what has got to be one of the most common needs in a documentation system: an alert (or callout) component:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>info<span>"</span></span><span>&gt;</span></span>You should know something important about this!<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>At face value this looks great. <code>Alert</code> is just a React component, and JSX is close enough to HTML that non-technical folks are able to pick it up fairly easily. Now the problem comes into play when you actually want to do something in the real world. Here’s an example from our API docs:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span>
    <span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.
<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>How would you expect this to render? Both as an engineer and a non-engineer, I would expect - given this is markdown - that the “PUT/DELETE” text would be bold. It’s not. Because the MDX interpreter decides that once you enter a component block, it’s no longer markdown. So instead, we’re forced with this monstrosity <em>everywhere</em> in our documentation:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;</span>markdown</span><span>&gt;</span></span>

<span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.

<span><span><span>&lt;/</span>markdown</span><span>&gt;</span></span><span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>There’s two things you should note here: 1) we have to use this <code>&lt;markdown&gt;</code> tag, 2) we have to put empty new-lines to ensure paragraph tags render.</p>
<p>“But David”, you might say, “why don’t you just tell the <code>Alert</code> component to render the text as markdown?“. If only you could, or at least, if only I could have possibly found a way to achieve that as a user with minimal Gatsby or MDX internals knowledge.</p>
<p>To Gatsby, or at least to the MDX team’s credit, they recognize some of these problems and <a href="https://github.com/mdx-js/mdx/issues/1041">there is work underway</a> on a 2.0 of the MDX dialect. While I’m confident they will improve things, I’m not confident MDX can ultimately succeed. It’s likely going to tradeoff one problem for another due to what it’s trying to achieve in the first place. It may get to a good place, but frankly, we need to step back and look at what we’re trying to solve, instead of creating a solution to a problem we don’t have. I don’t need JSX syntax in my markdown, I need a way to include JSX components. That might sound similar, but its quite a different thing.</p>
<p>As an example, there’s no reason I couldn’t simply use markdown syntax, and provide a way to achieve something akin to:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>a-valid-html-tag-because-markdown-allows-that</span> <span>a-valid-property</span><span><span>=</span><span>"</span>a-value<span>"</span></span><span>&gt;</span></span></code></pre></div>
<p>This wouldn’t force us to work around quirks in a new language (or interpreter even), and could be solved in a much more sustainable way. There are other alternatives as well. A generic way to render extensions in markdown could simply call into a React component, and avoid even trying to hijack HTML in the first place. While I don’t know what this might look like in Markdown, in <a href="https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html">Sphinx’s use of reStructuredText</a> this was solved early on with Directives:</p>
<div data-language="text"><pre><code>.. my-directive:: some data
   :property-name: property-value</code></pre></div>
<p>I will hold out for MDX 2.0 and hope that finds a nice minimal-compromise place, but if not, we’ll be looking for a way to extend native markdown.</p>
<h2>A Broken DOM</h2>
<p>While we were able to work around the kinks of MDX, there’s been some things not yet solved. One of those is the layer which Gatsby uses to apply diffs to the DOM. I’m going to caveat this section with <em>I don’t know what the technical implementation is</em>, but I can make some assumptions given what I know of the domain. The system itself is intended to apply deltas to the DOM. This is naively also how React works, and I imagine under the hood it’s relying on React at least for part of it. We’ve had issues with this identified in two places already:</p>
<ul>
<li>progressive image loading</li>
<li>dynamic JSX components</li>
</ul>
<p>While they might not be linked to the same issue, they smell like they are, so we’re going to roll with it. The problem exhibits itself when you have a bunch of DOM that to a naive robot might look the same:</p>
<div data-language="text"><pre><code>&lt;div&gt;foo&lt;/div&gt;
&lt;div&gt;bar&lt;/div&gt;
&lt;div&gt;baz&lt;/div&gt;
&lt;div&gt;foobizbar&lt;/div&gt;</code></pre></div>
<p>In React it uses the graph to identify which node is which - effectively creating a unique entity ID based on its location. In cases where that’s difficult, React will warn you to explicitly bind a <code>key</code> attribute on each element to ensure it can more accurately deal with updates. While I would assume Gatsby is at least partially using React’s DOM engine, what we see in production effectively takes the above example, and replaces some of the content with other subsets of content - meaning it’s unable to accurately identify which nodes need updated.</p>
<p>We’ve seen this where a progressive image is replaced with an entirely different image that’s present near it on the page. We’ve also seen this happen for a dynamically loaded section of content (our language-selector include tags). While we’ve yet to identify a fix for the image tags, our other issue was resolved by literally changing a <code>div</code> tag to a different tag, one which is less commonly used (in our case, <code>section</code>).</p>
<p>All of the cases happen after Gatsby’s initial static render and exist only when applying some form of delta.</p>
<h2>Let’s Talk GraphQL</h2>
<p>It’s a static website generator. It literally does not need GraphQL all over the place. While there are few instances in the real world where that is valuable, it shouldn’t require a GraphQL API to read objects that are already in memory.</p>
<p>I don’t want to spend the energy to hammer this in, but take a look at Jared Palmer’s <a href="https://jaredpalmer.com/gatsby-vs-nextjs">Gatsby vs. Next.js</a> as it echoes my thoughts.</p>
<p>So, let’s actually not talk about GraphQL, but all its done is create complexity for us.</p>
<h2>Minor Gripes</h2>
<p>There’s a number of other things we’ve found fairly frustrating at this point, but this post is already getting long, so I’m choosing to summarize them.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cra.mr/an-honest-review-of-gatsby/">https://cra.mr/an-honest-review-of-gatsby/</a></em></p>]]>
            </description>
            <link>https://cra.mr/an-honest-review-of-gatsby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670252</guid>
            <pubDate>Sat, 03 Oct 2020 07:18:12 GMT</pubDate>
        </item>
    </channel>
</rss>
