<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 29 Jul 2020 16:17:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 29 Jul 2020 16:17:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[WasmBoxC: Simple, Fast, and VM-Less Sandboxing]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23972929">thread link</a>) | @syrusakbary
<br/>
July 27, 2020 | https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html | <a href="https://web.archive.org/web/*/https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The software ecosystem has a lot of useful but unsafe code, and the easier it is to sandbox that code, the more
often that’ll happen. If it were as simple as passing the compiler a <code>--sandbox</code> flag
that makes an unsafe library unable to see or affect anything
outside of it, that would be incredible! We can’t get it quite that easy,
but this post describes <strong>WasmBoxC</strong>, a sandboxing approach that is
very simple to use. All you need to do is:</p>

<ul>
  <li><strong>Compile the unsafe library using a <a href="https://webassembly.org/">WebAssembly</a> (wasm) compiler instead of the normal system compiler</strong>.
That uses wasm internally, but you don’t need to care about that —
all you see is it emits a C file with sandboxed code.</li>
  <li><strong>Write some C to interface with the compiled C of the unsafe library</strong>. (This is
necessary because the sandboxed code can’t access outside memory, and also it
uses the portable wasm ABI.)</li>
</ul>

<p>Compile and link that C code, and now that unsafe library is sandboxed from the rest of your application!
In a later section we’ll see concrete examples of how easy both those steps are.</p>

<p>Here is the approach in more detail:</p>

<p><img src="https://kripken.github.io/blog/assets/wasmboxc.png" alt="unsafe code => safe wasm => safe c => safe native"></p>

<p>By <strong>compiling to wasm</strong> we sandbox the code, preventing it from accessing
anything on the outside.
That includes both <em>memory</em> - the sandboxed code can’t read or write to anywhere outside it -
and <em>capabilities</em> - the sandboxed code can’t do anything but pure computation,
unless you give it a function to call to do things like read from a file, tell
the time, etc.
We also get the rest of the wasm guarantees on
<a href="https://webassembly.org/docs/security/">safety</a> and
<a href="https://webassembly.org/docs/portability/">portability</a>. Wasm
sandboxing is even safe to run in the same process as other code (at least modulo
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre-type</a>
vulnerabilities), much like
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Software Fault Isolation (SFI)</a>.</p>

<p>After we’ve compiled an unsafe library to wasm, how can we run it as part of our
application?
We could integrate a wasm VM and run the wasm there. But instead,
with WasmBoxC we take a <strong>VM-less</strong> approach and compile the wasm into native
code, while preserving the wasm semantics, including the sandboxing.
That native code can be linked normally into an application, which
is much simpler than integrating a wasm VM.</p>

<p>The specific approach WasmBoxC takes to compile wasm into native code is to
<strong>compile it to C</strong> using
<a href="https://github.com/WebAssembly/wabt">wabt</a>’s
<a href="https://github.com/WebAssembly/wabt/tree/master/wasm2c">wasm2c</a> tool,
and then run a standard C compiler on it. In fact,
WasmBoxC’s approach compiles into a <strong>simple subset of C</strong>.
This is a big part of what makes this approach so simple, and
brings several advantages:</p>

<ul>
  <li>It’s easy to read and verify the generated C for security.</li>
  <li>It lets us use a C compiler like clang or gcc to make the sandboxed
code very fast.</li>
  <li>It’s very easy to use the code in existing build systems.</li>
  <li>It’s easy to write code to interact with the sandbox.</li>
  <li>A single build of C code can be compiled and run on practically any platform,
and code to interact with the sandbox also only needs to be written once.</li>
</ul>

<p>Despite the simplicity of using C, WasmBoxC sandboxing has low
overhead: just <strong>14%</strong> with some non-portable C code (the
“signal handler trick”, see later), or <strong>42%</strong> in 100% portable C
(with no OS- or CPU-specific operations at all). We’ll also see that there are options
in between those 14% and 42% numbers.</p>

<p>The basic idea in WasmBoxC is simple and
<a href="https://twitter.com/FlohOfWoe/status/1011523018428780544">not original</a>.
What is
new in this post is showing that the approach works, doing
benchmarking on real-world code to show it is fast, presenting complete examples of how
easy it is to sandbox real-world libraries, and writing up the approach in
detail to describe the benefits (see in particular the section on memory-safe
languages).
This post also invents a name for the technique.</p>

<h2 id="speed">Speed</h2>

<p>To get an idea of WasmBoxC’s speed, let’s take a look at
<a href="https://github.com/emscripten-core/emscripten/blob/master/tests/test_benchmark.py">20 benchmarks</a>,
comparing clang 9.0.1, clang 11 (dev version as of May 23 2020), gcc 9.2.1, and
WasmBoxC. All numbers are normalized to clang 9 (which is therefore equal to 1; lower numbers are better).</p>

<p><img src="https://kripken.github.io/blog/assets/wasmboxc-perf.png" alt="performance results"></p>

<table>
  <thead>
    <tr>
      <th>compiler</th>
      <th>relative speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>clang 9.0.1</td>
      <td>1.00</td>
    </tr>
    <tr>
      <td>clang 11 (dev)</td>
      <td>0.97</td>
    </tr>
    <tr>
      <td>gcc 9.2.1</td>
      <td>0.93</td>
    </tr>
    <tr>
      <td>WasmBoxC (explicit)</td>
      <td>1.42</td>
    </tr>
    <tr>
      <td>WasmBoxC (OS-based)</td>
      <td>1.14</td>
    </tr>
  </tbody>
</table>

<p>These benchmarks include a wide variety of code, and the ones prefixed with <code>zzz_</code> are real-world
codebases or benchmarks:
the 
<a href="https://box2d.org/">Box2D</a> and
<a href="https://en.wikipedia.org/wiki/Bullet_(software)">Bullet</a>
physics engines, the
<a href="https://en.wikipedia.org/wiki/Coremark">CoreMark</a> and
<a href="https://en.wikipedia.org/wiki/LINPACK_benchmarks">LINPACK</a>
benchmarks, the
<a href="https://www.lua.org/">Lua</a> VM (one GC and one computational benchmark),
the
<a href="https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Markov_chain_algorithm">LZMA</a>
and
<a href="https://zlib.net/">zlib</a>
compression libraries,
and the
<a href="https://www.sqlite.org/index.html">SQLite</a> database.
Incidentally, this shows WasmBoxC can run all of
these today!</p>

<p>Two results are shown for WasmBoxC, representing two implementations of memory sandboxing. The first is <strong>explicit</strong> sandboxing, in which each memory load and store is explicitly verified to be within the sandboxed memory using an explicit check (that is, an <code>if</code> statement is done before each memory access). This has <strong>42%</strong> overhead.</p>

<p>The <strong>OS-based</strong> implementation uses the
“<a href="https://github.com/WebAssembly/wabt/pull/1442/files#diff-e962256d2c336a13791ce03c1dae5d2fR106">signal handler trick</a>” that
<a href="https://hg.mozilla.org/mozilla-central/file/3334d8dff757051c7a359818e0ceb5ad7852fdbc/js/src/wasm/WasmSignalHandlers.cpp">wasm</a>
<a href="https://docs.google.com/document/d/17y4kxuHFrVxAiuCP_FFtFA2HP5sNPsCD10KEx17Hz6M/edit#heading=h.tbi7hpbheoai">VMs</a>
use.
This technique reserves lots of memory around the valid range and relies on
CPU hardware to give us a signal if an access is out of bounds
(for more background see section 3.1.4 in
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Tan, 2017</a>).
That is fully safe and has the benefit of avoiding explicit bounds checks. It has
just <strong>14%</strong> overhead! However, it cannot be used everywhere (it needs
signals and CPU memory protection, and only works on 64-bit systems).</p>

<p>There are more options in between those 14% and 42% figures.
Explicit and OS-based sandboxing preserve wasm semantics perfectly, that is, a trap
will happen exactly when a wasm VM would have trapped. If we are willing to relax
that
(but we may not want to <a href="https://github.com/WebAssembly/wabt/pull/1432">call it wasm</a> if we do)
then we can use masking sandboxing instead
(see section 3.1.3 in
<a href="http://www.cse.psu.edu/~gxt29/papers/sfi-final.pdf">Tan, 2017</a>),
which is 100% portable like explicit sandboxing and also prevents any accesses
outside of the sandbox, and is somewhat faster at <strong>29%</strong> overhead. Other sandboxing
improvements are possible too - almost no effort has gone into this yet.</p>

<p>An interesting thing happens in the <code>lua_binarytrees</code> and <code>havlak</code> benchmarks,
where WasmBoxC is actually faster than both gcc and clang in all sandboxing modes,
up to 32%! How can we beat normal native builds, and by so much?
<a href="https://twitter.com/kripken/status/1262092956070109185">Looking into this</a>,
both of these benchmarks use a lot of <code>malloc</code>s and data structures with pointers.
Like the <a href="https://en.wikipedia.org/wiki/X32_ABI">x32 ABI</a>, wasm is 32-bit,
so pointers take half the space. Measuring the maximum process memory used
in <code>lua_binarytrees</code>, WasmBoxC uses 33% less which helps a lot with CPU cache usage.
While this makes a big difference on these two benchmarks, we are likely
getting some speedup on the others as well due to this factor, as on average x32
is faster than normal x64
<a href="https://en.wikipedia.org/wiki/X32_ABI#Details">by around 5-8%</a>.
Wasm is a nice way to get something
like x32’s benefits!</p>

<p>The benchmarking here measures performance <em>within</em> the sandbox. It
does not measure the speed of calls from the outside in or inside out. Such
calls can be very fast because the sandboxed code is just C, which means that
we can even inline across the sandbox boundary — safely! — if we do
LTO. I verified that happens in the sandboxing example in the next section,
see later. (Note, however, then using the signal handler trick may make things
more complicated here.)</p>

<p>Some final notes on performance:</p>

<ul>
  <li>
    <p>We can compile WasmBoxC’s C code with any native compiler. In the
above we did so always with clang 9 for simplicity. The results vary a little
when changing the compiler, for example the “explicit” sandboxing results go from
14% up to 16% with gcc 9.2 or down to 11% with clang 11. There’s nothing magical about
that 14% figure — we are at the point where native compiler differences matter.</p>
  </li>
  <li>
    <p>Results should improve over time as wasm adds more performance features
like <a href="https://github.com/WebAssembly/simd">simd</a> (note that the native compilers we
compared to may have gained an advantage from autovectorization).</p>
  </li>
  <li>
    <p>That WasmBoxC can reach 14% overhead shows that the
cost of compiling through wasm (which cannot represent irreducible control
flow, for example) is fairly low, and also that current compilers to wasm are
not introducing significant unnecessary overhead.</p>
  </li>
</ul>

<p>I’ve done my best to measure everything here carefully and accurately, but
it’s possible I’ve made a mistake somewhere. Please check my work and see if you
get similar results!</p>

<h2 id="ease-of-use">Ease of use</h2>

<p>This section has a full example of WasmBoxC usage. Here are the source files:</p>

<div><div><pre><code><span>// my-code.c</span>

<span>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>// We could also include the .wasm.h file for these,</span>
<span>// but let's declare externs manually for the example.</span>

<span>extern</span> <span>void</span> <span>wasmbox_init</span><span>(</span><span>void</span><span>);</span>

<span>extern</span> <span>uint32_t</span> <span>(</span><span>*</span><span>Z_twiceZ_ii</span><span>)(</span><span>uint32_t</span><span>);</span>

<span>extern</span> <span>uint32_t</span> <span>(</span><span>*</span><span>Z_do_bad_thingZ_ii</span><span>)(</span><span>uint32_t</span><span>);</span>

<span>int</span> <span>main</span><span>()</span> <span>{</span>
  <span>puts</span><span>(</span><span>"Initializing sandboxed unsafe library"</span><span>);</span>
  <span>wasmbox_init</span><span>();</span>
  <span>printf</span><span>(</span><span>"Calling twice on 21 returns %d</span><span>\n</span><span>"</span><span>,</span> <span>Z_twiceZ_ii</span><span>(</span><span>21</span><span>));</span>
  <span>puts</span><span>(</span><span>"Calling something bad now..."</span><span>);</span>
  <span>Z_do_bad_thingZ_ii</span><span>(</span><span>1</span><span>);</span>
  <span>puts</span><span>(</span><span>"(this will never be printed, as the bad thing will trap)"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p><code>main()</code> is pretty simple: Initialize, call something in the sandbox that does a
computation for us, and call something that will trap inside the sandbox.
(What’s with the <code>Z_</code> stuff? See later in “API”.)</p>

<div><div><pre><code><span>// unsafe-lib.c</span>

<span>#include &lt;stdlib.h&gt;
</span>
<span>__attribute__</span><span>((</span><span>used</span><span>))</span>
<span>int</span> <span>twice</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>{</span>
  <span>return</span> <span>x</span> <span>+</span> <span>x</span><span>;</span>
<span>}</span>

<span>__attribute__</span><span>((</span><span>used</span><span>))</span>
<span>int</span> <span>do_bad_thing</span><span>(</span><span>int</span> <span>size</span><span>)</span> <span>{</span>
  <span>// Allocate an unknown size here (so the LLVM optimizer doesn't know if the</span>
  <span>// store later down is valid or not).</span>
  <span>char</span><span>*</span> <span>x</span> <span>=</span> <span>malloc</span><span>(</span><span>size</span><span>);</span>
  <span>// Write to an address that is definitely not in the sandbox (the default</span>
  <span>// memory size is much smaller), which in wasm will trap.</span>
  <span>x</span><span>[</span><span>1024</span> <span>*</span> <span>1024</span> <span>*</span> <span>1024</span><span>]</span> <span>=</span> <span>42</span><span>;</span>
  <span>// Avoid the optimizer knowing the store can never be observed.</span>
  <span>return</span> <span>(</span><span>int</span><span>)</span><span>x</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><code>twice()</code> does what you’d expect, and <code>do_bad_thing</code> does a store that will
definitely trap. (Ignore the details there; for this example we need the LLVM optimizer not to
remove the bad code as undefined behavior!)</p>

<p>And here’s how easy it is to use WasmBoxC to get a fully sandboxed library linked with our normal code:</p>

<div><div><pre><code><span># build our main code to an object normally</span>
<span>$ </span>clang my-code.c         <span>-c</span> <span>-O3</span> <span>-o</span> my-code.o
<span># build the unsafe library to C with emcc</span>
<span>$ </span>emcc unsafe-lib.c          <span>-O3</span> <span>-o</span> unsafe-lib.wasm <span>-s</span> WASM2C <span>--no-entry</span>
<span># build the unsafe …</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html">https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html</a></em></p>]]>
            </description>
            <link>https://kripken.github.io/blog/wasm/2020/07/27/wasmboxc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23972929</guid>
            <pubDate>Tue, 28 Jul 2020 06:34:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fewer premature babies born since Covid-19 lockdown]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 134 (<a href="https://news.ycombinator.com/item?id=23972152">thread link</a>) | @breitling
<br/>
July 27, 2020 | https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Doctors in countries&nbsp;including Denmark, Ireland, Australia, the U.S. and Canada&nbsp;have been reporting that fewer preterm babies are being born.</p><div><p><span><span><span></span><span>Dr. Belal Alshaikh says COVID-19 has brought a curious development to some maternity wards, and he is trying to help researchers from around the world find out why.<!-- --> <!-- -->4:35</span></span></span></p><p><span><p>Count this one as a positive side-effect of the COVID-19 pandemic.</p>  <p>Doctors in countries&nbsp;including Denmark, Ireland, Australia, the U.S. and Canada&nbsp;have been reporting that fewer preterm babies are being born.</p>  <p>While&nbsp;peer-reviewed studies investigating the drop&nbsp;are pending, and the downward&nbsp;trend across countries is currently anecdotal,&nbsp;Neonatologist Dr. Belal Alshaikh has been studying the possible&nbsp;phenomenon&nbsp;in Calgary.</p>  <p>"It's actually not that common to see this drop down in the numbers in many countries," said Alshaikh, who is&nbsp;also the medical director of the neonatal intensive care unit at the South Health Campus,&nbsp;and&nbsp;has seen the trend right here in Calgary.</p>  <p>Alshaikh told<em> <a href="https://www.cbc.ca/listen/live-radio/1-97-the-homestretch">The Homestretch</a></em> there are two ways to measure preterm birth — gestational age and actual birth weight. And by both measures, the numbers are dramatically lower.</p>  <p>Births considered very premature —&nbsp;born at fewer than 29 to 32 weeks&nbsp;— have&nbsp;dropped by&nbsp;34&nbsp;to 40 per cent, he said.</p>  <p>"If we use their gestational age and if we are talking about the very earliest preemies,"&nbsp;Alshaikh&nbsp;said.</p>  <p>"That's kind of dramatic, actually, and surprising for us."</p>  <p>The numbers are even more dramatic for babies under one kilogram.</p>  <p>"If we used birth weight, those babies born less than one kilo, the number was actually very low and half of what we used to see in the last few years, during the same period of time of the year."</p>    <p>Alshaikh said the trend is very unusual.</p>  <p>"Soon after the lockdown in mid-March, we started to see fewer babies coming to our unit and to intensive care units, and these numbers of preemies were also low in April and mid-May," Alshaikh said.&nbsp;</p>  <p>"So by that time, by late May, we felt like we needed to look at the numbers, and see where we are. And also at that time we started hearing that other hospitals, in Ireland and Denmark, have also noticed the drop down in the number of preemies."</p>  <p>When Calgary doctors took a good look at the numbers and compared them to the same time last year, it was an eyeopener.</p>  <p>"We were surprised," Alshaikh said. "We saw that our number is way lower than what we used to see during this period of time."</p>  <p>There are three main causes that doctors are looking at.</p>  <p>One is social distancing, which may have cut down on the amount of general infection from contact with others.</p>  <p>Another is less air pollution, from fewer cars being on the roads.</p>  <p>"This might actually help because studies in the past showed that air pollution actually increases the risk for preterm birth," Alshaikh said.</p>  <p>And simply not going out to work — resting — may be a final key.</p>  <p>"By staying home, a pregnant woman may have less stress from commuting and from work,&nbsp; and that might have helped them," Alshaikh said, adding it's too soon to know for sure which of these lockdown-related factors have contributed the most.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/premature-babies.jpg 300w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/premature-babies.jpg 460w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/premature-babies.jpg 620w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/premature-babies.jpg 780w,https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/premature-babies.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3068968.1431344120!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/premature-babies.jpg"></p></div><figcaption>Calgary doctors who noticed a reduced number of premature births during the pandemic lockdown, are seeing those numbers rise again as restrictions have eased.<!-- --> <!-- -->(Jim Lynch, Flickr cc)</figcaption></figure></span></p>  <p>&nbsp;"We see sometimes variation during the year, but it's not to the degree that we see fewer babies," Alshaikh said. "And the fact that we see the same trend in Ireland, in Denmark in Australia, it's kind of surprising for everyone working in this field."</p>  <p>Preterm birth comes with a host of challenges for the babies and their parents.</p>  <p>"The risk is high on children and their families, and also medical care resources," Alshaikh said. "For children, the risk increases for vision and hearing problems, and also for learning disability. It's higher even as the gestational age goes down. For example,&nbsp; 24 weeks is at very high risk compared to babies born at 28 weeks gestation or at 32 weeks gestation."</p>  <h2>Doctors teaming up to study</h2>  <p>The Calgary doctors will continue to study the phenomenon, which could hold clues to reducing preterm births in general.</p>  <p>For now, Alshaikh said it's too early to provide any specific advice to pregnant woman — other than to avoid stress, try to rest at home, get a lot of sleep&nbsp;and focus on good nutrition.&nbsp;</p>  <p>"We've teamed up, actually, with the teams across the world, in Ireland and also in Denmark, and there is also a group in Manitoba working on this project, and we are hoping to understand more the ways to prevent the preterm birth, and also like to see if we can understand more on risk factors that are affecting preterm birth," Alshaikh said.&nbsp;</p>  <p>But the Calgary doctor said there is one alarming development already —&nbsp;as the lockdown restriction ease, those preterm birth numbers are already on the rise again.</p>  <p>"We are actually noticing, even in Calgary, that when the restrictions started to be eased, the number of preterm babies coming to our unit and intensive care is going up again, which is quite actually interesting for us," Alshaikh said. "And we are trying to tease out what factors are affecting this trend."</p>  <p><strong>With files from <em><a href="https://www.cbc.ca/listen/live-radio/1-97-the-homestretch">The Homestretch</a></em>.</strong></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/calgary/fewer-premature-preterm-babies-born-during-pandemic-calgary-around-the-world-1.5665089</link>
            <guid isPermaLink="false">hacker-news-small-sites-23972152</guid>
            <pubDate>Tue, 28 Jul 2020 04:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Double-Entry Counting Method (2016)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23971567">thread link</a>) | @dragonsh
<br/>
July 27, 2020 | https://beancount.github.io/docs/the_double_entry_counting_method.html | <a href="https://web.archive.org/web/*/https://beancount.github.io/docs/the_double_entry_counting_method.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>

<p>Martin Blais, December 2016</p>
<p><a href="http://furius.ca/beancount/doc/double-entry"><span>http://furius.ca/beancount/doc/double-entry</span></a></p>
<p><a href="#introduction"><span>Introduction</span></a></p>
<p><a href="#basics-of-double-entry-bookkeeping"><span>Basics of Double-Entry Bookkeeping</span></a></p>
<blockquote>
<p><a href="#statements"><span>Statements</span></a></p>
<p><a href="#single-entry-bookkeeping"><span>Single-Entry Bookkeeping</span></a></p>
<p><a href="#double-entry-bookkeeping"><span>Double-Entry Bookkeeping</span></a></p>
<p><a href="#many-accounts"><span>Many Accounts</span></a></p>
<p><a href="#multiple-postings"><span>Multiple Postings</span></a></p>
</blockquote>
<p><a href="#types-of-accounts"><span>Types of Accounts</span></a></p>
<p><a href="#trial-balance"><span>Trial Balance</span></a></p>
<p><a href="#income-statement"><span>Income Statement</span></a></p>
<p><a href="#clearing-income"><span>Clearing Income</span></a></p>
<p><a href="#equity"><span>Equity</span></a></p>
<p><a href="#balance-sheet"><span>Balance Sheet</span></a></p>
<p><a href="#summarizing"><span>Summarizing</span></a></p>
<p><a href="#period-reporting"><span>Period Reporting</span></a></p>
<p><a href="#chart-of-accounts"><span>Chart of Accounts</span></a></p>
<blockquote>
<p><a href="#country-institution-convention"><span>Country-Institution Convention</span></a></p>
</blockquote>
<p><a href="#credits-debits"><span>Credits &amp; Debits</span></a></p>
<p><a href="#accounting-equations"><span>Accounting Equations</span></a></p>
<p><a href="#plain-text-accounting"><span>Plain-Text Accounting</span></a></p>
<p><a href="#the-table-perspective"><span>The Table Perspective</span></a></p>
<h2 id="introduction">Introduction<a id="introduction"></a><a href="#introduction" title="Permanent link"></a></h2>
<p>This document is a gentle introduction to the double-entry counting method, as written from the perspective of a computer scientist. It is an attempt to explain basic bookkeeping using as simple an approach as possible, doing away with some of the idiosyncrasies normally involved in accounting. It is also representative of how <a href="http://furius.ca/beancount/"><span>Beancount</span></a> works, and it should be useful to all users of <a href="http://plaintextaccounting.org/"><span>plain-text accounting</span></a>.</p>
<p>Note that I am not an accountant, and in the process of writing this document I may have used terminology that is slightly different or unusual to that which is taught in perhaps more traditional training in accounting. I granted myself license to create something new and perhaps even unusual in order to explain those ideas as simply and clearly as possible to someone unfamiliar with them.</p>
<p>I believe that the method of double-entry counting should be taught to everyone at the high school level everywhere as it is a tremendously useful organizational skill, and I hope that this text can help spread its knowledge beyond professional circles.</p>
<h2 id="basics-of-double-entry-bookkeeping">Basics of Double-Entry Bookkeeping<a id="basics-of-double-entry-bookkeeping"></a><a href="#basics-of-double-entry-bookkeeping" title="Permanent link"></a></h2>
<p>The double-entry system is just a simple <em>method of counting</em>, with some simple rules.</p>
<p>Let’s begin by defining the notion of an <strong>account</strong>. An account is something that can contain things, like a bag. It is used to count things, to accumulate things. Let’s draw a horizontal arrow to visually represent the evolving contents of an account over time:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/5b1da6643866c557b2a5ce687e70ee1db16b14de.png"></p>
<p>On the left, we have the past, and to the right, increasing time: the present, the future, etc.</p>
<p>For now, let’s assume that accounts can contain only one kind of thing, for example, <em>dollars</em>. All accounts begin with an empty content of zero dollars. We will call the number of units in the account the <strong>balance</strong> of an account. Note that it represents its contents at a particular point in time. I will draw the balance using a number above the account’s timeline:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/842dcb36da9e0e70c35d1023d65d8a571062baf0.png"></p>
<p>The contents of accounts can change over time. In order to change the content of an account, we have to add something to it. We will call this addition a <strong>posting</strong> to an account, and I will draw this change as a circled number on the account’s timeline, for example, adding $100 to the account:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/5e5e7897a346355eccd4d21ec9485c3464a2d996.png"></p>
<p>Now, we can draw the updated balance of the account after the posting with another little number right after it:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/0c8a78dac61ae7fddde25761f036e7f379cad247.png"></p>
<p>The account’s balance, after adding $100, is now $100.</p>
<p>We can also remove from the contents of an account. For example, we could remove $25, and the resulting account balance is now $75:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/98e314125325ecc72262a73a21b74db3200414fd.png"></p>
<p>Account balances can also become <em>negative</em>, if we remove more dollars than there are in the account. For example, if we remove $200 from this account, the balance now becomes $-125:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/bdc8a23347040de123e3359a7c8f0cc253c6d7d2.png"></p>
<p>It’s perfectly fine for accounts to contain a negative balance number. Remember that all we’re doing is counting things. As we will see shortly, some accounts will remain with a negative balance for most of their timeline.</p>
<h3 id="statements">Statements<a id="statements"></a><a href="#statements" title="Permanent link"></a></h3>
<p>Something worthy of notice is how the timeline notation I’ve written in the previous section is analogous to paper account statements institutions maintain for each client and which you typically receive through the mail:</p>
<table><thead><tr><th><em><strong>Date</strong></em></th><th><em><strong>Description</strong></em></th><th><em><strong>Amount</strong></em></th><th><em><strong>Balance</strong></em></th></tr></thead><tbody><tr><td>2016-10-02</td><td>...</td><td>100.00</td><td>1100.00</td></tr><tr><td>2016-10-05</td><td>...</td><td>-25.00</td><td>1075.00</td></tr><tr><td>2016-10-06</td><td>...</td><td>-200.00</td><td>875.00</td></tr><tr><td><em><strong>Final Balance</strong></em></td><td>875.00</td><td></td><td></td></tr></tbody></table>
<p>Sometimes the amount column is split into two, one showing the positive amounts and the other the negative ones:</p>
<table><thead><tr><th><em><strong>Date</strong></em></th><th><em><strong>Description</strong></em></th><th><em><strong>Debit</strong></em></th><th><em><strong>Credit</strong></em></th><th><em><strong>Balance</strong></em></th></tr></thead><tbody><tr><td>2016-10-02</td><td>...</td><td></td><td>100.00</td><td>1100.00</td></tr><tr><td>2016-10-05</td><td>...</td><td>25.00</td><td></td><td>1075.00</td></tr><tr><td>2016-10-06</td><td>...</td><td>200.00</td><td></td><td>875.00</td></tr><tr><td><em><strong>Final Balance</strong></em></td><td>875.00</td><td></td><td></td><td></td></tr></tbody></table>
<p>Here, “debit” means “removed from your account” and “credit” means “deposited in your account.” Sometimes the words “withdrawals” and “deposits” will be used. It all depends on context: for checking and savings accounts it is usual to have both types of postings, but for a credit card account typically it shows only positive numbers and then the occasional monthly payment so the single column format is used.</p>
<p>In any case, the “balance” column always shows the resulting balance <em>after</em> the amount has been posted to the account. And sometimes the statements are rendered in decreasing order of time.</p>
<h3 id="single-entry-bookkeeping">Single-Entry Bookkeeping<a id="single-entry-bookkeeping"></a><a href="#single-entry-bookkeeping" title="Permanent link"></a></h3>
<p>In this story, this account belongs to someone. We’ll call this person the <strong>owner</strong> of the account. The account can be used to represent a real world account, for example, imagine that we use it to represent the content of the owner’s checking account at a bank. So we’re going to label the account by giving it a name, in this case “Checking”:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/380ec8fea9ee9069411a61ccabcc838de44042ef.png"></p>
<p>Imagine that at some point, this account has a balance of $1000, like I’ve drawn on the picture. Now, if the owner spends $79 of this account, we would represent it like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b24d8c1e40edf6fd7e9d768ba8f0df279cd41f0e.png"></p>
<p>Furthermore, if the expense was for a meal at a restaurant, we could flag the posting with a <strong>category</strong> to indicate what the change was used for. Let’s say, “Restaurant”, like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/7ee843cd9b997a9447bb022d7d35121a820e296d.png"></p>
<p>Now, if we have a lot of these, we could write a computer program to accumulate all the changes for each category and calculate the sums for each of them. That would tell us how much we spent in restaurants in total, for example. This is called the <strong>single-entry method</strong> of accounting.</p>
<p>But we’re not going to do it this way; we have a better way. Bear with me for a few more sections.</p>
<h3 id="double-entry-bookkeeping">Double-Entry Bookkeeping<a id="double-entry-bookkeeping"></a><a href="#double-entry-bookkeeping" title="Permanent link"></a></h3>
<p>An owner may have multiple accounts. I will represent this by drawing many similar account timelines on the same graphic. As before, these are labeled with unique names. Let’s assume that the owner has the same “Checking” account as previously, but now also a <strong>“</strong>Restaurant<strong>”</strong> account as well, which can be used to accumulate all food expenses at restaurants. It looks like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/3c380375442a643877c59660832bd7df6192e9cb.png"></p>
<p>Now, instead of <em>categorizing</em> the posting to a “restaurant category” as we did previously, we could create a matching posting on the “Restaurant” account to record how much we spent for food, with the amount spent ($79):</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b86a7242b92effc613f88bc0cc70381d72e774f0.png"></p>
<p>The “Restaurant” account, like all other accounts, also has an accumulated balance, so we can find out how much we spent in “Restaurant” in total. This is entirely symmetrical to counting changes in a checking account.</p>
<p>Now, we can associate the two postings together, by creating a kind of “parent” box that refers to both of them. We will call this object a <strong>transaction</strong>:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b77efafcf2d6a6f1afbfb13da70be2f892b339b4.png"></p>
<p>Notice here that we’ve also associated a description to this transaction: “Dinner at Uncle Boons”. A transaction also has a <strong>date</strong>, and all of its postings are recorded to occur on that date. We call this the transaction date.</p>
<p>We can now introduce the fundamental rule of double-entry bookkeeping system:</p>
<pre><code>The sum of all the postings of a transaction must equal zero.
</code></pre>
<p>Remember this, as this is the foundation of the double-entry method, and its most important characteristic. It has important consequences which I will discuss later in this document.</p>
<p>In our example, we remove $79 from the “Checking” account and “give it” to the “Restaurant” account. ($79) + ($-79) = $0. To emphasize this, I could draw a little summation line under the postings of the transaction, like this:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/b4182b9f64113868123cbcec20d468ab18b2786f.png"></p>
<h3 id="many-accounts">Many Accounts<a id="many-accounts"></a><a href="#many-accounts" title="Permanent link"></a></h3>
<p>There may be many such transactions, over many different accounts. For example, if the owner of the accounts had a lunch the next day which she paid using a credit card, it could be represented by creating a “Credit Card” account dedicated to tracking the real world credit card balance, and with a corresponding transaction:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/f85a66510ce2e3bb614edca76463a9c4752a7d26.png"></p>
<p>In this example, the owner spent $35 at a restaurant called “Eataly.” The previous balance of the owner’s credit card was $-450; after the expense, the new balance is $-485.</p>
<p>For each real world account, the owner can create a bookkeeping account like we did. Also, for each category of expenditure, the owner also creates a bookkeeping account. In this system, there are no limits to how many accounts can be created.</p>
<p>Note that the balance in the example is a negative number; this is not an error. Balances for credit card accounts are normally negative: they represent an amount <em>you owe</em>, that the bank is lending you <em>on credit</em>. When your credit card company keeps track of your expenses, they write out your statement from their perspective, as positive numbers. For you, those are amounts you need to eventually pay. But here, in our accounting system, we’re representing numbers from the owner’s point-of-view, and from her perspective, this is money she owes, not something she has. What we have is a meal sitting in our stomach (a positive number of $ of “Restaurant”).</p>
<h3 id="multiple-postings">Multiple Postings<a id="multiple-postings"></a><a href="#multiple-postings" title="Permanent link"></a></h3>
<p>Finally, transactions may have more than two postings; in fact, they may have any number of postings. The only thing that matters is that the sum of their amounts is zero (from the rule of double-entry bookkeeping above).</p>
<p>For example, let’s look at what would happen if the owner gets her salary paid for December:</p>
<p><img src="https://beancount.github.io/docs/the_double_entry_counting_method/media/18980f41275676c5c7cf3b39dd256512bb45b78b.png"></p>
<p>Her gross salary received in this example is recorded as $-2,905 (I’ll explain the sign in a moment). $905 is set aside for taxes. Her “net” salary of $2,000, the remainder, is deposited in her “Checking” account and the resulting balance of that account is $2,921 (the previous balance of $921 + $2,000 = $2,921). This transaction has three postings: (+2,000) + (-2,905) + (+905) = 0. The double-entry rule is respected.</p>
<p>Now, you may ask: Why is her salary recorded as a negative number? The reasoning here is similar to that of the credit card above, though perhaps a bit more subtle. These accounts exist to track all the amounts from the owner’s point-of-view. The owner gives out work, and receives money and taxes in exchange for it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beancount.github.io/docs/the_double_entry_counting_method.html">https://beancount.github.io/docs/the_double_entry_counting_method.html</a></em></p>]]>
            </description>
            <link>https://beancount.github.io/docs/the_double_entry_counting_method.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23971567</guid>
            <pubDate>Tue, 28 Jul 2020 01:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Did the Casio F91W Become a Terrorist Icon?]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 74 (<a href="https://news.ycombinator.com/item?id=23971045">thread link</a>) | @joeschmoe83
<br/>
July 27, 2020 | https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/ | <a href="https://web.archive.org/web/*/https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>The humble Casio F91W has been an iconic watch since it was first made in Japan back in 1989. Upon its release, it was sold for around $20 making it one of the world’s first affordable digital watches. Today, Casio still produces over 3 million of the F91W every year. The prevalence of this iconic timepiece through the years means it’s likely you’ve worn one at some point. If you have, then it’s probably the only thing you have in common with Osama bin Laden, Chechen militants, and Napoleon Dynamite. Congratulations!</p>



<p>As a kid in school, I personally remember being told off for talking in the back of the class. I had been caught excitedly telling my friends that I had just figured out what kind of watch the most wanted man on earth, Osama bin Laden, wears. As punishment, I was called up to answer the maths question on the board, at which I failed miserably. <em>”You need to focus on what matters! You can’t solve maths problems but you can tell everyone about the watches worn by terrorists?”</em> screamed my teacher. <a href="https://reaperfeed.com/about-reaper-feed/">Looking back</a>, I feel I prioritized the right kind of knowledge.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?w=696&amp;ssl=1" alt="Inventor of the Casio FW91" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?w=860&amp;ssl=1 860w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=300%2C228&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=768%2C584&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=696%2C529&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=552%2C420&amp;ssl=1 552w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Casio-G-Shock-Designer-Moriai-aBlogtoWatch-67.jpg?resize=80%2C60&amp;ssl=1 80w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Inventor of the Casio F91W, Ryusuke Moriai, polishes a Samurai sword in Tokyo. Photo from <a href="https://www.ablogtowatch.com/tokyo-man-designs-casio-g-shock-watches-ryusuke-moriai/">A Blog to Watch.</a></figcaption></figure>



<p>The Casio F91W was designed by Ryusuke Moriai which he described as “small, flat and simple”. The watch features a seven-segment numerical display on a grey LCD screen. Water-resistant, extremely durable and accurate to within 30 seconds a month, it’s a tried and tested piece of kit.</p>



<hr>



<figure><a href="https://www.amazon.com/Military-Grade-Travel-Guide-Dangerous-ebook/dp/B086JBW97K"><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=696%2C392&amp;ssl=1" alt="" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=2048%2C1152&amp;ssl=1 2048w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=696%2C392&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1068%2C601&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=1920%2C1080&amp;ssl=1 1920w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?resize=747%2C420&amp;ssl=1 747w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/06/Corporate-Work-Blog-Banner-2.png?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></a></figure>



<hr>



<p>If there’s one thing that’s to be said for international terrorists, they know a thing or two about choosing reliable products for waging war. The F-91W joined the ranks of other terrorist accessories like the Kalashnikov and the Toyota technical because it’s cheap, solid, and reliable. Oh, and it also doubles as a bombmaking accessory which we’ll look into later.</p>



<h3><strong><em>A Terrorist Fashion Icon</em></strong></h3>



<p>Whilst Casio has advanced further into combat watches through its iconic Casio G-Shock range, the F91W has remained the true battlefield accessory throughout modern warfare. Aside from iconic weapons, the Casio F-91W is the only branded accessory that Osama bin Laden was ever seen wearing in the open. Al-Qaeda was reported to <a href="https://wikileaks.org/gitmo/prisoner/720.html">hand the watches out to recruits</a> at their terror training camps across Afghanistan and Pakistan throughout the 1990s and early 2000s. Thus, it was al-Qaeda and bin Laden who arguably started the terrorist trend surrounding the watch.</p>



<div><figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?w=696&amp;ssl=1" alt="Osama Bin Laden wearing Casio FW91" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?w=371&amp;ssl=1 371w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?resize=239%2C300&amp;ssl=1 239w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/obl_AP070817055372-1.jpg?resize=335%2C420&amp;ssl=1 335w" sizes="(max-width: 371px) 100vw, 371px" data-recalc-dims="1"><figcaption>Osama bin Laden wearing the iconic F-91W.</figcaption></figure></div>



<p>During the height of the War on Terror, it didn’t take long for the US government to spot the prevalence of the Casio F91W amongst terrorists. In 2011, Wikileaks released a document labeled the “Matrix of Threat Indicators for Enemy Combatants” which was intended to assist staff at Guantanamo decide which detainees are more likely to carry out suicide attacks. According to the document, owning an F-91W was the biggest giveaway of a serious terror suspect alongside ownership of a satellite phone, a radio transceiver, or large quantities of cash.</p>



<p>However, this wasn’t just paranoia. Statistics in other similar documents released by Wikileaks revealed that around a third of inmates being held at Guantanamo that were captured whilst wearing an F-91W had a known correlation with explosives. The F-91W watch came up almost 150 times in the piles of leaked <a href="https://wikileaks.org/gitmo/pdf/ym/us9ym-000840dp.pdf">Guantanamo prisoner assessments</a>. Ironically, four of the chaplains who worked at Guantanimo Bay also wore the watch.</p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?fit=696%2C348&amp;ssl=1" alt="Casio FW91 Guantanamo Bay" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?w=1100&amp;ssl=1 1100w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=1024%2C512&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=768%2C384&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=696%2C348&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=1068%2C534&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/5cc7041ab14bf43772045166.jpg?resize=840%2C420&amp;ssl=1 840w" sizes="(max-width: 696px) 100vw, 696px"></figure>



<p>One of the detainees at Guantanamo was grilled over the prevalence of the watch amongst suspected terrorists. He claimed that the water-resistant feature of the F91W watch was handy due to the Islamic requirement for followers to wash up to their elbows before prayers. Innocent enough explanation, right? Well not really. Interrogators smelled a rat when another prisoner claimed the prevalence of the watch amongst Jihadi inmates was simply due to the built-in compass that helped them pray towards Mecca. However, there is no compass in the F91W.</p>



<p>Despite the fairly frosty relationship between the two, ISIS didn’t let it get in between their choice of a good wristwatch. The F-91W was a feature of various ISIS militants including Tunisian born Tariq al-Harzi who was a high ranking Emir of the Islamic State. It was also worn by Kevin Chassin who was a French-born Jihadist who went to Syria to join ISIS. He was subsequently utilized for his high propaganda value in ISIS videos. </p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=696%2C364&amp;ssl=1" alt="Casio F91W." srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=300%2C157&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=768%2C402&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=696%2C364&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=1068%2C559&amp;ssl=1 1068w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?resize=803%2C420&amp;ssl=1 803w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-3.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></figure>



<p>However, the leader of ISIS Abu Bakr al-Baghdadi wasn’t so fond of the cheap Casio F91W. Instead, al-Baghdadi opted for a flashy watch that sparked debate over the exact model. The watch was spotted during his infamous speech in Mosul that declared the formation of the so-called Caliphate. It was believed to be either a Rolex or an Omega Seamaster, both of which run north of $3,000 and contradict the contents of his speech as well as his ideals.</p>



<p>It’s not just Jihadist terrorist groups that wear the watch. Introducing Subcomandante Marcos who, until recently, led the Zapatista National Liberation Army (EZLN) in Mexico. The photogenic insurgent leader was pictured in an iconic photo on horseback while smoking a pipe and wearing, you guessed it! </p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?fit=696%2C364&amp;ssl=1" alt="subcomandante Marcos Casio FW91" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=300%2C157&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=768%2C402&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=696%2C364&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=1068%2C559&amp;ssl=1 1068w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/Untitled-design-6.jpg?resize=803%2C420&amp;ssl=1 803w" sizes="(max-width: 696px) 100vw, 696px"><figcaption>Subcomandante Marcos wearing the Casio F91W</figcaption></figure>



<p>Of course, the watch is not only appreciated by the terrorists of the world but likewise by the people who combat them. Various fighting forces across the Middle East have been seen using the watch. Such as the Syrian Democratic Forces which is a coalition waging an anti-ISIS campaign across war-torn Syria.</p>



<h3><em><strong> How the Casio F91W Became a Bomb Makers Accessory</strong></em></h3>



<p>The Casio F91W is not only the terrorist’s timepiece of choice due to its ruggedness and reliability. Due to its long-lead timer, it also doubles as a bomb-making accessory for various terror groups around the world from Afghanistan to Chechnya. Deadly usage of the watch has been well documented through various case studies.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=696%2C500&amp;ssl=1" alt="Casio FW91" width="696" height="500" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?w=600&amp;ssl=1 600w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=300%2C216&amp;ssl=1 300w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/photo-casio-f91w-is-a-favourite-of-cia-s-terrorist-arm-al-qaeeda-supposedly.jpg?resize=585%2C420&amp;ssl=1 585w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"></figure>



<p>According to US intelligence officials, the watch doubles as a bomb timer as its alarm can be set beyond a 24-hour period. During the War on Terror, Pakistani ISI officials found more than 600 of the watches in a terrorist safe house in Karachi which led to a period of anybody being found wearing an F91W watch to be liable for arrest and questioning. However, with the watch being available for $4 dollars on Pakistani markets, simply possessing a Casio watch doesn’t prove anything and this tactic of arrest was soon dropped.</p>



<p>In September 1999, a series of bombs were detonated inside four Russian apartment buildings in the cities of Moscow, Volgodonsk, and Buinaksk. The blasts killed 367 people and injured over 1,000 others. Russian investigators concluded that the attackers had been trained in terror camps being run by Ibn al-Khattab inside Chechnya which had recently gained unstable independence following the First Chechen War.</p>



<figure><img src="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?w=696&amp;ssl=1" alt="Casio F91W" srcset="https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?w=800&amp;ssl=1 800w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=300%2C195&amp;ssl=1 300w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=768%2C498&amp;ssl=1 768w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=696%2C452&amp;ssl=1 696w, https://i1.wp.com/reaperfeed.com/wp-content/uploads/2020/07/ap_99090902501_custom-0dbb7e58420fd5260bf942910bfb61bd5c7c782f-s800-c85.jpg?resize=647%2C420&amp;ssl=1 647w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1"><figcaption>Fire and smoke rise from a destroyed apartment building as Russian firefighters try to save people in Moscow on Sept. 9, 1999.&nbsp;</figcaption></figure>



<p>Investigations carried out inside Chechnya discovered that the bombs used in the attacks were comprised of ammonium nitrate and aluminum powder, with plastic serving as an intermediate explosive. The detonator? A combination of a Krona battery and a Casio F-91W. </p>



<blockquote><p>“about a third of inmates at JTF-GTMO [the unit in charge of Guantanamo] who were captured wearing one of these watches had a known correlation with explosives”.</p><cite>– Prisoner evaluation sheet from Guantanamo.</cite></blockquote>



<p>In 1994, an al-Qaeda militant named Ramzi Yousef used the Casio F-91W as a 4-hour timer on the bomb he constructed in an airplane toilet of Philippine Airlines Flight 434. He proceeded to leave his deadly work under the seat before leaving the plane. It detonated on the next flight, killing a Japanese businessman named Haruki Ikegami who sat in Yousef’s seat. Thankfully, the bomb’s orientation caused the energy to be mostly absorbed by Ikegami. Thus other passengers and the plane were not catastrophically damaged.</p>



<p>So, to round off this article I feel it’s fitting to make a comparison between Ryusuke Moriai and Mikhail Kalashnikov. Just like when Kalashnikov designed the AK47 intended solely for the defense of his motherland, the innovative inventor Ryusuke Moriai could never have predicted that his creation would go on an unstoppable path of its own and be used for far more sinister purposes than ever intended. Mr. Moriai had unwittingly created a watch ideal for modern warfare.</p>



<figure><img src="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?fit=696%2C923&amp;ssl=1" alt="Casio F91W" srcset="https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=226%2C300&amp;ssl=1 226w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=772%2C1024&amp;ssl=1 772w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=768%2C1018&amp;ssl=1 768w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=1159%2C1536&amp;ssl=1 1159w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=696%2C923&amp;ssl=1 696w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=1068%2C1416&amp;ssl=1 1068w, https://i2.wp.com/reaperfeed.com/wp-content/uploads/2020/07/e5d2ebf24cf0e901f0be47c23482b2e8_0.jpg?resize=317%2C420&amp;ssl=1 317w" sizes="(max-width: 696px) 100vw, 696px"></figure>



<p>I was hoping to find a profound statement from Casio on the watch being used for deadly means by some pretty evil people. I was looking for something similar to what Kalashnikov said about the violent impact of his life’s work. <a href="https://www.theguardian.com/artanddesign/2011/apr/28/casio-f-91w-watch-design-hipsters-al-qaida">The Guardian</a> approached the PR department for Casio hoping for a similar statement on the widespread use of the F-91W amongst global terrorists. But they just received a blunt email stating: “Casio is not making any further comment on the F-91W watch at this point in time.” Damn.</p>



<p>For more stories like this as well as photography from the more bizarre sides of human conflict, you can stay up to speed with us on <a href="https://www.instagram.com/reaperfeed1/">Instagram</a> and <a href="https://twitter.com/Reaperfeed1">Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23971045</guid>
            <pubDate>Tue, 28 Jul 2020 00:40:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How GPT3 Works – Visualizations and Animations]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 85 (<a href="https://news.ycombinator.com/item?id=23967887">thread link</a>) | @dsr12
<br/>
July 27, 2020 | https://jalammar.github.io/how-gpt3-works-visualizations-animations/ | <a href="https://web.archive.org/web/*/https://jalammar.github.io/how-gpt3-works-visualizations-animations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>(Live thread, will be updated with new visuals and polish over the next few days. Join <a href="http://eepurl.com/gl0BHL">the mailing list</a> to get updated when completed)</p>

<p>A trained language model generates text.</p>

<p>We can optionally pass it some text as input, which influences its output.</p>

<p>The output is generated from what the model “learned” during its training period where it scanned vast amounts of text.</p>

<p><img src="https://jalammar.github.io/images/gpt3/01-gpt3-language-model-overview.gif">
  <br>

</p>

<!--more-->

<p>Training is the process of exposing the model to lots of text. That process has been completed. All the experiments you see now are from that one trained model. It was estimated to cost 355 GPU years and cost $4.6m.</p>

<p><img src="https://jalammar.github.io/images/gpt3/02-gpt3-training-language-model.gif">
  <br>

</p>

<p>The dataset of 300 billion tokens of text is used to generate training examples for the model. For example, these are three training examples generated from the one sentence at the top.</p>

<p>You can see how you can slide a window across all the text and make lots of examples.</p>

<p><img src="https://jalammar.github.io/images/gpt3/gpt3-training-examples-sliding-window.png">
  <br>

</p>

<p>The model is presented with an example. We only show it the features and ask it to predict the next word.</p>

<p>The model’s prediction will be wrong. We calculate the error in its prediction and update the model so next time it makes a better prediction.</p>

<p>Repeat millions of times</p>

<p><img src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif">
  <br>

</p>

<p>Now let’s look at these same steps with a bit more detail.</p>

<p>GPT3 actually generates output one token at a time (let’s assume a token is a word for now).</p>

<p><img src="https://jalammar.github.io/images/gpt3/04-gpt3-generate-tokens-output.gif">
  <br>

</p>

<p>Please note: This is a description of how GPT-3 works and not a discussion of what is novel about it (which is mainly the ridiculously large scale). The architecture is a transformer decoder model based on this paper https://arxiv.org/pdf/1801.10198.pdf</p>

<p>GPT3 is MASSIVE. It encodes what it learns from training in 175 billion numbers (called parameters). These numbers are used to calculate which token to generate at each run.</p>

<p>The untrained model starts with random parameters. Training finds values that lead to better predictions.</p>

<p><img src="https://jalammar.github.io/images/gpt3/gpt3-parameters-weights.png">
  <br>

</p>

<p>These numbers are part of hundreds of matrices inside the model. Prediction is mostly a lot of matrix multiplication.</p>

<p>In my <a href="https://youtube.com/watch?v=mSTCzNgDJy4">Intro to AI on YouTube</a>, I showed a simple ML model with one parameter. A good start to unpack this 175B monstrosity.</p>

<p>To shed light on how these parameters are distributed and used, we’ll need to open the model and look inside.</p>

<p>GPT3 is 2048 tokens wide. That is its “context window”. That means it has 2048 tracks along which tokens are processed.</p>

<p><img src="https://jalammar.github.io/images/gpt3/05-gpt3-generate-output-context-window.gif">
  <br>

</p>

<p>Let’s follow the purple track. How does a system process the word “robotics” and produce “A”?</p>

<p>High-level steps:</p>

<ol>
  <li>Convert the word to <a href="https://jalammar.github.io/illustrated-word2vec/">a vector (list of numbers) representing the word</a></li>
  <li>Compute prediction</li>
  <li>Convert resulting vector to word</li>
</ol>

<p><img src="https://jalammar.github.io/images/gpt3/06-gpt3-embedding.gif">
  <br>

</p>

<p>The important calculations of the GPT3 occur inside its stack of 96 transformer decoder layers.</p>

<p>See all these layers? This is the “depth” in “deep learning”.</p>

<p>Each of these layers has its own 1.8B parameter to make its calculations. That is where the “magic” happens. This is a high-level view of that process:</p>

<p><img src="https://jalammar.github.io/images/gpt3/07-gpt3-processing-transformer-blocks.gif">
  <br>

</p>

<p>You can see a detailed explanation of everything inside the decoder in my blog post <a href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT2</a>.</p>

<p>The difference with GPT3 is the alternating dense and <a href="https://arxiv.org/pdf/1904.10509.pdf">sparse self-attention layers</a>.</p>

<p>This is an X-ray of an input and response (“Okay human”) within GPT3. Notice how every token flows through the entire layer stack. We don’t care about the output of the first words. When the input is done, we start caring about the output. We feed every word back into the model.</p>

<p><img src="https://jalammar.github.io/images/gpt3/08-gpt3-tokens-transformer-blocks.gif">
  <br>

</p>

<p>In the React code generation example (https://twitter.com/sharifshameem/status/1284421499915403264), the description would be the input prompt (in green), in addition to a couple of examples of description=&gt;code, I believe. And the react code would be generated like the pink tokens here token after token.</p>

<p>My assumption is that the priming examples and the description are appended as input, with specific tokens separating examples and the results. Then fed into the model.</p>

<p><img src="https://jalammar.github.io/images/gpt3/09-gpt3-generating-react-code-example.gif">
  <br>

</p>

<p>It’s impressive that this works like this. Because you just wait until fine-tuning is rolled out for the GPT3. The possibilities will be even more amazing.</p>

<p>Fine-tuning actually updates the model’s weights to make the model better at a certain task.</p>

<p><img src="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif">
  <br>

</p>

  </div></div>]]>
            </description>
            <link>https://jalammar.github.io/how-gpt3-works-visualizations-animations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967887</guid>
            <pubDate>Mon, 27 Jul 2020 18:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quiet route planning for pedestrians in traffic noise polluted environments]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 122 (<a href="https://news.ycombinator.com/item?id=23967306">thread link</a>) | @ericdanielski
<br/>
July 27, 2020 | http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/ | <a href="https://web.archive.org/web/*/http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>#Noise #pollution is one of the main stressors in urban environments, having negative impacts on people’s quality of life and health. For some groups of citizens, such as school children, patients, and elders, there is a need to support them in finding pedestrian routes in noise polluted areas of cities. In<a href="https://ieeexplore.ieee.org/document/9139350" target="_blank"> a new paper</a>, <a href="http://uni-heidelberg.de/gis" target="_blank">we</a> focus on the <strong>estimation of traffic noise</strong>, and present an approach to <strong>provide quiet routing services</strong>, <em>taking into account the estimated noise levels of roads</em>.</p>
<p>By combining Volunteered Geographic Information from OpenStreetMap (OSM), official socio-economic data, and open-access GPS trajectory data, we develop a set of traffic related variables, and apply machine learning methods to perform<strong> traffic volume estimations</strong>. Given the estimated traffic information, an existing traffic noise model is then employed to derive the noise polluted areas. For generation of quiet routes, a new routing algorithm is proposed. It minimizes the exposure of pedestrians to traffic noise pollution while taking into account the route distance constraint. We apply our quiet routing approach to the city of Heidelberg (Germany). The application results demonstrate the efficacy of our algorithms in the generation of quiet routes customized to pedestrian preferences.</p>
<blockquote><p>Z. Wang, T. Novack, Y. Yan and A. Zipf, “<a href="https://ieeexplore.ieee.org/document/9139350" target="_blank">Quiet Route Planning for Pedestrians in Traffic Noise Polluted Environments</a>,” in IEEE Transactions on Intelligent Transportation Systems, doi: 10.1109/TITS.2020.3004660.</p></blockquote>
<p><a href="http://k1z.blog.uni-heidelberg.de/files/2020/07/noiseroutehdgisciencehd.jpg"><img src="http://k1z.blog.uni-heidelberg.de/files/2020/07/noiseroutehdgisciencehd-300x221.jpg" alt="" width="300" height="221"></a></p>
<p>In earlier work we looked already into generating customized pleasant pedestrian routes based on several factors like greenness, noise and sociability, and added this to <a href="https://openrouteservice.org/" target="_blank">Openrouteservice</a> by <a href="http://heigit.org/" target="_blank">HeiGIT</a> &amp; <a href="http://uni-heidelberg.de/gis" target="_blank">GIScience HD</a>:</p>
<blockquote><p><span>Novack, T.; Wang, Z.; Zipf, A. (2018):&nbsp;<a href="https://www.mdpi.com/1424-8220/18/11/3794" target="_blank">A System for Generating Customized Pleasant Pedestrian Routes Based on OpenStreetMap Data</a>. </span><em>Sensors</em><span> </span><span>2018</span><span>, </span><em>18</em><span>, 3794.</span></p></blockquote>
<p>Also currently we started to <a href="http://k1z.blog.uni-heidelberg.de/2020/06/19/going-green-with-meingrun-today-app-launch-in-heidelberg-and-dresden/">test related approaches in Dresden and Heidelberg</a> in the context of the <a href="https://www.geog.uni-heidelberg.de/gis/meingruen_en.html" target="_blank">meinGrün</a> project.<br>
This builds upon early work by <a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/arcviewbuch-zipf-roether.pdf" target="_blank">Zipf and Röther (2000)</a>, But nowadays the needed data sources are much more available, so that it becomes possible to scale these ideas to new levels using open data which allow to finetune and evaluate the approach using real world data.</p>
<p>The relevance of green spaces for wellbeing and mental health in cities has been proofed by a study published in <a href="https://www.nature.com/articles/s41593-019-0451-y" target="_blank">Nature Neuroscience</a></p>
<blockquote><p><span>H. Tost, M. Reichert, U. Braun, I. Reinhard, R. Peters, S. Lautenbach, A. Hoell, E. Schwarz, U. Ebner-Priemer, A. Zipf, and A. Meyer-Lindenberg (2019): </span><a href="https://www.nature.com/articles/s41593-019-0451-y" target="_blank">Neural correlates of individual differences in affective benefits of real-life urban green space exposure.</a><span> Nature Neuroscience. https://doi.org/10.1038/s41593-019-0451-y</span></p></blockquote>
<blockquote><p><span>Zipf, A. &amp; Röther, S. (2000): </span><a title="im neuen Fenster öffnen" href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/arcviewbuch-zipf-roether.pdf" target="_blank">Tourenvorschläge für Stadttouristen mit dem ArcView Network Analyst.</a><span> In: Liebig, W. (Hrsg.): ArcView Arbeitsbuch. Hüthig Verlag. Heidelberg.</span></p></blockquote>
<p>Other early examples on using OpenStreetMap for specialized routing and navigation applications for large areas or specific scenarios (e.g. disaster management, wheelchairs etc.) are given below:</p>
<blockquote><p>Neis, P. &amp; Zipf, A (2008): <a href="https://openrouteservice.org/" target="_blank">OpenRouteService.org</a> is three times “Open”: Combining OpenSource, OpenLS and OpenStreetMap. GIS Research UK (GISRUK 08). Manchester.</p>
<p><span>Schmitz, S., Neis, P. &amp; Zipf, A. (2008): </span><a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/cmap2008.cartography-bonn.subm.pdf" target="_blank">New Applications based on Collaborative Geodata – the Case of Routing.</a><span> XXVIII INCA International Congress on Collaborative Mapping and SpaceTechnology, Gandhinagar, Gujarat, India.</span></p>
<p><span>Rousell A. and Zipf A. (2017): </span><a href="http://www.mdpi.com/2220-9964/6/3/64" target="_blank">Towards a landmark based pedestrian navigation service using OSM data.</a><span> International Journal of Geo-Information, ISPRS IJGI, 6(3): 64.</span></p>
<p><span>Neis, P., Singler, P. &amp; Zipf, A. (2010): </span><a href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/un-osm-emergency-routing.gi-forum2010.full.pdf">Collaborative mapping and Emergency Routing for Disaster Logistics – Case studies from the Haiti earthquake and the UN portal for Afrika.</a><span> In: Car, A., Griesebner, G. &amp; Strobl, J. (Eds.): Geospatial Crossroads @ GI_Forum ‘10. Proceedings of the Geoinformatics Forum Salzburg.</span></p>
<p><span>Zipf, A., Mobasheri, A., Rousell, A. ,Hahmann, S. (2016): </span><a title="im neuen Fenster öffnen" href="https://www.geog.uni-heidelberg.de/md/chemgeo/geog/gis/europ_handb_crowds_infozipf.pdf">Crowdsourcing for individual needs - the case of routing and navigation for mobility-impaired persons </a><span>. In: Capineri, C, Haklay, M, Huang, H, Antoniou, V, Kettunen, J, Ostermann, F and Purves, R. (eds.) European Handbook of Crowdsourced Geographic Information, p. 325–337. London: Ubiquity Press. DOI: dx.doi.org/10.5334/bax.x</span></p>
<p><span>Miksch, J., Hahmann, S., Resch, B., Lauer, J., Zipf, A. (2017): </span><a title="im neuen Fenster öffnen" href="http://www.tandfonline.com/doi/full/10.1080/10095020.2017.1399675">Routing Through Open Spaces - A Performance Comparison Of Algorithms. </a><span>Geo-Spatial information Science, 2017. Taylor &amp; Francis. Geo-Spatial information Science, 2017. Taylor &amp; Francis. https://doi.org/10.1080/10095020.2017.1399675</span></p></blockquote>
										<p>
            Tags: <a href="http://k1z.blog.uni-heidelberg.de/tag/meingrun/" rel="tag">meinGrün</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/noise/" rel="tag">noise</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/openrouteservice/" rel="tag">OpenRouteService</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/osm/" rel="tag">OSM</a>, <a href="http://k1z.blog.uni-heidelberg.de/tag/routing/" rel="tag">routing</a><br> </p>
				</div></div>]]>
            </description>
            <link>http://k1z.blog.uni-heidelberg.de/2020/07/15/quiet-route-planning-for-pedestrians-in-traffic-noise-polluted-environments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967306</guid>
            <pubDate>Mon, 27 Jul 2020 17:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a file system from scratch in Rust]]>
            </title>
            <description>
<![CDATA[
Score 318 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23967016">thread link</a>) | @carlosgaldino
<br/>
July 27, 2020 | https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html | <a href="https://web.archive.org/web/*/https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>27 Jul 2020</span></p><p>Data produced by programs need to be stored somewhere for future reference, and
there must be some sort of organisation so we can quickly retrieve the desired
information. A file system (FS) is responsible for this task and provides an
abstraction over the storage devices where the data is physically stored.</p>

<p>In this post, we will learn more about the concepts used by file systems, and
how they fit together when writing your own.</p>

<h2 id="structuring-the-disk">Structuring the disk</h2>
<p>When data is stored in a hard-disk drive (HDD) or solid-state drive (SSD), it is
written in small units called sectors (or pages in the SSD case). The drives
don’t have any information about what that piece of data represents, for all it
is worth, the disk is just a giant array of sectors. It is the job of the file
system to make sense of it all.</p>

<p>A file system will divide the disk into fixed-sized blocks. The FS uses the
majority of these blocks to store user data, but some blocks are used to store
metadata that is essential for the file system operation.</p>

<p>The following figure gives an example of how a file system structures the
information on the disk:</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_filesystem_blocks.svg" alt="">
    <figcaption>File system structure in a disk</figcaption>
</figure>

<p>In the next sections, we will understand what each type of block means.</p>

<h3 id="superblock-and-bitmaps">Superblock and bitmaps</h3>

<p>The superblock stores most of the metadata about the file system, such as the
following: block size, timestamps, how many blocks and files are in use and how
many are free, etc.</p>

<p>Bitmaps are one way of tracking which data blocks and inodes are free. An index
in the bitmap set to <code>0</code> indicates a free slot, and an index set to <code>1</code>
indicates an occupied slot.</p>

<h3 id="inode">Inode</h3>

<p>The inode is the structure that stores metadata about a file. Attributes such as
permissions, size, location of data blocks that form the file and more are saved
in an inode.</p>

<p>The inodes are stored in blocks that together form the <em>inode table</em> as the
following figure shows.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_inode_table.svg" alt="">
    <figcaption>Inode table (detailed view)</figcaption>
</figure>

<p>For each slot in the inode bitmap set to <code>1</code>, there will be a corresponding
inode in the table. The index of the slot is the same as the index in the table.
And this explains the name inode being a short name for <em>index node</em>.</p>

<h3 id="data-blocks">Data blocks</h3>

<p>As the name suggests, the data blocks are the blocks where the actual data
belonging to a file is written. These blocks are also used for different
purposes which we will see shortly.</p>

<h2 id="pointing-to-data">Pointing to data</h2>

<p>The inode needs to have a way of pointing to the data blocks that assemble the
file. The simplest way is to have <strong>direct pointers</strong>. In this case, each
pointer points to a block that has some of the file data. The problem is that
large files; where the size exceeds the number of direct pointers an inode can
have; are not supported in this mode. One way of overcoming this issue is to use
<strong>indirect pointers</strong>, which instead of storing user data they store pointers to
blocks that hold user data. For larger files, another layer of indirection is
added with <strong>double indirect pointers</strong>. And for even larger files, <strong>triple
indirect pointers</strong> are put to use.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_direct_pointers.svg" alt="">
    <figcaption>Inode multi-level index</figcaption>
</figure>

<p>To give an idea of the largest file size that each level permit let’s run an
example considering that each block size is 4 KiB. Research has shown that the
majority of files are small [1] so 12 direct pointers would allow for files up
to 48 KiB. Considering that each pointer takes 4 bytes, a single indirect
pointer would then allow a file to be up to around 4 MiB:</p>

<pre>(12 + 1024) * 4 KiB
</pre>

<p>With the addition of double indirect pointers the size would jump to around 4
GiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup>) * 4 KiB
</pre>

<p>And finally, with triple indirect pointers the files could have a size of around
4 TiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup> + 1024<sup>3</sup>) * 4 KiB
</pre>

<p>This approach might not be very efficient for handling large files. For example,
a file of 100 MiB requires the allocation of 25600 blocks. The performance can
be severely impacted in case the blocks were fragmented over the disk.</p>

<p>Some file systems use <strong>extents</strong> to help with this situation. In this approach,
there is a single pointer and a length to tell that the data starts at the
address of the pointer and runs for the given range of blocks. In our example
above, describing the same file would use a single extent of size 100 MiB.
Multiple extents can be used to support larger files.</p>

<h2 id="directories">Directories</h2>

<p>You may have noticed that there isn’t a specific structure for directories. The
reason behind it is the fact that inodes represent both files and directories.
The difference is in what is stored in the corresponding data blocks.
Directories are simply a list of all files that it includes. Each entry has the
form of <code>(name, index number)</code> so when looking up a particular file (or another
directory), the system uses the <code>name</code> to find the corresponding inode.</p>

<p>Searching for a file can be slow if a directory contains a large number of
files. This issue can be mitigated by maintaining the list sorted and using
binary search, or instead of representing it as a list, a hash table or a
balanced search tree could also be used.</p>

<h2 id="access-paths">Access paths</h2>

<h3 id="read">Read</h3>

<p>When reading from a file, the file system needs to traverse the entire path,
visiting each inode along the way until reaching the inode for the desired file.
Assuming the user has permission to access the file, the file system consults
which blocks are associated with it and then read the solicited data from them.</p>

<h3 id="write">Write</h3>

<p>When writing to a file, the same process has to happen to find the corresponding
inode. If a new block is required for the write, the file system has to allocate
the block, update the associated information (bitmap and inode), and write to
the block. So one write operation requires five I/O operations: one read to the
bitmap, one write to mark the new block as occupied, two to read and write to
the inode, and one writing the data in the block. This number can increase when
creating a new file because now the associated information of the directory also
has to be read and written to reflect this new file, and operations to create a
new inode.</p>

<h2 id="gotenksfs">GotenksFS</h2>

<p>As a side project, I decided to write my own file system in Rust as I’m learning
the language. Some aspects are inspired by ext4 [2] (and family), and in this
section, you will learn more about it. The file system uses FUSE [3], and the
disk is represented as a regular file. The block size can be configured as 1
KiB, 2 KiB, or 4 KiB. Files can have a size of up to 4 GiB for block sizes of 4
KiB while the file system could theoretically be up to 16 TiB in size.</p>

<h3 id="mkfs"><code>mkfs</code></h3>

<p>The first step is to create the image itself with the configuration values for
the file system. This is achieved via the <code>mkfs</code> command:</p>

<div><div><pre><code><span>$ </span>./gotenksfs mkfs disk.img <span>-s</span> <span>"10 GiB"</span> <span>-b</span> 4096
</code></pre></div></div>

<p>After running the command, the image is created with a total size of 10 GiB, and
each block in the file system has a size of 4 KiB.</p>

<p>In this step, the configuration values and other structures such as a root
directory are written to the image in the first block: the superblock. Its
corresponding bitmap entries, and data are also written. These values will be
necessary for the next step: mounting the file system.</p>

<h3 id="mount"><code>mount</code></h3>

<p>After creating the image, we need to mount it so we can start using it. The
<code>mount</code> command is used for this:</p>

<div><div><pre><code><span>$ </span>./gotenksfs mount disk.img gotenks
</code></pre></div></div>

<p>And you can see some information about it:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs-mount.png">
    <figcaption>File system after mounting</figcaption>
</figure>

<h3 id="on-disk-structure">On-disk structure</h3>

<p>The superblock is written in the first 1024 bytes, and it holds the
configuration values provided in the <code>mkfs</code> command.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Superblock</span> <span>{</span>
    <span>pub</span> <span>magic</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>block_size</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>last_mounted_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>inode_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_blocks</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_inodes</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>groups</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>data_blocks_per_group</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>uid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>gid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>The next two blocks represent the data bitmap and inode bitmap. Then, a run of
<code>n</code> blocks are used for the inode table. And the blocks following that are the
ones where user data will be written.</p>

<p>The inode is defined as follows:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Inode</span> <span>{</span>
    <span>pub</span> <span>mode</span><span>:</span> <span>libc</span><span>::</span><span>mode_t</span><span>,</span>
    <span>pub</span> <span>hard_links</span><span>:</span> <span>u16</span><span>,</span>
    <span>pub</span> <span>user_id</span><span>:</span> <span>libc</span><span>::</span><span>uid_t</span><span>,</span>
    <span>pub</span> <span>group_id</span><span>:</span> <span>libc</span><span>::</span><span>gid_t</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span> <span>// should be in 512 bytes blocks</span>
    <span>pub</span> <span>size</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>accessed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>changed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>direct_blocks</span><span>:</span> <span>[</span><span>u32</span><span>;</span> <span>DIRECT_POINTERS</span> <span>as</span> <span>usize</span><span>],</span>
    <span>pub</span> <span>indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>double_indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>As you can see above, inodes support double indirect pointers which means that
for a disk with a block size of 4 KiB, the maximum capacity of a file is 4 GiB.
The number of direct pointers is set to 12:</p>

<div><div><pre><code><span>pub</span> <span>const</span> <span>DIRECT_POINTERS</span><span>:</span> <span>u64</span> <span>=</span> <span>12</span><span>;</span>
</code></pre></div></div>

<p>When starting the FS for the first time, it will create the root directory using
the definition below:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Directory</span> <span>{</span>
    <span>pub</span> <span>entries</span><span>:</span> <span>BTreeMap</span><span>&lt;</span><span>OsString</span><span>,</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<h3 id="block-groups">Block groups</h3>

<p>The inode bitmap has 4 KiB meaning that each bitmap block will have a capacity
for 32768 inodes. Suppose we round up the size of an <code>Inode</code> to 128 bytes; the
corresponding inode table will require 4 MiB of space. One of the ways for
structuring them would be to have many blocks dedicated to the bitmaps, then the
corresponding number blocks to store the inodes, and the remaining blocks for
user data.</p>

<p>Instead of doing that, we can create <em>block groups</em> that will always have one
block for the data bitmap and one for the inode bitmap. The next 1024 blocks
contain the inode table, and following that, 32768 blocks which are used for
user data.</p>

<!--
For a disk as in our case of 10 GiB, how many blocks should be dedicated to inode bitmaps?

Increasing the number of blocks to be inode bitmaps reduces the amount of available data blocks. And reducing the number of inode bitmaps restricts the total number of files supported by the system.
-->

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs_block_group.svg" alt="">
    <figcaption>Block groups</figcaption>
</figure>

<h3 id="reading-and-writing-to-files">Reading and writing to files</h3>

<p>Now that the “disk” is set up, we can start writing and reading files from it. Creating a new directory using <code>mkdir</code>:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/mkdir.gif" alt="">
    <figcaption>Creating a directory</figcaption>
</figure>

<p>The process that occurs is the following: the system searches for the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html">https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</a></em></p>]]>
            </description>
            <link>https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967016</guid>
            <pubDate>Mon, 27 Jul 2020 17:04:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Your DevOps Control Plane, in Slack]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23967015">thread link</a>) | @slajax
<br/>
July 27, 2020 | https://cto.ai/blog/slack-control-plane-for-devops-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/slack-control-plane-for-devops-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<blockquote>We're <a href="https://news.ycombinator.com/show">trending on Hacker News</a> - Please join the conversation there!</blockquote><p>In today's remote first world, Slack is increasingly becoming the natural place that communication and collaboration happen in all aspects of work. Personally, I look at Slack each morning before I look at email or even social media, making it the natural jump off point for the most important interactions that I have professionally.</p><div><p>Never has this also been more true, than for complex developer workflows which teams need to share to ensure enablement across their entire development team.</p><p>Traditionally, a developer would have to interface with many different softwares in order to complete their tasks, increasing the context that they need within each domain in order to complete their job. All of this comes at the expense of developer productivity and this is why CTO.ai set out to improve the holistic developer experience by re-imagining what DevOps should look like, Slack first.</p><p>Today we are happy to announce that we're continuing to invest into our mission to make DevOps more accessible and enjoyable for the next 40 million developers with the release of our Slack Home feature, which naturally acts as an easily accessible Control Plane for all of your team's developer workflows!</p></div><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><div><p>Within the Slack Home, you can quickly navigate the CTO.ai teams which you have joined and easily execute the workflows associated to that team, simply by clicking the Run button and picking the channel that you want to run the workflow in.</p><p>This makes it even easier for DevOps teams and Senior Engineers to build and distribute their developer tools to their entire team by creating a centralized control plane for accessing these often privileged and complex workflows.</p><p>Team management has also become centralized. At a glance, leads can see what teams they have created, what channels are associated to them and who are the members of the teams. You can now add team members from this location as well.</p><p>Soon, we'll also allow you to look at Workflow Events and even Metrics associated to the custom workflows that each team has architected, which represent their deliverables and day to day work, empowering leads with a strong feedback loop.</p></div><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab-teams.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><p>When a developer executes a workflow, the workflow can be then targeted to run in any channel which is associated to the team, giving the same inherit benefits which many of our users are already enjoying with SlackOps, such as; Secrets, Configs, Logs, Events and ultimately the inherent transparency and accessibility of Slack.</p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/07/home-tab-runop.png"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br><!--kg-card-end: html--><p>Here is a quick video overview of how this new feature works:</p><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/8RxGak-Bl3I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>A demo of the new Slack Home - a control plane for DevOps workflows</figcaption></figure><!--kg-card-end: embed--><p>We're really excited about what this new feature does to unlock the power of DevOps to truly enable Devs to leverage the 10x power of Ops. We believe this is a huge step in the right direction that will enable inclusivity and empowerment of developers on teams all around the world to adopt DevOps in their team.</p><div><p>We’re still just getting started though so if you have any suggestions or questions feel free to reach out to <a><span data-cfemail="8bf8fefbfbe4f9ffcbe8ffe4a5eae2">[email&nbsp;protected]</span></a>. We are building where collaboration will happen for the next 40 million developers and we can't do it alone.</p><p>Sign up for more information and to get a free demo of our platform today!</p></div><!--kg-card-begin: html--><!--[if lte IE 8]>
<script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/v2-legacy.js"></script>
<![endif]-->

<!--kg-card-end: html-->
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/slack-control-plane-for-devops-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23967015</guid>
            <pubDate>Mon, 27 Jul 2020 17:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of Synthetic Audio Deepfakes]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23965106">thread link</a>) | @ajay-d
<br/>
July 27, 2020 | https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes | <a href="https://web.archive.org/web/*/https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <h6>
        
        
        
        
        
        6 min read
        
      </h6>
        

        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><div class="page" title="Page 2">
<div>
<div>
<div>
<p><strong>Can Audio Deepfakes Really Fake a Human?</strong></p>
<p>Audio deepfakes are the new frontier for business compromise schemes and are becoming more common pathways for criminals to deceptively gain access to corporate funds. Nisos recently investigated and obtained an original attempted deepfake synthetic audio used in a fraud attempt against a technology company. The deepfake took the form of a voicemail message from the company’s purported CEO, asking an employee to call back to “finalize an urgent business deal.” The recipient immediately thought it suspicious and did not contact the number, instead referring it to their legal department, and as a result the attack was not successful.</p>
</div>
</div>
</div>
</div>
<!--more-->
<p>Nisos investigated the phone number the would-be attacker used and determined it was a VOIP service with no owner registration information. It was likely simply acquired and used as a “burner” for this fraud attempt only. While there was no actual voicemail message associated with the number, we made no attempt for live contact with the owner of the phone number for legal reasons.</p>

<p><strong>Deepfake Audio Analysis</strong></p>
<p>Nisos analyzed the deepfake voicemail audio recording with an audio spectrogram tool called Spectrum3d. Looking to detect any anomalies, we immediately noticed the highs spiking repeatedly in the spectrogram (see graphic below). We initially suspected the deepfake creator used audio playing over on multiple channels to help mask the voice.</p>
<p><strong><i><img src="https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=351&amp;name=pasted%20image%200%20(7).png" alt="pasted image 0 (7)" width="351" srcset="https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=176&amp;name=pasted%20image%200%20(7).png 176w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=351&amp;name=pasted%20image%200%20(7).png 351w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=527&amp;name=pasted%20image%200%20(7).png 527w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=702&amp;name=pasted%20image%200%20(7).png 702w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=878&amp;name=pasted%20image%200%20(7).png 878w, https://www.nisos.com/hs-fs/hubfs/pasted%20image%200%20(7).png?width=1053&amp;name=pasted%20image%200%20(7).png 1053w" sizes="(max-width: 351px) 100vw, 351px"></i></strong><strong><i>Graphic 1: Spectrogram analysis of the deepfake audio, displaying major inconsistencies in pitch and tone.</i></strong></p>
<p>We additionally noticed the audio was very choppy and not consistent with a similar human voice recording. When we altered the audio speed and played back at 1.2 speed, the audio then sounded more like a standard text to speech system. Most interesting, when we amplified the sound to detect any background noise we were unable to find any traces, which further indicated this was manipulated audio.</p>
<p>We then compared the deepfake spectrogram analysis with results of a "normal" human voice on a similar recording. We can immediately see how the pitch and tone is more smoothed out, as well as the ability to detect faint background noise.</p>
<p><strong><i><img src="https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=351&amp;name=unnamed%20(4).png" alt="unnamed (4)" width="351" srcset="https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=176&amp;name=unnamed%20(4).png 176w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=351&amp;name=unnamed%20(4).png 351w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=527&amp;name=unnamed%20(4).png 527w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=702&amp;name=unnamed%20(4).png 702w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=878&amp;name=unnamed%20(4).png 878w, https://www.nisos.com/hs-fs/hubfs/unnamed%20(4).png?width=1053&amp;name=unnamed%20(4).png 1053w" sizes="(max-width: 351px) 100vw, 351px"></i></strong><strong><i>Graphic 2: Spectrogram analysis of ‘normal’ human voice, displaying more consistent pitch and tone.</i></strong></p>
<p>We were unable to determine the exact software or voice model used to create this deepfake as we would have required access to a large enough sample of the attacker’s other deepfake audio files (we would likely need tens if not hundreds of files, and this assumes the attacker made more than just this one). However, we note several complicating factors an actor would have to overcome to create a more realistic deepfake audio:</p>
<ol>
<li>Capturing high quality audio with little to no background noise.</li>
<li>Staging the call for audio delivering in a realistic scenario (tone of the person talking, background noise and reason for the call) in which the person wouldn’t feel the need to call the person back.&nbsp;</li>
<li>Finding a way to leave a message, so they can avoid an in-person conversation.</li>
</ol>
<p>It is likely the attacker in this scenario above utilized a feature most cell/VOIP service providers offer, which is the ability to bypass the ring option and go straight into the voice mail using the `#` key.</p>

<p><strong>Has This Happened Before?</strong></p>
<p>The most famous use of deep fake synthetic audio technology in criminal fraud was a September 2019 incident involving a British energy company. The criminals reportedly used voice-mimicking software to imitate the British executive’s speech and trick his subordinate into sending hundreds of thousands of dollars to a secret account.&nbsp;</p>
<p>The managing director of this company, believing his boss was on the phone, followed orders to wire more than $240,000 to an account in Hungary.<sup>1</sup></p>
<p>Symantec security researchers reported in February on three cases of audio deepfakes used against private companies by impersonating the voice of the business’s CEO.<sup>2 </sup>The criminals reportedly trained machine learning engines from audio obtained on conference calls, YouTube, social media updates and even TED talks, to copy the voice patterns of company bosses.&nbsp;</p>
<p>They created audio deepfakes replicating the CEO’s voice and called senior members of the finance department to ask for funds to be sent urgently. There was no additional reporting on which companies these were, whether the techniques were successful, or whether Symantec was able to obtain recordings of the deepfakes themselves.</p>
<p>Without actual digital capture of the audio, and additional forensics analysis, it is unclear whether these attempts were in fact deepfake synthetic manipulated audio. Regardless, the ability to generate synthetic audio extends an e-criminal’s toolkit and the criminal at the end of the day still has to effectively use social engineering tactics to induce someone into taking an action.&nbsp;</p>
<p>Criminals and potentially broader nation state actors also learn from each other, so as these high-profile cases gain more notoriety and success, we anticipate more illicit actors trying them and learning from others who have paved the way.</p>
<p>Additionally, as deepfakes become easier to create or purchase, and the quality of synthetic manipulation -both audio (and video)- increases, we anticipate wider deployment of these e-crime exploits. If a fraud operation requires the use of a completely fake doctored video or audio for maximum impact, and it is worth the money and resources, it will be used. However, Nisos researchers have not seen the ability to easily outsource this type of deepfake for single individual or mass production.</p>
<p>Our researchers have contact with a few deepfake channels where we asked about this type of attack vector and participants were unsure something like this would be possible in the near future. The central issue with audio deepfakes has to do with capturing not only the person’s tone but also specific speech mannerisms. Future scenarios will likely materialize, however, where tools similar to a Yandex reverse image search (but for voice) could be used to gather numerous samples and then build and train a model that could help convert the source voice into the target voice.</p>

<p><strong>What Can Be Done?</strong></p>
<p>The most immediate action an employee can take, if they sense something suspicious in a voicemail (or any audio) instruction, is to call the person back directly using a known number and get them on the line.&nbsp;</p>
<p>Deepfake technology is not sophisticated enough to mimic an entire phone call with someone. Additionally, the company can exercise a series of ‘challenge questions’ using information that is not publicly known or conversation points that an actor could not readily answer, to vet the identity of the individual on the line.</p>
<p>This fraud scheme is a form of a business email compromise (a more sophisticated and AI-developed version) where typically the attacker will pretend to be a senior executive at a company and get a more susceptible ‘lower-level’ employee to send money to a bank account.&nbsp;</p>
<p>We would anticipate a deepfake audio would be the first step in a series of social engineering attempts to get an employee to wire money to a specific location. Phishing emails, additional phone calls, or even deepfake videos purporting to authorize an action could be used in furtherance of the criminal scheme.&nbsp;&nbsp;</p>
<p>Deepfake audio may also be used for reasons ancillary to the ones listed above. For example, criminals can leave fake messages instructing employees to provide network or physical access to the company, allowing attackers to easily compromise the network or physical assets of the company.</p>
<p>The availability of this nascent but rapidly-emerging technology emphasizes the criticality with which companies must develop security practices that encompass these measures. Any time an unusual incident occurs, and certainly when large financial transactions are involved, employees should be trained to ask challenge questions to senior executives.</p>

<p>Research featured in <a href="https://www.vice.com/en_us/article/pkyqvb/deepfake-audio-impersonating-ceo-fraud-attempt" rel=" noopener">Vice Article</a><span> by </span><a href="https://www.vice.com/en_us/contributor/lorenzo-franceschi-bicchierai">Lorenzo Franceschi-Bicchierai.</a></p>
<p>Twitter Handle: Rob Volkert <a href="https://twitter.com/DiligenceWatch" rel=" noopener"><span>@DiligenceWatch</span></a></p>
<hr>
<p><em>1. <a href="https://www.washingtonpost.com/technology/2019/09/04/an-artificial-intelligence-first-voice-mimicking-software-reportedly-used-major-theft/" rel=" noopener">https://www.washingtonpost.com/technology/2019/09/04/an-artificial-intelligence-first-voice-mimicking-software-reportedly-used-major-theft/</a></em></p>
<p><em>2. <a href="https://www.icaew.com/insights/features/2020/feb-2020/the-rise-of-deepfake-audio-fraud" rel=" noopener">https://www.icaew.com/insights/features/2020/feb-2020/the-rise-of-deepfake-audio-fraud</a></em></p>
</span>
        </p>
        
            
        

        
        
        
    </div>
</div></div>]]>
            </description>
            <link>https://www.nisos.com/white-papers/rise_synthetic_audio_deepfakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23965106</guid>
            <pubDate>Mon, 27 Jul 2020 13:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s easier to manage four people than one person]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23964905">thread link</a>) | @chesterarthur
<br/>
July 27, 2020 | https://staysaasy.com/management/2020/07/24/Managing-One-Person.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/07/24/Managing-One-Person.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>It’s easier to manage 4 people than it is to manage one person. The primary reason for this is the inherent over-reliance in the relationship between a manager and a single report. Let’s dive deeper.</p>

<p>It’s not uncommon for a first-time manager to get a single direct report. Try it out. See how it goes. Here’s what this ends up looking like:</p>
<ul>
  <li>The new manager is over-reliant on making sure their single report likes them and is doing well. If they give feedback that their manager stinks, that’s 100% bad feedback from your reports. If the report doesn’t do well, that’s 100% of your reports that aren’t succeeding.* If the report quits, you just lost your whole team.</li>
  <li>The manager’s over-reliance on the direct report’s success and happiness leads to risk-averse behavior, like not giving critical feedback or overcompensating. It also regularly leads to micromanagement.</li>
  <li>The single report is isolated. They don’t have any peers on the team to reach out to for help. If their manager is bad, they don’t have any corroborating voices. Anything that goes wrong is a they-said I-said debate. Any debate inside of the team is a faceoff with your manager.</li>
  <li>No one in this relationship has the ability to get context. With more reports, a manager gets clearer signals when they’re wrong. A report could look to teammates to corroborate or dissuade their ideas. With one report, disagreements have little additional evidence, so people have to either approach the situation with a supreme lack of ego, or they can just assume it’s the other person’s fault. Guess which option happens most.</li>
</ul>

<p>To further the problematic conditions, the single report will often be a very junior hire. This compounds the issue. Straight-from-college hires don’t have great context for what it means to be in industry, to have a manager, to work a job with no end-of-semester in sight. And hires aren’t expected to have as much autonomy in their formative early years. With these variables, the requirements on the manager are higher than average.</p>

<p>It’s not uncommon for these relationships to turn sour. The manager makes mistakes as they always do. The report makes mistakes as they always do. Fingers are pointed. Times are dire. If you ever hear someone call their manager a “first-time manager”, you know the relationship has reached a special level of hell.</p>

<p>To avoid this situation, consider doing the following:</p>
<ul>
  <li>Avoid having first time managers have a team of 1 individual contributor for a prolonged amount of time. That team size is an <a href="https://staysaasy.com/management/2020/06/21/goldilocks-management-structure.html">anti-pattern</a> for more reasons than just this one.</li>
  <li>Try and make sure the manager of a team with 1 individual contributor is also an expert in the domain area. Sometimes managers are explicitly not the domain expert by design, but when you have 1 report, a lack of domain expertise is one of the sure-fire ways to make mistakes and a sure-fire way for your report to get the idea that you’re no good.</li>
  <li>Avoid at all costs the combination of: new manager, 1 report, report is new-to-industry, manager is not a subject-matter expert.</li>
</ul>

<p>* Note: mangers should be very invested in their report’s success. But when the manager is <em>over-invested</em> it leads to all sorts of unsavory things, some of which are called out above. Another example is when a report is doing well-enough, but because the manager is <em>over-reliant</em> on their performance, they try to push the report beyond what they can or want to do.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/07/24/Managing-One-Person.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964905</guid>
            <pubDate>Mon, 27 Jul 2020 13:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Entry Accounting for Developers]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 140 (<a href="https://news.ycombinator.com/item?id=23964513">thread link</a>) | @adamcharnock
<br/>
July 27, 2020 | https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html | <a href="https://web.archive.org/web/*/https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="double-entry-accounting-for-developers">

<p>Hordak is inherently aimed at software developers as it provides core
functionality only. Friendly interfaces can certainly be built on top of it, but
if you are here there is a good chance you are a developer.</p>
<p>If you are learning about accounting as developer you may feel – as I did – that
most of the material available doesn’t quite relate to the developer/STEM mindset. I
therefore provide some resources here that may be of use.</p>
<div>
<p>Note</p>
<p>According to this <a href="https://news.ycombinator.com/item?id=23964513">Hacker News discussion</a>, some of what follows may be either incorrect
or abhorrent to those with a good knowledge of accounting practices. I still
feel the following is useful, and that taken as a whole it describes a working
double entry accounting system.</p>
</div>

<div id="in-a-little-more-detail">
<h2>In a little more detail<a href="#in-a-little-more-detail" title="Permalink to this headline">¶</a></h2>
<p>I found <a href="http://www.mathstat.dal.ca/~selinger/accounting/tutorial.html">Peter Selinger’s tutorial</a> to be very enlightening and is less terse than the functional description above.
The first section is short and covers single entry accounting, and then shows how one can expand that to create double
entry accounting. I found this background useful.</p>
</div>
<div id="examples">
<h2>Examples<a href="#examples" title="Permalink to this headline">¶</a></h2>
<p>You live in a shared house. Everyone pays their share into a communal bank account
every month.</p>
<div id="example-1-saving-money-to-pay-a-bill-no-sign-flipping">
<h3>Example 1: Saving money to pay a bill (no sign flipping)<a href="#example-1-saving-money-to-pay-a-bill-no-sign-flipping" title="Permalink to this headline">¶</a></h3>
<p>You pay the electricity bill every three months. Therefore every month you take £100
from everyone’s contributions and put it into Electricity Payable account (a liability
account) in the knowledge that you will pay the bill from this account when it eventually arrives:</p>
<p>These accounts are income &amp; liability accounts, so neither balance needs to be flipped (flipping
only applies to asset &amp; expense accounts). Therefore:</p>
<ul>
<li>Balances before:<ul>
<li><em>Housemate Contribution</em> (income): £500</li>
<li><em>Electricity Payable</em> (liability): £0</li>
</ul>
</li>
<li><strong>Transaction</strong>:<ul>
<li>£100 from <em>Housemate Contribution</em> to <em>Electricity Payable</em></li>
</ul>
</li>
<li>Balances after:<ul>
<li><em>Housemate Contribution</em> (income): £400</li>
<li><em>Electricity Payable</em> (liability): £100</li>
</ul>
</li>
</ul>
<p>This should also make intuitive sense. Some of the housemate contributions will be used to pay the electricity
bill, therefore the former decreases and the latter increases.</p>
</div>
<div id="example-2-saving-money-to-pay-a-bill-with-sign-flipping">
<h3>Example 2: Saving money to pay a bill (with sign flipping)<a href="#example-2-saving-money-to-pay-a-bill-with-sign-flipping" title="Permalink to this headline">¶</a></h3>
<p>At the start of every month each housemate pays into the communal bank account. We
should therefore represent this somehow in our double entry system (something we ignored in
example 1).</p>
<p>We have an account called <em>Bank</em> which is an asset account (because this is money
we actually have). We also have a <em>Housemate Contribution</em> account which is an
income account.</p>
<p>Therefore, <strong>to represent the fact that we have been paid money, we must create a transaction</strong>.
However, money cannot be injected from outside our double entry system, so how do we deal with this?</p>
<p>Let’s show how we represent a single housemate’s payment:</p>
<ul>
<li>Balances before:<ul>
<li><em>Bank</em> (asset): £0</li>
<li><em>Housemate Contribution</em> (income): £0</li>
</ul>
</li>
<li><strong>Transaction:</strong><ul>
<li>£500 from <em>Bank</em> to <em>Housemate Contribution</em></li>
</ul>
</li>
<li>Balances after:<ul>
<li><em>Bank</em> (asset): -£500 * -1 = <strong>£500</strong></li>
<li><em>Housemate Contribution</em>  (income): £500</li>
</ul>
</li>
</ul>
<p>Because the bank account is an asset account, we flip the sign of its balance.
<strong>The result is that both accounts increase in value.</strong></p>
</div>
</div>
</div>


           </div>
           
          </div></div>]]>
            </description>
            <link>https://django-hordak.readthedocs.io/en/latest/accounting-for-developers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964513</guid>
            <pubDate>Mon, 27 Jul 2020 12:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Procedural cityscapes creation: Openstreetmap import in Unity and Houdini Engine]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23964079">thread link</a>) | @liotier
<br/>
July 27, 2020 | http://stinaflodstrom.com/projects/osm/osm.html | <a href="https://web.archive.org/web/*/http://stinaflodstrom.com/projects/osm/osm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

                  <div><p>

                  I set up a procedural content creation pipeline that imports <a href="http://stinaflodstrom.com/projects/osm/www.openstreetmap.org">OpenStreetMap</a> data into Unity and uses the Houdini Engine to create realistic cityscapes based on real world locations. The goal was to have an as automated process as possible for generating environments based on real cities. The buildings and the roads are generated from OSM building shapes and road splines using a procedural system for building type and prop placing. Traffic lights, Crossings and Trees also get their positions from OSM. Values and procedural parameters can be tweaked in Unity making it possible to create endless variations.

                  </p><p>The project was developed with the simulation team in one of the bigger automotive companies as a proof of concept for creating syntetic data for AI and render out annotated images. The environmant is complete with tags for segmentation. 

                </p></div>

            </div></div>]]>
            </description>
            <link>http://stinaflodstrom.com/projects/osm/osm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23964079</guid>
            <pubDate>Mon, 27 Jul 2020 11:31:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GnuTLS audit: passive cleartext recovery attack]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23962840">thread link</a>) | @masklinn
<br/>
July 27, 2020 | https://anarc.at/blog/2020-06-10-gnutls-audit/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-06-10-gnutls-audit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>So <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> came out while I wasn't looking last week. The
GnuTLS advisory (<a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">GNUTLS-SA-2020-06-03</a>) is pretty opaque so I'll
refer instead to <a href="https://twitter.com/FiloSottile/status/1270061316368224256">this tweet</a> from <a href="https://twitter.com/FiloSottile">@FiloSottile</a> (Go team
security lead):</p>

<blockquote><p>PSA: don't rely on GnuTLS, please.</p>

<p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-13777">CVE-2020-13777</a> Whoops, for the past 10 releases most TLS 1.0–1.2
connection could be passively decrypted and most TLS 1.3 connections
intercepted. Trivially.</p>

<p>Also, <a href="https://blog.filippo.io/we-need-to-talk-about-session-tickets/">TLS 1.2–1.0 session tickets are awful</a>.</p></blockquote>

<p>You are reading this correctly: supposedly encrypted TLS connections
made with affected GnuTLS releases are vulnerable to <em>passive</em>
cleartext recovery attack (and active for 1.3, but who uses that
anyways). That is extremely bad. It's pretty close to just switching
everyone to HTTP instead of HTTPS, more or less. I would have a lot
more to say about the security of GnuTLS in particular -- and security
in general -- but I am mostly concerned about patching holes in the
roof right now, so this article is not about that.</p>

<p>This article is about figuring out what, exactly, was exposed in our
infrastructure because of this.</p>






<p>Assuming you're running Debian, this will show a list of packages that
<code>Depends</code> on GnuTLS:</p>

<pre><code>apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u
</code></pre>

<p>This assumes you run this only on hosts running Buster or
above. Otherwise you'll need to figure out a way to pick machines
running GnuTLS 3.6.4 or later.</p>

<p>Note that this list only <em>first level</em> dependencies! It is perfectly
possible that another package uses GnuTLS without being listed
here. For example, in the above list I have <code>libcurl3-gnutls</code>, so the
be really thorough, I would actually need to recurse down the
dependency tree.</p>

<p>On my desktop, this shows an "interesting" list of targets:</p>

<ul>
<li><code>apt</code></li>
<li><code>cadaver</code> - AKA WebDAV</li>
<li><code>curl</code> &amp; <code>wget</code></li>
<li><code>fwupd</code> - another attack on top of <a href="https://github.com/justinsteven/advisories/blob/master/2020_fwupd_dangling_s3_bucket_and_CVE-2020-10759_signature_verification_bypass.md">this one</a></li>
<li><code>git</code> (through the <code>libcurl3-gnutls</code> dependency)</li>
<li><code>mutt</code> - all your emails</li>
<li><code>weechat</code> - your precious private chats</li>
</ul>


<p>Arguably, fetchers like <code>apt</code>, <code>curl</code>, <code>fwupd</code>, and <code>wget</code> rely on HTTPS for
"authentication" more than secrecy, although <code>apt</code> has its own
OpenPGP-based authentication so that wouldn't matter anyways. Still,
this is truly distressing. And I haven't mentioned here things like
<code>gobby</code>, <code>network-manager</code>, <code>systemd</code>, and others - the scope of this is
broad. Hell, even good old <code>lynx</code> links against GnuTLS.</p>

<p>In our infrastructure, the magic command looks something like this:</p>

<pre><code>cumin -o txt -p 0  'F:lsbdistcodename=buster' "apt-cache --installed rdepends libgnutls30 | grep '^ ' | sort -u" | tee gnutls-rdepds-per-host | awk '{print $NF}' | sort | uniq -c | sort -n
</code></pre>

<p>There, the result is even more worrisome, as those important packages seem to rely on GnuTLS for their transport security:</p>

<ul>
<li><code>mariadb</code> - all MySQL traffic and passwords</li>
<li><code>mandos</code> - full disk encryption</li>
<li><code>slapd</code> - LDAP passwords</li>
</ul>


<p><code>mandos</code> is especially distressing although it's probably not
vulnerable because it seems it doesn't store the cleartext -- it's
encrypted with the client's OpenPGP public key -- so the TLS tunnel
never sees the cleartext either.</p>

<p><a href="https://twitter.com/jedisct1/status/1270078914996682753">Other reports</a> have also mentioned the following servers link
against GnuTLS and could be vulnerable:</p>

<ul>
<li><code>exim</code></li>
<li><code>rsyslog</code></li>
<li><code>samba</code></li>
<li>various <code>VNC</code> implementations</li>
</ul>




<p>Those programs are not affected by this vulnerability:</p>

<ul>
<li><code>apache2</code></li>
<li><code>gnupg</code></li>
<li><code>python</code></li>
<li><code>nginx</code></li>
<li><code>openssh</code></li>
</ul>


<p>This list is not exhaustive, naturally, but serves as an example of
common software you don't need to worry about.</p>

<p>The vulnerability only exists in GnuTLS, as far as we know, so
programs linking against other libraries are not vulnerable.</p>

<p>Because the vulnerability affects session tickets -- and those are set
on the server side of the TLS connection -- only users of GnuTLS as a
server are vulnerable. This means, for example, that while <code>weechat</code>
uses GnuTLS, it will only suffer from the problem when acting as a
server (which it does, in relay mode) or, of course, if the remote IRC
server also uses GnuTLS. Same with apt, curl, wget, or git: it is
unlikely to be a problem because it is only used as a client; the
remote server is usually a webserver -- not git itself -- when using
TLS.</p>



<p>Keep in mind that it's not because a package links against GnuTLS that
it <em>uses</em> it. For example, I have been told that, on Arch Linux, if
both GnuTLS and OpenSSL are available, the <code>mutt</code> package will use the
latter, so it's not affected. I haven't confirmed that myself nor have I
checked on Debian.</p>

<p>Also, because it relies on session tickets, there's a time window
after which the ticket gets cycled and properly initialized. But that
is <a href="https://twitter.com/__agwa/status/1270054740559384576">apparently 6 hours by default</a> so it is going to protect only
really long-lasting TLS sessions, which are uncommon, I would argue.</p>

<p>My audit is limited. For example, it might have been better to walk
the shared library dependencies directly, instead of relying on Debian
package dependencies.</p>



<p>It seems the vulnerability might have been introduced in <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/695">this merge
request</a>, itself following a (entirely reasonable) <a href="https://gitlab.com/gnutls/gnutls/-/issues/184">feature request
to make it easier to rotate session tickets</a>. The merge request was
open for a few months and was thoroughly reviewed by a peer before
being merged. Interestingly, the vulnerable function
(<code>_gnutls_initialize_session_ticket_key_rotation</code>), explicitly says:</p>

<pre><code> * This function will not enable session ticket keys on the server side. That is done
 * with the gnutls_session_ticket_enable_server() function. This function just initializes
 * the internal state to support periodical rotation of the session ticket encryption key.
</code></pre>

<p>In other words, it thinks it is not responsible for session ticket
initialization, yet it is. Indeed, the <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275/">merge request fixing the
problem</a> unconditionally does this:</p>

<pre><code>memcpy(session-&gt;key.initial_stek, key-&gt;data, key-&gt;size);
</code></pre>

<p>I haven't reviewed the code and the vulnerability in detail, so take
the above with a grain of salt.</p>

<p>The <a href="https://gitlab.com/gnutls/gnutls/-/merge_requests/1275.patch">full patch is available here</a>. See also the <a href="https://gitlab.com/gnutls/gnutls/-/issues/1011">upstream issue
1011</a>, the <a href="https://gnutls.org/security-new.html#GNUTLS-SA-2020-06-03">upstream advisory</a>, the <a href="https://security-tracker.debian.org/tracker/CVE-2020-13777">Debian security
tracker</a>,
and the <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1843723">Redhat Bugzilla</a>.</p>



<p>The impact of this vulnerability depends on the affected packages and
how they are used. It can range from "meh, someone knows I downloaded
that Debian package yesterday" to "holy crap my full disk encryption
passwords are compromised, I need to re-encrypt all my drives",
including "I need to change all LDAP and MySQL passwords".</p>

<p>It promises to be a fun week for some people at least.</p>

<p>Looking ahead, however, one has to wonder whether we should follow
<a href="https://twitter.com/FiloSottile">@FiloSottile</a>'s advice and stop using GnuTLS altogether. There are
at least a few programs that link against GnuTLS because of the
<a href="https://en.wikipedia.org/wiki/OpenSSL#Licensing">OpenSSL licensing oddities</a> but that has been first announced in
2015, then <a href="https://www.openssl.org/blog/blog/2017/03/22/license/">definitely and clearly resolved in 2017</a> -- or <a href="https://opensource.com/article/19/2/top-foss-legal-developments">maybe
that was in 2018</a>? Anyways it's fixed, pinky-promise-I-swear,
except if you're one of those weirdos still using GPL-2, of
course. Even though OpenSSL isn't the simplest and secure TLS
implementation out there, it could preferable to GnuTLS and maybe we
should consider changing Debian packages to use it in the future.</p>

<p>But then again, the last time something like this happened, it was
<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a> and GnuTLS wasn't affected, so who knows... It is
likely that people don't have OpenSSL in mind when they suggest moving
away from GnuTLS and instead think of other TLS libraries like
<a href="https://tls.mbed.org/">mbedtls</a> (previously known as PolarSSL), <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a>, <a href="https://boringssl.googlesource.com/boringssl/">BoringSSL</a>,
<a href="https://www.libressl.org/">LibreSSL</a> and so on. Not that those are totally sinless either...</p>

<p>"This is fine", as they say...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            <div>
            <p><span>Created <time datetime="2020-06-11T15:47:35Z" pubdate="pubdate" title="Thu, 11 Jun 2020 11:47:35 -0400">tard dans la matinée de Thursday, June 11th, 2020</time>.</span>
            <span>
            
            <a href="http://source.anarcat.wiki.orangeseeds.org/?p=source.git;a=history;f=blog/2020-06-10-gnutls-audit.mdwn">Edited <time datetime="2020-06-11T16:18:48Z" title="Thu, 11 Jun 2020 12:18:48 -0400">Thursday, à l'heure du déjeuner, June 11th, 2020</time>.</a>
            
            </span>
            </p></div>

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-06-10-gnutls-audit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962840</guid>
            <pubDate>Mon, 27 Jul 2020 07:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ted Williams's Strike Zone]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 59 (<a href="https://news.ycombinator.com/item?id=23962339">thread link</a>) | @dedalus
<br/>
July 26, 2020 | http://tedwilliams.com/_data/hzone.htm | <a href="https://web.archive.org/web/*/http://tedwilliams.com/_data/hzone.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div height="31" rowspan="3"> 
	  <p><span color="#51504E">&nbsp;&nbsp;&nbsp;My 
		first rule of hitting was to get a good ball to hit. I learned down to 
		percentage points where those good balls were. The box shows my particular 
		preferences, from what I considered my “happy zone” - where I could hit 
		.400 or better - to the low outside corner - where the most I could hope 
		to bat was .230. Only when the situation demands it should a hitter go 
		for the low-percentage pitch.<p>
		
		&nbsp;&nbsp;&nbsp;Since some players are better high-ball hitters than 
		low-ball hitters, or better outside than in; each batter should work out 
		his own set of percentages. But more important, each should learn the 
		strike zone, because once pitchers find a batter is going to swing at 
		bad pitches he will get nothing else. The strike zone is approximately 
		seven balls wide (allowing for pitches on the corners). When a batter 
		starts swinging at pitches just two inches out of that zone (shaded area), 
		he has increased the pitcher’s target from approximately 4.2 square feet 
		to about 5.8 square feet - an increase of 37 percent. Allow a pitcher 
		that much of an advantage and you will be a .250 hitter.</p></span></p>
	</div></div>]]>
            </description>
            <link>http://tedwilliams.com/_data/hzone.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23962339</guid>
            <pubDate>Mon, 27 Jul 2020 04:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACCC alleges Google misled consumers about expanded use of personal data]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 78 (<a href="https://news.ycombinator.com/item?id=23961881">thread link</a>) | @Khaine
<br/>
July 26, 2020 | https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div property="content:encoded"><p><em>Correction: An earlier version of this media release used a hypothetical example that suggested that Google used information about users’ health to personalise or target advertisements. Google says that it does not show personalised ads based on health information. This example has been removed from the media release.</em></p>

<p>The ACCC has launched Federal Court proceedings against Google LLC (Google), alleging Google misled Australian consumers to obtain their consent to expand the scope of personal information that Google could collect and combine about consumers’ internet activity, for use by Google, including for targeted advertising.</p>

<p>The ACCC alleges Google misled consumers when it failed to properly inform consumers, and did not gain their explicit informed consent, about its move in 2016 to start combining personal information in consumers’ Google accounts with information about those individuals’ activities on non-Google sites that used Google technology, formerly DoubleClick technology, to display ads.</p>

<p>This meant this data about users’ non-Google online activity became linked to their names and other identifying information held by Google. Previously, this information had been kept separately from users’ Google accounts, meaning the data was not linked to an individual user.</p>

<p>Google then used this newly combined information to improve the commercial performance of its advertising businesses.</p>

<p>The ACCC also alleges that Google misled consumers about a related change to its privacy policy.</p>

<p>“We are taking this action because we consider Google misled Australian consumers about what it planned to do with large amounts of their personal information, including internet activity on websites not connected to Google,” ACCC Chair Rod Sims said.</p>

<p>“Google significantly increased the scope of information it collected about consumers on a personally identifiable basis. This included potentially very sensitive and private information about their activities on third party websites. It then used this information to serve up highly targeted advertisements without consumers’ express informed consent,” Mr Sims said.</p>

<p>“We allege that Google did not obtain explicit consent from consumers to take this step.”</p>

<p>“The use of this new combined information allowed Google to increase significantly the value of its advertising products, from which it generated much higher profits.”</p>

<p>“The ACCC considers that consumers effectively pay for Google’s services with their data, so this change introduced by Google increased the “price” of Google’s services, without consumers’ knowledge,” Mr Sims said.</p>

<p><strong>“I agree” notification</strong></p>

<p>The conduct is alleged to have impacted millions of Australians with Google accounts.</p>

<p>From 28 June 2016 until at least December 2018, Google account holders were prompted to click “I agree” to a pop-up notification from Google that purported to explain how it planned to combine their data, and sought the consumers’ consent for this.</p>

<blockquote>
	<p><em>Some new features for your Google Account</em></p>

	<p><em>We’ve introduced some optional features for your account, giving you more control over the data Google collects and how it’s used, while allowing Google to show you more relevant ads.</em></p>
</blockquote>

<p>The notification also stated,&nbsp;<em>“More information will be available in your Google Account making it easier for you to review and control”</em>; and&nbsp;<em>“Google will use this information to make ads across the web more relevant for you.”</em></p>

<p>Before June 2016, Google only collected and used, for advertising purposes, personally identifiable information about Google account users’ activities on Google owned services and apps like Google Search and YouTube.</p>

<p>After June 2016, when consumers clicked on the “I agree” notification, Google began to collect and store a much wider range of personally identifiable information about the online activities of Google account holders, including their use of third-party sites and apps not owned by Google.</p>

<p>Previously, this additional data had been stored separately from a user’s Google account.</p>

<p>Combined with the personal data stored in Google accounts, this provided Google with valuable information with which to sell even more targeted advertising, including through its Google Ad Manager and Google Marketing Platform brands.</p>

<p>The ACCC alleges that the “I agree” notification was misleading, because consumers could not have properly understood the changes Google was making nor how their data would be used, and so did not - and could not - give informed consent.</p>

<p>“We believe that many consumers, if given an informed choice, may have refused Google permission to combine and use such a wide array of their personal information for Google’s own financial benefit,” Mr Sims said.</p>

<p><strong>Privacy policy change</strong></p>

<p>Before 28 June 2016, Google stated in its privacy policy that it&nbsp;<em>“will not combine DoubleClick cookie information with personally identifiable information unless we have your opt-in consent.”</em></p>

<p>On 28 June 2016, Google deleted this statement and inserted the following statement:<em>&nbsp;“[d]epending on your account settings, your activity on other sites and apps may be associated with your personal information in order to improve Google’s services and the ads delivered by Google.”</em></p>

<p>Google’s privacy policy also states:&nbsp;<em>“[w]e will not reduce your rights under this Privacy Policy without your explicit consent.”</em></p>

<p>The ACCC alleges that Google did not in fact obtain consumers’ explicit consent for this change to the privacy policy, and that Google’s statement that it would not reduce consumers’ rights without their explicit consent was therefore misleading.</p>

<p>“Google made a clear representation about how it would protect users’ privacy. The ACCC alleges that Google made changes without obtaining the explicit consent it had promised consumers it would obtain before altering how it protected their private information,” Mr Sims said.</p>

<p><strong>DoubleClick</strong></p>

<p>In 2008, Google acquired DoubleClick, a supplier of ad-serving technology services to publishers and advertisers.</p>

<p>Google now supplies DoubleClick’s services through its Google Ad Manager and Google Marketing Platform brands, which are the leading suppliers of ad-tech intermediary services.</p>

<p>These services track users’ internet activity on third-party sites that display ads through the use of DoubleClick’s advertising technology.</p>

<p>Google’s acquisition of DoubleClick required approval by competition authorities including the US Federal Trade Commission and the European Commission. The ACCC also reviewed and cleared this transaction.</p>

<p>FTC and EC cleared the acquisition, and in doing so considered submissions from Google that it would not be able to combine DoubleClick’s data on consumers’ internet activity with its own data about consumers’ activity on Google services because, at the time, DoubleClick’s contracts with its users prevented Google from doing so.</p>

<p>The agencies did not, however, rely on these submissions in clearing the acquisition.</p>

<p>Before 28 June 2016, Google collected and stored this information on a non-personally identifiable basis, as stated in its privacy policy.</p>

<p>On 28 June 2016, it changed its privacy policy by removing the term explaining how it would treat this DoubleClick data.</p>

<p><strong>Images</strong></p>

<p>Depending on the device and Google service being used by the consumer, the notification published by Google from 28 June 2016 was presented in a variety of ways. A copy of the notification in the form published to consumers using desktop devices is provided below for reference.</p>





<p><em>Source: Provided to the ACCC by Google Australia Pty Ltd</em></p>

<p>The relevant changes to Google’s Privacy Policy made on 28 June 2016 are also shown below for reference:</p>



<p>Source: Accessed from https://policies.google.com/privacy/archive?hl=en-US on 24 June 2020</p>

<p><strong>Background</strong></p>

<p>Google LLC (Google) is a multinational company incorporated in the United States with its headquarters in Mountain View, California. It is a subsidiary of Alphabet Inc.</p>

<p>Google supplies a range of services to consumers in Australia including Google Search, Google Maps, Gmail, YouTube, Google Play and Google Chrome.</p>

<p>Google also provides advertising services and analytics services to individuals and businesses. Advertising services are provided on Google services, such as Google Search, Google Maps and YouTube, as well as on websites and mobile device based applications not published or controlled by Google that partner with Google to display advertisements.</p>

<p>Google derives the majority of its revenue from its advertising and analytics services.</p>

<p><strong>Note:</strong> The concise statement has not been attached as it has been filed on a confidential basis pending claims by Google.</p>
</div></div></div></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/accc-alleges-google-misled-consumers-about-expanded-use-of-personal-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961881</guid>
            <pubDate>Mon, 27 Jul 2020 02:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Hard-to-Read Gravestones (2014)]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23961343">thread link</a>) | @vinnyglennon
<br/>
July 26, 2020 | https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/ | <a href="https://web.archive.org/web/*/https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://organizeyourfamilyhistory.com/reading-hard-read-gravestones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961343</guid>
            <pubDate>Mon, 27 Jul 2020 00:50:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Warren Buffett 1997 Email Exchange on Microsoft [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 136 (<a href="https://news.ycombinator.com/item?id=23961036">thread link</a>) | @breck
<br/>
July 26, 2020 | http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf | <a href="https://web.archive.org/web/*/http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sabercapitalmgt.com/wp-content/uploads/2019/12/BuffettRaikesemails.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23961036</guid>
            <pubDate>Sun, 26 Jul 2020 23:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Eng, the Master of the “Impossible Bottle”]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23960735">thread link</a>) | @fortran77
<br/>
July 26, 2020 | https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm | <a href="https://web.archive.org/web/*/https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="780">
  <tbody><tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot00.jpg" width="250" height="440"></td>
    <td colspan="2"><div>
      <h3>Harry Eng the Master Bottle Filler.</h3>
      <p>Harry was born in 1932 and died in 1996. He was  a school teacher, educational consultant, inventor, and magician. 
        A web search will tell you a little about his many talents but in summary: </p>
      <p><strong>Everything he did was intended to teach you to think. </strong></p>
      <p>Here are some of his bottles that are in the Puzzle Museum.</p>
      
      <p>This bottle contains his "Trademark" knot. It is, as always, too large to come out of the bottle, but also the stick  plus cord is too wide for the neck of the bottle.</p>
    </div></td>
  </tr>
  <tr>
    <td colspan="2"><p>One evening Harry was in a London hotel and decided to visit the Puzzle Museum the next morning. When he and his friends had finished their bottle of wine, he took the bottle up to his room. He then filled it with a book of matches, menu, and the pack of cards as a gift for us. This is a particular favourite as he assured us that the only tools he had were  a pencil and rubber bands. </p>
    <p>G135(AMB-POBJ) </p></td>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot01.jpg" width="250" height="622"></p></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot02.jpg" width="250" height="529"></p></td>
    <td colspan="2" rowspan="2">This is a "Loaded Deck". The deck is loaded with 6 shots. </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2">This incredible bottle has a bolt through 3 packs of playing cards. It is so tightly packed that there appears to be no room to get the nut on or off . </td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot03.jpg" width="250" height="523"></td>
  </tr>
  <tr>
    <td><p><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot04.jpg" width="250" height="491"></p></td>
    <td colspan="2"><p>Our venerable curator has gone nearly blind with a magnifying glass but has failed to find any sign of breaks or glue in this plank. It is a One Gallon Bottle and the plank measures about 14 cm x 12.5 cm x 1.8 cm thick.</p>
    <p>Even if one could use the key that is loose in the bottom of the bottle, the padlock on the bottom of the plank is too large to fit through the neck of the bottle.</p>
    <p>The plank is engraved with Harry's "Think" Logo. </p></td>
  </tr>
  <tr>
    <td colspan="2"><p>This was Harry's favourite. Made in 1991. The label records how it was made:</p>
    <p>"Find a piece of wood from the High Chaparral (Manginita wood). Drill Deck. Put case in bottle. Put cards in case. Put rope through deck. Tie knot. Put nut, bolt, and lock parts into bottle. Hold bolt with a magnet - screw nut on with dental floss. Assemble and lock padlock. Finally sign the pack of cards". </p></td>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot05.jpg" width="250" height="436"></td>
  </tr>
  <tr>
    <td><img src="https://www.puzzlemuseum.com/puzzles/amb/eng_botts/images/eng-bot06.jpg" width="380" height="444"></td>
    <td colspan="2"><p>This is Harry's ship in a bottle. <br>For details see<br> 
      <a href="https://www.puzzlemuseum.com/month/picm06/200608cutter.htm">Puzzle of the Month for August 2006</a> </p>
    </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</tbody></div></div>]]>
            </description>
            <link>https://www.puzzlemuseum.com/puzzles/amb/eng_botts/harry-eng.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23960735</guid>
            <pubDate>Sun, 26 Jul 2020 22:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small mail server best current practices]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 161 (<a href="https://news.ycombinator.com/item?id=23958599">thread link</a>) | @ebcase
<br/>
July 26, 2020 | https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/ | <a href="https://web.archive.org/web/*/https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <main>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
        <header>
          
          <time itemprop="datePublished" datetime="2020-07-24">July 24, 2020</time>
        </header>
        <p><em>(This post was originally written as a reply on the mailop mailing-list, but
a friend asked me to turn it into a blog post.  I've edited it, mostly
adding more links to elsewhere, but there are some additions here.)</em></p>
<p><em>Context: someone with a mail-server hosted in a German facility with a
poor reputation for handling abuse reports was asking for help on
sending email to their Gmail-using friends; they had SPF and didn't see
the point of DKIM; they had TLS setup for their mail-server, using a
certificate from CACert.</em></p>
<p>There's a PDF from Google from 2006 which is still worth reading:
<a href="https://research.google.com/pubs/archive/45.pdf">https://research.google.com/pubs/archive/45.pdf</a>, entitled
“Sender Reputation in a Large Webmail Service” by Bradley Taylor.
Anyone running a mail-server today needs to read that document.</p>
<p>If you don't send much email, then the only IP-based reputation which
Google can assess you on is the reputation of your address-block, so
being in a “troublesome” hosting provider will score heavily against
you.  At that point, if not moving away, you need to try to balance out
that negative score with enough positives that any of the large
providers using reputation scoring will accept the mail.</p>
<p>Working forward-and-reverse paired DNS is even more important for IPv6
than for IPv4; for better or worse, some of the large providers have
decided that exemptions in old standards for old behavior should not
apply when folks deploy standards which are far newer.  So you
absolutely need an <code>MX</code> record, you must not just rely upon
address-records (<code>A</code> and <code>AAAA</code>).</p>
<p>With a poor IP-based reputation, you need to see if you can score a
better domain-based reputation.  This is where DKIM comes into play:
once you can provably link a message to really be from a given domain,
then even if you don't send much mail you can benefit from stuff like
“not on day-old-bread domain-lists”.  But having DKIM and then a DMARC
record does help (and <a href="https://bridge.grumpy-troll.org/2014/04/dmarc-stance/">I'm no fan of DMARC</a>).</p>
<p>For the mail-server's TLS: for that to count in your favor instead of
being a wash, I strongly suspect that it needs to be a certificate which
senders can verify.  For those people scoring up for “better TLS”, those
senders using DANE will be happy with a TLSA record in DNSSEC for your
CACert anchor.  But the large webmail providers are Resistant to having
to deploy DNSSEC verification, so instead have pushed out an alternative
called MTA-STS.  With MTA-STS, you're tied into “whichever subset of CAs
all the large senders you care about will trust”, and then using that CA
for the certificates both for the MTA-STS web-server and for your
mail-server.  Note that you don't need to implement the client logic for
MTA-STS (and I think it's antithetical to an open federated platform)
but do need to just publish the static information for those senders who
do use it. At that point, CACert is not going to cut it.  You'd need to
try Let's Encrypt instead.</p>
<p>The ongoing natural tendency from larger providers is to favor
supporting what the majority of their users want the majority of the
time.  With so many people using larger providers, they naturally tilt
towards stuff which works with the larger senders, and requiring more
hoops.  Those additional hoops create more work for smaller providers
and self-hosters doing thing manually.</p>
<p>We need better automation tools around all of this.  The below will make
it clearer why.</p>
<p>So, here is my current understanding of the best current practices here,
in reality not IETF idealism.  This includes making mandatory stuff
which some folks insist must be optional, because realistically to send
to some large providers it's not optional.  This list includes features
to make you compatible with ongoing trends in the EU (particularly
Germany) to strongly disfavor allowing clear-text SMTP.</p>
<p>This assumes that you are <em>not</em> a large sender who should also be
setting up feedback loops, learning how to “warm” IPs, considering BIMI,
postmaster tooling domain verification, etc.</p>
<h3 id="deliverability-fixes">Deliverability fixes</h3>
<ol>
<li>reverse DNS with matching forward DNS; the name used should not
pattern-match anything generic and ideally would include a DNS label
of <code>mail</code> or <code>mx</code> or the like in it.</li>
<li>MX record, always.</li>
<li>Accurate SPF;
<ul>
<li>ideally not too broad; pay attention to SPF's query limits.</li>
<li>avoid <code>-all</code> at the end because, with the sole exception of “this
domain never sends email” records, the larger operators have metrics to
show that using <code>-all</code> <em>tends</em> to be a sign of over-enthusiasm rather
than reality, so it will slightly count against you;</li>
<li>remember to have an SPF record for your <code>HELO</code> hostname, because
when you send a “bounce” rejection, this is the thing which will be
looked up (since there's no domain in <code>&lt;&gt;</code>).</li>
</ul>
</li>
<li>DKIM set up, with thought towards the selector namespace.
<ul>
<li>RSA2048 key is effectively a hard-requirement
<ul>
<li>DNS TXT records consist of one or more DNS strings, each of which
is limited to 255 ASCII characters.  For a key of this size, you
will end up needing two DNS strings in the zonefile.</li>
</ul>
</li>
<li>Ed25519 keys are not yet widely supported, but by now are not
likely to actively break and make things worse for you, if you
dual-sign.  This needs to be a different selector.</li>
<li>Note that for various good reasons you should design this to be
something you routinely rotate.
<ul>
<li>Some folks use yearly, some monthly</li>
<li>I rotate every three months.</li>
</ul>
</li>
</ul>
</li>
<li>DMARC record; see <a href="https://tools.ietf.org/html/rfc7489" title="Domain-based Message Authentication, Reporting, and Conformance (DMARC)">RFC 7489</a>
<ul>
<li>But for domains which humans send from <em>don't</em> use
<code>p=quarantine</code> or <code>p=reject</code>;</li>
<li>Do consider setting up a receiver for reports, just so that you can
see how much of a privacy breach DMARC reporting is when you send
to mailing-lists which don't re-sign. :-/</li>
</ul>
</li>
<li>TLS certificate from a CA in the main trust anchor bundles;
<ul>
<li>Just use Let's Encrypt.</li>
</ul>
</li>
<li>MTA-STS web-server with HTTPS certificate from the same CA, and the
relevant MTA-STS txt file in place; add the DNS record when it's up
and happy.  See <a href="https://tools.ietf.org/html/rfc8461" title="SMTP MTA Strict Transport Security (MTA-STS)">RFC 8461</a>.
<ul>
<li>See <a href="https://esmtp.email/tools/mta-sts/">https://esmtp.email/tools/mta-sts/</a> for a testing validation tool
(with thanks to Luis Muñoz for the pointer).</li>
</ul>
</li>
<li>For the independent mail providers using the stuff broadly supported
in open source MTAs, you should look at DNSSEC, because the patterns
here are less susceptible to rent-seeking pressures:
<ul>
<li>DNSSEC-signed zone for your own domain
<ul>
<li>Use whichever signing algorithm CloudFlare are currently using:
this should be both current for cryptography and widely enough
supported that if it's not supported by someone's resolver, then
they have bigger problems than just your domain.</li>
</ul>
</li>
<li>DNSSEC validating resolver for you to look up records of others
(consider <a href="https://nlnetlabs.nl/projects/unbound/about/">Unbound</a> or <a href="https://www.knot-resolver.cz/">Knot Resolver</a>)</li>
<li>DANE records for your own domain (TLSA records in DNS)
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc7672" title="SMTP Security via Opportunistic DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS)">RFC 7672</a> for the SMTP details.</li>
<li>See <a href="https://tools.ietf.org/html/rfc6698" title="The DNS-Based Authentication of Named Entities (DANE) Transport Layer Security (TLS) Protocol: TLSA">RFC 6698</a> for the base spec with <a href="https://tools.ietf.org/html/rfc7218" title="Adding Acronyms to Simplify Conversations about DNS-Based Authentication of Named Entities (DANE)">RFC 7218</a> for some common
acronyms which make talking about it easier.</li>
<li>See <a href="https://tools.ietf.org/html/rfc7671" title="The DNS-Based Authentication of Named Entities (DANE) Protocol: Updates and Operational Guidance">RFC 7671</a> for the updates and operational guidance.</li>
<li>There are other RFCs, for SRV records and for OpenPGP, etc.</li>
</ul>
</li>
<li>Tell your mail-server to obey DANE stuff, so that if there's a TLSA
record in DNSSEC-verified DNS then the mail-server can disable
fallback to cleartext for delivery to MX (and ideally also then
verify the TLS connection has a cert chain which is anchored in one
of the TLSA records)</li>
<li><a href="https://dnsviz.net/">https://dnsviz.net</a> is your friend</li>
</ul>
</li>
<li><code>_smtp._tls</code> record so you can get reports of TLS failures sending to
you</li>
<li>Seeing if you can get your IP onto one of the open DNS-based
allow-lists (also called “whitelists” but some folks are moving away
from that term), such as <a href="https://www.dnswl.org/">https://www.dnswl.org/</a> or Spamhaus's SWL.</li>
<li>Periodically check if you appear in any DNS-based deny-lists.</li>
<li>Make sure you're not sending from “ISP residential address-space”; if
need be route your mail outbound via a host in better address-space
(and update SPF etc to match)</li>
<li>Don't do sender call-out verification to SMTP servers which aren't
yours.</li>
<li>For your own sanity, do make sure you set up <a href="https://www.fail2ban.org/">fail2ban</a>, or something
like it, scanning your mail-server logs, because SMTP AUTH online
cracking is widespread.  If they ever get in, your deliverability
will be negatively impacted by their spam campaign through your
mail-server.</li>
</ol>
<h3 id="convenience-stuff">Convenience Stuff</h3>
<p>Outside of “Phil's BCP” above, additional non-deliverability but
convenience options include:</p>
<ol>
<li>DNS SRV records for submission(s)/imap(s)/pop3(s)/sieve, even if just
to say with «<code>0 0 0 .</code>» that it's not supported.</li>
<li>If your communications base includes people using OpenPGP with email,
then set up WKD to publish OpenPGP keys for your domain too.
<ul>
<li>This is just a fixed schema for laying out keys for HTTPS retrieval.</li>
<li>See the <a href="https://datatracker.ietf.org/doc/draft-koch-openpgp-webkey-service/?include_text=1" title="OpenPGP Web Key Directory">WKD draft</a> for details.</li>
<li>I wrote <a href="https://github.com/PennockTech/openpgpkey-control">https://github.com/PennockTech/openpgpkey-control</a> as a
management framework for an organization; the
<code>other/standalone-update-website</code> script is designed to be
embeddable into an existing site-building workflow without anything
else from the repository.</li>
<li>The GnuPG project has tooling available which manages the WKD layout as
an email-integrated workflow, for people to update their own keys.</li>
</ul>
</li>
<li>If your communications base includes people using S/MIME then set up
SMIMEA records in your DNSSEC-signed DNS.
<ul>
<li>They look a lot like TLSA records; both are trust anchors in DNS.</li>
<li>See <a href="https://tools.ietf.org/html/rfc8162" title="Using Secure DNS to Associate Certificates with Domain Names for S/MIME">RFC 8162</a> for details.</li>
</ul>
</li>
<li>The moment you start specifying “must be TLS-secured” it's worth
adding <code>CAA</code> records into DNS, so that Certificate Authorities which
are broadly trusted will refuse to issue for your domain unless you
list them.
<ul>
<li>See <a href="https://tools.ietf.org/html/rfc8659" title="DNS Certification Authority Authorization (CAA) Resource Record">RFC 8659</a> for details</li>
<li>The values checked by each Certificate Authority as indicating they
have permission are required to be listed in their Certification
Practice Statement, as part of the CA/Browser forum's Baseline
Requirements.  If it's missing, then browsers are not supposed to
be trusting that CA.</li>
<li>For domain-validation CAs such as Let's Encrypt, consider adding
account information to those records to tie it to your specific
account.  See <a href="https://tools.ietf.org/html/rfc8657" title="Certification Authority Authorization (CAA) Record Extensions for Account URI and Automatic Certificate Management Environment (ACME) Method Binding">RFC 8657</a> for details.</li>
<li>Beware that at time of writing, Let's Encrypt only honors the
<code>accounturi</code> restriction in their staging environment, not their
production setup; this will likely change.</li>
<li>Remember that DNS zonefiles support comments.  You'll want them</li></ul></li></ol></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</a></em></p>]]>
            </description>
            <link>https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23958599</guid>
            <pubDate>Sun, 26 Jul 2020 17:31:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signing .jars is not worth the effort]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23957663">thread link</a>) | @nurettin
<br/>
July 26, 2020 | https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html | <a href="https://web.archive.org/web/*/https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <figure>
<picture>


<source srcset="https://quanttype.net/images/path.jpg.webp" type="image/webp">

<img src="https://quanttype.net/images/path.jpg" alt="Duckboards make a serpentine curve over a marsh.">

</picture>
</figure>

<p>If you try to deploy a new release of Clojure library with
<a href="https://leiningen.org/">Leiningen</a>, it prompts you to sign the .jar file with GPG. This step
often causes confusion and breaks. I believe that it’s not worth the effort to
make it work.</p>
<p>As far as I know, <em>nobody ever verifies the signatures</em> in a systematic way.
There are a bunch of obstacles:</p>
<ul>
<li>It’s unclear if any tools for verifying the signatures actually work. For
example, I just tried to run <code>lein deps :verify</code> against a couple of projects
and it reported every dependency as <code>:unsigned</code>. I know that some of those
dependencies are signed and I verified that the <code>.asc</code> files exist on
repo.clojars.org.</li>
<li>It’s hard to find the public keys for the library maintainers. Sometimes they
upload them on the keyservers, sometimes not.</li>
<li>There’s no established way of communicating that which public keys should be
trusted. If there’s a new release and it has been made with a new key, your
best bet is to e-mail the maintainer and ask what is up.</li>
</ul>
<p>It’s hard to get any security benefits from the signatures in practice. Thus
it’s okay to set <a href="https://github.com/technomancy/leiningen/blob/998d373ae06d17234efffde761fae93242c736fa/sample.project.clj#L111"><code>:sign-releases</code></a> to <code>false</code> in your
project.clj even if Leiningen’s manual does not recommend it.</p>
<hr>
<p>In princple, the systematic checking of signatures could provide security
against a dangerous supply-chain attack: weak or leaked passwords for package
manager accounts. For example, <a href="https://arstechnica.com/information-technology/2019/08/the-year-long-rash-of-supply-chain-attacks-against-open-source-is-getting-worse/">several RubyGems</a> have been attacked
this way. Most likely the signing keys would not be compromised at the same
time.</p>
<p>There are alternative solutions, though, such as disallowing publishing packages
without multi-factor authentication. Using Clojars’s <a href="https://groups.google.com/forum/#!topic/clojure/GmAU4XwnRpw">deploy tokens</a>
helps a bit as well.</p>
<p>Right now we place a lot of trust on Clojars and Maven Central. If either of
them got compromised, we all would be screwed. Package signing could be a part
of a solution to mitigate that risk, but a comprehensive solution would be
something like using <a href="https://theupdateframework.io/">The Update Framework</a>. Go’s <a href="https://blog.golang.org/module-mirror-launch">checksum
database</a> is also worth taking look at.</p>
<p>Finally, if you’re moved to do something about this, please do not build
anything new using PGP. To quote Latacora: <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">PGP is bad and needs to go
away</a>.</p>
<hr>
<p>I’ve written this post in part to be proven wrong. I’m eagerly waiting for posts
from y’all about how you do, in fact, systematically verify the signatures.</p>

    </article></div>]]>
            </description>
            <link>https://quanttype.net/posts/2020-07-26-signing-jars-is-worthless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957663</guid>
            <pubDate>Sun, 26 Jul 2020 15:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorize Your CLI]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23957325">thread link</a>) | @danyspin97
<br/>
July 26, 2020 | https://danyspin97.org/blog/colorize-your-cli/ | <a href="https://web.archive.org/web/*/https://danyspin97.org/blog/colorize-your-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danyspin97.org/blog/colorize-your-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957325</guid>
            <pubDate>Sun, 26 Jul 2020 14:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote work is not necessarily a good thing for the worker]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 281 (<a href="https://news.ycombinator.com/item?id=23957278">thread link</a>) | @rbanffy
<br/>
July 26, 2020 | https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/ | <a href="https://web.archive.org/web/*/https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.seanblanda.com/content/images/size/w300/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 300w,
                            https://www.seanblanda.com/content/images/size/w600/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 600w,
                            https://www.seanblanda.com/content/images/size/w1000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 1000w,
                            https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.seanblanda.com/content/images/size/w2000/2020/07/z-yu-rR8o1kEBmMQ-unsplash.jpg" alt="Our remote work future is going to suck">
            </figure>

            <section>
                <div>
                    <p>As COVID-19 continues to alter the way we live, there is a scramble to predict what our “new normal” will look like. After the virus fades away or, God help us, becomes a constant in our day-to-day life for years to come, which change brought on by the pandemic will stick? </p><p>There is one consensus prediction that is emerging, especially among knowledge workers and those in tech: The distributed workforce is here to stay. And, furthermore, this change is a good thing for workers and welcomed by all.</p><p>To which I say: Um, have you ever worked remotely?</p><p>I have understood and enjoyed the perks of working remotely before. From 2009 to 2016 I wrote about entrepreneurs and creatives, many of whom were early proponents of remote work. And from 2017 to 2019, I worked remotely for a small, privately-owned e-learning company and then a 1000-employee SaaS company. </p><p>While the upsides to remote work are true, for many people remote work is a poison pill — one where you are given “control” in the name of productivity in exchange for some pretty nasty long-term effects.</p><p><strong>In reality, remote work makes you vulnerable to outsourcing, reduces your job to a metric, creates frustrating change-averse bureaucracies, and stifles your career growth.</strong> The lack of scrutiny our remote future faces is going to result in frustrated workers and ineffective companies.</p><p>Let’s tackle these issues one at a time. </p><h2 id="remote-work-democratizes-talent-for-everyone-even-you-">Remote work “democratizes talent” for everyone. Even you.</h2><p>In May 2020, <a href="https://blogs.gartner.com/manjunath-bhat/2020/05/03/remote-work-is-the-next-big-equalizer/" rel="noreferrer nofollow noopener">a Gartner blog post</a> summarized a common argument in favor of remote work: “Democratizing access to resources lowers the barriers to innovation and enables everybody to partake in the ensuing prosperity.” Not everyone can (or wants to) live in an urban commercial hub. Remote work, the thinking goes, allows people to live in whatever environment they’d like — depending on their own circumstances.</p><p>These remote technology jobs don’t just go to a version of you living on a cute farm in the Hudson Valley. Those jobs go to <em>anyone, anywhere.</em> </p><p>This is good for global prosperity and perhaps arguably inevitable. However, if you’re working in technology today as an American, you have tremendous earning potential. This earning potential may not be possible forever. It’s baffling to me that American workers would cheer an acceleration of this trend that would place downward pressure on their wages.</p><p>When you, the American worker, share this belief you are being blinded by an erroneous belief in American exceptionalism. When your company goes all-remote, it is starting a clock that ends in you eventually competing with the global talent market — especially if travel and visas continue to be restricted by the federal government.</p><p>A tech optimist will likely (and correctly) point out that more innovation and new technologies will replace any outsourced jobs. While my academic brain wants that to be true, I can’t help but see the devastating effects globalization had to our manufacturing workers and communities — many of which have never recovered or benefited from new innovations.</p><p>Innovation in the American economy didn’t get transferred one-to-one. Every manufacturing worker did not suddenly receive a tech job. Every technology worker outsourced will not receive the benefit of the next wave of innovation directly. </p><h2 id="remote-enables-you-to-be-forgotten">Remote enables you to be forgotten</h2><p>Remote work advocates often praise the focus that remote work enables. No longer will you be judged by the time you spend at the office, they say, you’ll instead be judged and rewarded on whether you “get things done.” </p><p>These “benefits” are always used to sell remote work to an imagined audience of Dilbert-like cubicle dwellers who are imprisoned and subjected by annoying coworkers and an oppressive boss. The key to freedom, they say, is to work remotely. Basecamp co-founder Jason Fried <a href="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html" rel="noreferrer nofollow noopener">writes in <em>Remote</em></a>:</p><!--kg-card-begin: html--><blockquote darkmode="" data-title="Working%20From%20Home%20Boosts%20The%20Quality%20Of%20The%20Work" data-author="Jason Fried&nbsp;" cite="https://www.inc.com/jason-fried/excerpt-remote-workers-boost-quality.html">
                      <p>What you're left with is "what did this person actually do today?" Not "when did they get in?" or "how late did they stay?" Instead it's all about the work produced. So instead of asking a remote worker "what did you do today?" you can now just say, "Show me what you did today." As a manager, you can directly evaluate the work--the thing you're paying this person for--and ignore all the stuff that doesn't actually matter.</p>
                      
                      </blockquote>
                      <!--kg-card-end: html--><p>First, being more productive isn’t the only goal of working, but let’s put that to the side. Second, Fried is right, you do gain a bit of freedom from your boss (which doubles as a loss of a mentor, but we’ll get to that). You also gain “freedom” from your colleagues and collaborators. Which means you’re effectively on your own. </p><p>This is empowering to some, but the isolation can mean your contributions are easily overlooked or misunderstood. As a result, I’ve noticed a disturbing trend at (especially larger) remote companies: Some managers often have no clue what their direct reports are doing and how they are doing it. </p><p>Performance reviews are difficult enough under normal circumstances. But how do you judge someone when you can only see their output and never their process? Marketers, project managers, product managers, growth marketers, and others spend their days supporting or maintaining existing things. &nbsp;</p><p>This a difficult problem that predates any shift to remote work. But when applied to remote work, a manager loses several of the inputs needed to judge a direct report’s output — including, yes, who is physically (and mentally) present when actual work is being done. But also: Do the other team members appear to enjoy working with this person? And, if they are struggling, is it due to a lack of effort/focus or something outside of their control? </p><p>Employees who “do the right thing” spending extra time and energy supporting their teammates receive absolutely no recognition for doing the little things needed for a smooth-running, collaborative organization. It’s usually a quantifiable fact whether a sales departments reaches their goals. It’s not as clear that the social media manager had a good quarter.</p><p>With the removed context of a real-life office, your team’s output is difficult to individualize for your manager — especially if work is done in private DMs or one-on-one Zoom calls. The manager sees the end product with no visibility as to who did what, who pulled their weight, who made tough choices, and who made things more difficult. This has a nasty side effect of the leader viewing you less as a person who they have to empathize with and understand — and more as a talking head on a Zoom call or Slack who does things for them. </p><p>This will cause your work to “flatten.” Whatever soft skills you bring to the table will be minimized when working remotely. This will lead to companies and processes relying less on things like creativity and collaboration and more on simple inputs and outputs. Which, again, makes your work easier to outsource.</p><p>We bemoan the loss of empathy and context created by solely getting our news and interacting via social media … and we then turn around and set up our working lives in their image.</p><p>This has a pronounced effect in large organizations.</p><h2 id="remote-work-breaks-large-companies">Remote work breaks large companies</h2><p>Remote work supporters often return to the “interruption culture” at an IRL office as an argument for distributed work. First, clearly people that believe remote work creates an interruption-free zone have never used Slack or email. Second, those interruptions often exist for a reason: They often communicate information that ensures everyone is working on the right thing.</p><p>For companies that have strong product/market fit, have reached scale, and have a clear product roadmap, remote works swimmingly. A distraction-free environment means everyone can focus on “what matters” because “what matters” has been clear and consistent. &nbsp;</p><p>But what happens when “what matters” changes? </p><p>Because it will. Eventually, the market shifts. There’s a competitor or a Black Swan-style event in the industry (like, say, a global pandemic). Suddenly the well-oiled machine needs to adapt and change course. For companies larger than 100 people, this is tremendously difficult in an in-person environment. Working remote, it’s damn near impossible. Twice-a-year in-person meetups are not enough to disseminate brand new strategies. </p><p>And I'd bet that as formerly IRL companies go remote, it will have a negative effect on their ability to iterate and adjust to market conditions making them vulnerable for a smaller, co-located upstart.</p><h2 id="remote-work-can-stifle-your-career-growth">Remote work can stifle your career growth</h2><p>Think back to your first job in your current field. I’d bet there is a person or group of people who were tremendously important in shaping your career. They gave you candid advice and were able to passively observe and critique your behavior.</p><p>When you work remotely, mentorship is stifled because there is no learning via osmosis. You can’t model your behavior on your successful teammates because you only see them on Zoom and in Slack. Whatever process they are using to achieve their results is opaque to you. </p><p>Much of the language used around remote work (and remote events) assumes that one is in the mid-to-late stages of their career. When you’re young, you don’t need “focus” or to “get things done.” You need exposure to new ideas and people. You need the serendipitous fortune of sitting in on the right meeting, attending the right happy hour, or earning the respect of the right observer.</p><p>All of the above is more difficult in a remote environment. As a result, we are in danger of having a generation of new knowledge workers who are never properly onboarded and hastily told to work remotely with nothing but an OKR to chase. They have no context for how to do all of the messy office-ready skills like building consensus, having productive disagreements, and advocating for their ideas.</p><p>Additional…</p></div></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/">https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</a></em></p>]]>
            </description>
            <link>https://www.seanblanda.com/our-remote-work-future-is-going-to-suck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23957278</guid>
            <pubDate>Sun, 26 Jul 2020 14:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding Gene Cernan's Missing Moon Camera]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23956771">thread link</a>) | @uptown
<br/>
July 26, 2020 | https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera | <a href="https://web.archive.org/web/*/https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5e5ee63acb9e965b95a34c71" data-item-id="5e5ee63acb9e965b95a34c71">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1583277661007" id="item-5e5ee63acb9e965b95a34c71"><div><div><div data-aspect-ratio="100.80906148867315" data-block-type="5" id="block-yui_3_17_2_1_1583276156349_38578"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg" data-image-dimensions="1920x1981" data-image-focal-point="0.5,0.5" alt="Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17." data-load="false" data-image-id="5e5ff5accacd55785de67f35" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1583347117747-139CXE1Z4V06A2R9DZTP/ke17ZwdGBToddI8pDm48kEShyqQ9O1OHn77DDyKnJG17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USgZjwvdKoQqiLv-vLpSRt4LEvWluek6h9YHD7M-gaCITcn62T-SmTYC0sJwT9G4IA/Apollo_17_Cernan_on_moon.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Gene Cernan photographed by Harrison Schmitt with the camera on Apollo 17.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594000429895_118575"><div><h2>The mystery of its location</h2><p>It’s often repeated how most of the cameras that landed on the moon stayed on the moon. Astronaut Gene Cernan had been telling the story of how<a href="https://petapixel.com/2012/12/06/the-last-man-to-walk-on-the-moon-left-his-camera-for-a-long-term-gear-test/" target="_blank"> he left his camera</a> on the lunar rover<a href="https://www.telegraph.co.uk/news/science/space/9728289/Apollo-17-commander-left-camera-on-moon-40-years-ago.html" target="_blank"> for years</a>, recounting the tale in interviews:</p><blockquote><p>"I left my Hasselblad camera there with the lens pointing up at the zenith, the idea being someday someone would come back and find out how much deterioration solar cosmic radiation had on the glass. So, going up the ladder, I never took a photo of my last footstep. How dumb! Wouldn’t it have been better to take the camera with me, get the shot, take the film pack off and then (for weight restrictions) throw the camera away?"</p></blockquote><p>It’s easy to accept Cernan at his word - he’s an American hero who flew to space three times, twice to the moon - so as far as everyone was concerned, including the press, the camera was right where he said he left it. Plus, a quick scan of the Apollo 17 stowage list reveals no mention of a lunar surface camera splashing down with the command module. So why the mystery? </p><p>Looking closer, there’s a sprinkling of evidence in photos and transcripts that suggest his camera did in fact return to earth, contradicting both the 1972 NASA inventory and the astronaut. No, don’t cue the dramatic music… there’s no mischief or intentional deception here. I believe Gene Cernan did leave a camera on the lunar rover, just not “his.”&nbsp;Memory can be a fickle thing, even for heroes, and that rings especially true in this case&nbsp;when the story involves not one camera, but three.</p><h2>A tale of three cameras</h2><p>When you’re going to the moon, you’re assigned a camera with a 60mm lens that gets strapped to your chest to document samples, experiments, and the lunar terrain. Both astronauts get their own, clearly labeled with a sticker on the side: “CDR” for commander and “LMP” for lunar module pilot, but they weren’t mutually exclusive, often being swapped throughout the mission based on what film they were shooting with. On Apollo 17, Jack Schmitt - LMP and geologist extraordinaire - was set up with the black &amp; white film. When he needed color, he’d grab Cernan’s camera and vice versa. </p><p>A third Hasselblad camera was also to be used on the mission; it was a bit of a beast really, boasting a 500mm telephoto lens meant to capture distant lunar features for, you know… science. Of the two astronauts, Cernan got stuck looking down the barrel of the 500mm the most, so it’s entirely possible that <em>this</em> is the camera he remembers leaving on the rover. In fact, the post-flight analysis of the transcript pretty much confirms it. But what happened with the other two?</p><h2>The stowage list says they stayed </h2><p>A little background. As each Apollo mission launched, NASA prepared a final stowage list that documented all the equipment aboard, detailing what was to be transferred between each spacecraft before and after landing on the moon. This list was then revised in real time as plans changed due to time or weight restrictions. In the latest revision of the <a href="https://www.hq.nasa.gov/alsj/a17/a17stowage.pdf" target="_blank">Apollo 17 LM Lunar Launch Stowage List</a>, dated December 12th, 1972, the three cameras that went down in the LM are all marked as “offloaded,” meaning they were left on the surface. The problem is, they launched from the moon on December 13th! So if extra items were brought onboard, it’s not recorded. At least not in what’s available online.</p></div></div><div><div><div data-aspect-ratio="55.70987654320988" data-block-type="5" id="block-yui_3_17_2_1_1594649779919_85920"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Two Hasselblad Data Cameras with 60mm lenses marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1594000429895_28896"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>One Lunar Surface Camera with 500 lens marked as “Offloaded” in the AS17 LM Lunar Launch Stowage List</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594649779919_62191"><div><h2>The <a href="https://www.hq.nasa.gov/alsj/a17/a17.clsout3.html#1702716" target="_blank">audio</a> says otherwise</h2><p>The next logical step was to check the transcripts to see if it was possible to follow the cameras by listening to what was happening. As you read the following excerpt, Cernan and Schmitt are both standing by the final resting place of the lunar rover at the end of their last EVA.</p><blockquote><p>169:29:44<strong>&nbsp;Parker [Mission Control]:</strong> ...and, Jack, <strong>we're making plans here, to change the camera usage at the end of EVA here.</strong> And we're going to let you take Commander's camera out to the ALSEP and take a few photos which people think we need. And Gene's going to take your camera out and document the geophone, when he deploys it. We will not deploy it for the long-term experiment, however. <strong>And we'll bring both (cameras) back, and carry them to the ETB when we get done.</strong></p><p>169:30:17&nbsp;<strong>Cernan:</strong> Okay.</p><p><em>[When he said "document the geophone", Bob may have been referring to documentary photos of the seismic charge Gene will deploy near the VIP site. "When he deploys it" probably refers to the charge and the phrase "we will not deploy it for the long-term experiment" refers to a planned deployment of the camera on the Rover seat as indicated on checklist page&nbsp;</em><a href="https://www.hq.nasa.gov/alsj/a17/a17eva3_cdr30.gif" title="image" target="new"><em>CDR-3</em></a><em>2. </em><strong><em>Specifically, the checklist calls out "Pos(ition) LMP cam(era) vert(ically) on seat."</em></strong><em> Gene remembers that he did put the camera on the seat, with the lens pointed at the zenith. Presumably, the intent was to recover the camera at some future date to get information of long-term exposure to the lunar environment.]</em></p><p>[Cernan - "Parker said 'We'll bring them both (that is, both cameras) back,' but I know what I did with that camera. I left it on the Rover pointed straight up. <strong>That's what I planned to do and that's what I did. </strong>I can remember specifically wedging it - I don't remember exactly where - somewhere up between our seats."]</p></blockquote><p><em>&gt;&gt;&gt;&gt; Fast forward to where the astronauts are now back at the LM &gt;&gt;&gt;&gt;</em></p><blockquote><p>170:39:59&nbsp;<strong>Parker [Mission Control]: </strong>Okay, and we gather an ETB coming up with two cameras in it.</p><p>170:40:04&nbsp;<strong>Schmitt:</strong> ETB's next. (Pause) (To Gene) Got an ETB? Yeah. (Pause) ETB has two cameras.</p></blockquote></div></div><div data-aspect-ratio="94.44444444444444" data-block-type="5" id="block-yui_3_17_2_1_1594747724966_190880"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594825976236-1SVG5OGUZT2EP651YJXF/ke17ZwdGBToddI8pDm48kOabQMA48lNEHEge2DHP_4BZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVG80vl9d_s-qFVXDXCvZPrcxRtjF1HoAkofddffLg65SWQ6l2WM7tn7mqHTODzkmeM/image-asset.gif" data-image-dimensions="378x380" data-image-focal-point="0.5,0.5" alt="CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera" data-load="false" data-image-id="5f0f1cf80254b81fb47dba1f" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>CDR Checklist pg. 32 instructing Gene Cernan to leave the LMP camera</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594747724966_196522"><div><p>Ok, let’s unpack this:</p><ol data-rte-list="default"><li><p>NASA deviates from the flight plant requesting the astronauts swap cameras:<strong> Schmitt is to return to the LM with Cernan’s CDR camera</strong>, and Cernan is to use Schmitt’s LMP camera at the rover.</p></li><li><p>When they’re done, both CDR and LMP cameras<strong> are to be brought back into the LM</strong> using the equipment transfer bag (ETB). </p></li><li><p>On Gene’s cuff checklist was an item to “Position the LMP camera facing up on the seat of the rover,” leaving it behind, but because NASA had just asked for that camera to be returned, Gene, following the checklist, positions the 500mm in its place, returning to the lunar module with the LMP in hand.</p></li><li><p>Two cameras, the CDR and LMP, are then confirmed in the ETB going up to the LM.</p></li></ol><p><em>&gt;&gt;&gt;&gt; Fast forward again to the astronauts inside the LM after a rest period &gt;&gt;&gt;&gt;</em></p><blockquote><p>183:40:17&nbsp;<strong>Fullerton [Mission Control]:</strong> Challenger, Houston. One update for the post-sleep procedure. I understand you brought in the LMP's camera, and we want to be sure you get that into the&nbsp;<a href="https://www.hq.nasa.gov/alsj/alsj-JettBag.html" target="new">jett bag</a>&nbsp;before the final jettison here. And, by the way, you're Stay for that final jettison.</p><p>183:40:39&nbsp;<strong>Schmitt: </strong>Okay, Gordy. It's already in the jett bag, thank you. (Pause)</p><p><em>[</em><strong><em>Cernan </em></strong><em>- "Obviously, I did not leave the LMP's camera on the Rover pointed at the zenith. But I swear I put something there. It's possible it could have been the 500 lens, because we didn't bring it back and I mentioned it was under the seat. I know that I did something with a camera. Now, it could have been a lens. And I stuck it between the seats, sort of wedged it in somewhere, and pointed the lens toward the zenith."]</em></p><p>[<strong>Schmitt </strong>- "Houston wanted us to jettison the camera because they didn't want us to take pictures of Ron Evans' EVA. They had decided it was too cumbersome and too risky. But, we were going to ignore them, and we figured out how we could do it. But we needed a camera. Ron had a camera, but it was not EVA-qualified."]</p><p>[<strong>Cernan</strong> - "We had made up our minds we were going to take pictures of Ron."]</p><p>[<strong>Schmitt </strong>- "And we needed a lunar-surface camera to do it."]</p><p><strong>[Cernan - "Now, we did put the LMP's camera in the jett bag, so we must have had mine."]</strong></p></blockquote><p>*Click*. Finally, we have some clarity. One 500mm camera stays behind, and of the two that go up into the LM, the LMP camera gets jettisoned back to the surface before launch. Cernan’s camera leaves with them as they blasted off live on TV and in color.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1594997167739_70248"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg" data-image-dimensions="1721x1721" data-image-focal-point="0.5,0.5" alt="At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover." data-load="false" data-image-id="5f11ba2ee9f8df4e02356918" data-type="image" src="https://images.squarespace-cdn.com/content/v1/53ed2ba5e4b063ce9289be49/1594997298011-8DXNEGQSWGZDHEZH9I0P/ke17ZwdGBToddI8pDm48kLinFFHfOWxXfI2MB8J8Z5F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeCxvKzvbr2aY_wkb4kfp5UNe_pYlreFWyc7yFYM3uBMtrU8UFk4BXyUXL-Dw_TrVg/500.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>At the end of EVA-3, Jack Schmitt removes film magazine “N” from the 500mm camera, visible on the lunar rover.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594997167739_107441"><div><h2>The photos confirm it</h2><p>Every lunar camera has a unique serial number, usually etched into a piece of glass that’s pressed against the film plane. It’s known as the Réseau plate, used to help scientists both accurately measure objects in view, and identify what camera took what image.&nbsp;By simply <a href="https://tothemoon.ser.asu.edu/gallery/Apollo/17/Hasselblad%20500EL%20Data%20Camera%2070%20mm" target="_blank">looking through the …</a></p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera">https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</a></em></p>]]>
            </description>
            <link>https://www.spacecamera.co/articles/2020/3/3/gene-cernans-missing-lunar-surface-camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956771</guid>
            <pubDate>Sun, 26 Jul 2020 13:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Surprise AWS Bill]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 305 (<a href="https://news.ycombinator.com/item?id=23956671">thread link</a>) | @oaf357
<br/>
July 26, 2020 | https://chrisshort.net/the-aws-bill-heard-around-the-world/ | <a href="https://web.archive.org/web/*/https://chrisshort.net/the-aws-bill-heard-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><h2 id="scene">Scene</h2><p>It was a bright, Saturday morning, July 4, 2020. I had just gotten Max all situated with breakfast and cartoons (Mighty Mike, if you’re curious). Julie was sleeping in like she usually does on every day I have off. I’m an early riser and this is a cherished part of our co-parenting. It gives Max and I time to bond (when he’s not stuffing his face and laughing at cartoons). I sat down with my laptop to plow through the week’s personal email.</p><h3 id="the-e-mail">The e-mail</h3><p>“Oh look, the AWS bill, I should have a laugh at that,” I thought to myself. Until recently, it had been pennies a month for some very light SES usage. In February, I moved off Google Cloud back to AWS. The primary motivation was that Google had so intertwined GSuite and GCP IAM that it became overly confusing.</p><p>Along with that migration came the CDN for this web site (cdn.chrisshort.net). I mean <a href="https://chrisshort.net/low-cost-content-delivery-network-cdn/">a Cloudflare fronted S3 bucket that holds assets deemed too big for git</a> when I say CDN. It’s not even <a href="https://chrisshort.net/">chrisshort.net</a> itself, as it is hosted on Netlify’s CDN and every other static site I own or manage. I’ve been a Cloudflare user for a long time. The CDN is less than 300 files and has existed for over five years on various clouds. Moving it back to AWS from GCP bumped the AWS bill to an average of $23/month. Not too bad given the <a href="https://app.usefathom.com/share/suwvjwwc/chrisshort.net">site’s traffic</a>.</p><h3 id="the-shock">The shock</h3><p>Not on this Saturday morning, nope. June 2020’s AWS bill was a heart palpitation causing <strong>$2,657.68</strong> (<a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/invoice498711077_redacted.jpg">JPG</a>). I audibly gasped, “Keep your shit together.” I thought to myself. Max was leaned up against me drinking his milk. I know he could tell something was wrong because he looked at the laptop screen. I only assume when he saw letters and numbers, he thought, “Adult stuff… These cartoons and this Cinnamon Toast Crunch tho.” 2020 being the year that it is and my military history being what it is, I’ve been diagnosed with a panic disorder (on top of the PTSD and physical injuries).</p><h3 id="the-panic">The panic</h3><blockquote data-dnt="true"><div lang="en" dir="ltr"><p>Good morning, $2700 AWS bill!</p><p>Holy shit...</p></div>— Chris Short (@ChrisShort) <a href="https://twitter.com/ChrisShort/status/1279406322837082114?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><p>I immediately began having a panic attack. As I took the mental steps to mitigate the onset of the panic attack, I started forming a battle plan. Yes, I can switch back to emergency mode, like back in the old days, when something would go bang or boom, and I’d run towards it (it’s not helpful overall, trust me).</p><p>First, Max: Maslow’s Hierarchy of Needs? Check.<br>Next, me: As if it was destined, my alert for morning medications went off.</p><p>“Daddy’s gotta grab his meds, bud.” Instinctively, Max leans off me (wow… okay… he’s used to hearing that reminder and statement shortly after that; my brain is now in overdrive). I take everything I need to conquer this while still being able to function cognitively. I refill my coffee and grab a laptop charger.</p><h2 id="incident-response">Incident response</h2><p>Check the source of truth.</p><p>What’s diverged?</p><p>How do we get things back to normal?</p><p>I login to the AWS console, hoping I got some output that was uniquely off this month. Weirder stuff has happened (like <a href="https://aws.amazon.com/message/41926/">S3 going down</a>). This bill couldn’t be more out of the norm than ever. This AWS bill is several hundred dollars more than our mortgage! I hit the AWS Billing page and am deeply saddened by what I see:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/1f2dd17bc5d8e1407c22b84f7f981a7ad9888eba/8e235/the-aws-bill-heard-around-the-world/aws-bill-landing-page.png" alt="AWS Billing landing page showing a $2,657.68 balance"></p><p>There it was. <strong>$2,657.68</strong>, staring at me. “This can’t be legit.” Drilling down even further, it looks like it is indeed legitimate traffic from the cdn.chrisshort.net S3 bucket in us-east-2. In total, <strong>more than 30.6 terabytes of traffic</strong> had moved out of that one S3 bucket. WHEN?!? Did this just happen? Nope.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/3373f05e910b0938aeed4a2975b4b4f48922fdc0/2e223/the-aws-bill-heard-around-the-world/aws-june-2020-data-transfer.png" alt="AWS data transfer billing break down"></p><p><img src="https://d33wubrfki0l68.cloudfront.net/46294144a86a5d64df074d306386b3024b7d882a/af2d6/the-aws-bill-heard-around-the-world/june-23-24-2020-s3-breakdown.png" alt="S3 Activity"></p><p><strong>30.6 TB?!?!</strong> how is that even possible???<br>$1,011.59 on 23 June 2020.<br>$1,639.07 on 24 June 2020.</p><p>I immediately open a ticket with AWS Support frantically wondering what broke? How is this even possible? Did someone bypass Cloudflare? What the hell is Cloudflare saying?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/6cd3322753f262dc51bbca44a07fef6b19b381e9/52aec/the-aws-bill-heard-around-the-world/cloudflare_june_22_2020.png" alt="Cloudflare 22 June 2020"><br>Oh cool, Cloudflare let those 2,700 requests passthrough completely uncached? How is that not anomaly detected as a DDoS??? How is it that barely a fraction of the traffic is cached (more on that later)?</p><p><img src="https://d33wubrfki0l68.cloudfront.net/a0f7d1526c44cb74baba13f749f3d5a886bbdadb/6d2b1/the-aws-bill-heard-around-the-world/cloudflare_june_23_2020.png" alt="Cloudflare 23 June 2020"><br>Oh, another 4,400 requests the next day… Sweet, baby Jesus. Oh, but you served 9 GB from cache. Thanks, Cloudflare.</p><h2 id="help-arrives">Help Arrives</h2><p>Apparently, when you tweet something crazy af, like a $2700 AWS bill, it gets a lot of attention on a quiet holiday morning. A quarter-million people saw the tweet and a third of them interacted with it. It was enough attention that the AWS Support Twitter account was on it before, <a href="https://twitter.com/QuinnyPig/status/1186319925901586432">my friend</a> and <a href="https://www.duckbillgroup.com/">cloud economist</a>, Corey Quinn.</p><blockquote data-dnt="true"><p lang="en" dir="ltr">Oh no! 😰 Sorry to hear about this unpleasant Saturday morning surprise, Chris. Please create a support case so our agents can help get to the bottom of this: <a href="https://t.co/weTUnSYLRU">https://t.co/weTUnSYLRU</a>. 🕵️‍♀️ ^HG</p>— AWS Support (@AWSSupport) <a href="https://twitter.com/AWSSupport/status/1279424879566163970?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>Praise Twitter for at least its ability to draw attention to things. I am not sure this would’ve ended up as well as it did without it.<blockquote data-dnt="true"><p lang="und" dir="ltr"><a href="https://t.co/tUrNnXqWMY">pic.twitter.com/tUrNnXqWMY</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1279446759664611329?ref_src=twsrc%5Etfw">July 4, 2020</a></blockquote><br>I forwarded the bill to Corey almost immediately after seeing it at pre-dawn west coast time. I am forever thankful to Corey for his analysis. When he was ready, Corey sent me a list of things he needed to do an analysis (instead, I created him a regular IAM account with the proper perms 😉 and yes I cleaned up after).<p>Corey encouraged me to apply a bucket policy that would only allow Cloudflare IP addresses to access anything from the bucket. The theory here is that someone could have been bypassing Cloudflare somehow. But, thankfully, <a href="https://www.cloudflare.com/ips/">Cloudflare publishes their IP blocks</a> and they don’t change all that often. The Cloudflare support article, <a href="https://support.cloudflare.com/hc/en-us/articles/360037983412-Configuring-an-Amazon-Web-Services-static-site-to-use-Cloudflare#77nNxWyQf69T1a78gPlCi9">Configuring an Amazon Web Services static site to use Cloudflare</a> gives you an example bucket policy to do exactly that. This should become a standard practice for folks. However, it wouldn’t have mattered in this case; more on that later.</p><p>Corey Quinn’s thread on the topic covers what happened on the AWS side pretty well:</p><blockquote data-dnt="true"><p lang="en" dir="ltr">That's right--it's threading time!<a href="https://twitter.com/ChrisShort?ref_src=twsrc%5Etfw">@chrisshort</a>'s surprise <a href="https://twitter.com/awscloud?ref_src=twsrc%5Etfw">@awscloud</a> bill of $2700 looks S3 driven... <a href="https://t.co/VnXufn24iA">https://t.co/VnXufn24iA</a> <a href="https://t.co/tKLWv5rHtW">pic.twitter.com/tKLWv5rHtW</a></p>— HydroxyCoreyQuinn (@QuinnyPig) <a href="https://twitter.com/QuinnyPig/status/1280280727133642753?ref_src=twsrc%5Etfw">July 6, 2020</a></blockquote><ul><li>”…it’s almost entirely due to us-east-2 data transfer out…”</li><li>“Now, what caused this? Nobody knows!”</li><li>“Chris Short isn’t some random fool…” (Might be the nicest thing Corey’s every said about anyone he’s not related to)</li><li>”‘Surprise jackhole, your mortgage isn’t your most expensive bill this month, guess you shoulda enabled billing alarms!’ is crappy, broken, and WOULD NOT HAVE SOLVED THE PROBLEM!”</li><li><a href="https://twitter.com/QuinnyPig/status/1280289410844471296?s=20">“I want to be explicitly clear here: Chris Short didn’t do anything wrong!”</a></li></ul><h2 id="but-wait-there-s-more">But wait! There’s more!</h2><p>I had tickets in with Cloudflare (1918916) and AWS (7153956931). Cloudflare was the least helpful service I could have imagined given the circumstances. A long term user and on and off customer thinks they were attacked for two days and you don’t lift a finger? If I didn’t have reason enough to move off of Cloudflare, I do now. That’ll be an update for a later blog post. But, if you work for a CDN company and you’re relatively painless to get up and running, I’m interested in hearing from you.</p><p>After a very chaotic morning, I take Corey’s advice, disconnect, and enjoy the holiday weekend.</p><h2 id="more-help-arrives">More Help Arrives</h2><p>On July 8th, an astute AWS employee starts doing some digging around and reaches out to me. Because they see this as bafflingly as Corey and I do. How did so few requests generate so much traffic so quickly and then as soon as it appears, it’s gone again? It doesn’t seem like something intentionally malicious either because Cloudflare and AWS let it right on through.</p><h3 id="here-s-the-theory">Here’s the theory</h3><p>In hindsight, I made a poor decision to distribute a trial Windows 2019 SQL Server virtual machine images (fully patched with all necessary drivers and VM extensions) in the form of a qcow2 file. Someone became aware of the existence of this VM image. They then stood up hundreds, potentially thousands, of copies this VM using the internet accessible URL. This is, in theory, possible, with something like <a href="https://chrisshort.net/tags/kubernetes/">Kubernetes</a> and <a href="https://kubevirt.io/">Kubevirt</a>. Given that the disk image becomes a volume mount in the corresponding VMs pod. Spin up enough copies of the VM, a single YAML file can create infinite copies of a VM. If the YAML definition directly referenced the Cloudflare or S3 URL and not a locally cached copy, you can rack up the number of times you pull down an image real quick. The qcow2 image, in this case, was 13.7 GB. But it’s trickier than that.</p><h3 id="the-sharp-edge-of-the-cloud">The sharp edge of the cloud</h3><p>File this under, “Things I should’ve known but didn’t.” Did you know that “The maximum file size Cloudflare’s CDN caches <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files."><strong>is 512MB</strong></a> for Free, Pro, and Business customers and 5GB for Enterprise customers.” That’s right, Cloudflare saw requests for a 13.7 GB file and sent them straight to origin every time <em>BY DESIGN</em>. <strong>Ouch!</strong></p><p>I suspected these files immediately on July 4 and moved them to an internal work GDrive for the time being. If you need the images, let me know, you’re also a suspect if you ask for them, be warned.</p><p>If you’re sitting at home doing the math, something might not be adding up. The bandwidth cost is off, there was indeed some legitimate traffic to the bucket in June, of course, But, as it turns out the intrepid AWS employee discovered that 3655 partial GETs to the object might have actually been delivered as full file requests and Cloudflare might have ever done anything with them. Yes, this is a bug somewhere and folks are looking into it. I also suggested that object size limits be a tunable S3 bucket policy. This way, I wouldn’t have even been able to upload the files to the bucket, to begin with.</p><h2 id="the-resolution">The Resolution</h2><p>As I mentioned, I’ve removed the multiple gigabyte files from the bucket the day I got the bill (July 4). <a href="https://twitter.com/QuinnyPig/status/1280282363461726208">Corey pointed that out here</a>. That might have hindered the investigation from the AWS side. I won’t be so quick to delete in the future. I will lock files down though. But, let’s face it. Now that I’m aware of the <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#:~:text=The%20maximum%20file%20size%20Cloudflare's,request%20caching%20of%20larger%20files.">512 MB file limit at Cloudflare</a>, I am moving other larger files in that bucket to <a href="https://archive.org/">archive.org</a> for now (and will add them to my supported <a href="https://chrisshort.net/causes/">Causes</a>).</p><p>Long term, I won’t want to store files in …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisshort.net/the-aws-bill-heard-around-the-world/">https://chrisshort.net/the-aws-bill-heard-around-the-world/</a></em></p>]]>
            </description>
            <link>https://chrisshort.net/the-aws-bill-heard-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956671</guid>
            <pubDate>Sun, 26 Jul 2020 12:40:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Emergency Remote – Actions to win remote work]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23956482">thread link</a>) | @oDot
<br/>
July 26, 2020 | https://www.emergencyremote.com/emergencyremote | <a href="https://web.archive.org/web/*/https://www.emergencyremote.com/emergencyremote">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
      
      
      <div id="title">
        <p><img alt="" src="https://www.emergencyremote.com/images/image1.jpg"></p>
      </div>
      
      
      
      
      

      
      
      
      <p>
        <span>Emergency Remote is a book of opportunity. It lights the way to turn a forced
          remote work situation into a great management success. It contains simple steps
          that will help you not only keep operating, but blow away the competition.</span>
      </p>
      
      <p>
        <span>Some believe they can work from home as if they are in the office. "Just add
          some tools for video calls and everything will work just fine", they say.
          This cannot be further from the truth. Setting up video is to successful remote
          work as setting up tables is to successful onsite work. You'll probably use
          it, but it's not nearly enough.</span>
      </p>
      
      <p>
        <span>Emergency Remote is divided into three succinct sections. The first discusses the
          underlying values required for remote work to function, the second ensures the
          right tools are set up, and the third describes the five immediate actions to
          perform for better remote work.</span>
      </p>
      
      <p>
        <span>It is an easy, quick read. In fact, the average reader will finish the book in
          less than 15 minutes. After following it you'll have enough space to learn
          from the vast resources on remote work </span><span>available </span><span>online and adjust them to fit your company.</span>
      </p>
      
      
      
      
      
      
      
      
      <p>
        <span>Remote work is composed of three pillars that are crucial to the success of the
          method. They are important to understand before going forward with
          implementation.</span>
      </p>
      
      <h2 id="h.rrpubh4i8p5v"><span></span></h2>
      
      <h2 id="h.1fqjja11bgze"><span>Trust</span></h2>
      
      <p>
        <span>Trust is your belief in a colleague's ability to deliver work in the best
          possible way. Note, this does not mean a guaranteed delivery every time, but the
          ability to deliver. It includes asking for help if needed, recovering from
          mistakes and improving for next time.</span>
      </p>
      
      <p>
        <span>Trust is essential because trusting others allows you to focus on your actual
          work, knowing they'll deliver. When others trust you, you get that unique
          peace of mind, the freedom to do your work.</span>
      </p>
      
      <p>
        <span>Without trust, employees will be agitated. Worried that their own work will be
          wronged by employees they rely on, either directly or indirectly. That is an
          impossible way to work, especially remotely.</span>
      </p>
      <h2 id="h.1cdix8fys4aq"><span> </span></h2>
      <h2 id="h.vvx9who9kf19"><span>Evergreen Communication</span></h2>
      
      <p>
        <span>Evergreen </span><span>C</span><span>ommunication achieves productive work and </span><span>always-available </span><span>conversations. Both are "evergreen"</span><span>,</span><span> meaning preserved. To accomplish </span><span>that</span><span>, </span><span>two things are needed.</span>
      </p>
      
      <p>
        <span>First</span><span>,</span><span> </span><span>asynchronous (async) communication</span><span> —</span><span> communicati</span><span>on</span><span> without the expectation of immediate response.</span>
      </p>
      
      <p>
        <span>Second</span><span>,</span><span> </span><span>history preservation</span><span>. </span><span>C</span><span>onversation</span><span>s</span><span> should be kept whole and in orde</span><span>r</span><span>, forever.</span>
      </p>
      
      <p>
        <span>Evergreen </span><span>C</span><span>ommunication is essential because it allows employees to always work on
          what's most important, always be up to date, and have the reasoning behind
          every decision at their fingertips. They can jump into any conversation that needs
          them, and answer without sacrificing productive work. New employees could even
          onboard themselves.</span>
      </p>
      
      <p>
        <span>Without </span><span>Evergreen</span><span> </span><span>Communication</span><span>, we're back to square one. Having everyone present, either in a chat, call
          or physical room forces participants to stop ongoing productive flow. Incomplete
          summaries, as they always are, </span><span>c</span><span>ause information loss and make the reasoning behind decisions </span><span>v</span><span>ague at best.</span>
      </p>
      <h2 id="h.i59vuej2ah6f"><span></span></h2>
      <h2 id="h.30fd3thx8ylx"><span>Independence</span></h2>
      
      <p>
        <span>Independence is the state where the employee(s) working on a task needs little to
          no outside involvement. This does not mean that employees will work in silos. Some
          tasks require more than one person to perform. If most tasks require one person,
          it means they are small (as they should) and that team cooperation will take place
          when joining the individual tasks to form a whole.</span>
      </p>
      
      <p>
        <span>It is essential because it makes sure each and every task is self-contained. That
          is, the employees responsible for it have all they need in order to deliver, and
          the risk of them being blocked is reduced. Further, increasing employees'
          resources in this way increases innovation, which again contributes to
          production.</span>
      </p>
      
      <p>
        <span>Without independence, productive work is undermined. The business will be tangled
          with permissions requests, employees will be blocked by their privileged
          counterparts, and innovation will halt at the face of bureaucracy. All of these
          are detrimental, more so in a remote environment, where bureaucracy is harder to
          deal with, and therefore should be prevented.</span>
      </p>
      
      
      
      
      
      
      
      
      <p>
        <span>You will only need four tools to be productive remotely. A tool used as a single
          source of truth and three tools used for the three forms of communication: async,
          hybrid and sync. That's it.</span>
      </p>
      
      <p>
        <span>All employees should have access to as much material as your company's level
          of transparency allows, without complex permissions or process.</span>
      </p>
      
      <p>
        <span>Each tool will have an example using a specific brand. While many brands supply
          these tools, make sure to only use one for each categor</span><span>y</span><span>. Different teams prefer different tools, but they cause duplication and
          fragmentation, which harms productivity.</span>
      </p>
      
      
      <h2 id="h.ga1500ptl4sj"><span></span></h2>
      <h2 id="h.vkvqh8m4qqe0">
        <span>Single Source of Truth</span>
      </h2>
      
      <p>
        <span>The Single Source of Truth is a website or collection of files that always
          represent the up-to-date and true state of work. It must adhere to Evergreen
          Communication and track changes and their reasoning, allow rollbacks to previous
          versions and keep communications async.</span>
      </p>
      
      <p>
        <span>Once this is set up, everyone should always update the work and communicate in
          regards to the single source of truth. Gone are the days of files scattered across
          various emails.</span>
      </p>
      
      <p>
        <span>Example:</span><span>
          Google Docs for a law company will hold all strategies, contracts, company
          policies, and so on. Every change done for the client or </span><span>to</span><span>
          company policy will be reflected immediately to all involved. Changes are always
          tracked, previous versions preserved, and </span><span>d</span><span>iscuss</span><span>ions are evergreen</span><span>.</span>
      </p>
      
      
      
      
      <h2 id="h.tqqlh9vccq1a">
        <span>Async Communication: Task Manager</span>
      </h2>
      
      <p>
        <span>Tasks should be managed using a task manager, a type of software. </span><span>They</span><span>
          should be discussed and when done, changes should be made to the source of truth.
          Task managers are completely async, have reproducible history to understand </span><span>past</span><span>
          decisions, and always show the state of work, making status meetings
          redundant.</span>
      </p>
      
      <p>
        <span>This is the hardest tool to choose, as it is company specific. Take </span><span>time</span><span>
          to test different options. If the one you have doesn't work for you, change
          it. Communicate this to your employees</span><span>. P</span><span>revent disruption </span><span>with gradual adoption</span><span>. </span><span>You will find one that works.</span>
      </p>
      
      <p>
        <span>Example #1:</span><span> Trello or Asana for a law firm. </span><span>E</span><span>mployees could open tasks, involve others and</span><span> jump i</span><span>n to help. A paralegal may open a task "Fix typo in website", the IT
          person may reply "Currently overwhelmed", then a secretary may jump in
          "I've built website</span><span>s </span><span>before, can I help?". This kind of </span><span>exchange is impossible</span><span> to achieve without the three pillars</span><span>.</span><span> </span><span>It</span><span>
          happens in remote companies every day, boosting the heart of the</span><span>ir</span><span> production.</span>
      </p>
      
      <p>
        <span>Example #2:</span><span> GitLab for software companies. </span><span>These apps</span><span> often double as a source of truth </span><span>with</span><span> their code hosting function and as task managers </span><span>with</span><span> their ticketing (issues, pull requests) system.</span>
      </p>
      <h2 id="h.ga1500ptl4sj"><span></span></h2>

      <h2 id="h.siasagdslt5x">
        <span>Hybrid Communication: Chat App</span>
      </h2>
      
      <p>
        <span>While the bulk of communication should be done using the task manager, sometimes
          we need to quickly hash things out. This is where chat apps come into play. They
          are hybrid, neither async n</span><span>or</span><span>
          sync. While it's possible to reply later, it's not easy. </span><span>M</span><span>essages come and go</span><span>,</span><span> pushing people to </span><span>respond immediately</span><span>.</span>
      </p>
      
      <p>
        <span>Therefore, for work talk, use these only for quick, ephemeral conversations. Any
          long lasting or high impact communications should use the task manager. Outside of
          work talk, chat plays a big role in socializing and enjoying each other's
          company, an important aspect to preserve when working </span><span>remotely</span><span>.</span><span> </span><span>Avoid email or WhatsApp as much as you can. They are private by nature and make
          it harder for people to jump in if needed.</span>
      </p>
      
      <p>
        <span>Example:</span><span> Slack</span><span> or any </span><span>app </span><span>with</span><span> private messages</span><span> and </span><span>public channels will do. Employees could publicly commend a team member for good
          work in the general channel, or offer feedback privately. They could hop into the
          memes and music channels for fun, ask in the IT channel if anyone noticed a system
          slowdown, or share research about </span><span>new</span><span> strategies in the marketing channel.</span>
      </p>
      
      <h2 id="h.50r9p5st2zyu"><span></span></h2>
      <h2 id="h.9yjvjddetok5">
        <span>Sync Communication: Video/Voice Calls</span>
      </h2>
      
      <p>
        <span>Sync communication makes sense in a few cases. Usually for brainstorms and when
          the team still isn't well acclimated to proper remote work. Keep it available,
          but try to avoid it as much as possible. Calls are fine …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.emergencyremote.com/emergencyremote">https://www.emergencyremote.com/emergencyremote</a></em></p>]]>
            </description>
            <link>https://www.emergencyremote.com/emergencyremote</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956482</guid>
            <pubDate>Sun, 26 Jul 2020 12:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying MLsub – The Simple Essence of Algebraic Subtyping]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23956315">thread link</a>) | @panic
<br/>
July 26, 2020 | https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html | <a href="https://web.archive.org/web/*/https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong><em>Note: this web article is an older version of a paper which has now been published as an ICFP Pearl. You can find a preprint of that paper <a href="https://lptk.github.io/simple-sub-paper">here</a>.</em></strong></p> <p><strong><em>It’s probably better to read the paper rather than this post, as the paper contains more material, is more up to date, and is better explained!</em></strong></p> <p><strong>Algebraic subtyping</strong> is a new approach to global type inference in the presence of subtyping. It extends traditional Hindley-Milner type inference while preserving the principal type property — that is, it can always infer <em>the</em> most general type for any given expression. This approach was developed by <a href="http://stedolan.net/about/">Stephen Dolan</a> as part of his PhD thesis, along with Alan Mycroft.</p> <p>Algebraic subtyping was implemented in <a href="https://www.cl.cam.ac.uk/~sd601/mlsub/">the <strong>MLsub</strong> type inference engine</a>. However, the design of MLsub seems significantly more complex than the simple unification algorithms used for traditional ML languages. MLsub has proven harder to grasp, even for people already familiar with compilers and type systems, such as myself.</p> <p>Dissatisfied with this state of affairs, I wanted to get to the bottom of the algebraic subtyping approach. What really is special about it, beyond the formalism? What are the simple concepts that hide behind the strange notions of <em>biunification</em> and <em>polar types</em>?</p> <p>This article is an answer to those questions. I propose an alternative algorithm for algebraic subtyping, called <strong>Simple-sub</strong>. Simple-sub can be implemented <strong>efficiently</strong> in <strong>under 500 lines of code</strong> (including parsing, simplification, and pretty-printing), and I think it is much more familiar-looking and easier to understand than MLsub.</p> <h4 id="---you-can-try-simple-sub-online-here---"><strong>⇨ ⇨ ⇨ <em><a href="https://lptk.github.io/simple-sub/">You can try Simple-sub online here!</a></em> ⇦ ⇦ ⇦</strong></h4> <p>This article is meant to be light in formalisms and easy to consume for prospective designers of new type systems and programming languages.</p> <p><a href="https://github.com/LPTK/simple-algebraic-subtyping">The complete source code of Simple-sub is available on Github.</a></p>   <h2 id="summary">Summary</h2> <ol> <li> <p><strong><a href="#intro">Introduction</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-mlsub">Algebraic Subtyping in MLsub</a></strong></p> </li> <li> <p><strong><a href="#algebraic-subtyping-simple-sub">Algebraic Subtyping in Simple-sub</a></strong></p> </li> <li> <p><strong><a href="#simplifying-types">Simplifying Types</a></strong></p> </li> <li> <p><strong><a href="#conclusions">Conclusions</a></strong></p> </li> </ol> <hr>  <p>The ML family of languages, which encompasses Standard ML, OCaml, and Haskell, have been designed around a powerful “global” approach to type inference, rooted in the work of <a href="https://doi.org/10.2307%2F1995158">Hindley</a> and <a href="https://doi.org/10.1016%2F0022-0000%2878%2990014-4">Milner</a>, later closely formalized by <a href="https://dl.acm.org/doi/10.1145/582153.582176">Damas</a>. In this approach, the type system is designed to be simple enough that types can be unambiguously inferred from terms without the help of any type annotations. That is, for any unannotated term, it is always possible to infer a <em>principal type</em> which subsumes all other types that can be assigned to this term. For instance, the term $\lambda{x}. {x}$ can be assigned types $\mathsf{bool} \to \mathsf{bool}$ and $\mathsf{int} \to \mathsf{int}$, but both of these are subsumed by the polymorphic type $\forall a.\ a \to a$, also written <code>'a -&gt; 'a</code>, which is the principal type of this term.</p> <p><strong><em>Hindley-Milner</em></strong> (HM) type inference contrasts with more restricted “local” approaches to type inference, found in languages like Scala and C#, which often require the types of variables to be annotated explicitly by programmers. On the flip side, abandoning the principal type property allows these type systems to be more expressive and to support features such as object orientation and first-class polymorphism. Note that in practice, even ML languages like OCaml and Haskell have adopted expressive type system features which, when used, break the principal type property.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p> <p><strong><em>Subtyping</em></strong> is an expressive feature allowing types to be structured into hierarchies (usually a subtyping <a href="https://en.wikipedia.org/wiki/Lattice_(order)"><em>lattice</em></a>) with the property that types can be <em>refined</em> or <em>widened</em> transparently following this hierarchy. This lets us express the fact that some types are more precise (contain more information) than others, but still have a compatible runtime representation, so that no coercions between them are needed. For instance, in a system where the type <code>nat</code> is a subtype of <code>int</code>, one can transparently use a <code>nat list</code> in place where an <code>int list</code> is expected, without having to apply a coercion function on all the elements of the list. Subtyping can be emulated using somewhat heavy type system machinery (which both OCaml and Haskell occasionally do<sup id="fnref:2"><a href="#fn:2">2</a></sup>), but first-class support for subtyping gives the benefit of simpler type signatures and better type inference.</p> <p>For a long time, it was widely believed that pervasive implicit subtyping got in the way of satisfactory global type inference. Indeed, previous approaches to inferring subtypes failed to support principal types or resulted in the inference of large, unwieldy typing schemes which included sets of complex constraints, making their understanding by programmers difficult.</p> <p><strong><em>Algebraic subtyping</em></strong> was introduced by Dolan and Mycroft as an ML-style type system supporting subtyping and global type inference, while producing compact principal types. Here, <em>compact</em> refers to the fact that the inferred types are relatively simple type expressions without any visible constraints, making them easy to understand by programmer. This was achieved by carefully designing the syntax and semantics of the underlying subtyping lattice, allowing for simplifying assumptions in to be made the constraint resolution process of the type inference algorithm.</p> <p>However, <em>biunification</em>, the algorithm proposed by Dolan in order to implement algebraic subtyping, has been quite difficult to understand for many experts and non-experts alike. Indeed, on the surface it looks quite different from the usual <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Algorithm_J"><em>Algorithm J</em></a> traditionally used for Hm type systems: it requires several additional concepts, such as bisubstitution and polar types, making it look more complicated.</p> <p>Thankfully, it turns out that algebraic subtyping admits a type inference algorithm, which I called <em>Simple-sub</em>, that is very similar to the familiar Algorithm J, and also much more efficient than biunification (or at least, than the basic syntax-driven form of biunification.<sup id="fnref:3"><a href="#fn:3">3</a></sup> In this article, I show that inferring algebraic subtypes is actually extremely easy, and can be done in under 300 lines of Scala code. Most of the complexity actually comes from simplifying the inferred type representations, which we will get to later.</p> <p>While the implementation we present is written in Scala, it is straightforward to translate into any other functional programming language.</p> <p><strong><em>The goal of this article</em></strong> is to recast algebraic subtyping into a simpler mold, allowing more prospective designers of type systems and programming languages to benefit from the great insights that this approach offers.</p> <hr>  <p>Let’s start by briefly reviewing what algebraic subtyping and MLsub are and what they are not, and by trying to assess their expressiveness.</p> <h2 id="term-language">Term Language</h2> <p>The term syntax of MLsub is given below. I have omitted boolean literals and if-then-else, as they can easily be typed as primitive combinators. I also used only one form of variables $x$, which will be sufficient for our use (Dolan’s MLsub formalism distinguishes lambda-bound variables from let-bound variables for technical reasons).</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>variable</td> <td>$x$</td> <td><code>x</code></td> </tr> <tr> <td>lambda</td> <td>$\lambda{x}. {e}$</td> <td><code>fun x -&gt; e</code></td> </tr> <tr> <td>application</td> <td>$e\ e$</td> <td><code>e e</code></td> </tr> <tr> <td>record creation</td> <td>$\{\ l_0 = e \,;\; … \,;\; l_n = e\ \}$</td> <td><code>{ l_0 = e; ...; l_n = e }</code></td> </tr> <tr> <td>field selection</td> <td>$e.l$</td> <td><code>e.l</code></td> </tr> <tr> <td>let bindings</td> <td>$\mathsf{let}\ x = e\ \mathsf{in}\ e$</td> <td><code>let x = e in e</code></td> </tr> </tbody> </table> <h2 id="type-language">Type Language</h2> <p>The type syntax of MLsub, summarized below, consists in booleans, function types, record types, type variables, top $\top$ (the type of all values — supertype of all types), bottom $\bot$ (the type of no values — subtype of all types), type union $\sqcup$, type intersection $\sqcap$, and recursive types $\mu{\alpha}. {\tau}$.</p> <table> <thead> <tr> <th>name</th> <th>formal syntax</th> <th>ML pseudo-syntax</th> </tr> </thead> <tbody> <tr> <td>primitives</td> <td>$\mathsf{bool}$, $\mathsf{int}$, …</td> <td><code>bool</code>, <code>int</code>, …</td> </tr> <tr> <td>function</td> <td>$\tau \to \tau$</td> <td><code>t -&gt; t</code></td> </tr> <tr> <td>record</td> <td>$\set{\ l_0: \tau \,,\; … \,,\; l_n: \tau\ }$</td> <td><code>{ l_0: t, ..., t_n: t }</code></td> </tr> <tr> <td>variable</td> <td>$\alpha $</td> <td><code>'a</code></td> </tr> <tr> <td>top</td> <td>$\top$</td> <td><code>⊤</code></td> </tr> <tr> <td>bottom</td> <td>$\bot$</td> <td><code>⊥</code></td> </tr> <tr> <td>union</td> <td>$\tau \sqcup \tau$</td> <td><code>∨</code></td> </tr> <tr> <td>intersection</td> <td>$\tau \sqcap \tau$</td> <td><code>∧</code></td> </tr> <tr> <td>recursive</td> <td>$\mu\alpha. \tau$</td> <td><code>t as 'a</code></td> </tr> </tbody> </table> <h2 id="informal-semantics-of-types">Informal Semantics of Types</h2> <p>While most MLsub type forms are usual and unsurprising, two kinds of types require our special attention: set-theoretic types (more specifically union and intersection types), and recursive types.</p> <h3 id="set-theoretic-types">Set-Theoretic Types</h3> <p>To a first approximation, union and intersection types can be understood in set-theoretic terms: the type term $\tau_0 \sqcup \tau_1$ (resp. $\tau_0 \sqcap \tau_1$) represents the type of values that are <em>either</em> (resp. <em>both</em>) of type $\tau_0 $ <em>or</em> (resp. <em>and</em>) of type $\tau_1$.</p> <p>MLsub uses these types to indirectly constrain inferred type variables; for instance, one type inferred for term $\lambda{x}. {\set{l = x - 1 \,;\; r = x}}$ could be $\alpha \sqcap \mathsf{int} \to \set{l: \mathsf{int} \,,\; r: \alpha}$. This type reflects the fact that the original argument, of type $\alpha$, is returned in the $r$ field of the result record, as the input type $\alpha$ ends up in that position, but also that this argument should be able to be treated as an $\mathsf{int}$, expressed via the type intersection $\alpha \sqcap \mathsf{int}$ on the left-hand side of the function type. Keeping track of the precise argument type $\alpha$ is important: it could be later substituted with a more specific type than $\mathsf{int}$, such as $\alpha = \mathsf{nat}$, which would give us $\mathsf{nat} \to \set{l: \mathsf{int} \,;\; r: \mathsf{nat}}$.</p> <p>On the other hand, there may be type signatures where some $\alpha$ becomes undistinguishable from $\mathsf{int}$. For instance, consider the term $\lambda{x}. {\mathsf{if}\ \mathsf{true}\ \mathsf{then}\ {x - 1}\ \mathsf{else}\ {x}}$, whose simplified inferred type would be just $\mathsf{int} \to \mathsf{int}$, as the seemingly-more precise type $\alpha \sqcap \mathsf{int} \to \alpha \sqcup \mathsf{int}$ does not actually contain more information (see the MLsub paper for details).</p> <p>The beauty of algebraic subtyping is that this sort of reasoning scales to arbitrary flows of variables and higher-order functions; for instance, the previous example can be generalized by passing in a function $f$ to stand for the $\cdot - 1$ operation, as in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html">https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</a></em></p>]]>
            </description>
            <link>https://lptk.github.io/programming/2020/03/26/demystifying-mlsub.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23956315</guid>
            <pubDate>Sun, 26 Jul 2020 11:38:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to effectively evade the GDPR and the reach of the DPA]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 190 (<a href="https://news.ycombinator.com/item?id=23955596">thread link</a>) | @thierryzoller
<br/>
July 26, 2020 | https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html | <a href="https://web.archive.org/web/*/https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is a post in a series of posts :</p>
<br>
<div><p>
As my regular readers know I reluctantly trust anything that isn't tested and battle proof. In the last 2 years, I applied the same logic that I apply to vulnerability research to the Data Privacy environment and proceeded to test a broad range of Data Subject Rights. Expect a few disclosures following this one.</p><p>

In true Information Security Fashion (insiders will understand) have attributed this weakness the ID :</p><ul>
<li><b>CDPWE-0001 - Does not designate a Representative in the European Union</b></li>
</ul>
<h3>
Introduction</h3>
<br></div>
<p>
When I searched Google for my name an interesting website came up in the results. A company called "Rocket Reach" allowed others to buy access to my personal data. I was intrigued as I have never given any consent for Rocketreach to store (or even sell) my data and I saw no other legal basis for RocketReach processing of my data.</p>
<div>

<p>
"Rocket Reach" a data broker that describes it's service as :</p>
<blockquote>
<p>
"Connect directly with the right decision makers, using the world's largest and most accurate database of emails and direct dials.&nbsp;Real-time verified data for 430 million professionals across 17 million companies, worldwide.Trusted by over 5.0 million users — powering sales, recruiting, and marketing at companies large and small.</p>
<p>
Prospect, connect and converse with your leads at scale."</p>
</blockquote>
</div>
<p>



<h3>
Issuing a DSAR</h3>
</p>
<p>
On the <b>5th of April&nbsp; 2019</b>, I asked Rocketreach access to my personal data (Data Subject Access Request) and asked for the purpose and the legal basis of processing. Instead of giving me access to my data and reply adequately, RocketReach decided to <b>delete/remove all traces of it </b>and informed me that it did so the same day.</p>

<p>
While it might be surprising to some, this is actually a common reaction to DSARs when the Data Controller realizes the data they have may have no real legal basis.</p>
<br>
<h3>
Filing a complaint&nbsp;</h3>
<p>
On the <b>05th of April 2019</b>, I filed a complaint with the Luxemburgish Data Protection Agency (CNPD). The reference for this complaint is #3018 (For those that want to request information/documents from the CNPD).</p>

<h3>
Waiting for roughly a year</h3>
<br>
<h3>
"We agree with you but we can't do anything, sorry, move on"</h3>
<p>
On the <b>6th of March 2020</b>&nbsp;(<span>1 year!</span>) the CNPD responded as follows (Original Version on top, the Translated version at the bottom).</p>
<br>
<blockquote>
<p><span lang="FR">Monsieur Zoller,<o:p></o:p></span></p>
<p><span lang="FR">La
 Commission nationale pour la protection des données (CNPD) se permet de
 revenir vers vous concernant votre réclamation du 5 avril 2019 à 
l’encontre de la société RocketReach.<o:p></o:p></span></p>
<p><span lang="FR">Dans le cadre de l’instruction de votre réclamation, la 
société RocketReach nous a communiqué qu’elle considère que ce sont les 
utilisateurs de ses services, et non elle-même, qui sont les 
responsables du traitement pour ce qui concerne les
 données à caractère personnel traitées sur son site internet. <o:p></o:p></span></p>
<p><span lang="FR">Par ailleurs, il ressort également de cette instruction 
que la société RocketReach est une société située aux Etats-Unis 
d’Amérique <b>ne disposant pas d’un représentant dans l’Union au sens de 
l’article 27 du règlement général sur la protection
 des données (RGPD). </b><o:p></o:p></span></p>
<p><span lang="FR">Au sujet des responsables du traitement établis dans des
 pays tiers, comme les Etats-Unis d’Amérique, nous souhaitons attirer 
votre attention sur le considérant (116) du RGPD qui précise que:</span></p>
<p>
«&nbsp;<i>Lorsque
 des données à caractère personnel franchissent
 les frontières extérieures de l'Union, cela peut accroître le risque 
que les personnes physiques ne puissent exercer leurs droits liés à la 
protection des données, notamment pour se protéger de l'utilisation ou 
de la divulgation illicite de ces informations.
 De même, les autorités de contrôle peuvent être confrontées à 
l'impossibilité d'examiner des réclamations ou de mener des enquêtes sur
 les activités exercées en dehors de leurs frontières. Leurs efforts 
pour collaborer dans le contexte transfrontalier peuvent
 également être freinés par les pouvoirs insuffisants dont elles 
disposent en matière de prévention ou de recours, par l'hétérogénéité 
des régimes juridiques et par des obstacles pratiques tels que le manque
 de ressources.&nbsp;»</i></p>
<p><span lang="FR">Dans le cas de votre réclamation cela signifie que, <b>bien
 que nous ne partagions pas le point de vue de RocketReach et que nous 
sommes au contraire d’avis que cette société est bien à considérer comme
 responsable du traitement pour les traitements
 de données à caractère personnel effectués sur son site internet, il 
nous est impossible de poursuivre plus en avant le traitement de votre 
réclamation</b>. En effet, nous ne disposons pas des pouvoirs de mener des 
enquêtes et de faire appliquer les décisions
 que nous serions amenés à prendre sur le territoire des Etats-Unis 
d’Amérique.<o:p></o:p></span></p>
<p><span lang="FR">Nous sommes dès lors au regret de vous informer que nous
 considérons qu’il nous est impossible de poursuivre de façon effective 
le traitement de votre dossier.&nbsp;
<o:p></o:p></span></p>
<p><span lang="FR">Veuillez agréer, Monsieur Zoller, l’expression de nos sentiments distingués.<o:p></o:p></span></p>

</blockquote>
<blockquote><b>English Translation</b><p>
Mr. Zoller, </p><p>The National Commission for Data Protection (CNPD) would like to get back to you regarding your complaint of 5 April 2019 against the company RocketReach. </p><p>Rocket Reach has informed us that <b>it considers that it is the users of its services, and not itself, who are responsible for processing personal data processed on its website</b>.  Furthermore, it also emerges from this instruction that RocketReach is a company located in the United States of America that does not have a representative in the Union within the meaning of Article 27 of the General Regulation on Data Protection (RGPD).&nbsp;</p> <p>As regards data controllers established in third countries, such as the United States of America, we would like to draw your attention to recital (116) of the DPMR which states that: 'When personal data crosses the external borders of the Union, this may increase the risk that individuals may not be able to exercise their data protection rights, in particular to protect themselves against unlawful use or disclosure of such information.</p><p>Similarly, supervisory authorities may be faced with the impossibility to investigate complaints or activities outside their borders. Their efforts to work together in the cross-border context may also be hampered by insufficient preventive or remedial powers, heterogeneous legal regimes and practical obstacles such as lack of resources. »&nbsp;</p> <p>In the case of your complaint, this means that, although <b>we do not share RocketReach's view and to the contrary believe <span>that RocketReach is the data controller</span> </b>for the processing of personal data on its website, <b>we are unable to take any further action in relation to your complaint.</b> We do not have the authority to investigate and enforce any decision we would have to take in the United States of America.&nbsp;</p> <p><b>We regret to inform you that we consider it impossible for us to proceed with the processing of your case.</b></p></blockquote>
<div><p>In Summary -&nbsp; Rocketreach has <b>not met the requirement</b> of the GDPR to name an EU representative (Art27) to account for the processing of European Personal Data. <b>In their answer, the CNPD makes it sound like it is optional, it isn't.</b> Instead of pursuing Rocketreach locally on that basis alone, the CNPD just gives up arguing it has no jurisdiction in the US.</p></div>

<p><span>In other words, just don't designate a representative in Europe, build your business model around the exploitation of data from millions of European data subjects and you are fine?</span></p>

<p>
I&nbsp; am fully aware that I could engage in legal procedures myself.&nbsp; That's not in my interest (in this case). The overall question you should ask is: Do we need a European Institution that handles extra-territorial investigations and fines? <b>Why should it take the time, money, and energy from an individual when the DPA is supposed to defend the rights of the data subjects</b>?</p>
<p>
What the CNPD could have done according to [1]</p><ul>
<li><span><span>to impose a temporary or definitive limitation including a ban on processing;</span></span></li>
<li><span><span>to order the suspension of data flows to a recipient in a third country or to an international organisation.</span></span></li>
<li><span><span>to impose an administrative fine pursuant to Article 83, in addition to, or instead of measures referred to in this paragraph, depending on the circumstances of each individual case;</span></span></li>
<li><span><span>to order the controller or processor to bring processing operations into compliance with the provisions of this Regulation, where appropriate, in a specified manner and within a specified period;</span></span></li>
</ul>
<p>
[1]&nbsp;<a href="https://cnpd.public.lu/en/commission-nationale/pouvoirs.html">https://cnpd.public.lu/en/commission-nationale/pouvoirs.html</a></p><p>
Instead, Rocketreach just continues to sell the personal data of millions of European data subjects like nothing ever happened. Including all of the below :</p><p><a href="https://1.bp.blogspot.com/-z6piNinfp7c/Xs-0S2Xm-rI/AAAAAAAAA0Q/1YXUi3ANINEUhF9UJebPzPAUW8Oa2U80QCLcBGAsYHQ/s1600/trophy1.PNG"><img data-original-height="886" data-original-width="1542" height="227" src="https://1.bp.blogspot.com/-z6piNinfp7c/Xs-0S2Xm-rI/AAAAAAAAA0Q/1YXUi3ANINEUhF9UJebPzPAUW8Oa2U80QCLcBGAsYHQ/s400/trophy1.PNG" width="400"></a></p>
<p><span>
Members of the CNPD</span></p>

<p><a href="https://1.bp.blogspot.com/-KTvsmbvPPwA/Xs-0sPl_y5I/AAAAAAAAA0Y/3XeiS_j0L6EOxtVkLI2ajjTlyDiKADDIwCLcBGAsYHQ/s1600/trophy2.PNG"><img data-original-height="798" data-original-width="1521" height="208" src="https://1.bp.blogspot.com/-KTvsmbvPPwA/Xs-0sPl_y5I/AAAAAAAAA0Y/3XeiS_j0L6EOxtVkLI2ajjTlyDiKADDIwCLcBGAsYHQ/s400/trophy2.PNG" width="400"></a></p>
<p><span>
Members of the European Data Protection Board</span></p>

<p><a href="https://1.bp.blogspot.com/-LeEhjvJtgmk/Xs-1KUiVvjI/AAAAAAAAA0g/4pXoPjpjssceaGi6UJAOna8guxKQam1EACLcBGAsYHQ/s1600/trophy3.PNG"><img data-original-height="690" data-original-width="1534" height="178" src="https://1.bp.blogspot.com/-LeEhjvJtgmk/Xs-1KUiVvjI/AAAAAAAAA0g/4pXoPjpjssceaGi6UJAOna8guxKQam1EACLcBGAsYHQ/s400/trophy3.PNG" width="400"></a></p>

<p><span>
CNIL</span></p>






</div></div>]]>
            </description>
            <link>https://blog.zoller.lu/2020/05/how-to-effectively-evade-gdpr-and-reach.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955596</guid>
            <pubDate>Sun, 26 Jul 2020 09:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebGL Fluid Simulation]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 49 (<a href="https://news.ycombinator.com/item?id=23955527">thread link</a>) | @maxraz
<br/>
July 26, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/?play</link>
            <guid isPermaLink="false">hacker-news-small-sites-23955527</guid>
            <pubDate>Sun, 26 Jul 2020 08:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Montreal is taxing churches (2017)]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 300 (<a href="https://news.ycombinator.com/item?id=23954846">thread link</a>) | @seesawtron
<br/>
July 25, 2020 | https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
	Churches in Montreal are becoming concerned about hosting community groups after being hit with bills for municipal taxes.</p>
<p>
	Joel Coppetiers, the Minister at the Cote des Neiges Presbyterian church, was shocked when his institution first received a municipal tax bill in early 2015.</p>
<p>
	It was "the first indication that something had changed," said Coppetiers.</p>
<p>
	Provincial law exempts churches and manses from paying municipal taxes but Coppetiers was told that if a manse is vacant for several months between ministers, it's taxable.</p>
<p>
	Following that, city officials arrived for an inspection of every room in the church and how they were used.</p>
<p>
	"The indication is there's not an exemption for the church as a whole, there's only an exemption for those areas used for public worship and things directly related to it," said Coppetiers.</p>
<p>
	As a result, many churches in Montreal that host community groups, such as food banks, or Girl Guides or Boy Scouts, are facing mounting tax bills.</p>
<p>
	Coppetiers says the city has changed how it interprets the law.</p>
<p>
	"We're there to care and serve the community and this is part of it," said Coppetiers.</p>
<p>
	Coppetiers says taxes are due even when services are suspended for renovations.</p>
<p>
	The amount owed in taxes can increase swiftly if a church closes its doors.</p>
<p>
	When <a href="http://montreal.ctvnews.ca/trinity-memorial-church-in-ndg-closes-its-doors-1.3302321">Trinity Memorial Church in NDG </a>closed earlier this year, the city started enacting taxes immediately following the last service.</p>
<p>
	As a result churches feel pressured to sell swiftly, with Trinity Memorial being sold to Stanford Properties Group within two months.</p>
<p>
	The issue of places of worship owing taxes and fighting the city's exemptions office came as a surprise to city politicians, including Councillor Peter McQueen.</p>
<p>
	"Already our churches are in danger, they're having a number of financial problems and this is a further low blow," said McQueen.</p>
<p>
	The NDG councillor said his party, Projet Montreal, will study the exemption issue, but he said Montreal's Executive Committee needs to step up.</p>
<p>
	"If we don't do something you're going to see churches closed, churches possibly torn down, heaven forbid, certainly converted away from community use," said McQueen.</p>
<p>
	Meanwhile churches across the island are praying that the city will cease surprising them with taxes they can't afford.</p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/no-more-religious-exemptions-montreal-is-taxing-churches-1.3415164</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954846</guid>
            <pubDate>Sun, 26 Jul 2020 06:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running DOS Apps on Windows]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 51 (<a href="https://news.ycombinator.com/item?id=23954234">thread link</a>) | @bluedino
<br/>
July 25, 2020 | https://gekk.info/articles/dosapps.html | <a href="https://web.archive.org/web/*/https://gekk.info/articles/dosapps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tr><td>
	<div>
	<p>It's worth discussing <em>how</em> all this works so you understand the 
	challenges that are being overcome here. The ability to run multiple DOS 
	programs at once is a pretty neat trick, given that this software heralds 
	from an era of computing that was <em>just barely</em> ahead of what the 
	Apple ][ was doing in 1978. If you want to skip this, <a href="#Windows_1.0">go ahead</a>.</p>
	<p>The root of the problem is that the IBM PCs basic architecture 
	crystallized a very long time ago, in 1981. In a world where ten kilobytes of RAM counted for 
	about what a gig does now, there was not a lot of room for "overhead" and 
	the idea that you would run two programs simultaneously was generally 
	unrealistic except at the high end of the computing world, which most PC 
	buyers were nowhere near. You needed every bit (<em>ha</em>) of memory you could get, and when 
	memory became more affordable a few years later, it was too late 
	to change anything.</p>
	<p>After just a couple years on the market, MS-DOS had become the 
	unquestioned OS of choice for the PC<a href="#footnote1">*</a> 
	and developed a monumental stable of software, every bit of which<em> </em>
	was essential to someone, somewhere, and could not be easily replaced. Thus 
	began one of the longest tails in technology history, as the PC industry and 
	Microsoft began contorting themselves to try not to 
	break compatibility with old software while still moving forward with advanced 
	functionality.<br>
	<sub><a name="footnote1">*</a>(specifically, since there were MS-DOSes for 
	other architectures, and other OSes for the PC)</sub></p>
	<p>Because DOS was developed under constraints very similar to those 
	in the 
	late '70s that gave us the "bitty boxes" (C64, Apple ][, ZX 
	Spectrum, etc.) it was not built with any kind of "supervision" in mind. In 
	other words, there was no abstraction level above the current running program. 
	DOS was more like a set of tools than what we think 
	of as an operating system now - specifically, it had no "process management"; no concept of "processes" at all, in fact.</p>
	<h2><strong>DOS</strong></h2>
	<p>When the machine booted, the part of DOS that was considered "the OS" - 
	the code for accessing disk drives, writing text to screen, etc. - was copied 
	into memory, and then execution was handed off to the command interpreter, COMMAND.COM, 
	which was an application like any other, at which point you could begin 
	entering commands to use the computer.</p>
		<p>At this point, DOS was no longer "running" in 
	any meaningful way. The code was "resident," meaning it was present in the 
		computer's memory, but 
	the processor wasn't&nbsp; executing any of it. Instead, the CPU was busy executing 
	whatever the current program was - if you were at the command prompt, then 
		all the code the PC was executing was part of COMMAND.COM. When you launched another application, COMMAND.COM was 
	vacated and replaced by that other application.</p>
	<p>In other words, while an application was running, DOS was almost totally out of 
	the picture. The only time execution returned to DOS itself was when the 
	application requested a "service" from DOS, like accessing a disk drive, at 
	which point it would tell the CPU to go execute one of DOS' stored routines 
	for this, and when that routine was done, control would return to the 
	application. This meant that,<em> generally speaking</em>,<em> </em>the current 
	program 
	had absolute control of the PCs execution and it's memory. It could in fact choose to 
	overwrite DOS itself, obliterating it out of memory, and DOS couldn't do a damn thing about it.</p>
	<p>The currently running app also had the option to speak directly to hardware. 
	The 
	whole purpose of DOS was to abstract things like that so programs wouldn't 
	need to know the details of the system they were running on, but since the 
	IBM PC was <em>extremely</em> consistent hardware-wise in its early 
	incarnations, it was entirely 
	optional for developers to take advantage of that, and often 
	there were reasons - of performance, perhaps - to bypass DOS and do things 
	directly.</p>
		<p>DOS provided disk access routines, 
	but the app could blow right by them and shoot commands straight to the 
	floppy drive if it wanted. DOS provided routines for printing text and clearing the 
	screen, but the app could just write directly to video memory. I can't speak to how common this kind of behavior actually was, but it 
	certainly wasn't rare, and it speaks to a larger problem - DOS apps simply 
	expect total control over the system.</p>
		<p>If you run two DOS apps at once, they're 
	going to stomp on each other, because each one thinks it's in charge of the 
		whole machine. The first one would store data in the same spot that the 
		second one stored program code, and thus one would overwrite the other 
		and crash it. So DOS was a single-tasking operating system - you could 
		run one program at a time, and when you wanted to run another, you had 
		to exit, return to the command prompt, and then launch your other app.</p>
		<p>Consequently, if you were working on something 
	in Microsoft Multiplan and wanted to go look up some data in dBase, you had to quit completely 
	out of Multiplan and then start dBase, which would take over the system and totally 
	overwrite the previous app. To get back to where you were you'd have to exit 
		dBase, restart Multiplan, load your document and find your place again - 
		in the process, totally forgetting what you were there to do in the 
		first place, because it's so many steps and takes so long.</p>
	<p>Right from the get-go, PC users wanted to be able to look at one program, then rapidly 
	switch to another. On its face this seems to mean "run two programs at once," 
	which is what we do now, but that's not quite the full story. Let's touch on how 
	that works nowadays, however.</p>
	<h2><strong>Multiprocessing</strong></h2>
	<p>To be clear, you <em>cannot</em> run two programs "at once" on a 
	computer. Some would call this semantics, but it's important in a very real 
	way, <em>especially</em> when talking about 80s-era PCs.</p>
		<p>Modern multicore CPUs get very close to true parallel processing by 
		letting separate programs run on separate cores, but of course, nobody has a CPU so big 
	that they have one core per process. And even if you did, programs still 
		have to share other 
	resources - the system bus, hard drives, and so on. Access to these 
	resources has to be carefully managed so that only one application can use 
		them at a time, and each one has to be cleaned up after before another 
		one can use the same resources. Otherwise, one program could leave the 
		hardware in a state where the commands that the next program sends put 
		it in an unusable state and crash the machine, or corrupt data.</p>
	<p>Even with all our modern pipelined cleverness, you have the 
	fundamental problem that a CPU, and a computer in general, has a limited 
	amount of physical hardware and can't dedicate some to each individual 
	program that's running. When you have more processes running than you have silicon, the only option left is to share 
	resources by dividing up the amount of time that each process gets to use the hardware 
	- this is one of the oldest concepts in computing, and goes back to the late '50s.</p>
	<p>The fundamentals of this process are simple: At 
	any given moment, one program has near-total control of the entire 
	system, to execute its code and use all the resources, and then after it 
	executes for a bit, it goes into a paused state and control is handed off to 
	the next program, which does its work and then hands off to the next. This 
	continues in a round-robin fashion, so that every program gets to use the 
	hardware for a certain portion of every second.</p>
	<p>Modern implementations take this to a fever pitch with all the complex 
	machinations used to make this process efficient, but the fundamentals have 
	never changed; this is how your PC is operating right now.</p>
	<p>One big hurdle to overcome in implementing this is that programs don't just execute 
	instructions in a vacuum. As code is executed, there are side 
	effects. Some are values internal to the CPU, like the&nbsp; status of CPU registers and the current 
	position of the instruction pointer. This is called "CPU state," amd is specific to 
	each running program. When you switch from one program to another, you have to 
	save that information - called "context switching" - and restore it when you 
	come back. Storing this info takes extra time and memory.</p>
		<p>Another hurdle is the state of other hardware. If two programs are 
		talking to the hard drive, you can't let them both just blindly issue 
		commands every time they get control of the CPU. The first process might 
		start a data read that the second process interrupts with a data write, 
		confusing the hard drive controller. So when switching from one process 
		to another, you also have to save the state of these other hardware 
		resources - and possibly even delay switching tasks until those hardware 
		requests are complete.</p>
	<p>If you have enough RAM to store this state, and if your apps don't need too many cycles per second to appear responsive, you can do all this and the user 
	will feel like they're "running multiple programs at 
	once."</p>
	<p>Now, in business applications - the 
	driving force behind the first couple decades of computing - actual 
	"multiprocessing" of this type is not as important as simple usability - users 
	just don't want to have to close one program in order to open another, as they 
	did throughout the DOS days. That, ultimately, is the goal: it 
	doesn't matter if the computer is perfectly speedy, or if programs can run 
	simultaneously, it just matters that 
	users not have to lose all their work in one program simply in order to look 
	at another.</p>
	<h2>Multitasking</h2>
	<p>This desire was of course tremendous right from the start of computing. Who wants to 
	be stuck in one program at a time? So, almost from the 
	earliest days of the IBM PC, software was created to enable task switching 
	with various degrees of success.</p>
		<h3>Early Attempts</h3>
		<p><a data-lity="" href="https://gekk.info/articles/images/doswin/dos4_taskswitch.png">
		<img alt="Multitasking DOS 4" height="177" src="https://gekk.info/articles/images/doswin/dos4_taskswitch_small.png" width="320"><!-- MSComment="autothumbnail" xthumbnail-orig-image="file:///C:/Users/dthom/Documents/My Web Sites/images/doswin/dos4_taskswitch.png" --></a></p>
	<p>Microsoft actually released a version of DOS with true multitasking 
	support, but it …</p></div></td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gekk.info/articles/dosapps.html">https://gekk.info/articles/dosapps.html</a></em></p>]]>
            </description>
            <link>https://gekk.info/articles/dosapps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23954234</guid>
            <pubDate>Sun, 26 Jul 2020 03:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[D3js Tree of Wittgenstein's Tractatus]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23953857">thread link</a>) | @motohagiography
<br/>
July 25, 2020 | https://pbellon.github.io/tractatus-tree/#/ | <a href="https://web.archive.org/web/*/https://pbellon.github.io/tractatus-tree/#/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pbellon.github.io/tractatus-tree/#/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23953857</guid>
            <pubDate>Sun, 26 Jul 2020 02:07:18 GMT</pubDate>
        </item>
    </channel>
</rss>
