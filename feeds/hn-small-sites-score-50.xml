<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Sep 2020 04:25:19 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Sep 2020 04:25:19 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Simple WireGuard Docker network setup]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24583512">thread link</a>) | @bjoko
<br/>
September 24, 2020 | https://www.eisfunke.com/article/docker-wireguard-systemd.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/docker-wireguard-systemd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        A simple solution for routing specific docker containers through a WireGuard VPN using only two simple systemd-networkd files, no cumbersome <code>wg</code> or <code>ip</code> calls.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/metro-tunnel.jpg" alt=""><figcaption>I heard that dramatic article images heavy with meaning are a meme, so here you have a picture of a subway tunnel because VPNs are network tunnels. <a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="#instructions-in-short">Jump to short instructions</a></p>
<p>I recently reorganized my self-hosted stuff to use Docker. While Docker not really fits my philosophy, the broad availability and low-maintenance of images for pretty much all software convinced me to switch and so far I‚Äôm happy, it‚Äôs significantly less work than before, I can check the Docker Compose files into version control, and backups are easy with everthing inside Docker volumes.</p>

<p>Anyway ‚Äì here is the scenario I want to talk about: You have one or more Docker containers and you want to route all its traffic through a WireGuard VPN, but not the other containers‚Äô or the host‚Äôs traffic. You have root access to the host machine.</p>

<h2 id="wg-quick">wg-quick</h2>
<p>The most straightforward way of using WireGuard is <a href="https://git.zx2c4.com/wireguard-tools/about/src/man/wg-quick.8"><em>wg-quick</em></a>. You just need a configuration file, about 10 lines long (take a look at an OpenVPN config file and you will appreciate this shortness), run <code>sudo wg-quick up {config file}</code> and your VPN is up and running. These files also work with the Android/iOS/MacOS/Windows apps.</p>
<p>For example, the VPN provider <a href="https://mullvad.net/">Mullvad</a>, which I can recommend 100%, lets you download wg-quick files for easy setup.</p>
<p>wg-quick is easy, but it routes <em>all</em> traffic through the VPN, which is what you want <em>most of the times</em>, but not in our use case. Watch out, the allowed IP range does not help as you might think: You can tell WireGuard that only traffic <em>to</em> specific IPs should be routed through the VPN, which makes sense for something like a VPN for employees: only traffic to the company‚Äôs network should go through the VPN. We however need to filter by <em>source</em>. wg-quick can‚Äôt do that.</p>

<p>After quite a lot of searching I finally found a great <a href="https://nbsoftsolutions.com/blog/routing-select-docker-containers-through-wireguard-vpn#solution-2">blog article</a> detailing a solution to our exact problem using the <code>wg</code> and <code>ip</code> tools directly (and one using WireGuard client inside another container). This article is mostly based on that one.</p>
<p>The gist of that that method is: You set up a WireGuard interface manually, the same way wg-quick does internally, but without any routing to it yet. Then you add a routing rule via <code>ip</code> that sends all traffic from a specific subnet to the VPN. Lastly, you configure the desired Docker container to use exactly that subnet using Docker Compose or <code>docker network</code>.</p>
<p>While it is a nice and elegant solution, I think it is kind of cumbersome to configure, so I tried to find a more comfortable way of setting this up.</p>
<h2 id="systemd-networkd">systemd-networkd</h2>
<p>While I agree with some of the criticism against systemd and its policies, systemd-networkd really is the best thing that ever happened to network configuration on Linux. Instead of fiddling around with awfully complex tools like <code>ip</code> or weird network managers, you can set up your network with short, few and well-documented plain-text config files. I love it. Turns out it also has everything we need for tunneling our Docker containers, and in a nice and easy way. This is the solution I went with and want to show you.</p>

<p>For the impatient. For detailed instructions see below.</p>
<p>To tunnel a container through a WireGuard VPN given a wg-quick config file from your VPN provider, add these files to <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb1"><pre><code><span id="cb1-1"><span>[NetDev]</span></span>
<span id="cb1-2"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb1-3"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb1-4"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span>[WireGuard]</span></span>
<span id="cb1-7"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span>[WireGuardPeer]</span></span>
<span id="cb1-10"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb1-11"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb1-12"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb2"><pre><code><span id="cb2-1"><span>[Match]</span></span>
<span id="cb2-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span>[Network]</span></span>
<span id="cb2-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb2-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb2-7"></span>
<span id="cb2-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb2-9"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb2-10"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span>[Route]</span></span>
<span id="cb2-13"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above in [Network] in Address}</span></span>
<span id="cb2-14"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>[Route]</span></span>
<span id="cb2-17"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb2-18"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb2-19"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb2-20"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>Then run <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code>. Now you can run docker containers with <code>--net=tunneled0</code> to tunnel them.</p>
<p>Alternatively use Docker Compose to create and use a Docker network in that subnet:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb3-2"><span>services</span><span>:</span></span>
<span id="cb3-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb3-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb3-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb3-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb3-7"><span>      </span><span>tunneled0</span><span>:</span><span> </span><span>{}</span></span>
<span id="cb3-8"><span>networks</span><span>:</span></span>
<span id="cb3-9"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb3-10"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb3-11"><span>      </span><span>config</span><span>:</span></span>
<span id="cb3-12"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<p>That‚Äôs it!</p>

<h2 id="preparation">Preparation</h2>
<p>Make sure that your host has:</p>
<ul>
<li>systemd. Most Linuxes do.</li>
<li>The WireGuard kernel module installed or kernel 5.6 or newer running.</li>
<li>The WireGuard tools installed.</li>
<li>Docker and optionally Docker Compose installed.</li>
<li>A working network connection. I don‚Äôt think it needs to be configured using systemd-networkd, though I haven‚Äôt tested that. I recommend to use networkd if possible anyway.</li>
<li>systemd-networkd running and enabled (<code>sudo systemctl enable systemd-networkd &amp;&amp; systemctl start system-networkd</code>).</li>
</ul>
<h2 id="setting-up-the-interface">Setting up the Interface</h2>
<p>First we have to get the WireGuard interface running. We couldn‚Äôt do it with <code>wg-quick</code> as it automatically routes all traffic through it, and using <code>wg</code> is cumbersome, so we use systemd-networkd. All we have to do is add two files in <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb4"><pre><code><span id="cb4-1"><span>[NetDev]</span></span>
<span id="cb4-2"><span># Or any other name</span></span>
<span id="cb4-3"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb4-4"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb4-5"><span># Or your own description</span></span>
<span id="cb4-6"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span>[WireGuard]</span></span>
<span id="cb4-9"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb4-10"></span>
<span id="cb4-11"><span>[WireGuardPeer]</span></span>
<span id="cb4-12"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb4-13"><span># Remeber, these are allowed target IPs, not source, therefore we allow all</span></span>
<span id="cb4-14"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb4-15"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb5"><pre><code><span id="cb5-1"><span>[Match]</span></span>
<span id="cb5-2"><span># Same as in .netdev file</span></span>
<span id="cb5-3"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb5-4"></span>
<span id="cb5-5"><span>[Network]</span></span>
<span id="cb5-6"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb5-7"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span></code></pre></div>
<p>As you can see, it‚Äôs very similar to and just as easy as a wg-quick config file and most values can be taken straight from said file. For more info take a look at the man pages of <a href="https://www.freedesktop.org/software/systemd/man/systemd.netdev.html">netdev</a> and <a href="https://www.freedesktop.org/software/systemd/man/systemd.network.html">network</a> files.</p>
<p>The names of the files can be adjusted to your liking. Note that systemd-networkd reads config files in alphabetic order, so adjust the prefixed numbers in the names if necessary.</p>
<p>Use <code># systemctl restart systemd-networkd</code> (or reboot to be sure) to apply the configs. Now you can verify that the inferface is actually working:</p>
<pre><code>$ curl -4 icanhazip.com
$ sudo curl -4 --interface wg0 icanhazip.com</code></pre>
<p>The results of the two <code>curl</code> calls should be different, the first shows your normal IP, the second one should yield the VPN IP address. Note that for me the second curl only works as root (probably curl can only bind to the interface as root for some reason). With <code>sudo wg</code> and <code>networkctl status wg0</code> you can get further info about the interface.</p>
<h2 id="routing">Routing</h2>
<p>Now that we got the WireGuard interface up and running we have to arrange for the traffic of our Docker container to actually go through it. Turns out all we have to do is adding four lines to <code>85-wg0.network</code>. This it how it should look like:</p>
<p><strong>Updated <code>85-wg0.network</code>:</strong></p>
<div id="cb7"><pre><code><span id="cb7-1"><span>[Match]</span></span>
<span id="cb7-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>[Network]</span></span>
<span id="cb7-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb7-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb7-9"><span># Or any other unused private subnet</span></span>
<span id="cb7-10"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb7-11"><span># Or any other unused table number</span></span>
<span id="cb7-12"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-13"></span>
<span id="cb7-14"><span>[Route]</span></span>
<span id="cb7-15"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above}</span></span>
<span id="cb7-16"><span># Same table number as above</span></span>
<span id="cb7-17"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-18"></span>
<span id="cb7-19"><span>[Route]</span></span>
<span id="cb7-20"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb7-21"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb7-22"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb7-23"><span># Same table number as above</span></span>
<span id="cb7-24"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>What the <code>[RoutingPolicyRule]</code> section does is taking all traffic from the specified subnet and looking up the routes in routing table 242 for it. We add a route to (hopefully previously empty) table 242 with the <code>[Route]</code> section, and that route sends the traffic to our WireGuard interface because we set the interface‚Äôs address as gateway.</p>
<p>The second <code>[Route]</code> section sets a blackhole route in the same table with a metric of 1, that means a lower priority than the default metric of 0. This should discard all traffic (instead of routing it through the default network without any VPN) if the VPN gateway is down and therefore prevent leaks.</p>
<p>That should be all we have to do on the system side!</p>
<h2 id="using-it-with-docker">Using it with Docker</h2>
<p>To actually get Docker to use the interface with specific containers we have two possibilities.</p>
<p>Note for both methods that published ports will not be available on <code>localhost</code> on the host as they normally would as all container traffic goes through the VPN (which is what we wanted, of course). So if you add an exposed port it must be accessed through the VPN‚Äôs outside address.</p>
<h3 id="docker-directly">Docker Directly</h3>
<p>Create a Docker network in the subnet we used in the systemd-networkd config file with <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code> (or use any other name than <code>tunneled0</code>), then run containers in that network by using the <code>--net=tunneled0</code> option. With the <code>--dns</code> option you can set a custom DNS so that no DNS traffic gets leaked.</p>
<p>For example, you can use <code>sudo docker run -t --net=tunneled0 curlimages/curl icanhazip.com</code> to check that the returned IP is actually the VPN‚Äôs IP.</p>
<h3 id="docker-compose">Docker Compose</h3>
<p>This is the more comfortable method. You can use this as a base for your own compose files:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb8-2"><span>services</span><span>:</span></span>
<span id="cb8-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb8-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb8-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb8-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb8-7"><span>      # Or your own name</span></span>
<span id="cb8-8"><span>      </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-9"><span>networks</span><span>:</span></span>
<span id="cb8-10"><span>  # Same name as above</span></span>
<span id="cb8-11"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-12"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb8-13"><span>      </span><span>config</span><span>:</span></span>
<span id="cb8-14"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<h2 id="port-forwarding">Port Forwarding</h2>
<p>You can use Docker‚Äôs normal port publishing options to make ports available through the VPN. So, for example, if your VPN provider gives you port <code>1234</code> and you want port <code>80</code> inside your container to be available through the VPN, call Docker with <code>-p 1234:80</code> (do not forget ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eisfunke.com/article/docker-wireguard-systemd.html">https://www.eisfunke.com/article/docker-wireguard-systemd.html</a></em></p>]]>
            </description>
            <link>https://www.eisfunke.com/article/docker-wireguard-systemd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583512</guid>
            <pubDate>Thu, 24 Sep 2020 20:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work on What Matters]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 95 (<a href="https://news.ycombinator.com/item?id=24581810">thread link</a>) | @wholien
<br/>
September 24, 2020 | https://staffeng.com/guides/work-on-what-matters | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/work-on-what-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/work-on-what-matters">Work on what matters</a></h4><div><p>We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.</p>
<p>If you‚Äôre continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you‚Äôll inevitably find that your work maintains an aloof indifference to your sacrifice rather than rewarding it. Only through <a href="https://lethain.com/forty-year-career/">pacing your career to your life</a> can you sustain yourself for the long-term.</p>
<p>Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.</p>
<p>First a discussion on a few common ways to get tripped up: <em>snacking</em>, <em>preening</em>, and <em>chasing ghosts</em>. Then we‚Äôll get into the good stuff: how <em>do</em> you work on what really matters?</p>
<h2>Avoid snacking</h2>
<p>Hunter Walk recommends that folks <a href="https://hunterwalk.com/2016/06/18/the-best-startups-resists-snacks-im-not-talking-about-food/">avoid ‚Äúsnacking‚Äù</a> when they prioritize work. If you‚Äôre in a well-run organization, at some point you‚Äôre going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice--easy and low-impact--is what Walk refers to as <em>snacking</em>.</p>
<p>When you‚Äôre busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you‚Äôre unlikely to learn much from doing them, others are likely equally capable of completing them (<em>and</em> for some of them it might be a good development opportunity), and there‚Äôs a tremendous opportunity cost versus doing something higher impact.</p>
<p>It‚Äôs ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you‚Äôre spending on high-impact work versus low-impact work. In senior roles, you‚Äôre more likely to self-determine your work and if you‚Äôre not deliberately tracking your work, it‚Äôs easy to catch yourself doing little to no high-impact work.</p>
<h2>Stop preening</h2>
<p>Where ‚Äúsnacking‚Äù is the broad category of doing easy and low-impact work, there‚Äôs a particularly seductive subset of snacking that I call ‚Äúpreening.‚Äù Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can‚Äôt distinguish between preening and impact, which is why it‚Äôs not uncommon to see some companies‚Äô senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.</p>
<p>If you‚Äôre taking a short-term look at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">career growth</a>, then optimizing for your current organization‚Äôs pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you‚Äôre thinking about developing yourself to succeed as your <a href="https://lethain.com/growing-with-your-company/">current role grows in complexity</a> or across multiple organizations, then it‚Äôs far more important to strike a balance between valued work and self-growth.</p>
<p>This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company‚Äôs leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don‚Äôt be surprised when your success in the company depends on those activities.</p>
<p>Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work <em>will</em> suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn‚Äôt you, then your attempt to exchange your good judgement for company success will end up failing anyway: you‚Äôll get held accountable for the lack of true impact where others who match the company‚Äôs expectation of how a leader appears will somehow slip upward.</p>
<h2>Stop chasing ghosts</h2>
<p>Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn‚Äôt consistently the case. It‚Äôs surprisingly common for a new senior leader to join a company and immediately drive <a href="https://lethain.com/grand-migration/">a strategy shift that fundamentally misunderstands the challenges at hand</a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.</p>
<p>As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you‚Äôve been repeatedly told that you‚Äôve been hired to fix something deeply broken -- you‚Äôre the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.</p>
<p>I had a recent discussion with someone who argued that new senior leaders <em>deliberately</em> push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that <em>does</em> go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you‚Äôre awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.</p>
<h2>Existential issues</h2>
<p>Now that you‚Äôre done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal <a href="https://lethain.com/iterative-elimination-tournaments/">iterative elimination tournament</a>, balancing future success against surviving until that future becomes the present. If you‚Äôre about to lose one of those rounds, then always focus there.</p>
<p>Running out of money, <a href="https://lethain.com/digg-v4/">like my experience at Digg</a>, can be the most obvious issue, but not every existential issue is financial, like <a href="https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/">Twitter‚Äôs fail whale stability challenges</a> or adapting to the shifts caused by the Covid-19 pandemic.</p>
<p>If something dire is happening at your company, then that‚Äôs the place to be engaged. Nothing else will matter if it doesn‚Äôt get addressed.</p>
<h2>Work where there‚Äôs room <em>and</em> attention</h2>
<p>Existential issues are usually <em>not</em> the most efficient place to add your efforts, but efficiency isn‚Äôt a priority when the walls are crashing down around you. You <em>should</em> swarm to existential problems, but if a problem isn‚Äôt existential then you should be skeptical of adding your efforts where everyone‚Äôs already focused. Folks often chase leadership‚Äôs top priority, but with so many folks looking to make their impact there, it‚Äôs often challenging to have a meaningful impact.</p>
<p>Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing <em>ok</em> but could be doing <em>great</em> with your support?</p>
<p>Sometimes you‚Äôll find work that‚Äôs <em>worthy</em> of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn‚Äôt value that work. In some companies this is developer tooling work, in others it‚Äôs inclusion work, and in most companies it‚Äôs <a href="https://noidea.dog/glue">glue work</a>.</p>
<p>There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you‚Äôll be able to make rapid initial progress on it, which <em>feels</em> like a good opportunity to invest. At some point, though, you‚Äôll find that the work needs support, and it‚Äôs quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.</p>
<p>Does this mean you shouldn‚Äôt do inclusion work? No, that‚Äôs not the conclusion I want you to take away from this. Sometimes an area that an organization doesn‚Äôt pay attention to is so important that you‚Äôre going to want to advocate for it to start paying attention. Teaching a company to value something it doesn‚Äôt care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it‚Äôs important to recognize what you‚Äôre up against and time your efforts accordingly.</p>
<h2>Foster growth</h2>
<p>One area that‚Äôs often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. <em>Hiring</em> has a lot of folks involved in it, usually in terms of optimizing the <a href="https://lethain.com/hiring-funnel/">hiring funnel</a>, but onboarding, mentoring and coaching are wholly neglected at many companies despite being <em>at least</em> <a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/">as impactful as hiring to your company‚Äôs engineering velocity</a>.</p>
<p>If you start dedicating even a couple hours a week to developing the team around you, it‚Äôs quite likely that will become your legacy long after your tech specs and pull requests are forgotten.</p>
<h2>Edit</h2>
<p>A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as <em>editing</em> your team‚Äôs ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staffeng.com/guides/work-on-what-matters">https://staffeng.com/guides/work-on-what-matters</a></em></p>]]>
            </description>
            <link>https://staffeng.com/guides/work-on-what-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581810</guid>
            <pubDate>Thu, 24 Sep 2020 18:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We cancelled standups and let the team build]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 226 (<a href="https://news.ycombinator.com/item?id=24581360">thread link</a>) | @thellimist
<br/>
September 24, 2020 | https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>üëã I'm Julian, the Cofounder of <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a>. We're building dashboards and alerts that plug into Github - helping engineering leaders build happier, healthier, more productive teams. </p><p>We wanted to share a quick story on why "we cancelled standups and just let the team build". </p><p>It's not as crazy as it sounds so let's dive an and see what happened..</p><p>‚Äç</p><h2>So.. why did we do this?</h2><p>‚Äç</p><h4>At first we were doing great</h4><p>At first the team was moving at (what seemed to be) the speed of light. We were handling issues, fixing bugs, launching features. We even tackled our biggest, nagging pieces of technical debt. Dream come true, right? As a team of technical founders, we patted ourselves on the back for a job well done. It felt like we couldn't be stopped.</p><p>‚Äç</p><h4>But things quickly turned around on us..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cc6238ba8f66e10c539_Screenshot_2020-09-08_at_10.22.47_PM.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And we noticed an odd pattern happening daily..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc18e8a5d4f630d45d4f2_2.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>We brought this data to the team and uncovered a few issues.. Here are some notes from our retro</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6ccdaf16b35490656f58c6_retro-summary.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h2>So.. What did we do?</h2><p>‚Äç</p><h4>We asked for suggestions. Here are the results..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd0bbf86c9040f44cc92b_retro-votes.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Top Votes:&nbsp;</h4><ol start="" role="list"><li>Cancel Standup</li><li>Work on 'Fun Projects'</li></ol><p>‚Äç</p><p>Might seem crazy but we like to empower the team to improve themselves. &nbsp;We take pride in our ability to iterate our process as often as possible. </p><p>Plus we've got Haystack to see if our changes are working.</p><p>So why not?&nbsp;Let's try it for a week. Revert back if it isn't working out.</p><p>‚Äç</p><h2>We cancelled standup and let the team 'just build'.</h2><p>‚Äç</p><h4>We did agree on some ground rules though..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd49e16b35472506f74b8_fun-sprint-etiquette.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>And with those rules in place we were off üí®üö£‚Äç‚ôÄÔ∏è</h4><p>Without hesitation we kicked off. Very surprised to see how many 'fun projects' the team already had in mind. It didn't take much prompting at all.</p><p>‚Äç</p><h2>And.. We had our most productive week EVER:</h2><p>‚Äç</p><h4>We recovered our Throughput!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc209c0fe2df87e4583c0_3.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Improved our Cycle Time (reversing the trend)!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc20f1523b25682b1fe92_4.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Got our 'deep work' back.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2169b6b491e6744cd11_5.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And tackled projects we've wanted to do for MONTHS.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2313f047785e14bf727_11.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Most Importantly..We DECREASED BURNOUT</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd71016b35499cd6f7f8d_before.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc24b1523b2af6fb20099_13.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><p>‚Äç</p><h2>It was a HUGE success.</h2><p>The experiment went better than we could have hoped. By removing standups and letting the team work on new, exciting projects we were able to get out of the funk we found ourselves in. Without skipping a beat our team is refreshed, recovered, and excited.</p><p>‚Äç</p><p>‚Äç</p><h2>Does this mean no more stand-ups or roadmaps?</h2><p>Well.. No. But we are considering it. </p><p>‚Äç</p><p>We'll continue to experiment until we find the right balance. Today, we do 2-3 in-person standups per week with async standups on Slack the other days. We carefully document our work in Notion everyday and have Weekly Kick-Off meetings every Monday.</p><p>‚Äç</p><p>The new process is working well so far - plus we have Haystack to help us check-in and make changes if needed.</p><p>‚Äç</p><p>‚Äç</p><h2>So.. how often do YOU experiment with process?</h2><p>The 'right' process is a constantly moving target. What works one day might not work the next. It's important to empower your team to make changes when necessary and improve their day-to-day experience. </p><p>‚Äç</p><p>If you want to experiment like a mad man(woman) on your process. AGGRESSIVELY enable improvement. Empower your team to improve their own work environment - then come check out <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a> and we'll show you how to implement a culture of continuous improvement.</p><p>‚Äç</p><p>Either way, hope our story got your wheels turning!</p><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get insights in your inbox every morning. Plus a dashboard to track improvements over time.</p><p>‚Äç</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581360</guid>
            <pubDate>Thu, 24 Sep 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping the Dark Forest]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24580879">thread link</a>) | @CyrusL
<br/>
September 24, 2020 | https://samczsun.com/escaping-the-dark-forest/ | <a href="https://web.archive.org/web/*/https://samczsun.com/escaping-the-dark-forest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://samczsun.com/content/images/size/w300/2020/09/109768371_xl.jpg 300w,
                            https://samczsun.com/content/images/size/w600/2020/09/109768371_xl.jpg 600w,
                            https://samczsun.com/content/images/size/w1000/2020/09/109768371_xl.jpg 1000w,
                            https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg" alt="Escaping the Dark Forest">
</figure>
<section>
<div>
<p><em>On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract. This is our story.</em></p><p>I was about to wrap up for the night when I decided to take another look at some smart contracts.</p><p>I wasn‚Äôt expecting anything interesting, of course. Over the past few weeks I had seen countless yield farming clones launch with the exact same pitch: stake your tokens with us and you could be the next cryptocurrency millionaire. Most were simply forks of well-audited code although some tweaked bits and pieces, sometimes with catastrophic results.</p><p>But amidst all of the noise there was some code I hadn‚Äôt seen before. The contract held over 25,000 Ether, worth over 9,600,000 USD at the time, and would be a very juicy payday for anyone who managed to find a bug in its logic.</p><p>I quickly looked through the code for where Ether is transferred out and found two hits. One of them transferred the Ether to a hardcoded token address, so that could be ignored. The second was a burn function that transferred Ether to the sender. After tracing the usage of this function, I discovered that it would be trivial for anyone to mint tokens to themselves for free, but then burn them in exchange for all of the Ether in the contract. My heart jumped. Suddenly, things had become serious.</p><p>Some digging revealed that the contract I had found was part of <a href="https://lien.finance/">Lien Finance</a>‚Äôs protocol. Unfortunately, their team was anonymous! The only IM platform they supported was Telegram, and I couldn‚Äôt be sure that the admins of that channel were actually protocol developers or just a few early supporters. The last thing I wanted to do was accidentally leak the exploit to the wrong person.</p><p>After browsing their website a little while longer, I noticed that they had worked with ConsenSys Diligence and CertiK for an audit. This seemed like a good avenue, since both ConsenSys and CertiK must have interacted with the developers during their audits. I quickly pinged <a href="https://twitter.com/maurelian_">maurelian</a> on Telegram.</p><figure><img src="https://samczsun.com/content/images/2020/09/image.png" alt=""><figcaption>You never want to be on the receiving end of this message</figcaption></figure><p>Unfortunately, time ticked on, my heart kept pounding, but there was no response from maurelian. It seemed like he had already gone to sleep. Desperate, I sent a message to the ETHSecurity Telegram channel.</p><figure><img src="https://samczsun.com/content/images/2020/09/image-1.png" alt=""><figcaption>Artist's rendering of the message, since I deleted the original</figcaption></figure><p>Within minutes, I got a message from someone I‚Äôd worked with quite a few times in the past - <a href="https://twitter.com/wadealexc">Alex Wade</a>.</p><hr><p>My head had just hit the pillow when I got a knock on my door. It was my roommate: ‚ÄúSam‚Äôs in the ETHSec Telegram asking for anyone from Diligence.‚Äù</p><figure><img src="https://samczsun.com/content/images/2020/09/image-2.png" alt=""><figcaption>It was, in fact, a long night</figcaption></figure><p>Knowing Sam, this couldn‚Äôt be good. I found a channel we‚Äôd set up with Lien a few months ago and an email address. Better than nothing, given their team was anon.</p><p>I was still half asleep. Sam, not wanting to commit details to text, asked for a Zoom call. Groggily wishing I was back in bed, I attempted to gauge the severity of the situation:</p><figure><img src="https://samczsun.com/content/images/2020/09/image-4.png" alt=""><figcaption>Five minutes later, it was clear that the situation called for coffee</figcaption></figure><p>Sam and I reviewed the code together. By this point, Sam had already prepared a sample exploit and was able to confirm the issue on his machine. The conversation quickly turned to discussing options:</p><ol><li>Attempt to exploit the issue ourselves.</li><li>Reach out to Lien and have them go public, urging users to withdraw.</li></ol><p>Neither of these were appealing options. The first was risky because, as discussed in <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff">Ethereum is a Dark Forest</a> by <a href="https://twitter.com/danrobinson">Dan Robinson</a> and <a href="https://twitter.com/gakonst/">Georgios Konstantopoulos</a>, the possibility of our transactions getting frontrun was very real. The second option was similarly risky, as a public announcement would draw attention to the problem and create a window of opportunity for attackers. We needed a third option.</p><p>Recalling a section from <em>Ethereum is a Dark Forest</em>, Sam reached out to <a href="https://twitter.com/epheph">Scott Bigelow</a>:</p><blockquote>If you find yourself in a situation like this, we suggest you reach out to Scott Bigelow, a security researcher who has been studying this topic and has a prototype implementation for a better obfuscator.</blockquote><hr><p>After participating in the recovery attempt from <em>Ethereum is a Dark Forest, </em>which ultimately lost to front-runners, I was hungry for a re-match. I‚Äôve spent time monitoring front-running and designing a simple system that seemed able to fool generalized front-runners, at least for the $200 I‚Äôd been able to test it with. When Sam reached out to me in the late evening with the innocent-sounding ‚Äúmind staying up for another hour or so‚Äù, I couldn‚Äôt wait to try it out! I was already working it out: how I‚Äôd make a few tweaks, stay up a couple hours, feel a sense of accomplishment having helped rescue and return a few thousand dollars of user funds, and get a good night‚Äôs sleep.</p><p>Those plans immediately fell apart when Sam shared the contract with me: ~25,000 ETH, valued at $9.6M, at stake. For as much as I wanted that rematch, $9.6M was way outside my humble script‚Äôs weight class.</p><p><br>For the past few months, I had been trying to establish contacts with miners for this very purpose: white-hat transaction cooperation. If ever there was a time to appeal to a miner to include a transaction without giving front-runners the chance to steal it, it was now. Luckily, <a href="https://twitter.com/tzhen">Tina</a> and I have worked together over the past few months on establishing this cooperation. It seemed like a slim chance at the time, but it was worth a shot: let‚Äôs bring Tina into the rescue attempt to work with a mining pool to mine a private transaction.</p><hr><p>I had just evacuated from the Bobcat forest fire and was sipping on unknown beachy drinks zoning out to the monotonic sound of dark Pacific waves, when a Telegram DM from Sam buzzed me back to a darker reality: ‚Äúfunds at risk, frontrunnable‚Äù. Over the last few weeks, I had been collaborating with Sam and Scott on a research project on MEV and could already guess their ask before they sent it: a direct channel to shield a whitehat tx from getting sniped by the ‚Äúadvanced predators‚Äù in the mempool‚Äôs ‚Äúdark forest‚Äù.</p><p>Since this was a risky move that entailed exposing our strategy to miners, we decided we should first try to get the greenlight from the anonymous Lien team. While Alex was trying to get in contact via ConsenSys-internal channels, we tried to loop in CertiK as well.</p><p>I realized it may take another 4 hours before Certik's US-based auditors would wake up, yet the clock was ticking. &nbsp;Knowing nothing much about CertiK beyond the fact it had serviced quite a few Asian projects, I tried to reach the CertiK China team to arbitrage the time zone difference. I blasted a casual sounding message in ‚ÄúDeFi the World‚Äù and ‚ÄúYellow Hats‚Äù WeChat groups. Four leads slid into my DMs independently within 30 minutes, confirming the WeChat ID that I connected with was indeed the real Zhaozhong Ni, CTO of CertiK. I was added to a WeChat group with 5 CertiK team members, yet at this point I was still not in a position to disclose the project nor the vulnerability. To minimize the exposure and potential liability, we could only invite one member from Certik to join our whitehat operation. After passing a final verification via official email, Georgios Delkos, the engineering lead at CertiK joined our call.</p><p>With Georgios‚Äôs help, Alex was able to quickly get in contact with the Lien team and verify their identity. We brought them up-to-speed on the current situation and asked for their permission to try working directly with a mining pool to rescue the vulnerable funds. After some deliberation, the Lien team agreed that the risk from trying to rescue the funds directly or publishing a warning was too high, and gave the go-ahead to continue.</p><p>Now we needed to identify a mining pool that had the infrastructure ready in place and would be willing to cooperate with us ASAP. Which mining pool should we tap? Which contact from the pool would be in a position to make technical decisions swiftly that help us beat the clock?</p><p>SparkPool came to mind, as I knew they had been working on a piece of public infrastructure called Taichi Network that could easily offer what we needed. I decided to ping Shaoping Zhang, SparkPool‚Äôs co-founder, who had helped me investigate mempool events in the past.</p><p>Half an hour later, Shaoping responded: ‚ÄúYou mean do we have a whitelist service for transactions? Sorry, we don‚Äôt.‚Äù Oops, something was lost in translation, ‚Äúwhitehat‚Äù and ‚Äúwhitelist‚Äù sounded similar in Chinese.</p><p>‚ÄúThere‚Äôs 10mn dollar worth of funds at risk. samczsun is on the line.‚Äù I tried again to communicate the situation without revealing any specifics.</p><figure><img src="https://samczsun.com/content/images/2020/09/photo5145442418169063579.png" alt="" srcset="https://samczsun.com/content/images/size/w600/2020/09/photo5145442418169063579.png 600w, https://samczsun.com/content/images/size/w1000/2020/09/photo5145442418169063579.png 1000w, https://samczsun.com/content/images/size/w1600/2020/09/photo5145442418169063579.png 1600w, https://samczsun.com/content/images/2020/09/photo5145442418169063579.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>‚ÄúAre you guys saving the world again? Do you need help from our mining pool?‚Äù To my surprise and great relief, Shaoping jokingly extended an offer to help. After official email verification, Shaoping popped into our marathon Zoom call with the support of a roomful of SparkPool devs.</p><hr><p>After lunch, just when I was about to take a nap, I received a message from Tina: ‚ÄúHas SparkPool ever helped with whitehat transactions??‚Äù I mistook it for whitelisting a transaction at first. No whitehats had approached us before, and we were not familiar with what ‚Äúwhitehat transactions‚Äù entailed. After Tina explained it in more details, I realized that what they needed was a private transaction service, i.e. the whitehats wanted to send transactions to save a DeFi contract, but in order to prevent getting front-runned, they needed a mining pool to include the transaction without broadcasting it.</p><p>We had been working on a ‚Äúprivate transaction‚Äù feature on our Taichi Network, which was still under development and had not been tested. I brought the whitehats‚Äô request to our development team, and explained the urgency: our private transaction feature needed to be in production within a few hours. Our devs said they could try their best to finish in time, and we immediately got to work. We finished development of the private transaction feature in 2 hours, and then spent some time fixing bugs.</p><p>After we completed our internal testing, we sent the <em>whitehat.taichi.network</em> endpoint to ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samczsun.com/escaping-the-dark-forest/">https://samczsun.com/escaping-the-dark-forest/</a></em></p>]]>
            </description>
            <link>https://samczsun.com/escaping-the-dark-forest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580879</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing harm of manual dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24580479">thread link</a>) | @amkkma
<br/>
September 24, 2020 | https://andreaskroepelin.de/blog/manual_dispatch/ | <a href="https://web.archive.org/web/*/https://andreaskroepelin.de/blog/manual_dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Just a short one today:
New users of Julia coming from other dynamically typed languages might write functions like</p>
<div><pre><code data-lang="julia"><span>function</span> <span>foo</span><span>(</span><span>x</span><span>)</span>
    <span>if</span> <span>x</span> <span>isa</span> <span>Int</span>
        <span>x</span> <span>+</span> <span>x</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>Float64</span>
        <span>x</span> <span>/</span> <span>2.0</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>String</span>
        <span>length</span><span>(</span><span>x</span><span>)</span>
    <span>else</span>
        <span>1</span>
    <span>end</span>
<span>end</span>
</code></pre></div><p>This is clearly unidiomatic and should be written as</p>
<div><pre><code data-lang="julia"><span>bar</span><span>(</span><span>x</span><span>::</span><span>Int</span><span>)</span> <span>=</span> <span>x</span> <span>+</span> <span>x</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>Float64</span><span>)</span> <span>=</span> <span>x</span> <span>/</span> <span>2.0</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>String</span><span>)</span> <span>=</span> <span>length</span><span>(</span><span>x</span><span>)</span>
<span>bar</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span># or bar(x::Any), to be explicit</span>
</code></pre></div><p>because it is nicer to read and very easy to extend for other types of <code>x</code>.
Well, you technically can extend <code>foo</code> the same way as <code>bar</code>, but reading the definition of <code>foo</code> one would expect to then know its complete behavior, so it would be misleading.</p>
<p><em>However</em>, my point is that there is actually (maybe surprisingly) no harm at runtime for code as in <code>foo</code>!
The Julia compiler isn‚Äôt tricked that easily and will still produce optimal machine code for each type of the argument:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div><p>Both functions basically compile down to a single adding instruction (<code>leaq</code>; <code>retq</code> is for returning from the function and <code>nopw</code> is an operation that does nothing and is there for <a href="https://en.wikipedia.org/wiki/NOP_%28code%29%23Machine_language_instructions">technical reasons</a>).
Think about it this way:
When Julia compiles <code>foo(1)</code>, it knows that <code>1</code> is of type <code>Int</code>, can evaluate the <code>x isa Int</code> expression at compile time to <code>true</code>, and discard everything but the <code>x + x</code> without a problem.</p>
<h2 id="appendix">‚ÄúAppendix‚Äù</h2>
<p>For completeness, here is what‚Äôs produced in the other cases:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530607976</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A168</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530608088</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A1D8</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div>
        </div></div>]]>
            </description>
            <link>https://andreaskroepelin.de/blog/manual_dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580479</guid>
            <pubDate>Thu, 24 Sep 2020 16:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Reader]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24580453">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-6/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. This time I want to take a break
from compiling and finally add a <em>reader</em>. I‚Äôm finally getting frustrated
manually entering increasinly complicated ASTs, so I figure it is time. After
this post, we‚Äôll be able to type in programs like:</p>



<p>and have our compiler make ASTs for us! Magic. This will also add some nice
debugging tools for us. For example, imagine an interactive command line
utility in which we can enter Lisp expressions and the compiler prints out
human-readable assembly (and hex? maybe?). It could even run the code, too.
Check out this imaginary demo:</p>

<div><div><pre><code>lisp&gt; 1
; mov rax, 0x4
=&gt; 1
lisp&gt; (add1 1)
; mov rax, 0x4
; add rax, 0x4
=&gt; 2
lisp&gt;
</code></pre></div></div>

<p>Wow, what a thought.</p>

<h3 id="the-reader-interface">The Reader interface</h3>

<p>To make this interface as simple and testable as possible, I want the reader
interface to take in a C string and return an <code>ASTNode *</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>);</span>
</code></pre></div></div>

<p>We can add interfaces later to support reading from a <code>FILE*</code> or file
descriptor or something, but for now we‚Äôll just use strings and line-based
input.</p>

<p>On success, we‚Äôll return a fully-formed <code>ASTNode*</code>. But on error, well, hold
on. We can‚Äôt just return <code>NULL</code>. On many platforms, <code>NULL</code> is defined to be
<code>0</code>, which is how we encode the integer <code>0</code>. On others, it could be defined to
be <code>0x55555555</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> or something equally silly. Regardless, its value might
overlap with our type encoding scheme in some unintended way.</p>

<p>This means that we have to go ahead and add another immediate object: an
<code>Error</code> object. We have some open immediate tag bits, so sure, why not. We can
also use this to signal runtime errors and other fun things. It‚Äôll probably be
useful.</p>

<h3 id="the-error-object">The Error object</h3>

<p>Back to the object tag diagram. Below I have reproduced the tag diagram from
previous posts, but now with a new entry (denoted by <code>&lt;-</code>). This new entry
shows the encoding for the canonical <code>Error</code> object.</p>

<div><div><pre><code>High							     Low
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX00  Integer
0000000000000000000000000000000000000000000000000XXXXXXX00001111  Character
00000000000000000000000000000000000000000000000000000000X0011111  Boolean
0000000000000000000000000000000000000000000000000000000000101111  Nil
0000000000000000000000000000000000000000000000000000000000111111  Error &lt;-
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX001  Pair
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX010  Vector
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX011  String
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX101  Symbol
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX110  Closure
</code></pre></div></div>

<p>If we wanted to, we could even add additional tag bits to the (currently all 0)
payload, to signal different kinds of errors. Maybe later. For now, we add a
tag constant and associated <code>Object</code> and <code>AST</code> functions:</p>

<div><div><pre><code><span>const</span> <span>unsigned</span> <span>int</span> <span>kErrorTag</span> <span>=</span> <span>0x3f</span><span>;</span> <span>// 0b111111</span>
<span>uword</span> <span>Object_error</span><span>()</span> <span>{</span> <span>return</span> <span>kErrorTag</span><span>;</span> <span>}</span>

<span>bool</span> <span>AST_is_error</span><span>(</span><span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span> <span>return</span> <span>(</span><span>uword</span><span>)</span><span>node</span> <span>==</span> <span>Object_error</span><span>();</span> <span>}</span>
<span>ASTNode</span> <span>*</span><span>AST_error</span><span>()</span> <span>{</span> <span>return</span> <span>(</span><span>ASTNode</span> <span>*</span><span>)</span><span>Object_error</span><span>();</span> <span>}</span>
</code></pre></div></div>

<p>That should be enough to get us going for now. Perhaps we could even convert
our <code>Compile_</code> suite of functions to use this object instead of an <code>int</code>. It
would certainly be more informative. Maybe in a future post.</p>

<h3 id="language-syntax">Language syntax</h3>

<p>Let‚Äôs get back to business and think about what we want our language to look
like. This is a Lisp series but really you could adapt your reader to read any
sort of syntax. No need for parentheses if you‚Äôre allergic.</p>

<p>I‚Äôm going to use this simple Lisp reader because it‚Äôs short and simple, so
we‚Äôll have some parens.</p>

<p>First, our integers will look like integers in most languages ‚Äî <code>0</code>, <code>123</code>,
<code>-123</code>.</p>

<p>You can add support for other bases if you like, but I don‚Äôt plan on it here.</p>

<p>Second, our characters will look like C characters ‚Äî <code>'a'</code>, <code>'b'</code>, etc. Some
implementations opt for <code>#'a</code> but that has always looked funky to me.</p>

<p>Third, our booleans will be <code>#t</code> and <code>#f</code>. You‚Äôre also welcome to go ahead and
use symbols to represent the names, avoid special syntax, and have those
symbols evaluate to truthy and falsey values.</p>

<p>Fourth, the nil object will be <code>()</code>. We can also later bind the symbol <code>nil</code> to
mean <code>()</code>, too.</p>

<p>I‚Äôm going to skip error objects, because they don‚Äôt yet have any sort of
user-land meaning yet ‚Äî they‚Äôre just used in compiler infrastructure right
now.</p>

<p>Fifth, pairs will look like <code>(1 2 3)</code>, meaning <code>(cons 1 (cons 2 (cons 3
nil)))</code>. I don‚Äôt plan on adding support for dotted pair syntax. Whitespace will
be insignificant.</p>

<p>Sixth, symbols will look like any old ASCII identifier: <code>hello</code>, <code>world</code>,
<code>fooBar</code>. I‚Äôll also include some punctuation in there, too, so we can use <code>+</code>
and <code>-</code> as symbols, for example. Or we could even go full Lisp and use
<code>train-case</code> identifiers.</p>

<p>I‚Äôm going to skip closures, since they don‚Äôt have a syntactic representation
‚Äî they are just objects known to the runtime. Vectors and strings don‚Äôt have
any implementation right now so we‚Äôll add those to the reader later.</p>

<p>That‚Äôs it! Key points are: mind your plus and minus signs since they can appear
in both integers and symbols; don‚Äôt read off the end; have fun.</p>

<h3 id="the-reader-implementation">The Reader implementation</h3>

<p>Now that we‚Äôve rather informally specified what our language looks like, we can
write a small reader. We‚Äôll start with the <code>Reader_read</code> function from above.</p>

<p>This function will just be a shell around an internal function with some more
parameters.</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
  <span>word</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
  <span>return</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>&amp;</span><span>pos</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This is because we need to carry around some more state to read through this
string. We need to know how far into the string we are. I chose to use an
additional <code>word</code> for the index. Some might prefer a <code>char**</code> instead. Up to
you.</p>

<p>With any recursive reader invocation, we should advance through all the
whitespace, because it doesn‚Äôt mean anything to us. For this reason, we have a
handy-dandy <code>skip_whitespace</code> function that reads through all the whitespace
and then returns the next non-whitespace character.</p>

<div><div><pre><code><span>void</span> <span>advance</span><span>(</span><span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span> <span>++*</span><span>pos</span><span>;</span> <span>}</span>

<span>char</span> <span>next</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
<span>}</span>

<span>char</span> <span>skip_whitespace</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>for</span> <span>(</span><span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isspace</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>;</span>
  <span>}</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>We can use <code>skip_whitespace</code> in the <code>read_rec</code> function to fetch the next
non-whitespace character. Then we‚Äôll use that character (and sometimes the
following one, too) to determine what structure we‚Äôre about to read.</p>

<div><div><pre><code><span>bool</span> <span>starts_symbol</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
  <span>case</span> <span>'+'</span><span>:</span>
  <span>case</span> <span>'-'</span><span>:</span>
  <span>case</span> <span>'*'</span><span>:</span>
  <span>case</span> <span>'&gt;'</span><span>:</span>
  <span>case</span> <span>'='</span><span>:</span>
  <span>case</span> <span>'?'</span><span>:</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>default:</span>
    <span>return</span> <span>isalpha</span><span>(</span><span>c</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_rec</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>isdigit</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'+'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '+'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '-'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>-</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>starts_symbol</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_symbol</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '\''</span>
    <span>return</span> <span>read_char</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'t'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 't'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>true</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'f'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 'f'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>false</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'('</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '('</span>
    <span>return</span> <span>read_list</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>AST_error</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Note that I put the integer cases above the symbol case because we want to
catch <code>-123</code> as an integer instead of a symbol, and <code>-a123</code> as a symbol instead
of an integer.</p>

<p>We‚Äôll probably add more entries to <code>starts_symbol</code> later, but those should
cover the names we‚Äôve used so far.</p>

<p>For each type of subcase (integer, symbol, list), the basic idea is the same:
while we‚Äôre still inside the subcase, add on to it.</p>

<p>For integers, this means multiplying and adding (concatenating digits, so to
speak):</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_integer</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>,</span> <span>int</span> <span>sign</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>word</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>c</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>AST_new_integer</span><span>(</span><span>sign</span> <span>*</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It also takes a sign parameter so if we see an explicit <code>-</code>, we can negate the
integer.</p>

<p>For symbols, this means reading characters into a C string buffer:</p>

<div><div><pre><code><span>const</span> <span>word</span> <span>ATOM_MAX</span> <span>=</span> <span>32</span><span>;</span>

<span>bool</span> <span>is_symbol_char</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>return</span> <span>starts_symbol</span><span>(</span><span>c</span><span>)</span> <span>||</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_symbol</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>buf</span><span>[</span><span>ATOM_MAX</span> <span>+</span> <span>1</span><span>];</span> <span>// +1 for NUL</span>
  <span>word</span> <span>length</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>length</span> <span>=</span> <span>0</span><span>;</span> <span>length</span> <span>&lt;</span> <span>ATOM_MAX</span> <span>&amp;&amp;</span> <span>is_symbol_char</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]);</span> <span>length</span><span>++</span><span>)</span> <span>{</span>
    <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>}</span>
  <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>return</span> <span>AST_new_symbol</span><span>(</span><span>buf</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>For simplicity‚Äôs sake, I avoided dynamic resizing. We only get at most symbols
of size 32. Oh well.</p>

<p>Note that symbols can also have trailing numbers in them, just not at the front
‚Äî like <code>add1</code>.</p>

<p>For characters, we only have three potential input characters to look at:
quote, char, quote. No need for a loop:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_char</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]</span> <span>!=</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>AST_new_char</span><span>(</span><span>c</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This means that input like <code>''</code> or <code>'aa'</code> will be an error.</p>

<p>For booleans, we can tackle those inline because there‚Äôs only two cases and
they‚Äôre both trivial. Check for <code>#t</code> and <code>#f</code>. Done.</p>

<p>And last, for lists, it means we recursively build up pairs until we get to
<code>nil</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_list</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>')'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
    <span>return</span> <span>AST_nil</span><span>();</span>
  <span>}</span>
  <span>ASTNode</span> <span>*</span><span>car</span> <span>=</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>assert</span><span>(</span><span>car</span> <span>!=</span> <span>AST_error</span><span>());</span>
  <span>ASTNode</span> <span>*</span><span>cdr</span> <span>=</span> <span>read_l‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">https://bernsteinbear.com/blog/compiling-a-lisp-6/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580453</guid>
            <pubDate>Thu, 24 Sep 2020 16:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake ‚Äì A Namespace for the Decentralized Web]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24579284">thread link</a>) | @rasengan
<br/>
September 24, 2020 | https://meowis.ms/handshake.html | <a href="https://web.archive.org/web/*/https://meowis.ms/handshake.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://meowis.ms/"> &lt; </a>




<!-- <div class="subtitle"></div> -->

<p>Names are fundamental to human existence and how we relate to everything in the world. At the heart of all interactions lies the ability for all the parties to match names to the respective entities they stand for.</p>

<p>Names are so integral to the human experience that a strong argument can be made that if <em>something doesn√¢‚Ç¨‚Ñ¢t have a name, it does not exist.</em></p>

<p>Correspondingly, names on the internet are critical to our online existence. Users, apps, or machines locate a resource on the internet via its name. The name needs to not only be understood by humans but also needs to be uniquely identifiable by machines amongst the billions of potential destinations.</p>

<p>Given that the act of matching a name to the eventual resource is the starting point of trillions of internet transactions that happen daily,  it is no surprise that out of the three core layers of internet stack - naming (DNS), transportation (TCP/IP) and application (HTTP), naming is at the very start of the stack.</p>

<p>Naming needs a single source of truth as the names within the namespaces have to be unique across the whole system. Hence, an effective naming system cannot merely be a standard or a protocol, it has to meet all the other aspects of running an internet-scale namespace - including enforcement of unique names, the management of the naming records, scaling to internet traffic, while remaining fully accessible to anyone, anywhere.</p>

<h2 id="namespaces">Namespaces</h2>

<p>Names are the most valuable assets on the internet, but we don√¢‚Ç¨‚Ñ¢t own our own names. All of the crucial namespaces belong to centralized entities who control the namespaces and take that control away from you. This is true for all significant namespaces today - the ICANN namespace, Facebook, Twitter, and Google.</p>

<p>As a result, your name on the internet does not belong to you, but rather to the owners of these centralized namespaces.  With a stroke of the keyboard, they can remove anyone from existence.  If your name lives on a centralized namespace, your right to exist effectively belongs to someone else.</p>

<p>Centralized namespaces also determine much more than a user√¢‚Ç¨‚Ñ¢s ability to exist. They also decree a user√¢‚Ç¨‚Ñ¢s ability to search, match, and communicate with others. They unilaterally set the framework for what protocols can be used, which use cases are permitted, and what information can flow.</p>

<p>The power to enforce monopolies with little consequence also makes these centralized namespaces some of the most valuable properties on the internet today. Verisign makes billions a year controlling .com with practically zero innovation, while ICANN has the power to arbitrarily raise price caps of entire TLDs with their pet cartel companies. Facebook and Twitter controls exactly how users can use their names/accounts, and can heedlessly cancel pages and remove identities for barely specified reasons.</p>

<p>Everywhere we see, we are seeing the serious dangers of depending on centralized entities to exist and be found by others. The Internet is supposed to be kingless, but the ability to strike away one√¢‚Ç¨‚Ñ¢s existence and control exactly how the name is to be used makes the owners of these namespaces the de-facto kings/governors of the internet.</p>

<h2 id="the-world-needs-a-decentralized-namespace">The World Needs a Decentralized Namespace</h2>

<p>Of course, the ability of these centralized namespace owners to control digital existence, lockout access, and enforce monopolistic economics is the complete opposite goal of the decentralized web, which is the ability to exist, innovate, and create their own business models without the need for centralized control or systems.</p>

<p>Whether it√¢‚Ç¨‚Ñ¢s decentralized currencies, decentralized file systems, or decentralized servers - if these decentralized entities do not live on a widely used namespace, they simply do not exist to the vast majority of users on the internet.</p>

<p><em>Without a decentralized namespace widely readable by humans and resolvable by machines, it is impossible for the decentralized world to be widely adopted by users</em>.</p>

<p><strong>Criteria for a Decentralized Naming System</strong></p>

<p>Naming systems play a crucial role in discovery, connection and identification. As one of the most fundamental and long-lasting components of the internet backbone infrastructure, the bar needs to be set very high in terms of longevity, stability, and technical scalability.</p>

<p>For a decentralized naming system to become the legitimate namespace for the decentralized world, the bar is even higher. Without a centralized body in charge, the world has to trust that this naming system will exist in a stable state for a long time to come and stay relevant regardless of potential upheavals and technological progress.</p>

<p>As such, this naming system√¢‚Ç¨‚Ñ¢s fundamental construction needs to have certain key technical, social, and governance requirements:</p>

<ol>
  <li><strong>Be truly decentralized</strong>: what is the point of a decentralized naming system if it remains controlled by a small set of people?</li>
  <li><strong>Main key focus as a naming system</strong>: naming systems need to be extremely focused and fast. Can you imagine the DNS system operating reliably if it was also designed for delivering 4K video?</li>
  <li><strong>Be as accessible yet trustless as possible</strong>: anyone should be able to access the namespace directly in a fully trustless manner without intensive resources</li>
  <li><strong>Compatible with the rest of the internet</strong>: allowing for seamless usage with the rest of the application, user, and technical stack</li>
  <li><strong>Stability and upgradability at the protocol level</strong>: allowing for innovation moving forward without disrupting regular operations</li>
</ol>

<h2 id="handshake-design">Handshake Design</h2>

<p>Given these objectives, and with the general goal of the decentralized root zone and certificate authority, Handshake is the only naming system that is fundamentally suitable to be the namespace for decentralized web.</p>

<h3 id="1-focus-as-a-naming-system">1. Focus as a Naming System</h3>

<p>Let√¢‚Ç¨‚Ñ¢s consider the inherent complexity of an internet-scale naming system. For reference, the naming layer (DNS), unlike the other layers of the internet stack, is the only layer that is a system and not a protocol - the key difference between the two is that a protocol cannot enforce uniqueness of names, which is essential to a functioning namespace. It√¢‚Ç¨‚Ñ¢s also arguably by far the most complex layer with many competing technical, political, and economical demands.</p>

<p>As a standalone blockchain, Handshake has room to grow all on its own and govern itself without interfering with other projects or having to compete with different priorities with other use cases (like gaming or DeFi) trying to run in parallel on the same network. In addition, there are several fundamental constraints in other blockchains - for example, Bitcoin limited OP sizes and Ethereum√¢‚Ç¨‚Ñ¢s notoriously hard to sync blockchain.</p>

<p>If Handshake is built on another blockchain, the instability caused by these competing priorities for use cases and political interests also eliminates one of the core requirements for a decentralized naming infrastructure - which is stability. A naming infrastructure needs to be highly stable - remember - both users, hosts and developers need to be confident that the names will be around for a long time in the same format. For instance, Ethereum√¢‚Ç¨‚Ñ¢s sky high gas prices due to DeFi and the complex migration to ETH2 are both creating high levels of certainty around how apps will work in the future, and whether retail users will be able to have the same level of access as large ticket users.</p>

<p>Lastly, creating a native auction system is complicated and requires highly specific primitives, such as making coins unspendable for certain periods, and increases the complexity of the system if HNS is a non-native token.</p>

<h3 id="2-decentralization">2. Decentralization</h3>

<p>The other critical consideration is decentralization. <em>Remember, the goal here is to achieve a truly decentralized, uncensorable namespace independent of centralized control and policies. Anything less than will be completely redundant.</em></p>

<p>Ethereum is the most decentralized smart contract platform of date, but it√¢‚Ç¨‚Ñ¢s still insufficient as a base layer blockchain for a truly decentralized naming system. A system based on Ethereum either would have to be strictly immutable or engineer a governance mechanism with a single or multiple signers. For example, the ENS system on Ethereum has a 7-part multisig making it either censorable and shutting it off to any future innovations or upgrades. These mechanisms either risk shutting off future innovations or don√¢‚Ç¨‚Ñ¢t meet the decentralized requirement.</p>

<p>How about sidechains? Sidechains mostly rely on the main chain√¢‚Ç¨‚Ñ¢s security, which makes them completely subject to the same concerns above in terms of sharing priorities with the main chain. In addition, there is currently no such thing as a decentralized side-chain on Bitcoin. Counterparty is a one-way system, Liquid requires a small federated multisig, and Rootstock is currently federated waiting on Drivechain support from Bitcoin.</p>

<p>For all of PoW√¢‚Ç¨‚Ñ¢s issues, namely with the limited number of miners, it is built on competition which is inherently decentralized as well as clear separation of concerns between developers, users, and miners. This is in contrast to PoS which encourages stakeholders to collude and centralize, creating a largely plutocratic environment.</p>

<p>As such, true naming decentralization with the ability to upgrade is likely best achieved on a standalone PoW chain with robust hash power, a strong ecosystem, and miner confidence in the value of the blockchain.</p>

<h3 id="3-ease-of-trustless-resolution">3. Ease of Trustless Resolution</h3>

<p>Compared to other naming blockchains, _the entire Handshake stack is engineered for the use case of creating a human readable, truly decentralized, fully accessible and secure namespace. _</p>

<p>The naming data in Handshake is stored in a novel data structure called an Urkel Tree,  which was designed specifically for this purpose. The proofs are small and verify quickly, allowing name resolution to happen with very little computation.</p>

<p>Secondly, a highly unique application called HNSD written in C only handles the DNS functions of Handshake (avoiding ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meowis.ms/handshake.html">https://meowis.ms/handshake.html</a></em></p>]]>
            </description>
            <link>https://meowis.ms/handshake.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579284</guid>
            <pubDate>Thu, 24 Sep 2020 15:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS 0.7.0, the SECIO retirement edition]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24578953">thread link</a>) | @georgyo
<br/>
September 24, 2020 | https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Jacob Heun &amp; Adin Schmahmann on 2020-09-24</p>

      

      

<p>In August we announced the <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">deprecation of the SECIO security transport</a>. In this release we have disabled SECIO by default, which will have an impact on older nodes on the network. The best way to mitigate the impact of this change is to <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrade your IPFS nodes</a> as soon as possible! Not only will upgrading ensure you‚Äôre using the latest security transports, you‚Äôll get access to all of the <a href="https://blog.ipfs.io/2020-07-20-dht-deep-dive/">performance improvements</a> we‚Äôve made this year to content routing.</p>

<p>With this release you will also start seeing more Peer IDs and IPNS Keys on the network that start with <code>1</code> instead of the typical <code>Qm</code>. This is due to a switch to ed25519 keys being used by default over RSA keys, which you can read more about in the highlights below.</p>

<p>üö® For those of you using plugins with IPFS there is a breaking change detailed below to the build process.</p>



<h2 id="secio-is-now-disabled-by-default">üîí SECIO is now disabled by default</h2>

<p>As part of deprecating and removing support for the SECIO security transport, we have disabled it by default. TLS1.3 will remain the default security transport with fallback to Noise. You can read more about the deprecation in the blog post, <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">https://blog.ipfs.io/2020-08-07-deprecating-secio/</a>. If you‚Äôre running Go IPFS older than 0.5 or JS IPFS older than 0.47, this may start to impact your performance on the public network, so we strongly encourage you to upgrade today!</p>

<h2 id="ed25519-keys-are-now-used-by-default">üóùÔ∏è Ed25519 keys are now used by default</h2>

<p>Previously go-ipfs generated 2048 bit RSA keys for new nodes, but it will now use ed25519 keys by default. This will not affect any existing keys, but newly created keys will be ed25519 by default. The main benefit of using ed25519 keys over RSA is that ed25519 keys have an inline public key. This means that someone only needs your PeerId to verify things you‚Äôve signed, such as your Peer Records or in the future Signed Provider Records, which means we don‚Äôt have to worry about storing bulky RSA public keys.</p>

<h3 id="rotating-keys">Rotating keys</h3>

<p>Along with switching the default key type, we‚Äôve added support for rotating Identity keys. If you would like to change the key type of your IPFS node, you can now do so with the rotate command. <strong>NOTE: This will affect your Peer Id, so be sure you want to do this!</strong> Your existing identity key will be backed up in the Keystore so that it can still be referenced for things like IPNS records.</p>

<pre><code>$ ipfs key rotate -o my-old-key -t ed25519
</code></pre>

<h2 id="key-export-import">üì¶ Key export/import</h2>

<p>Speaking of backing up keys, we‚Äôve added commands to allow you to export and import keys from the IPFS Keystore to a local .key file. This does not currently apply to the IPFS identity key, <code>self</code>, which is housed in the configuration file.</p>

<pre><code>$ ipfs key gen mykey
$ ipfs key export -o mykey.key mykey # ./&lt;name&gt;.key is the default path
$ ipfs key import mykey mykey.key # on another node
</code></pre>

<h2 id="ipns-paths-now-encode-the-key-name-as-a-base36-cidv1-by-default">#Ô∏è‚É£ IPNS paths now encode the key name as a base36 CIDv1 by default</h2>

<p>Previously go-ipfs encoded the key names for IPNS paths as base58btc multihashes (e.g. <code>Qmabc...</code>). We now encode them as base36 encoded CIDv1s as defined in the <a href="https://github.com/libp2p/specs/blob/master/peer-ids/peer-ids.md#string-representation">peerID spec</a> (e.g. <code>k51xyz...</code>) which also deals with the encoding of public keys. This is nice because it means that IPNS keys will by default be case-insensitive and that they will fit into DNS labels (e.g. <code>k51xyz...ipns.localhost</code>) and therefore that subdomain gateway redirections (e.g. from <code>localhost:8080/ipns/{key}</code> to <code>{key}.ipns.localhost</code>) will look better to users in the default case.</p>

<p>Many commands will accept a <code>--ipns-base</code> option that allows changing command outputs to use a particular encoding (i.e.  base58btc multihash, or CIDv1 encoded in any supported base):</p>

<pre><code>$ ipfs key list -l --ipns-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK self
$ ipfs key list -l --ipns-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2 self
</code></pre>

<h2 id="multiaddresses-now-accept-peerids-encoded-as-cidv1">üìÆ Multiaddresses now accept PeerIDs encoded as CIDv1</h2>

<p>In preparation for eventually changing the default PeerID representation multiaddresses can now contain strings like <code>/p2p/k51xyz...</code> in addition to the default <code>/p2p/Qmabc...</code>. There is a corresponding <code>--peerid-base</code> option to many functions that output peerIDs:</p>

<pre><code>$ ipfs id --format "&lt;id&gt;" --peerid-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK
$ ipfs id --format "&lt;id&gt;" --peerid-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2
</code></pre>

<h2 id="dag-stat-command">üßÆ <code>dag stat</code> command</h2>

<p>Initial support has been added for the <code>ipfs dag stat</code> command. Running this command will traverse the DAG for the given root CID and report statistics. By default, progress will be shown as the DAG is traversed. Supported statistics currently include DAG size and number of blocks.</p>

<pre><code>$ ipfs dag stat bafybeihpetclqvwb4qnmumvcn7nh4pxrtugrlpw4jgjpqicdxsv7opdm6e # the IPFS webui
Size: 30362191, NumBlocks: 346
</code></pre>

<h2 id="plugin-build-changes">üö® Plugin build changes üö®</h2>

<p>We have changed the build flags used by the official binary distributions on <a href="https://dist.ipfs.io/">dist.ipfs.io</a> (or <code>/ipns/dist.ipfs.io</code>) to use the simpler and more reliable <code>-trimpath</code> flag instead of the more complicated and brittle <code>-asmflags=all=-trimpath="$(GOPATH)" -gcflags=all=-trimpath="$(GOPATH)"</code> flags, however the build flags used by default in go-ipfs remain the same.</p>

<p>The scripts in <a href="https://github.com/ipfs/go-ipfs-example-plugin">go-ipfs-example-plugin</a> have been updated to reflect this change. This is a <strong>breaking change</strong> to how people have been building plugins against the dist.ipfs.io binary of go-ipfs and plugins should update their build processes accordingly. See <a href="https://github.com/ipfs/go-ipfs-example-plugin/pull/9">go-ipfs-example-plugin/pull/9</a> for details.</p>

<h2 id="the-changelog">The Changelog</h2>

<p>For a full list of updates included in this release you can review the Changelog at <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22">https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22</a>.</p>

<h2 id="thank-you-contributors">Thank you contributors!</h2>

<p>A huge thank you to <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#contributors">everyone who contributed</a> patches and improvements in this release, all <strong>53</strong> of you! We couldn‚Äôt have made this happen without your help and feedback. ‚ù§</p>

<h2 id="install-upgrade-and-join-us">Install, upgrade, and join us!</h2>

<p>You can get started by <a href="https://dist.ipfs.io/#go-ipfs">installing go-ipfs</a> or <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrading to go-ipfs 0.7</a>.</p>

<p>There are many ways to get involved with IPFS based on your skill set, interest, and availability.  Please check out <a href="https://github.com/ipfs/community/blob/master/CONTRIBUTING.md">our contribution page</a> on GitHub for guidance and next steps.</p>

<p>This is an exciting time for IPFS and the web in general. Join us!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578953</guid>
            <pubDate>Thu, 24 Sep 2020 14:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important non-programming skills for programmers]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24577876">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://welearncode.com/most-important-nonprogramming/ | <a href="https://web.archive.org/web/*/https://welearncode.com/most-important-nonprogramming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://welearncode.com/">‚Üê Home</a></p><p>When I think about who I would like to work with as a programmer, I think so much more about non-technical skills than technical skills that make somebody a good co-worker. In fact, all of the skills that are in this post contribute to writing good code that improves technical projects. Most of them are really helpful for careers outside of programming too, but I'm going to focus on why they're useful for programmers specifically.</p><h2>Empathy</h2><p>To build a great product, you must put yourself in the shoes of your users. How will they be using your product? What features will be helpful for them? How can your program help them or improve their lives? And -- conversely -- how could it harm them or negatively impact their lives? What are the ethical implications of your application?</p><p>Empathy is essential for so many pieces of your programs -- if they aren't secure then your user's information could be used negatively by a third party. If they aren't accessible, then you are limiting the number of people that can use your project. If they run slowly or needs huge amounts of bandwidth to run, then users will leave and people in areas with slow internet or mobile users won't be able to run them. It seems like every day an article comes out with some harmful algorithm a company has implemented, like the <a href="https://www.theguardian.com/media/2018/sep/18/report-youtubes-alternative-influence-network-breeds-rightwing-radicalisation">YouTube algorithm radicalizing the alt-right</a>, <a href="https://www.inc.com/guadalupe-gonzalez/amazon-artificial-intelligence-ai-hiring-tool-hr.html">Amazon creating a sexist hiring algorithm (which they didn't end up using)</a>, or <a href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI misgendering black women</a>. Think about everybody when you are writing your code!</p><p>Also, empathy is helpful for being a team member and a mentor. Put yourself in your manager or another developer's shoes. Why are they making their decisions? What can you do to help them? Having empathy will definitely improve your ability to be an effective teammate. If you're an employer, you can retain your employees for longer, and they will be more effective workers if you display empathy <a href="https://www.forbes.com/sites/karenhigginbottom/2018/05/31/why-empathy-matters-in-the-workplace/#386ca65d1130">(src)</a>.</p><p>Have patience for other programmers, especially ones that are learning new things. Remind yourself of something that was really hard for you to learn and how that felt. They probably feel similarly. Being rude to them, diminishing their progress, or being pedantic will only be harmful and make that process harder for them.</p><p><strong>Your words and actions have real consequences -- you can use that to enact positive change or hurt somebody. That doesn't end with in-person communication -- online communication counts too. You may think you're being funny or just letting off steam, but you may actually causing a very negative impact on someone's life. It's up to you to decide how to act, and how to apologize if you hurt someone to undo some of that harm.</strong></p><h2>Problem Solving</h2><p>When I teach people to code, I see a lot more people struggling with problem-solving than the code itself. The ability to break a problem into smaller ones and then solve all of those smaller problems takes a lot of practice. Getting good at problem-solving can help you become a much stronger programmer.</p><p>Also, for most problems, there will be more than one solution. A large part of our jobs as software developers is to think through those different solutions and choose the one that is best. Is one faster to implement? Or does it run more efficiently? Or will it be less expensive? All of these are important questions, and picking the correct solution is a challenging but important part of software development.</p><h2>Collaboration</h2><p>Chances are very high that you with other people as a programmer. You will have to work with other developers, business people, managers, open source contributors, stakeholders, and countless other people even if you are a freelancer or entrepreneur. Learning how to work well with different people and their personalities is critical.</p><p>There are so many things that contribute to good collaboration. The first is knowing that one person can't do everything, or at least do everything well. Different people have different skills, points of view, and life experiences that are more powerful in combination than isolation. Don't feel like you always need to "put the team on your back" or be everything to everybody. You can be a lot better if you allow other people to contribute too.</p><p>Ask other people for help, and be willing to help people in return. You don't need to be an expert in everything, and different people will be experts in different things. Rely on other people, and if you are stuck on something make sure to ask for help so that you don't stay stuck for too long. When somebody asks you for help, be willing to help them. You can learn a lot by explaining things well, and you will be able to reinforce your knowledge of the topic. If you're in a management position, make sure to give people time for mentorship and effective collaboration!</p><p>Along the same lines, don't talk over people or immediately dismiss their viewpoints. They will probably be much less likely to contribute in the future if their opinions aren't valued or taken into account. Actively listen when people share their ideas -- instead of thinking about your response or why your idea is better while they are talking, try to think about why their approach is also good or how it could be implemented.</p><p>Then, once you implement their awesome ideas, give them credit for those ideas. Nothing has made me less effective as an employee as being on a team where my ideas were dismissed, under-valued, and un-credited by other people on my team.</p><h2>Communication</h2><p>When you are working with other people, whether those people are co-workers, clients, the people who use your projects, managers, or people you manage, good communication is crucial. Give honest updates on how things are going, where projects currently stand, and your opinions on things honestly but kindly. People will be less receptive to feedback if you are rude or unconstructive. But, if you are dishonest or sugar-coat the truth, then you may not see a positive change. There's definitely a fine line here.</p><p>One real life example from my life: I had somebody who read one of my blog posts write a very long letter about how dumb I sound because of the tone I take. I usually use a lot of exclamation points and try to sound exciting in my posts -- and that's very intentional to try and make topics that can be intimidating or boring more fun. The person got pretty sexist in this email and said some pretty hurtful things. That being said, I probably could scale back on the exclamation points and still get people excited about programming. I would have been a lot more receptive to that point if the person had framed the criticism more constructively.</p><p>If things are not going well, make sure to say so. Be honest about needing a deadline pushed back, or how something isn't going well at work. You will have a much better chance at changing it and making the environment better for yourself if you speak up.</p><h2>Inclusiveness</h2><p>I used to work as a rock climbing instructor and counselor at a summer camp, and the age group I worked with most were middle school girls. They were some of my favorite people I've ever worked with, but, that being said, middle schoolers aren't usually the most accepting of difference or that clique-adverse. We used to run a game where we started out in one large circle, and then one counselor would tell people they were "out of the circle", and they would have to leave the game based on some characteristic that they weren't informed of and couldn't control. The people still inside the circle would play a game, and the people outside of the circle were excluded and just had to watch from afar.</p><p>This activity was super effective in showing these girls what it was like to be left out for reasons outside of your control, and I still think back on it a lot. As adults, we still leave people out of the circle and exclude them based on certain characteristics outside their control, but if we let them back into the circle and allow them to contribute then our products draw on more diverse experiences and are better. <strong>There's <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">a lot of research</a> on more diverse teams performing better, but from an individual perspective, think about what it feels like to be left out of the circle and try to make your circle larger, not smaller.</strong> Chances are, a lot of your users may be people that have traditionally been left out of the circle in tech. I can tell you from my own experience, that it's really difficult to be the only person like you on a team as someone who's been on a team with another woman for ~5% of my programming career.</p><p>This also links into empathy -- make sure that you are making your programs for a wide variety of users. Not just the able-bodied or those with cutting-edge internet or technologies. You will be able to reach more people.</p><h2>Patience</h2><p>The first person that you need to have patience with when you are programming is yourself. <strong>Programming is hard</strong> and sometimes you will have bugs or difficult problems to overcome. If it's always easy, then you aren't challenging yourself, and you aren't growing as a programmer. Have the tenacity to keep working through a problem and not give up when it gets hard. But, also, know that you can take a break and come back to the problem in a little while. Maybe taking a break will help you solve the problem more efficiently or to see it differently when you come back to it.</p><p>Also, be patient with other people. Things can take a while to learn and people are not perfect. Making mistakes and failing can be some of the most important experiences in the learning process, so allow for that instead of creating an environment where it isn't safe to take risks or grow. Understand that different things click more easily for different people, and know that learning can take a while.</p><h2>Creativity</h2><p>My favorite thing about being a programmer is that I get to use my creative energy to build things that other people can then benefit from. You get to think outside of the box to create really cool things.</p><p>Having creative ideas is important for coming up with ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://welearncode.com/most-important-nonprogramming/">https://welearncode.com/most-important-nonprogramming/</a></em></p>]]>
            </description>
            <link>https://welearncode.com/most-important-nonprogramming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577876</guid>
            <pubDate>Thu, 24 Sep 2020 12:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Cow Collars]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24577468">thread link</a>) | @troydavis
<br/>
September 24, 2020 | https://halterhq.com/smart-cow-collars | <a href="https://web.archive.org/web/*/https://halterhq.com/smart-cow-collars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ca2563ba93dc6cf1ddae"><div><p>Shift, manage and monitor your herd remotely - we‚Äôve summed it up fairly concisely, but how we do that may require a little more paper and a sharpening of the pencil. How are we able to shift a cow to and from the milk shed with the click of a button? Essentially, we train cows to respond to sensory cues which help them understand where they can and cannot go, a method based on the theory of Pavlovian Conditioning. Now, it‚Äôs likely your list of questions is long, so we‚Äôve brought in our Head of Rural, Chris, who oversees all on farm training to give you some answers.</p><p><strong>You say that you use sensory cues to guide cows‚Ä¶ how does that work?</strong></p><p>Like any animal, cows learn behaviours through the use of positive and negative reinforcement. This technique is commonly known as Pavlovian Conditioning, whereby certain stimuli such as sounds, touches and smells are paired with a conditioned response in order to elicit a desired behaviour.</p><p>If you think about the way we farm today, farmers use a multitude of different cues to shift cows or keep them in a particular zone. To put it really simply, Halter replicates these cues and places them on a collar in the form of sound and vibration. </p><p>Vibration can be seen as a positive reinforcer, enabling us to shift cows around the farm as well as indicating to a cow that she is moving in the right direction. You might like to think of vibration as a farmer walking behind their cows to shift them up to the shed! Sound on the other hand helps a cow understand she is moving in the wrong direction or outside of the allocated zone. Currently on the farm an electric fence is the only real means available for farmers to keep their cows within a particular boundary; we instead use sound to replicate a fence line with a pulse used during the initial training period to help a cow understand the meaning of sound. Once the girls are trained we combine sound cues with vibration and we have the ability to guide cows around a farm, keep them out of waterways and set up virtual paddocks and break fences.</p><p><strong>How quick is the training process? Do all cows learn or do some just not get it?&nbsp;</strong></p><p>Cows are extremely quick to respond to sound, within a couple hours of wearing a collar cows learn to stay within a static boundary. It takes a little longer for them to associate vibration with positive cues, however we are currently seeing this happen within a week. In general onboarding takes a week, however this process is continually being modified and improved.</p><p>To date we haven‚Äôt come across any cows that we couldn‚Äôt train! Some learn faster than others but due to the fact that cows are herd animals, the slower ones tend to follow and learn from the faster cows.</p><p><strong>How do you ensure that the training is safe and ethical?</strong></p><p>We‚Äôve been working with animal ethics committees from the start and continue to work closely with them, along with vets and professors in this domain. Welfare is our top priority and our founding vision is to unlock the connection between animals and humans to create a better world, with the hope of not only improving the welfare of cows but other animals in the future. </p><p>We are employing a number of systems to ensure our technology is never harmful to a cow, for instance we have hardcoded mechanisms in place that will shut down a collar should anything out of the ordinary happen, for example a cow getting spooked. We have also considered the training process itself and will begin training softly until a cow becomes more comfortable. </p><p>We want to dramatically improve the welfare of cows and will never compromise their wellbeing.</p><p><strong>Will Halter work on other livestock like sheep and beef cattle? And what about calves?</strong></p><p>Absolutely. Beef cattle would be simple - it just requires a slight change in use case. Sheep would require a collar redesign to fit their small fluffy necks and, no, they are not too stupid! I am confident that the fundamental techniques will work on pretty much any mammal. Pavlovian conditioning is a concept that appeals to very basic animalistic instincts that all mammals, and most likely many other types of animals share.</p><p>In terms of calves there is no reason that Halter wouldn‚Äôt work for them, we‚Äôd just need collars small enough! Although we are currently focused on dairy cattle I see no reason why Halter wouldn‚Äôt work on other livestock in the future!</p><p>Setting up a virtual break fence, shifting cows automatically or drafting a single cow with the touch of a button sounds like a rather crazy concept, but we hope this has given you a touch of background and understanding to it all. We‚Äôll leave you to train your dogs, but trust us when we say - we‚Äôve got the cows covered.</p></div></div></div>]]>
            </description>
            <link>https://halterhq.com/smart-cow-collars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577468</guid>
            <pubDate>Thu, 24 Sep 2020 11:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Version Control with Liquibase]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24577239">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/database-version-controler-with-liquibase/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/database-version-controler-with-liquibase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>Introduction to managing DB shcema changes with Liquibase</h4>
                <h6>
                    By Suresh Regmi, Published 2020-09-06
                </h6>
    </p><div itemprop="articleBody"><h2 id="motivation">Motivation</h2>
<p>Let me give you a scenario,<br>
You have a project with multiple database instances in different environments (Dev, QA, Production) and you need to manage the database schema changes that are done against those environments.
Let‚Äôs assume that you are managing those changes by creating a git project or a shared file on a drive and adding a new SQL file for each database changes you are doing.
To implement your changes in that database, for each SQL file, you need to run the changes in each environment manually and add a flag or note to indicate which change is run on which environment.<br>
Would it be able to complete your task?
Yes, Yet, is it a decent method to manage schema changes?<br>
Of Course Not.</p>
<h2 id="here-are-some-of-the-many-problems-you-might-face-while-doing-so">Here are some of the many problems you might face while doing so</h2>
<ol>
<li>Hard to synchronize database and application code changes in different environments</li>
<li>The tedious process to run each change manually in different environments</li>
<li>Collaboration across the development team on what change is deployed and what is not</li>
<li>Hard to roll-back to the previous version of the database</li>
<li>Possibility of data loss</li>
</ol>
<h2 id="here-comes-liquibase">Here comes Liquibase</h2>
<p>Liquibase is an open-source library for tracking and managing database schema changes that can be used for any database with a JDBC driver.<br>
It is a platform-independent database migration tool that allows the database changes referred to as ‚Äòchangesets‚Äô to be written in various formats including XML, JSON, YAML, and SQL.</p>
<h2 id="features">Features</h2>
<ol>
<li>Supports almost all databases that have a JDBC driver.</li>
<li>Changesets can be written in different formats like XML, JSON, YAML, and SQL.</li>
<li>Can be used to automatically generate changesets for an existing database</li>
<li>Easy to integrate with build tools like Jenkins, Maven etc</li>
<li>Supports database rollbacks</li>
<li>Supports context-dependent logic allowing us to use global context and preconditions</li>
<li>Can be executed via command line, Apache Maven, Apache Ant, Spring Framework</li>
<li>Has feature to generate changeset from an existing database and can also generate schema difference as changesets</li>
</ol>
<h2 id="different-ways-to-run-liquibase">Different ways to run liquibase</h2>
<ol>
<li><strong>Embed liquibase with your app:</strong> Embedding liquibase with your application code will automatically deploy liquibase on the app startup.</li>
<li><strong>Run liquibase using build tools:</strong> Integrate liquibase into your build process (with build tools like Jenkins, Ant, Maven, and Gradle) and update them without being tied up with the application.</li>
<li><strong>Generate the SQL and run it manually:</strong> Using update SQL, Liquibase provides the SQL generated from the changeset along with the database changes required to keep the tracking tables up to date. DBA will then inspect the SQL and run them against the database.</li>
</ol>
<h2 id="installation-process">Installation Process</h2>
<p><strong>Prerequisites:</strong> Liquibase requires Java 8+</p>
<p>There are two ways to install Liquibase, Manual installation and using liquibase installer.</p>
<p>If you set up liquibase using the liquibase installer, dependencies, directories, config and properties files will all be in place already.
It also provides some examples which will provide you with the core concepts required to understand the changesets.</p>
<p>In the case of manual installation, you need to download the compressed liquibase file and extract it in your workspace.<br>
For windows users, you need to add a new <code>PATH</code> variable in the <code>Environment Variables</code>.<br>
For macOS users, the path should be added to the <code>bash.profile</code> file.</p>
<p>For detailed instruction on Installation please follow this <a href="https://docs.liquibase.com/concepts/installation/home.html" target="_blank"> document </a>.</p>
<h2 id="core-concepts">Core Concepts</h2>
<ol>
<li><strong>liquibase.properties:</strong> The file <code>liquibase.properties</code> is a text-based file that stores common properties like database connection parameters, driver details, classpath parameters, global changelog parameters etc.
If you install liquibase using liquibase installer, it will provide pre-written <code>liquibase.properties</code> file while in case of manual installation, you need to create <code>liquibase.properties</code> file using a sample file provided.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" alt="Sample liquibase.properties file for Oracle"></a></p>
<ol start="2">
<li><strong>DatabaseChangeLog:</strong> Databasechangelog is a file where all changesets go. Each database changelog can include one or more changesets.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" alt="Example of an empty DatabaseChangeLog file
"></a></p>
<ol start="3">
<li><strong>Changeset:</strong> In liquibase, a changeset is represented as an atomic change to the database. Each changeset should be uniquely identified using author and id fields.
The database handles each changeset as a single transaction.
Changesets can be written in JSON, XML, SQL and YAML formats.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" alt="Example of a changeset in XML format"></a></p>
<ol start="4">
<li><strong>DATABASECHANGELOG &amp; DATABASECHANGELOGLOCK:</strong> These two tables are created by liquibase to track the changes that are run against the database and to make sure that no other migrations age going on.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" alt="DATABASECHANGELOG table structure"></a></p>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" alt="DATABASECHANGELOGLOCK table structure"></a></p>
<h2 id="what-if-i-dont-like-liquibase">What if I don‚Äôt like Liquibase?</h2>
<p>If you told me that you don‚Äôt like liquibase and are looking for alternatives, I would ask why not Liquibase first.<br>
Liquibase is a sophisticated tool for database migration that has all features that you need for professional database refactoring and versioning.</p>
<p>But still, if you don‚Äôt want to use liquibase, here are some alternatives.</p>
<ol>
<li>
<p><strong>Flyway:</strong> Flyway is an open-source Apache licenced tool for database migration where you can write migrations in database-specific SQL or using Java code. For more details on Flyway, you can refer to this website. <a href="https://flywaydb.org/">https://flywaydb.org/</a></p>
</li>
<li>
<p><strong>YUNIQL:</strong> YUNIQL is also an open-source schema versioning and database migration engine that uses plain SQL scripts which can be integrated with CI/CD pipelines. If you want to check out YUNIQL, you can refer to this website. <a href="https://yuniql.io/">https://yuniql.io/</a></p>
</li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/database-version-controler-with-liquibase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577239</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open-Source Memex ‚Äì Alternative Approach to Roam/Obsidian]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24572449">thread link</a>) | @steve1820
<br/>
September 23, 2020 | https://www.steveliu.co/memex | <a href="https://web.archive.org/web/*/https://www.steveliu.co/memex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-33de0799eab39cfadbe1"><div><p>I‚Äôve never been a huge online note taker. From high school to university, I‚Äôve always relied on pen and paper as my weapon of choice. At the time and even to some extent now, I‚Äôve felt like this was a good enough solution to my problems.</p><p>I‚Äôve always felt the simpler the solution the better. Why complicate things?</p><p>This changed however after working as a software engineer in industry. As I worked on a software product that derived its core functionality from machine learning, it seemed that I was constantly drowning in a sea of information.&nbsp;</p><p>It was a constant repetition of learning something, forgetting about it 5 months later and then having to recycle through my notes and reread the article/paper/blog.</p><p>My brain was a leaky bucket. Every time I poured something in, something else would leak out.</p><p>It was during those dark times of desperation that I stumbled upon the ‚Äúniche‚Äù industry of Knowledge Management Systems (KMS) and as an extension, the Memex.</p><p> I was fascinated with all the innovation coming from up and coming open source projects and companies in this space. Software like Athens (https://github.com/athensresearch/athens), Roam (https://roamresearch.com/), Obsidian (https://obsidian.md/) all seemed so promising. </p><p>I was particularly inspired by reading karlicoss‚Äôs blog (https://beepb00p.xyz/promnesia.html). He outlines so many good and intuitive reasons why the current solutions are broken (although in this particular post he focuses on browser history).</p></div></div></div></div>]]>
            </description>
            <link>https://www.steveliu.co/memex</link>
            <guid isPermaLink="false">hacker-news-small-sites-24572449</guid>
            <pubDate>Wed, 23 Sep 2020 21:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bleeding-edge tech will kill your startup]]>
            </title>
            <description>
<![CDATA[
Score 302 | Comments 191 (<a href="https://news.ycombinator.com/item?id=24571216">thread link</a>) | @bmaho
<br/>
September 23, 2020 | https://www.contrast.app/posts/bleeding-edge-tech-means-youll-bleed-to-death | <a href="https://web.archive.org/web/*/https://www.contrast.app/posts/bleeding-edge-tech-means-youll-bleed-to-death">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Remember those old don't-do-drug ads? A shaky camera pans to a narc wearing a wrinkled button-down:</p><p><strong>Egg is lifted:</strong></p><p>"This is your brain"</p><p><strong>Points to hot skillet:</strong></p><p>"This is drugs"</p><p><strong>Cracks egg into skillet. Egg starts frying:</strong></p><p>"This is your brain on drugs"</p><figure id="w-node-8595f4c9f275-ccb706c6"><p><img src="https://uploads-ssl.webflow.com/5f08abd1a8581a1027bfc65a/5f6b8cd757b4ac440ca61db3_Frame%202.png" loading="lazy" alt=""></p></figure><p>Firstly, makes no sense seeing everyone loves fried eggs. Secondly, this is how my brain looked when trying to start a "bleeding edge" tech company.</p><p>2018. Winter. NYC.</p><p>Lying on the floor, looking like the beached whale I am, I stared at the ceiling. For months, we had been trying to start a food delivery business. Nothing bleeding-edge, just pain.</p><p>It was in that moment, with my shirt gathering fuzz from the un-vacuumed carpet below, that we changed everything. New market, new users, new product, new tech. We just wanted to do something new‚Äîsomething no one else was doing.</p><p>As designers and engineers, we knew of a rather niche problem: if your company has a design system, it's practically impossible to know the adoption rate of those components in your product. Huzzah! we thought. We should build a tool that tells you the adoption rate of every component in your design system‚Äîacross your product. Chefs kiss.</p><figure id="w-node-f806252cfa53-ccb706c6"><p><img src="https://uploads-ssl.webflow.com/5f08abd1a8581a1027bfc65a/5f6b8ce4411317e302386081_Frame%208.png" loading="lazy" alt=""></p></figure><p>Now, no worries if you don't know what this means. For the sake of the article, this was "bleeding-edge tech," and this simple fact got us psyched. We would be the first, the trailblazers. We felt like how I imagine all the kids who grow up watching "Baby Einstein" feel‚Äîpompous, cute, and little geniuses.</p><p>Little did I know, this mentality would fuck us...</p><p>Before continuing with my failures, a history lesson. After a quick Wikipedia search, the first time we see the term "bleeding edge technology" being used was during the early 80s‚Äîright when the drug-ad above aired (clearly some weird shit happening then). Bleeding edge was an iteration on the classic "cutting-edge" or "leading-edge" phrases‚Äîaltered to show an even higher level of risk for both the company and the customer.</p><p>So how did this mentality fuck us? Well, I've come up with a rather clever framework I'm calling:</p><h5>"The Bloody Edged Circle of Death"</h5><p>‚Äç</p><p>This loop consists of <strong>three parts:</strong></p><ol role="list"><li>Sales</li><li>Product</li><li>Mental game</li></ol><figure id="w-node-c5258bced305-ccb706c6"><p><img src="https://uploads-ssl.webflow.com/5f08abd1a8581a1027bfc65a/5f6b8bf55a4723fd0e275db4_Frame%2012-min.png" loading="lazy" alt=""></p></figure><h5>Sales</h5><p>Sales is hard and if you want to make it 10X harder, try selling something nobody knows anything about. Like literally nothing. When we started, prospects didn't know our name, the problem we were solving, our solution, how valuable it would be, what it should be priced at, and the list went on and on. And here's the kicker, because they knew nothing, they didn't trust us. We weren't proven and thus we were a huge risk to adopt.</p><p>With this bleeding edge product in hand, we were banging our heads against the wall, trying to sell to early users who'd be willing to try something incredibly new and incredibly risky. Not fun. Very difficult.</p><p>‚Äç</p><figure id="w-node-b112f59a5983-ccb706c6"><p><img src="https://uploads-ssl.webflow.com/5f08abd1a8581a1027bfc65a/5f6b8bfe1409e87b269d51cd_Frame%2013-min.png" loading="lazy" alt=""></p></figure><h5>Product</h5><p>The brutal sales cycles then bled into our product. After a few months, we had convinced a handful of companies to test our tech. The day would arrive and we'd finally onboard them. But guess what, they had no idea how to use our tool or integrate it within their workflow. And to be honest, nor did we. Adoption was bleak and feedback was dry‚Äîsilence in startups is not golden.</p><p>What I realized is when you're the first, there is very little to look at for inspiration, ideas, or as a benchmark. It's up to you as the trailblazer to build the path and hope it will lead somewhere. This is something I think many of wish we could do‚Äîbut I think very few can.</p><p>‚Äç</p><figure id="w-node-97e798a4e2ae-ccb706c6"><p><img src="https://uploads-ssl.webflow.com/5f08abd1a8581a1027bfc65a/5f6b8c07e074c53b56bc6989_Frame%2014-min.png" loading="lazy" alt=""></p></figure><h5>Mental game</h5><p>I think the worst stage is the mental-game. When you're trying to drag your zombie-death startup from the crypts of hell and into the light, there are so many things to stress about. Your messaging, positioning, pricing, product, customers, sales, employees‚Äîliterally everything. But when you're building something truly new, there is an additional poisonous leach that creeps into your brain and plants its ugly seed: doubt.</p><p>Bleeding edge tech means you'll constantly be doubting whether what you've created will ever be something or not‚Äîthere is no market data to tell you otherwise. You don't know if customers are already using a solution like yours. You don't know if anyone is willing to pay for your offering. You don't know how big the market is or will ever become. You don't know anything.</p><p>This was the hardest thing for me to deal with personally. The daily doubt. Constantly wondering if we needed to just tweak a few of the 4 P's or much worse‚Äîthat this wasn't a real problem needed to be solved.</p><p>"The Bloody Edged Circle of Death" continued its cycle until one day, we decided no more. We didn't have the conviction in ourselves and the product to keep pushing through the long sales cycles, silence from inactive users, and the crippling doubt. We were done <strong>bleeding out from bleeding edge tech.</strong></p><p>Since then, I've been thinking a lot about why we were so keen on building tech no one had ever seen before. When I started to look for answers, I noticed something peculiar. All of the "hottest" tech companies: Airtable, Notion, Slack, Zoom‚Äînone of them are "bleeding edge" per se. Sure, they have incrementally innovated on existing products in existing categories‚Äîbut they're not doing anything truly <em>new.</em></p><p>They identified problems with the status quo, in massive markets, with huge amounts of users and money. They then developed a better product by improving the UX, performance, and adding new features. Don't get me wrong, this is an insanely difficult feat to ever pull off. Yet, before I gave this any thought, I assumed they were successful because they were doing something new‚Äîbecause they were bleeding edge.</p><p>So why was I fed this lie and believed it to be true?</p><p>I think the answer is pretty simple‚Äîmarketing and ego. If you're a founder, you want your company to be seen as revolutionary. Even if your startup just slapped lipstick on a pig, you want the world to believe you invented a super hot and sexy pig, one that sprouts wings and poops pearls.</p><p>And same thing goes for VCs. Investors want to be seen as picking the best and brightest‚Äîfinding the diamonds in the rough. Their aim is to say: "I backed a ground breaking technology that changed the world," and not: "I invested in 10 slightly-better-than-Google-Docs competitors." No one on Twitter is getting jacked on that.</p><p>If you're anything like me, you've been reading, listening, and following the big players in Silicon-Valley for years. We've been told a narrative that sounds great and inspires, but it's not based in facts. Bleeding edge is a myth that fucks up your chances of success.</p><p>Since this realization, we've purposefully taken our company in a different direction. A new strategy, one where we purposefully have entered an existing market‚Äîa market where we have expertise. Yes, there is competition, but we've been using these tools for years, we know the problems they have, and we want to make something better‚Äîboth for our team and customers.</p><p>Although this path doesn't have the same sparkle as a bleeding-edge tech company might, I can sleep easier knowing we have a higher chance of getting somewhere with it. I can finally focus on the problems every startup deals with without that doubt‚Äîthat nose-crinkling, water-trash stench of doubt. </p><p>There is a market. There are users who pay. There is value to what we're doing. Now it's just up to us to make our product, positioning, and team the best it can be.</p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.contrast.app/posts/bleeding-edge-tech-means-youll-bleed-to-death</link>
            <guid isPermaLink="false">hacker-news-small-sites-24571216</guid>
            <pubDate>Wed, 23 Sep 2020 19:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray Marching Soft Shadows in 2D]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24569542">thread link</a>) | @rjkaplan
<br/>
September 23, 2020 | https://www.rykap.com/2020/09/23/distance-fields/ | <a href="https://web.archive.org/web/*/https://www.rykap.com/2020/09/23/distance-fields/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        




<article>
  

<p><em>Disclaimer: the demos on this page use WebGL features that aren‚Äôt available on some mobile devices.</em></p>

<p>A couple of weeks ago I tweeted a video of a toy graphics project (below). It‚Äôs not done, but a lot of people liked it which was surprising and fun! A few people asked how it works, so that‚Äôs what this post is about.</p>



<p>Under the hood it uses something called a distance field. A distance field is an image like the one below that tells you how far each pixel is from your shape. Light grey pixels are close to the shape and dark grey pixels are far from it.</p>

<img src="https://www.rykap.com/images/ray-marching/distance-field.png">

<p>When the demo starts up, it draws some text on a 2D canvas and generates a distance field of it. It uses <a href="https://github.com/ryankaplan/gpu-distance-field">a library I wrote</a> that generates distance fields really quickly. If you‚Äôre curious how the library works, I wrote about that <a href="http://rykap.com/graphics/skew/2016/02/25/voronoi-diagrams/">here</a>.</p>

<p>Our lighting scheme works like this: when processing a particular pixel we consider a ray from it to the light, like so‚Ä¶</p>

<img src="https://www.rykap.com/images/ray-marching/ray-march-1.png">

<p>If the ray intersects a glyph, the pixel we‚Äôre shading must be in shadow because there‚Äôs something between it and the light.</p>

<p>The simplest way to check this would be to move along the ray in 1px increments, starting from the pixel we‚Äôre shading and ending at the light, repeatedly asking the distance field if we‚Äôre distance 0 from a shape. This would work, but it‚Äôd be really slow.</p>

<p>We could pick some specific length like 30px and move in increments of that size, but then we risk jumping over glyphs that are smaller than 30px. We might think we‚Äôre not in shadow when we should be.</p>

<p><strong>Ray marching‚Äôs core idea is this: the distance field tells you how far you are from the closest glyph. You can safely advance along your ray by that distance without skipping over any glyphs.</strong></p>

<p>Let‚Äôs walk through an example. We start as pictured above and ask the distance field how far we are from any glyph. Turns out in this case that the answer is 95px (pictured left). This means that we can move 95px along our ray without skipping over anything!</p>

<img src="https://www.rykap.com/images/ray-marching/ray-march-2.png">

<p>Now we‚Äôre a little closer to the light. We repeat the process until we hit the ascender of the b! If the b glyph weren‚Äôt there, we‚Äôd have kept going until we hit the light.</p>

<p>Below is a demo that shows the ray marching steps for a given pixel. The red box is the pixel we‚Äôre shading, and each circle along the ray represents a ray marching step and the distance from the scene at that step.</p>

<p>Try dragging the light and the pixel around to build an intuition for it.</p>



<p>Below is GLSL to implement this technique. It assumes you‚Äôve defined a function <code>getDistance</code> that samples the distance field.</p>

<div><div><pre><code><span>vec2</span> <span>rayOrigin</span> <span>=</span> <span>...;</span>
<span>vec2</span> <span>rayDirection</span> <span>=</span> <span>...;</span>

<span>float</span> <span>rayProgress</span> <span>=</span> <span>0</span><span>;</span>
<span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>rayProgress</span> <span>&gt;</span> <span>distance</span><span>(</span><span>rayOrigin</span><span>,</span> <span>lightPosition</span><span>))</span> <span>{</span>
    <span>// We hit the light! This pixel is not in shadow.</span>
    <span>return</span> <span>1</span><span>.;</span>
  <span>}</span>

  <span>float</span> <span>sceneDist</span> <span>=</span> <span>getDistance</span><span>(</span>
    <span>rayOrigin</span> <span>+</span> <span>rayProgress</span> <span>*</span> <span>rayDirection</span><span>);</span>
  <span>if</span> <span>(</span><span>sceneDist</span> <span>&lt;=</span> <span>0</span><span>.)</span> <span>{</span>
    <span>// We hit a shape! This pixel is in shadow.</span>
    <span>return</span> <span>0</span><span>.;</span>
  <span>}</span>

  <span>rayProgress</span> <span>+=</span> <span>sceneDist</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>It turns out that some pixels are really expensive to process. So in practice we use a for-loop instead of a while loop ‚Äì that way we bail out if we‚Äôve done too many steps. A common ‚Äúslow case‚Äù in ray marching is when a ray is parallel to the edge of a shape in the scene‚Ä¶</p>



<p>The approach I‚Äôve described so far will get you a scene that looks like the one below.</p>



<p>It‚Äôs cool, but the shadows are sharp which doesn‚Äôt look very good. The shadows in the demo look more like this‚Ä¶</p>

<img src="https://www.rykap.com/images/ray-marching/desired-shadows.png">

<p>One big disclaimer is that they‚Äôre not physically realistic! Real shadows look like hard shadows where the edges have been fuzzed. This approach does something slightly different: all pixels that were previously in shadow are still fully in shadow. We‚Äôve just added a penumbra of partially shaded pixels around them.</p>

<p>The upside is that they‚Äôre pretty and fast to compute, and that‚Äôs what I care about! There are three ‚Äúrules‚Äù involved in computing them.</p>

<p><strong>Rule 1:</strong> The closer a ray gets to intersecting a shape, the more its pixel should be shadowed. In the image below there are two similar rays (their distances to the shape pictured in yellow and green). We want the one that gets closer to touching the corner to be more shadowed.</p>

<img src="https://www.rykap.com/images/ray-marching/rule-1.png">

<p>This is cheap to compute because the variable <code>sceneDist</code> tells us how far we are from the closest shape at each ray marching step. So the smallest value of <code>sceneDist</code> across all steps is a good approximation for the yellow and green lines in the image above.</p>

<p><strong>Rule 2:</strong> if the pixel we‚Äôre shading is far from the point where it almost intersects a shape, we want the shadow to spread out more.</p>

<img src="https://www.rykap.com/images/ray-marching/rule-2.png">

<p>Consider two pixels along the ray above. One is closer to the almost-intersection and is lighter (its distance is the green line). The other is farther and darker (its distance is the yellow line). In general: the further a pixel is from its almost intersection, the more ‚Äúin shadow‚Äù we should make it.</p>

<p>This is cheap to compute because the variable <code>rayProgress</code> is the length of the green and yellow lines in the image above.</p>

<p>So: we previously returned <code>1.0</code> for pixels that weren‚Äôt in shadow. To implement rules 1 and 2, we compute <code>sceneDist / rayProgress</code> on each ray marching step, keep track of its minimum value, and return that instead.</p>

<div><div><pre><code><span>vec2</span> <span>rayOrigin</span> <span>=</span> <span>...;</span>
<span>vec2</span> <span>rayDirection</span> <span>=</span> <span>...;</span>
<span>float</span> <span>rayProgress</span> <span>=</span> <span>0</span><span>.;</span>
<span>float</span> <span>stopAt</span> <span>=</span> <span>distance</span><span>(</span><span>samplePt</span><span>,</span> <span>lightPosition</span><span>);</span>
<span>float</span> <span>lightContribution</span> <span>=</span> <span>1</span><span>.;</span>
<span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>64</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>rayProgress</span> <span>&gt;</span> <span>stopAt</span><span>)</span> <span>{</span>
    <span>return</span> <span>lightContribution</span><span>;</span>
  <span>}</span>

  <span>// `getDistance` samples our distance field texture.</span>
  <span>float</span> <span>sceneDist</span> <span>=</span> <span>getDistance</span><span>(</span>
    <span>rayOrigin</span> <span>+</span> <span>rayProgress</span> <span>*</span> <span>rayDirection</span><span>);</span>
  <span>if</span> <span>(</span><span>sceneDist</span> <span>&lt;=</span> <span>0</span><span>.)</span> <span>{</span>
    <span>// We hit a shape! This pixel is in shadow.</span>
    <span>return</span> <span>0</span><span>.;</span>
  <span>}</span>

  <span>lightContribution</span> <span>=</span> <span>min</span><span>(</span>
    <span>lightContribution</span><span>,</span>
    <span>sceneDist</span> <span>/</span> <span>rayProgress</span>
  <span>);</span>

  <span>rayProgress</span> <span>+=</span> <span>sceneDist</span><span>;</span>
<span>}</span>

<span>// Ray-marching took more than 64 steps!</span>
<span>return</span> <span>0</span><span>.;</span>
</code></pre></div></div>

<p>This ratio feels kind of magical to me because it doesn‚Äôt correspond to any physical value. So let‚Äôs build some intuition for it by thinking through why it might take on particular values‚Ä¶</p>

<ul>
  <li>
    <p>If <code>sceneDist / rayProgress &gt;= 1</code>, then either <code>sceneDist</code> is big or <code>rayProgress</code> is small (relative to each other). In the former case we‚Äôre far from any shapes and we shouldn‚Äôt be in shadow, so a light value of <code>1</code> makes sense. In the latter case, the pixel we‚Äôre shadowing is really close to an object casting a shadow and the shadow isn‚Äôt fuzzy yet, so a light value of <code>1</code> makes sense.</p>
  </li>
  <li>
    <p>The ratio is <code>0</code> only when <code>sceneDist</code> is <code>0</code>. This corresponds to rays that intersect an object and whose pixels are in shadow.</p>
  </li>
</ul>

<p>And here‚Äôs a demo of what we have so far‚Ä¶</p>



<p><strong>Rule #3</strong> is the most straightforward one: light gets weaker the further you get from it.</p>

<p>Instead of returning the minimum value of <code>sceneDist / rayProgress</code> verbatim, we multiply it by a <code>distanceFactor</code> which is <code>1</code> right next to the light, <code>0</code> far away from it, and gets quadratically smaller as you move away from it.</p>

<p>All together, the code for the approach so far looks like this‚Ä¶</p>

<div><div><pre><code><span>vec2</span> <span>rayOrigin</span> <span>=</span> <span>...;</span>
<span>vec2</span> <span>rayDirection</span> <span>=</span> <span>...;</span>
<span>float</span> <span>rayProgress</span> <span>=</span> <span>0</span><span>.;</span>
<span>float</span> <span>stopAt</span> <span>=</span> <span>distance</span><span>(</span><span>samplePt</span><span>,</span> <span>lightPosition</span><span>);</span>
<span>float</span> <span>lightContribution</span> <span>=</span> <span>1</span><span>.;</span>
<span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>64</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>rayProgress</span> <span>&gt;</span> <span>stopAt</span><span>)</span> <span>{</span>
    <span>// We hit the light!</span>
    <span>float</span> <span>LIGHT_RADIUS_PX</span> <span>=</span> <span>800</span><span>.;</span>

    <span>// fadeRatio is 1.0 next to the light and 0. at</span>
    <span>// LIGHT_RADIUS_PX away.</span>
    <span>float</span> <span>fadeRatio</span> <span>=</span>
      <span>1</span><span>.</span><span>0</span> <span>-</span> <span>clamp</span><span>(</span><span>stopAt</span> <span>/</span> <span>LIGHT_RADIUS_PX</span><span>,</span> <span>0</span><span>.,</span> <span>1</span><span>.);</span>

    <span>// We'd like the light to fade off quadratically instead of</span>
    <span>// linearly.</span>
    <span>float</span> <span>distanceFactor</span> <span>=</span> <span>pow</span><span>(</span><span>fadeRatio</span><span>,</span> <span>2</span><span>.);</span>
    <span>return</span> <span>lightContribution</span> <span>*</span> <span>distanceFactor</span><span>;</span>
  <span>}</span>

  <span>// `getDistance` samples our distance field texture.</span>
  <span>float</span> <span>sceneDist</span> <span>=</span> <span>getDistance</span><span>(</span><span>rayOrigin</span> <span>+</span> <span>rayProgress</span> <span>*</span> <span>rayDirection</span><span>);</span>
  <span>if</span> <span>(</span><span>sceneDist</span> <span>&lt;=</span> <span>0</span><span>.)</span> <span>{</span>
    <span>// We hit a shape! This pixel is in shadow.</span>
    <span>return</span> <span>0</span><span>.;</span>
  <span>}</span>

  <span>lightContribution</span> <span>=</span> <span>min</span><span>(</span>
    <span>lightContribution</span><span>,</span>
    <span>sceneDist</span> <span>/</span> <span>rayProgress</span>
  <span>);</span>

  <span>rayProgress</span> <span>+=</span> <span>sceneDist</span><span>;</span>
<span>}</span>

<span>// Ray-marching took more than 64 steps!</span>
<span>return</span> <span>0</span><span>.;</span>
</code></pre></div></div>

<p>I forget where I found this soft-shadow technique, but I definitely didn‚Äôt invent it. Inigo Quilez <a href="https://www.iquilezles.org/www/articles/rmshadows/rmshadows.htm">has a great post on it</a> where he talks about using it in 3D.</p>

<p>Inigo‚Äôs post also talks about a gotcha with this approach that you might have noticed in the demos above: it causes banding artifacts. This is because Rule 1 assumes that the smallest value of <code>sceneDist</code> across all steps is a good approximation for the distance from a ray to the scene. This is not always true because we sometimes take very few ray marching steps.</p>

<p>So in my demo I use an improved approximation that Inigo writes about in his post. I also use another trick that is more effective but less performant: instead of advancing by <code>sceneDist</code> on each ray marching step, I advance by something like <code>sceneDist * randomJitter</code> where <code>randomJitter</code> is between <code>0</code> and <code>1</code>.</p>

<p>This improves the approximation because we‚Äôre adding more steps to our ray march. But we could do that by advancing by <code>sceneDist * .3</code>. The random jitter ensures that pixels next to each other don‚Äôt end up in the same band. This makes the result a little grainy which isn‚Äôt great. But I think looks better than banding‚Ä¶ This is an aspect of the demo that I‚Äôm still not satisfied with, so if you have ideas for how to improve it please tell me!</p>

<p>Overall my demo has a few extra tweaks that I might write about in future but this is the core of it. Thanks for reading! If you have questions or comments, let me know <a href="https://twitter.com/ryanjkaplan">on Twitter</a>.</p>

<p><em>Thank you to Jessica Liu, Susan Wang, Matt Nichols and Kenrick Rilee for giving feedback on early drafts of this post! Also, if you enjoyed this post you might enjoy working with me at <a href="https://www.figma.com/careers/">Figma</a>!</em></p>

</article>






  
  
  






      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.rykap.com/2020/09/23/distance-fields/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24569542</guid>
            <pubDate>Wed, 23 Sep 2020 17:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Child‚Äôs Guide to Spinors (2016) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24565914">thread link</a>) | @bindidwodtj
<br/>
September 23, 2020 | http://www.weylmann.com/spinor.pdf | <a href="https://web.archive.org/web/*/http://www.weylmann.com/spinor.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.weylmann.com/spinor.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24565914</guid>
            <pubDate>Wed, 23 Sep 2020 11:57:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the CPython compiler works]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24565499">thread link</a>) | @r4victor
<br/>
September 23, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <h3>Today's subject</h3>
<p>In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">the first post</a> of the series we've looked at the CPython VM. We've learned that it works by executing a series of instructions called bytecode. We've also seen that Python bytecode is not sufficient to fully describe what a piece of code does. That's why there exists a notion of a code object. To execute a code block such as a module or a function means to execute a corresponding code object. A code object contains block's bytecode, constants and names of variables used in the block and block's various properties.</p>
<p>Typically, a Python programmer doesn't write bytecode and doesn't create the code objects but writes a normal Python code. So CPython must be able to create a code object from a source code. This job is done by the CPython compiler. In this part we'll explore how it works.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h3>What CPython compiler is</h3>
<p>We understood what the responsibilities of the CPython compiler are, but before looking at how it is implemented, let's figure out why we call it a compiler in the first place?</p>
<p>A compiler, in its general sense, is a program that translates a program in one language into an equivalent program in another language. There are many types of compilers, but most of the times by a compiler we mean a static compiler, which translates a program in a high-level language to a machine code. Does the CPython compiler have something in common with this type of a compiler? To answer this question, let's take a look at the traditional three-stage design of a static compiler.</p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram1.png" alt="diagram1"></p>
<p>The frontend of a compiler transforms a source code into some intermediate representation (IR). The optimizer then takes an IR, optimizes it and passes an optimized IR to the backend that generates machine code. If we choose an IR that is not specific to any source language and any target machine, then we get a key benefit of the three-stage design: for a compiler to support a new source language only an additional frontend is needed and to support a new target machine only an additional backend is needed.</p>
<p>The LLVM toolchain is a great example of a success of this model. There are frontends for C, Rust, Swift and many other programming languages that rely on LLVM to provide more complicated parts of the compiler. LLVM's creator, Chris Lattner, gives a good <a href="http://aosabook.org/en/llvm.html">overview of its architecture</a>.</p>
<p>CPython, however, doesn't need to support multiple source languages and target machines but only a Python code and the CPython VM. Nevertheless, CPython compiler is an implementation of the three-stage design. To see why, we should examine the stages of a three-stage compiler in more detail. </p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram2.png" alt="diagram1"></p>
<p>The picture above represents a model of a classic compiler. Now compare it to the architecture of the CPython compiler in the picture below.</p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram3.png" alt="diagram1"></p>
<p>Looks similar, isn't it? The point here is that the structure of the CPython compiler should be familiar to anyone who studied compilers before. If you didn't, a famous <a href="https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">Dragon Book</a> is an excellent introduction to the theory of compiler construction. It's long, but you'll benefit even by reading only the first few chapters.</p>
<p>The comparison we've made requires several comments. First, since version 3.9, CPython uses a new parser by default that outputs an AST (Abstract Syntax Tree) straight away without an intermediate step of building a parse tree. Thus, the model of the CPython compiler is simplified even further. Second, some of the presented phases of the CPython compiler do so little compared to their counterparts of the static compilers that some may say that the CPython compiler is no more than a frontend. We won't take this view of the hardcore compiler writers.</p>
<h3>Overview of the compiler's architecture</h3>
<p>The diagrams are nice, but they hide many details and can be misleading, so let's spend some time discussing the overall design of the CPython compiler.</p>
<p>The two major components of the CPython compiler are:</p>
<ol>
<li>the frontend; and</li>
<li>the backend.</li>
</ol>
<p>The frontend takes a Python code and produces an AST. The backend takes an AST and produces a code object. Throughout the CPython source code the terms parser and compiler are used for the frontend and the backend respectively. This is yet another meaning of the word compiler. It was probably better to call it something like a code object generator, but we'll stick with the compiler since it doesn't seem to cause much trouble.</p>
<p>The job of the parser is to check whether the input is a syntactically correct Python code. If it's not, then the parser reports an error like the following:</p>
<div><pre><span></span><span>x</span> <span>=</span> <span>y</span> <span>=</span> <span>=</span> <span>12</span>
        <span>^</span>
<span>SyntaxError</span><span>:</span> <span>invalid</span> <span>syntax</span>
</pre></div>


<p>If the input is correct, then the parser organizes it according to the rules of the grammar. A grammar defines the syntax of a language. The notion of a formal grammar is so crucial for our discussion that, I think, we should digress a little to remember its formal definition.</p>
<p>According to the classic definition, a grammar is a tuple of four items:</p>
<ul>
<li><span>\(\Sigma\)</span> ‚Äì a finite set of terminal symbols, or simply terminals (usually denoted by lowercase letters).</li>
<li><span>\(N\)</span> ‚Äì a finite set of nonterminal symbols, or simply nonterminals (usually denoted by uppercase letters).</li>
<li><span>\(P\)</span> ‚Äì a set of production rules. In the case of context-free grammars, which include the Python grammar, a production rule is just a mapping from a nonterminal to any sequence of terminals and nonterminals like <span>\(A \to aB\)</span>.</li>
<li><span>\(S\)</span> ‚Äì one distinguished nonterminal.</li>
</ul>
<p>A grammar defines a language that consists of all sequences of terminals that can be generated by applying production rules. To generate some sequence, one starts with the symbol <span>\(S\)</span> and then recursively replaces each nonterminal with a sequence according to production rules until the whole sequence consists of terminals. Using established convention for the notation, it's sufficient to list production rules to specify the grammar. Here is, for example, a simple grammar that generates sequences of alternating ones and zeros:</p>
<p><span>\(S \to 10S \;| \;10\)</span></p>
<p>We'll continue to discuss grammars when we look at the parser in more detail.</p>
<h3>Abstract syntax tree</h3>
<p>The ultimate goal of the parser is to produce an AST. An AST is a tree data structure that serves as a high-level representation of a source code. Here's an example of a piece of code and a dump of the corresponding AST produced by the standard <a href="https://docs.python.org/3/library/ast.html"><code>ast</code></a> module:</p>



<div><pre><span></span>$ python -m ast example1.py
Module(
   body=[
      Assign(
         targets=[
            Name(id='x', ctx=Store())],
         value=Constant(value=123)),
      Expr(
         value=Call(
            func=Name(id='f', ctx=Load()),
            args=[
               Name(id='x', ctx=Load())],
            keywords=[]))],
   type_ignores=[])
</pre></div>


<p>The types of the AST nodes are formally defined using <a href="https://www.cs.princeton.edu/research/techreps/TR-554-97">the Zephyr Abstract Syntax Definition Language</a> (ASDL). The ASDL is a simple declarative language that was created to describe tree-like IRs, which is what the AST is. Here is the definitions of the <code>Assign</code> and <code>Expr</code> nodes from <a href="https://github.com/python/cpython/blob/master/Parser/Python.asdl">Parser/Python.asdl</a>:</p>
<div><pre><span></span>stmt = ... | Assign(expr* targets, expr value, string? type_comment) | ...
expr = ... | Call(expr func, expr* args, keyword* keywords) | ...
</pre></div>


<p>The ASDL specification should give us an idea of what the Python AST looks like. The parser, however, needs to represent an AST in the C code. Fortunately, it's easy to generate the C structs for the AST nodes from their ASDL descriptions. That's what CPython does, and the result looks like this:</p>
<div><pre><span></span><span>struct</span> <span>_stmt</span> <span>{</span>
    <span>enum</span> <span>_stmt_kind</span> <span>kind</span><span>;</span>
    <span>union</span> <span>{</span>
        <span>// ... other kinds of statements</span>
        <span>struct</span> <span>{</span>
            <span>asdl_seq</span> <span>*</span><span>targets</span><span>;</span>
            <span>expr_ty</span> <span>value</span><span>;</span>
            <span>string</span> <span>type_comment</span><span>;</span>
        <span>}</span> <span>Assign</span><span>;</span>
        <span>// ... other kinds of statements</span>
    <span>}</span> <span>v</span><span>;</span>
    <span>int</span> <span>lineno</span><span>;</span>
    <span>int</span> <span>col_offset</span><span>;</span>
    <span>int</span> <span>end_lineno</span><span>;</span>
    <span>int</span> <span>end_col_offset</span><span>;</span>
<span>};</span>

<span>struct</span> <span>_expr</span> <span>{</span>
    <span>enum</span> <span>_expr_kind</span> <span>kind</span><span>;</span>
    <span>union</span> <span>{</span>
        <span>// ... other kinds of expressions</span>
        <span>struct</span> <span>{</span>
            <span>expr_ty</span> <span>func</span><span>;</span>
            <span>asdl_seq</span> <span>*</span><span>args</span><span>;</span>
            <span>asdl_seq</span> <span>*</span><span>keywords</span><span>;</span>
        <span>}</span> <span>Call</span><span>;</span>
        <span>// ... other kinds of expressions</span>
    <span>}</span> <span>v</span><span>;</span>
    <span>// ... same as in _stmt</span>
<span>};</span>
</pre></div>


<p>An AST is a handy representation to work with. It tells what a program does, hiding all non-essential information such as indentation, punctuation and other Python's syntactic features.</p>
<p>One of the main beneficiaries of the AST representation is the compiler, which can walk an AST and emit bytecode in a relatively straightforward manner. Many Python tools, besides the compiler, use the AST to work with Python code. For example, <a href="https://github.com/pytest-dev/pytest/">pytest</a> makes changes to an AST to provide useful information when the <code>assert</code> statement fails, which by itself does nothing but raises an <code>AssertionError</code> if the expression evaluates to <code>False</code>. Another example is <a href="https://github.com/PyCQA/bandit">Bandit</a> that finds common security issues in Python code by analyzing an AST.</p>
<p>Now, when we've studied the Python AST a little bit, we can look at how the parser builds it from a source code.</p>
<h3>From source code to AST</h3>
<p>In fact, as I mentioned earlier, starting with version 3.9, CPython has not one but two parsers. The new parser is used by default. It's also possible to use the old parser by passing <code>-X oldparser</code> option. In CPython 3.10, however, the old parser will be completely removed.</p>
<p>The two parser are very different. We'll focus on the new one but before discuss the old parser as well.</p>
<h4>old parser</h4>
<p>For a long time the Python's syntax was formally defined by the generative grammar. It's a kind of grammar we've talked about earlier. It tells us how to generate sequences belonging to the language. The problem is that a generative grammar doesn't directly corresponds to the parsing algorithm that would be able to parse those sequences. Fortunately, smart people have been able to distinguish classes of generative grammars for which the corresponding parser can be built. These include <a href="https://en.wikipedia.org/wiki/Context-free_grammar">context free</a>, <a href="https://en.wikipedia.org/wiki/LL_grammar">LL(k),</a> <a href="https://en.wikipedia.org/wiki/LR_parser">LR(k)</a>, <a href="https://en.wikipedia.org/wiki/LALR_parser">LALR</a> and many ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24565499</guid>
            <pubDate>Wed, 23 Sep 2020 11:08:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Almost Realtime Live Data Visualization in QGIS ‚Äì Air Traffic Use Case]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24565250">thread link</a>) | @geomatics99
<br/>
September 23, 2020 | https://www.geodose.com/2020/09/realtime%20live%20data%20visualization%20qgis.html | <a href="https://web.archive.org/web/*/https://www.geodose.com/2020/09/realtime%20live%20data%20visualization%20qgis.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-3280341045593062951" itemprop="articleBody">
<p>
  When working in a GIS software like QGIS, mostly we are working with static
  data like street, building, land cover, etc. Or might be a data which has time
  information so we can visualize the temporal change. What about visualize live
  data in almost real time? Do we need a GIS server, cloud or map service? I
  think this is an interesting topic, and I will discuss about it in this post
  with live air traffic data use case.
</p>
<p>
  In the previous post, I made a tutorial
  <a href="https://www.geodose.com/2020/08/create-flight-tracking-apps-using-python-open-data.html">how to build a flight tracking application with open air traffic data in
    Python</a>. The application is running in a web browser and the flight data will be
  updated in a specified time interval. In this tutorial we will do the same
  thing in QGIS. We will visualize the air traffic live data on QGIS map canvas
  and get the update data in every five or ten seconds. At the end of this
  tutorial we will get an almost realtime airplanes' location within an area as
  in figure 1 below.
</p>

<table>
  <tbody>
    <tr>
      <td>
        <a href="https://1.bp.blogspot.com/-Uk3IIrnlhrg/X1ulZ9x2OlI/AAAAAAAACRA/E1JjjYxKqBYgOCpc2ConnZDGREkWEuNAwCNcBGAsYHQ/s997/live-data-sfo-airport3.gif"><img alt="Air Traffic Live Data in QGIS" data-original-height="602" data-original-width="997" height="386" src="https://1.bp.blogspot.com/-Uk3IIrnlhrg/X1ulZ9x2OlI/AAAAAAAACRA/E1JjjYxKqBYgOCpc2ConnZDGREkWEuNAwCNcBGAsYHQ/w640-h386/live-data-sfo-airport3.gif" title="Air Traffic Live Data in QGIS" width="640"></a>
      </td>
    </tr>
    <tr>
      <td>
        Figure 1. Air Traffic Live Data in QGIS. Airplanes are queueing for
        landing at San Fransisco International Airport <br>
      </td>
    </tr>
  </tbody>
</table>

<p>
  Figure 2 is the schema that shows how the system works. Can be seen from the
  schema that Python plays role for requesting the data, get the response,
  process it and store the data into a CSV plain text. On the other side, QGIS
  will render the airplanes position based on the data and refresh it with in an
  interval to get the latest information. To make it happen, we don't need any
  GIS server, cloud or map service. Anyone could do this as long as there is
  internet connection available with Python and QGIS installed in a machine.<br>
</p>
<br>
<div>
  <table>
    <tbody>
      <tr>
        <td>
          <img alt="Schema how the system works (QGIS Live Data)" data-original-height="173" data-original-width="1053" height="106" src="https://1.bp.blogspot.com/-JaG5RhN6xJA/X19BMD_ygnI/AAAAAAAACRg/2u5J81mQquAFKSYqE6eBa_PMtrKRVuX_gCNcBGAsYHQ/w640-h106/schema%2Blive%2Bdata%2Bqgis.png" title="Schema how the system works (QGIS Live Data)" width="640">
        </td>
      </tr>
      <tr>
        <td>
          &nbsp;Figure2 . Schema how the system works<br>
        </td>
      </tr>
    </tbody>
  </table>
  
  
</div>






<p>
  Based on the schema, this tutorial consist of several sub-topics, such as:
  getting the data (send the request and process the response), Plotting the
  data on QGIS map canvas and render it within a time interval. Let's get
  started!<br>
</p>

<p><h3>Getting Air Traffic Live Data</h3></p>

<p>
  The data for this tutorial is coming from
  <a href="https://opensky-network.org/" rel="nofollow" target="_blank">OpenSky Network</a>
  which is an association that provides air traffic data around the globe. There
  are some APIs that can be used to retrieve data from OpenskyNetwork such as:
  Python API, Java API and REST API. In this tutorial we will use REST API to
  retrieve data within a specified boundary area.
</p>
<p>
  To retrieve air traffic data within an area we need to define minimum and
  maximum coordinate in geographic coordinate system. For example I want to
  fetch all planes over United States with minimum and maximum coordinate
  respectively -125.974,30.038 and -68.748,52.214. The REST API query to request
  the data anonymously will be as follow:
</p>
<p>
  <i>https://opensky-network.org/api/states/all?lamin=30.038&amp;lomin=-125.974&amp;
    <br>lamax=52.214&amp;lomax=-68.748</i><br>
</p>
<p>
  The anonymous request has resolution 10 seconds, it means we can send the
  request in every 10 seconds. On the other hand if you are a registered user,
  the resolution will be faster, about 5 seconds. To make a request as
  registered user, the username and password must be include in the query. Then
  the query will be:
</p>
<p>
  https://<span>username:password</span>@opensky-network.org/api/states/all?lamin=30.038lomin=-125.974&amp;
  lamax=52.214&amp;lomax=-68.748
</p>
<p>
  To try the query, simply copy it and paste into a browser. If you get a
  response like figure 3, means it works and we are ready to continue to the
  next step. Furthermore if you want to know in more detail about air traffic
  data response from OpenSky Network please visit
  <a href="https://opensky-network.org/apidoc/rest.html">REST API Documentation</a>.<br>
</p>

<table>
  <tbody>
    <tr>
      <td>
        <img alt="Live Air Traffic Data Response" data-original-height="452" data-original-width="793" height="364" src="https://1.bp.blogspot.com/-Y8dig7kzJZY/X2Dzni4ErgI/AAAAAAAACRs/AngxaoNxE94l0AU3j2rVDHTzH3I8FhFYgCNcBGAsYHQ/w640-h364/air-traffic-data-response.png" title="Live Air Traffic Data Response" width="640">
      </td>
    </tr>
    <tr>
      <td>
        Figure 3. Live Air Traffic Data Response<br>
      </td>
    </tr>
  </tbody>
</table>



<h3>
  Sending Request and Process The Live Data Response
</h3>
<p>
  In this step we will write Python code to request the live air traffic data
  and process the response. The complete code can be found at the end of this
  section.
</p>
<p>
  We are starting with importing some libraries namely: requests, json, csv and
  time. Then define the coordinate extent with minimum and maximum coordinate.
  Next at line 16 an output path where the response data will be stored is
  specified, so make sure to change with yours. If you are a registered OpenSky
  Network user, giver your username and also the password in
  <i>user_name</i> and <i>password</i> variable at line 19-20. The last part of
  the code is used to send the query using requests, get response in JSON format
  and save it into a CSV file. This process will be done in a loop within
  interval 10 seconds for anonymous request or 5 seconds for a registered user.
  &nbsp; <br>
</p>

<div>
  <table>
    <tbody>
      <tr>
        <td>
          <pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47</pre>
        </td>
        <td>
          <pre><span>'''</span>
<span>LIVE AIR DATA TRAFFIC REQUEST</span>
<span>by ideagora geomatics | www.geodose.com | @ideageo</span>
<span>'''</span>
<span>#IMPORTING LIBRARIES</span>
<span>import</span> <span>requests</span>
<span>import</span> <span>json</span>
<span>import</span> <span>csv</span>
<span>import</span> <span>time</span>

<span>#AREA EXTENT COORDINATE GCS WGS84</span>
<span>lon_min,lat_min</span><span>=-</span><span>125.974</span><span>,</span><span>30.038</span>
<span>lon_max,lat_max</span><span>=-</span><span>68.748</span><span>,</span><span>52.214</span>

<span>#CSV OUPUT PATH</span>
<span>csv_data</span><span>=</span><span>'/home/data.csv'</span>

<span>#REST API QUERY</span>
<span>user_name</span><span>=</span><span>''</span>
<span>password</span><span>=</span><span>''</span>
<span>url_data</span><span>=</span><span>'https://'</span><span>+</span><span>user_name</span><span>+</span><span>':'</span><span>+</span><span>password</span><span>+</span><span>'@opensky-network.org/api/states/all?'</span><span>+</span><span>'lamin='</span><span>+</span><span>str(lat_min)</span><span>+</span><span>'&amp;lomin='</span><span>+</span><span>str(lon_min)</span><span>+</span><span>'&amp;lamax='</span><span>+</span><span>str(lat_max)</span><span>+</span><span>'&amp;lomax='</span><span>+</span><span>str(lon_max)</span>
<span>col_name</span><span>=</span><span>[</span><span>'icao24'</span><span>,</span><span>'callsign'</span><span>,</span><span>'origin_country'</span><span>,</span><span>'time_position'</span><span>,</span><span>'last_contact'</span><span>,</span><span>'long'</span><span>,</span><span>'lat'</span><span>,</span><span>'baro_altitude'</span><span>,</span><span>'on_ground'</span><span>,</span><span>'velocity'</span><span>,</span>       
<span>'true_track'</span><span>,</span><span>'vertical_rate'</span><span>,</span><span>'sensors'</span><span>,</span><span>'geo_altitude'</span><span>,</span><span>'squawk'</span><span>,</span><span>'spi'</span><span>,</span><span>'position_source'</span><span>]</span>

<span>#REQUEST INTERVAL</span>
<span>if</span> <span>user_name</span> <span>!=</span><span>''</span> <span>and</span> <span>password</span> <span>!=</span><span>''</span><span>:</span>
    <span>sleep_time</span><span>=</span><span>5</span>
<span>else</span><span>:</span>
    <span>sleep_time</span><span>=</span><span>10</span>

<span>#GET DATA AND STORE INTO CSV</span>
<span>while</span> <span>col_name</span> <span>!=</span><span>''</span><span>:</span>
    <span>with</span> <span>open(csv_data,</span><span>'w'</span><span>)</span> <span>as</span> <span>csv_file:</span>
        <span>csv_writer</span><span>=</span><span>csv</span><span>.</span><span>writer(csv_file,delimiter</span><span>=</span><span>','</span><span>,quotechar</span><span>=</span><span>'"'</span><span>,quoting</span><span>=</span><span>csv</span><span>.</span><span>QUOTE_ALL)</span>
        <span>csv_writer</span><span>.</span><span>writerow(col_name)</span>
        <span>response</span><span>=</span><span>requests</span><span>.</span><span>get(url_data)</span><span>.</span><span>json()</span>
        
        <span>try</span><span>:</span>
            <span>n_response</span><span>=</span><span>len(response[</span><span>'states'</span><span>])</span>
        <span>except</span> <span>Exception</span><span>:</span>
            <span>pass</span>
        <span>else</span><span>:</span>
            <span>for</span> <span>i</span> <span>in</span> <span>range(n_response):</span>
                <span>info</span><span>=</span><span>response[</span><span>'states'</span><span>][i]</span>
                <span>csv_writer</span><span>.</span><span>writerow(info)</span>
    <span>time</span><span>.</span><span>sleep(sleep_time)</span>
    <span>print(</span><span>'Get'</span><span>,len(response[</span><span>'states'</span><span>]),</span><span>'data'</span><span>)</span>
</pre>
        </td>
      </tr>
    </tbody>
  </table>
</div>

<p>
  Save the code with Python extension (.py) and run it from a command prompt or
  terminal. Type <i>python</i> or <i>python3</i> if you use python 3 followed by
  the file name. The code will be running as in figure 4 below.&nbsp;
</p>
<p>
  Don't close the terminal, because it will work continuously to get the latest
  air traffic data from OpenSky Network, and we will use it in QGIS. <br>
</p>
<table>
  <tbody>
    <tr>
      <td>
        <img alt="Flight Data Request" data-original-height="309" data-original-width="480" height="258" src="https://1.bp.blogspot.com/-RAkHV_x_kTE/X2Fl4gX-HsI/AAAAAAAACSA/IAMcBX7xGTMkROtvJ6GQp_FoQn2yRHMqQCNcBGAsYHQ/w400-h258/flight-request-code-running.png" title="Flight Data Request" width="400">
      </td>
    </tr>
    <tr>
      <td>
        Figure 4. Flight Data Request<br>
      </td>
    </tr>
  </tbody>
</table>

<h3>Visualize Live Air Traffic Data in QGIS</h3>
<p>
  We already get the live data streaming, now let's visualize it in QGIS with
  the following steps.
</p>
<p>
  Add the CSV data into QGIS. From <i>Data Source Manager</i>, select
  <i>Delimited Text</i> in the left menu. Then in the right side, select&nbsp;
  the <i>File Name. </i>In <i>Geometry Definition</i> section select
  <i>long</i> column for <i>X field</i> and <i>lat </i>column for
  <i>Y field</i>. Make sure to get the <i>Sample Data</i> correctly. If not try
  to change the delimiter properties in <i>File Format</i> section with
  <i>Custom delimiters</i> option.&nbsp; &nbsp; &nbsp;
</p>

<table>
  <tbody>
    <tr>
      <td>
        <img alt="Add flight data QGIS" data-original-height="601" data-original-width="856" height="450" src="https://1.bp.blogspot.com/-nTLyM8xeWeE/X2JDVOIugiI/AAAAAAAACSY/tUnwZ1Z0Gxg2-FMWbU_Db3QcWIAMH0bowCNcBGAsYHQ/w640-h450/qgis-add-flight-data.png" title="Add flight data QGIS" width="640">
      </td>
    </tr>
    <tr>
      <td>
        Figure 5. Add Air Traffic Data to QGIS<br>
      </td>
    </tr>
  </tbody>
</table>
<p>
  After pushing the <i>Add</i> button in the <i>Data Source Manager</i>, the air
  plane's position within the requested area will be plotted on QGIS map canvas.
  To make it more meaningful in a geospatial extent, add a basemap. To add a
  basemap I used
  <a href="https://www.geodose.com/2018/11/qgis3-basemap-plugin-tile-plus.html">Tile+</a>
  plugin which provides some popular basemaps. For this case I used STAMEN
  TERRAIN basemap.&nbsp; Figure 6 shows all aircraft's position over the US with
  STAMEN TERRAIN basemap.<br>
</p>
<table>
  <tbody>
    <tr>
      <td>
        <img alt="Aircraft Position in QGIS Map Canvas" data-original-height="599" data-original-width="1091" height="352" src="https://1.bp.blogspot.com/-6FDJtf32igE/X2JFxFj06TI/AAAAAAAACSs/2VvbdqRN8WA5YRMYS7hv0RueuEWFBGviACNcBGAsYHQ/w640-h352/flight-data-plot-qgis-basemap.png" title="Aircraft Position in QGIS Map Canvas" width="640">
      </td>
    </tr>
    <tr>
      <td>
        Figure 6. Aircraft Position in QGIS Map Canvas<br>
      </td>
    </tr>
  </tbody>
</table>
<p>
  So far we already get airplane position in a static way. The position of
  airplanes will not change because it doesn't fetch any updated data. Therefore
  in this last step, we will make it dynamic. The position of aircraft will be
  updated every 5 or 10 seconds. Then we will change the dot marker with
  airplane icon and also rotate it respectively with the track direction.
</p>
<p>
  Firstly let's change the dot marker into airplane icon. Right click on data
  layer and then select <i>Properties</i>. On the left menu select
  <i>Symbology</i> and chose <i>topo airport</i> icon as in figure 7.<br>
</p>

<table>
  <tbody>
    <tr>
      <td>
        <a href="https://1.bp.blogspot.com/-LKKiEhhdoSQ/X2JKDHl_NkI/AAAAAAAACS4/pjayRfO1zGo4kYT062mVtN7zqkaFxiA0gCNcBGAsYHQ/s823/change-symbology-qgis.png"><img alt="Change Symbology" data-original-height="566" data-original-width="823" height="440" src="https://1.bp.blogspot.com/-LKKiEhhdoSQ/X2JKDHl_NkI/AAAAAAAACS4/pjayRfO1zGo4kYT062mVtN7zqkaFxiA0gCNcBGAsYHQ/w640-h440/change-symbology-qgis.png" title="Change Symbology" width="640"></a>
      </td>
    </tr>
    <tr>
      <td>
        Figure 7. Change Symbology<br>
      </td>
    </tr>
  </tbody>
</table>
<p>To set rotation angle of the marker, select the menu at the right of
<i>Rotation</i> parameter then&nbsp; select <i>Field type:....</i> and then
select <i>true_track</i> column (see figure 8).&nbsp; <br>

<ins data-ad-client="ca-pub-5632482621101280" data-ad-format="fluid" data-ad-layout="in-article" data-ad-slot="7655392618"></ins></p>
<table>
  <tbody>
    <tr>
      <td>
        <a href="https://1.bp.blogspot.com/-w2UafXoJYDg/X2JLHf8QBuI/AAAAAAAACTA/z3V9zCZTI6s9hb4iwPLifcEcTp-UXvBuwCNcBGAsYHQ/s513/select-rotation-angle.png"><img alt="Set Rotation Angle" data-original-height="294" data-original-width="513" height="229" src="https://1.bp.blogspot.com/-w2UafXoJYDg/X2JLHf8QBuI/AAAAAAAACTA/z3V9zCZTI6s9hb4iwPLifcEcTp-UXvBuwCNcBGAsYHQ/w400-h229/select-rotation-angle.png" title="Set Rotation Angle" width="400"></a>
      </td>
    </tr>
    <tr>
      <td>
        Figure 8. Set Rotation Angle<br>
      </td>
    </tr>
  </tbody>
</table>
&nbsp;

<p>
  Before proceeding to the next step, click <i>Apply </i>or <i>OK </i>button.
  You should see the airplane marker and&nbsp; it rotates in flight direction
  angle as shown in figure 9.
</p>
<table>
  <tbody>
    <tr>
      <td>
        <a href="https://1.bp.blogspot.com/-T9sCVld99NY/X2JMuwFYwWI/AAAAAAAACTM/RAB0B78Cihw7oel_TPmZmigrsxAOoAAuACNcBGAsYHQ/s1089/airplanes-marker-rotate.png"><img alt="Airplane marker with it's rotation angle" data-original-height="600" data-original-width="1089" height="352" src="https://1.bp.blogspot.com/-T9sCVld99NY/X2JMuwFYwWI/AAAAAAAACTM/RAB0B78Cihw7oel_TPmZmigrsxAOoAAuACNcBGAsYHQ/w640-h352/airplanes-marker-rotate.png" title="Airplane marker with it's rotation angle" width="640"></a>
      </td>
    </tr>
    <tr>
      <td>
        Figure 9. Airplane marker with it's rotation angle<br>
      </td>
    </tr>
  </tbody>
</table>

<p>
  Finally let's update the data within a time interval. Select data layer and
  choose Properties again. On the left menu select <i>Rendering</i>. In the
  right window check <i>Refresh layer at interval (seconds)</i> option, and set
  it to 5 or 10 as in figure 10. It means the layer will refreshed every 5 or 10
  seconds. If there is any data change after refreshing is taking place, the
  position of airplanes will be updated and we get an almost realtime air
  traffic live data that visualized in QGIS as seen before in figure 1.<br>
</p>
<table>
  <tbody>
    <tr>
      <td>
        <a href="https://1.bp.blogspot.com/-xXMt1izln4g/X2JN5Hnp72I/AAAAAAAACTY/UKczXaiKqGovSKw8gQrWjM9uuEEUW-ekQCNcBGAsYHQ/s824/refreshed-layer.png"><img alt="Set refresh layer interval time" data-original-height="616" data-original-width="824" height="478" src="https://1.bp.blogspot.com/-xXMt1izln4g/X2JN5Hnp72I/AAAAAAAACTY/UKczXaiKqGovSKw8gQrWjM9uuEEUW-ekQCNcBGAsYHQ/w640-h478/refreshed-layer.png" title="Set refresh layer interval time" width="640"></a>
      </td>
    </tr>
    <tr>
      <td>
        Figure 10. Set refresh layer interval time<br>
      </td>
    </tr>
  </tbody>
</table>

<p>
  That's all this tutorial how to visualize an almost realtime live data in
  QGIS. I think&nbsp; this approach can be applied for other cases like
  visualize data from a sensor that taking measurement in a field like water level, temperature, humidity, and many more. Hope this post could
  inspire you and thanks for reading!<br>
</p>

<!--large_rectangle_336x280-->

<p><i>Ó¢ì</i>
<a href="https://www.geodose.com/search/label/Live%20Data?&amp;max-results=8" rel="tag" title="Live Data">Live Data</a>
<a href="https://www.geodose.com/search/label/QGIS?&amp;max-results=8" rel="tag" title="QGIS">QGIS</a>
<a href="https://www.geodose.com/search/label/Tutorial?&amp;max-results=8" rel="tag" title="Tutorial">Tutorial</a></p>

</div></div>]]>
            </description>
            <link>https://www.geodose.com/2020/09/realtime%20live%20data%20visualization%20qgis.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24565250</guid>
            <pubDate>Wed, 23 Sep 2020 10:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is a Minimally Good Life?]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24565154">thread link</a>) | @bertdc
<br/>
September 23, 2020 | https://psyche.co/ideas/what-is-a-minimally-good-life-and-are-you-prepared-to-live-it | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/what-is-a-minimally-good-life-and-are-you-prepared-to-live-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>As a basic minimum</strong>, what do members of a society owe to one another? How we answer this question determines what safety nets societies provide for their members, and so helps to shape the structure of the society at large. It is crucial, then, that we formulate a method in which to figure out what, at a minimum, we owe to others. The way to do that is simple: we should consider whether <em>we</em> would be content to live the lives that the least fortunate in our society actually live. We should put ourselves into each other√¢‚Ç¨‚Ñ¢s shoes √¢‚Ç¨‚Äú and then consider what each person needs to live well<em>.</em></p>
<p>People need many of the same things, by virtue of being human. Everyone must be able to meet their basic needs for things such as food, water and shelter. But that√¢‚Ç¨‚Ñ¢s not all. To live at least minimally well, the good things in each person√¢‚Ç¨‚Ñ¢s life (such as relationships, pleasures, knowledge, appreciation, worthwhile activities) must compensate for their difficulties, pains, losses and frustrations. Everyone also needs decent opportunities and the capabilities to realise them. Or, at least, each person should get as close as possible to meeting this standard.</p>
<p>However, the differences between people also matter immensely, and our differences as people explain why it is not enough if everyone has exactly the same things. Pregnant women, for instance, need more food than those who aren√¢‚Ç¨‚Ñ¢t pregnant. Those who can√¢‚Ç¨‚Ñ¢t walk might need help getting around. And, in some cases, we have to consider cultural differences just to ensure that everyone can eat.</p>
<p>We should ask whether <em>we</em> would really be content to live each other person√¢‚Ç¨‚Ñ¢s life in our society. To be clear, this is different from asking each person directly what they need. The danger here is that people can be mistaken about their needs. Some get so used to poor conditions that they no longer strive to improve them. Others are so poorly off that they simply don√¢‚Ç¨‚Ñ¢t understand that their conditions are poor in the first place. The thought is that having some distance from each person√¢‚Ç¨‚Ñ¢s experience will help us see whether that person really needs all the things they think they need. We might likewise consider whether the person needs resources, opportunities, capabilities and so forth that they think they don√¢‚Ç¨‚Ñ¢t need, but in fact do.</p>
<p>Of course, not everyone will agree on what we all need in order to live a minimally good life. But it is my contention that free, reasonable and caring people <em>should</em>. To see why, it is important to understand what it actually is that makes people reasonable, caring and free. People are reasonable when they are appropriately impartial; they don√¢‚Ç¨‚Ñ¢t privilege the greater needs of some over others. People are caring when they empathise with others: understanding their circumstances, their history, their perspectives. Caring people want to promote others√¢‚Ç¨‚Ñ¢ interests in proportion to their weight. And people are free when they can reason about, make and carry out plans for themselves. Free people also have decent options and bargaining power.</p>
<p>I believe that no one really deserves to be born with what they have √¢‚Ç¨‚Äú their natural resources, institutions or tools</p>
<p><strong>Now, consider why</strong> reasonable, caring, free people √¢‚Ç¨‚Äú who have all the relevant information √¢‚Ç¨‚Äú will agree that everyone should have adequate resources, opportunities, capabilities and so forth to live a minimally good life. If we√¢‚Ç¨‚Ñ¢re appropriately impartial, we√¢‚Ç¨‚Ñ¢ll set for others only that standard under which we√¢‚Ç¨‚Ñ¢re content to live as others do. If we√¢‚Ç¨‚Ñ¢re caring, we√¢‚Ç¨‚Ñ¢ll set a standard that we believe is sufficient for others with their particular interests. If we√¢‚Ç¨‚Ñ¢re free and caring, and have all the relevant information, we won√¢‚Ç¨‚Ñ¢t make a mistake about whether the standard is sufficient for others with those interests.</p>
<p>There is a sense in which even some of the most impoverished, oppressed and disadvantaged people can live excellent, never mind minimally good, lives. As the philosopher Dan Haybron suggests, it is often reasonable to affirm lives, even when they lack many of the things that people can justifiably aspire to as a matter of basic rights<em>.</em> Still, I am interested here in the latter sense of what makes lives minimally good √¢‚Ç¨‚Äú I am concerned with what people can justifiably aspire to as a matter of basic right.</p>
<p>My proposal is this: in order to figure out what this kind of minimally good life requires, we should attempt to avail ourselves of another√¢‚Ç¨‚Ñ¢s perspective on their own life, and consider what we√¢‚Ç¨‚Ñ¢d need to live such a life. And when we are reasonable, caring and free, we√¢‚Ç¨‚Ñ¢ll set a standard that is sufficient for others given their particular interests. Moreover, if we put ourselves in others√¢‚Ç¨‚Ñ¢ shoes in trying to figure out what a minimally good life requires, we won√¢‚Ç¨‚Ñ¢t set the threshold too high. The question is not whether a fortunate individual would be willing to trade places with someone who is able to live only a minimally good life. Rather, the question is only whether the free, reasonable and caring person would be content if they had to live as that person does.</p>
<p>Since people have different backgrounds, goals, tools and resources, one might argue that different standards are appropriate for those who grow up in different circumstances (whether it be the cornfields of Nebraska or the slums of New York City). Furthermore, it√¢‚Ç¨‚Ñ¢s commonly held that people deserve the advantages they have: since everyone has grown up in the √¢‚Ç¨Àúreal world√¢‚Ç¨‚Ñ¢, they should know what to expect for their efforts. I believe that no one really deserves to be born with what they have √¢‚Ç¨‚Äú their natural resources, institutions or tools. Everyone will try hard enough to live minimally well if they can. So, while some might need more than others, we should help everyone live at least minimally well. This doesn√¢‚Ç¨‚Ñ¢t mean we have to give everyone exactly the same things √¢‚Ç¨‚Äú still, if we are, or consider ourselves to be, reasonable, caring and free, then we must help everyone secure the things they need to live minimally well.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/what-is-a-minimally-good-life-and-are-you-prepared-to-live-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-24565154</guid>
            <pubDate>Wed, 23 Sep 2020 10:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell's Children]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24565019">thread link</a>) | @xiaodai
<br/>
September 23, 2020 | https://owenlynch.org/posts/2020-09-16-haskells-children/ | <a href="https://web.archive.org/web/*/https://owenlynch.org/posts/2020-09-16-haskells-children/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>
    Posted on September 16, 2020
    
</p>

<p>If I were to travel back in time 4 years ago, and tell my old self that Haskell was starting to lose its shine, I wouldn‚Äôt believe it. I grew up on Haskell, my appetite for category theory was whetted by Haskell, my biggest programming projects have been in Haskell, and my dream job was to work at a company that used Haskell.</p>
<p>But now, I find myself simply not as excited about Haskell as I used to be. What changed?</p>
<p>I think there are a couple things. I think one primary factor is that the kind of programming that Haskell really excells in; i.e.&nbsp;creating abstract, correct interfaces for things, is just not a type of programming that‚Äôs interesting to me anymore. When I wanted to work on software as a career, a language that allowed incredible facilities in not repeating yourself was very useful. Types that ensure correctness of data interchange, or lenses that allow access to complicated data structures are all very well for implementing, say, a compiler, or complicated business logic in a web backend. However, my interests in software are now primarily as a scientific/mathematical tool. Numerical algorithms can be done in Haskell, but they don‚Äôt really gain much benefit from the type system, and they also don‚Äôt have great library support.</p>
<p>No doubt Haskell could be made into the kind of language to use for the problems that I am interested in, but given the choice between working on the problems that interest me, and working on infrastructure for the problems that interest me, I would rather work on the problems that interest me. The general feeling that I have is that Haskell is a great tool for a software engineer, but I don‚Äôt want to be a software engineer, I want to be a mathematician that sometimes uses computers.</p>
<p>But there is another reason too. While I think that Haskell is still a great language, it is close to 30 years old at this point. It manages to stay fresh and relevant with an ever-growing list of extensions, and constantly changing best practices and libraries (which is itself a problem‚Ä¶), but it would be very sad if we as a society of programmers had failed to surpass it in any respect with any of the programming languages that have had the advantage of starting from a clean slate. In this post, I want to talk about these successor languages, and what I think about them.</p>
<h2 id="rust">Rust</h2>
<p>Surprisingly, one of Haskell‚Äôs great strengths is as a systems language. It manages to be much faster than most dynamic languages, while allowing a much higher-level interface than traditional systems languages like C (obviously). One great example of a ‚Äúsystems‚Äù program written in Haskell is git-annex. It is a git addition that adds tracking of large files, and was my primary backup system for a long time (I eventually decided that I didn‚Äôt need the additional power from it, and was better served by a more seamless solution).</p>
<p>However, in 2020, the premier system‚Äôs language is surely Rust. It would be unfair to compare the performance of Rust and Haskell, because Haskell is optimized for things other than performance. That being said, Rust is <em>faster</em> and <em>lower-latency</em> than Haskell, both of which are important. However, it also has a great type system, unlike C or C++ (we don‚Äôt talk about Go‚Ä¶). The type system in Rust is obviously very influenced by the type system of Haskell, but they also implemented ‚Äúownership‚Äù which allows for the killer feature garbage-collection free automatic memory management.</p>
<p>When I first started using Rust, I really missed monads. But here‚Äôs the thing. Having used lots of monads in Haskell, and read lots of blog posts about monads, I‚Äôve learned that in systems contexts, it‚Äôs often best to just have a simple monad stack that just consists of Reader + IO (and Maybe‚Äôs and Option‚Äôs sprinkled about occasionally). Huge monad transformer stacks often raise more problems than they solve. But Reader + IO is <em>essentially</em> the ‚Äúdefault monad stack‚Äù of Rust.</p>
<p>Rust also has some other killer features, like the ability to compile to webassembly (yes there is ghcjs, but, really, do you want to use ghcjs?) It also from the beginning was targetted towards industry, and consequentially has a much more vibrant ecosystem.</p>
<p>This all being said, I think it is worth looking at the features that are prominent in Haskell that ended up going to Rust</p>
<ul>
<li>Typeclasses (in Rust they are Traits)</li>
<li>Sum types (you may take this for granted, but a lot of languages don‚Äôt have them‚Ä¶.)</li>
<li>Pervasive pattern matching</li>
<li>Hindley-Mindler type inference (automatic type inference for variables)</li>
<li>Pervasiveness of things being <em>expressions</em> rather than statements</li>
<li>Parametric Polymorphism</li>
<li>The feeling that once your program compiles, it will run</li>
</ul>
<p>I think that we should recognize Rust for what it is, a child of Haskell and the Haskell community, and like all good parents, we should want it to do better than the previous generation. In as much as Haskell is the ideas that form Haskell, the success of Rust is the success of Haskell.</p>
<h2 id="idris">Idris</h2>
<p>OK, mainstream programming languages are great, but sometimes you just want to make the perfect type-based interface to your stuff and show the imperative scrubs what a wiz-kid you are. Or alternatively, sometimes you really care that your software is correct. Or you want to concretize a new category-theory inspired design for a part of a compiler. Nowadays, the language for that is not Haskell, it is Idris.</p>
<p>There are about six different ways to sort of have dependent types in Haskell (types that depend on values, like a length-<span>n</span>) array. I don‚Äôt really fully understand any of them, and it is totally unclear to me how they work together. Presumably, there are blogs which outline the One True Way, but‚Ä¶ it‚Äôs tough. In Idris, it just seems perfectly natural to use dependent types, like, why wouldn‚Äôt you able to have a type parameter which was a value? In many ways other than dependent types, Idris is a much cleaner language than Haskell too. And with Idris2, it has support for <em>linear types</em>, which allow mutability in a functional context via guarantees that nobody is going to try and use the old value. If I want to play around with a cool type system in a language that can also actually do things with the real world (i.e., unlike Agda or Coq), I would go to Idris rather than Haskell.</p>
<p>But Idris is undeniably Haskell‚Äôs child. The first version was written in Haskell (it is now self-hosting). They are similar in more ways than it is worth counting. Enough said.</p>
<h2 id="julia">Julia</h2>
<p>Unlike the first two, Julia doesn‚Äôt really muscle into Haskell‚Äôs territory. Scientific computing was never really Haskell‚Äôs forte, despite there being some very cool libraries written in it, like <code>ad</code> for autodifferentiation, or various array-handling packages that automatically fused consecutive array operations.</p>
<p>Also, Julia is a dynamically typed language. How could a filthy dynamically typed language ever claim to be Haskell‚Äôs child??</p>
<p>Well, for one it steals some of those cool libraries, and makes them much better! Flux is a neural networks library which essentially is just autodifferentiation + some nice utilities, and it is already competitive in my mind with TensorFlow. Julia also has StaticArrays, which integrates the size of the array into the type, and Julia has some neat fusion abilities too for making array operations really fast.</p>
<p>But wait, you ask, how can it do this if it‚Äôs not a statically typed language? Well, Julia is not your average dynamically typed language. It actually has a very interesting type system, a full discussion of which is beyond the scope of this post, and the focus on types as the unit of programming is (somewhat?) similar to Haskell (now I‚Äôm stretching it a little though).</p>
<p>The real reason I include Julia, however, is because for me personally, it has replaced Haskell as the place to do category theory. This is because of a shift of viewpoint: rather than providing a type system into which category theory can be embedded in to guide typical software engineering tasks, Julia provides a system in which <em>computations</em> in category theory can be carried out in an efficient way. Specifically, I‚Äôm talking about <a href="https://github.com/olynch/Catlab.jl">Catlab.jl</a>. A discussion of Catlab.jl is also beyond the scope of this post, but I encourage you to check it out.</p>
<p>Therefore, I count Julia as a child of Haskell (or maybe, I count Catlab.jl as a child of Haskell) because the idea of organizing computation with category theory would not exist in the same way if it weren‚Äôt for Haskell.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If I could talk to the Haskell-obsessed teenager that was me four years ago, I would tell him to keep his mind open. Haskell is still great for a lot of things (compilers come to mind), but if Haskell couldn‚Äôt inspire superior successors, there wouldn‚Äôt be worthwhile ideas in Haskell. There are those on the internet who are talking about how Haskell is dying, and they may or may not be wrong. Stephen Diehl, one of my main Haskell idols, is distancing himself from the Haskell community because of Haskell‚Äôs use as intellectual eye-candy on scam cryptocurrencies, and I think that there may be a tipping point where Haskell loses the zeitgeist of being exciting, and because it never had much of a foothold to begin with in industry, slips into irrelevance. But Haskell will always live on; it had a huge impact on many programmers and many languages disproportionate to its actual use, and it will always have a special place in my heart.</p>





        </div>
      </div></div>]]>
            </description>
            <link>https://owenlynch.org/posts/2020-09-16-haskells-children/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24565019</guid>
            <pubDate>Wed, 23 Sep 2020 09:47:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Studio Ghibli releases 400 free-to-use images]]>
            </title>
            <description>
<![CDATA[
Score 638 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24564775">thread link</a>) | @DyslexicAtheist
<br/>
September 23, 2020 | http://www.ghibli.jp/info/013344/ | <a href="https://web.archive.org/web/*/http://www.ghibli.jp/info/013344/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>‰ªäÊúà„Åã„Çâ„Çπ„Çø„Ç∏„Ç™„Ç∏„Éñ„É™ÂÖ®‰ΩúÂìÅ„ÅÆÂ†¥Èù¢ÂÜôÁúü„ÇíÈ†ÜÊ¨°Êèê‰æõ„Åô„Çã„Åì„Å®„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ‰ªäÊúà„ÅØ„ÄÅÊñ∞„Åó„ÅÑ‰ΩúÂìÅ„Çí‰∏≠ÂøÉ„Å´ 8‰ΩúÂìÅ„ÄÅÂêàË®à400ÊûöÊèê‰æõ„Åó„Åæ„Åô„ÄÇ</p>
<p>Â∏∏Ë≠ò„ÅÆÁØÑÂõ≤„Åß„ÅîËá™Áî±„Å´„Åä‰Ωø„ÅÑ„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
</div></div>]]>
            </description>
            <link>http://www.ghibli.jp/info/013344/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24564775</guid>
            <pubDate>Wed, 23 Sep 2020 09:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From QMake to CMake: A story on why CMake is pretty nice in 2020]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24564760">thread link</a>) | @Kelteseth
<br/>
September 23, 2020 | https://screen-play.app/blog/qmake_to_cmake/ | <a href="https://web.archive.org/web/*/https://screen-play.app/blog/qmake_to_cmake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://screen-play.app/images/blog/blog_post_1.jpg" alt="post-thumb"></p><div>
              <p>
              ScreenPlay is an Open-Source Live Wallpaper and Widgets app for Windows (and soon Linux &amp; MacOSX) written in modern C++/Qt/QML and is in active development since early 2017 on <a href="https://gitlab.com/kelteseth/ScreenPlay">Gitlab</a>.
            </p>
            </div>
            <h3 id="1-code-sharing-with-qmake-is-a-mess">1. Code sharing with qmake is a mess</h3>
<p>When developing apps that are a bit more complex, the best solution is often try to split them into little more managable pieces. For example if you want to test your app as a separate executable, a subdirs project (a tree of projects) is the only choice here.</p>
<blockquote>
<p>A <a href="https://wiki.qt.io/SUBDIRS_-_handling_dependencies">subdirs projects</a> is just a simple MyApp.pro that only contains a template and subdirs:</p>
</blockquote>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre><code data-lang="perl">  

  TEMPLATE <span>=</span> subdirs
 
  SUBDIRS <span>=</span> <span>\</span>
            src<span>/</span>app <span>\</span>   <span># relative paths</span>
            src<span>/lib \
</span><span>            src/</span>lib2
            </code></pre></td></tr></tbody></table>
</div>
</div>
<p>We now have multiple subprojects needing to share code between each other. To tell the compiler where to find the header and source files from the other project, we need to tell the linker what library to link and where to find the compiled files. The way to go in qmake is to make giant .pri files that is solely used for including  files. This is similar to regular #include &lt;xyz.h&gt; in c++. These MyProjectName.pri are now included in other MyProjectName.pro. To fix the relative path problem you have to add the current absolute path to <em>every</em> line:</p>
<h4 id="11-external-dependencies">1.1 External dependencies</h4>
<p>Working with external dependencies on multiple operating system mostly consists of copy pasting chunks of plattform specific paths into your .pro file. This is really a tedious work because every OS handles the paths a bit differently. E.g. we do not have a separate subfolder for debug/release on linux.</p>
<h4 id="12-compiling-performance-killer-config--ordered">1.2 Compiling performance killer ‚ÄúCONFIG += ordered‚Äù</h4>
<p>Another big problem with qmake is the seemingly random compiler races. When you have many subprojects that are libraries for other subprojects, it would randomly fail because library libA depends on library libB and libC. But libC was not yet build at the time. Most of the time a simple second recompile would fix this. But this clearly shows some serious flaws. This problem never really was fixed with libA.depends = libB. Maybe (pretty sure) I made some mistakes, but  my colleagues and I never solved this issue. The only way to make sure that the build order is fixed, was to set ‚ÄúCONFIG += ordered‚Äù which kills all build parallelism.</p>
<h3 id="2-why-qbs-lost-against-cmake">2. Why QBS lost against CMake</h3>
<p>It was a real shocker when the <a href="https://www.qt.io/blog/2018/10/29/deprecation-of-qbs#commento">QtCompany announced to no longer activly support QBS</a>. I was even one of the people who pushed to make a second community vote. QBS syntax looks nice and familiar to everyone who ever coded QML. CMake does not. After working with CMake for some months now,</p>
<blockquote>
<p>I can confidently say it was the right decision to use CMake instead of QBS as the default build system from Qt6 and forward.</p>
</blockquote>
<p>CMake (with has mostly syntax flaws) works solid. QBS problems are more political than technical:</p>
<p>This is one of the main no go for many programmers that dislike Qt for its size (both in lines of code and library size). Also, many people hate MOC. This is the pre compiler that compiles your Qt C++ into regular C++. This is for writing nice code like emit mySignal();</p>
<h4 id="22-yet-another-build-system">2.2 Yet another build system</h4>
<p>We already have build2, CMake, meson, scons that have many projects using outside of the Qt eco system.</p>
<h4 id="23-no-support-for-ides">2.3 No support for IDEs</h4>
<p>As far as I know QtCreator is the only IDE that ever supported QBS.</p>
<h4 id="24-vcpkg--cmake--">2.4 vcpkg + CMake = ‚ù§Ô∏è</h4>
<p>Remember my rant about external dependencies from paragraph 1.1? Well for me vcpkg is the holy grail for every C++ developer. Install dependencies with one command!</p>
<pre><code><blockquote><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/vcpkg?src=hash&amp;ref_src=twsrc%5Etfw">#vcpkg</a> is the single best thing that happened to c++.</p>‚Äî Elias Steurer (@Kelteseth) <a href="https://twitter.com/Kelteseth/status/1270348439214264321?ref_src=twsrc%5Etfw">June 9, 2020</a></blockquote>


</code></pre>
<h3 id="3-cmake-is-ugly-kinda">3. CMake is ugly, kinda</h3>
<p>CMake is really ugly if you click on the first 10 google results. This is because <em>google shows you old CMake stackoverflow answers from 2008</em> and often redirects you to the old documentation from 2.8. CMake syntax can be quite nice, because most of the time you only these commands:</p>
<h5 id="screenplay-cmakeliststxthttpsgitlabcomkeltesethscreenplay-blobmasterscreenplaycmakeliststxt"><a href="https://gitlab.com/kelteseth/ScreenPlay/-/blob/master/ScreenPlay/CMakeLists.txt">ScreenPlay CMakeLists.txt</a></h5>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span><span>73
</span><span>74
</span><span>75
</span><span>76
</span><span>77
</span><span>78
</span><span>79
</span><span>80
</span><span>81
</span><span>82
</span><span>83
</span><span>84
</span></code></pre></td>
<td>
<pre><code data-lang="CMake"><span># Set the minimum requirement
</span><span></span>cmake_minimum_required(<span>VERSION</span> <span>3.16.0</span>)<span>
</span><span>
</span><span></span><span># Set the Project name. This is later used for the executable name and the 
</span><span># very useful ${PROJECT_NAME}
</span><span></span>project(<span>ScreenPlay</span>)<span>
</span><span>
</span><span></span><span># Some Qt settings for resources and MOC
</span><span></span>set(<span>CMAKE_AUTORCC</span> <span>ON</span>)<span>
</span><span></span>set(<span>CMAKE_AUTOMOC</span> <span>ON</span>)<span>
</span><span>
</span><span></span><span># This is actually only synatx sugar. This only creates the variable src
</span><span># with these strings as array elements. This is used later at add_executable
</span><span></span>set(<span>src</span> <span>main.cpp</span>
        <span>app.cpp</span>
        <span># Lets skip some content here
</span><span></span>        <span>src/util.cpp</span>
        <span>src/create.cpp</span>)<span>
</span><span>
</span><span></span>set(<span>headers</span> <span>app.h</span>
        <span>src/globalvariables.h</span>
        <span># Lets skip some content here
</span><span></span>        <span>src/util.h</span>
        <span>src/create.h</span>)<span>
</span><span>
</span><span></span><span># Qt macro for big resources like our fonts
</span><span></span>qt5_add_big_resources(<span>resources</span>  <span>resources.qrc</span>)<span>
</span><span>
</span><span></span><span># Tell CMake to compile our qml into C++ in release mode
</span><span># to make it fast!
</span><span></span>if(<span>CMAKE_BUILD_TYPE</span> <span>STREQUAL</span> <span>"Debug"</span>)<span>
</span><span></span>    set(<span>qml</span> <span>qml.qrc</span>)<span>
</span><span></span>else()<span>
</span><span></span>    qtquick_compiler_add_resources(<span>qml</span> <span>qml.qrc</span> )<span>
</span><span></span>endif()<span>
</span><span>
</span><span></span><span># Tell CMake to search for these libraries. Because we set the CMAKE_TOOLCHAIN_FILE earlier
</span><span># we no longer have to manage ugly relative paths by hand!
</span><span></span>find_package(
  <span>Qt5</span>
  <span>COMPONENTS</span> <span>Quick</span>
             <span>QuickCompiler</span>
             <span>Widgets</span>
             <span>Gui</span>
             <span>WebEngine</span>
  <span>REQUIRED</span>)<span>
</span><span>
</span><span></span><span># External vcpkg libraries
</span><span></span>find_package(<span>ZLIB</span> <span>REQUIRED</span>)<span>
</span><span></span>find_package(<span>OpenSSL</span> <span>REQUIRED</span>)<span>
</span><span></span>find_package(<span>libzippp</span> <span>CONFIG</span> <span>REQUIRED</span>)<span>
</span><span></span>find_package(<span>nlohmann_json</span> <span>CONFIG</span> <span>REQUIRED</span>)<span>
</span><span>
</span><span></span><span># CMake has two main commands: 
</span><span># add_executable for creating an executalbe
</span><span># add_library for creating a library
</span><span></span>add_executable(<span>${</span>PROJECT_NAME<span>}</span> <span>${</span>src<span>}</span> <span>${</span>headers<span>}</span> <span>${</span>resources<span>}</span> <span>${</span>qml<span>}</span>)<span>
</span><span>
</span><span></span><span># Custom property to disable console window on Windows
</span><span># https://stackoverflow.com/questions/8249028/how-do-i-keep-my-qt-c-program-from-opening-a-console-in-windows
</span><span></span>set_property(<span>TARGET</span> <span>${</span>PROJECT_NAME<span>}</span> <span>PROPERTY</span> <span>WIN32_EXECUTABLE</span> <span>true</span>)<span>
</span><span>
</span><span></span><span># Tell the linker to search for these dependencies. Most of the time vcpkg will
</span><span># tell you the name of the libary. If not look at the vcpkg/installed path for
</span><span># the name of the dll/lib/so/dynlib
</span><span># If you need to have dependencies inside your project structure you can simply
</span><span># add the project(MyLib) to the target_link_libraries. No inlude paths, 
</span><span># no additional stuff, it simply works!
</span><span></span>target_link_libraries(<span>${</span>PROJECT_NAME<span>}</span>
    <span>PRIVATE</span>
    <span>Qt5::Quick</span>
    <span>Qt5::Gui</span>
    <span>Qt5::Widgets</span>
    <span>Qt5::Core</span>
    <span>Qt5::WebEngine</span>
    <span>nlohmann_json::nlohmann_json</span>
    <span>libzippp::libzippp</span>
    <span>ScreenPlaySDK</span>
    <span>QTBreakpadplugin</span>)<span>
</span><span>
</span><span></span><span># Tell CMake to copy this file to your build dir if changed
</span><span># ${CMAKE_BINARY_DIR} is your build directory!
</span><span></span>file(<span>MAKE_DIRECTORY</span> <span>${</span>CMAKE_BINARY_DIR<span>}</span><span>/bin/assets/fonts</span>)<span>
</span><span></span>configure_file(<span>assets/fonts/NotoSansCJKkr-Regular.otf</span> <span>${</span>CMAKE_BINARY_DIR<span>}</span><span>/bin/assets/fonts</span> <span>COPYONLY</span>)</code></pre></td></tr></tbody></table>
</div>
</div>
<h3 id="4-ninja-makes-cmake-fast">4. Ninja makes CMake fast</h3>
<p>CMake only generates instructions for your build system of choice. This can be a big advantage when working with people that prefer VisualStudio over QtCreator. When using CMake one can (should) choose <a href="https://ninja-build.org/">Ninja</a> as the default build system. Compiling projects with CMake+Ninja is fun. Ninja and CMake comes shipped with the Qt Maintenance in the tools category. Iterative changes are incredible fast and clean to look at with the [13/424] progress.</p>
<blockquote>
<p>It‚Äôs so fast that working with Godots scons makes me activly want to convert Godot to CMake.</p>
</blockquote>
<h3 id="5-vcpkg-is-where-cmake-really-shines">5. vcpkg is where CMake really shines!</h3>
<p>Managing dependencys in C++ is tedious, many projects even ship dlls with their git repository. This is bad because it blows up the git repo size (we ignore git-lfs for now). A drawback is that vcpkg only supports one global version of packages (you manually install different versions of vcpkg, but this is more like a hack and only seldom needed). This is a feature on their <a href="https://devblogs.microsoft.com/cppblog/vcpkg-2020-04-update-and-product-roadmap/">roadmap</a>.
</p><div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="shell">  
    vcpkg install crashpad</code></pre></td></tr></tbody></table>
</div>
</div><p>
In ScreenPlay we simply have an <a href="">install_dependencies_windows.bat</a> or <a href="https://gitlab.com/kelteseth/ScreenPlay/-/blob/master/install_dependencies_linux_mac.sh">install_dependencies_linux_mac.sh</a> to clone vcpkg, build it and install all our dependencies.
When working with QtCreator, we must set the CMAKE_TOOLCHAIN_FILE to the relative path of vcpkg. Also we must tell vcpkg on what OS and arch we use.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="shell">  
    <span># QtCreator setup. Extras -&gt; Tools -&gt; Kits -&gt;  -&gt; CMake Configuration -&gt; Append this:</span>
    CMAKE_TOOLCHAIN_FILE:STRING<span>=</span>%<span>{</span>CurrentProject:Path<span>}</span>/Common/vcpkg/scripts/buildsystems/vcpkg.CMake
    VCPKG_TARGET_TRIPLET:STRING<span>=</span>x64-windows
    </code></pre></td></tr></tbody></table>
</div>
</div>
<p>Need to install another library? Simply call <em>vcpkg install myLibToInstall</em> again and you are good to go!</p>
<h3 id="6-conclusion">6. Conclusion</h3>
<p>Going with the flow has its advantages but comes at a cost. Build systems, like qbs, with a big potential get thrown under the bus. What to use is up to the developer and thats why my projects will use CMake from now on.</p>
<p>The next blog post will be about how to set-up Qt projects beyond ‚ÄúHello World‚Äù. Stay tuned!</p>
<p>You can discuss this blog post <a href="https://forum.screen-play.app/topic/24/blog-porting-screenplay-from-qmake-to-cmake-a-story-on-why-cmake-is-actually-pretty-nice-in-2020">here post in our forum.</a></p>

          </div></div>]]>
            </description>
            <link>https://screen-play.app/blog/qmake_to_cmake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24564760</guid>
            <pubDate>Wed, 23 Sep 2020 09:09:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frugality Is Non-Linear (2019)]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 212 (<a href="https://news.ycombinator.com/item?id=24564669">thread link</a>) | @luu
<br/>
September 23, 2020 | https://scattered-thoughts.net/writing/frugality-is-non-linear/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/frugality-is-non-linear/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Most people have a mental model of budgeting which is roughly linear. If you spend half as much money, your money will last twice as long. As you approach zero spending, your runway goes up to infinity.</p>
<p>In this model, the space of options looks like this:</p>
<div>
<p>[I am an interactive graph made of javascript!]</p>
</div>
<p><label for="growth">Return on investment =&nbsp;</label>
  
</p>
<p>This model is wrong.</p>
<p>It's wrong because your savings grow over time. If you change the return rate above to 5%, you can see that someone who has 500k in savings and spends 75k per year has a runway of 7 years. At 50k per year that extends to 13 years. But if they can cut their spending to 25k per year they have a runway of 62 years!</p>
<p>Effectively, including growth in the model moves the asymptote to the right - your runway goes up to infinity as your spending approaches some percentage of your total savings, rather than as it approaches zero.</p>
<p>So halving your expenses can much more than double your runway. Or to put it another way - halving your expenses can much more than halve the number of years of your life you need to spend working.</p>
<hr>
<p>I picked the examples above with a particular motive in mind. According to <a href="https://danluu.com/startup-tradeoffs/">Dan Luu's conservative estimates</a> a fresh grad at a big tech company can safely earn ~$500k post-tax in 5 years. The US median income post-tax is ~$25k, and investing in an index fund has historically earned ~5% average returns in the long run. So as a tech worker, if you can manage to live as 'frugally' as the average American, you can <a href="https://networthify.com/calculator/earlyretirement?income=120000&amp;initialBalance=0&amp;expenses=25000&amp;annualPct=5&amp;withdrawalRate=4">comfortably retire</a> before 30.</p>
<p>In the tech industry we have some very loud voices arguing that if you desire autonomy or leverage, the best path forwards is to start a VC-backed startup. But reducing spending and saving towards early retirement has some compelling advantages:</p>
<ul>
<li>It's much more reliable - most startups fail, but most people who work at a large tech company make sufficient money to be able to retire early.</li>
<li>Financial independence is a huge safety net - reducing stress and lowering the risk of later projects. If you still want to run a startup, doing it from a position of infinite personal runway will be a lot less stressful.</li>
<li>By separating the means of earning money from the freedom you are pursuing, it enables pursuing goals in that under-served intersection of valuable but not profitable. Whether that's supporting free software, producing art or home-schooling your children, trying to fit such activities into a profitable enterprise inevitably produces uncomfortable compromises which can be avoided by removing the need to earn money.</li>
</ul>
<p>The last point is particularly compelling if you have strong ethical/political/economic beliefs that would benefit from the leverage of financial independence.</p>
<hr>
<h3 id="faq">FAQ</h3>
<p><strong>What about inflation?</strong> Inflation is essentially negative growth, so you can subtract it from the return rate and then keep the rest of the calculations in today-dollars. 5% seems to be a reasonable estimate of average inflation-adjusted returns on stocks based on recent decades, but see below for better models.</p>
<p><strong>What about volatility?</strong> I used a fixed average return rate above, which doesn't tell you odds of running out of money early due to a string of bad years. <a href="https://retirementplans.vanguard.com/VGApp/pe/pubeducation/calculators/RetirementNestEggCalc.jsf">But simulations based on historical data</a> produce similar results to those above, and <a href="https://www.kitces.com/wp-content/uploads/2014/11/Kitces-Report-March-2012-20-Years-Of-Safe-Withdrawal-Rate-Research.pdf">retirement planning literature</a> tends to put the asymptote at around 4-5% which is consistent with the numbers above. You should definitely use a more detailed model than this if you are seriously considering this path, but I think the simple model accurately conveys the underlying intuition - that the returns to reducing spending are non-linear.</p>
<p><strong>What about crashes?</strong> The simulation linked above uses data that covers existing crashes, including the Great Depression. But in the event that they are overly optimistic, I think there is a strong argument that having large savings and cheap habits are as useful for weathering a crash as having a filled-in employment history. Especially if you used the additional free time to build useful non-tech skills or strong communities.</p>
<p><strong>What about other countries?</strong> Dan Luu's article suggests that similar salaries are available in many major hubs. I've built a reasonably detailed model for my own situation in the UK and arrived at similar numbers. (Salaries are lower, unless you can land a remote job, but free healthcare and lower cost of living make up a lot of the difference.) It's worth at least running the numbers for your own country, just so you know what your options are.</p>
<p><strong>Hasn't the <a href="https://en.wikipedia.org/wiki/FIRE_movement">FIRE community</a> already said all of this?</strong> Yes, but I very rarely see it discussed in tech circles, so it seems worth repeating. Also I haven't seen the calculation in terms of runway before, and the graph above improved my intuition on the subject.</p>



</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/frugality-is-non-linear/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24564669</guid>
            <pubDate>Wed, 23 Sep 2020 08:57:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Drive on Sand Without Getting Stuck (2017)]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24564542">thread link</a>) | @luu
<br/>
September 23, 2020 | https://www.offroaddiscovery.com/2017/10/16/taking-a-4x4-trip-down-the-beach | <a href="https://web.archive.org/web/*/https://www.offroaddiscovery.com/2017/10/16/taking-a-4x4-trip-down-the-beach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Do you have the pleasure to live or travel in a sandy location? Tropical beach, rolling sand hills or maybe it‚Äôs the desert for work. No matter where your sandy destination is be alert of the challenges of driving in sand. Too many people join the ‚Äòdigging club‚Äô and it‚Äôs one club you‚Äôd rather avoid.</p><p>Please note this is general Sand not Desert Driving, although many of the basic principles are the same, Desert Driving is a ‚Äúlong‚Äù discussion in itself.</p><p><img src="https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/58e720ad6dba09dcc4206c19856bec9f/SandOffRoading_640.JPG" width="640" height="532" srcset="https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/58e720ad6dba09dcc4206c19856bec9f/SandOffRoading_360.JPG 360w, https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/58e720ad6dba09dcc4206c19856bec9f/SandOffRoading_640.JPG 640w" sizes="(min-width: 768px) 720px, 100vw" alt="How to Drive Through Sand without Getting Stuck"></p><p><em>This content was developed by and owned by Paul Sinkinson, Xplorability owner. Paul is a 4wd Defensive Driver Training Consultant/Trainer and Programme Developer.</em></p><h2>Basic Driving in Sand Tips</h2><ul><li>A variety of conditions may co-exist - Learn to recognise surface conditions</li><li>Beware of ‚Äúwet sand‚Äù. These areas can seem bottomless and usually require assistance from other vehicles with a winch to extricate</li><li>If unsure carry out reconnaissance on foot</li><li>Engage high ratio 4wd for long beach runs on hard sand. Engage low ratio 4wd for soft sand and dunes to avoid overheating transmission</li><li>Avoid sharp turns and wheel spin</li><li>Utilise speed for controlled momentum</li><li>Keep gear changes to a minimum ‚Äì Normally choose a gear and stay in it to avoid baulking</li><li>Low tyre pressures are highly recommended</li><li>If it becomes necessary to stop on soft sand, try to choose an area that allows a down hill restart</li><li>To get re-started on flat, soft, dry sand. Reverse 1-2 metres and form hard sand ramps so as to get a good starting speed before hitting soft sand again</li><li>To ascend a sand hill, utilise controlled momentum. If you fail to ascend, back down the same wheel tracks far enough to allow a faster approach up the same wheel tracks</li><li>To descend keep vertical to the sand hill/descent and avoid brakes, accelerate gently if necessary to aid descent.</li></ul><h2>There is Nothing Quite Like Driving on Sand</h2><p>Most off-roaders may never come across sand unless they happen to make it to coastal regions and hit the beach. However, if they do start to undertake longer distance adventure treks, they may at some time
make it to the more arid regions and the odd few may even make it to the ‚ÄúReal‚Äù Desert. Perhaps like myself, when I first flew in on a light aircraft to a desert strip in the deep Sahara to run driver training, their answer to the question from colleagues as to what they thought of the place will be the same as mine. <strong>‚ÄúI think I‚Äôm going to need a bigger bucket and spade!‚Äù</strong></p><h3>Beach Sand</h3><p>Beach Sand is totally different to the sand you find in the desert. Much of it tends to be much coarser in grain texture and therefore can at time be more forgiving that the desert sand that runs like water. Of course, being close to the sea it can also be damp, wet, extremely wet or waterlogged. It can also be dry, gravelly and have
the odd rock thrown in for good measure. Away from the water‚Äôs edge you will often find dunes, some with vegetation, some without and in certain areas around the World you will find larger dunes, similar to the ones you find in the desert. While those dunes look similar and do have some of the same features they are very different. We‚Äôll come to that later but only touch on them briefly as ‚Äúreal‚Äù desert driving needs lots of space for discussion on techniques.</p><p>So, we‚Äôve hit the beach, some great scenery, lots of fresh air, all your mates are with you looking at those long, sometimes wide strips of sand with the waves lapping at the edge. This is usually where common sense and safety goes out of the window! Competitive, idiotic behavior, spurred on usually by male testosterone reacting with the ozone fresh sea breeze leads to frantic and erratic driving at high speed along the sand and often in and out of the water. <strong>Beaches are great BUT they are not playgrounds with your truck. In a 4wd Vehicle
they can be one of the most dangerous places you will ever drive and can be like playing Russian Roulette, with a Round in every chamber.</strong> The normal <a href="https://www.offroaddiscovery.com/off-road-driver-training/hazard-identification-safety-environment">Hazard Identifications</a> when off-roading apply, so read the earlier article on this on the site.</p><h3>Three Common Sense Driving Tips for Beaches</h3><ol><li><p><strong>Keep out of the Sea</strong>: Salt Water is not good for 4wd vehicle chassis and body components. Driving in the Sea as many will do despite this article, will throw salt water everywhere and it will get into the chassis, it will in time cause rust erosion and pressure washing after may nod get rid of it. Vehicle electrics
and water do not go well together at any time. Hot radiator fins are thin, if salt water passes through the fins the heat dries it and the salt deposit remains to eat its way into the core. I‚Äôve seen many a vehicle being taken home on a recovery truck from the beach due to water getting into badly position ECU and ignition units in the engine bay. It may look fantastic, cause lots of spray and a splash ‚Äì BUT KEEP OUT OF THE SALT WATER!</p></li><li><p>Ok, hopefully you‚Äôve got the message on point one and you‚Äôre just going to drive on the beach sand. It looks nice and flat; it may even look fairly dry. However, it‚Äôs a beach, normally the tide comes in and out twice a day that means, although it may look dry on the surface because of all that ‚ÄúSunshine‚Äù in some Countries, it could well be soggy under the surface. You can <strong>drive it in either high or low range but KEEP THE SPEED DOWN</strong>.</p></li><li><p>As mentioned, it can be soggy below the surface or it can also be dry with patches of deeper sand. <strong>Keep driving in straight lines on it and NEVER turn sharply</strong> as if a front wheel happens to dig in the softer areas it will immediately act as a brake, weight will transfer on to it and you‚Äôll become a statistic in the rollover records. These beach rollovers happen every day around the globe. IF you are going to turn, firstly slow down
and secondly turn in a wide arc. It doesn‚Äôt take much for a loaded 4wd, especially if you have equipment high up on a roof rack, for the dynamics to transfer weight. Even experienced and regular beach drivers forget this simple message. I‚Äôve been on beaches around the world and viewed many who thought they were ‚Äúexperts,‚Äù being scraped up by the medics or recovery vehicles. Don‚Äôt join their gang!</p></li></ol><p><strong>NOTE: In an effort to try and keep you SAFE watch some videos</strong>
There are plenty of good and instructional videos covering
Sand on the Internet - (YouTube etc.) One of the best is <strong>‚ÄúGuide to Off-Roading ‚Äì Driving on Sand ‚Äì
by Land Rover Experience</strong>. There are also lots of videos that highlight the art of BAD
Driving on both Beach and Desert Sand. They cover the accidents! Watch those ones several times and then look around you at the kids and the rest of your family and consider the implications should you drive in Sand (or anywhere else for that matter) like some of the idiots involved in these incidents.
Keep everyone‚Äôs Seat Belts on ‚Äì Don‚Äôt let the kids hang out of the Sunroof or Side Windows. If you see some of the more serious rollover accidents you will understand why.</p><p><iframe width="640" height="360" src="https://www.youtube.com/embed/0-1__frSTno" frameborder="0" allowfullscreen=""></iframe></p><h3>Driving on Sand</h3><p>It is reasonable to assume that you can drive on firm sand if you take notice of the previous three tips but there will come a time when the surface will not be firm and supple sand is a different thing altogether.
Once you start driving in the softer sand, traction can be at a premium, any increase in speed may be and usually is, difficult if not impossible, so to make headway you need to maintain momentum.
Should you lose that, it is unlikely you will regain it and you will likely become bogged down.</p><p><em>Once you lose traction in sand and have wheel-spin, abort immediately or you
will just dig yourself in further. Engage reverse gear and ‚ÄúGently‚Äù try to drive out
along your tracks.</em></p><p><img src="https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/f56ccdf56a9223c94760e725fd691e55/4x4inSand_640.png" width="640" height="536" srcset="https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/f56ccdf56a9223c94760e725fd691e55/4x4inSand_360.png 360w, https://storage.googleapis.com/images.blogserve.co/offroaddiscovery/f56ccdf56a9223c94760e725fd691e55/4x4inSand_640.png 640w" sizes="(min-width: 768px) 720px, 100vw" alt="Tips for Driving on Sand and not getting Stuck"></p><h3>Tyre Pressures</h3><p>Assuming you are going to be on the beach or coastal sand for any length of time rather than just sticking your nose in for a few minutes to take in the sea air, it is advisable to reduce your tyre pressures.
The reason for this is that it provides what is termed as a better footprint reducing the ground pressure and allowing better ‚Äúflotation‚Äù which in turn improves traction. (Think of the ‚ÄúSnow Shoe‚Äù effect on
Snow)</p><p>Most people think that reducing the tyre pressure makes the contact with the ground wider because they see the tyre ‚Äúbulge‚Äù out and become fatter. In reality, this is not the case, the tyre footprint actually
becomes longer although there may be a slight increase in width. If you have ever seen a vehicle with a punctured tyre you will remember it was flat at the bottom along the ground for maybe 18 to
20 inches whereas when it was inflated, only 8 inches were in contact with the ground. When it comes to low ground pressure, ‚ÄúSize Matters.‚Äù With lower ground pressure there is less strain on the
vehicles steering components as well as the power unit and transmission as they don‚Äôt have to work as hard.
Before you consider lowering the pressures you must of course ensure that you have a suitable pump to re-inflate them when you come back to the normal roads and tracks. Assuming you have the
pump you can now reduce the pressure but to what level? Often you have the pump but no pressure gauge. Oops! I forgot to pack it in the truck. Now what do I do?</p><p><strong>For general sand driving a tyre pressure of circa 15 to 16 psi is the norm</strong>. If you don‚Äôt have a gauge, you can use the old explorer‚Äôs trick of using a stick or a small rock placed an inch away from the edge of
the tyre sidewall. On the average 4wd tyre of say 235x85x16, if you now let the air out of the tyre valve until the sidewall touches the stick on each tyre, you should have all the tyres down to the same level
and roughly with a suitable amount of deflation. You can use the same method the other way around when you re-inflate so you have them back to the same level for normal use until you can check and adjust with a gauge.</p><p>You must remember, now that you have the lower pressure and perhaps with the bulging side-walls, that the tyres are more susceptible to wear or damage. You need to balance the risk when lowering the pressure between the increased traction it delivers and the possible tyre damage and wear. The correct balance will certainly make the ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.offroaddiscovery.com/2017/10/16/taking-a-4x4-trip-down-the-beach">https://www.offroaddiscovery.com/2017/10/16/taking-a-4x4-trip-down-the-beach</a></em></p>]]>
            </description>
            <link>https://www.offroaddiscovery.com/2017/10/16/taking-a-4x4-trip-down-the-beach</link>
            <guid isPermaLink="false">hacker-news-small-sites-24564542</guid>
            <pubDate>Wed, 23 Sep 2020 08:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firefox usage is down despite Mozilla's top exec pay going up]]>
            </title>
            <description>
<![CDATA[
Score 1593 | Comments 1258 (<a href="https://news.ycombinator.com/item?id=24563698">thread link</a>) | @todsacerdoti
<br/>
September 22, 2020 | http://calpaterson.com/mozilla.html | <a href="https://web.archive.org/web/*/http://calpaterson.com/mozilla.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
            
            <p>September 2020</p>
            <p id="article-description">Mozilla is in an absolute state: high
            overheads, falling usage of Firefox, questionable sources of revenue and
            now making big cuts to engineering as their income falls.</p>
            <hr>
            <figure>
                <img src="http://calpaterson.com/assets/mozilla-boss-pay.svg" alt="a graph showing that executive pay has grown fast while Firefox's market share has fallen">
                <figcaption>
                    Mozilla's top exec pay has gone up hugely even as usage has
                    crashed.
                </figcaption>
            </figure>
            <p>Mozilla recently announced that they would be dismissing 250 people.
            That's a quarter of their workforce so there are some deep cuts to their
            work too. The victims include: the MDN docs (those are the web standards
            docs everyone likes better than w3schools), the Rust compiler and even some
            cuts to Firefox development. Like most people I want to see Mozilla do well
            but those three projects comprise pretty much what I think of as the whole
            point of Mozilla, so this news is a big let down.</p>
            <p>The stated reason for the cuts is falling income. Mozilla largely relies
            on "royalties" for funding. In return for payment, Mozilla allows big
            technology companies to choose the default search engine in Firefox - the
            technology companies are ultimately paying to increase the number of
            searches Firefox users make with them. Mozilla haven't been particularly
            transparent about why these royalties are being reduced, except to blame
            the coronavirus.</p>
            <p>I'm sure the coronavirus is not a great help but I suspect the bigger
            problem is that Firefox's market share is now a tiny fraction of its
            previous size and so the royalties will be smaller too - fewer users, so
            fewer searches and therefore less money for Mozilla.</p>
            <p>The real problem is not the royalty cuts, though. Mozilla has already
            received more than enough money to set themselves up for financial
            independence. Mozilla received up to half a billion dollars a year (each
            year!) for many years. The <em>real problem</em> is that Mozilla didn't use
            that money to achieve financial independence and instead just spent it each
            year, doing the organisational equivalent of living hand-to-mouth.</p>
            <p>Despite their slightly contrived legal structure as a non-profit that
            owns a for-profit, Mozilla are an NGO just like any other. In this article
            I want to apply the traditional measures that are applied to other NGOs to
            Mozilla in order to show what's wrong.</p>
            <p>These three measures are: overheads, ethics and results.</p>
            <h2>Overheads</h2>
            <p>One of the most popular and most intuitive ways to evaluate an NGO is to
            judge how much of their spending is on their programme of works (or
            "mission") and how much is on other things, like administration and
            fundraising. If you give money to a charity for feeding people in the third
            world you hope that most of the money you give them goes on food - and not,
            for example, on company cars for head office staff.</p>
            <p>Mozilla looks bad when considered in this light. Fully 30% of all
            expenditure goes on administration. Charity Navigator, an organisation that
            measures NGO effectiveness, would give them <a href="https://www.charitynavigator.org/index.cfm?bay=content.view&amp;cpid=48#PerformanceMetricTwo">
            zero out of ten</a> on the relevant metric. For context, to achieve 5/10 on
            that measure Mozilla admin would need to be under 25% of spending and, for
            10/10, under 15%.</p>
            <p>Senior executives have also done very well for themselves. Mitchell
            Baker, Mozilla's top executive, was paid $2.4m in 2018, a sum I personally
            think of as instant inter-generational wealth. Payments to Baker have more
            than doubled in the last five years.</p>
            <p>As far as I can find, there is no UK-based NGO whose top executive makes
            more than ¬£1m ($1.3m) a year. The UK certainly has its fair share of big
            international NGOs - many much bigger and more significant than
            Mozilla.</p>
            <p>I'm aware that <a href="https://concepts.effectivealtruism.org/concepts/relationship-between-overheads-and-effectiveness/">
            some people dislike overheads as a measure</a> and argue that it's possible
            for administration spending to increase effectiveness. I think it's hard to
            argue that Mozilla's overheads are correlated with any improvement in
            effectiveness.</p>
            <h2>Ethics</h2>
            <p>Mozilla now thinks of itself less as a custodian of the old Netscape
            suite and more as a 'privacy NGO'. One slogan inside Mozilla is: "Beyond
            the Browser".</p>
            <p>Regardless of how they view themselves, most of their income comes from
            helping to direct traffic to Google by making that search engine the
            default in Firefox. Google make money off that traffic via a big targeted
            advertising system that tracks people across the web and largely without
            their consent. Indeed, one of the reasons this income is falling is because
            as Firefox's usage falls less traffic is being directed Google's way and so
            Google will pay less.</p>
            <p>There is, as yet, no outbreak of agreement among the moral philosophers
            as to a universal code of ethics. However I think most people would
            recognise hypocrisy in Mozilla's relationship with Google. Beyond the
            ethical problems, the relationship certainly seems to create conflicts of
            interest. Anyone would think that a privacy NGO would build anti-tracking
            countermeasures into their browser right from the start. In fact, this was
            only added relatively recently (<a href="https://blog.mozilla.org/blog/2019/06/04/firefox-now-available-with-enhanced-tracking-protection-by-default/">in
            2019</a>), after both Apple (<a href="https://webkit.org/blog/7675/intelligent-tracking-prevention/">in
            2017</a>) and Brave (since release) paved the way. It certainly seems like
            Mozilla's status as a Google vassal has played a role in the absence of
            anti-tracking features in Firefox for so long.</p>
            <p>Another ethical issue is Mozilla's big new initiative to <a href="https://vpn.mozilla.org/">move into VPNs</a>. This doesn't make a lot of
            sense from a privacy point of view. Broadly speaking: VPNs are not a useful
            privacy tool for people browsing the web. A VPN lets you access the
            internet through a proxy - so your requests superficially appear to come
            from somewhere other than they really do. This does nothing to address the
            main privacy problem for web users: that they are being passively tracked
            and de-anonymised on a massive scale by the baddies at Google and
            elsewhere. This tracking happens regardless of IP address.</p>
            <p>When I tested Firefox through <a href="https://vpn.mozilla.org/">Mozilla
            VPN</a> (a rebrand of <a href="https://mullvad.net/">Mullvad VPN</a>) I
            found that I could be de-anonymised by browser fingerprinting - already a
            fairly widespread technique by which various elements of your browser are
            examined to create a "fingerprint" which can then be used to re-identify
            you later. Firefox does not include as many countermeasures against this as
            some other browsers (<strong>this is a correction</strong> - I previously
            said Firefox contained none but it's been pointed out to me that <a href="https://blog.mozilla.org/security/2020/01/07/firefox-72-fingerprinting/">since
            earlier this year</a> it does block some kinds of fingerprinting).</p>
            <figure>
                <img src="http://calpaterson.com/assets/panopticlick-firefox.png" alt="firefox's results on panopticlick - my browser has a unique fingerprint">
                <figcaption>
                    Even when using Mozilla's "secure and private" VPN, Firefox is
                    trackable by browser fingerprinting, as demonstrated by the
                    <a href="https://panopticlick.eff.org/">EFF's Panopticlick
                    tool</a>. Other browsers use randomised fingerprints as a
                    countermeasure against this tracking.
                </figcaption>
            </figure>
            <p>Another worry is that many of these privacy focused VPN services have a
            nasty habit of turning out to keep copious logs on user behaviour. A few
            months ago several "no log" VPN services inadvertently released terabytes
            of private user data that they had promised not to collect <a href="https://www.vpnmentor.com/blog/report-free-vpns-leak/">in a massive
            breach</a>. VPN services are in a great position to eavesdrop - and even if
            they promise not to, your only option is to take them at their word.</p>
            <h2>Results</h2>
            <p>I've discussed the Mozilla chair's impressive pay: $2.4m/year. Surely
            such impressive pay is justified by the equally impressive results Mozilla
            has achieved? Sadly on almost every measure of results both quantitative
            and qualitative, Mozilla is a dog.</p>
            <p>Firefox is now so niche it is in danger of garnering a cult following:
            it has just 4% market share, down from 30% a decade ago. Mobile browsing
            numbers are bleak: Firefox barely exists on phones, with a market share of
            less than half a percent. This is baffling given that mobile Firefox has a
            rare feature for a mobile browser: it's able to install extensions and so
            can block ads.</p>
            <p>Yet despite the problems within their core business, Mozilla, instead of
            retrenching, has diversified rapidly. In recent years Mozilla has
            created:</p>
            <ul>
                <li>a mobile app for making websites</li>
                <li>a federated identity system</li>
                <li>a large file transfer service</li>
                <li>a password manager</li>
                <li>an internet-of-things framework/standard</li>
                <li>an email relay service</li>
                <li>a completely new phone operating system</li>
                <li>an AI division (but of course)</li>
                <li>and spent $25 million buying the reading list management startup,
                Pocket</li>
            </ul>
            <p>Many of the above are now abandoned.</p>
            <p>Sadly <a href="https://www.mozilla.org/en-US/foundation/annualreport/2018/">Mozilla's
            annual report</a> doesn't break down expenses on a per-project basis so
            it's impossible to know how much of the spending that <em>is</em> on
            Mozilla's programme is being spent on Firefox and how ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://calpaterson.com/mozilla.html">http://calpaterson.com/mozilla.html</a></em></p>]]>
            </description>
            <link>http://calpaterson.com/mozilla.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24563698</guid>
            <pubDate>Wed, 23 Sep 2020 06:38:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at /e/OS on the FairPhone 3 ‚Äì a FOSS OS for phones [video]]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24563576">thread link</a>) | @indidea
<br/>
September 22, 2020 | https://share.tube/videos/watch/ef3e5eec-27aa-45c8-b87b-64a57fc6e176 | <a href="https://web.archive.org/web/*/https://share.tube/videos/watch/ef3e5eec-27aa-45c8-b87b-64a57fc6e176">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://share.tube/videos/watch/ef3e5eec-27aa-45c8-b87b-64a57fc6e176</link>
            <guid isPermaLink="false">hacker-news-small-sites-24563576</guid>
            <pubDate>Wed, 23 Sep 2020 06:17:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Gzip Compression with Python]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24563372">thread link</a>) | @brenns10
<br/>
September 22, 2020 | https://brennan.io/2020/09/22/compression-curves/ | <a href="https://web.archive.org/web/*/https://brennan.io/2020/09/22/compression-curves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan ‚Ä¢ 22 September 2020</em></p><p>Not that long ago, I found myself wanting to understand gzip. I didn‚Äôt necessarily want to learn to implement the algorithm, but rather I just wanted to understand how it was performing on a particular file. Even more specifically, I wanted to understand which parts of a file compressed well, and which ones did not.</p>

<p>There may be readily available tools for visualizing this, but I didn‚Äôt find anything. Since I know gzip is implemented in the Python standard libraries, and I‚Äôm familiar with Python plotting libraries, I thought I would try to make my own visualization. This blog post (which is in fact just a Jupyter notebook) is the result.</p>

<h2 id="what-to-measure">What to measure</h2>

<p>Sometimes the hardest part of a data analysis problem is just figuring out what you want to measure. The data is all there, and you have a computer at your disposal, so the possibilities are endless. Knowing <em>what</em> to compute is tricky. In my case, I want to understand which parts of a file compress well. So it makes sense that whatever I visualize should include the position in the file along the X axis, and the compressed size along the Y axis. An uncompressed file would simply be a diagonal line. The better the compression, the more this line would stay <em>under</em> the diagonal line of an uncompressed file.</p>

<h2 id="how-to-measure-it">How to measure it?</h2>

<p>Since Python supports gzip in the standard library, let‚Äôs see how we can measure these X and Y coordinates. First, let‚Äôs create a file with some compressed data. My favorite to use in this instance is <a href="http://www.gutenberg.org/ebooks/11">Alice‚Äôs Adventures in Wonderland</a>, downloaded from Project Gutenberg. We‚Äôll compress it on the command line for simplicity.</p>

<p>(Note that code prefixed by ‚Äò!‚Äô is executed via bash - everything else is executed in Python).</p>

<div><div><pre><code>!gzip -k alice.txt
!ls -lh alice*
</code></pre></div></div>

<div><div><pre><code>-rw-r--r-- 1 stephen stephen 171K Sep 22 20:25 alice.txt
-rw-r--r-- 1 stephen stephen  60K Sep 22 20:25 alice.txt.gz
</code></pre></div></div>

<p>gzip does a pretty decent job at compressing this, far better than I could do myself. Now, let‚Äôs use Python to decompress just a little bit of it, and how much of the original file is consumed as we go.</p>

<div><div><pre><code><span>import</span> <span>gzip</span>
<span>compressed</span> <span>=</span> <span>open</span><span>(</span><span>'alice.txt.gz'</span><span>,</span> <span>'rb'</span><span>)</span>
<span>gzip_file</span> <span>=</span> <span>gzip</span><span>.</span><span>GzipFile</span><span>(</span><span>fileobj</span><span>=</span><span>compressed</span><span>)</span>
</code></pre></div></div>

<p>In the above code, we save the open file object as <code>compressed</code> before giving it over to the <code>GzipFile</code>. That way, as we read the decompressed data out of <code>gzip_file</code>, we‚Äôll be able to use the <code>tell()</code> method to see how far we are through the compressed file.</p>

<div><div><pre><code><span>first_100_bytes</span> <span>=</span> <span>gzip_file</span><span>.</span><span>read</span><span>(</span><span>100</span><span>)</span>
<span>first_100_bytes</span>
</code></pre></div></div>

<div><div><pre><code>b'\xef\xbb\xbfThe Project Gutenberg EBook of Alice\xe2\x80\x99s Adventures in Wonderland, by Lewis Carroll\r\n\r\nThis eBook'
</code></pre></div></div>





<p>This feels disappointing. We only read 100 bytes and yet it took 8212 bytes of gzip to give us that data? Well, we have to consider that compression algorithms need to store some tables of data which help decompress the rest of the file, so we should cut gzip some slack. Let‚Äôs do this a few more times.</p>



<div><div><pre><code>b' is for the use of anyone anywhere at no cost and with\r\nalmost no restrictions whatsoever.  You may '
</code></pre></div></div>





<p>This feels wrong. After reading 8212 bytes of compressed data for the first 100 bytes, it takes zero bytes to get the next 100?</p>



<div><div><pre><code>b'copy it, give it away or\r\nre-use it under the terms of the Project Gutenberg License included\r\nwith '
</code></pre></div></div>





<p>Clearly there is some buffering going on here. 8212 is suspiciously close to 8192 (20 bytes away) which is a power of two, and thus likely to be a common buffer size. Python‚Äôs file I/O machinery is responsible for the buffering, but we can actually get rid of it by disabling buffering.</p>

<div><div><pre><code><span>gzip_file</span><span>.</span><span>close</span><span>()</span>
<span>compressed</span><span>.</span><span>close</span><span>()</span>
<span>compressed</span> <span>=</span> <span>open</span><span>(</span><span>'alice.txt.gz'</span><span>,</span> <span>'rb'</span><span>,</span> <span>buffering</span><span>=</span><span>0</span><span>)</span>
<span>gzip_file</span> <span>=</span> <span>gzip</span><span>.</span><span>GzipFile</span><span>(</span><span>fileobj</span><span>=</span><span>compressed</span><span>)</span>
<span>gzip_file</span><span>.</span><span>read</span><span>(</span><span>100</span><span>)</span>
<span>compressed</span><span>.</span><span>tell</span><span>()</span>
</code></pre></div></div>



<p>Hm. We made <code>compressed</code> an unbuffered file, but maybe <code>GzipFile</code> has its own internal buffering. To avoid this, let‚Äôs do a bad thing. We can actually set the buffer size for all I/O operations by modifying <code>io.DEFAULT_BUFFER_SIZE</code>. If we set it to a small value, then we can reduce the impact of buffering on our measurements. Just for fun, let‚Äôs try setting it to 1.</p>

<div><div><pre><code><span>import</span> <span>io</span>
<span>old_buffer_size</span> <span>=</span> <span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span>
<span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span> <span>=</span> <span>1</span>
<span>gzip_file</span><span>.</span><span>close</span><span>()</span>
<span>compressed</span><span>.</span><span>close</span><span>()</span>

<span>compressed</span> <span>=</span> <span>open</span><span>(</span><span>'alice.txt.gz'</span><span>,</span> <span>'rb'</span><span>,</span> <span>buffering</span><span>=</span><span>0</span><span>)</span>
<span>gzip_file</span> <span>=</span> <span>gzip</span><span>.</span><span>GzipFile</span><span>(</span><span>fileobj</span><span>=</span><span>compressed</span><span>)</span>
<span>gzip_file</span><span>.</span><span>read</span><span>(</span><span>100</span><span>)</span>
<span>compressed</span><span>.</span><span>tell</span><span>()</span>
</code></pre></div></div>



<p>This seems <em>much</em> more believable. To read 100 bytes of decompressed data, gzip had to read 205 bytes of compressed data (again, this is probably due to tables and other header information). Let‚Äôs continue for a bit:</p>

<div><div><pre><code><span>bytes_unc</span> <span>=</span> <span>100</span>
<span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>5</span><span>):</span>
    <span>gzip_file</span><span>.</span><span>read</span><span>(</span><span>100</span><span>)</span>
    <span>bytes_unc</span> <span>+=</span> <span>100</span>
    <span>bytes_cmp</span> <span>=</span> <span>compressed</span><span>.</span><span>tell</span><span>()</span>
    <span>print</span><span>(</span><span>f</span><span>'uncompressed: {bytes_unc} / compressed: {bytes_cmp}'</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>uncompressed: 200 / compressed: 279
uncompressed: 300 / compressed: 335
uncompressed: 400 / compressed: 376
uncompressed: 500 / compressed: 449
uncompressed: 600 / compressed: 541
</code></pre></div></div>

<p>We can see that after reading 400 uncompressed bytes, the gzip compression has caught up! 376 compressed bytes needed to be read to give us those 400. The gap continues to widen as we go on.</p>

<p>Now that we‚Äôre confident that this approach is giving us interesting data, let‚Äôs make some functions to get all of this data for a particular file, so we can visualize it!</p>

<div><div><pre><code><span>gzip_file</span><span>.</span><span>close</span><span>()</span>
<span>compressed</span><span>.</span><span>close</span><span>()</span>
<span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span> <span>=</span> <span>old_buffer_size</span>
</code></pre></div></div>

<p>That was just some cleanup. Since modifying the buffer size would likely impact other code we run, it‚Äôs best to only modify the buffer size when we need it, and reset it back to its original value when we‚Äôre done. This can be done with a context manager.</p>

<div><div><pre><code><span>import</span> <span>contextlib</span>
<span>@contextlib.contextmanager</span>
<span>def</span> <span>buffer_size</span><span>(</span><span>newsize</span><span>=</span><span>1</span><span>):</span>
    <span>old_buffer_size</span> <span>=</span> <span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span>
    <span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span> <span>=</span> <span>newsize</span>
    <span>try</span><span>:</span>
        <span>yield</span>
    <span>finally</span><span>:</span>
        <span>io</span><span>.</span><span>DEFAULT_BUFFER_SIZE</span> <span>=</span> <span>old_buffer_size</span>
        
        
<span>with</span> <span>buffer_size</span><span>():</span>
    <span>print</span><span>(</span><span>f</span><span>'size: {io.DEFAULT_BUFFER_SIZE}'</span><span>)</span>
<span>print</span><span>(</span><span>f</span><span>'size: {io.DEFAULT_BUFFER_SIZE}'</span><span>)</span>
</code></pre></div></div>



<p>Now for a function to retrieve compressed and uncompressed sizes. We can do this with a ‚Äúchunk size‚Äù as a parameter. The larger our chunk size, the fewer data points we will have, but the code will run faster. We used 100 as a chunk size above, which seems good enough, but I do prefer a good <a href="https://xkcd.com/1000/">round number</a>, so I‚Äôll change it to 64.</p>

<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>def</span> <span>create_compression_curve</span><span>(</span><span>filename</span><span>,</span> <span>chunksize</span><span>=</span><span>64</span><span>):</span>
    <span>with</span> <span>buffer_size</span><span>(</span><span>1</span><span>),</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>fileobj</span><span>:</span>
        <span>gf</span> <span>=</span> <span>gzip</span><span>.</span><span>GzipFile</span><span>(</span><span>fileobj</span><span>=</span><span>fileobj</span><span>)</span>
        <span>records</span> <span>=</span> <span>[]</span>
        <span>read</span> <span>=</span> <span>0</span>
        <span>while</span> <span>True</span><span>:</span>
            <span>data</span> <span>=</span> <span>gf</span><span>.</span><span>read</span><span>(</span><span>chunksize</span><span>)</span>
            <span>if</span> <span>len</span><span>(</span><span>data</span><span>)</span> <span>==</span> <span>0</span><span>:</span>
                <span>break</span>  <span># end of file</span>
            <span>else</span><span>:</span>
                <span>read</span> <span>+=</span> <span>len</span><span>(</span><span>data</span><span>)</span>
                <span>records</span><span>.</span><span>append</span><span>((</span><span>read</span><span>,</span> <span>fileobj</span><span>.</span><span>tell</span><span>()))</span>
                
    <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>records</span><span>,</span> <span>columns</span><span>=</span><span>[</span><span>'uncompressed'</span><span>,</span> <span>filename</span><span>])</span>
    <span>return</span> <span>df</span><span>.</span><span>set_index</span><span>(</span><span>'uncompressed'</span><span>)</span>


<span>ccurve</span> <span>=</span> <span>create_compression_curve</span><span>(</span><span>'alice.txt.gz'</span><span>)</span>
<span>ccurve</span>
</code></pre></div></div>

<div>

<table>
  <thead>
    <tr>
      <th></th>
      <th>alice.txt.gz</th>
    </tr>
    <tr>
      <th>uncompressed</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>64</th>
      <td>176</td>
    </tr>
    <tr>
      <th>128</th>
      <td>224</td>
    </tr>
    <tr>
      <th>192</th>
      <td>271</td>
    </tr>
    <tr>
      <th>256</th>
      <td>315</td>
    </tr>
    <tr>
      <th>320</th>
      <td>345</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>174272</th>
      <td>61351</td>
    </tr>
    <tr>
      <th>174336</th>
      <td>61362</td>
    </tr>
    <tr>
      <th>174400</th>
      <td>61379</td>
    </tr>
    <tr>
      <th>174464</th>
      <td>61404</td>
    </tr>
    <tr>
      <th>174484</th>
      <td>61417</td>
    </tr>
  </tbody>
</table>
<p>2727 rows √ó 1 columns</p>
</div>

<p>The above function simply reads the gzipped file in chunks, measuring the distance we‚Äôve gone through the compressed file each time, and adding it to a list of ‚Äúrecords‚Äù. This list is converted into a Pandas Dataframe, which is commonly used to hold tabular data like this. We set the ‚Äúuncompressed‚Äù column to be the ‚Äúindex‚Äù, since that‚Äôs what we‚Äôd consider the X-axis.</p>

<p>The result looks exciting! We can even go right ahead and plot it from here.</p>

<div><div><pre><code><span># Some style changes to make the plots more pretty</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>matplotlib</span> <span>as</span> <span>mpl</span>
<span>plt</span><span>.</span><span>style</span><span>.</span><span>use</span><span>(</span><span>'ggplot'</span><span>)</span>
<span>mpl</span><span>.</span><span>rcParams</span><span>[</span><span>'figure.figsize'</span><span>]</span> <span>=</span> <span>[</span><span>16</span><span>,</span> <span>8</span><span>]</span>

<span>ccurve</span><span>.</span><span>plot</span><span>()</span>
</code></pre></div></div>

<p><img src="https://brennan.io/images/ccurves/output_28_1.png" alt="Plot 1"></p>

<p>Well, I gotta give it to gzip ‚Äì it‚Äôs pretty consistent. I can‚Äôt really see anything interesting in the plot, except that the gzipped data is smaller than the uncompressed version (duh). We can add this in to make it more explicit:</p>

<div><div><pre><code><span>ccurve</span><span>[</span><span>'uncompressed'</span><span>]</span> <span>=</span> <span>ccurve</span><span>.</span><span>index</span>
<span>ccurve</span><span>.</span><span>plot</span><span>()</span>
</code></pre></div></div>

<p><img src="https://brennan.io/images/ccurves/output_30_1.png" alt="Plot 2"></p>

<h2 id="what-to-do-with-this-new-power">What to do with this new power?</h2>

<p>So, the result here seems to be blindingly mundane. gzip compresses reasonably well, it‚Äôs obviously better than uncompressed.</p>

<p>Well, let‚Äôs try to make things less mundane. First, a peek at the gzip(1) manual page indicates that it has different compression levels 1-9. I‚Äôll let the manual do the explaining:</p>

<div><div><pre><code>   -# --fast --best
          Regulate the speed of compression using the specified digit #, where -1
          or  --fast  indicates the fastest compression method (less compression)
          and -9 or --best indicates the slowest compression  method  (best  com‚Äê
          pression).   The  default  compression level is -6 (that is, biased to‚Äê
          wards high compression at expense of speed).
</code></pre></div></div>

<p>What if we used this compression curve plot to compare the gzip compression levels?</p>

<div><div><pre><code><span>import</span> <span>os</span>
<span>files</span> <span>=</span> <span>[]</span>
<span>for</span> <span>level</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
    <span>os</span><span>.</span><span>system</span><span>(</span><span>f</span><span>'gzip -k -S .gz.{level} -{level} alice.txt'</span><span>)</span>
    <span>files</span><span>.</span><span>append</span><span>(</span><span>f</span><span>'alice.txt.gz.{level}'</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>'Created {files[-1]}'</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>Created alice.txt.gz.1
Created alice.txt.gz.2
Created alice.txt.gz.3
Created alice.txt.gz.4
Created alice.txt.gz.5
Created alice.txt.gz.6
Created alice.txt.gz.7
Created alice.txt.gz.8
Created alice.txt.gz.9
</code></pre></div></div>

<p>Above I went ahead and created all the different compression levels. Now, we can get compression curves for all of them and plot them:</p>

<div><div><pre><code><span>ccurves</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span>
    <span>create_compression_curve</span><span>(</span><span>fn</span><span>)</span> <span>for</span> <span>fn</span> <span>in</span> <span>files</span>
<span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code><span>ccurves</span><span>.</span><span>plot</span><span>(</span><span>title</span><span>=</span><span>"gzip Compression Level Comparison (Alice's Adventures in Wonderland)"</span><span>)</span>
</code></pre></div></div>

<p><img src="https://brennan.io/images/ccurves/output_35_1.png" alt="Plot 3"></p>

<p>That seems slightly more interesting. The default compression level of 6 seems to be chosen well. Beyond level 6, the reduction in file size seems pretty difficult to notice. However, the difference between the compression ratios is rather small compared to the uncompressed line:</p>

<div><div><pre><code><span>ccurves</span><span>[</span><span>'uncompressed'</span><span>]</span> <span>=</span> <span>ccurves</span><span>.</span><span>index</span>
<span>ccurves</span><span>.</span><span>plot</span><span>()</span>
</code></pre></div></div>
<hr>
<p><img src="https://brennan.io/images/ccurves/output_37_1.png" alt="Plot 4"></p>

<h2 id="making-an-interesting-graph">Making an ‚Ä¶</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brennan.io/2020/09/22/compression-curves/">https://brennan.io/2020/09/22/compression-curves/</a></em></p>]]>
            </description>
            <link>https://brennan.io/2020/09/22/compression-curves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24563372</guid>
            <pubDate>Wed, 23 Sep 2020 05:41:31 GMT</pubDate>
        </item>
    </channel>
</rss>
