<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 10 Oct 2020 12:33:49 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 10 Oct 2020 12:33:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[New York City thinks up to half of restaurants will close permanently [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 120 (<a href="https://news.ycombinator.com/item?id=24715150">thread link</a>) | @bookofjoe
<br/>
October 7, 2020 | https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf | <a href="https://web.archive.org/web/*/https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715150</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24715148">thread link</a>) | @zoozla
<br/>
October 7, 2020 | https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715148</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recycling was a lie to sell more plastic, recycling industry veteran says]]>
            </title>
            <description>
<![CDATA[
Score 691 | Comments 308 (<a href="https://news.ycombinator.com/item?id=24714880">thread link</a>) | @vivekd
<br/>
October 7, 2020 | https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Less than 10 per cent of the plastics we’ve used have been recycled. A new documentary reveals why</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5755241.1602170985!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/157672506.jpg"></p></div><figcaption>trash on the beach<!-- --> <!-- -->(Getty Images)</figcaption></figure><p><span><p>Although our landfills and oceans are full of it, we are as dependent as ever on plastic. And since COVID-19, it's gotten worse.&nbsp;</p>  <p>Last year, Canada announced it was working on a ban of single-use plastics, which was initally&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">sidelined by the pandemic</a>. Recently, the government announced that <a href="https://www.cbc.ca/news/politics/single-use-plastics-1.5753327">many single-use plastics will be banned</a> by the end of 2021. At the same time, <a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">CBC News reports</a> our single-use plastic use increased by 250 to 300 per cent as people tossed their personal protective equipment and stopped using reusable bags and containers over fears they would spread the virus.</p>  <p>What makes our lives convenient is also burying us. <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><strong><em>Plastic Wars</em></strong></a>, presented by <em>The Passionate Eye</em>, looks at the mounting crisis and how the industry has spent millions promoting recycling — just to sell more plastic.</p>  <h2>Less than 10% of the plastics we've used have been recycled</h2>  <p>Although activists sounded the alarm about plastic waste in the 1970s, the documentary claims from 1990 to 2010, plastic production more than doubled. We've been sorting our trash for decades, believing it would be recycled. But the truth is the vast majority of the plastic we use won't be. Over the last seven decades, <a href="https://www.oecd.org/environment/waste/policy-highlights-improving-plastics-management.pdf">less than 10 per cent of plastic waste has been recycled</a>.&nbsp;</p>  <p>That's because, says David Allaway, from the Oregon Department of Environmental Quality, the conversation has been almost exclusively about recycling and not reducing and reusing.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Recycling"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1002/935/PlasticWars_Recycling_2500kbps_620x350_1755680835594.jpg" alt=""></p></div></div></div><span>Even as the plastic crisis worsens, the demand for plastic grows and plastic production is rapidly expanding. One issue? Only focusing on recycling, and not reducing the amount of plastic that we use.<!-- --> <!-- -->1:06</span></span></span></p>  <h2>Recycling logo was used as a green marketing tool, says industry expert</h2>  <p>In the '80s, the industry was at the centre of an environmental backlash. Fearing an outright ban on plastics, manufacturers looked for ways to get ahead of the problem. They looked at recycling as a way to improve the image of their product and started labeling plastics with the now ubiquitous chasing-arrows symbol with a number inside.&nbsp;</p>  <p>According to Ronald Liesemer, an industry veteran who was tasked with overseeing the new initiative, "Making recycling work was a way to keep their products in the marketplace."&nbsp;</p>  <p>Most consumers might have assumed the symbol meant the product was recyclable. But according to experts in the film, there was no economically viable way to recycle most plastics, and they have ultimately ended up in a landfill. This included plastic films, bags and the wrapping around packaged goods, as well as containers like margarine tubs.<br> "Our own customers … they would flat out say, 'It says it's recyclable right on it,'" says Coy Smith, former board member of the National Recycling Coalition. "And I'd be like, 'I can tell you, I can't give this away. There's no one that would even take it if I paid them to take it.'" He believes manufacturers used the symbol as a green marketing tool.</p>  <p>"If the public thinks that recycling is working, then they're not going to be as concerned about the environment," says Larry Thomas, another top industry official interviewed in <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>.</p>  <p>According to Lewis Freeman, a former vice-president with the Society of the Plastics Industry, many in the industry had doubts about recycling from the start. "There was never an enthusiastic belief that recycling was ultimately going to work in a significant way," he says.</p>  <p>Yet the plastic industry spent millions on ads selling plastics and recycling to consumers.</p>  <h2>Lots of our plastic was shipped to China, then Southeast Asia, for 'recycling'</h2>  <p>To solve the plastic waste problem, many recyclers started selling their product to China in the 1990s. According to recycling broker Sunil Bagaria, China took waste that North American recyclers couldn't use. "As long as it remotely resembled plastic, they wanted it," he says.</p>  <p>But they used the good stuff and disposed of the rest. And because of a growing plastic waste problem in that country, China finally stopped taking most imported plastic waste in 2018.</p>  <p>"We never asked the question, 'Are they doing it the right way? Are we damaging the environment more in the name of recycling?'" says Bagaria.</p>  <p>Now, Southeast Asian countries like Indonesia have picked up the plastic waste market. And although some North American plastics recyclers are following up to ensure their products are in fact being recycled, plastic waste is now a growing problem there, too.&nbsp;</p>  <p>In <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>, local activist Yuyan Ismawati visits a rural community where locals scour through a huge field of plastic waste for items of value and burn the rest. This creates health problems for the residents in addition to destroying the surrounding environment. "We are struggling to clean up the modern debris and modern litter in Indonesia, the additional burden of waste from overseas — I don't know how we are going to handle it," says Ismawati. "Americans need to know that your waste ended up here."</p>  <h2>Production of plastics expected to triple by 2050</h2>  <p>In 2020, roughly 60 years after concerns about plastic waste were first raised, the focus is still on the consumer to recycle, says Allaway, and not on the environmental impact of the product and overproduction by the industry.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Full Impact"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1004/887/PlasticWars_FullImpact_2500kbps_620x350_1755684419745.jpg" alt=""></p></div></div></div><span>Consumers are constantly told that they should do their part to reduce plastic waste, but in reality, consumers have the lowest amount of leverage in reducing waste - it's plastic producers that should be reporting their full environmental impacts.<!-- --> <!-- -->1:56</span></span></span></p>  <p>According to <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> the problem is only going to get worse. By 2050, it's estimated the global production of plastic will triple. As the oil and gas industry — which provides the source materials for plastics — &nbsp;faces a future of declining demand for fuel, it has turned to other markets.&nbsp;</p>  <p>The stakes are high, says Annie Leonard, executive director of Greenpeace USA. "This is their lifeline," she says. "They are going to double down on single-use plastic like we have never seen. So we're heading towards a real battle.... This is the big war."&nbsp;</p>  <p>Watch <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> on <em>The Passionate Eye</em>.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24714880</guid>
            <pubDate>Thu, 08 Oct 2020 02:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp and Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24712207">thread link</a>) | @dunefox
<br/>
October 7, 2020 | https://markkarpov.com/post/lisp-and-haskell.html | <a href="https://web.archive.org/web/*/https://markkarpov.com/post/lisp-and-haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          

<p><a href="https://markkarpov.com/tag/haskell.html">haskell</a></p><p>
  <em>
    Published on October 23, 2015, last updated November 23, 2019
  </em>
</p>

  <p>Lisp and Haskell are arguably some of the more peculiar languages out there.
It is always interesting to compare languages, so let me entertain you with
a story how I finally decided which of them is better.</p>
<p>When I first found out about Common Lisp it took my breath away. Seriously,
Lisp has consistent syntax, good design, and unique metaprogramming
capabilities. After Common Lisp, I learned a few other languages, some of
them out of necessity, others because of curiosity: Python, JavaScript,
Prolog, Clojure, and Haskell. I also was doing C and C++ in the past, but I
don’t touch them now. Until recently I considered Common Lisp the best
language I know, and probably the most powerful language in existence.</p>
<p>The fact is, I know what Common Lisp is and what it can do, but the days
when I actually hacked Lisp (more or less) regularly are long gone, and I’m
mainly doing Haskell these days.</p>
<h2 id="goodbye-lisp">Goodbye, Lisp</h2>
<p>Today I actually have had a chance to compare my productivity with Common
Lisp and Haskell. I decided to spend a few hours on my open source projects.
First, I refactored <a href="https://github.com/mrkkrp/megaparsec">Megaparsec</a>, and that was nice and easy,
but I didn’t notice this because I’m already used to the level of efficiency
Haskell gives me.</p>
<p>Next, a user of one of my Common Lisp libraries opened an issue asking to
improve one thing a bit. I estimated the required work in 15 minutes of time
and started Common Lisp hacking for the first time in a couple of months.</p>
<p>It took about 1 hour to write about 20 lines of trivial code. Of course one
might say that I just forgot the details. Yet, from my point of view the
real reasons are:</p>
<ul>
<li>
<p>Common Lisp is dynamically typed and the compiler cannot help you when you
write your code. (Well, it can help you a bit, making sure that your code
is syntactically correct and all your declared variables are used for
something.)</p>
</li>
<li>
<p>Common Lisp mixes functional code with code that has side effects. To
write idiomatic Common Lisp, you usually have to mix functional code with
not-so-functional approaches. See how this works below.</p>
</li>
<li>
<p>Common Lisp’s standard library (the functions that are available to you as
part of the ANSI Common Lisp standard) is quite poor by modern standards.
A lot of useful functions are missing. There are libraries, but I’ll get
to them.</p>
</li>
</ul>
<p>It’s essential for that library I was working on to have minimal
dependencies, so I came up with this function in bare Common Lisp to add
padding to every line of text except for the first line:</p>
<div><pre><code><span>(</span><span>defun</span><span> add-text-padding </span><span>(str &amp;key padding newline)</span>
<span>  </span><span>"Add padding to text STR. Every line except for the first one, will be</span>
<span>prefixed with PADDING spaces. If NEWLINE is non-NIL, newline character will</span>
<span>be prepended to the text making it start on the next line with padding</span>
<span>applied to every single line."</span>
<span>  (</span><span>let</span><span> ((str (</span><span>if</span><span> newline</span>
<span>                 (</span><span>concatenate</span><span> 'string (</span><span>string</span><span> </span><span>#\N</span><span>ewline) str)</span>
<span>                 str)))</span>
<span>    (</span><span>with-output-to-string</span><span> (s)</span>
<span>      (</span><span>map</span><span> 'string</span>
<span>           (</span><span>lambda</span><span> (x)</span>
<span>             (</span><span>princ</span><span> x s)</span>
<span>             (</span><span>when</span><span> (</span><span>char=</span><span> x </span><span>#\N</span><span>ewline)</span>
<span>               (</span><span>dotimes</span><span> (i padding)</span>
<span>                 (</span><span>princ</span><span> </span><span>#\S</span><span>pace s))))</span>
<span>           str))))</span>
</code></pre></div>
<p>In case you don’t speak Common Lisp, let me highlight some parts of the
code:</p>
<ul>
<li>
<p><code>concatenate</code> needs to know the type of its output, so we pass it a symbol
specifying type of desired result as the first argument.</p>
</li>
<li>
<p><code>(string #\Newline)</code> constructs a line containing a single newline
character. There is no syntax in Common Lisp to write something like
<code>"\n"</code>. The alternative approach would be <code>(format nil "~%")</code>. There is no
syntax for all other special characters if you want to put them into
string. To be fair, you have multi-line string literals without funny
escaping instead, which is vital for doc-strings and the like.</p>
</li>
<li>
<p><code>(map 'string …)</code> is used to loop through characters in a string. Note
that here we use <code>map</code> function as a helper for a rather imperative
procedure—printing results to new string using a temporarily created
stream <code>s</code> (with the help of <code>with-output-to-string</code>). But that’s
idiomatic in Common Lisp.</p>
</li>
</ul>
<p>When I ran this in the REPL, I got the following:</p>
<div><pre><code><span>; SLIME 2015-10-18</span>
<span>CL-USER&gt; (asdf:load-system :unix-opts)</span>
<span>T</span>
<span>CL-USER&gt; (</span><span>in-package</span><span> :unix-opts)</span>
<span>#&lt;PACKAGE </span><span>"UNIX-OPTS"</span><span>&gt;</span>
<span>OPTS&gt; (</span><span>defvar</span><span> *foo* </span><span>(</span><span>format</span><span> </span><span>nil</span><span> </span><span>"first line~%second line~%third line"</span><span>))</span>
<span>*FOO*</span>
<span>OPTS&gt; *foo*</span>
<span>"first line</span>
<span>second line</span>
<span>third line"</span>
<span>; compiling (DEFUN ADD-TEXT-PADDING ...)</span>
<span>OPTS&gt; (add-text-padding *foo* :padding </span><span>10</span><span>)</span>
<span>; Evaluation aborted on #&lt;TYPE-ERROR expected-type: CHARACTER datum: NIL&gt;.</span>
</code></pre></div>
<p>The debugger popped up and told me in plain English:</p>
<blockquote>
<p>The value NIL is not of type CHARACTER.</p>
</blockquote>
<p>It is difficult to argue with, <code>nil</code> is definitely not a character. But why
the heck do I get this? Can you tell? Please try as hard as you can! <em>(The
answer is at the end of the blog post.)</em></p>
<p>I decided that I won’t hack Common Lisp anymore. That’s great and expressive
language, but I want to write in something I’m efficient with.</p>
<h2 id="productivity-of-haskell-programmer">Productivity of Haskell programmer</h2>
<p>I use <a href="https://gnu.org/software/emacs/">Emacs</a> for almost everything that is
related to text. One package I love in particular is
<a href="http://www.flycheck.org/">Flycheck</a>. When I edit Haskell source code,
Flycheck is running GHC with <code>-Wall</code> flag and
<a href="https://github.com/ndmitchell/hlint">HLint</a> in the background and displays
warnings and errors interactively underlining my source code. This is a
convenient feature for any language, but only Haskell with its type system
takes this sort of tool to its limits.</p>
<p>In fact, this non-stop interactive conversation with compiler is the most
efficient programming workflow I’ve ever used. Combined with the fact that
<em>if your code compiles, it probably works</em>, Haskell must be the most
efficient (with respect to human resources) programming language in
existence just because of the static type system that works as a powerful
ally for the programmer. Of course, bugs can live in Haskell code too, but
I’m not saying we should abandon writing tests.</p>
<h2 id="problems-of-common-lisp">Problems of Common Lisp</h2>
<p>Speaking of tests, recently I discovered that Zach Beane AKA Xach, an
über-level Common Lisp hacker <a href="http://xach.livejournal.com/278047.html?thread=674335#t674335">doesn’t usually write tests</a>.
FYI, he is the author of <a href="https://www.quicklisp.org/beta/">Quicklisp</a>, that is something like (but
not quite) Cabal or Stack. Quicklisp is de-facto the only widely used
library manager in Common Lisp world, and so it’s written in Common Lisp and
<a href="https://github.com/quicklisp/quicklisp-client">doesn’t have any tests</a>. It is a wonder for me how it
works. Usually when a project is big enough I start to have doubts whether
all parts of it still work after some changes, so I cannot imagine you can
do a thing like Quicklisp without tests and be confident about the result.</p>
<p>But you know what, Lisp, and its most advanced dialect (IMO), Common Lisp is
really cool. If you don’t believe me, you can read <a href="http://www.paulgraham.com/avg.html">Paul Graham</a> at any
time. The author can tell you what a great language Common Lisp is on
many-many pages. I don’t remember where I read this, but he has something
like “There is the problem of lacking libraries, but on a big enough project
benefits of the language itself outweigh the lack of libraries.”</p>
<p><em>Well, take any high-level language like Python, which have all the nice
libraries, and for project of any size it will be better than Common Lisp.
Macros are missing, but you can live without macros after all.</em></p>
<p>Common Lisp doesn’t have enough high-quality, actively maintained libraries.
The fact is, there are some pearls like <a href="https://github.com/fukamachi/caveman">caveman</a> or
<a href="https://github.com/stumpwm/stumpwm">stumpwm</a>, but most libraries don’t look good enough. Sometimes you
start thinking that if you want to end up with a great project you’ll need
to write your own libraries (which you’ll probably do, like many people
before you, not that it has improved the situation though).</p>
<p>Another problem is that some widely-used Common Lisp libraries have no
documentation at all. If you’re to understand how to use them, <em>read the
source code</em>. I can name a couple of them, but I don’t want to do so,
because I don’t think it’s polite. I’ve opened an issue on GitHub of one
quite popular library, asking the maintainer to write documentation. After 6
months it’s still not written (strange, right?). In my opinion, this is not
a serious approach to maintaining your code.</p>
<p>When I was interested in Common Lisp, I had an idea of a pet project to help
me remember all sorts of French words and verbs in particular. Of course I
wanted to do the whole thing decently, even though it’s console app, it
should have decent interface and work smoothly in general. I succeeded, but
I had to do a lot more than I would need to do if I wrote it in, say Python.
This is how (in retrospect I understand) less powerful Python would be
better fit for this (or almost any) project.</p>
<h2 id="the-curse-of-dynamic-languages">The curse of dynamic languages</h2>
<p>There is a blog post called <a href="https://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/"><em>Dynamic Languages are Static
Languages</em></a>. In short, the author makes the point that
dynamic langauges are static languages but with one huge type including all
possible values. Here is a paragraph I find important:</p>
<blockquote>
<p>And this is precisely what is wrong with dynamically typed languages:
rather than affording the <em>freedom</em> to ignore types, they instead impose
the <em>bondage</em> of restricting attention to a <em>single</em> type! Every single
value has to be a value of that type, you have no choice! Even if in a
particular situation we are absolutely certain that a particular value is,
say, an integer, we have no choice but to regard it as a value of the “one
true type” that is <em>classified</em>, not typed, as an integer. Conceptually,
this is just rubbish, but it has serious, tangible penalties. For one, you
are depriving yourself of the ability to state and enforce the <em>invariant</em>
that the value at a particular program point must be an integer. For
another, you are imposing a serious bit of run-time overhead to represent
the class itself (a tag of some sort) and to check and remove and apply
the class tag on the value each time it is used.</p>
</blockquote>
<p>The lack of the power to express meaning of your program on type level is
another downside of Lisp. (You can add types in Common Lisp too, but that’s
used solely for optimization. Common Lisp can be almost as fast …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://markkarpov.com/post/lisp-and-haskell.html">https://markkarpov.com/post/lisp-and-haskell.html</a></em></p>]]>
            </description>
            <link>https://markkarpov.com/post/lisp-and-haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24712207</guid>
            <pubDate>Wed, 07 Oct 2020 20:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a New Rust Class at Stanford: Safety in Systems Programming]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24711314">thread link</a>) | @ksml
<br/>
October 7, 2020 | https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Writing quality software is hard. Sometimes, software breaks in entertaining
ways. However, when software runs everything from personal assistants like
Alexa and Google Home to banking to elections, some bugs can be much more
severe.</p>

<p>This past quarter, Armin Namavari and I tried teaching a class about how to
write software that sucks just a <em>little</em> less. We focused on common problems
in computer systems caused by certain kinds of silly (but very serious)
mistakes, such as issues of memory safety and thread safety. The core theme of
the class was, <em>What are common problems with systems programming right now?
How are people responding to those issues? How do those measures fall short?</em>
We wanted students to be aware of problems that have plagued the industry for
decades, and we wanted to teach students how to use tools and mental models
that people have developed to combat those issues. However, these tools are
imperfect, and we also wanted students to experience and understand the
limitations of such tools to be better aware of what to watch out for when
building systems.</p>

<!--more-->

<p>In particular, we focused on teaching the Rust programming language as a way to
build better habits and combat mistakes endemic to C- and C++-based software.
In many ways, Rust <em>requires</em> good practices, and it has an educational
compiler with helpful error messages that help students learn. Additionally, we
looked at how lessons from Rust can be applied to write better code in C++, and
we taught students about tools that can be used to detect common mistakes
before they become a problem.</p>

<p>In contrast with a typical security class, we aimed to build a robust software
engineering aspect into the course, giving code-heavy assignments and trying to
improve students’ processes rather than merely giving awareness about common
problems. Our goal with this class was to train students to be better software
developers, regardless of what programming language they end up using.</p>

<p>I think the class went quite well, and student evaluations were extremely
positive. Even before the quarter ended, students told us that the class was
extremely helpful for implementing and debugging assignments in other classes.
We hope to teach the class again this coming fall, and are looking for input on
how it might be improved.</p>

<p>This blog post aims to be a summary of what we did, why we did it, and what we
are thinking about changing for the future. It’s long, but written so you can
skip around to whatever is interesting to you. Here’s an outline:</p>

<!--* [What is systems programming?](#what-is-systems-programming)-->
<ul>
  <li><a href="#what-is-safety-and-why-should-we-care">What is safety, and why should we care?</a></li>
  <li><a href="#imagining-safety-education">Imagining safety education</a>
    <ul>
      <li><a href="#should-there-be-a-safety-class">Should there be a “safety class”?</a></li>
      <li><a href="#how-would-this-be-different-from-a-security-class">How would this be different from a security class?</a></li>
      <li><a href="#how-does-one-teach-safe-programming">How does one teach safe programming?</a></li>
    </ul>
  </li>
  <li><a href="#summary-of-the-class">Summary of the class</a>
    <ul>
      <li><a href="#lectures">Lectures</a></li>
      <li><a href="#assignments">Assignments</a></li>
    </ul>
  </li>
  <li><a href="#survey-results">Survey results</a></li>
  <li><a href="#takeaways">Takeaways</a>
    <ul>
      <li><a href="#is-there-a-place-for-a-safety-class-in-a-cs-curriculum">Is there a place for a safety class in a CS curriculum?</a></li>
      <li><a href="#whats-it-like-for-students-to-learn-rust-in-a-short-time-frame">What’s it like for students to learn Rust in a short time frame?</a></li>
      <li><a href="#should-we-try-to-incorporate-rust-into-the-stanford-core-curriculum">Should we try to incorporate Rust into the Stanford core curriculum?</a></li>
      <li><a href="#should-this-be-a-standalone-class-or-should-it-remain-an-addon-to-cs-110">Should this be a standalone class, or should it remain an addon class to CS 110?</a></li>
    </ul>
  </li>
  <li><a href="#general-teaching-lessons-learned">General teaching lessons learned</a></li>
</ul>

<p>Major thanks go to Armin Namavari for being a wonderful co-instructor, Sergio
Benitez for giving an excellent guest lecture, Will Crichton for providing
feedback and guidance in designing the class, Jerry Cain for giving us the
opportunity to teach and giving encouragement throughout, and Rakesh Chatrath,
Jeff Tucker, Vinesh Kannan, John Deng, and Shiranka Miskin for reviewing drafts
of this post.</p>

<!--
## What is systems programming?

In this class, we wanted to focus on safety in systems programming &mdash; but what
*is* systems programming, anyways?

"Systems programming" is a frequently-used term that I have never heard a clear
definition for, despite specializing in this track in undergrad. While it is
used in many different ways, I think about it like this: **Systems programming
is when you spend more time thinking about hardware than humans.** An
application programmer must think, *what does a user of my software need, and
how can I implement that in code?* An application programmer might work with
different programming languages and libraries, but rarely needs to think about
exactly what the hardware is doing under the hood. By contrast, a systems
programmer must think, *how can I teach this hardware new tricks in order to do
the things we need to do?* A systems programmer spends much more time thinking
about when memory is allocated, when a processor might switch contexts, when
data might be passed over a network, etc.
-->

<!-- TODO: picture of restaurant -->

<!--
As an application developer, you spend more time implementing business logic using whatever programming languages and tools you've decided to use. You're trying to design something that fits within the physical constraints of whatever you're running on. As a systems programmer, you spend much more time thinking about when memory gets allocated, when a processor switches contexts, when data gets passed over a network, etc.

Humans are still important (I'll admit I deemphasized humans partially for the alliteration), but the focus is less on end users and more on supporting the application developers and the application software that builds on top

Diagram: trying to show humans walking on top, hardware on bottom, and application developers standing on top of the systems developers
Diagram: floor is programming languages, libraries, and abstractions
Have some plumbers, carpenters, etc under the floor, and application devs servicing customers on top

If a computer were a restaurant, systems programmers would be the plumbers etc, and application programmers would be the chefs, waiters, etc

Examples of systems software: the code generating directions for Google Maps, Google Chrome, the infrastructure that does transcription for Siri (not the AI algorithms, but everything in between your phone and the algorithms), banking infrastructure, car firmware, etc.
-->

<h2 id="what-is-safety-and-why-should-we-care">What is safety, and why should we care?</h2>

<p>Safety is an unfortunately vague term lacking a great definition, but for our
purposes, we’ll say <strong>safety is about avoiding harmful mistakes.</strong> I view
safety as being concerned with the subset of potentially serious bugs: if a
button on a website renders as purple instead of blue, that’s a bug we might
not care much about, but if bank account software allows users to withdraw the
same $1000 multiple times, or if autonomous vehicle software can fail under
certain circumstances, that’s a more concerning problem.</p>

<p>Safety is particularly relevant in systems programming because systems
programming is <em>hard</em>. Systems programming often involves pushing the limits of
what hardware can do, and often involves reasoning about the state of multiple
threads sometimes even distributed across thousands of machines. Additionally,
for performance and historical reasons, the majority of systems software is
written in C or C++, which are <em>notoriously</em> difficult to use correctly.
Reasoning about pointers and memory is hard, and C and C++ do little to help.
C/C++’s weak type systems and poorly defined
specifications mean they will happily accept <a href="https://www.radford.edu/ibarland/Manifestoes/whyC++isBad.shtml">clearly broken code with no
sensible
interpretation</a>.
Even worse, there are countless minefields where the languages’ poor designs
are just begging for mistakes to happen. Simple functions like <code>strcpy</code>, which
copies a string from one place in memory to another, are extremely easy to
misuse and have been the cause of countless <a href="https://pointerless.wordpress.com/2012/02/26/strcpy-security-exploit-how-to-easily-buffer-overflow/">security
vulnerabilities</a>.
The <code>strncpy</code> function was introduced to address the weaknesses of <code>strcpy</code>,
yet <a href="https://devblogs.microsoft.com/oldnewthing/20050107-00/?p=36773"><code>strncpy</code> turns out to be almost just as
bad</a>. Even
<a href="https://stackoverflow.com/questions/7459630/how-can-a-format-string-vulnerability-be-exploited"><code>printf</code> can lead to security
vulnerabilities</a>
when called the wrong way.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png" alt="">
    </a>
    
</figure>

<p>Also, as systems software provides the foundation on which other software runs,
it’s particularly important to get right. Many real-world examples demonstrate
the severe impact of the aforementioned issues.  One of my favorite examples is
presented in <a href="http://www.autosec.org/pubs/cars-usenixsec2011.pdf">Comprehensive Experimental Analyses of Automotive Attack
Surfaces</a>.  It’s a great
read, but as a summary, the authors bought a popular car and attempted to find
as many ways as possible to remotely hijack the car without having physical
access. They examined vectors such as wireless key fobs, Bluetooth, and even
the tire pressure monitoring system (which uses wireless signals to transmit
information from sensors in the tires). Every vector was found to be
exploitable, many of them trivially so. For example, the Bluetooth software had
“over 20 calls to <code>strcpy</code>, none of which were clearly safe.” The authors only
looked at the first instance of <code>strcpy</code>, and found that it copies data to the
stack when handling a Bluetooth configuration command without checking the
length of the string. This results in a trivially exploitable buffer overflow
that allows a paired device to execute arbitrary code in the media system.
Since the subsystems in most cars lack isolation, compromising one subsystem
(such as the media player) can result in the compromise of the entire car. In
2015, researchers demonstrated this, <a href="https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/">remotely killing a Jeep that was driving
on the
highway</a>.</p>

<p>This isn’t just a problem with the automotive industry. <a href="https://blog.zimperium.com/whatsapp-buffer-overflow-vulnerability-under-the-scope/">Professional</a>
<a href="https://www.theregister.com/2019/08/06/qualcomm_android_security_patches/">programmers</a>
<a href="https://www.biometricupdate.com/202006/acronis-reports-critical-flaws-in-geovision-biometric-devices-man-in-the-middle-attack-risks">across</a>
<a href="https://www.zdnet.com/article/critical-security-flaw-schneider-industrial-software-power-plants-vulnerabilty/">many</a>
<a href="https://blog.zecops.com/vulnerabilities/youve-got-0-click-mail/">industries</a>
<a href="https://www.theverge.com/2017/5/12/15630354/nhs-hospitals-ransomware-hack-wannacry-bitcoin">regularly</a>
<a href="https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-sdwanbo-QKcABnS2">make</a>
<a href="https://threatpost.com/netgear-zero-day-takeover-routers/156744/">simple</a>
<a href="https://gadgets.ndtv.com/mobiles/news/samsung-critical-bug-fix-skia-sve-2020-16747-zero-click-vulnerability-2224867">but</a>
<a href="https://redmondmag.com/articles/2020/07/16/cisa-windows-server-dns-vulnerability.aspx">serious</a>
<a href="https://threatpost.com/google-squashes-high-severity-flaws-in-chrome-browser/154424/">mistakes</a>.</p>

<p>This seems like something we should be talking about. Would you hand a
chemistry student a bunch of volatile chemicals that regularly explode in
professional labs without a robust discussion of safety?  Probably not. Yet
that’s effectively what our curriculums are doing. We’re handing students a
series of tools that professionals routinely shoot themselves in the foot with,
and we aren’t having a substantial discussion of precautions we can take to
avoid potentially life-threatening mistakes.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png" alt="In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.">
    </a>
    
    <figcaption>In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.</figcaption>
    
</figure>

<p>One might argue that the perils of strcpy are nothing like the dangers of a
fully-stocked chemistry lab; there’s no danger of students dying in front of
the computer here. (Well, we hope.) However, I argue that we deal with dangers
on a much larger scale.  One line of code can easily affect millions (or
billions) of people, and the impacts of our code can be much greater than we
realize, even when we aren’t working on software for cars (which <a href="https://www.safetyresearch.net/blog/articles/toyota-unintended-acceleration-and-big-bowl-%E2%80%9Cspaghetti%E2%80%9D-code">we’ve killed
people
with</a>)
or medical devices (which <a href="https://hackaday.com/2015/10/26/killed-by-a-machine-the-therac-25/">we’ve also killed people
with</a>). It
may seem that the worst-case bugs in a file sharing server would simply prevent
users from sharing files, but one such bug led to the <a href="https://www.telegraph.co.uk/technology/2018/10/11/wannacry-cyber-attack-cost-nhs-92m-19000-appointments-cancelled/">significant disruption
of the National Health Service in the
UK</a>.
Non-critical emergencies had to be refused. It may seem that the worst-case
bugs in a web application library would simply take down some websites, but one
such bug led to the <a href="https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html">exfiltration of extremely sensitive data on nearly every
American adult with a credit
history</a>.</p>

<!--We've spent a lot of effort over the last three decades finding ways to improve
the safety of code. We have linters, which can detect unsafe patterns in code
(e.g. calls to `strcpy`, or use of uninitialized memory). We have fuzzers and
sanitizers, which can stress test our code and identify memory errors and data
races. Most promising (in my opinion), we have new progamming languages such as
Rust and Swift which are safer, competitive on performance, and showing
potential for replacing C and C++ in the settings that those languages have
typically dominated. These languages can prevent entire classes of mistakes
that keep recurring in C and C++ codebases even with the use of other safety
tools. Linters, sanitizers, fuzzers, and static analyzers all help to catch
mistakes, but they don't *prevent* them, and they can't catch everything. While
these new languages are not a panacea and have their own problems, they make
massive strides towards squashing issues we haven't been able to address via
other means. Despite having some of the best security and development practices
in the world, Google Chrome (written in C++) is still plagued with memory
errors that would have been entirely prevented with Rust. Recently, they found
that [70% of security vulnerabilities were caused by memory
errors](https://www.chromium.org/Home/chromium-security/memory-safety).-->

<p>Precautions and safety measures <em>do</em> exist, but people aren’t using them. Part
of this may be because the tooling isn’t good enough or easy enough to use.
Part of this may be because there hasn’t been enough time to see mass adoption.
But I think part of this may also be because of a lack of education and
awareness surrounding these issues. We can teach C and C++ and hope that
students will learn good habits and learn how to use static analyzers,
sanitizers, fuzzers, and safer languages on the job, but then have we not
failed them as educators? Seeing that software engineers keep making pretty
basic mistakes with critical impact, it seems that something is wrong and we
should be trying to do more.</p>

<h2 id="imagining-safety-education">Imagining safety education</h2>

<p>So, we should talk more about safety. But how should we go about it?</p>

<h3 id="should-there-be-a-safety-class">Should there be a “safety class”?</h3>

<p>In planning this class, we couldn’t find any other programming safety class out
there. Is that because no one has thought to do it yet, or is it because it is
better to teach safety in context alongside more central material?</p>

<p>Particularly because “safety” is so broad, it does seem helpful
to cover best practices and helpful tricks/tools while introducing new
material. However, there were two reasons we felt it might make sense to teach
a class entirely focused on safety.</p>

<p>First, teaching a separate safety class gives us room to experiment with
teaching new material that would be difficult to integrate into existing</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711314</guid>
            <pubDate>Wed, 07 Oct 2020 18:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Interview Questions Deconstructed: The Knight’s Dialer]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 100 (<a href="https://news.ycombinator.com/item?id=24711094">thread link</a>) | @thanato0s
<br/>
October 7, 2020 | https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/ | <a href="https://web.archive.org/web/*/https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This is the second in a series of posts in which I share my advice for candidates interviewing for tech companies, drawing on my experience as an engineer and interviewer at Google. If you haven’t already, take a look at the <a href="https://alexgolec.dev/introducing-google-interview-questions-deconstructed/">introduction</a> to this series.</p><p><em>Before I start, a disclaimer: while interviewing candidates is one of my professional responsibilities, this blog represents my personal observations, my personal anecdotes, and my personal opinions. Please don’t mistake this for any sort of official statement by or about Google, Alphabet, or any other person or organization.</em></p><p>This was the first problem I used during my interviewing career, and it was also the first to leak and get banned. I like it because it hits number of sweet spots:</p><ul><li>It’s easy to state and understand.</li><li>It has a number of solutions, each requiring varying degrees of algorithms and data structures knowledge. Also, a little bit of insight goes a long way.</li><li>Each solution can be implemented in relatively few lines, making it perfect for a time-constrained environment.</li></ul><p>If you’re a student or otherwise applying to tech jobs, my hope is that you’ll come away from reading this with a better understanding of what to expect from interview problems. If you’re an interviewer, I’d like to share my thought process and stylistic approach to interviewing, the better to inform others and solicit comments.</p><p>Note I’ll be writing code in Python. I like Python because it’s easy to learn, compact, and has an absolutely massive standard library. Candidates like it, too: even though we impose no language constraints, 90% of people I interview use Python. Also I use Python 3 because c’mon, it’s 2018.</p><p><em>Join <a href="https://discord.gg/cKFppJ">our Discord</a> to discuss this problem with the author and the community! </em></p><p>Imagine you place a knight chess piece on a phone dial pad. This chess piece moves in an uppercase “L” shape: two steps horizontally followed by one vertically, or one step horizontally then two vertically:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-pE4b3hqGDv7pKivQTQZyPw.png" alt="Image for post"><figcaption>Pay no attention to the poorly-redacted star and pound keys</figcaption></figure><p>Suppose you dial keys on the keypad using only hops a knight can make. Every time the knight lands on a key, we dial that key and make another hop. The starting position counts as being dialed.</p><p>How many distinct numbers can you dial in N hops from a particular starting position?</p><p>Every interview I conduct basically breaks down into two parts: first we find an algorithmic solution and then the candidate implements it in code. I say “we” find a solution because I’m not a mute spectator: 45 minutes is not a lot of time to design and implement anything under the best circumstances, never mind under pressure. I let candidates take the lead in the discussion, generating ideas, solving instances of the problem, etc., but I’m more than happy to give a nudge in the right direction. The better the candidate, the fewer hints I tend to have to give, but I have yet to see a candidate who required no input from me at all.</p><p>I should underscore this, because it’s important: as an interviewer, I’m not in the business of sitting back and watching people fail. I want to write as much positive feedback as I can, and I try to give you opportunities to allow me to write good things about you. Hints are my way of saying “okay, I’m gonna give this bit to you, but only so you can move on and show me what you’ve got on the other parts of the question.”</p><p>With that being said, your first action after hearing the question should be stepping up to the whiteboard and solving small instances of the problem by hand. <em>Never dive right into code!</em> Solving small instances lets you spot patterns, observed and edge cases, and also helps crystallize a solution in your head. As an example, suppose you start on 6 and have two hops to make. Your sequences will be…</p><ul><li>6–1–8</li><li>6–1–6</li><li>6–7–2</li><li>6–7–6</li><li>6–0–4</li><li>6–0–6</li></ul><p>…for a total of six sequences. If you’re following along, try taking a pencil and paper and deriving these. This doesn’t translate well into a blog post, but trust me when I say there’s something magical about working out a problem by hand that leads to many more insights than just staring at it and thinking quietly.</p><p>With all that said, you may have a solution forming in your head. But before we get there…</p><p>One of the surprises I had when I started using this problem is how often candidates get stuck on computing the keys to which we can hop from a given position, also known as the neighbors. My advice is: when in doubt, write an empty placeholder and ask the interviewer if you can implement it later. This problem’s complexity does not lie in the neighbor computation; I’m paying attention to how well you count full numbers. Any time spent on neighbor computation is effectively wasted.</p><p>I would accept “let’s assume there’s a function that gives me the neighbors” along with the following stub. Of course, I’ll probably ask you to double back and implement this later, but only if we have time. You can simply write a stub like this and move on:</p><pre><code>def neighbors(position):
	...</code></pre><p>Also, you don’t really lose much by asking to use a stub: if the question’s complexity is elsewhere I’ll allow it. If not, I’ll ask you to actually implement it. I don’t mind when candidates don’t realize where the complexity of a question lies, especially in the early stages when they might not have fully explored the problem.</p><p>As for the neighbors function here, given that it never changes you can simply create a map and return the appropriate value:</p><pre><code>NEIGHBORS_MAP = {
    1: (6, 8),
    2: (7, 9),
    3: (4, 8),
    4: (3, 9, 0),
    5: tuple(),  # 5 has no neighbors
    6: (1, 7, 0),
    7: (2, 6),
    8: (1, 3),
    9: (2, 4),
    0: (4, 6),
}
def neighbors(position):
    return NEIGHBORS_MAP[position]</code></pre><p>Anyway, on to the solution. Perhaps you’ve already noticed this problem can be solved by enumerating all possible numbers and counting them. You can use recursion to generate these values:</p><pre><code>def yield_sequences(starting_position, num_hops, sequence=None):
    if sequence is None:
        sequence = [starting_position]
    
    if num_hops == 0:
        yield sequence
        return

    for neighbor in neighbors(starting_position):
        yield from yield_sequences(
            neighbor, num_hops - 1, sequence + [neighbor])

def count_sequences(starting_position, num_hops):
    num_sequences = 0
    for sequence in yield_sequences(starting_position, num_hops):
        num_sequences += 1
    return num_sequences</code></pre><p>This works, and it’s a common starting point I saw in interviews. Notice, however, that we generate the numbers and never actually use them. This problem asks for the <em>count</em> of numbers, not the numbers themselves. Once we count a number we never revisit it. As a general rule of thumb, I recommend paying attention to when your solution computes something it doesn’t use. Often you can cut it out and get a better solution. Let’s do that now.</p><p>How can we count phone numbers without generating them? It can be done, but not without an additional insight. Notice how the count of numbers that can be generated from a given starting position in N hops is equal to the sum of the counts of hops that can be generated starting from each of its neighbors in N-1 hops. Stated mathematically as a recurrence relation, it looks like this:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-mcwSdrDe69X5FDegPmfgHg.png" alt="Image for post"></figure><p>This is intuitively obvious when you consider what happens with one hop: 6 has 3 neighbors (1, 7, and 0) and in zero hops you can reach one number for each, so you can only dial three numbers.</p><p>How does one arrive at this insight, you might ask? If you’ve studied recursion, this should become evident after some exploration on the whiteboard. Many candidates who’ve practiced recursion immediately notice this problem breaks down into smaller subproblems, which is a dead giveaway. If you’re in an interview with me and you can’t seem to arrive at this insight, I will usually give hints to help get you there, up to and including outright giving it away if prodding fails.</p><p>Once you have this insight in hand, you can already move forward and solve this problem again. There are a number of implementations that use this fact, but let’s start with the one I see most often in interviews: the naive recursive approach:</p><pre><code>from neighbors import neighbors                                 
                                                                
def count_sequences(start_position, num_hops):                  
    if num_hops == 0:                                           
        return 1                                                
                                                                
    num_sequences = 0                                           
    for position in neighbors(start_position):                  
        num_sequences += count_sequences(position, num_hops - 1)
    return num_sequences                                        
                                                                
if __name__ == '__main__':                                      
    print(count_sequences(6, 2))                                </code></pre><p>That’s it! Combine this with a function to compute the neighbors and you’ve produced a working solution! At this point, you should pat yourself on the back. If you scroll down you’ll notice we’ve still got a lot of ground to cover, but this point is a milestone. Producing any working solution already sets you apart from a surprising number of candidates.</p><p>This next question is one you’re going to be hearing a lot from me: what is the Big-O complexity of this solution? For those who don’t know, Big-O complexity is (informally) a sort of shorthand for the rate at which the amount of computation required by a solution grows as a function of the size of the input. For this problem, the size of the input is the number of hops. If you’re interested in the proper mathematical definition, you can read more <a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="noopener nofollow">here</a>.</p><p>For this implementation, every call to <code>count_sequences()</code> recursively calls <code>count_sequences()</code> at least twice, because each key has at least two neighbors. Since we recurse a number of times equal to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</a></em></p>]]>
            </description>
            <link>https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711094</guid>
            <pubDate>Wed, 07 Oct 2020 18:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL2 – Installation Tutorial for Graphical Windows Subsystem on Linux]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24711054">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://l-o-o-s-e-d.net/wsl2 | <a href="https://web.archive.org/web/*/https://l-o-o-s-e-d.net/wsl2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><h2>WSL2</h2></p>

            

            <div>
              <p>06:00pm | 10/05/2020<br>Daniel Tompkins</p>
              


 
            </div>

            <p>
              <h3>Microsoft 💔 Linux</h3>
            </p>

            <div>
              <p>In 2001, Microsoft's former CEO— Steve Ballmer— was <a target="_blank" href="https://www.theregister.com/2001/06/02/ballmer_linux_is_a_cancer/">quoted</a> by the online tech news publication, <em>The Register</em>, saying:</p>
              <p>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches</p>
              <p>Fast-forward 15 years into the future— at Microsoft's developer conference, <em>Build 2016</em>— and Gates' tech behemoth reveals a sudden volte-face. The current CEO, Satya Nadella, announces Windows Subsystem for Linux. With WSL, Microsoft is taking some of the most popular Linux distributions and making them available within Windows through the Microsoft Store.</p>
              <p>According to a <a target="_blank" href="https://w3techs.com/technologies/overview/operating_system">W<sup>3</sup>Techs survey</a>, Unix operating systems (the under-pinning OS of Linux, as well as MacOS) make up 71% of the Web, the remaining 29% being Windows. Additionally, every Android phone, tablet and smart TV runs on a modified version of the Linux kernel. So, I guess if you can't beat 'em, join 'em?</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              <p><img alt="W3Techs Survey on Web OS's, Unix: 71%, Windows: 29%" data-src="assets/img/wsl2/w3techs_webservers.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              </p>
            </a>

            <p>Whether or not its because of Microsoft's good graces or some ulterior motive, I know having an easily accessible Unix-type environment available on Windows has been a godsend for me and for so many other developers.</p>

            <p>
              <h3>What's so great about WSL?</h3>
            </p>

            <div>
              <p>Before WSL, developers running Windows had two options: 1) a virtual machine (VM), or 2) dual-booting. Running a virtual machine uses up more resources than WSL. It can also be difficult to integrate hardware and files between the host machine and the VM. Dual-booting allows for a full-fledged install on a separate disk partition; but it requires a restart any time you want to switch between OS's.</p>
              <p>Windows Subsystem on Linux doesn't integrate with the host's hardware perfectly— for example, NVIDIA is still working on <a target="_blank" href="https://developer.nvidia.com/cuda/wsl">CUDA drivers</a> that will take advantage of GPU resources from within WSL. However, for Linux developers who are frequently running CAD software or Adobe Suite (which are <a target="_blank" href="https://appdb.winehq.org/objectManager.php?iId=17&amp;sClass=application">difficult-to-impossible</a> to install on Linux), WSL can be a fantastic partner.</p>
            </div>

            <p>
              <h3>WSL1 vs WSL2</h3>
            </p>

            <div>
              <p>More recently, Microsoft announced WSL2— an update that allows for a more complete Linux kernel to run on a Windows machine. This made it much easier to install a variety of software that had been difficult to run on the previous, WSL1. WSL2 is very similar to running a virtual machine (in fact it uses Microsoft's hyperV virtual machines).</p>
              <p>However, using WSL2 (as opposed to installing a Linux distro through VirtualBox, or another VM manager) provides some minor performance benefits since Microsoft has optimized it to integrate with Windows' services. If you want, I recommend reading Microsoft's own WSL1-vs-WSL2 <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">feature comparison</a> docs.</p>
            </div>

            <p>
              <h3>Alright, so how do I install WSL2?</h3>
            </p>

            <div>
              <p>Microsoft has clean, straight-forward <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">installation documentation</a> for WSL and WSL2. You can refer to that tutorial if you get stuck, or just follow the steps outlined below. Before starting, make sure you update your Windows 10 installation with the most recent build.</p>
              <p>I'll also be going one-step further, and showing you how to run a Linux GUI using WSL2 and VcXsrv (display forwarding). If you're more of a visual-learner, I've also included an installation speedrun <a target="_blank" href="https://www.youtube.com/embed/gtXIzVM5wZE">video</a> that follows the same steps outlined below (<em>edit: I forgot step 11 in the video, and it's a critical one! Make sure you do that!</em>).</p>
            </div>

            <div>
              <p><b>1. Enable WSL Feature</b></p>
              <p>First you need to enable the Windows Subsystem on Linux feature by right-clicking on Powershell from the start menu and clicking "Run as Administrator".</p>
              <p>Then, paste the following command and hit "Enter"— don't close the Powershell!</p>
              <pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</code></pre>
            </div>

            <div>
              <p><b>2. Enable WSL2 Virtual Machine Feature</b></p>
              <p>After the last command is finished, paste the following command in the same Administrator-level shell, and hit "Enter" to enable the WSL2 VM. Again, keep this shell open.</p>
              <pre><code>dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</code></pre>
            </div>

            <div>
              <p><b>3. Download and Install the WSL2 Linux Kernel Update</b></p>
              <p>Click <a target="_blank" href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">here</a> to download the Microsoft executable for installing the WSL2 Linux Kernel update. Once it's finished downloading, double-click the executable and follow the installation steps. This part's pretty straightforward</p>
            </div>

            <div>
              <p><b>4. Set WSL2 as Default Version</b></p>
              <p>Copy and paste the following command in Powershell to set WSL2 to be the default version:</p>
              <pre><code>wsl --set-default-version 2</code></pre>
            </div>

            <div>
              <p><b>5. Install Ubuntu 20.04 from the Microsoft Store</b></p>
              <p>Click the start menu and open the Microsoft Store. Search for "Ubuntu 20.04" and install this Linux distro. If you want to use another distro, that's fine; but Ubuntu 20.04 is compatible with the Regolith Linux desktop GUI we'll be installing in just a bit.</p>
            </div>

            <div>
              <p><b>6. Ubuntu 20.04 Initial Setup</b></p>
              <p>Once Ubuntu is done installing, click "Launch" to initiate first-time installation setup. You'll be prompted to put in a username and password.</p>
            </div>

            <div>
              <p><b>7. Make sure You're Using WSL2</b></p>
              <p>At this point, it might be a good idea to double-check that WSL is using version 2 by default. Open a command prompt (or use Powershell if it's still open) to paste in the following command:</p>
              <pre><code>wsl --list --verbose</code></pre>
            </div>

            <div>
              <p><b>8. Download and Install VcXsrv</b></p>
              <p>VcXsrv is an X Server that we'll use to view the GUI from WSL2.</p>
              <p>There are a few other display-forwarding servers available (like <a target="_blank" href="https://sourceforge.net/projects/xming/">Xming</a>), but I've found VcXsrv works the best. Download the executable <a target="_blank" href="https://sourceforge.net/projects/vcxsrv/">here</a> and click through the installation steps.</p>
            </div>

            <div>
              <p><b>9. Install Regolith Desktop</b></p>
              <p>I have <a target="_blank" href="https://l-o-o-s-e-d.net/regolith">Regolith Desktop</a> installed on one of my PCs, and it's fantastic. It's preconfigured to use the i3 window manager which I find incredibly efficient for its tiling and hotkey features.</p>
              <p>A <em>loosed</em> reader, Rodrigo, asked me use Regolith for the tutorial; but if you want to install a different GUI you can! To install Regolith Desktop, open your fresh Ubuntu install, and paste in the following lines:</p>
              <pre><code>sudo add-apt-repository ppa:regolith-linux/release</code></pre>
              <pre><code>sudo apt install regolith-desktop i3xrocks-net-traffic i3xrocks-cpu-usage i3xrocks-time</code></pre>
              <p>It's a lot of packages, so it'll take some time.</p>
            </div>

            <div>
              <p><b>10. Change the "Mod" Key</b></p>
              <p>Regolith, or rather i3-wm, uses the Super (Windows) key as the hotkey prefix by default. Since you're running this GUI within Windows, you'll run into a lot of overlap between Windows' and i3-wm's preconfigured shortcuts.</p>
              <p>For this reason, I recommend swapping the Super key for the Alt key. To  change the Mod key mapping use the Vim or Nano text editors to open the configuration file located at:</p>
              <pre><code>vim /etc/regolith/i3/config</code></pre>
              <p>On line 42 and 43, you'll find the Mod key assignment. Switch "Mod1" and "Mod4" and you'll be good to go! Your edited lines should look like this:</p>
              <pre><code>set_from_resource $mod i3-wm.mod Mod1</code></pre>
              <pre><code>set_from_resource $alt i3-wm.alt Mod4</code></pre>
              <p>If you're using Vim, hit "Escape" and type ":wq", then hit "Enter" to write and quit the file. You can check out the <a target="_blank" href="https://regolith-linux.org/regolith-site-r13/docs/howto/super-to-alt/">official Regolith tutorial</a> on making these changes if you get stuck.</p>
            </div>

            <div>
              <p><b>11. Export DISPLAY parameter</b></p>
              <p>Another critical edit (that I forgot to put in the video— oops 🙃) is to export the DISPLAY variable. Since WSL2 is a VM, it has it's own IP address (which can change at each startup). As a result, you'll need to add a couple lines to your bash profile for VcXsrv to connect to WSL2.</p>
              <p>To open your ".bashrc" with Vim:</p>
            </div>
            <div>
              <pre><code>vim ~/.bashrc</code></pre>
              <p>Press and hold Shift then press "G" to jump to the bottom of the file. On two new lines, paste in the following code:</p> 
              <pre><code>export DISPLAY=$(awk '/nameserver / {print $2; exit}' /etc/resolv.conf 2&gt;/dev/null):0<br>export LIBGL_ALWAYS_INDIRECT=1</code></pre>
            </div>

            <div>
              <p><b>12. Open and Configure VcXsrv</b></p>
              <p>Click the start menu and type in "Xlaunch" then hit "Enter" to run VcXsrv. Click the "One window without titlebar" option (you can explore the others later, if you want) and click next. Leave it on "Start no client" and click next. Then, in the "Additional parameters" input, add "-ac" and click next. I recommend clicking "Save configuration" for ease of use.</p>
              <p>At this point, you should have a black screen waiting to accept a display input.</p>
            </div>

            <p><b>13. Run Regolith Desktop</b></p>
            <p>The last thing to do is run the magic line:</p>
            <div>
              <pre><code>i3-gnome-flashback-session</code></pre>
              <p>You should then see a graphical Regolith Desktop appear in the VcXsrv window! Huzzah! Feel free to play around with your new graphical WSL2 setup. To see an overview of the available shortcuts, use "Alt+Shift+?" to bring up the help menu. You can find more help in Regolith's official <a target="_blank" href="https://regolith-linux.org/docs/">documentation</a>.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              <p><img alt="Regolith Desktop with Windows 10 Taskbar and i3 tiling running on WSL2" data-src="assets/img/wsl2/regolith_screenshot.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              </p>
            </a>

            <p>
              </p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://l-o-o-s-e-d.net/wsl2">https://l-o-o-s-e-d.net/wsl2</a></em></p>]]>
            </description>
            <link>https://l-o-o-s-e-d.net/wsl2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711054</guid>
            <pubDate>Wed, 07 Oct 2020 18:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Translation Units Considered Harmful?]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24710612">thread link</a>) | @ingve
<br/>
October 7, 2020 | https://cor3ntin.github.io/posts/translation_units/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/translation_units/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Let say you have some struct <code>square</code> you want to compute the area of.</p>
<p><code>struct square { int width; }</code></p>
<p>You could of course do that:</p>
<p><code>int area(square s) { return s.width * s.width; }</code></p>
<p>But, your friend Tony told you to use more functions, so instead you do that</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(square s) { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p><code>area</code> being the function you really care about it is defined first - after all, code reads from top to bottom.</p>
<p>As you may have guessed from the lack of <code>;</code> after the struct’s closing bracket, the above code is written in D.
I figure my readership isn’t really into D, so maybe you would prefer some <strong>Rust</strong>?</p>
<div><pre><code data-lang="rs"><span>pub</span><span> </span><span>fn</span> <span>area</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>width(s)<span> </span>*<span> </span>width(s)<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>fn</span> <span>width</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>s.width<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>struct</span> <span>Square</span><span> </span>{<span> </span>width: <span>i32</span> }<span>
</span></code></pre></div><p>You can even compute the area of you square <strong><em>at scale</em></strong> with go</p>
<div><pre><code data-lang="go"><span>func</span> <span>Area</span>(s square) <span>int</span> { <span>return</span> <span>width</span>(s) * <span>width</span>(s); }
<span>func</span> <span>width</span>(s square) <span>int</span> { <span>return</span> s.width }
<span>type</span> square <span>struct</span> { width  <span>int</span> }
</code></pre></div><p>Or even <strong>Swift</strong>ly.</p>
<div><pre><code data-lang="swift"><span>func</span> <span>area</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> width(s:s) * width(s:s); }
<span>func</span> <span>width</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> s.width }
<span>struct</span> <span>Square</span> { <span>var</span> <span>width</span>:<span>Int</span> = <span>0</span>; }
</code></pre></div><p>But of course, <em>you</em> will worry about the overhead and will want the language the most performant (that’s not a word).
Eager to please and impress, let me copy the D code and add that oh-so-important semi-colon.</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>area</span>(square s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p>That’s nice, isn’t it?  Interesting how most languages look alike.
Hum, wait, that doesn’t work???!!!</p>
<p><code>error: 'width' was not declared in this scope</code></p>
<p>But, you stupid thing, it’s <em>RIGHT THERE</em>.
I declared everything in the global scope like a maniac, can’t you see?</p>
<p>Alas, the standard makes the compiler blind.</p>
<blockquote>
<p>In the definition of a function that is a member of namespace N, a name used after the function’s declarator-id23 shall be declared before its use in the block in which it is used or in one of its enclosing blocks ([stmt.block]) or shall be declared before its use in namespace N or, if N is a nested namespace, shall be declared before its use in one of N’s enclosing namespaces.</p>
</blockquote>
<p>Of course, this makes no sense, a compiler can really easily parse the declaration independently of the definition, as
proven by other languages. Or you know, C++ classes. (imagine replacing a big namespace with a class full of static methods and nested types)
Unless of course, it’s a performance thing.
But, you are a very great engineer, so you wouldn’t let a source file grow above a few hundred lines of code, would you?
I bet your code is beautiful, like this small self-contained super useful program</p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span><span></span><span>int</span> <span>main</span> () {
    std::cout &lt;&lt; <span>"Hello world</span><span>\n</span><span>"</span>;
}
</code></pre></div><p>Which on my system expands to about <em>33000</em> lines of code. The freaking thing. But more on that later.</p>
<p>Let’s go back to square one.
C++, in its infinite wisdom, lets us forward-declare functions, so we can write this:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>width</span>(<span>const</span> square&amp; s);
<span>int</span> <span>area</span>(<span>const</span> square&amp; s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) { <span>return</span> s.width; }
</code></pre></div><p>Which is nice and dandy, if you squint.</p>
<p>Besides requiring you to get the exact declaration of functions perfectly right - which is hard to maintain, lots of entities are not forward-declarable,
notably type alias, templated types, etc.
Which is an odd limitation given that where forward declaring a function require you
to know the precise signature, for types you are merely trying to introduce a name.</p>
<h2 id="noexcept">noexcept</h2>
<p>You will notice that <code>area</code> never throws.
That is, there is no subexpression of <code>area</code> that can throw, ever.</p>
<p>You can check that it does not.</p>
<p><code>static_assert(noexcept(area(square{})));</code></p>
<p>Inevitably,  that fails.
<code>error: static assertion failed</code>.
We indeed forgot to tell the compiler that our function could not throw.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span>;
<span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> s.width; }
</code></pre></div><p>Notice that we need to add <code>noexcept</code> on all declarations, including the forward declarations.
And, you can lie to the compiler pretty easily.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> {
    <span>return</span> width(s) * width(s);
}

<span>int</span> <span>width</span>(<span>const</span> square&amp; s) {
    <span>throw</span> <span>42</span>;
}
</code></pre></div><p>The above code will <code>std::terminate()</code>, you know that the compiler knows that, everybody knows that.</p>
<p>So…what functions should be marked <code>noexcept</code>?
It’s pretty simple actually. All the functions that can not throw.
That is the functions that:</p>
<ul>
<li>Don’t contain a <code>throw</code> exception</li>
<li>Don’t call non-noexcept functions</li>
</ul>
<p>Notice the double (triple?) negative.</p>
<p>So you, as a developer striving to mark all function that can be <code>noexcept</code> as such,
have to walk the call tree recursively until you can ascertain that the call chain will never throw
or actually might (because one callee does throw, or is at a C interface boundary, etc).
One argument against exceptions is that it makes reasoning about control flow harder:
Exceptions more or less force you to reason about the control flow of the whole program at every time.
<code>noexcept</code> is supposed to solve that, but, to put that <code>noexcept</code> keyword confidently, you still need
to do that analyze. The chances you get it wrong are high.
If you write generic code, you will have to tell the compiler that a symbol is noexcept
if all of it’s subexpression is noexcept manually.</p>
<p>And the compiler can not trust you that the function will indeed not throw, so implementers will inject calls to <code>std::terminate</code>
here and there, negating somewhat the performance benefits of marking the function <code>noexcept</code> in the first place.</p>
<p>Let’s rewrite our code using lambda instead</p>
<div><pre><code data-lang="cpp"><span>auto</span> width = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> s.width;
};
<span>auto</span> area = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> <span>width</span>(s) * width(s);
};
</code></pre></div><p>Of course, lambdas cannot be forward declared.
So I had to reorganize the code.</p>
<p>And now, despite the lack of <code>noexcept</code> keyword,
<code>static_assert(noexcept(area(square{})));</code> passes.</p>
<p><strong>What is happening?</strong></p>
<p>It turns out that the compiler is pretty good at knowing which functions are <code>noexcept</code>.
In the case of lambdas, the definition will always be visible to the compiler before any invocation,
so it can implicitly mark it no except and do the work for us. This allowed as part of C++20.</p>
<h3 id="what-does-noexcept-even-mean">What does noexcept even mean?</h3>
<p>I’m not saying that <code>noexcept</code> would not be necessary in an ideal world, because it has more than one meaning
and people use it differently. Notably, <code>noexcept</code> might mean:</p>
<ul>
<li>Do not generate exception handling code for this function</li>
<li>This function does not throw</li>
<li>This function will <em>never</em> throw</li>
</ul>
<p>The first statement is a request for the compiler, the second is an assertion for both the compiler and human readers,
while the last one is exclusively for people.</p>
<p>So <code>noexcept</code> would remain interesting at API boundary as a contract between people even if the compiler could decide
for itself whether the function was actually non-throwing.</p>
<h2 id="transaction_safe">transaction_safe</h2>
<p>The Transactional Memory TS defines the notion of <em>transaction safe expression</em> as follow:</p>
<blockquote>
<p>An expression is transaction-unsafe if it contains any of the following as a potentially-evaluated subexpression (3.2[basic.def.odr]):</p>
</blockquote>
<blockquote>
<ul>
<li>an lvalue-to-rvalue conversion (4.1 [conv.lval]) applied to a volatile glvalue</li>
<li>an expression that modifies an object through a volatile glvalue</li>
<li>the creation of a temporary object of volatile-qualified type or with a subobject of volatile-qualified type</li>
<li>a function call (5.2.2 expr.call) whose postfix-expression is an id-expression that names a non-virtual
function that is not transaction-safe</li>
<li>an implicit call of a non-virtual function that is not transaction-safe</li>
<li>any other <strong>call of a function, where the function type is not “transaction_safe function”</strong></li>
</ul>
</blockquote>
<p>(Emphasis mine)</p>
<p>The details are not important, but, basically, a <code>transaction_safe</code> safe expression is one that doesn’t touch volatile objects.
And only call functions with the same properties.
That’s probably upward of 99% of functions - I suspect the very terrible default exists for compatibility reasons.
The important part is that you have to tag all your functions or hope that the property holds true recursively.
(Like <code>noexcept</code>, you can lie, by marking a function <code>transaction_safe</code> even if a callee is not itself <code>transaction_safe</code>, opening the door to UB).
An issue that seems to hold this TS back.</p>
<h2 id="constexpr">constexpr</h2>
<p><code>constexpr</code> functions are a bit different. The compiler knows what functions are candidate <code>constexpr</code>.
Most of the time it will constant evaluate them regardless of whether they are actually marked as such.
The keyword is required to ensure that the compiler will actually do the constant evaluation when it can and, most importantly,
because removing the constexpr-ness of a function may be a source breaking change - (if that function is called during the evaluation of a <code>constexpr</code> variable).
By its very nature, <code>constexpr</code> implies that <code>constexpr</code> functions are defined somewhere is the TU. And everything not defined in the TU cannot be constant-evaluated.
<a href="https://wg21.link/p1235">A proposal for C++20 proposes to make it implicit in some cases</a></p>
<p>For now, we are left with the following code, and it is on you to use the appropriate qualifiers.</p>
<div><pre><code data-lang="cpp"><span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe;
<span>constexpr</span> <span>int</span> <span>area</span>(square s) <span>noexcept</span> transaction_safe  { <span>return</span> width(s) * width(s); }
<span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe { <span>return</span> s.width; }
</code></pre></div><p>As of C++20, <code>constexpr</code> functions can throw. The committee is also considering making <code>new</code> expressions
<code>noexcept</code> by 23 or 26 so we are slowly getting to a place where 95%+ of functions will be both <code>constexpr</code> and <code>noexcept</code>
eligible and will have to be marked manually.</p>
<p><strong>Is there a better way ?</strong></p>

<p>A source file and its included headers form a translation unit.
Multiple translations units form a program.</p>
<p>Sounds simple enough right?
It’s actually <em>simpler</em> than right.</p>
<p>Headers and sources files are a bit of a lie we tell ourselves.
As far as I can tell, the term “header” only appear in the standard as to name the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/translation_units/">https://cor3ntin.github.io/posts/translation_units/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/translation_units/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710612</guid>
            <pubDate>Wed, 07 Oct 2020 17:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generalizing 'jq' and Traversal Systems using optics and standard monads]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24710565">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://chrispenner.ca/posts/traversal-systems | <a href="https://web.archive.org/web/*/https://chrispenner.ca/posts/traversal-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Hi folks! Today I'll be chatting about <strong>Traversal Systems</strong> like <strong>jq</strong> and <strong>XPath</strong>; we're going to discover which properties make them useful, then see how we can replicate their most useful behaviours in Haskell using (almost entirely) pre-ols!existing standard Haskell tools! Let's go!</p>
<h2 id="whats-a-traversal-system">What's a Traversal System?</h2>
<p>First off I'll admit that "Traversal System" is a name I just came up with, you probably won't find anything if you search for it (unless this post really catches on 😉).</p>
<p>A <strong>Traversal System</strong> allows you dive deeply into a piece of data and may allow you to fetch, query, and edit the structure as you go while maintaining references to other pieces of the structure to influence your work. The goal of most Traversal Systems is to make this as painless and concise as possible. It turns out that this sort of thing is <strong>incredibly useful</strong> for manipulating JSON, querying HTML and CSS, working with CSVs, or even just handling standard Haskell Records and data-types.</p>
<p>Some good examples of existing <strong>Traversal Systems</strong> which you may have heard of include the brilliant <a href="https://stedolan.github.io/jq/">jq</a> utility for manipulating and querying JSON, the <strong>XPath</strong> language for querying XML, and the <a href="https://github.com/noprompt/meander">meander</a> data manipulation system in Clojure. Although each of these systems may appear drastically different at a glance, they both <em>accomplish many of the same goals</em> of manipulating and querying data in a concise way.</p>
<p>The similarities between these systems intrigued me! They seem so similar, but yet still seem to share very little in the way of structure, syntax, and prior art. They re-invent the wheel for each new data type! Ideally we could recognize the useful behaviours in each system and build a generalized system which works for any data type.</p>
<p>This post is an attempt to do exactly that; we'll take a look at a few things that these systems do well, then we'll re-build them in Haskell using standard tooling, all the while abstracting over the type of data!</p>
<h2 id="optics-as-a-basis-for-a-traversal-system">Optics as a basis for a traversal system</h2>
<p>For any of those who know me it should be no surprise that my first thought was to look at optics (i.e. Lenses and Traversals). In general I find that optics solve a lot of my problems, but in this case they are particularly appropriate! Optics inherently deal with the idea of diving deep into data and querying or updating data in a structured and compositional fashion.</p>
<p>In addition, optics also allow abstracting over the data type they work on. There are pre-existing libraries of optics for working with JSON via <a href="https://hackage.haskell.org/package/lens-aeson"><code>lens-aeson</code></a> and for html via <a href="https://hackage.haskell.org/package/taggy-lens"><code>taggy-lens</code></a>. I've written optics libraries for working with <a href="https://hackage.haskell.org/package/lens-csv">CSVs</a> and even <a href="https://hackage.haskell.org/package/lens-regex-pcre">Regular Expressions</a>, so I can say confidently that they're a brilliantly adaptable tool for data manipulation.</p>
<p>It also happens that optics are well-principled and mathematically sound, so they're a good tool for studying the properties that a system like this may have.</p>
<p>However, optics themselves don't provide everything we need! Optics are rather obtuse, in fact I wrote <a href="https://leanpub.com/optics-by-example">a whole book</a> to help teach them, and they lack clarity and easy of use when it comes to building larger expressions. It's also pretty tough to work on one part of a data structure while referencing data in another part of the same structure. My hope is to address some of these short comings in this post.</p>
<p>In this particular post I'm mostly interested in explaining a framework for traversal systems in Haskell, we'll be using many standard <a href="https://hackage.haskell.org/package/mtl"><strong>mtl</strong></a> Monad Transformers alongside a lot of combinators from the <a href="https://hackage.haskell.org/package/lens"><strong>lens</strong></a> library. You won't need to understand any of these intimately to get the <em>gist</em> of what's going on, but I won't be explaining them in depth here, so you may need to look elsewhere if you're lacking a bit of context.</p>
<h2 id="establishing-the-problem">Establishing the Problem</h2>
<p>I'll be demoing a few examples as we go along so let's set up some data. I'll be working in both <strong>jq</strong> and <strong>Haskell</strong> to make comparisons between them, so we'll set up the same data in both <strong>JSON</strong> and Haskell.</p>
<p>Here's a funny lil' company as a JSON object:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>{</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span>"staff"</span><span>:</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>      <span>[</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"1"</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"bob"</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-7"><a href="#cb1-7"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Rocky"</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>              <span>}</span><span>,</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Bullwinkle"</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"dog"</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>              <span>}</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>            <span>]</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>        <span>}</span><span>,</span></span>
<span id="cb1-15"><a href="#cb1-15"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"2"</span></span>
<span id="cb1-16"><a href="#cb1-16"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"sally"</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-18"><a href="#cb1-18"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Inigo"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-20"><a href="#cb1-20"></a>              <span>}</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>            <span>]</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>        <span>}</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>      <span>]</span><span>,</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>    <span>"salaries"</span><span>:</span> <span>{</span></span>
<span id="cb1-25"><a href="#cb1-25"></a>        <span>"1"</span><span>:</span> <span>12</span><span>,</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>        <span>"2"</span><span>:</span> <span>15</span></span>
<span id="cb1-27"><a href="#cb1-27"></a>    <span>}</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span>}</span></span></code></pre></div>
<p>And here's the same data in its Haskell representation, complete with generated optics for each record field.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>Company</span> <span>=</span> <span>Company</span> {<span> _staff ::</span> [<span>Employee</span>]</span>
<span id="cb2-2"><a href="#cb2-2"></a>                       ,<span> _salaries ::</span> <span>M.Map</span> <span>Int</span> <span>Int</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>                       } <span>deriving</span> <span>Show</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span>data</span> <span>Pet</span> <span>=</span> <span>Pet</span> {<span> _petName ::</span> <span>String</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>               ,<span> _petType ::</span> <span>String</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>               } <span>deriving</span> <span>Show</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span>data</span> <span>Employee</span> <span>=</span> <span>Employee</span> {<span> _employeeId ::</span> <span>Int</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>                         ,<span> _employeeName ::</span> <span>String</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>                         ,<span> _employeePets ::</span> [<span>Pet</span>]</span>
<span id="cb2-10"><a href="#cb2-10"></a>                         } <span>deriving</span> <span>Show</span></span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a>makeLenses '<span>'Company</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>makeLenses '<span>'Pet</span></span>
<span id="cb2-14"><a href="#cb2-14"></a>makeLenses '<span>'Employee</span></span>
<span id="cb2-15"><a href="#cb2-15"></a></span>
<span id="cb2-16"><a href="#cb2-16"></a><span>company ::</span> <span>Company</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>company <span>=</span> <span>Company</span> [ <span>Employee</span> <span>1</span> <span>"bob"</span> [<span>Pet</span> <span>"Rocky"</span> <span>"cat"</span>, <span>Pet</span> <span>"Bullwinkle"</span> <span>"dog"</span>] </span>
<span id="cb2-18"><a href="#cb2-18"></a>                  , <span>Employee</span> <span>2</span> <span>"sally"</span> [<span>Pet</span> <span>"Inigo"</span> <span>"cat"</span>]</span>
<span id="cb2-19"><a href="#cb2-19"></a>                  ] (M.fromList [ (<span>1</span>, <span>12</span>)</span>
<span id="cb2-20"><a href="#cb2-20"></a>                                , (<span>2</span>, <span>15</span>)</span>
<span id="cb2-21"><a href="#cb2-21"></a>                                ])</span></code></pre></div>
<h2 id="querying">Querying</h2>
<p>Let's dive into a few example queries to test the waters! First an easy one, let's write a query to find all the pets owned by any of our employees.</p>
<p>Here's how it looks in <strong>jq</strong>:</p>
<pre><code>$ cat company.json | jq '.staff[].pets[] | select(.type == "cat")'
{
  "name": "Rocky",
  "type": "cat"
}
{
  "name": "Inigo",
  "type": "cat"
}</code></pre>
<p>We look in the <code>staff</code> key, then <em>enumerate</em> that list, then for each staff member we enumerate their cats! Lastly we filter out anything that's not a cat.</p>
<p>We can recognize a few hallmarks of a <strong>Traversal System</strong> here. <strong>jq</strong> allows us to "dive" down deeper into our structure by providing a path to where we want to be. It also allows us to <strong>enumerate</strong> many possibilities using the <code>[]</code> operator, which will forward <strong>each</strong> value to the rest of the pipeline one after the other. Lastly it allows us to <strong>filter</strong> our results using <code>select</code>.</p>
<p>And in Haskell using optics it looks like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>&gt;&gt;&gt;</span> toListOf (staff <span>.</span> folded <span>.</span> employeePets <span>.</span> folded <span>.</span> filteredBy (petType <span>.</span> only <span>"cat"</span>)) company</span>
<span id="cb4-2"><a href="#cb4-2"></a>[ <span>Pet</span> {_petName <span>=</span> <span>"Rocky"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-3"><a href="#cb4-3"></a>, <span>Pet</span> {_petName <span>=</span> <span>"Inigo"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-4"><a href="#cb4-4"></a>]</span></code></pre></div>
<p>Here we use "toListOf" along with an optic which "folds" over each staff member, then folds over each of their pets, again filtering for "only" cats.</p>
<p>At a glance the two are extremely similar!</p>
<p>They each allow the <em>enumeration</em> of multiple values, in <strong>jq</strong> using <code>[]</code> and in optics using <code>folded</code>.</p>
<p>Both implement some form of <strong>filtering</strong>, <strong>jq</strong> using <code>select</code> and our optics with <code>filteredBy</code>.</p>
<p>Great! So far we've had no trouble keeping up! We're already starting to see a lot of similarities between the two, and our solutions using optics are easily generalizable to any data type.</p>
<p>Let's move on to a more complex example.</p>
<h2 id="keeping-references">Keeping references</h2>
<p>This time we're going to print out each pet and their owner!</p>
<p>First, here's the <strong>jq</strong>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a>$ <span>cat</span> join.json <span>|</span> <span>jq</span> <span>'</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>    .staff[] </span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>  | .name as $personName </span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span>  | .pets[] </span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>  | "\(.name) belongs to \($personName)"</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span>'</span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb5-9"><a href="#cb5-9"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Here we see a new feature in <strong>jq</strong> which is the ability to maintain <strong>references</strong> to a part of the structure for later while we continue to dig deeper into the structure. We're grabbing the name of each employee as we enumerate them and saving it into <code>$personName</code> so we can refer to this later on. Then we enumerate each of the pets and use string interpolation to describe who owns each pet.</p>
<p>If we try to stick with optics on their own, well, it's possible, but unfortunately this is where it all starts to break down, look at this absolute mess:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>owners ::</span> [<span>String</span>]</span>
<span id="cb6-2"><a href="#cb6-2"></a>owners <span>=</span> </span>
<span id="cb6-3"><a href="#cb6-3"></a>  company <span>^..</span> </span>
<span id="cb6-4"><a href="#cb6-4"></a>    (staff <span>.</span> folded <span>.</span> reindexed _employeeName selfIndex <span>&lt;.</span> employeePets <span>.</span> folded <span>.</span> petName) </span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span>.</span> withIndex </span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span>.</span> to (\(eName, pName) <span>-&gt;</span> pName <span>&lt;&gt;</span> <span>" belongs to "</span> <span>&lt;&gt;</span> eName)</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span>&gt;&gt;&gt;</span> owners</span>
<span id="cb6-9"><a href="#cb6-9"></a>[ <span>"Rocky belongs to bob"</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>, <span>"Bullwinkle belongs to bob"</span></span>
<span id="cb6-11"><a href="#cb6-11"></a>, <span>"Inigo belongs to sally"</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>]</span></code></pre></div>
<p>You can bet that nobody is calling that "easy to read". Heck, I wrote a book on optics and it still took me a few tries to figure out where the brackets needed to go!</p>
<p>Optics are great for handling a <em>single</em> stream of values, but they're much worse at more complex expressions, especially those which require a reference to values that occur <em>earlier</em> in the chain. Let's see how we can address those shortcomings as we build our <strong>Traversal System</strong> in Haskell.</p>
<p>Just for the <strong>jq</strong> aficionados in the audience I'll show off this alternate version which uses a little bit of <em>magic</em> that <strong>jq</strong> does for you.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a> $ <span>cat</span> company.json <span>|</span> <span>jq</span> <span>'.staff[] | "\(.pets[].name) belongs to \(.name)"'</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Depending on your experience may be less <strong>magical</strong> and more <strong>confusing</strong> 😬. Since the final expression contains an <strong>enumeration</strong> (i.e. <code>\(.pets[].name)</code>) <strong>jq</strong> will expand the final term once for each value in the enumeration. This is really cool, but unfortunately a bit "less principled" and tough to understand in my opinion.</p>
<p>Regardless, the behaviour is the same, and we haven't replicated it in Haskell satisfactorily yet, let's see what we can do about that!</p>
<h2 id="monads-to-the-rescue-again">Monads to the rescue (again...)</h2>
<p>In Haskell we love our <strong>embedded DSLs</strong>; if you give a Haskeller a problem to solve, you can bet that 9 times out of 10 they'll solve it with a custom monad and an DSL 😂. Well, I'm sorry to tell you that I'm no different!</p>
<p>We'll be using a monad to address the readability problem of the last optics solution, but the question is... <em>which</em> monad?</p>
<p>Since all we're doing at the moment is <strong>querying</strong> data, we can make use of the esteemed <strong>Reader Monad</strong> to provide a context for our query.</p>
<p>Here's what that last query looks like when we use the <a href="https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Reader.html"><code>Reader</code></a> monad with the relatively …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrispenner.ca/posts/traversal-systems">https://chrispenner.ca/posts/traversal-systems</a></em></p>]]>
            </description>
            <link>https://chrispenner.ca/posts/traversal-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710565</guid>
            <pubDate>Wed, 07 Oct 2020 17:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Competition and Quarter-Life Crises]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24710496">thread link</a>) | @arvarik
<br/>
October 7, 2020 | https://www.arvarik.com/competition-quarter-life-crisis | <a href="https://web.archive.org/web/*/https://www.arvarik.com/competition-quarter-life-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Growing up in an Indian household and in one of the most
<a href="https://en.wikipedia.org/wiki/New_Jersey#Demographics">diverse states/towns</a> in the US, it’s not easy to avoid
the competitive stress that derives from first generation families.</p><p>From test scores, which classes I take, SAT scores, college admissions, sports performance, internships received etc.,
the first 22 years of my life have been filled with constant competition with others. As a result I’ve turned out to
be a pretty competitive person - if there was anything that I liked, I not only wanted to be good at it, but I also wanted
to be better at it than others.</p><p>Something happened right around when I graduated college and joined the workforce. My Saturdays were totally free and
weren’t consumed by an all-day track meet where I would compete in the 800m and gruel over two laps trying to edge out
other people over the finish line. After work, my weekday nights consisted of me making dinner instead of living in the
library and taking caffeine pills to study for a test that I’ve been procrastinating to study for. </p><p>For the first time in my life there was no clear next step in what I had to do, and there was no clear competition that
I could engage in with peers. It was a dramatic change and something that I refer to as my quarter life crisis. It’s not
well documented in many places, but it’s a concept that I think is
<a href="https://en.wikipedia.org/wiki/Quarter-life_crisis">picking up steam</a> in recent years.</p><h3>What does a Quarter-Life Crisis look like?</h3><p>I think there’s one song that really encapsulates this feeling, The Beatles’
<a href="https://www.youtube.com/watch?v=8scSwaKbE64">Nowhere Man</a>. The opening lines go:</p><blockquote><p>He's a real nowhere man.
Sitting in his nowhere land.
Making all his nowhere plans for nobody</p></blockquote><p>In fact, the song is what inspired me to name my blog post <strong>Nowhere Plans</strong>. John Lennon was 25 when he wrote this,
and I think he really captures the general feeling of this time in one’s life.</p><p>Back when I was in college and high school I was really competitive with other people, whether in academics or sports,
and I felt I had a strong purpose - anything that I did was to get further in these pursuits. It was a nice and easy
framework to live life by. Decision making was incredibly easy.</p><p>Fast forward to work-life ~&gt; I felt that I couldn’t really relate much to my work peers, and all my college and high
school friends were vibing and doing their own thing in their respective companies. I spent my nights binge watching
shows, my weekends binge watching movies, and my free time working or hanging with peers talking about the binge
watched shows/movies. </p><p>The <a href="https://en.wikipedia.org/wiki/Seattle_Freeze">isolating</a> and incredibly gray city of Seattle didn’t help not
feeling like a nowhere man in nowhere land.</p><p>Maybe I’ll get a cat? Will that help find some purpose to be doing something? I’ll download some dating apps and try to
get a girlfriend, hopefully that should bring me closer to my next stage in life of marriage right? Should I go to grad
school? I have to, no, I need to do these things now! 😬</p><p>I was truly lost in what my next steps in life were going to be, and felt that I was just aimlessly swimming around in a sea of uncertainty.</p><h3>Swimming Out</h3><p>When 2019 had come, I knew I wanted to do something different. I made a list of things that were important to me and that I
wanted to achieve. Visiting friends more, learning to play the piano, getting back into running races, fixing my posture, volunteering etc. </p><p>But the biggest shift in my thinking during this time was to try to bring back competition in my life. No, not competition
with others like I had previously experienced all my life, but instead with something much easier to think about. Myself. </p><p>There’s a saying that you should “Compare yourself to who you were yesterday, not to who someone else is today”. People always
say that you’ll never find happiness comparing yourself to others, and that competitive stress is really bad for you. While that
is true, I also don’t think many people advocate for competition against yourself. It’s possibly because of the stress and
anxiety induced from competition, but if you’re anything like me, it’s necessary to find some purpose and bring back a fire
in you to go about and live life.</p><p>In 2019, I had worked on things I had never done in my life in order to be a better person than who I was in years past.
I’ll probably never be as fit as I was in college on the varsity XC/T&amp;F teams, but hey, in 2019 I
set <a href="https://www.strava.com/athletes/19875553">personal records</a> in
the 10 mile and marathon (granted it was my only time running them but that’s besides the point). </p><p>I also had an entirely different view in perceiving others. Anyone who has spent 5 min on LinkedIn can describe this
feeling - seeing other people who are really successful and do the things that you’ve always want to do is disheartening to
say the least. You feel like somewhere along your life path you made a wrong turn which didn’t lead you to where that other
person is. But, at the end of the day, that’s just life - there’s always going to be someone better than you at everything
you do, you just have to find solace in that you’re better than who you used to be.</p><h3>Where are you now?</h3><p>This past year has been wild. It felt like a decade fit into 9 months so far, but with all the major events and uncertainty
happening, I’ve never felt more certain about myself than I have now.</p><p>I try to focus on things that I really enjoy, and try to be better than my former self. I stopped going to my piano teacher
because of COVID, but still try to play the pieces that I remember learning every now and then while also trying to learn
some more music theory. Writing and deep diving on topics that I find interesting have always been a favorite past-time of
mine, why not start a blog and have others critique me to become better? And finally, if I’m going to make a career out of
my current profession, why not be the best that I can be in more ways than programming. I’ve engaged in more leadership
opportunities to mentor younger engineers and also participate in the daunting interviewing process but this time as an interviewer.</p><p>Through this process I’ve grown to know that I really enjoy helping and teaching others - it’s something that has helped me
envision what I want to be doing as I grow.</p><p>I don’t advise many people to live life with this much analysis on your past self, but if this story resonated with you I
encourage to try it out! It’s helped me get out of a quarter life crisis and will hopefully keep me going until my
inevitable mid-life crisis. Stay tuned for that post.</p></section></div>]]>
            </description>
            <link>https://www.arvarik.com/competition-quarter-life-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710496</guid>
            <pubDate>Wed, 07 Oct 2020 17:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust and Raspberry Pi Tide Clock]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24708345">thread link</a>) | @zdw
<br/>
October 7, 2020 | https://thefuntastic.com/blog/rust-tide-clock | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/rust-tide-clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-6f4ff34b=""><p><em>In this part 1 of 2 posts, I share the process of a heartwarming maker project built on top of Raspberry Pi and Rust. It's more a story than a how-to guide, but provides an interesting chronology of problems encountered. In part 2 I'll be getting technical and discussing Rust in-depth. Source code for this project can be found on <a href="https://github.com/thefuntastic/rust-tide-clock" target="_blank" rel="nofollow noopener noreferrer">Github</a></em></p>
<p>I had the good fortune to spend my summer with Alice's family who had recently moved to a seaside town. Tim, the patriarch of the family, was distraught to learn that, out of his impressive array of nautical implements, his tide clock readings were never accurate. This is the story of how we built him a surprise 60th birthday present he'd never forget: </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Clock-12.jpg" title="Picture completed Tide-Clock"></p>
<h2 id="the-problem-with-tides">The Problem with Tides</h2>
<p>Most people understand the moons gravitational pull causes a regular ebb and flow in water levels. Those concerned with the sea will likely recite 6 hours and 10-ish minutes as the duration between low and high tide. Consider a wristwatch or wall clock, most mechanical timepieces already track a daily period of 12 hours. With a small adjustment to gearing ratios, it would be easy enough to build a clock that reports instead the tidal cycle of 12 hours and 25 minutes. Indeed this is how most ornamental tide clocks work. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Wikipedia-Tide-clock.jpg" title="Picture of tide clock - Wikipedia"></p>
<p>I was surprised, however, to learn <a href="http://www.coastalwiki.org/wiki/Tidal_asymmetry_and_tidal_basin_morphodynamics" target="_blank" rel="nofollow noopener noreferrer">tides can be asymmetric</a>! Instead of six hours, it might take the tide seven hours to come in and five hours to go out again. Local environmental factors like the shallowness of an estuary basin can have a pronounced effect on tidal regularity. In extreme places, like the Gulf of Mexico, this can be enough to reduce the regular cycle from four tides a day to just two. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Graph.png" title="WorldTides.info graph of tide station in the Gulf of Mexico showing asymmetry changing to produce single daily tide"></p>
<p>A disaster for the clockmaker! This asymmetry also changes with the lunar cycle, so it's not even possible for a mechanical clock to be consistently wrong. It makes intuitive sense if you think about it. Water is "stuff". When the tide changes that stuff has to go somewhere. If something makes it hard for stuff to move about, like say sandbars in a shallow basin, it's going to make the stuff pile up. The bigger the change in stuff, like say near spring tide, the more piling up is going to happen. If that stuff is still hanging about when the tide changes, the net effect is going to be an asymmetric tide.</p>
<h2 id="making-with-embedded-devices">Making with Embedded Devices</h2>
<p>To my mind, this was the perfect application for an internet-of-things powered device. By outsourcing the problem and fetching data from an API it meant the source of truth would always be accurate. Furthermore, a digital display could accurately visualise the asymmetric ebbs and floods.</p>
<h3 id="on-choosing-raspberry-pi">On choosing Raspberry Pi</h3>
<p>Initially, I considered using an Arduino, as I already had one knocking about my toolbox, together with a compatible LED screen. Ultimately I chose the path of least resistance because the Raspberry Pi comes with an integrated WiFi chip. Unlike the Arduino, the Pi is a mini-computer running an entire operating system. This is the sledgehammer approach, but has advantages considering the project would eventually live in the hands of someone unfamiliar with embedded tech. If the WiFi connection were to drop or need changing, logging onto a desktop would be a much friendlier experience. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-21.jpg" title="Raspbian Desktop Interface running on Raspberry Pi"></p>
<p>Having settled on a Raspberry Pi build, the next job was to find a suitable display. Considering tides change relatively slowly, it was tempting to use an e-ink display for crazy power efficiency. That might be necessary if the clock was battery-powered, however, the need to keep the Pi running meant we were already committed to a plug-in power supply. In the end, I choose the 128x32 pixel <a href="https://thepihut.com/collections/waveshare/products/128x32-2-23inch-oled-display-hat-for-raspberry-pi" target="_blank" rel="nofollow noopener noreferrer">Waveshare 1305</a>. Its convenient "hat" form factor meant no soldering. Also, OLED looks crazy good compared to the standard LED screen I already had. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-3.jpg" title="Waveshare OLED screen shown attached to Raspberry Pi"></p>
<h3 id="on-choosing-rust">On Choosing Rust</h3>
<p>At this point, I was still unsure of which programming language to use. Whilst the Raspberry Pi can run anything that compiles to Linux, communication to the screen happens through the Pi's <code>GPIO</code> pins (<a href="https://en.wikipedia.org/wiki/General-purpose_input/output" target="_blank" rel="nofollow noopener noreferrer">General Purpose Input/Output</a>). All information is transmitted by setting pins high and low and feels reminiscent of working on Arduino and other embedded platforms. Even though the screen is just 128x32 (aka 4096) pixels, that's far more destinations than the Pi's 40 <code>GPIO</code> pins can individually address. Fortunately protocols, in this case <code>SPI</code>, exist to pack data into compressed blocks which can be sent over the limited bandwidth of the IO pins. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-31.jpg" title="Raspberry Pi 3 GPIO Pins"></p>
<p>The screen manufacturer-provided <a href="https://www.waveshare.com/wiki/2.23inch_OLED_HAT#Demo_codes" target="_blank" rel="nofollow noopener noreferrer">3 code samples</a>: 1 written in python and 2 written in C. Python was my immediate choice, given the online nature of the project, however, I simply couldn't get it to work. The two C samples were curious. One was built on top of a bring-your-own driver for the embedded Broadcom chip that controls <code>GPIO</code> pins. The other was written on top of <a href="https://github.com/WiringPi/WiringPi" target="_blank" rel="nofollow noopener noreferrer"><code>wiringPi</code></a>, which ships with Raspbian (aka the Pi flavoured Linux OS) and seems to be the blessed path for doing IO. However, I was saddened to learn this open source project was largely the efforts of a single person who has since <a href="http://wiringpi.com/wiringpi-deprecated/" target="_blank" rel="nofollow noopener noreferrer">stepped down as a maintainer</a> due to open source burnout. It's a worrying trend I'm seeing a lot lately. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-4.jpg" title="Waveshare OLED screen showing Hello World"></p>
<p>Despite the above, the current <code>wiringPi</code> sample still works well. In theory I'm sure it would have been absolutely possible to complete the rest of the project in C. As a language though, C tends to come batteries-not-included. The prospect of stumbling my way through image processing, data parsing, fetching URLs and date-time munging did not fill me with joy, especially given my rudimentary C experience. I'd much rather be building sand-castles in a play pit that didn't require me to build my shovel first.  </p>
<p>I've been "Rust-curious" for a long time, and it's done a great job of establishing itself as <strong>an alternative for workloads where C was historically the only viable candidate </strong>(high performance or memory-constrained). That it does so without forsaking a first-class developer experience is one of the many reasons it's become such <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages" target="_blank" rel="nofollow noopener noreferrer">a beloved language</a>. Through the package manager, <code>cargo</code>, I'd have a thriving ecosystem of 3rd party libraries (aka crates) within arms reach. Indeed, I quickly found <code>rppal</code> (<a href="https://github.com/golemparts/rppal" target="_blank" rel="nofollow noopener noreferrer">Raspberry Pi Peripheral Access Layer</a>), a Rust crate to manage <code>GPIO</code>.</p>
<pre>

<span>[</span><span>dependencies</span><span>]</span>
<span>image</span> <span>=</span> <span>"0.23.8"</span>
<span>chrono</span> <span>=</span> <span>"0.4"</span>
<span>serde</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"1.0"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"derive"</span><span>]</span> <span>}</span>
<span>serde_json</span> <span>=</span> <span>"1.0"</span>
<span>toml</span> <span>=</span> <span>"0.5"</span>
<span>ordered-float</span> <span>=</span> <span>"2.0"</span>
<span>reqwest</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.10"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"json"</span><span>]</span> <span>}</span>
<span>tokio</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.2"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"full"</span><span>]</span> <span>}</span>
<span>simple-error</span> <span>=</span> <span>"0.1.9"</span>

<span>[</span><span>target.'cfg(target_arch="arm")'.dependencies</span><span>]</span>
<span>rppal</span> <span>=</span> <span>"0.9.0"</span></pre>
<p>There were also plenty of reasons <strong>not</strong> to choose Rust. Scant few weeks remained until the birthday party; if we were going to pull off the surprise it meant sticking to a very aggressive timeline. <code>rppal</code> is not a port of <code>wiringPi</code>, the <code>SPI</code> protocol implementation details might differ in subtle but fundamental ways, enough to bork the entire endeavour. Rust's borrow checker is infamously unforgiving to the uninitiated (it's a bit of an arsehole really). If I was being a responsible lead I'd probably command the troops to trudge on with C. But hack projects really should be about personal edification. So sod it, how hard could it be? </p>
<h2 id="programming-the-app">Programming the App</h2>
<p>Lets just say I got a beating, the likes of which demand a doughnut-shaped cushion afterwards. Rust's learning curve is notoriously steep, and hoping to grok it on such a tight schedule was perhaps optimistic. To Rust's credit, there are plenty of escape hatches to get yourself out of (or into) trouble. This is useful when writing your own code, but by consuming 3rd party libraries you're expected to be more fluent with "idiomatic Rust". </p>
<p><em>(Stay tuned for part 2 where I'll discuss my technical first impressions of Rust)</em>.</p>
<p>Idiomatic understanding is difficult to rush, as it requires a breadth of exposure. I'd fare better now, but as my first-touch point I simply couldn't figure out how I was meant to consume the <code>rppal</code> library. Combing the changelog revealed a big refactor towards a <strong>more</strong> idiomatic and Rust-like API. By reverting to an earlier <strong>less</strong> idiomatic version I'd found a cheeky get out of jail card. Breakthrough, at last, a single pixel signalled business time. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-5.jpg" alt="The happiest pixel" title="Displaying single pixel"></p>
<h3 id="interface-and-ui">Interface and UI</h3>
<p>Now that drawing was possible, the next question was a matter of <em>what</em> to draw? In answer, I cracked open a pixel editor and performed a design sprint in miniature. Several iterations later I had a single image that served as my "design document". </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-6.jpg" title="Designing in the pixel editor"></p>
<p>That's a great example of why this project was so much fun. The problem space left room to flex muscles in every layer of abstraction, whilst being constrained enough to avoid becoming an onerous chore. Font rendering is another example. By using the old school technique of copying slices from a sprite sheet I didn't have to bother myself with font files or font rendering libraries.   </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-7.jpg" title="Designing the font. First on paper, then on screen"></p>
<p>To help me copy slices I relied on the <code>image</code> crate. Again there was a high degree of fumbling to get my head around the API, but once I did I was very impressed by the quality of the library. Even if the ecosystem is still technically maturing, the quality already on display announces Rust's arrival as a serious contender. </p>
<pre>

 
<span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>)</span> <span>-&gt;</span> <span>Font5</span> <span>{</span>
    <span>let</span> p <span>=</span> <span>Path</span><span>::</span><span>new</span><span>(</span><span>"resources/Font-5px.png"</span><span>)</span><span>;</span>

    <span>let</span> img <span>=</span> <span>image<span>::</span></span><span>open</span><span>(</span>p<span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>.</span><span>to_rgb</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> <span>mut</span> faces <span>=</span> <span>HashMap</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    faces<span>.</span><span>insert</span><span>(</span><span>'1'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'2'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>2</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'3'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>6</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>...</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'X'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>95</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Y'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>99</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Z'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>103</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>Font5</span> <span>{</span> faces <span>}</span>
<span>}</span></pre>
<p>Up till now, I had been doing all the development directly on a Raspberry Pi 3. It worked well enough, but I was sorely missing the quality of life features I could enjoy in a full developer environment. The <code>image</code> crate was convenient enough that I started using it for other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/rust-tide-clock">https://thefuntastic.com/blog/rust-tide-clock</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/rust-tide-clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708345</guid>
            <pubDate>Wed, 07 Oct 2020 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete AWS Lambda Handbook for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24708237">thread link</a>) | @maridashbird
<br/>
October 7, 2020 | https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/ | <a href="https://web.archive.org/web/*/https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Welcome to the Serverless world. One of the first things you’ll hear about is AWS Lambda - and you’ll continue to keep hearing about it! While architecture can be serverless without Lambdas involved, it’s very often the key component within a serverless application. In the first post of this 3-part AWS Lambda Handbook series, we run through what is AWS Lambda, dialling back to basics with the various terminology, how to create a Lambda function and how to run it.&nbsp;</p>
<blockquote>
<p>Read <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-2/">Part 2</a> and <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-3/">Part 3</a></p>
</blockquote>
<h2 id="what-is-aws-lambda-and-what-does-it-do">What is AWS Lambda, and what does it do?</h2>
<p>AWS Lambda is an event-driven serverless compute platform, spinning up the service in response to an event - find out more about Lambda triggers in <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-1/">part 1</a> and <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-2/">part 2</a> of our Complete Guide to Lambda Triggers series. Your code simply sits there as a file while AWS keeps a lookout for the trigger event you’ve set. When that event occurs, your code is executed and the required operations are carried out. It’s deemed ‘serverless’ because the server doesn’t exist until the user goes out to look for it - this is the epitome of <a href="https://dashbird.io/blog/what-is-faas-function-as-a-service/">Function-as-a-Service (FaaS)</a>.</p>
<p>Another bonus to Lambda is it’s auto-scalability managed by AWS, meaning you don’t need to think about infrastructure. The service will automatically accommodate growing needs and likewise, will scale down to conserve resources. All of this makes AWS Lambda a great solution to reduce waste of resources and budget.&nbsp;</p>
<h2 id="aws-lambda-definitions-explained">AWS Lambda Definitions Explained</h2>
<p>Before getting into how to set up and configure Lambda, below are definitions and terminology commonly used and spoken about.</p>
<p>Lambda Function: a group of related statements that perform a specific task in your application. It consists of code and any dependencies that are associated with it. Each Lambda function has its associated configuration information (name, description, entry point, and resource requirements).</p>
<p>The function itself has the following important aspects associated with it:</p>
<ol>
<li>
<p>Trigger: A set of activities which invokes the function (runs the code you provide). The activity could be anything like a new object coming to your S3 bucket, a website or a service going down, an API call, etc.</p>
</li>
<li>
<p>The actual function: This is the run-time code that constitutes the function. AWS supports Python, Node.js, C#, Go and Java8 as runtime environments.&nbsp;</p>
</li>
<li>
<p>Resources: Each function can be assigned certain Roles, which grants the function certain privileges such as reading S3 bucket contents, writing results to a database and so on.</p>
</li>
</ol>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/1aws-lambda-api-gateway-trigger.png" alt="AWS Lambda anatomy" title="AWS Lambda anatomy"></p>
<p>The triggers are shown to the left, and in this case an API gateway trigger is active. The resources are shown on the right, which in this case, are CloudWatch Logs and DynamoDB.</p>
<p>Event Sources: an entity that publishes events. An event source can be an AWS service or developer-created application that produces events that trigger a function to run.</p>
<p>Invocation: an invocation is called up to execute a specific Lambda function. These are triggers for the code of the function to start running. Invocations can be either <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-options.html">synchronous or asynchronous</a>.</p>
<p>Event Source Mapping: a configuration of AWS services in which an event source is tied to a specific Lambda function. It enables automatic invocation of a Lambda function when specific events occur.</p>
<p>Lambda Execution Model: When you create a Lambda function, you can specify configuration information, such as the amount of memory and maximum execution time that you allow for your function. When that function is invoked, AWS Lambda launches an <a href="https://docs.aws.amazon.com/lambda/latest/dg/running-lambda-code.html">Execution Context</a> based on the configuration settings you have provided.</p>
<p>Cold Starts: A cold start happens when a Lambda function is invoked after not being used for an extended period of time, which results in increased invocation latency (more on this later).</p>
<h2 id="aws-lambda-configuration-elements">AWS Lambda Configuration Elements</h2>
<p>A Lambda function consists of the code and associated dependencies, and it also has configuration information within it. An API is also provided so you can update some of the configuration data. Lambda function configuration information comes with these critical elements:</p>
<ul>
<li>
<p>Calculating the required resources: specifying the amount of memory that you wish to allocate for your Lambda function. AWS Lambda allocates CPU power in proportion to the memory by the same ratio as a general-purpose AWS EC2 instance type, like an M3 type.&nbsp;</p>
</li>
<li>
<p>Maximum execution time (timeout): specified to prevent the Lambda function from running non-stop. Since you’re paying for the AWS resources that are used to run your Lambda function, this is particularly important. Upon reaching the timeout, AWS Lambda is terminating the execution of your Lambda function. The recommended setting is valued upon the expected execution time.</p>
</li>
<li>
<p>IAM role (execution role): the role that AWS Lambda performs on your behalf when executing a Lambda function.</p>
</li>
<li>
<p>Handler name: the method of entry point that runs your code with any event source dependencies included as a part of your Lambda function. You will be able to discover more details, and the quality features of monitoring and debugging AWS Lambda using this.&nbsp;</p>
</li>
</ul>
<h2 id="creating-a-simple-aws-lambda-function">Creating a Simple AWS Lambda Function</h2>
<p>Let’s create a simple Lambda function that is invoked by an API call, i.e. we generate a URL, which when entered in the browser would invoke the function. Our input would be passed into the function via this URL and the output would be returned and shown in the browser.</p>
<p>Step 1: Creating the function</p>
<p>In the Lambda console panel, click on create function. Give your function a name, in our case, it is DemoFunction. Also select the runtime as Python3, as we will be using that particular language for this example. Lastly, give your function’s role a name and, from Policy Templates, select Simple Microservice permissions.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/2creating-new-aws-serverless-function.png" alt="AWS Lambda Author From Scratch" title="AWS Lambda Author From Scratch"></p>
<p>Click on Create Function and you will be taken to the next screen where you can provide the actual code. We are authoring this API from scratch, but there are tons of templates from Amazon repository that you can explore.</p>
<p>The next page will have an inline text editor with a simple python function in there. Replace that with the following content:</p>
<pre><code>import json

print('Loading function')

def lambda_handler(event, context):

&nbsp;&nbsp;&nbsp;&nbsp;firstName = event['first']

&nbsp;&nbsp;&nbsp;&nbsp;lastName = event['last']

&nbsp;&nbsp;&nbsp;&nbsp;return 'Greetings, ' + firstName + ' ' + lastName +'!' 
</code></pre><p>The first line is for parsing the JSON using the JSON library in Python. The lambda_handler function gets the event as one of its parameters; this event brings along a set of data. The first and second line inside the function extracts whatever data is labeled first and second, and stores them into the respective variables.</p>
<p>The last line returns a message back and that’s what we will see in our browser.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/3creating-new-aws-serverless-function.png" alt="Creating AWS Lambda function" title="Creating AWS Lambda function"></p>
<p>We can add an API Gateway trigger right here, but for the sake of clarity, let’s do it separately. For now, we can click Save and move into the testing phase.</p>
<p>Step 2: Testing your function</p>
<p>To test your function, just click on the top right corner where it says ‘TestEvent’, then click on Configure Test Event.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/4creating-new-aws-serverless-function.png" alt="Testing AWS Lambda function" title="Testing AWS Lambda function"></p>
<p>Here we will have our first encounter with a JSON payload. In the template TestEvent.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/5test-new-aws-serverless-function.png" alt="Testing AWS Lambda JSON function" title="Testing AWS Lambda JSON function"></p>
<p>Replace the file’s content with the following lines:</p>
<pre><code>{

&nbsp;&nbsp;"first": "Jane",

&nbsp;&nbsp;"last": "Doe"

}
</code></pre><p>Now that we have saved the test event. Click on Test in the previous menu. Upon successful execution you should see:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/6creating-new-aws-serverless-function.png" alt="AWS Lambda function output" title="AWS Lambda function output"></p>
<p>Step 3: Setting up a Trigger</p>
<p>As mentioned before, our user would <a href="https://dashbird.io/blog/what-are-aws-lambda-triggers/">invoke the function</a> by accessing a certain URL. To enable that go to the API Gateway Console under your AWS Services and click on Get Started or New API option.</p>
<p>Let’s create one from scratch:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/7creating-new-aws-serverless-function.png" alt="AWS Lambda API creation" title="AWS Lambda API creation"></p>
<p>Our API is named dashbird-api. After clicking on Create API. You will get the resources that the API has access to (listed in the next menu):</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/8creating-new-aws-serverless-function.png" alt="AWS Lambda API resources" title="AWS Lambda API resources"></p>
<p>Since there are no resources, we just get a forward-slash. But you can create a new resource by using the Actions drop-down and picking Create Resource.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/9creating-new-aws-serverless-function.png" alt="AWS Lambda child resources" title="AWS Lambda child resources">
In the resource list, you can select this new resource (named greetings), click on actions and select Create Method. Our HTTP request method is going to be a GET request since our aim is to get an appropriate response from invoking the function.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/91creating-new-aws-serverless-function.png" alt="AWS Lambda GET request" title="AWS Lambda GET request"></p>
<p>The method will have a Lambda integration option, select that and then enter the function name chosen by you earlier Step 2. Also, from Step 2’s screenshot, make note of the function’s <a href="https://dashbird.io/knowledge-base/aws-cloud/arn-amazon-resource-names/">ARN</a> (top-right corner), it has the string eu-central-1 indicating the region it is in. Make sure that the same region is selected for the Lambda region also, as shown above. It would then ask permission for invoking the function; grant that and now we are ready for the final modification.</p>
<p>The GET method execution is explained in this diagram:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/92-GET-method-execution-aws-serverless.png" alt="AWS Lambda modify method" title="AWS Lambda modify method">
We still need to make sure that the input parameters are passed on correctly. For that we need to modify the Integration Request stage from above. You can click on it to make modifications:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/93-GET-method-execution-aws-serverless.png" alt="AWS Lambda body mapping" title="AWS Lambda body mapping"></p>
<p>Leave everything as it is, except at the very bottom of the menu where you will find the Body Mapping Template here we get to describe our input template.The template is going to be of type application/json :</p>
<pre><code data-lang="{">
&nbsp;&nbsp;&nbsp;&nbsp;"first": "$input.params('first')",

&nbsp;&nbsp;&nbsp;&nbsp;"last": "$input.params('last')"

}
</code></pre><p>The dollar sign and the input.params() part act as a placeholder and helps us define the structure of a proper request. Now we can save our changes, and click on Actions and select Deploy API option. It will ask for a stage name; give it a suitable name (in our case it is called prod). All is set! We can now run this function in real-time.</p>
<h2 id="running-the-function">Running the Function&nbsp;</h2>
<p>The function can be invoked using a unique URL associated with it. In the API console, where we first selected Resources, select Stage submenu instead. Then drop down to greetings and then to the GET option.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/94-GET-method-execution-aws-serverless.png" alt="AWS Lambda invoke URL" title="AWS Lambda invoke URL"></p>
<p>It will give you an invoke URL, which you can click on for the function to run. However, on the first try you might get an error message if you didn’t give any input. You can rectify this by modifying the URL like this:</p>
<p><a href="https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe">https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe</a></p>
<p>Adding …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</a></em></p>]]>
            </description>
            <link>https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708237</guid>
            <pubDate>Wed, 07 Oct 2020 13:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from onboarding emails with no HTML styling]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 166 (<a href="https://news.ycombinator.com/item?id=24707994">thread link</a>) | @pau_alcala
<br/>
October 7, 2020 | https://blog.palabra.io/great-onboarding-plain-text | <a href="https://web.archive.org/web/*/https://blog.palabra.io/great-onboarding-plain-text">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a></em></p><p>Great onboarding emails don't need to have impressive design. They should provide a clear path for new users to follow to get as much value from your product and as quickly as possible. While creating <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra's</a> onboarding, we went through our favorite plain text emails. Here's what we learned.</p><h2>Plain text is the way to go 🚀</h2><p>Writing HTML emails takes a lot of time, even with image based builders. As an early stage company, we simply didn't have enough time to design and mark our emails.</p><p>We also have <a href="https://blog.palabra.io/plain-text-engagement">a lot of reasons to go with plain text</a> instead of image-based. It helps deliverability, accesibility and looks much more real and important than ad-looking emails.</p><p>That's why we decided to go with plain text emails all the way. We explored different email sequences that used plain text (or simple styling) to understand what they did best. And where better to start than our very own inbox?</p><p>We noticed a few of the onboarding email sequences we got were really helpful for us as users. They kept simple a simple design and used mostly text to share their best features. </p><p>And we found some awesome examples of onboarding sequences that use little to no HTML styling:</p><ul><li>Notion's awesome and personal onboarding (simple styling).</li><li>Superhuman's daily bits of information on its greatest features (only text and images).</li><li><a href="http://zest.is/">Zest.is</a> drips using only plain text and images or gifs (our personal favorite).</li></ul><p>Here's what we discovered.</p><h2>Welcome emails are more than a confirmation</h2><p>Every SaaS company must start their onboarding sequences with a welcome message that is sent when a user joins the platform. This is a must by now, since everyone who signs up will expect some sort of confirmation of their transaction.</p><p>I mean, it is essentially a welcome message, but it can be so much more.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png" srcset="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/5243c/01.png 240w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/ab158/01.png 480w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png 809w" sizes="(max-width: 809px) 100vw, 809px" loading="lazy">
    </span></p><p>For example, SuperHuman sends you a warm welcome message that immediately teaches you how to use their Command.</p><p>Another excellent example of welcome email is from Zest:</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png" srcset="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/5243c/02.png 240w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/ab158/02.png 480w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png 960w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/b1884/02.png 994w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>We love these simple but catchy lines. They nail the exact effect that plain text should achieve: make you feel among friends.</p><p>Both Superhuman and Zest suggest a next step you should follow after receiving that first email. This gives a clear path for people to follow if they want to get value from their products. And that's the best thing you can do with a welcome message.</p><h2>A name and a face</h2><p>This is a great tip to increase engagement. I always feel awkward when I don’t know who is writing on the other side. Is it the CEO? Someone from Sales? Is it a super intelligent baby? Who knows.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png" srcset="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/5243c/03.png 240w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/ab158/03.png 480w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png 658w" sizes="(max-width: 658px) 100vw, 658px" loading="lazy">
    </span></p><p>We can see this information clearly in Notion’s emails. Ivan is not only a name, he is Notion’s Co-founder. It’s flattering to receive a direct message from a co-founder, it also gives the impression of commitment from the very roots of the company. </p><p>At <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a> we do the very same thing. Our emails are sent by Paula or Karen, who are the founders (and the heart) of this project. </p><p>A photo is not a requirement in itself, yet, the clearer the image we have of the person who sends and receives the emails, the more engagement we can generate.</p><p>Even if you have hundreds of people working in your business, you can create an identity to address your users.</p><h2>Emojis in the subject (use with caution)</h2><p>This point is more to talk about email subjects, a very important topic that sometimes is forgotten.</p><p>If every email is a gift to your users, the subject is the wrapping paper. You want it to be shining, flashy, stunning so the reader has no other option than to open the email.</p><p>Definitely, most of the plain text onboarding sequences than we observed have emojis (at some stage) in their subjects. </p><p>Remember: emojis are important, but they have to reinforce the idea of the text in the subject. Otherwise you’re gonna look cu-cu or, even worse, desperate.</p><p>Zest win the contest of better subjects seding thing like: </p><ul><li>you here -&gt; 💗</li><li>make yourself at home 🍋</li></ul><p>You can also include them in the body of the email to generate a greater visual impact and a neatear appearance.</p><h2>Email 'til you make it</h2><p>Yes, we received tons of emails per week. In fact, Superhuman mentioned it in their onboarding email sequence.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png" srcset="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/5243c/04.png 240w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/ab158/04.png 480w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png 701w" sizes="(max-width: 701px) 100vw, 701px" loading="lazy">
    </span></p><p><em>(this is simply genius)</em></p><p>But preciscely for that reason you have to be present. The first days are critical to impress your users.</p><p>Zest has the strategy of sending an email the first day a user joins. And then three more during the second day, another 4 days after and another one 10 days after.</p><p>Imagine someone you’re dating sends you 4 emails in 10 days (well, in that case, you’re probably Meg Ryan, so maybe it’s not so bad).</p><p>This could sound excessive, but it can take a while until people understand your value. Just make sure the value you're providing is clear, and that each email you send has a reason to be in people's inbox.</p><h2>Thank yous matter</h2><p>Far from recommending you stalk your users, we want to encourage you to use emails as a tool for a meaningful exchange of information. You can learn one thing or two about your own service or product.</p><p>The Superhuman sequence puts feedback as a priority, using sentences like:</p><p>“<strong>We love hearing your feedback: please reply to this email and say hello :)”</strong></p><p><strong>“We love hearing from you! Please reply and let us know what you think 😃”</strong></p><p>In the email sequence that we mentioned from Zest, at the 10 day after the user joins, they ask for the thoughts and feelings about the platform and for the likes and dislikes.</p><p>A “thank you” at the end of every email leaves a good impression. Of course. It’s also a good idea to make a special thanking email. When a business is growing, every user is something to thank, so let them know that in your own words (or emojis!).</p><p>If you read this far, ping us at <a href="https://twitter.com/palabraio">Twitter</a> and tell us who sent you your favorite onboarding emails.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/great-onboarding-plain-text</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707994</guid>
            <pubDate>Wed, 07 Oct 2020 13:35:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monty Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 208 (<a href="https://news.ycombinator.com/item?id=24707305">thread link</a>) | @dyno-might
<br/>
October 7, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Sep 17, 2020</strong></p>
            
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don’t affect the solution. At the end, we arrive at the classic Monty Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn’t matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don’t. Why?</p>



<p>Here’s our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There’s nothing mysterious here. You should choose option B. There’s only a 10% chance you picked the right door, so there’s a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says “Hey! I promise you that there is a goat behind at least 8 of the other 9 doors!”</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty’s statement changes nothing. You don’t need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let’s update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven’t learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn’t door 7 seem special?</p>



<p>Let’s make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn’t get you the 8 visible goats. Since you don’t care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we’re done.</p>



<ul>
  <li>
    <p>It’s important that Monty looked behind the doors before choosing which to open. This is where people’s intuition usually fails. If he had chosen a door at random — <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there’s no advantage or harm in switching.) But he doesn’t choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen’t matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
 ↓<br>
 ↓ (Use 10 doors instead of 3)<br>
 ↓ <br>
Game 4<br>
 ↓<br>
 ↓ (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
 ↓<br>
Game 3<br>
 ↓<br>
 ↓ (Monty promises 8 goats behind the other doors instead of showing you.)<br>
 ↓<br>
Game 2<br>
 ↓<br>
 ↓ (Monty doesn’t bother promsising.)<br>
 ↓<br>
Game 1 (Dyno Might© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monty Hall problem, also intended to be more intuitive. These involve switching the doors for “boxers”.</p>
  </li>
  <li>
    <p>Monty Hall was actually named “Monte” at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that’s either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707305</guid>
            <pubDate>Wed, 07 Oct 2020 11:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Design an Algorithm (2018)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24706841">thread link</a>) | @rohithkp
<br/>
October 7, 2020 | https://www.adamconrad.dev/blog/how-to-design-an-algorithm/ | <a href="https://web.archive.org/web/*/https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>

            <p>If you missed my <a href="https://www.adamconrad.dev/blog/why-hiring-is-broken-and-how-im-dealing-with-it">previous article</a>, I’m going to spend a series of articles providing notes as I audit <a href="http://www3.cs.stonybrook.edu/~skiena/373/">Steven Skiena’s CSE 373 Analysis of Algorithms class</a>.</p>

<p>In the first lecture, Skiena mentions you should take a data structures course and a linear algebra course before studying this material.</p>

<p>For professional (read: practical) purposes, we’re obviously not starting from scratch, but peaking at the syllabus I do believe we can incorporate data structures by implementing them in JavaScript (this is, after all, a front-end blog) along the way.</p>

<p>And as much as foundational linear algebra will help, there simply won’t be anything in a technical interview that would warrant deep study anyway, so we can safely skip this prerequisite.</p>

<h2 id="what-is-an-algorithm">What is an algorithm?</h2>

<p>An algorithm is <strong>an instruction set.</strong> Kind of like a recipe for a food dish. And just like that recipe for cauliflower rice you found on some random blog, you can translate that recipe into any language you want.</p>

<p>Algorithms are the same way: they are language-agnostic and can be expressed in a human-readable form or machine-readable. The simpler the idea, the easier it’s going to be to express in English. The more complex or nuanced the algorithm is, the more likely you’ll want to lean on a machine language like Python or JavaScript.</p>

<p>For practical purposes, think of the high-level overview of your algorithm as something you’ll explain to an interviewer in English before you dive into the code, but understand that in order to prove your chops as a programmer the code will have to be the primary source for explaining and validating the algorithms you design.</p>

<p>The two defining characteristics of an algorithm that separate an algorithm from other instructions are:</p>

<ol>
  <li><strong>It’s correct.</strong> Has anyone ever received credit for implementing an algorithm in a tech interview that didn’t produce the correct result every single time?</li>
  <li><strong>It’s efficient.</strong> We’d like our algorithms to run sometime before we get old.</li>
</ol>

<p>Now, <em>technically</em>, programs don’t have to run correctly to be acceptable. Programs that run instructions that are <em>mostly</em> correct are known as <em>heuristics</em>. These will become important when studying approximation algorithms later, but for now, assume that correctness is a requirement.</p>

<h3 id="how-do-you-prove-an-algorithm-is-correct">How do you prove an algorithm is correct?</h3>

<p>Proofs were not my strong suit in high school or college. For some reason, it never really clicked for me because the steps in a proof never seemed to line up with the logic my brain used to jump from one step to the next.</p>

<p>Luckily, the easiest way to prove correctness is to prove something <strong>isn’t correct.</strong></p>

<p>Wait, what? How does proving the opposite help us here?</p>

<p>Well, when we’re trying to figure out a correct and efficient algorithm to solve a problem, we can narrow the scope of possible choices by eliminating the ones that are demonstratively incorrect. Proving by counterexample can be far easier than other methods.</p>

<p>As a trivial example, suppose we have a total <em>T = 6</em> we want to strive for by adding up numbers in a valid set like <em>S = [1,2,3]</em>. It might seem like a very simple algorithm that will solve this problem is to pick numbers from left to right until we reach the total <em>T</em>. Even if you add in a big number at the beginning like <em>S = [5,1,2,3]</em> this works since we can just scrap the last two numbers.</p>

<p>What’s a counterexample that wouldn’t work?</p>

<p>How about <em>S = [5,2,4]</em>.</p>

<p>First, we pick 5, which is less than 6. There are no other numbers in our set that could add up to equal 6 after already picking 5, but there <em>is</em> a valid configuration that would still satisfy <em>T</em> (2 and 4). That’s proof by counterexample that our algorithm was not correct. It’s also a pretty simple counterexample. <strong>Counter-examples can be useful in the real-world to quickly help you assess if the path you’re going down is a good one or not.</strong></p>

<p>If you can come up with a relatively simple counterexample (simple meaning it should only require a handful of variables or items) you know that your algorithm is dead on arrival and you’ll need to try something else. If you can’t, you’re probably on the right track, but that doesn’t mean your algorithm is definitively correct.</p>

<h3 id="what-techniques-are-used-to-prove-correctness">What techniques are used to prove correctness?</h3>

<p>One way to prove correctness is induction. <strong>Proof by induction indicates that if we can solve for a base case <em>and</em> the general case for <code>n+1</code>, we know we’ve provided a correct answer for all possible inputs.</strong></p>

<p>There are two important connections to make here about induction which are useful in a professional setting:</p>

<ol>
  <li><strong>Proof by induction is a mathematical form of recursion.</strong> Recursion is a fundamental concept in programming which allows a function to call itself. It allows us to split up large problems into smaller ones.</li>
</ol>

<p>The classic example here is the Fibonacci sequence (a sequence of integers where the current number is the sum of the previous two numbers). To calculate Fibonacci for a value <em>n</em> in the sequence, you <em>could</em> count up all of the previous numbers manually for each input of <em>n</em>, but that would not only be slow and laborious, it would also be difficult to express as a program.</p>

<p>Another way would be to count a few base cases (n = 0 and n = 1) to get the counting started, and then continuously call a <code>Fibonacci</code> function with the summed values from the previous step. Recursion is what allows us to accomplish this in code. It is the programming strategy for tackling induction, which is the mathematical strategy for proving statements for algorithms which operate on our sets of data.</p>

<ol>
  <li><strong>Proof by induction is useful for summation.</strong> If you’re adding up a lot of inputs together, and you need to prove it will work for all cases, even ones larger than the set you have defined, it can be proven with induction.</li>
</ol>

<p>But are you ever going to need to formally prove something at work or in an interview? Absolutely not. <strong>But you will need to test your code, and tests are a form of proof.</strong></p>

<p>So while a formal mathematical proof of induction is likely way more rigorous than you will ever need to showcase in a professional setting, it does set the tone that you can’t simply write code and have people assume what you wrote is correct. It needs to be tested somehow, so if you have the mindset that your algorithm needs to be proven correct in some form, you’re on the right track to writing quality code.</p>

<h3 id="and-how-do-you-prove-something-is-efficient">And how do you prove something is efficient?</h3>

<p>If we’ll primarily be using code to express our algorithms, and tests to prove their correctness, Big O notation will be used to prove our algorithms are efficient.</p>

<p>We’ll cover Big O in a later post in this series, but the important thing to remember now is that in general, you’re going to want to strive for things that take a reasonable amount of time on large data.</p>

<p>For example, if something you design takes an <code>n!</code> factorial amount of time, anything over a measly 30 items and you’re dealing with numbers larger than the number of stars in the known universe. You <em>probably</em> want something that runs a bit faster than that.</p>

<h3 id="the-big-picture-on-the-properties-of-algorithms">The big picture on the properties of algorithms</h3>

<p>Most CS courses (and most schools) only ever care about these two things. If your teachers and TAs can successfully run your program within a reasonable amount of time, you get an A. Real life doesn’t give you an A for these two things because <em>you don’t work in a vacuum</em> as you do on a problem set or exam. So what things are missing from the real world picture?</p>

<ul>
  <li><strong>Orthogonality:</strong> Is your code dependent on other stuff? Are you writing stateful or functional code? Since most coding whiteboard problems are isolated and self-contained, you usually can’t test for this, so make sure you present a portfolio of real-world projects and open source code to demonstrate this</li>
  <li><strong>Readability:</strong> You can write the hackiest crap to get an algorithm to work, but in the real world other people can’t read or use that code, and that’s a fail. Make sure if you have time and your code is correct and efficient, to <em>refactor</em> to demonstrate you can write readable, reusable code that is DRY (don’t repeat yourself) and orthogonal (or at least that it can be written as part of an orthogonal system)</li>
</ul>

<h3 id="the-first-step-in-designing-an-algorithm">The first step in designing an algorithm</h3>

<p>So now that we know what defines an algorithm and what is required to prove it’s worth using to solve our problems, the next step is to decide how we will design our algorithms. Modeling a problem means knowing the objects you’re dealing with, and there are two classes of objects we will cover:</p>

<h4 id="combinatorial-objects">Combinatorial objects</h4>

<p>A <em>combinatorial object</em> is just a fancy way of saying “what kinds of things can I use to count with?” Since machines are just big 0 and 1 factories, combinatorial objects are the way for us to collect and organize all of the 0 and 1 math our machines are performing thousands upon millions of instructions per second. What kinds of things are we talking about?</p>

<ul>
  <li><strong>Permutations:</strong> reorderings of a set. Colloquial terms for this include words like <em>arrangement</em>, <em>tour</em>, <em>ordering</em>, and/or <em>sequence</em>.</li>
  <li><strong>String:</strong> sequence of characters or patterns. Think of strings like permutations but with letters instead of numbers. Words like <em>text</em>, <em>character</em>, <em>pattern</em>, <em>label</em>, <em>sentence</em> are key insights that you’re dealing with string data.</li>
  <li><strong>Subsets:</strong> portions of a set. If you see words like <em>cluster</em>, <em>collection</em>, <em>committee</em>, <em>group</em>, <em>packaging</em>, or <em>selection</em>, you’ve probably got a subset.</li>
  <li><strong>Points:</strong> locations in space. Words like <em>node</em>, <em>site</em>, <em>position</em>, <em>record</em>, or <em>location</em> are all references to <em>points</em>.</li>
  <li><strong>Graphs:</strong> nodes with vertices to connect them and give them direction. We mentioned this much earlier in this article. Words like <em>network</em>, <em>circuit</em>, <em>web</em>, and <em>relationship</em> all describe graphs.</li>
  <li><strong>Trees:</strong> graphs that flow in one direction and don’t end up where they started (acyclic). When they’re perfectly balanced, they literally look like a Christmas tree. Words like <em>hierarchy</em>, <em>dominance relationship</em>, <em>ancestor/descendent relationship</em>, <em>taxonomy</em> are all indicators you’re dealing with trees in your problem.</li>
  <li><strong>Polygon:</strong> …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</a></em></p>]]>
            </description>
            <link>https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706841</guid>
            <pubDate>Wed, 07 Oct 2020 10:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crouching T2, Hidden Danger]]>
            </title>
            <description>
<![CDATA[
Score 217 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24705645">thread link</a>) | @xrayarx
<br/>
October 6, 2020 | https://ironpeak.be/blog/crouching-t2-hidden-danger/ | <a href="https://web.archive.org/web/*/https://ironpeak.be/blog/crouching-t2-hidden-danger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="info"><div><p><h4><br><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" width="25" height="20"><path fill="currentcolor" d="M448 0H64C28.7.0.0 28.7.0 64v288c0 35.3 28.7 64 64 64h96v84c0 7.1 5.8 12 12 12 2.4.0 4.9-.7 7.1-2.4L304 416h144c35.3.0 64-28.7 64-64V64c0-35.3-28.7-64-64-64zm16 352c0 8.8-7.2 16-16 16H288l-12.8 9.6L208 428v-60H64c-8.8.0-16-7.2-16-16V64c0-8.8 7.2-16 16-16h384c8.8.0 16 7.2 16 16v288z"></path></svg></span>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4></p></div></div><div id="features"><div><p><h4>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4><hr><br></p><p><strong>Let’s talk about that thing nobody’s talking about.
Let’s talk about a vulnerability that’s exposing 2018-2020 Macs while most are declining to act nor report about the matter.
Oh, and did I mention it’s unpatchable?</strong></p><p><strong>Buckle up buckaroo, we’re in for a wild ride.</strong></p><p>Skip to <a href="#security-issues">#security-issues</a> for the technical mumbo-jumbo.</p><h2 id="preface">Preface</h2><h3 id="attribution">Attribution</h3><p>The following post is an industry analysis of the code and research performed by <a href="https://twitter.com/axi0mx/">twitter.com/axi0mx</a>, <a href="https://twitter.com/h0m3us3r/">twitter.com/h0m3us3r</a>, <a href="https://twitter.com/aunali1/">twitter.com/aunali1</a>, <a href="https://twitter.com/mcmrarm/">twitter.com/mcmrarm</a> and <a href="https://twitter.com/su_rickmark/">twitter.com/su_rickmark</a> who poured endless hours of work into this, allowing companies and users to understand their risks concerning this issue.</p><h3 id="intel-vs-silicon">Intel vs Silicon</h3><p>This blog post only applies to macOS systems with an Intel processor and the embedded T2 security chip.
Apple silicon systems will run completely on a set of Apple-designed ARM processors and mighth have a different topology, e.g. based on the A12.
Since the A12 chip seems to have fixed this issue (to be confirmed), it’s highly likely the new Apple Silicon machines will not be vulnerable.
And while the new upcoming Intel Macs at the end of year will probably receive a new hardware revision of the T2 chip (e.g. based on the A12), we are still stuck with this vulnerability on Macs between 2018 and 2020.</p><h3 id="so-about-this-t2-thing">So about this T2 thing</h3><p>In case you are using a recent macOS device, you are probably using <a href="https://support.apple.com/en-us/HT208862">the embedded T2 security chip</a> which runs <em>bridgeOS</em> and is actually based on watchOS. This is a custom ARM processor designed by Apple based on the A10 CPU found in the iPhone 7.
The T2 chip contains a <em>Secure Enclave Processor</em> (SEP), much like the A-series processor in your iPhone will contain a SEP.</p><p>While newer Macs and/or Apple Silicon (including the dev kit) will use a more recent A-series processor such as the one found in the recent iPhone (A12), current Macs still use the A10.</p><p>It performs a predefined set of tasks for macOS such as audio processing, handling I/O, functioning as a <a href="https://en.wikipedia.org/wiki/Hardware_security_module">Hardware Security Module</a> for e.g. Apple KeyChain or 2FA, hardware accelerating media playback, whitelisting kernel extensions, cryptographic operations and <strong>ensuring the operating system you are booting is not tampered with</strong>.
The T2 chip runs its own firmware called <em>bridgeOS</em>, which can be updated when you install a new macOS version. (ever notice the screen flickering? that’s the display driver being interrupted and possibly updated.)</p><p><em>Edit</em>: I first mentioned the iPad Pro to be impacted by the T2 vulnerability, but while it could suffer from the same vulnerability, it does not contain a T2 chip.</p><h3 id="the-macos-boot-sequence">The macOS boot sequence</h3><p>So let’s focus on the boot image verification on macOS. What exactly happens when you press that power button?
<a href="https://eclecticlightdotcom.files.wordpress.com/2018/08/bootprocess.png">There’s also a visual representation for any <em>conaisseurs</em></a>.
For the enthusiasts, I personally find <a href="https://michaellynn.github.io/2018/07/27/booting-secure/">Booting Secure by mikeymikey</a> a more in-depth description.</p><ol><li><p>The T2 chip is fully booted and stays on, even if your Mac device is shutdown.</p></li><li><p>The press of the power button or the opening of the lid triggers the System Management Controller (SMC) to boot.</p></li><li><p>The SMC performs a Power-On-Self-Test (POST) to detect any EFI or hardware issues such as bad RAM and possibly redirect to Recovery.</p></li><li><p>After those basic sanity checks, the T2 chip is triggered and I/O connectors are setup. (USB, NVMe, PCIe, …) It will use NVMe and PCIe to talk to NAND storage.</p></li><li><p>The applicable boot disk is selected and a disk encryption password is asked if enabled to mount <a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS</a> volumes possibly via FileVault2 disk encryption.</p></li><li><p><code>/System/Library/CoreServices/boot.efi</code> is located on your System APFS volume and <a href="https://support.apple.com/en-us/HT208330">depending on your secure boot settings</a> is validated.</p></li><li><p><em>boot.efi</em> is ran which loads the Darwin kernel <em>(throwback to BSD)</em> (or Boot Camp if booting Microsoft Windows) &amp; IODevice drivers. If a kernel cache is found in <code>/System/Library/PrelinkedKernels/prelinkedkernel</code>, it will use that.</p></li><li><p>Any User Approved Kernel Extensions are initialized &amp; added to the kernel space -if- they are approved by the T2 chip.
<em>This will go away with System Extensions</em>.</p></li></ol><h3 id="macos-security-features">macOS security features</h3><p>So Apple has a couple of tricks up its sleeve to limit the attack surface of any potential security vulnerabilities. A small summary of related measures since macOS Big Sur on Intel processors:</p><ul><li><p><em>System Integrity Protection</em> (SIP): a read-only <code>/System</code> partition so the base install of macOS (including the kernel) cannot be tampered with.</p></li><li><p><em>System Extensions</em>: a move to away from Kernel Extensions, getting external code out of the Kernel framework-wise.</p></li><li><p><em>Secure Boot</em>: verifies the signature validity of the operating system on disk.</p></li><li><p><em>Filesystem seals</em>: every byte of data is compared to a hash in the filesystem metadata tree, recursively verifying integrity.</p></li></ul><h3 id="apple-marketing">Apple marketing</h3><p>As you probably all already know, Apple pushes forward privacy &amp; security as important weapons in todays world of technology.
They tout their devices as highly secure and vouch to handle your personal data using a privacy-centric approach.
While there have been mistakes made in the past (who can blame them?), Apple has been generally quick to fix any security issues that were disclosed to <a href="https://support.apple.com/en-gb/HT201220">their responsible disclosure program</a> or in public.</p><h2 id="security-issues">Security issues</h2><h3 id="jailbreaking">Jailbreaking</h3><h3 id="the-core-problem">The core problem</h3><p>The mini operating system on the T2 (<em>SepOS</em>) suffers from a security vulnerable also found in the iPhone 7 since it contains a processor based on the iOS A10. Exploitation of this type of processor for the sake of installing homebrew software is very actively discussed in the <a href="https://reddit.com/r/jailbreak/">/r/jailbreak</a> subreddit.</p><p>So using the <a href="https://checkm8.info/">checkm8 exploit</a> originally made for iPhones, the checkra1n exploit was developed to build a semi-tethered exploit for the T2 security chip, exploiting a flaw. This could be used to e.g. circumvent activation lock, allowing stolen iPhones or macOS devices to be reset and sold on the black market.</p><p>Normally the T2 chip will exit with a fatal error if it is in DFU mode and it detects a decryption call, but thanks to the <a href="https://github.com/windknown/presentations/blob/master/Attack_Secure_Boot_of_SEP.pdf">blackbird vulnerability</a> by team Pangu, we can completely circumvent that check in the SEP and do whatever we please.</p><p>Since sepOS/BootROM is <em>Read-Only Memory</em> for security reasons, interestingly, Apple cannot patch this core vulnerability without a new hardware revision.
This thankfully also means that this is not a persistent vulnerability, so it will require a hardware insert or other attached component such as a malicious USB-C cable.</p><h3 id="debugging">Debugging</h3><p>Every Apple iDevice (which includes the T2 and the Watch, via a port under the band) ships with a firmware recovery USB interface called Device Firmware Update (DFU), which is triggered when the device is not be able to boot or by pressing a particular set of buttons when turned on. It is always available because it is code run from SecureROM. This is the mode in which checkm8 runs.</p><p>Apple also leaves the ability to access various debug functionality which is disabled on production devices unless a special boot payload is used which runs in DFU. Since Apple is the only one who can sign code for DFU, they can demote any device they like, including the most recent A14 processors.
But since the checkm8 vulnerability runs so early in the boot process, we too can demote the T2 into DFU mode.
Without checkm8, we would not be able to run unsigned code in DFU and thus not be able enable debug interfaces. Once the debug interface is enabled Apple uses specialized cables with simian names (see Chimp, Kanzi, Gorilla).</p><h3 id="impact">Impact</h3><p>Once you have access on the T2, you have full <code>root</code> access and kernel execution privileges since the kernel is rewritten before execution.
Good news is that if you are using FileVault2 as disk encryption, they do not have access to your data on disk <em>immediately</em>.
They can however inject a keylogger in the T2 firmware since it manages keyboard access, storing your password for retrieval or transmitting it in the case of a malicious hardware attachment.</p><p>The functionality of locking an Apple device remotely (e.g. via MDM or FindMy) can be bypassed (<em>Activation Lock</em>).</p><p>A firmware password does not mitigate this issue since it requires keyboard access, and thus needs the T2 chip to run first.</p><p>Any kernel extension could be whitelisted since the T2 chip decides which one to load during boot.</p><p>If the attack is able to alter your hardware (or sneak in a malicious USB-C cable), it would be possible to achieve a semi-tethered exploit.</p><p>While this may not sound as frightening, be aware that this is a perfectly possible attack scenario for state actors.
I have sources that say more news is on the way in the upcoming weeks. I quote: <em>be afraid, be very afraid</em>.</p><h2 id="exploitation">Exploitation</h2><pre><code># install devtools
$ xcode-select --install

# check the script &amp; install homebrew
$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"

# install packages
$ brew install libplist automake autoconf pkg-config openssl libtool llvm libusb

# git clone, autogen.sh, make &amp; make install
# https://github.com/sbingner/ldid
# https://github.com/libimobiledevice/libusbmuxd
# https://github.com/libimobiledevice/libimobiledevice
# https://github.com/libimobiledevice/usbmuxd

# Run checkra1n and wait for T2 boot. It will stall when complete.
# TODO describe the checkra1n exploitation 

# Unplug and replug the usb connection. Checkra1n should now send the overlay.
# TODO describe the usb debug mode &amp; overlay

# Bring up a proxy to dropbear
$ iproxy 2222 44 &amp;

# Connect to T2 &amp; enjoy
$ ssh -p 2222 root@127.0.0.1
</code></pre><h2 id="responsible-disclosure">Responsible Disclosure</h2><p>I’ve reached out to Apple concerning this issue on numerous occasions, even doing the dreaded cc <em>tcook@apple.com</em> to get some exposure.
Since I did not receive a response for weeks, I did the same to numerous news websites that cover Apple, but no response there as well.
In hope of raising more awareness (and an official response from Apple), I am hereby disclosing almost all of the details.
You could argue I’m not following responsible disclosure, but since this issue has been known since 2019, I think …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ironpeak.be/blog/crouching-t2-hidden-danger/">https://ironpeak.be/blog/crouching-t2-hidden-danger/</a></em></p>]]>
            </description>
            <link>https://ironpeak.be/blog/crouching-t2-hidden-danger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705645</guid>
            <pubDate>Wed, 07 Oct 2020 05:52:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode on Google Colab]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24705599">thread link</a>) | @amitness
<br/>
October 6, 2020 | https://amitness.com/vscode-on-colab/ | <a href="https://web.archive.org/web/*/https://amitness.com/vscode-on-colab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

2 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>I recently discovered a way to set up VSCode on Google Colab and use it as an editor to write code and run experiments on the Colab VM.</p>
<p>With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. Here is how you can replicate my setup.</p>
<h2 id="approach-1-python-package">Approach 1: Python Package</h2>
<p>In this setup, we use the <a href="https://github.com/abhishekkrthakur/colabcode">colab-code</a> package that automates all the manual setup steps previously described in the <strong>Approach 2</strong> section of this blog post. You can make a copy of this <a href="https://colab.research.google.com/github/abhishekkrthakur/colabcode/blob/master/colab_starter.ipynb">notebook</a> directly to get started.</p>
<ol>
<li>
<p>First, install the <code>colab-code</code> package using the following command:</p>

</li>
<li>
<p>Now, import <code>ColabCode</code> class from the package and specify the port and password.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>(</span><span>port</span><span>=</span><span>10000</span><span>,</span> <span>password</span><span>=</span><span>"password123"</span><span>)</span>
</code></pre></div> </div>
<p>You can also use it directly with the default port and without any password as shown below.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>()</span>
</code></pre></div> </div>
</li>
<li>
<p>You will get the ngrok URL in the output. Click the link and a login page will open in a new tab.</p>
<p><img src="https://amitness.com/images/colab-code-step-1.png" alt="Generated NGROK URL"></p>
</li>
<li>
<p>Type the password you had set in step 2 and click submit. If the page gets stuck for more than 4-5 seconds, refresh the page and you should be redirected to the editor.</p>
<p><img src="https://amitness.com/images/colab-code-step-2.png" alt="Authenticating with password in VSCode"></p>
</li>
<li>
<p>Now you will get access to the editor interface and can use it to work on python files.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt="VSCode Interface"></p>
</li>
</ol>
<h2 id="approach-2-manual-setup">Approach 2: Manual Setup</h2>
<p>I have described the setup steps in detail below. After going through all the steps, please use this <a href="https://colab.research.google.com/drive/1yvUy5Gn9lPjmCQH6RjD_LvUO2NE0Z7RM?usp=sharing">colab notebook</a> to try it out directly.</p>
<ol>
<li>
<p>First, we will install the <a href="https://github.com/cdr/code-server">code-server</a> package to run VSCode editor as a web app. Copy and run the following command on colab to install <code>code-server</code>.</p>
<div><div><pre><code> !curl -fsSL https://code-server.dev/install.sh | sh
</code></pre></div> </div>
</li>
<li>
<p>After the installation is complete, we will expose a random port <code>9000</code> to an external URL we can access using the <code>pyngrok</code> package. To install <code>pyngrok</code>, run</p>
<div><div><pre><code> <span>!</span>pip <span>install</span> <span>-qqq</span> pyngrok
</code></pre></div> </div>
</li>
<li>
<p>Then, run the following command to get a public ngrok URL. This will be the URL we will use to access VSCode.</p>
<div><div><pre><code> <span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
 <span>url</span> <span>=</span> <span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>port</span><span>=</span><span>9000</span><span>)</span>
 <span>print</span><span>(</span><span>url</span><span>)</span>
</code></pre></div> </div>
</li>
<li>
<p>Now, we will start the VSCode server in the background at port 9000 without any authentication using the following command.</p>
<div><div><pre><code> !nohup code-server --port 9000 --auth none &amp;
</code></pre></div> </div>
</li>
<li>
<p>Now, you can access the VSCode interface at the URL you got from step 3. The interface and functionality are the same as the desktop version of VSCode.</p>
</li>
</ol>
<p><img src="https://amitness.com/images/colab-vscode.png" alt="Example of a running instance of VSCode server"></p>
<h2 id="usage-tips">Usage Tips</h2>
<ol>
<li>
<p>You can switch to the dark theme by going to the bottom-left corner of the editor, clicking the <strong>settings icon</strong>, and then clicking ‘<strong>Color Theme</strong>’.</p>
<p><img src="https://amitness.com/images/colab-dark-theme-step-1.png" alt="Switching to dark theme on VSCode"></p>
<p>A popup will open. Select <strong>Dark (Visual Studio)</strong> in the options and the editor will switch to a dark theme.
<img src="https://amitness.com/images/colab-dark-theme-step-2.png" alt="Theme selection interface on VSCode"></p>
</li>
<li>
<p>All the keyword shortcuts of regular VSCode works with this. For example, you can use <code>Ctrl + Shift + P</code> to open a popup for various actions.</p>
<p><img src="https://amitness.com/images/vscode-ctrl-shift-p.png" alt="Action popup in VSCode"></p>
</li>
<li>
<p>To open a terminal, you can use the shortcut <code>Ctrl + Shift + `</code>.</p>
<p><img src="https://amitness.com/images/vscode-terminal.png" alt="Opening integrated terminal in VSCode"></p>
</li>
<li>
<p>To get python code completions, you can install the Python(<code>ms-python</code>) extension from the extensions page on the left sidebar.</p>
<p><img src="https://amitness.com/images/vscode-code-completions.png" alt="Installing extensions in VSCode"></p>
</li>
<li>
<p>The Colab interface is still usable as a notebook and regular functions to upload and download files and mount with Google Drive. Thus, you get the benefits of both a notebook and a code editor.</p>
</li>
</ol>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/cdr/code-server/blob/v3.5.0/doc/FAQ.md">Code-Server FAQs</a></li>
<li><a href="https://pyngrok.readthedocs.io/en/latest/">pyngrok - a Python wrapper for ngrok</a></li>
</ul>
</section>



</div></div>]]>
            </description>
            <link>https://amitness.com/vscode-on-colab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705599</guid>
            <pubDate>Wed, 07 Oct 2020 05:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USB3: Why it's a bit harder than USB2]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24704298">thread link</a>) | @panic
<br/>
October 6, 2020 | https://lab.ktemkin.com/post/why-is-usb3-harder/ | <a href="https://web.archive.org/web/*/https://lab.ktemkin.com/post/why-is-usb3-harder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>A few people on twitter have asked me to explain why the USB3 winds up being much harder to implement than USB2.
The answer is more than will fit in a single tweet, so I thought I'd put a quick-but-rough answer, here. This is
by no means comprehensive; consider it <del>a longer tweet</del> what a tweet would be given I had more than 240 characters and a proclivity to babble. (I do.)</p>
<p>A lot of the challenges come from the way we work around <em>physical-layer</em> limitations. Put poetically, physics gives
us lots of little obstacles we have to work around in order to talk at 5 billion transfers per second (5GT/s).</p>
<h5 id="its-hard-to-establish-common-dc-operating-conditions-on-both-sides-of-a-link">It's hard to establish common “DC operating conditions” on both sides of a link.</h5>
<p>It's not trivial to get the same bias voltages – and common grounds – across a long motherboard or down a cable – and when you're operating at really high frequencies, you're a lot more sensitive to changes in your operating environment. In USB3, we work around this by <em>capacitively isolating</em> both sides of the link from each other – in short, we use capacitors to ensure only signal <em>changes</em> are carried across the link, which means that both sides can establish their own local operating conditions.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/circuit.png" alt="diagram showing the transmitter is connected to the receiver through a pair of AC coupling capacitors"> <figcaption>
            <h4>From the USB3.2 specification: diagram showing how signals are isolated</h4>
        </figcaption>
</figure>

<p>This puts some requirements on the digital protocols used to exchange data. Because data currents are exchanged as the relevant capacitors charge and discharge, <em>capacitive coupling</em> only works when those capacitors have room to charge and discharge. <strong>This means our data must be DC-balanced; we have to spend as much time charging those capacitors as we do discharging them</strong>. In digital terms, this means we have to encode the data in a way that sends the same amount of <code>1</code>s and <code>0</code>s.</p>
<h5 id="its-hard-to-establish-a-common-clock-across-both-sides-of-a-link">It's hard to establish a “common clock” across both sides of a link.</h5>
<p>When sending serial data, you typically have two challenges: you need to make sure both sides are sampling the data <em>at the same rate</em>, and that both sample clocks are <em>synchronized enough</em> that you're sampling at the right point. Many high-speed protocols deal with this using a technique called <em>clock recovery</em>, which essentially means that each receiver looks at the data it receives and tries to figure out what the clock that produced it looks like.</p>
<p>If both sides have agreed on a clock rate, this can be simple, in theory: if the receiver sees a change in its
received data, it can infer that that changed happened <em>on an active edge of the transmitter's clock</em>, and so it can start to figure out how to align its internal clock with the transmitter's.</p>
<p>This introduces another protocol requirement: <strong>for <em>clock recovery</em> to work, the data has to change frequently enough that the two sides can keep synchronized</strong>. At 5GT/s and high data throughputs, there's not much time for clocks to become synchronized when a packet is received; accordingly, it's important that data is encoded with lots of transitions, even when the line is idle.</p>
<p><strong>To ensure both <em>DC-Balance</em> and <em>sufficient transition density</em>, USB3 uses a method of encoding called 8b10b encoding.</strong>
In this encoding scheme, every single byte of data is transmitted as ten bits, with encodings chosen so that:</p>
<ul>
<li>A typical data byte can be transmitted <em>either</em> as a code with <em>one more one than zero</em>, or <em>one more zero than one</em>.
This allows the transmitter to choose between the two encodings, in order to keep the data stream at 50% ones.</li>
<li>Every valid encoding has sufficient <em>transition density</em> to ensure that it's useful for clock recovery.</li>
</ul>
<p>I won't go into more 8b10b background here, but you can read about the typical IBM implementation <a href="https://en.wikipedia.org/wiki/8b/10b_encoding">on wikipedia</a>.</p>
<h5 id="its-hard-to-run-both-sides-of-the-link-at-the-same--clock-rate-">It's hard to run both sides of the link at the same <em>clock rate</em>.</h5>
<p>Even with successful <em>clock recovery</em>, it's difficult to have both sides of the link produce and consume data at
the same rate. Each side's internal logic is running off of its own <em>clock source</em>; and every clock has a bit of deviation from its nominal frequency. For the protocol to function despite these differences, the USB3 specification allows each clock to deviate from its nominal value by up to a certain <em>tolerance</em>; and specifies a method for compensating for this tolerance. This technique is appropriately named <em>clock tolerance compensation</em>, or CTC.</p>
<p><strong>To compensate for mismatches in sender/receiver clock rates, USB3 requires senders to periodically insert filler data into their transmitted data-stream</strong>. Receivers can then discard this data; allowing a brief pause in which the slower
side of the link can “catch up”. For this to be useful, the filler data (called ‘skip sets’) must be sent regularly;
which means additional logic on the transmitter side for insertion, and additional logic on the receiver side for
removal.</p>
<h5 id="its-hard-to-deal-with-varying-electrical-properties-of-different-transmitters-receivers-and-cables">It's hard to deal with varying electrical properties of different transmitters, receivers, and cables.</h5>
<p>When operating at very high frequencies, all of the little non-idealities along your transmission path really add up. At slower data rates, there's plenty of time for digital signals to “settle” after a change; making the non-ideal properties of your transmission lines less important. The faster your data gets, the more important it is for your data
to reach a “readable” value quickly.</p>
<p>To help with this, most high-speed receivers employ a technique called <em>receiver equalization</em>, which uses analog hardware
to help reshape signal transitions, so they can be more reliably sampled. Equalization helps to “cancel out” some of the ways the non-ideal transmission path adversely affects the signal.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/eye.png" alt="diagram showing a variety of slow rises and falls; illustrating that the physical link slows transitions"> <figcaption>
            <h4>From the USB3.2 specification: an 'eye diagram', which shows an overlay of many rising and falling transitions, illustrating how non-ideal properties affect the link.</h4>
        </figcaption>
</figure>

<p>Since every transmission path is different – due to different transmitter, receiver, and cable properties – it's impossible to create a single “one size fits all” equalizer. Instead, each USB3 equalizer needs to be tuned to its transmission path via a process called <em>link training</em>.</p>
<p><strong>At the start of each USB3 communication, link partners repeatedly exchange collections of known data called <em>training sets</em>, which give the opportunity for each side to tune their equalizer.</strong> Training sets include both sets of data chosen to have high transition density and sets designed to include a wide range of “normally-distributed” data.</p>
<p>During a few milliseconds of data exchange – an eternity in fast-protocol terms – both sides of the link gradually
tweak their equalizer settings until they're clearly seeing the expected values from the other side.</p>
<h5 id="its-hard-not-to-generate-harmful-interference">It's hard not to generate harmful interference.</h5>
<p>USB3 has a very high transition rate – it easily qualifies as high radio-frequency signaling – and its link
often tends to exchange repeating data. This has a nasty side effect: even a well-functioning link can act as an
antenna; unintentionally emitting RF that can interfere with nearby systems. The more repeating elements this signaling
has, the more troublesome the interference tends to be.</p>
<p><strong>To reduce the amount of harmful interference generated, USB3 links use a technique called <em>scrambling</em>, in which data is XOR'd with a fixed pattern before transmission.</strong> The receiver is then capable of applying the same transform to <em>descramble</em> the data stream, recovering the relevant data.</p>
<p>You can think of scrambling as being very similar to encryption – except everyone knows the key. Once data is scrambled, it looks a lot more like “random numbers” than the pre-scrambling data – and accordingly, it's a lot less likely to
generate troublesome interference. Once the scrambled data travels the link, it can be <em>descrambled</em> by the receiving end – a process similar to decryption – restoring the original data stream.</p>
<h5 id="in-summary">In summary…</h5>
<p>In summary, before you can even exchange meaningful data, the digital side of your device needs:</p>
<ul>
<li><strong>8b10b encoding and decoding hardware</strong>, so the data exchanged is <em>DC-balanced</em> and contains sufficient transitions as to allow <em>clock recovery</em>;</li>
<li><strong>Clock Tolerance Compensation hardware</strong>, which allows the two sides to communicate even with slightly-varying clock frequencies;</li>
<li>Hardware to orchestrate <strong>link training</strong> and <strong>receiver equalization</strong>, which helps to deal with non-ideal transmission properties;</li>
<li><strong>Scrambling</strong> and <strong>descrambling</strong> hardware, which help to reduce harmful interference.</li>
</ul>
<p>This omits a few minor things, such as USB3's <em>Low Frequency Periodic Signaling</em>; but these are the major components.</p>
<h5 id="oh-and-one-more-thing-its-hard-to-get-good-resources">Oh, and one more thing: it's hard to get good resources.</h5>
<p>Finally, ignoring all the physical layer challenges associated with bringing a link up, there's one more major obstacle: it's hard to get good resources for working with USB3:</p>
<ul>
<li>Most hardware enabling custom USB designs is expensive; and <a href="https://lab.ktemkin.com/post/ab07-usb3fmc-wtf/">still rife with issues</a>.</li>
<li>Most USB3 tooling is <a href="https://www.totalphase.com/products/beagle-usb5000-v2-ultimate/">very expensive</a>, and still rife with issues.</li>
<li>There's very little documentation in support of the specification; and what documentation exists still hasn't been
used enough to <a href="https://lab.ktemkin.com/post/mindshare-usb3/">identify all of its errors</a>.</li>
</ul>
<p>Hopefully, at some point, I'll have built enough tooling to change this.</p>


  </article></div>]]>
            </description>
            <link>https://lab.ktemkin.com/post/why-is-usb3-harder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24704298</guid>
            <pubDate>Wed, 07 Oct 2020 01:11:58 GMT</pubDate>
        </item>
    </channel>
</rss>
