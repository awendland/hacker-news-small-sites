<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 28 Dec 2020 17:05:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 28 Dec 2020 17:05:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kit FUI – User interfaces found in films]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25547352">thread link</a>) | @ChrisArchitect
<br/>
December 26, 2020 | https://www.saji8k.com/kit-fui/ | <a href="https://web.archive.org/web/*/https://www.saji8k.com/kit-fui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>User interfaces from film, television, video games and the designers that created them.</p>
				<p>Keep track of updates to Kit FUI on my <a href="https://www.saji8k.com/blog/">blog</a> or by following me on <a href="https://twitter.com/saji8k">Twitter</a> or <a href="https://www.facebook.com/saji8k">Facebook</a>.</p>
				<p>If you have suggestions for the site or would like to submit your work, send me a <a href="https://twitter.com/saji8k">tweet</a>.</p>
			</div>
		</div><div>
			<div>
				<h3>What is FUI?</h3>
				<p>Fantasy User Interfaces, Fictional User Interfaces, Fake User Interfaces, Futuristic User Interfaces, Film User Interfaces, Future User Interfaces. Regardless of what the F stands for, they all represent the same thing, the user interfaces (UIs) and heads up displays (HUDs) found in many popular movies and television shows.</p>
				<p>Most FUIs are not actual computer programs but simply animations being played back at the correct time or added in post production. These graphics and animations are designed in applications like Adobe Illustrator, Adobe After Effects and Maxon Cinema 4D.</p>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.saji8k.com/kit-fui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547352</guid>
            <pubDate>Sat, 26 Dec 2020 23:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run More Stuff in Docker]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 178 (<a href="https://news.ycombinator.com/item?id=25547205">thread link</a>) | @psxuaw
<br/>
December 26, 2020 | https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-03-10</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech/">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming/">programming</a>
			
		</span>
		
	</h6>
	<hr>
	<p>In 2020, <strong>Docker is the best medium for distributing and running most developer-facing software</strong>. It’s widely accepted that Docker is great for building and deploying the artifacts for your enterprise web app, but this is less well known when it comes to things like developer tools. However, running tools in containers has many benefits over installing and running them in the conventional way, and we should all start doing it more.</p>
<h2 id="why">Why?</h2>
<p>I install very few things on either my personal or work computer. I don’t have <code>terraform</code>, <code>aws</code>, <code>node</code>, or <code>pip</code> installed, but I use them all the time. I have a Docker image for each, and I run them in containers with minimal privileges. I’m definitely <a href="https://github.com/jessfraz/dockerfiles">not the only one</a>, but it’s not as popular as it should be. None of these tools actually need full access to my computer to do their work, but that is normally how they’re run.</p>
<p>Here are some benefits of running these tools in Docker.</p>
<h4 id="cross-platform">Cross-platform</h4>
<p>At this point in time, Docker is ubiquitous and you get cross-platform support for free, thanks to Docker Inc’s investments in that area (Docker for Mac &amp; Windows). This is useful both for people developing/distributing tools, and for people working on a team that needs to share tooling. You have one Docker image and it will run pretty much everywhere. OS package managers can be great, but they’re very much not cross-platform. Things like <code>pip install</code> will sometimes work cross-platform, but have other serious drawbacks.</p>
<p>While every platform has its own sandboxing mechanisms, running with Docker lets you specify runtime context and enforce a sandbox in a cross-platform way, which is useful when you expect anybody else to run the same command as you.</p>
<h4 id="sandboxed">Sandboxed</h4>
<p>When you <code>docker run</code>, you have to be explicit about privileges. A container is mostly sandboxed and unprivileged by default. It doesn’t have access to ambient environment variables. It doesn’t have access to the host system’s disk. A tool like <code>jq</code> just needs to read stdin and print to stdout. It doesn’t need access to my shell’s environment variables (or, if it does, I explicitly pass those through to the container). <code>yarn</code> should be fine operating on just the working directory, and maybe a cache directory. I don’t want it to have access to my ~/.aws directory (for <a href="https://securityboulevard.com/2020/01/malicious-npm-package-exfiltrating-data-from-unix-systems/">obvious reasons</a>).</p>
<p>Some tools do need access to things. I want my <code>aws</code> CLI to be able to read ~/.aws, so I grant that explicitly. This makes running the tool more verbose but less magical.</p>
<h4 id="simple-uniform-interface">Simple, uniform interface</h4>
<p>Running a program in a container is a lot like running it normally, but the user doesn’t need to jump through hoops to configure the system, build and install. The developer of the image jumps through those hoops and produces a runnable artifact with a simple interface. That interface is the same whether the tool was written in Python or Rust or C or anything else.</p>
<p>Downloading a pre-compiled binary is almost like this, except with worse odds. Maybe there’s a build for your architecture. If it was statically linked, you’re golden. Otherwise, use <code>ldd</code> to reverse engineer the fact that you need to install <code>libjpeg</code>.</p>
<p>A Docker image “just works”. It comes bundled with what it needs to run.</p>
<p>If you think about it, it’s pretty strange to execute <a href="https://github.com/aws/aws-cli/tree/0b3d9a4260fdda5c6a8b736439e0776bc2252f41#installation"><code>pip install awscli</code></a>. It’s immaterial to an end user that the tool is written in Python, and requiring him or her to set up and use Python tooling doesn’t make sense. I don’t mean to pick on <code>pip</code> or <code>awscli</code> in particular, but this is a poor mechanism for distributing non-library software. It leaves <a href="https://github.com/aws/aws-cli/issues?q=is%3Aissue+pip">far too much to chance</a>. It’s a clumsy and leaky interface for tool distribution. So is <code>npm install</code>. So is telling somebody to install your tool by installing golang, and then running <code>go build</code>. No, thanks. If I’m hacking on the project, then by all means. But don’t foist that on end users.</p>
<h4 id="facilitates-version-pinning">Facilitates version pinning</h4>
<p>When collaborating, it’s important that people run the same versions of software to get consistent results. Version pinning is essential to that. Pinning dependency manifests is good, but it’s not enough: it only covers the one situation of installing things with a language package manager. It may not cover using the same linter version, or the same version of <code>node</code>, <code>aws</code>, <code>ansible</code>, <code>terraform</code>, or any libraries installed at the OS level. Invoking <code>docker run node:13.10.1</code>, instead of whatever the user happens to have installed as <code>node</code>, solves this problem in general. Having the ability to specify the versions at the point of use, rather than out-of-band as part of some other installation process, is also convenient and tidy.</p>
<p>It’s easy to run different versions of a tool side by side with Docker. Docker solves this more generally than things like virtualenv for Python, rvm for Ruby, etc. You specify what version of the tool to use when you’re invoking it, and it pins a whole lot of context more than just the tool’s version, which is always preferable for reproducibility.</p>
<p>In one recent situation at work, we had a test case start failing when we upgraded our runtime from Python 3.6.5 to Python 3.6.8. Having the ability to easily run the tests with any version of Python made it easy to bisect and identify a change in 3.6.7 as the cause. This could have been debugged without Docker, but it was particularly natural and easy with Docker.</p>
<h4 id="reproducible">Reproducible</h4>
<p>Invoking a tool with <code>docker run</code> should specify everything needed to reproducibly run it somewhere else. It’s running some specific version of the tool? Okay. It needs my AWS credentials? Okay. It needs some specific combination of environment variables set? Okay.</p>
<p>I cringe when I see a Makefile or build instructions saying to run <code>yarn</code> or <code>terraform</code> or <code>go</code>. What version? What’s being assumed about my environment? Maybe this worked on your <a href="https://martinfowler.com/bliki/SnowflakeServer.html">unique snowflake of a machine</a> 18 months ago, but good luck with it now. (My laptop is a unique snowflake too. Everyone’s is, until we all figure out how to use NixOS.)</p>
<p>Running tools in Docker, there are few expectations of the runtime environment beyond having Docker installed. All the other requirements should be made explicit in the <code>docker run</code> command. The command that you’re running locally will work the same on your colleague’s machine, and in any CI with minimal configuration (or none). This is absolutely critical, especially when working on a team. This is a far more robust approach than expecting (requiring) anybody’s system, or a CI slave, to be set up “just so”.</p>
<h4 id="minimizes-global-state">Minimizes global state</h4>
<p>I have very few things installed on my host system beyond the base OS. There’s less to remember when setting up a new machine, fewer things to go wrong during upgrades, and fewer opportunities for conflicts over shared libraries.</p>
<h2 id="examples">Examples</h2>
<h4 id="one-offs">One-offs</h4>
<p>I have bash aliases for a bunch of tools that I run all the time. These are just for my own convenience. For anything shared with other people, I’d use a project’s Makefile (see below).</p>
<ul>
<li>
<p><strong>Some basics</strong></p>
<pre><code>alias aws='docker run --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 -e AWS_PROFILE mikesir87/aws-cli:1.18.11 aws'
alias jq='docker run -i --rm jess/jq jq'
alias terraform='docker run -it --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 hashicorp/terraform:0.12.23'
</code></pre><p>With these aliases, I can <code>AWS_PROFILE=... aws sts get-caller-identity | jq -r .Arn</code> as if they were “really” installed.</p>
</li>
<li>
<p><strong>zoom</strong></p>
<p>Here’s zoom (video conferencing):</p>
<pre><code>alias zoom='xhost +local:docker \
    &amp;&amp; docker run -it --rm -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    --device /dev/video0 --device /dev/snd:/dev/snd --device /dev/dri -v /dev/shm:/dev/shm \
    -v ~/.config/zoom/.zoom:/root/.zoom -v ~/.config/zoom/.config/zoomus.conf:/root/.config/zoomus.conf \
    jess/zoom-us'
</code></pre><p>Notice that <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5">port 19421</a> remains stubbornly closed unless we explicitly let the container claim it on the host.</p>
</li>
<li>
<p><strong>Snes9x</strong></p>
<p>I do this with other stuff, too. Here’s Snes9x (can you imagine <a href="http://www.snes9x.com/phpbb3/viewtopic.php?t=23603">installing it</a>?):</p>
<pre><code>alias snes9x='docker run -it --rm -u 1000:1000 -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    -v /run/dbus:/run/dbus -v /dev/shm:/dev/shm \
    --device /dev/snd --device /dev/dri --device /dev/input/js0 \
    -e PULSE_SERVER=unix:$XDG_RUNTIME_DIR/pulse/native -v $XDG_RUNTIME_DIR/pulse/native:$XDG_RUNTIME_DIR/pulse/native \
    --group-add $(getent group audio | cut -d: -f3) \
    -v ~/.config/snes9x:/.snes9x/ -v ~/Games/SNES:/SNES -v ~/.local/share:/.local/share \
    danniel/snes9x'
</code></pre></li>
</ul>
<h4 id="projects">Projects</h4>
<p>For things that are project-specific, or in a team setting, all useful commands should be codified in something like a Makefile. This wraps the complexity and verbosity of the <code>docker run</code> incantations, makes it possible to share them easily, and makes them passably ergonomic.</p>
<ul>
<li>
<p><strong>hugo</strong></p>
<p>When I’m writing an article for this site, I run <code>make hugo-watch</code> and load http://localhost:1313 in a web browser:</p>
<pre><code>hugo = docker run --rm -u $$(id -u):$$(id -g) -v "$$(pwd)":/src -v "$$(pwd)"/output:/target $(2) klakegg/hugo:0.54.0-ext-alpine $(1)

hugo-watch:
    mkdir -p output
    $(call hugo, server, -it -p 1313:1313)
</code></pre></li>
<li>
<p><strong>prettier</strong></p>
<p>To format a JavaScript project, we might have the make targets</p>
<pre><code>prettier = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" elnebuloso/prettier:1.19.1 $(1) "src/**/*.js"

format:
    $(call prettier)

format-check:
    $(call prettier, --check)
</code></pre><p>We would run <code>make format</code> to format the code and <code>make format-check</code> to check the style. It runs on my Linux box, it runs on my colleague’s Mac, and it runs in any Docker-equipped CI. None of those machines need to have <code>node</code>, <code>npm</code>, or <code>prettier</code> installed. We completely trivialize the issues of versioning and of synchronizing our environments: the version is specified once, here in the Makefile, and it’s obeyed everywhere.</p>
<p>In a language like Python, where libraries are forced to fight to the death for control of transitive dependency versions, lifting a tool like <code>black</code> or <code>flake8</code> out of the project’s requirements.txt, and into a self-contained Docker image, can be a big …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547205</guid>
            <pubDate>Sat, 26 Dec 2020 23:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost nuclear device atop of Nanda Devi]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25547123">thread link</a>) | @hudvin
<br/>
December 26, 2020 | https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device | <a href="https://web.archive.org/web/*/https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <div id="container">
                          
  <div>
    


<div id="story-f889b712-c891-4d7d-b740-a08c112f512d" data-public-preview="">
  <article data-story-url="" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc" data-story-headline="Nanda Deviâ€™s Nuclear Secret and a Botched CIA Operation" data-loader="story">
    
          <div>
    <figure>
        <img src="https://images.assettype.com/indynetwork%2F2020-09%2Fde00724b-9ea2-4f38-82dc-ca78b3e6dee0%2FImage_9.jpg?w=1500">
    </figure>
</div>
<div>
  <div>
    
    <div itemprop="articleBody" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc">
      
                        
              <div data-card-content-id="efdfb573-ba3e-4852-b9ee-0486b7498411" data-card-version-id="49dda451-df77-4ea6-9f9b-3d28a0f6cf13">
        
      <div id="inf-card-b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-id="b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-type="text">
          <div>
    <p>The past few months have seen a rise in volatility along the Indo-Tibetan border, with the forces of both India and China coming to blows. While these events are extraordinary in present times, the border has witnessed far more heated exchanges, most notably during the 1962 <a href="https://www.livehistoryindia.com/in-the-news/2020/06/21/across-the-karakorams">Indo-China</a> War.</p><p>The unforgiving terrain that marks the frontier creates an additional dimension to the already complex nature of these clashes, whether in regard to more conventional manoeuvres, or other irregular military activity which is far more frequent. This is the story of the latter kind of action, that of daring espionage against Communist China, played for the highest stakes with the greatest risks.</p>
  </div>
</div>



      <div id="inf-card-33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-id="33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-type="text">
          <div>
    <p>Cold, harsh, inviolate. Straddling between the <a href="https://www.livehistoryindia.com/snapshort-histories/2017/06/21/kumaon-echoes-of-the-past">Kumaon</a> and Garhwal districts of Uttarakhand, deep in the Himalayas, stands Nanda Devi. The second-highest mountain in India, towering at an astonishing 25,646 feet, it is named after the patron goddess of Uttarakhandâ€” the mountain being her temporal manifestation.</p><p>Its unique topographical environment makes it one of the most inaccessible places on Earth. Surrounded on three sides by massive mountain rampartsâ€”its natural fortifications measuring at no point below 17,000 feetâ€” only the narrow and dangerously steep Rishi Ganga river gorge allows access to it. The mountain in itself is a citadel of rock and ice, with steep, angled faces and avalanche-prone ridges guarding its summit. Its immense proportions make it far tougher to climb than Everest. It is at once a supremely magnificent and terrifyingly intimidating mountain.</p>
  </div>
</div>



      <div id="inf-card-67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-id="67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Map of the Nanda Devi Sanctuary, the thick hachures marking the semi-circular natural fortifications in the form of mountains that surround most of the Nanda Devi" src="https://images.assettype.com/indynetwork%2F2020-09%2F65d1a1da-2c67-4059-aeb0-c5437f7f191d%2FImage_3.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-id="ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-type="text">
          <div>
    <p>For much of the 19th and early 20th century, before it was finally summited in 1936, it was considered to be the third pole â€“ a point of virtual inaccessibility. However, this awe-inspiring creation of nature shelters a device, abhorrent to nature, manufactured by man. Somewhere high on the harrowing slopes of Nanda Devi, buried deep in snow, lies a lost nuclear listening device slowly depleting its plutonium cores. Containing 5kg of plutonium â€“ 1 kg less than the nuclear bomb dropped on Nagasaki â€“ with a predicted lifespan of 900 years, this nuclear trespasser has been forfeited to the mountain forever.</p><p>This is the story behind one of the most audacious acts of espionage in the 20th century.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5350a04d-7e5b-48a5-9ccc-0c0b06771394" data-card-version-id="b82a93e5-a227-4175-b91c-b1fe616b5c7c">
        
      <div id="inf-card-d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-id="d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-type="text">
          <div>
    <p><strong>Cold War In High Places</strong></p><p>The year was 1965, and the Cold War was reaching its apogee, with America stretching its geopolitical reach to all corners of the world in order to counter the communist influence. Closer to home, the War of â€™62 had left India intensely wary of its neighbour, China. To add fuel to simmering embers, China carried out its first nuclear test in 1964 in Xinjiang, a province that borders the northern tip of India. In this atmosphere of intense mutual suspicion and paranoia, the Pentagon began concocting a plan that would help both India and America keep a closer eye on China, especially with regard to its nuclear programme.</p><p>With satellites that could gather useful photographic intelligence still a few years away, Americaâ€™s Central Intelligence Agency (CIA) along with the Indian Intelligence Bureau (IB) planned on placing a powerful listening device at a point of extreme prominence along the Indo-Tibetan border. The site where the device would be placed was key as it would need to have uninterrupted access in order to intercept Chinese radio signals. This meant it would have to be positioned on a mountain that was high as well as close to the Tibetan plateau. With an unparalleled height advantage and an unobstructed view of China from its summit, there was no better choice than Nanda Devi.</p>
  </div>
</div>



      <div id="inf-card-21631012-ab2e-4940-a233-267421b9382d" data-story-element-id="21631012-ab2e-4940-a233-267421b9382d" data-story-element-type="text">
        <div>
     <hr>
  <div>
    <blockquote>To ensure the longevity and endurance of the device, which was supposed to work at an altitude of nearly 26,000 feet, it was decided that it would be nuclear-powered. </blockquote>
  </div>
  <hr>
</div>
  </div>



      <div id="inf-card-ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-id="ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-type="text">
          <div>
    <p>A System for Nuclear Auxiliary Power (SNAP) generator was designed so that it would power the telemetry functions of the device, a power unit similar to the ones being used in space at the time.</p><p>It was within the SNAP that seven plutonium fuel rods would be stored, made from a compound of Pu-238 and Pu-239. Once activated, the SNAP would constantly be converting radioactive heat energy created by the rods into electricity, which would power the multiple-sensor device as well as its six-foot-long antenna.</p><p>With the technical aspect settled, the question of who would carry and set up all this equipment remained. Only two expeditions had summited the mountain up until then, and more than a few climbers had died. There was no doubt that only the very best mountaineers could be trusted to carry a nuclear payload up one of the most difficult mountains in the world.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5aeaa671-5f93-450a-971d-b5690e92888f" data-card-version-id="58f0cfc2-71cc-46c3-a836-d90e638e4071">
        
      <div id="inf-card-a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-id="a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-type="text">
          <p><strong>League of Extraordinary Climbers</strong></p>
</div>



      <div id="inf-card-44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-id="44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Captain MS Kohli AVSM, leader of the covert climbing expeditions, now at the ripe old age of 88. " src="https://images.assettype.com/indynetwork%2F2020-09%2Faea6959e-2270-436f-bbd2-426467f4f81b%2FImage_8.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-id="9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-type="text">
          <div>
    <p>A group of 14 American and four Indian mountaineers was assembled. In totality, they represented the cream of a mountaineering generation. Among the Americans, some of the more famous climbers were Dr Robert Schaller, Tom Frost and Jim McCarthy. The Indian contingent consisted of Captain M S Kohli, Sonam Wangyal, H C S Rawat and G S Bhangu. All four had been members of the successful 1965 Indian Everest Expedition, which had put a record nine climbers on the summit. They were in fact enlisted for this covert expedition just a few days after returning from Everest. Together, the entire group was no less than a mountaineering dream team.</p><p>After having sworn their respective oaths of secrecy, the climbing team was flown to Mount McKinley in Alaska, the highest mountain in North America, to prepare for the arduous expedition ahead. While all of them were without doubt among the most experienced climbers at the time, they were rather new to the more idiosyncratic aspect of the expedition â€“ that of dealing with nuclear material.</p><p>American climber Jim McCarthy was appointed as the designated member of the team who would handle the plutonium rods. Through the summer of 1965, officials from Americaâ€™s Atomic Energy Commission trained McCarthy to load and unload the device without disturbing its deadly occupant. Other team members were briefed on the dangers of their special load as well, and ways to ensure minimum exposure to the deadly radioactive isotopes.</p><p>All climbers were going to be paid $1,000 per month, a hefty amount in the 1960s. While there would be personal gratification from having been of service to their respective nations, they were on no account to tell anyone about the nature of their expedition. The cover for the entire team was that they were a joint Indo-American mountaineering team conducting research for high-altitude flight for the American Air Force. Before departing for India, the covert operation was finally given its official codename: Operation Hat.</p>
  </div>
</div>



      <div id="inf-card-368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-id="368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-type="image">
  <div>
  <figure>
    <img alt="A Nanda Devi Temple at Munsiyari. This particular temple, and itâ€™s idol inside, is among the oldest of Uttarakhand" src="https://images.assettype.com/indynetwork%2F2020-09%2F49dfca8c-132b-43f5-b063-81b86f25e855%2FImage_5.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-id="5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-type="text">
          <div>
    <p><strong>Into the Sanctuary of the Goddess</strong></p><p>In an effort to attract minimal attention, most of the mountaineers were flown into base camp by helicopter in September 1965. However, the climbing equipment, rations, and of course the listening device itself â€” stored inside a solid lead casket â€” were transported in the time-honoured fashion, carried by nearly 150 <em>dotial</em> porters through the Rishi Ganga gorge. The special load did not go unnoticed among the porters, and apart from its unusual weight, many of them alleged to have felt heat emanating from the casket. Mounted on poles, some climbers later noted its uncanny resemblance to the Biblical Ark of the Covenant, in the manner it was transported as well as the supreme power it possessed.</p><p>After having established themselves at the base of the mountain, the mountaineers methodically began making their way up Nanda Devi. Establishing a series of camps along the climbing route, the team was finally positioned to make an attempt on the summit in the middle of October. It was then that catastrophe struck.</p><p>A violent storm hit the mountain and made it impossible to continue. The summit team, along with the device, was encamped just 2,000 feet below their objective. The extreme conditions, however, greatly endangered their position. Keeping in mind the extreme volatility of such storms, Captain Kohli â€” the leader of the climbing team â€” called for an immediate retreat.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="65e7e1e4-a3b0-4ec4-9aaa-c4696502703a" data-card-version-id="344b6037-e7b7-4181-b199-8bea1745da05">
        
      <div id="inf-card-6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-id="6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-type="text">
          <div>
    <p>Carrying the 56 kg listening device in deteriorating weather conditions at 23,000 feet was going to be a Herculean task. Prioritising the need for a quick descent to minimise the risk to the lives of his fellow climbers, Kohli decided to ditch the equipment in the high camp. He reasoned that another expedition could always be mounted when weather conditions improved, in order to retrieve the device. On the other hand, the life of a fellow climber was irreplaceable.</p><p>Thus, with all the climbers having safely descended, the expedition came to an end. Being late in the year, the weather window to climb Nanda Devi was now closed. Any new expedition would have to bide their time till the following year. The nuclear device too, abandoned on a high precipice of the mountain, would have to wait.</p><p><strong>Plan B</strong></p><p>With the arrival of spring in 1966, a second expedition was launched to locate the equipment, and most importantly the nuclear device, that had been left the previous autumn. The composition of the climbing team was more or less the same, and soon they were scouring the slopes of Nanda Devi, trying to find their highly valuable and potentially dangerous belongings. But it was all …</p></div></div></div></div></div></div></article></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</a></em></p>]]>
            </description>
            <link>https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547123</guid>
            <pubDate>Sat, 26 Dec 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dunning-Kruger Effect Is Probably Not Real]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25546787">thread link</a>) | @ingve
<br/>
December 26, 2020 | https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real | <a href="https://web.archive.org/web/*/https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I want the Dunning-Kruger effect to be real. First described in<a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.77.6.1121"> a seminal 1999 paper</a> by David Dunning and Justin Kruger, this effect has been the darling of journalists who want to explain why dumb people don’t know they’re dumb. There’s even<a href="https://youtu.be/BdnH19KsVVc"> video of a fantastic pastiche</a> of Turandot’s famous aria, <i>Nessun dorma,</i> explaining the Dunning-Kruger effect. “They don’t know,” the opera singer belts out at the climax, “that they don’t know.”</p>

<p>I was planning on writing a very short article about the Dunning-Kruger effect and it felt like shooting fish in a barrel. Here’s the effect, how it was discovered, what it means. End of story.</p>

<p>But as I double-checked the academic literature, doubt started to creep in. While trying to understand the criticism that had been leveled at the original study, I fell down a rabbit hole, spoke to a few statistics-minded people, corresponded with Dr. Dunning himself, and tried to understand if our brain really was biased to overstate our competence in activities at which we suck... or if the celebrated effect was just a mirage brought about by the peculiar way in which we can play with numbers.</p>

<p>Have we been overstating our confidence in the Dunning-Kruger effect?</p>

<h5><b>A misunderstood effect</b></h5>

<p>The most important mistake people make about the Dunning-Kruger effect, according to Dr. Dunning, has to do with who falls victim to it. “The effect is about us, not them,” he wrote to me. “The lesson of the effect was always about how we should be humble and cautious about ourselves.” The Dunning-Kruger effect is not about dumb people. It’s mostly about all of us when it comes to things we are not very competent at.</p>

<p>In a nutshell, the Dunning-Kruger effect was originally defined as a bias in our thinking. If I am terrible at English grammar and am told to answer a quiz testing my knowledge of English grammar, this bias in my thinking would lead me, according to the theory, to believe I would get a higher score than I actually would. And if I excel at English grammar, the effect dictates I would be likely to slightly underestimate how well I would do. I might predict I would get a 70% score while my actual score would be 90%. But if my actual score was 15% (because I’m terrible at grammar), I might think more highly of myself and predict a score of 60%. This discrepancy is the effect, and it is thought to be due to a specific problem with our brain’s ability to assess its skills.</p>

<p>This is what student participants went through for Dunning and Kruger’s research project in the late 1990s. There were assessments of grammar, of humour, and of logical reasoning. Everyone was asked how well they thought they did and everyone was also graded objectively, and the two were compared.</p>

<p>Since then, many studies have been done that have reported this effect in other domains of knowledge. Dr. Dunning tells me he believes the effect “has more to do with being <i>misinformed</i> rather than uninformed.” If I am asked the boiling point of mercury, it is clear my brain does not hold the answer. But if I am asked what is the capital of Scotland, I may think I know enough to say Glasgow, but it turns out it’s Edinburgh. That’s misinformation and it’s pushing down on that confidence button in my brain.</p>

<p>So case closed, right? On the contrary. In 2016 and 2017, two papers were published in a mathematics journal called <i>Numeracy</i>. In them, the authors argued that the Dunning-Kruger effect was a mirage. And I tend to agree.</p>

<h5><b>The effect is in the noise</b></h5>

<p>The<a href="https://scholarcommons.usf.edu/numeracy/vol9/iss1/art4/"> two</a><a href="https://scholarcommons.usf.edu/numeracy/vol10/iss1/art4/"> papers</a>, by Dr. Ed Nuhfer and colleagues, argued that the Dunning-Kruger effect could be replicated by using random data. “We all then believed the [1999] paper was valid,” Dr. Nuhfer told me via email. “The reasoning and argument just made so much sense. We never set out to disprove it; we were even fans of that paper.” In Dr. Nuhfer’s own papers, which used both computer-generated data and results from actual people undergoing a science literacy test, his team disproved the claim that most people that are unskilled are unaware of it (“a small number are: we saw about 5-6% that fit that in our data”) and instead showed that both experts and novices underestimate and overestimate their skills with the same frequency. “It’s just that experts do that over a narrower range,” he wrote to me.</p>

<p>Wrapping my brain around all this took weeks. I recruited a husband-and-wife team, Dr. Patrick E. McKnight (from the Department of Psychology at George Mason University, also on the advisory board of Sense About Science and STATS.org) and Dr. Simone C. McKnight (from Global Systems Technologies, Inc.), to help me understand what was going on. Patrick McKnight not only believed in the existence of the Dunning-Kruger effect: he was teaching it to warn his students to be mindful of what they actually knew versus what they thought they knew. But after replicating Dr. Nuhfer’s findings using a different platform (the statistical computing language R instead of Nuhfer’s Microsoft Excel), he became convinced the effect was just an artefact of how the thing that was being measured was indeed measured.</p>

<p>We had long conversations over this as I kept pushing back. As a skeptic, I am easily enticed by stories of the sort “everything you know about this is wrong.” That’s my bias. To overcome it, I kept playing devil’s advocate with the McKnights to make sure we were not forgetting something. Every time I felt my understanding crystallize, doubt would creep in the next day and my discussion with the McKnights would resume.</p>

<p>I finally reached a point where I was fairly certain the Dunning-Kruger effect had not been shown to be a bias in our thinking but was just an artefact. Here then is the simplest explanation I have for why the effect appears to be real.</p>

<p>For an effect of human psychology to be real, it cannot be rigorously replicated using random noise. If the human brain was predisposed to choose heads when a coin is flipped, you could compare this to random predictions (heads or tails) made by a computer and see the bias. A human would call more heads than the computer would because the computer is making random bets whereas the human is biased toward heads. With the Dunning-Kruger effect, this is not the case. Random data actually mimics the effect really well.</p>

<p>The effect as originally described in 1999 makes use of a very peculiar type of graph. “This graph, to my knowledge, is quite unusual for most areas of science,” Patrick McKnight told me. In the original experiment, students took a test and were asked to guess their score. Therefore, each student had two data points: the score they thought they got (self-assessment) and the score they actually got (performance). In order to visualize these results, Dunning and Kruger separated everybody into quartiles: those who performed in the bottom 25%, those who scored in the top 25%, and the two quartiles in the middle. For each quartile, the average performance score and the average self-assessed score was plotted. This resulted in the famous Dunning-Kruger graph.</p>

<p><img height="627" width="725" src="https://www.mcgill.ca/oss/files/oss/figure_1_3.png" alt=""></p>

<p>Plotted this way, it looks like those in the bottom 25% thought they did much better than they did, and those in the top 25% underestimated their performance. This observation was thought to be due to the human brain: the unskilled are unaware of it. But if we remove the human brain from the equation, we get this:</p>

<p><img height="451" width="1086" src="https://www.mcgill.ca/oss/files/oss/figure_2_1.png" alt=""></p>

<p>The above Dunning-Kruger graph was created by Patrick McKnight using computer-generated results for both self-assessment and performance. The numbers were random. There was no bias in the coding that would lead these fictitious students to guess they had done really well when their actual score was very low. And yet we can see that the two lines look eerily similar to those of Dunning and Kruger’s seminal experiment. A<a href="https://www.sciencedirect.com/science/article/pii/S019188690100174X"> similar simulation</a> was done by Dr. Phillip Ackerman and colleagues three years after the original Dunning-Kruger paper, and the results were similar.</p>

<p>Measuring someone’s perception of anything, including their own skills, is fraught with difficulties. How well I think I did on my test today could change if the whole thing was done tomorrow, when my mood might differ and my self-confidence may waver. This measurement of self-assessment is thus, to a degree, unreliable. This unreliability--sometimes massive, sometimes not--means that any true psychological effect that does exist will be measured as smaller in the context of an experiment. This is called attenuation due to unreliability. “Scores of books, articles, and chapters highlight the problem with measurement error and attenuated effects,” Patrick McKnight wrote to me. In his simulation with random measurements, the so-called Dunning-Kruger effect actually becomes <i>more</i> visible as the measurement error increases. “We have no instance in the history of scientific discovery,” he continued, “where a finding improves by increasing measurement error. None.”</p>

<h5><b>Breaking the spell</b></h5>

<p>When I plug “Dunning-Kruger effect” into Google News, I get over 8,500 hits from media outlets like <i>The New York Times</i>, <i>New Scientist</i>, and the CBC. So many simply endorse the effect as a real bias of the brain, so it’s no wonder that people are not aware of the academic criticism that has existed since the effect was first published. It’s not just Dr. Nuhfer and his <i>Numeracy </i>papers. Other academic critics have pointed the finger, for example, at regression to the mean.</p>

<p>But as Patrick McKnight points out, regression to the mean occurs when the same measure is taken over time and we track its evolution. If I take my temperature every morning and one day spike a fever, that same measure will (hopefully) go down the next day and return to its mean value as my fever abates. That’s regression to the mean. But in the context of the Dunning-Kruger effect, nothing is measured over time, and self-assessment and performance are different measures entirely, so regression to the mean should not apply. The unreliability of the self-assessment …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</a></em></p>]]>
            </description>
            <link>https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546787</guid>
            <pubDate>Sat, 26 Dec 2020 22:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of NPM scripts]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25546460">thread link</a>) | @efortis
<br/>
December 26, 2020 | https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
In 2016, Sam Saccone <a rel="noopener" target="_blank" href="https://www.kb.cert.org/vuls/id/319816">discovered a vulnerability</a> that
allows adversaries to run arbitrary scripts when installing an NPM package of
theirs. As mitigation, NPM co-founder Laurie Voss <a rel="noopener" target="_blank" href="https://blog.npmjs.org/post/141702881055/package-install-scripts-vulnerability">
suggests</a>:
</p>
<ul>
<li>
<b>Option 1</b>: adding <code>--ignore-scripts</code> when running <code><span>npm</span>
install</code>
</li>
<li>
<b>Option 2</b>: permanently adding <code>ignore-scripts=true</code> to <code>.npmrc</code>
</li>
</ul>
<p>
UI Drafter uses the latter because it avoids having to
remember the flag everytime. But that option disables NPM
<code>"scripts"</code>. Therefore, we end up with two alternatives:
</p>
<ul>
<li>
<b>Option A</b>: overriding: <code><span>npm</span> run --ignore-scripts=false
<b>test</b></code>
</li>
<li>
<b>Option B</b>: using this shell script or a <a href="#-Makefile">Makefile</a>:
</li>
</ul>
<pre><span>#!/bin/sh</span>

<span>case</span> <span>$1</span> <span>in</span>
  <b>dev</b>)   ./make-dev.js <span>;;</span>
  <b>test</b>)  mocha <span>"src/**/*.test.js"</span><span></span> <span>;;</span>
  <b>lint</b>)  eslint src <span>;;</span>
  <b>slint</b>) stylelint <span>"src/**/*.css"</span><span></span> <span>;;</span>

  <b>prod</b>)  <span>time</span> ./make-production.js <span>;;</span>
  <b>all</b>)   <span>$0</span> <b>test</b> &amp;&amp; <span>$0</span> <b>lint</b> &amp;&amp; <span>$0</span> <b>slint</b> &amp;&amp; <span>$0</span> <b>prod</b> <span>;;</span>

  *)     <span>echo</span> <span>"Invalid task: <span>$1</span>"</span><span>;</span> <span>exit</span> <span>1</span> <span>;;</span>
<span>esac</span>
</pre>
<p>Which can be ran as:</p>
<pre>./<span>make</span> <b>test</b>
</pre>
<p>
If the package is not globally installed, prefix the path. For example:
</p>
<pre><b>lint</b>) <span>node_modules/.bin/</span>eslint src <span>;;</span>
</pre>
<h3>Overriding at installation</h3>
<p>
If you need to install packages that install binary dependencies, or rely
on running an NPM script, override the <code>.npmrc</code>:
</p>
<pre><span>npm</span> install <span>--ignore-scripts=false</span> <i>package-name</i>
</pre>

<p>
EDIT: (Dec/27/2020) As suggested in the <a rel="noopener" target="_blank" href="https://news.ycombinator.com/item?id=25546460">Hacker News thread</a>:
</p>
<a id="-Makefile"></a>
<details>
<summary>
<h3>
Makefile
</h3>
</summary>
<pre><b>dev</b>:
	./make-dev.js
<b>test</b>:
	mocha <span>"src/**/*.test.js"</span>
<b>lint</b>:
	eslint src
<b>slint</b>:
	stylelint <span>"src/**/*.css"</span>

<b>prod</b>:
	sh -c 'time ./make-production.js'

<b>all</b>: test lint slint prod

<span>.PHONY: dev test lint slint prod all</span>
</pre>
<pre><span>make</span> <b>test</b>
</pre>
</details>
</article>
<article>
<hr>
<h2>Engineering Blog</h2>
<ul>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/isolated-tls-certificate-creation">Isolated Creation of Let's Encrypt TLS Certificates</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/bitwise-table-lookup">Bitwise Table Lookup</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering">More…</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546460</guid>
            <pubDate>Sat, 26 Dec 2020 21:06:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Pinterest SEO: An insider's guide]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25546430">thread link</a>) | @jmilinovich
<br/>
December 26, 2020 | https://blog.aesthetic.com/blog/pinterest-guide/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/pinterest-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>Pinterest is an extraordinarily powerful tool for consumers, but is still misunderstood by marketers. I worked at Pinterest for 2 years helping build their core content understanding technology, and learned a lot about what makes for a successful Pinterest marketing strategy. I hope this guide helps demystify how marketers can get the most from Pinterest as a marketing channel. </p><p>If you have any questions, please <a href="https://twitter.com/intent/tweet?text=Hey%20@jmilinovich">Tweet @jmilinovich</a>! </p><ol><li><a href="#Why-is-Pinterest-marketing-important">Why is Pinterest marketing important?</a></li><li><a href="#How-does-Pinterest-marketing-work">How does Pinterest marketing work?</a></li><li><a href="#How-to-create-a-Pinterest-marketing-plan">How to create a Pinterest marketing plan?</a></li><li><a href="#How-to-make-Pinterest-pins">How to make Pinterest pins?</a></li><li><a href="#How-to-make-Pinterest-Pins-popular">How to make Pinterest Pins popular?</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2>Pinterest as a distribution channel</h2><p>Pinterest is a powerful tool that helps people all over the world discover ideas for things to do in their lives. Whether it’s finding recipes, figuring out what to wear, finding new beauty tips or literally any other use case imaginable… people are doing it on Pinterest.</p><p>While search engines like Google focus on the bottom of the purchase funnel (ie, once someone knows that they have a need and are actively looking for it) and social networks like Facebook and Instagram focus on the top of the funnel (ie, when customers are passively looking to consume content with no intent), Pinterest is the only place on the internet that lets marketers reach consumer in the consideration phase. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/2514c6be4877df4b7599580c5af4d1c3c2f54f86/453eb/img/posts/pinterest-guide/consideration.png" alt="The marketing consideration funnel"></p><p>This creates a big opportunity for businesses to get their products, goods and services in front of potential buyers while they’re deciding what they want to buy, but haven’t made the decision yet. That’s one of the most powerful things about Pinterest- people go there to find ideas, not just to make purchasing decisions. This means that marketers are able to reach consumers before they’ve made up their mind on what they’re looking to do.</p><h2>Pinterest as a source of inbound links</h2><p>While the most clear first-order effect to a strong Pinterest presence is creating a powerful new referral traffic source, there’s also a misunderstood but very powerful second-order effect: creating more inbound links to your website. </p><p>Have you noticed how no matter what you search for, it seems that you almost always see Pinterest results on the first page of Google? Pinterest’s core growth strategy has been about getting excellent at SEO, or search engine optimization. Practically speaking this means that the company has spent a lot of effort creating millions of high quality landing pages with the explicit purpose of being indexed by Google. Each of these landing pages shows dozens of Pins, and each contains a link to that Pin’s page on Pinterest. </p><p>As your content becomes more popular, it will begin showing up on more of Pinterest’s SEO pages, which means that it will be more readily indexed by Google. Since Google gives Pinterest’s domain a high authority and quality score, this means that over time you will start to accumulate some of this authority if your Pins are shown in prominent places. So, getting good at Pinterest doesn’t just help improve your Pinterest referral traffic, it can also improve your traffic from places like Google! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbc3082cbd708936207fcc8fed30415b5077ee03/32add/img/posts/pinterest-guide/pinterest-results.png" alt="Example of Pinterest landing pages"></p><h2>Pinterest is a search engine</h2><p>The most important thing to understand about Pinterest is that at its core it’s a search engine, not a social network.  People don’t use Pinterest to “follow” specific brands but rather to follow interests and search for ideas. A “Pin” is simply a visual bookmark to a webpage, and under the hood Pinterest’s technology stack is focused on figuring out what interests a Pin is about, and which users are interested in which interests. Content on Pinterest isn’t temporal like other social networks, but evergreen like on Google.</p><h2>Help Pinterest understand your content</h2><p>This means that the most important thing to get right for Pinterest marketing is helping Pinterest understand what interests your Pins are about. This means that the key underlying concept for Pinterest marketing is to create Pins for all of your web content, and then make sure that Pinterest has a clear understanding of what interests they align to. </p><p>Once Pinterest understands what a given Pin is about, it can start showing it to users to see how they interact with it. If they engage with it (ie, Save it to one of their boards or Click on it to see the underlying content), Pinterest uses this as a positive sign that this is quality content and will begin showing it to more people. </p><p>As such, one of the most important things to get right is having a clear strategy for how to communicate to Pinterest what your Pins are about and getting engagement signals on the Pins early. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/db6e047a9650880cd7f0be4c4718c0791790c2e0/18ef8/img/posts/pinterest-guide/pinterest-interests.png" alt="Example of Pinterest interests"></p><h2>Choose your Interests</h2><p>The most critical thing to get right in your Pinterest marketing plan is determining what Interests are most important to your business. There are <a href="https://docs.google.com/spreadsheets/d/1HxL-0Z3p2fgxis9YBP2HWC3tvPrs1hAuHDRtH-NJTIM/edit#gid=118370875">over 10,000 interests on Pinterest today</a>, ranging from highly broad to highly specific. Start by brainstorming what interests your target audience has today, as well as what interests your content is actually about. Look for the overlap of these two sets and choose the 10-15 that have the most promise to focus in on first. </p><h2>Create your Boards</h2><p>Once you’ve chosen the interests that you want to focus on, the next step is to decide on the architecture of your Pinterest for Business account. Pinterest accounts for users and businesses alike are defined by the boards that they create and post Pins to. You can think of a board as a folder of visual bookmarks that are public by default. When someone looks at your Pinterest account, the fastest way that they will understand what you’re about is by the names of the boards that you create. </p><p>Start by creating boards whose names are the same as the 10-15 interests you chose to focus on. It’s OK if they have more words in them as well, but make sure that the Interest name itself is very prominent. Make sure that each board has a very specific description that explains the core ideas that you’ll be pinning to the board.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/dadf2e2890dde22bbff64a7ded8e0dcf6b592fe9/31afa/img/posts/pinterest-guide/boards.png" alt="Example of Pinterest boards"></p><p>Next, you need to decide what content to start posting onto these boards. </p><h2>Pinning existing content</h2><p>There are only two kinds of Pins on Pinterest: Pins from your own website, and Pins from other people’s websites. Both are equally important to a strong Pinterest strategy. The first thing you should do is to fill your boards with Pins that are already on Pinterest and were created by other people. Spend some time saving 20-30 Pins to each of your boards. As you do this, Pinterest will also begin recommending new Pins in your homefeed that are related to what you’ve been Pinning. </p><p>The reason you’re seeing the Pins that Pinterest is recommending to you is because Pinterest already knows a lot about them and has a high confidence that users like you will find them interesting. When you save them to your boards, you’re giving Pinterest even more signal about what your board is about. This is extremely important, because Pinterest learns a lot about new Pins based on the other Pins that it shows up on boards with. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/a3580f834d291668bd22cae46f7854ddb0106853/de8da/img/posts/pinterest-guide/existing-pin.png" alt="Example of Pinterest pins"></p><p>Each week you should also continue to save new, existing content to your boards to keep giving Pinterest more signal and context for what your Pins are about. </p><h2>Pinning your own content</h2><p>Once you create a good base of existing Pins on your boards, you can start to plan your strategy for getting your own original content into Pinterest. First, go through all of your existing website content and map out what content would be relevant for the Pinterest audience. Generally speaking, the best content will be things like blog posts or eCommerce product landing pages. You should skip things like your homepage, about page, contact us page or other informational pages that don’t provide highly specific and useful content about a specific concept. </p><p>On social networks, it’s important that you have a steady pace of posting content into your feed so that you stay top of mind and also don’t inundate followers by posting 100 things at once. Pinterest is much more like Google, however, where you want them to know about your content upfront and all at once. </p><p>You should post all of your existing, relevant content to Pinterest upfront and then consistently add new content as it’s published online. Save it to the most relevant board to give Pinterest a clear understanding of what your content’s about. You can also post it to more than one board if it’s relevant to multiple categories. </p><p>The Pins that perform best on Pinterest have been created specifically for Pinterest following their <a href="https://business.pinterest.com/en-gb/content/creative-best-practices/">creative best practices</a>. Practically speaking this means that each Pin will require some editing work within a graphics editor tool. Generally speaking, each Pin can take anywhere from 5-20 minutes to create by hand if using a tool like Photoshop, Canva or Adobe Spark. This can be quite burdensome, especially if you’re trying to create dozens or hundreds of Pins for your site. </p><p><a href="https://www.aesthetic.com/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=pinterest-guide">Aesthetic’s software</a> is able to generate on-brand Pinterest Pins from a company’s website automatically. Simply enter a URL, and our app will create dozens of variations of graphics to promote that webpage, including several that follow Pinterest’s best practices guide. We’ve seen our users cut down the time it takes to create a Pin by 95% using our tool. </p><p>Once you’ve created your Pin graphics, you can upload them into the Pinterest system. Add the URL for each Pin along with a detailed description that touches upon what the Pins about and ideally mentions the specific interests that it’s related to. Post these to the right boards, and you’re off to the races! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/4ab1dd02738de6695f0118fd169a78c4e10d21bb/09e8b/img/posts/pinterest-guide/aesthetic-pins.png" alt="Example of Pinterest pins made with Aesthetic"></p><p>Once you’ve uploaded your content to Pinterest, you will see the impressions slowly start to trickle in as the system understands more about what your content’s about. Generally speaking it can take months for new content on Pinterest to get enough exposure for Pinterest to determine whether it’s sufficiently interesting enough for it to be promoted more widely within the system.</p><p>Another option to fast track the distribution of your Pins is to run small budget ads for your own Pins, targeting the Interests that they’re related …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aesthetic.com/blog/pinterest-guide/">https://blog.aesthetic.com/blog/pinterest-guide/</a></em></p>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/pinterest-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546430</guid>
            <pubDate>Sat, 26 Dec 2020 21:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with IP address parsing]]>
            </title>
            <description>
<![CDATA[
Score 424 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25545967">thread link</a>) | @mr_tyzic
<br/>
December 26, 2020 | https://blog.dave.tf/post/ip-addr-parsing/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/ip-addr-parsing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-12-25 00:00:00 +0000 UTC">December 25, 2020</time>
</p>
		


		

		<p>In my quest to write a fast IPv4+6 parser, I wrote a
slow-but-I-think-correct parser, to use as a base of comparison. In
doing so, I discovered more cursed IP address representations that I
was previously unaware of. Let’s explore together!</p>

<p>We start out simple, with IPv4 and IPv6 in what I’ll call their
“canonical form”: <code>192.168.0.1</code> and <code>1:2:3:4:5:6:7:8</code>. Various specs
call these “dotted quad” (more specifically, “dotted decimal”),
dot-separated fields each representing 1 byte; and “colon-hex”,
colon-separated fields each representing 2 bytes.</p>

<p>The first bits of complexity come from IPv6. In canonical form, common
addresses would end up with long runs of zeros in the middle. So, <code>::</code>
allows you to elide 1 or more 16-bit blocks of zeros: <code>1:2::3:4</code> means
<code>1:2:0:0:0:0:3:4</code></p>

<p>Next up, for cursed historical reasons, IPv6 permits you to write the
final 32 bits of the address in dotted quad form. Effectively, you can
splat an IPv4 address onto the end of IPv6 addresses!
<code>1:2:3:4:5:6:77.77.88.88</code> means <code>1:2:3:4:5:6:4d4d:5858</code>.</p>

<p>And of course, you can combine the two! <code>fe80::1.2.3.4</code> means <code>fe80:0:0:0:0:0:102:304</code></p>

<p>The existence of <code>::</code> introduces an annoying edge case in parsing: the
<code>::</code> can be at the start or end of the address, and the “empty” side
of the address is not one of the 16-bit fields. <code>::1</code> means
<code>0:0:0:0:0:0:0:1</code>, <code>1::</code> means <code>1:0:0:0:0:0:0:0</code>, and <code>::</code> means
<code>0:0:0:0:0:0:0:0</code>. This is a natural consequence of the <code>::</code> rule, but
it makes the parser slightly more annoying to write.</p>

<p>One final rule for IPv6: technically, each colon-hex field is 4 hex
digits, but you can elide leading zeros, as I’ve been doing so
far. Fully canonically, <code>::</code> is
<code>0000:0000:0000:0000:0000:0000:0000:0000</code>. My apologies to trypophobic
readers.</p>

<p>That’s it for IPv6, mostly. Now, on to IPv4!</p>

<p>Fun fact, the textual representation of IPv4 was never standardized in
any document before IPv6 needed a grammar for its weirdo “trailing
dotted quad” notation. So, it’s a de-facto standard that boils down to
mostly “what did 4.2BSD understand?”, and “what did other OSes keep
when they copied 4.2BSD?”</p>

<p>And hoo boy, strap yourselves in, because 4.2BSD sure had some whacky
opinions! Let’s use <code>192.168.140.255</code> as an example. That’s an IPv4
address that people would look at and go “yes, that sure is an IPv4
address.” How else can we write that exact same address?</p>

<p>This is the same IP address: <code>3232271615</code>. You get that by
interpreting the 4 bytes of the IP address as a big-endian unsigned
32-bit integer, and print that. This leads to a classic parlor trick:
if you try to visit <a href="http://192.168.140.255/">http://3232271615</a> , Chrome will load
<a href="http://192.168.140.255/">http://192.168.140.255</a>.</p>

<p>Okay, but that’s sort-of sensible, right? An IPv4 address is 4 bytes,
so printing it as a single number is a bit human-unfriendly, but
broadly plausible, right?</p>

<p>How about <code>0300.0250.0214.0377</code> ? That’s still the same
address. Dotted quad, except each field is written out in octal.</p>

<p>And if octal is supported, you might be wondering about hex. And you’d
be right! <code>192.168.140.255</code> is also <code>0xc0.0xa8.0x8c.0xff</code>, according
to 4.2BSD.</p>

<p>Now, remember before we had CIDR (Classless Inter-Domain Routing) ?
IPv4 addresses were Class A, Class B or Class C. It was a weird time.</p>

<p>And that weird time made it into IP addresses! The familiar
<code>192.168.140.255</code> notation is technically the “Class C” notation. You
can also write that address in “class B” notation as <code>192.168.36095</code>,
or in “Class A” notation as <code>192.11046143</code>. What we’re doing is
coalescing the final bytes of the address into either a 16-bit or a
24-bit integer field.</p>

<p>This, by the way, is why utilities like <code>ping</code> will accept weird
looking addresses like <code>127.1</code> for <code>127.0.0.1</code>. Unlike IPv6, it’s not
doing some kind of “missing fields are zero” expansion. <code>127.1</code> is the
Class A notation for “host 1 of network 127”, where the 1 is a 24-bit
number.</p>

<p>And finally, we come to one last bit of unspecified behavior: do IPv4
addresses permit an unlimited number of leading zeros in each quad? Or
is there a maximum of 3 digits? <code>001.002.003.004</code> is universally
recognized as valid. What about
<code>0000000001.0000000002.0000000003.000000004</code>?</p>

<p>You might also be wondering if either of these numbers should be read
in as octal, since we said earlier that a leading zero might be
interpreted as octal. It depends! There are implementations that do
both, but <em>most</em> modern implementations have abandoned the octal and
hex notation, and treat leading 0s as decimal.</p>

<p>The leading zero debate also infects IPv6, to some extent. Is
<code>000001::00001.00002.00003.00004</code> is a valid IPv6 address (“common”
form <code>1::1.2.3.4</code>, or <code>1::102:304</code>)? Most modern parsers seem to allow
an unlimited amount of leading zeros in their representations,
probably because they’re leaning on some “parse integer” library that
implements that behavior.</p>

<p>And so, we reach the bitter end. If you want to <em>truly</em> parse IP
addresses, this is the bullshit you have to put up with.</p>

<p>Currently, my slow reference parser jettisons a lot of old baggage,
and sticks to what I think is a sensible subset of these
possibilities. It understands:</p>

<ul>
<li>Classic v4 dotted decimal, with any number of leading zeros.</li>
<li>It does not process Class A/B notation, or hex or octal notation.</li>
<li>It does not process the “uint32 to the knee” representation.</li>
<li>For IPv6, it understands canonical colon-hex form, as well as ::
and trailing-IPv4 style (where the trailing IPv4 follows the same
rules as the previous tweet). Each field is allowed any number of
leading zeros.</li>
</ul>

<p>I’m on the fence about that last one, the “IPv6 with an embedded
dotted decimal” form. My reference parser (Go’s <code>net.ParseIP</code>)
understands it, but it’s not really that useful any more in the real
world. At the dawn of IPv6, the idea was that you could upgrade an
address to IPv6 by prepending a pair of colons, as in <code>::1.2.3.4</code>, but
modern transition mechanisms no longer offer anything as clear-cut as
this, so the notation doesn’t really show up in the wild.</p>

		
	</div>

	
</div></div>]]>
            </description>
            <link>https://blog.dave.tf/post/ip-addr-parsing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545967</guid>
            <pubDate>Sat, 26 Dec 2020 19:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s the best non-smart TV sold today?]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 241 (<a href="https://news.ycombinator.com/item?id=25544831">thread link</a>) | @thomas
<br/>
December 26, 2020 | https://helpatmyhome.com/best-non-smart-tv/ | <a href="https://web.archive.org/web/*/https://helpatmyhome.com/best-non-smart-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="What’s The Best Non-Smart TV Sold Today?"><div itemprop="text">
<p>With the industry-wide transition to smart TVs many of us have felt like there is no option but to get one. And the walls are closing in — it seems like almost every TV sold today is a smart one, which means a lack of control of what’s happening on our device, the possibility of the company deciding one day to show us ads (as Samsung as done), and the certainty that our viewing and usage data is being sent off to all sorts of third parties. </p>



<p>The solution? Buy a dumb TV!</p>



<h2><span id="What_Is_A_Dumb_TV">What Is A Dumb TV?</span></h2>



<p>The alternative to Smart TVs are, of course, non-smart TVs or, as people have taken to calling them, dumb TVs. These are televisions without an internet connection, without built-in HBO Max or Disney, without Amazon Alexa, and lacking apps of any kind. A dumb TV is the television equivalent of a flip phone. </p>



<p>Just because your TV is dumb doesn’t mean you can’t use Roku or Apple TV, etc. In this case you are simply opting to plug those devices into your TV via HDMI rather than having them built in. In almost all cases the plugged in device is better than having the software version built into your TV, so you are making your TV be smart instead of being forced to have one. </p>



<h2><span id="Why_Not_Buy_An_Old_TV">Why Not Buy An Old TV?</span></h2>



<p>You can definitely buy an old TV to solve this problem instead of hunting around for an increasingly rare non-smart in 2021. Televisions age pretty well, so as long as you can find something relatively high quality and made in the last 8 (or so) years you are good to go. </p>



<p>You’ll mainly need to ensure that your older model is in good physical condition, has enough HDMI ports to suit a current user, has no burn-in or wear issues, has a working remote, doesn’t have cracked or wrecked speakers, and that the color hasn’t gone crazy over time. You’ll also want to make sure your TV is an LED TV, so it’s power efficient and looks great, instead of using an outdated technology (like plasma). </p>



<p>For example, I have a Samsung dumb TV from 2012 (or so) that works perfectly well, has sufficient volume, and completely gets the job done. It was a good TV when I bought it, and it’s a great TV now, because it doesn’t have any of the features that I don’t want — and can’t avoid — today. </p>



<h2><span id="Just_Dont_Connect_It_To_the_Internet">Just Don’t Connect It To the Internet</span></h2>



<p>A smart TV can’ the smart without an internet connection so one thing you can do to get a dumb TV is to simply not connect it to your WiFi network. Your TV will will work since it’s connect through coax but the rest of the data cannot flow because the television doesn’t have an internet connection!</p>



<p>You can then go ahead and add a Nvidia Shield or Apple TV and connect that to the internet. This way the auxiliary devices will have internet connection <em>while you are using them</em>, but the TV itself (the hypervisor in this scenario) stays blissfully unaware of that internet connection. </p>



<p>Note, there have been scattered reports of some TVs, including those from Samsung, simply searching for open WiFi signals and attempting to connect to them, but this is an extreme and user-hostile example that hopefully won’t be repeated (assuming its true in the first place).</p>



<p>Some smart TV will force you to connect them to the internet for firmware updates and will resort to frequent nagging to get you to do this, but very few will force you to do it or not work entirely without the connection (yet). </p>



<h2><span id="Best_Dumb_TVs">Best Dumb TVs</span></h2>



<p>Here are some intelligent picks in non-smart TVs. </p>



<figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg" alt="" width="433" height="256" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-350x207.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-768x454.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1536x908.jpg 1536w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter.jpg 1782w" sizes="(max-width: 433px) 100vw, 433px"></figure><h2><span id="Sceptre_50-inch_4K_LED_TV">Sceptre 50-inch 4K LED TV</span></h2>



<p>Sceptre has generally been considered a mid-tier TV company, but they have done a good job of not transitioning entirely to Smart TVs. The <a href="https://amzn.to/3mZUDAp" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3mZUDAp" data-wpel-link="external">Sceptre U518CV-UM</a> is a 50-inch 4K that’s completely non-smart TV that is from the 2019 model year, so you are getting recent tech without the connectivity features that you don’t want.</p>



<ul><li>4K Television (3840×2160, UHD resolution)</li><li>Dimensions: 44.6 x 28.5 x 10.8 inches</li><li>Weight: 29.3 pounds</li></ul><p>Sceptre has the same non-smart TV in larger sizes as well, <a href="https://amzn.to/2VGHSyD" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VGHSyD" data-wpel-link="external">up to 65-inches</a> if you need the extra size or have a big room to fill. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg" alt="" width="341" height="207" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-350x213.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-768x466.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing.jpg 1258w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<h3><span id="Insignia_55-inch_Class_LED">Insignia 55-inch Class LED</span></h3>



<p>If you live near a Best Buy then you will have access to their house brand, Insignia. The Insignia 55-inch (NS-55D420NA20) is a LED-lit 1080p television that sells for about $300. It’s devoid of smart features but it has three HDMI ports and was first released in 2019. </p>



<p>This line of Insignia dumb TVs is sold from 19 inches up to 58 inches so there will be a TV for every room size. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg" alt="" width="451" height="275" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-350x214.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-768x469.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns.jpg 1170w" sizes="(max-width: 451px) 100vw, 451px"></figure></div>



<h2><span id="Samsung_Business_BER_43-Inch">Samsung Business BER 43-Inch </span></h2>



<p>This <a href="https://amzn.to/2VFc4di" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VFc4di" data-wpel-link="external">Samsung Business line TV</a> (model BE43R) is a full HD (1080p) LED TV that is part of Samsung’s commercial line, but doesn’t have the crazy price tag to reflect it. Commercial TV’s can get super experience for what seems like a normal TV — and for what will function like a normal TV if you are simply using it like one! The smartest feature this TV has is the ability to play images from a USB stick.</p>



<p>This TV has all the features you’d expect from a normal television, like HDMI input, and isn’t missing anything obvious. For example it still has integrated speakers and 1080p (1920×1080) resolution.</p>



<p>If you are open to commercial TVs there <a href="https://amzn.to/3gdIm8R" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3gdIm8R" data-wpel-link="external">are a huge number to explore</a>.</p>



<h2><span id="Dumb_TV_Alternatives">Dumb TV Alternatives</span></h2>



<p>Of course there are other ways to avoid a smart TV. Here are some bright ideas…</p>



<ul><li><strong>Projector:</strong> The smart device revolution has really come to projectors yet, so you can watch your TV and movies through a projector without having to worry about your privacy or ads</li><li><strong>Monitor:</strong> Computer monitors haven’t gotten smart (since they are connected to something smart) so if you watch television on a computer monitor you’ll have no need to worry about built-in Alexa or Google Home</li><li><strong>Business TV (aka Commercial Display):</strong> A <a href="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" target="_blank" rel="noreferrer noopener nofollow external" title="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" data-wpel-link="external">business-focused TV</a> (something you’d see hung in an office or airport and playing CNN all day on mute) is designed for simplicity and long-lasting performance. These haven’t yet gotten smart and will likely stay dumb for years as they need to have error- and update-free operation for years on end</li><li><strong>Outdoor TV:</strong> For some reason outdoor and weatherproof televisions have yet to go smart. Here is a <a href="https://amzn.to/3lMr0B0" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3lMr0B0" data-wpel-link="external">good example of one from Furrion</a>.</li></ul><h2><span id="FAQs">FAQs</span></h2>


<div><ol><li><strong>Can I use PiHole or a similar device to block the ads and privacy leaks from my smart TV?</strong><p>You'd think this would work, but manufacturers have gotten wise to the PiHole and other methods of blocking tracking and advertising injection so, no, you really can't. At this point many manufacturers will take measures like building ads into the core technology of their software so blocking ads will break other features. Also many manufacturers will hardcode their DNS to their preferred vendor, not allowing you to override their option with your PiHole. </p></li></ol></div></div></article></main></div></div></div>]]>
            </description>
            <link>https://helpatmyhome.com/best-non-smart-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544831</guid>
            <pubDate>Sat, 26 Dec 2020 17:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers automate this, so why don't airlines?]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 145 (<a href="https://news.ycombinator.com/item?id=25543861">thread link</a>) | @leejo
<br/>
December 26, 2020 | https://leejo.github.io/2020/12/26/EZY1952/ | <a href="https://web.archive.org/web/*/https://leejo.github.io/2020/12/26/EZY1952/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				<center>Lawyers Automate This, So Why Don't Airlines?</center>
			</p>
			<div>
				<center>
				
				
				

				December 26, 2020 (
				
				
					<a href="https://leejo.github.io/2020/11/19/some_kind_of_paypal_refund_scam/">Prev</a>
				
				/
				
					Next
				
			)

			
				</center>
			</div>
			<p>My working title for this blog post was “Why I’ll Never Fly With easyJet Again”, but that was far too clickbaity. Also it’s probably worth prefixing this post with two things. The first being the caveat that whether or not i ever fly with easyJet again is immaterial to their business, given that the model of budget airlines is one of opportunistic sales. Their loyalty programmes are minimal to non-existent<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (although that may change in the near future<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>) because the nature of their passengers is not one of loyalty. When you’re looking for a short haul cheap flight you’re unlikely to be attracted to schemes that only benefit you after years, or hundreds of thousands of air miles, worth of loyalty.</p>

<p>The reality of the budget airlines is they don’t have to worry about losing future passengers, thousands of them even, because there will always be enough replacement passengers. Budget airlines’ flights average above a 90% occupancy rate<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>So the point of me never flying with easyJet again is not because i am under any illusion that it will be detrimental to their business, it won’t, but rather to protect <em>myself</em> should the situation happen again. They’re not the first airline to make my “list”, but the others have reasons that aren’t interesting enough to require a blog post.</p>

<p>What i am hoping with this post is that it gives the reader enough information that, should they find themselves in a similar situation, they are more informed as to their options and the potential ramifications of the choice they make. This is going to affect more travelers when the UK leaves the EU.</p>

<p>The second prefix is that easyJet recently posted their first year of losses<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">4</a></sup>, due to the current global situation. I started writing this post sometime in 2019, way before the pandemic royally fucked the airline industry. It’s arguable that the airline industry being royally fucked was only a matter of time, and the consequences of <em>that</em> could mean the details here are now even more relevant - It may become even harder to claim refunds and compensation from them in the future. Airline companies will probably double down on their approach to handling compensation claims to avoid yet more financial loss.</p>

<p><strong>EZY1952</strong></p>

<p>On 23rd December 2018 my partner and I were due to fly from Geneva to Manchester on easyJet flight EZY1952, aircraft registration G-EZRU, which was scheduled to depart at 16:50 CET and arrive at 17:50 GMT. I had booked these flights a couple of months earlier, which combined with the date of our departure and return lead to a total cost of 619.38 CHF.</p>

<p>The 600+ CHF didn’t include any of the optional extras, priority boarding, seat choice, checked bags, etc. It was the “basic” cost of the “cheap” flights. This cost is four to five times more than the normal cost of this route, as I said due to the relatively late booking (two months in advance) and the dates of the flights. This route is normally far cheaper:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/typical_cost.png"></p>

<p>Anyway, given the alternatives and the limited options for our dates these were the flights we settled on and decide the cost was worth it to spend Xmas with the family. The flight was delayed by just a few minutes, which isn’t unusual for this route, but then took off as normal at 17:14:05 CET.</p>

<p>A few moments after take off, the literal wheels no longer being on the ground part of it, I felt my ears pop quite suddenly. That might not be taken as unusual either, but I live at altitude and my ears don’t normally pop on flights. The plane then spent several minutes in low cloud, another unusual thing given the cloud line is normally cut through quicker. I turned to my partner and suggested that something was off.</p>

<p>A couple of minutes later the pilot informed us that the flight would be returning to Geneva airport as the cabin pressure system, and its backup, had failed. Given the potentially catastrophic consequences of the cabin pressure system failing at cruising altitude, I considered that everyone on the plane had been very lucky.</p>

<p>The plane landed safely at Geneva airport at 17:41:00 CET, meaning a total flight time of about 25 minutes<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. I contacted my parents to let them know we wouldn’t be arriving as planned and would keep them informed as to any updates:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/messages_to_mum.png"></p>

<p>We remained on the plane, after the pilot informed us that the technical crew were going to look into the issue. We were then told the parts would be replaced/fixed and this would take three to four hours. At this point I knew that we would not be flying until the next day as a) it was now 19:00 and Geneva airport has strict limitations on flights after 22:00, and b) it would be massively irresponsible of the airline to let this plane fly without a more comprehensive test that would probably take longer than the three to four hour estimate<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<p>Since it was going to take a few hours all passengers disembarked and returned to the departure gate. I’m not sure how long we were on the plane, while it was on the ground, but looking at the evidence I kept afterwards it appears that we were on it for approximately one hour fifteen minutes. This is from the time it landed to receiving a text message from easyJet apologising for the delay:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/sorry_for_delay.png"></p>

<p>As soon as we got back into the gate I sat down and checked to see if there were any other flights available. Sure enough there was: we could get a one way easyJet flight to Liverpool, so I booked two seats for a total of 189.26 CHF. This flight would depart at 21:25 CET and arrive at 22:20 GMT, four hours and thirty minutes after our original arrival time.</p>

<p>It should be said at this point I was reasonably confident of a few things:</p>

<ul>
  <li>It was highly unlikely the original fight was going to depart that night</li>
  <li>In fact, it would probably be delayed until the next afternoon</li>
  <li>We would have all the inconvenience of that, and lose one third of our time in the UK</li>
  <li>Given the original arrival time was delayed by more than three hours we were covered by EU Regulation 261/2004</li>
  <li>So the airline would have to compensate €250 for each of us, which would at least cover the alternate flights I had booked</li>
</ul>

<p>I was correct on four out of five of these:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/delayed_overnight.png"></p>

<p>Our flight to Liverpool went without issue, and we weren’t the only people to have rebooked from the delayed flight as we overheard some other passengers explaining their situation to the cabin crew<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>.</p>

<p><strong>Contacting easyJet Customer Service</strong></p>

<p>The next day I used easyJet’s contact form to submit a claim under EC261/2004 regulations. I knew this was going to take a long time so figured I may as well start the process as soon as possible. My claim was made on the basis that the original flight had been delayed overnight and I had booked alternate travel arrangements to get to my destination.</p>

<p>I considered the cost of the original flights a sunk cost. I wasn’t actually interested in compensation and I just wanted the cost of the alternate flights refunded, which came in at less than half the amount of compensation EC261/2004 would give considering the length of the delay to the original flight.</p>

<p>The response from easyJet came back quickly, the next day: <em>As you were a no show on the flight we would not be able t reimburse the costs for alternate transport.</em> - well that didn’t read like a response by someone/thing that had actually looked into the details. We had shown up for the flight, given we were on it when the pressure systems failed, and clearly we wouldn’t show up for the <em>rescheduled</em> flight if we arranged alternate transport as we can’t be in two places at once.</p>

<p>I assumed this was just a first level response of “refuse all claims, through a semantic dispute, because this will cause a not insignificant number of people to give up”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>. The contact form doesn’t have a place to describe the reason for the claim in detail so I needed to call easyJet to explain.</p>

<p><strong>EU Regulation 261/2004</strong></p>

<p>I’ll spare you too much detail, as you can search for it if you want to (or read a summary on <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation">Wikipedia</a>). Essentially - EU 261/2004 allows compensation if your flight is from or to an EU/EAA area and is either delayed or cancelled [less than one week before the flight date]. The level of compensation depends on the distance of the flight.</p>

<p>In this particular case the delay was more than four hours, and the flight was less than 1,500km, so would qualify for €250 compensation (per passenger).</p>

<p>The regulation also says the passengers must be given assistance, and in this particular case of the flight being delayed overnight would mean hotel accommodation and transport between the airport and the hotel. This was Geneva two days from Xmas, so that would probably mean another €250.</p>

<p>So a reasonable estimate is easyJet would be paying in the region of €750 per passenger on this delayed flight. Given it was full (at least to my recollection) easyJet were looking at a bill of at least €100,000 for compensation + accommodation expenses<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup>.</p>

<p>To go off on a tangent slightly - all of this is going to be up in the air when the UK leaves the EU. Of course that depends what the UK government <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation#Brexit_and_British_Consumers">decide to do about it</a>. Given everything else on their plate don’t be surprised if this one gets forgotten about until the claims start to appear.</p>

<p><strong>Contacting easyJet Customer Service Again</strong></p>

<p>As my claim, via easyJet’s web form, was rejected relatively quickly I decided to pick up the phone and see if speaking to someone would make a difference. I explained the situation and they agreed to pass this on to someone who would look at it in more detail, given the time of year this would take a few days at the least.</p>

<p>A couple of weeks later I received an email stating “Unfortunately as you were a no show on the transferred flight there is no reimbursement for EUC216 Compensation”. But also “As a goodwill gesture I have created a flight voucher to the value of the 51.90 GBP”.</p>

<p>Slightly odd - no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leejo.github.io/2020/12/26/EZY1952/">https://leejo.github.io/2020/12/26/EZY1952/</a></em></p>]]>
            </description>
            <link>https://leejo.github.io/2020/12/26/EZY1952/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543861</guid>
            <pubDate>Sat, 26 Dec 2020 15:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want us to be compliant, not secure]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 165 (<a href="https://news.ycombinator.com/item?id=25543818">thread link</a>) | @_wldu
<br/>
December 26, 2020 | https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some years ago, I worked for an organization that was involved in federally funded research. Occasionally, government IT auditors (or contractors that they hired) would visit our facilities to audit our systems.</p><p>We used a wide variety of operating systems on several different hardware platforms. Windows, Mac, Linux and Unix systems were scattered throughout our buildings running on desktops, laptops, workstation, servers and embedded devices. We ran several different Linux distributions, multiple Unixes and had standardized on <a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> hashes to store user passwords.</p><p>Bcrypt was released in 1999 and is based on <a href="https://www.schneier.com/academic/blowfish/">Blowfish</a>. Blowfish is a fast, unpatented block cipher that was developed by <a href="https://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> in 1993. It’s been in the mainline Linux kernel since the 2.6 release.</p><p>Bcrypt is a fast and efficient password hash yet strong and hard to attack. At the time, it was the strongest password hash that we could use and as an added bonus, it worked on all of our Linux and Unix systems.</p><p>One particular year, the IT auditors realized that we were using bcrypt hashes to store user passwords. They said that it was not a <a href="https://csrc.nist.gov/publications/detail/fips/180/4/final">FIPS approved algorithm</a> and by using bcrypt hashes, we were noncompliant. They insisted that we switch to a SHA-2 based hash function right away.</p><p>We ran several tests that demonstrated how the SHA-2 hashes were much easier to crack than the bcrypt hashes (see below for a performance comparison on a semi-modern GPU). But the auditors were adamant. They did not care that the approved algorithms were weaker. Nothing would change their decision.</p><p>In their minds, it was a simple matter. Bcrypt was not on the list. It was not an approved hashing function. They would not discuss it further.</p><p>To satisfy the auditors, we switched all the systems to an approved SHA-2 hash function. This action probably made our systems more vulnerable to cyber attacks.</p><p>A colleague said, <em>“They want us to be compliant, not secure.”</em></p><div><pre><code data-lang="bash">$ hashcat -b -m <span>1800</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>1800</span> - sha512crypt $6$, SHA512 <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 5000<span>)</span>

Speed.#1.........:    <span>78810</span> H/s <span>(</span>51.36ms<span>)</span> @ Accel:512 Loops:128 Thr:32 Vec:1
</code></pre></div><div><pre><code data-lang="bash">$ hashcat -b -m <span>3200</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>3200</span> - bcrypt $2*$, Blowfish <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 32<span>)</span>

Speed.#1.........:     <span>7570</span> H/s <span>(</span>41.13ms<span>)</span> @ Accel:16 Loops:8 Thr:8 Vec:1
</code></pre></div><ul><li><a href="https://www.go350.com/tags/compliance">compliance</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543818</guid>
            <pubDate>Sat, 26 Dec 2020 14:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executable PNGs]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25543191">thread link</a>) | @todsacerdoti
<br/>
December 26, 2020 | https://djharper.dev/post/2020/12/26/executable-pngs/ | <a href="https://web.archive.org/web/*/https://djharper.dev/post/2020/12/26/executable-pngs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>
<time datetime="2020-12-26">Saturday, December 26, 2020</time>
</p>
<figure>
<a href="https://djharper.dev/img/peek.webm"><video src="https://djharper.dev/img/peek.webm" loop="true" width="100%" title="The pixels have been adjusted in colour slightly." autoplay=""></video></a>
<figcaption><br>It's an image <i>and</i> a program</figcaption>
</figure>
<p>A few weeks ago I was reading about <a href="https://www.lexaloffle.com/pico-8.php">PICO-8</a>, a fantasy games console with limited constraints. What really piqued my interest about it was the novel way games are distributed, you encode them into a PNG image. This includes the game code, assets, everything. The image can be whatever you want, screenshots from the game, cool artwork or just text. To load them you pass the image as input to the PICO-8 program and start playing.</p>
<p>This got me thinking, wouldn’t it be cool if you could do that for programs on Linux? No! I hear you cry, that’s a dumb idea, but whatever, herein lies an overview of possibly the dumbest things I’ve worked on this year.</p>
<h2 id="encoding">Encoding</h2>
<p>I’m not entirely sure what PICO-8 is actually doing, but at a guess it’s probably use <a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> techniques to ‘hide’ the data within the raw bytes of the image. There are a lot of resources out there that explain how Steganography works, but the crux of it is quite simple, your image your want to hide data into is made up of bytes, an image is made up of pixels. Pixels are made up of 3 Red Green and Blue (RGB) values, represented as 3 bytes. To hide your data (the “payload”) you essentially “mix” the bytes from your payload with the bytes from the image.</p>
<p>If you just replaced each byte in your cover image with the bytes from your payload, you would end up with sections of the image looking distorted as the colours probably wouldn’t match with what your original image was. The trick is to be as subtle as possible, or <em>hide in plain sight</em>. This can be achieved by <em>spreading</em> your payload bytes over the bytes of the cover image by using the <em>least significant bits</em> to hide them in. In other words, make subtle adjustments to the byte values so the colour changes are not drastic enough to be perceptive by the human eye.</p>
<p>For example if your payload was the letter <code>H</code>, represented as <code>01001000</code> in binary (72), and your image contained a series of black pixels</p>
<figure>
<a href="https://djharper.dev/img/byte-replace1.png"><img src="https://djharper.dev/img/byte-replace1.png" title="The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit"></a>
<figcaption><br>The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit</figcaption>
</figure>
<p>The output is two-and-a-bit pixels that are slightly less black than before, but can you tell the difference?</p>
<figure>
<a href="https://djharper.dev/img/pixels1.png"><img src="https://djharper.dev/img/pixels1.png" title="The pixels have been adjusted in colour slightly."></a>
<figcaption><br>The pixels have been adjusted in colour slightly.</figcaption>
</figure>
<p>Well, an exceptionally trained colour connoisseur might be able to, but in reality these subtle shifts can really only be noticed by a machine. Retrieving your super secret <code>H</code> is just a matter of reading 8 bytes from the resulting image and re-assembling them back into 1 byte. Obviously hiding a single letter is lame, but this can scale to anything you want, a super secret sentence, a copy of <em>War and Peace</em>, a link to your soundcloud, the go compiler, the only limit is the amount of bytes available in your cover image as you’ll require at least 8x whatever your input is.</p>
<h2 id="hiding-programs">Hiding programs</h2>
<p>So, back to the whole linux-executables-in-an-image thing, that old chestnut. Well, seeing as executables are just bytes, they can be hidden in images. Just like in the PICO-8 thing.</p>
<p>Before I could achieve this I decided to write my own <a href="https://github.com/djhworld/steg">Steganography library</a> and <a href="https://github.com/djhworld/stegtool">tool</a> to support encoding and decoding data into PNGs. Yes, there are lots of steganography libraries and tools out there but I learn better by building.</p>
<figure>
<div><pre><code data-lang="bash">$ stegtool encode <span>\
</span><span></span>--cover-image htop-logo.png <span>\
</span><span></span>--input-data /usr/bin/htop <span>\
</span><span></span>--output-image htop.png
$
$ <span>echo</span> <span>"Super secret hidden message"</span> | stegtool encode <span>\ </span>
--cover-image image.png <span>\
</span><span></span>--output-image image-with-hidden-message.png
$ stegtool decode --image image-with-hidden-message.png
Super secret hidden message</code></pre></div>
</figure>
<p>As it’s all written in <a href="https://www.rust-lang.org/">Rust</a> it wasn’t that difficult to compile to WASM, so feel free to play with it here:</p>

<p>Anyway, now that can embed data, including executables into an image, how do we run them?</p>
<h2 id="get-it-running">Get it running</h2>
<p>The simple option would be to just run the tool above, <code>decode</code> the data into a new file, <code>chmod +x</code> it and then run it. It works but that’s not fun enough. What I wanted was something similar to the PICO-8 experience, you pass something a PNG image and it takes care of the rest.</p>
<p>However, as it turns out, you can’t just load some arbitrary set of bytes into memory and tell Linux to jump to it. Well, not in a direct way anyway, but you <em>can</em> use some cheap tricks to fudge it.</p>
<h2 id="memfd-create">memfd_create</h2>
<p>After reading <a href="https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html">this blogpost</a> it became apparent to me you can create an in-memory file and mark it as executable</p>
<blockquote>
<p>Wouldn’t it be cool to just grab a chunk of memory, put our binary in there, and run it without monkey-patching the kernel, rewriting execve(2) in userland, or loading a library into another process?</p>
</blockquote>
<p>This method uses the syscall <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd_create(2)</a> to create a file under the <code>/proc/self/fd</code> namespace of your process and load any data you want in it using <code>write</code>. I spent quite a while messing around with the <a href="https://crates.io/crates/libc">libc</a> bindings for Rust to get this to work, and had a lot of trouble understanding the data types you pass around, the documentation for these Rust bindings doesn’t help much.</p>
<p>I got something working eventually though</p>
<figure>
<div><pre><code data-lang="rust"><span>unsafe</span><span> </span>{<span>
</span><span>    </span><span>let</span><span> </span>write_mode<span> </span><span>=</span><span> </span><span>119</span>;<span> </span><span>// w
</span><span></span><span>    </span><span>// create executable in-memory file
</span><span></span><span>    </span><span>let</span><span> </span>fd<span> </span><span>=</span><span> </span>syscall(libc::SYS_memfd_create,<span> </span><span>&amp;</span>write_mode,<span> </span><span>1</span>);<span>
</span><span>    </span><span>if</span><span> </span>fd<span> </span><span>==</span><span> </span><span>-</span><span>1</span><span> </span>{<span>
</span><span>        </span><span>return</span><span> </span><span>Err</span>(<span>String</span>::from(<span>"memfd_create failed"</span>));<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span>file<span> </span><span>=</span><span> </span>libc::fdopen(fd,<span> </span><span>&amp;</span>write_mode);<span> 
</span><span>
</span><span>    </span><span>// write contents of our binary
</span><span></span><span>    </span>libc::fwrite(<span>
</span><span>        </span>data.as_ptr()<span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span>libc::c_void,<span> 
</span><span>        </span><span>8</span><span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>data.len()<span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>file,<span>
</span><span>    </span>);<span>
</span><span></span>}<span>
</span></code></pre></div>
</figure>
<p>Invoking <code>/proc/self/fd/&lt;fd&gt;</code> as a child process from the parent that created it is enough to run your binary.</p>
<figure>
<div><pre><code data-lang="rust"><span>let</span><span> </span>output<span> </span><span>=</span><span> </span>Command::new(format<span>!</span>(<span>"/proc/self/fd/{}"</span>,<span> </span>fd))<span>
</span><span>    </span>.args(args)<span>
</span><span>    </span>.stdin(std::process::Stdio::inherit())<span>
</span><span>    </span>.stdout(std::process::Stdio::inherit())<span>
</span><span>    </span>.stderr(std::process::Stdio::inherit())<span>
</span><span>    </span>.spawn();<span>
</span></code></pre></div>
</figure>
<p>Given these building blocks, I wrote <a href="https://github.com/djhworld/pngrun">pngrun</a> to run the images. It essentially…</p>
<ol>
<li>Accepts an image that has had our binary embedded in it from the steganography tool, and any arguments</li>
<li>Decodes it (i.e. extracts and re-assembles the bytes)</li>
<li>Creates an in-memory file using <code>memfd_create</code></li>
<li>Puts the bytes of the binary into the in-memory file</li>
<li>Invokes the file <code>/proc/self/fd/&lt;fd&gt;</code> as a child process, passing any arguments from the parent</li>
</ol>
<p>So you can run it like this</p>
<figure>
<div><pre><code data-lang="bash">$ pngrun htop.png
&lt;htop output&gt;
$ pngrun go.png run main.go
Hello world!</code></pre></div>
</figure>
<p>Once <code>pngrun</code> exits the in-memory file is destroyed.</p>
<h2 id="binfmt-misc">binfmt_misc</h2>
<p>It’s annoying having to type <code>pngrun</code> every time though, so my last cheap trick to this pointless gimmick was to use <a href="https://en.wikipedia.org/wiki/Binfmt_misc">binfmt_misc</a>, a system that allows you to “execute” files based on its file types. I think it was mainly designed for interpreters/virtual machines, like Java. So instead of typing <code>java -jar my-jar.jar</code> you can just type <code>./my-jar.jar</code> and it will invoke the <code>java</code> process to run your JAR. The caveat is your file <code>my-jar.jar</code> needs to be marked as executable first.</p>
<p>So adding an entry to binfmt_misc for <code>pngrun</code> to attempt to run any <code>png</code> files that have the <code>x</code> flag set was as simple as</p>
<figure>
<div><pre><code data-lang="bash">$ cat /etc/binfmt.d/pngrun.conf
:ExecutablePNG:E::png::/home/me/bin/pngrun:
$ sudo systemctl restart binfmt.d
$ chmod +x htop.png
$ ./htop.png
&lt;output&gt;</code></pre></div>
</figure>
<h2 id="what-s-the-point">What’s the point</h2>
<p>Well, there isn’t one really. I was seduced by the idea of making PNG images run programs and got a bit carried away with it, but it was fun none the less. There’s something amusing to me about distributing programs as an image, remember the ridiculous cardboard boxes PC software used to come in with artwork on the front, why not bring that back! (lets not)</p>
<p>It’s really dumb though and comes with a lot of caveats that make it completely pointless and impractical, the main one being needing the stupid <code>pngrun</code> program on your machine. But I also noticed some weird stuff around programs like <code>clang</code>. I encoded it into this fun LLVM logo and while it runs OK, it fails when you try to compile something.</p>
<figure>
<a href="https://djharper.dev/img/DragonMedium.png"><img src="https://djharper.dev/img/DragonMedium.png" title="Clang/LLVM logo"></a>
</figure>
<figure>
<div><pre><code data-lang="bash">$ ./clang.png --version
clang version <span>11</span>.0.0 <span>(</span>Fedora <span>11</span>.0.0-2.fc33<span>)</span>
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /proc/self/fd
$ ./clang.png main.c
error: unable to execute command: Executable <span>""</span> doesn<span>'</span>t exist!</code></pre></div>
</figure>
<p>This is probably a product of the anonymous file thing, which can probably be overcome if I could be bothered to investigate.</p>
<h3 id="additional-reasons-why-this-is-dumb">Additional reasons why this is dumb</h3>
<p>A lot of binaries are quite large, and given the constraints of needing to fit them into an image, sometimes these need to be <em>big</em>, meaning you end up with comically large files.</p>
<p>Also most software isn’t just one executable so the dream of just distributing a PNG kinda falls flat for more complex software like games.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is probably the dumbest project I’ve worked on all year but it’s been fun, I’ve learned about Steganography, <code>memfd_create</code>, <code>binfmt_misc</code> and played a little more with Rust.</p>
</article>
</div></div>]]>
            </description>
            <link>https://djharper.dev/post/2020/12/26/executable-pngs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543191</guid>
            <pubDate>Sat, 26 Dec 2020 13:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manga Guide to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25541919">thread link</a>) | @joubert
<br/>
December 25, 2020 | http://lambda.bugyo.tk/cdr/mwl/ | <a href="https://web.archive.org/web/*/http://lambda.bugyo.tk/cdr/mwl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambda.bugyo.tk/cdr/mwl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541919</guid>
            <pubDate>Sat, 26 Dec 2020 06:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backdoor in Zyxel Products]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25539876">thread link</a>) | @ta988
<br/>
December 25, 2020 | https://www.eyecontrol.nl/blog/undocumented-user-account-in-zyxel-products.html | <a href="https://web.archive.org/web/*/https://www.eyecontrol.nl/blog/undocumented-user-account-in-zyxel-products.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<div>
							<p>TL;DR: If you have a Zyxel USG, ATP, VPN, ZyWALL or USG FLEX you should update to the latest firmware version today. You can find the full list of affected devices <a href="https://businessforum.zyxel.com/discussion/5252/zld-v4-60-revoke-and-wk48-firmware-release">here</a> and the Zyxel advisory <a href="https://www.zyxel.com/support/CVE-2020-29583.shtml">here</a>.</p>
                            <p>Zyxel is a popular brand for firewalls that are marketed towards small and medium businesses. Their Unified Security Gateway (USG) product line is often used as a firewall or VPN gateway. As a lot of us are working from home, VPN-capable devices have been quite selling well lately.</p>
                            <p>When doing some research (rooting) on my Zyxel USG40, I was surprised to find a user account 'zyfwp' with a password hash in the latest firmware version (4.60 patch 0). The plaintext password was visible in one of the binaries on the system. I was even more surprised that this account seemed to work on both the SSH and web interface.</p>
                            <pre>$ ssh <a href="https://www.eyecontrol.nl/cdn-cgi/l/email-protection" data-cfemail="4b31322d3c3b0b7a7279657a7d73657a65797e79">[email&nbsp;protected]</a>
Password: Pr*******Xp
Router&gt; show users current
No: 1
  Name: zyfwp
  Type: admin
(...)
Router&gt;</pre>
                            <p>The user is not visible in the interface and its password cannot be changed. I checked the previous firmware version (4.39) and although the user was present, it did not have a password. It seemed the vulnerability had been introduced in the latest firmware version. Even though older versions do not have this vulnerability, they do have others (such as this <a href="https://www.zyxel.com/us/en/support/Zyxel-security-advisory-for-buffer-overflow-vulnerability.shtml">buffer overflow</a>) so you should still update.</p>
                            <p>As SSL VPN on these devices operates on the same port as the web interface, a lot of users have exposed port 443 of these devices to the internet. Using publicly available data from Project Sonar, I was able to identify about 3.000 Zyxel USG/ATP/VPN devices in the Netherlands. Globally, more than 100.000 devices have exposed their web interface to the internet.</p>
                            <p>In our experience, most users of these devices will not update the firmware very often. Zyxel devices do not expose their firmware version to unauthenticated users, so determining if a device is vulnerable is a bit more difficult. We wanted to get an idea of the amount of affected devices, but simply trying the password is not really an option (ethically and legally). Luckily, some javascript and css files can be requested from the web interface of these devices without authentication. These files seem to change with every firmware release. Using this information, we can obtain a unique fingerprint of the vulnerable firmware version. We used this information to identify the firmware version of 1.000 devices in The Netherlands and found that around 10% of devices are running the affected firmware version. Zyxel does offer automatic updates, but these are not enabled by default. Luckily, we were able to find this vulnerability just a few weeks after it had been introduced, or the number of affected devices could have been much larger.</p>
                            <p>As the zyfwp user has admin privileges, this is a serious vulnerability. An attacker could completely compromise the confidentiality, integrity and availability of the device. Someone could for example change firewall settings to allow or block certain traffic. They could also intercept traffic or create VPN accounts to gain access to the network behind the device.  Combined with a vulnerability like Zerologon this could be devastating to small and medium businesses.</p>
                            <p>Because of the seriousness of the vulnerability and it being so easy to exploit, we have decided not to release the password for this account at this time. We do expect others to find and release it, which is why we suggest you install the updated firmware as soon as possible.</p>
                            <p>I quickly sent out a mail to Zyxel to report the undocumented user account. According to Zyxel, the account was designed to deliver automatic firmware updates for access points via FTP. They released a fixed firmware version less than two weeks later. You can find the release notes for the USG40 <a href="ftp://ftp.zyxel.com/USG40/firmware/USG40_4.60(AALA.1)C0_2.pdf">here</a>.</p>
                            <p>This is the entry in the release notes that describes this vulnerability:</p>
                            <pre>[BUG FIX][CVE-2020-29583]
a. Vulnerability fix for undocumented user account.</pre>
                            <p>We would like to thank the Zyxel Security Team for their quick response and patch.</p>
                            <p><b>Disclosure timeline</b></p>
                            <p>2020-11-29: EYE reports vulnerability to Zyxel security</p>
                            <p>2020-11-30: Zyxel acknowledges receipt</p>
                            <p>2020-12-02: Zyxel requests more information about how the vulnerability was discovered</p>
                            <p>2020-12-03: EYE sends more details</p>
                            <p>2020-12-08: Zyxel releases beta firmware 4.60-WK48 and removes the vulnerable firmware version from their site</p>
                            <p>2020-12-15: Zyxel releases firmware 4.60 patch 1 for most devices</p>
                            <p>2020-12-18: Zyxel releases firmware 4.60 patch 1 for all remaining devices</p>
                            <p>2020-12-23: Zyxel publishes <a href="https://www.zyxel.com/support/CVE-2020-29583.shtml">advisory</a></p>

						</div>
						
					</div>
                </div></div>]]>
            </description>
            <link>https://www.eyecontrol.nl/blog/undocumented-user-account-in-zyxel-products.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25539876</guid>
            <pubDate>Fri, 25 Dec 2020 23:15:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Complete Guide to LLVM for Programming Language Creators]]>
            </title>
            <description>
<![CDATA[
Score 391 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25539797">thread link</a>) | @mseri
<br/>
December 25, 2020 | https://mukulrathi.co.uk/create-your-own-programming-language/llvm-ir-cpp-api-tutorial/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/create-your-own-programming-language/llvm-ir-cpp-api-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Creating the Bolt Compiler: Part 8</h3><p><h3>December 24, 2020</h3><h3>12 min read</h3></p><nav><h2>Series: Creating the Bolt Compiler</h2><ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li><strong>Part 8: A Complete Guide to LLVM for Programming Language Creators</strong></li><li><em>Part 9: Concurrency is a Runtime Feature, Not a Compiler Feature*</em></li><li><em>Part 10: Inheritance and method overriding in Bolt*</em></li><li><em>Part 11: Generics - adding polymorphism to Bolt*</em></li><p>*coming soon! </p></ul></nav><hr><p><strong>Update</strong>: this post has now taken off on <a href="https://news.ycombinator.com/item?id=25539797">Hacker News</a> and <a href="https://www.reddit.com/r/programming/comments/kjjijf/a_complete_guide_to_llvm_for_programming_language/">Reddit</a>. Thank you all!</p><p>I have a small request:</p><div><div><div> <h3>Share This On Twitter</h3><p>If you find this useful, please share on Twitter, thank you!</p></div></div></div><h2 id="whos-this-tutorial-for"><a href="#whos-this-tutorial-for" aria-label="whos this tutorial for permalink"></a>Who’s this tutorial for?</h2><p>This series of compiler tutorials is for people who don’t just want to create a <em>toy</em> language.
You want objects. You want polymorphism. You want concurrency. You want garbage collection. Wait you don’t want GC? Okay, no worries, we won’t do that :P</p><p>If you’ve just joined the series at this stage, here’s a quick recap. We’re designing a Java-esque concurrent object-oriented programming language <em>Bolt</em>. We’ve gone through the compiler frontend, where we’ve done the parsing, type-checking and dataflow analysis. We’ve <a href="https://mukulrathi.co.uk/create-your-own-programming-language/lower-language-constructs-to-llvm/">desugared our language to get it ready for LLVM</a> - the main takeaway is that objects have been desugared to structs, and their methods desugared to functions.</p><p>Learn about LLVM and you’ll be the envy of your friends. Rust uses LLVM for its backend, so it must be cool. You’ll beat them on all those performance benchmarks, without having to hand-optimise your code or write machine assembly code. Shhhh, I won’t tell them.</p><h2 id="just-give-me-the-code"><a href="#just-give-me-the-code" aria-label="just give me the code permalink"></a>Just give me the code!</h2><p>All the code can be found in the <a href="https://github.com/mukul-rathi/bolt">Bolt compiler repository</a>.</p><p>The C++ class definitions for our desugared representation (we call this <em>Bolt IR</em>) can be found in <a href="https://github.com/mukul-rathi/bolt/tree/master/src/llvm-backend/deserialise_ir">deserialise_ir</a> folder. The code for this post (the LLVM IR generation) can be found in the <a href="https://github.com/mukul-rathi/bolt/tree/master/src/llvm-backend/llvm_ir_codegen">llvm_ir_codegen</a> folder. The repo uses the Visitor design pattern and ample use of <code>std::unique_ptr</code> to make memory management easier.</p><p>To cut through the boilerplate, to find out how to generate LLVM IR for a particular language expression, search for the <code>IRCodegenVisitor::codegen</code> method that takes in the corresponding <code>ExprIR</code> object. e.g. for if-else statements:</p><div><div><pre><p><span>Value </span><span>*</span><span>IRCodegenVisitor</span><span>::</span><span>codegen</span><span>(</span><span>const</span><span> ExprIfElseIR </span><span>&amp;</span><span>expr</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>.</span><span>.</span><span>.</span><span> </span><span></span></p><p><span></span><span>}</span></p></pre></div></div><h2 id="understanding-llvm-ir"><a href="#understanding-llvm-ir" aria-label="understanding llvm ir permalink"></a>Understanding LLVM IR</h2><p>LLVM sits in the <strong>middle-end</strong> of our compiler, <em>after</em> we’ve desugared our language features, but <em>before</em> the backends that target specific machine architectures (x86, ARM etc.)</p><p>LLVM’s IR is pretty low-level, it can’t contain language features present in some languages but not others (e.g. classes are present in C++ but not C). If you’ve come across instruction sets before, LLVM IR is a <a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer#:~:text=A%20reduced%20instruction%20set%20computer,instruction%20set%20computer%20(CISC).">RISC</a> instruction set.</p><p>The upshot of it is that LLVM IR looks like a more <em>readable</em> form of assembly. As LLVM IR is <strong>machine independent</strong>, we don’t need to worry about the number of registers, size of datatypes, calling conventions or other machine-specific details.</p><p>So instead of a fixed number of physical registers, in LLVM IR we have an unlimited set of <em>virtual</em> registers (labelled <code>%0</code>, <code>%1</code>, <code>%2</code>, <code>%3</code>… we can write and read from. It’s the backend’s job to map from virtual to physical registers.</p><p>And rather than allocating specific sizes of datatypes, we retain <strong>types</strong> in LLVM IR. Again, the backend will take this type information and map it to the size of the datatype. LLVM has types for different sizes of <code>int</code>s and floats, e.g. <code>int32</code>, <code>int8</code>, <code>int1</code> etc. It also has derived types: like <strong>pointer</strong> types, <strong>array</strong> types, <strong>struct</strong> types, <strong>function</strong> types. To find out more, check out the <a href="https://llvm.org/doxygen/classllvm_1_1Type.html">Type</a> documentation.</p><p>Now, built into LLVM are a set of optimisations we can run over the LLVM IR e.g. <a href="https://en.wikipedia.org/wiki/Dead_code_elimination">dead-code elimination</a>, <a href="https://en.wikipedia.org/wiki/Inline_expansion">function inlining</a>, <a href="https://cran.r-project.org/web/packages/rco/vignettes/opt-common-subexpr.html">common subexpression elimination</a> etc. The details of these algorithms are irrelevant: LLVM implements them for us.</p><p>Our side of the bargain is that we write LLVM IR in <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Static Single Assignment (SSA) form</a>, as SSA form makes life easier for optimisation writers. SSA form sounds fancy, but it just means we define variables before use and assign to variables <strong>only once</strong>. In SSA form, we cannot reassign to a variable, e.g. <code>x = x+1</code>; instead we assign to a fresh variable each time (<code>x2 = x1 + 1</code>).</p><p>So in short: LLVM IR looks like assembly with <strong>types</strong>, minus the messy machine-specific details. LLVM IR must be in SSA form, which makes it easier to optimise. Let’s look at an example!</p><h3 id="an-example-factorial"><a href="#an-example-factorial" aria-label="an example factorial permalink"></a>An example: Factorial</h3><p>Let’s look at a simple factorial function in our language Bolt:</p><div><p><span>factorial.bolt</span></p><div><pre><p><span>function </span><span>int</span><span> </span><span>factorial</span><span>(</span><span>int</span><span> n</span><span>)</span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>n</span><span>==</span><span>0</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>1</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>else</span><span>{</span><span></span></p><p><span>    n </span><span>*</span><span> </span><span>factorial</span><span>(</span><span>n </span><span>-</span><span> </span><span>1</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre></div></div><p>The corresponding LLVM IR is as follows:</p><div><p><span>factorial.ll</span></p><div><pre><p><span>define i32 @</span><span>factorial</span><span>(</span><span>i32</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>entry</span><span>:</span><span></span></p><p><span>  </span><span>%</span><span>eq </span><span>=</span><span> icmp eq i32 </span><span>%</span><span>0</span><span>,</span><span> </span><span>0</span><span>   </span><span></span></p><p><span>  br i1 </span><span>%</span><span>eq</span><span>,</span><span> label </span><span>%</span><span>then</span><span>,</span><span> label </span><span>%</span><span>else</span><span></span></p><p><span>then</span><span>:</span><span>                                             </span><span>;</span><span> preds </span><span>=</span><span> </span><span>%</span><span>entry</span></p><p><span>  br label </span><span>%</span><span>ifcont</span></p><p><span></span><span>else</span><span>:</span><span>                                             </span><span>;</span><span> preds </span><span>=</span><span> </span><span>%</span><span>entry</span></p><p><span>  </span><span>%</span><span>sub </span><span>=</span><span> sub i32 </span><span>%</span><span>0</span><span>,</span><span> </span><span>1</span><span>   </span><span></span></p><p><span>  </span><span>%</span><span>2</span><span> </span><span>=</span><span> call i32 @</span><span>factorial</span><span>(</span><span>i32 </span><span>%</span><span>sub</span><span>)</span><span> </span><span></span></p><p><span>  </span><span>%</span><span>mult </span><span>=</span><span> mul i32 </span><span>%</span><span>0</span><span>,</span><span> </span><span>%</span><span>2</span><span>  </span><span></span></p><p><span>  br label </span><span>%</span><span>ifcont</span></p><p><span>ifcont</span><span>:</span><span>                                           </span><span>;</span><span> preds </span><span>=</span><span> </span><span>%</span><span>else</span><span>,</span><span> </span><span>%</span><span>then</span></p><p><span>  </span><span>%</span><span>iftmp </span><span>=</span><span> phi i32 </span><span>[</span><span> </span><span>1</span><span>,</span><span> </span><span>%</span><span>then </span><span>]</span><span>,</span><span> </span><span>[</span><span> </span><span>%</span><span>mult</span><span>,</span><span> </span><span>%</span><span>else</span><span> </span><span>]</span><span></span></p><p><span>  ret i32 </span><span>%</span><span>iftmp</span></p><p><span></span><span>}</span></p></pre></div></div><p>Note the <code>.ll</code> extension is for <strong>human-readable</strong> LLVM IR output. There’s also <code>.bc</code> for bit-code, a more compact machine representation of LLVM IR.</p><p>We can walk through this IR in 4 levels of detail:</p><h4 id="at-the-instruction-level"><a href="#at-the-instruction-level" aria-label="at the instruction level permalink"></a>At the Instruction Level:</h4><p>Notice how LLVM IR contains assembly instructions like <code>br</code> and <code>icmp</code>, but abstracts the machine-specific messy details of function calling conventions with a single <code>call</code> instruction.</p><p><span>
      <a href="https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/565cc/factorial-instructions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Factorial instructions" title="Factorial instructions" src="https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/a6d36/factorial-instructions.png" srcset="https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/222b7/factorial-instructions.png 163w,https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/ff46a/factorial-instructions.png 325w,https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/a6d36/factorial-instructions.png 650w,https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/e548f/factorial-instructions.png 975w,https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/3c492/factorial-instructions.png 1300w,https://mukulrathi.co.uk/static/f987ee45552570ad7aa513f6d3fc19a7/565cc/factorial-instructions.png 1806w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><h4 id="at-the-control-flow-graph-level"><a href="#at-the-control-flow-graph-level" aria-label="at the control flow graph level permalink"></a>At the Control Flow Graph Level:</h4><p>If we take a step back, you can see the IR defines the <strong>control flow graph</strong> of the program. IR instructions are grouped into labeled <strong>basic blocks</strong>, and the <code>preds</code> labels for each block represent incoming edges to that block. e.g. the <code>ifcont</code> basic block has predecessors <code>then</code> and <code>else</code>:</p><p>At this point, I’m going to assume you have come across Control Flow Graphs and basic blocks. We introduced Control Flow Graphs in a previous post in the series, where we used them to perform different dataflow analyses on the program. I’d recommend you go and check the <a href="http://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/#control-flow-graph">CFG section of that dataflow analysis post</a> now. I’ll wait here :)</p><p><span>
      <a href="https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/11864/factorial-cfg.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Factorial control flow graph" title="Factorial control flow graph" src="https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/a6d36/factorial-cfg.png" srcset="https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/222b7/factorial-cfg.png 163w,https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/ff46a/factorial-cfg.png 325w,https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/a6d36/factorial-cfg.png 650w,https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/e548f/factorial-cfg.png 975w,https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/3c492/factorial-cfg.png 1300w,https://mukulrathi.co.uk/static/6a6edf6d916150ea4de92c0fc1a68e1a/11864/factorial-cfg.png 2034w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>The <code>phi</code> instruction represents <strong>conditional assignment</strong>: assigning different values depending on which preceding basic block we’ve just come from. It is of the form <code>phi type [val1, predecessor1], [val2, predecessor2], ...</code> In the example above, we set <code>%iftmp</code> to 1 if we’ve come from the <code>then</code> block, and <code>%mult</code> if we’ve come from the <code>else</code> block. Phi nodes must be at the <strong>start</strong> of a block, and include one entry for each predecessor.</p><h4 id="at-the-function-level"><a href="#at-the-function-level" aria-label="at the function level permalink"></a>At the Function Level:</h4><p>Taking another step back, the overall structure of a function in LLVM IR is as follows:</p><p><span>
      <a href="https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/b2b2c/factorial-fn.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Factorial fn" title="Factorial fn" src="https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/a6d36/factorial-fn.png" srcset="https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/222b7/factorial-fn.png 163w,https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/ff46a/factorial-fn.png 325w,https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/a6d36/factorial-fn.png 650w,https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/e548f/factorial-fn.png 975w,https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/3c492/factorial-fn.png 1300w,https://mukulrathi.co.uk/static/c80bbba94459a0ac84429c53299823b2/b2b2c/factorial-fn.png 1708w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><h4 id="at-the-module-level"><a href="#at-the-module-level" aria-label="at the module level permalink"></a>At the Module Level:</h4><p>An LLVM <strong>module</strong> contains all the information associated with a program file. (For multi-file programs, we’d link together their corresponding modules.)</p><p><span>
      <a href="https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/cad61/module.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="LLVM Module" title="LLVM Module" src="https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/a6d36/module.png" srcset="https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/222b7/module.png 163w,https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/ff46a/module.png 325w,https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/a6d36/module.png 650w,https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/e548f/module.png 975w,https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/3c492/module.png 1300w,https://mukulrathi.co.uk/static/e21edb9623d8fb7bc23f57db23b93cf8/cad61/module.png 1988w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>Our <code>factorial</code> function is just one function definition in our module. If we want to execute the program, e.g. to compute <code>factorial(10)</code> we need to define a
<code>main</code> function, which will be the entrypoint for our program’s execution. The <code>main</code> function’s signature is a hangover from C (we return 0 to indicate successful execution):</p><div><p><span>example_program.c</span></p><div><pre><p><span></span><span>int</span><span> </span><span>main</span><span>(</span><span>)</span><span>{</span><span></span></p><p><span>  </span><span>factorial</span><span>(</span><span>10</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>0</span><span>;</span><span></span></p><p><span></span><span>}</span></p></pre></div></div><p>We specify that we want to compile for an Intel Macbook Pro in the module target info:</p><div><p><span>example_module.ll</span></p><div><pre><p><span>source_filename </span><span>=</span><span> </span><span>"Module"</span><span></span></p><p><span>target triple </span><span>=</span><span> </span><span>"x86_64-apple-darwin18.7.0"</span><span></span></p><p><span></span><span>.</span><span>.</span><span>.</span><span></span></p><p><span>define i32 @</span><span>factorial</span><span>(</span><span>i32</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>.</span><span>.</span><span>.</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span>define i32 @</span><span>main</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>entry</span><span>:</span><span></span></p><p><span>  </span><span>%</span><span>0</span><span> </span><span>=</span><span> call i32 @</span><span>factorial</span><span>(</span><span>i32 </span><span>10</span><span>)</span><span></span></p><p><span>  ret i32 </span><span>0</span><span></span></p><p><span></span><span>}</span></p></pre></div></div><h2 id="the-llvm-api-key-concepts"><a href="#the-llvm-api-key-concepts" aria-label="the llvm api key concepts permalink"></a>The LLVM API: Key Concepts</h2><p>Now we’ve got the basics of LLVM IR down, let’s introduce the LLVM API. We’ll go through the key concepts, then introduce more of the API as we explore LLVM IR further.</p><p>LLVM defines a whole host of classes that map to the concepts we’ve talked about.</p><ul><li><code>Value</code></li><li><code>Module</code></li><li><code>Type</code></li><li><code>Function</code></li><li><code>BasicBlock</code></li><li><code>BranchInst</code>
…</li></ul><p>These are all in the namespace <code>llvm</code>. In the Bolt repo, I chose to make this namespacing explicit by referring to them as <code>llvm::Value</code>, <code>llvm::Module</code> etc.)</p><p>Most of the LLVM API is quite mechanical. Now you’ve seen the diagrams that define modules, functions and basic blocks, the relationship between their corresponding classes in the API falls out nicely. You can query a <code>Module</code> object to get a list of its <code>Function</code> objects, and query a <code>Function</code> to get the list of its <code>BasicBlock</code>s, and the other way round: you can query a <code>BasicBlock</code> to get its parent <code>Function</code> object.</p><p><code>Value</code> is the base class for any value computed by the program. This could be a function (<code>Function</code> subclasses <code>Value</code>), a basic block (<code>BasicBlock</code> also subclasses <code>Value</code>), an instruction, or the result of an intermediate computation.</p><p>Each of the expression <code>codegen</code> methods returns a <code>Value *</code>: the result of executing that expression. You can think of these <code>codegen</code> methods as generating the IR for that expression and the <code>Value *</code> representing the virtual register containing the expression’s result.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/llvm-backend/llvm_ir_codegen/ir_codegen_visitor.h#L64-L84"> <!-- -->ir_codegen_visitor.h</a></span></p><div><pre><p><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprIntegerIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span><span></span></p><p><span></span><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprBooleanIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span><span></span></p><p><span></span><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprIdentifierIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span><span></span></p><p><span></span><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprConstructorIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span><span></span></p><p><span></span><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprLetIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span><span></span></p><p><span></span><span>virtual</span><span> Value </span><span>*</span><span>codegen</span><span>(</span><span>const</span><span> ExprAssignIR </span><span>&amp;</span><span>expr</span><span>)</span><span> override</span><span>;</span></p></pre></div></div><p>How do we generate the IR for these expressions? We create a <strong>unique</strong> <code>Context</code> object to tie our whole code generation together. We use this <code>Context</code> to get access to core LLVM data structures e.g LLVM modules and <code>IRBuilder</code> objects.</p><p>We’ll use the context to create just one module, which we’ll imaginatively name <code>"Module"</code>.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/llvm-backend/llvm_ir_codegen/ir_codegen_visitor.cc#L17-L19"> <!-- -->ir_codegen_visitor.cc</a></span></p><div><pre><p><span>context </span><span>=</span><span> make_unique</span><span>&lt;</span><span>LLVMContext</span><span>&gt;</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>builder </span><span>=</span><span> std</span><span>::</span><span>unique_ptr</span><span>&lt;</span><span>IRBuilder</span><span>&lt;</span><span>&gt;&gt;</span><span>(</span><span>new</span><span> IRBuilder</span><span>&lt;</span><span>&gt;</span><span>(</span><span>*</span><span>context</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>module </span><span>=</span><span> make_unique</span><span>&lt;</span><span>Module</span><span>&gt;</span><span>(</span><span>"Module"</span><span>,</span><span> </span><span>*</span><span>context</span><span>)</span><span>;</span></p></pre></div></div><h3 id="irbuilder"><a href="#irbuilder" aria-label="irbuilder permalink"></a>IRBuilder</h3><p>We use the <code>IRBuilder</code> object to incrementally build up our IR. It is intuitively the equivalent of a file pointer when reading/writing a file - it carries around <em>implicit</em> state, e.g. the last instruction added, the basic block of that …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mukulrathi.co.uk/create-your-own-programming-language/llvm-ir-cpp-api-tutorial/">https://mukulrathi.co.uk/create-your-own-programming-language/llvm-ir-cpp-api-tutorial/</a></em></p>]]>
            </description>
            <link>https://mukulrathi.co.uk/create-your-own-programming-language/llvm-ir-cpp-api-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25539797</guid>
            <pubDate>Fri, 25 Dec 2020 23:03:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NixOS on ARM/Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25538764">thread link</a>) | @botayhard
<br/>
December 25, 2020 | https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi | <a href="https://web.archive.org/web/*/https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr">
<div>
<table>
<tbody><tr>
<th colspan="2">Raspberry Pi Family
</th></tr>
<tr>
<td colspan="2"><a href="https://nixos.wiki/wiki/File:Raspberry_pi_3_glamour.jpg" title="A Raspberry Pi 3 with enclosure."><img alt="A Raspberry Pi 3 with enclosure." src="https://nixos.wiki/images/thumb/4/40/Raspberry_pi_3_glamour.jpg/x256px-Raspberry_pi_3_glamour.jpg.pagespeed.ic.oggU_vQtmX.jpg" width="256" height="204" srcset="https://nixos.wiki/images/thumb/4/40/Raspberry_pi_3_glamour.jpg/x384px-Raspberry_pi_3_glamour.jpg.pagespeed.ic.Jh6nwVCkVn.jpg 1.5x, https://nixos.wiki/images/thumb/4/40/Raspberry_pi_3_glamour.jpg/x512px-Raspberry_pi_3_glamour.jpg.pagespeed.ic.oXV576JEG6.jpg 2x"></a>
</td></tr>
<tr>
<th colspan="2">Raspberry Pi
</th></tr>
<tr>
<th>Architecture
</th>
<td>ARMv6
</td></tr>
<tr>
<th colspan="2">Raspberry Pi 2
</th></tr>
<tr>
<th>Architecture
</th>
<td>ARMv7
</td></tr>
<tr>
<th colspan="2">Raspberry Pi 3
</th></tr>
<tr>
<th>Architecture
</th>
<td>AArch64 + ARMv7
</td></tr>
<tr>
<th colspan="2">Raspberry Pi 4
</th></tr>
<tr>
<th>Architecture
</th>
<td>AArch64 + ARMv7
</td></tr></tbody></table>
</div>
<p>The Raspberry Pi family of devices is a series of single-board computers made by the Raspberry Pi Foundation. They are all based on Broadcom System-on-a-chip (SOCs). 
</p>


<h2><span id="Status"></span>Status</h2>
<p>Only the <i>Raspberry Pi 3 Family</i> is supported upstream, with the AArch64 effort.
</p><p>The Raspberry Pi 4B is not <em>supported</em> by NixOS, though a beta-quality disk image specific for it is produced. It will be supported the same as the Pi 3 family once the mainline kernel and mainline U-Boot boot fine through the generic mainline image.
</p><p>Other Raspberry Pis (0, 1, and 2) are part of diverse community porting efforts to ARMv6 and ARMv7.
</p><p>The Linux kernel in use, except for the Raspberry Pi 1 family, is the mainline Linux kernel, and not the Raspberry Pi Foundation's fork. This could reduce compatibility with some add-on boards or third-party libraries<sup>[expanded explanation needed]</sup>.
</p><p>The following table is intended to be updated by the NixOS contributors with the current status of the boards. For a list of products, <a rel="nofollow" href="https://www.raspberrypi.org/products/">see the <i>Products Archive</i></a>.
</p>
<table>

<tbody><tr>
<th> Board name
</th>
<th> Architecture
</th>
<th> Support
</th></tr>
<tr>
<th colspan="3">Raspberry&nbsp;Pi&nbsp;1
</th></tr>
<tr>
<td> Raspberry Pi 1 Model B
</td>
<td rowspan="5"> armv6
</td>
<td> C
</td></tr>
<tr>
<td> Raspberry Pi 1 Model A+
</td>
<td> C*
</td></tr>
<tr>
<td> Raspberry Pi 1 Model B+
</td>
<td> C
</td></tr>
<tr>
<td> Raspberry Pi Zero
</td>
<td> C*
</td></tr>
<tr>
<td> Raspberry Pi Zero W
</td>
<td> C
</td></tr>
<tr>
<th colspan="3">Raspberry&nbsp;Pi&nbsp;2
</th></tr>
<tr>
<td> Raspberry Pi 2 Model B
</td>
<td> armv7
</td>
<td> C
</td></tr>
<tr>
<th colspan="3">Raspberry&nbsp;Pi&nbsp;3
</th></tr>
<tr>
<td> <a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_3" title="NixOS on ARM/Raspberry Pi 3">Raspberry Pi 3 Model B</a>
</td>
<td rowspan="3"> AArch64<br> <i>+&nbsp;armv7</i>
</td>
<td> YES
</td></tr>
<tr>
<td> <a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_3" title="NixOS on ARM/Raspberry Pi 3">Raspberry Pi 3 Model B+</a>
</td>
<td> YES
</td></tr>
<tr>
<td> <a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_3" title="NixOS on ARM/Raspberry Pi 3">Raspberry Pi 3 Model A+</a>
</td>
<td>&nbsp;?
</td></tr>
<tr>
<th colspan="3">Raspberry Pi 4
</th></tr>
<tr>
<td> <a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_4" title="NixOS on ARM/Raspberry Pi 4">Raspberry Pi 4 Model B</a>
</td>
<td> AArch64<br> <i>+ armv7</i>
</td>
<td> YES* (<a rel="nofollow" href="https://github.com/NixOS/nixpkgs/issues/63720">GitHub issue</a>)
</td></tr></tbody></table>
<p><i>Support</i>
</p>
<ul><li> YES: Supported architecture by Nixpkgs downstream and tested to be working.</li>
<li> YES*: Available in Nixpkgs downstream but experimental.</li>
<li> C: Community supported, and tested to be working.</li>
<li> C*: Community supported, unverified but should be working.</li>
<li>&nbsp;?&nbsp;: Unverified, unknown if it will work.</li></ul>
<p>The Raspberry Pi 3 Family is only supported as <b>AArch64</b>. Use as armv7 is community supported.
</p>
<h2><span id="Board-specific_installation_notes"></span>Board-specific installation notes</h2>
<p>First follow the <a href="https://nixos.wiki/wiki/NixOS_on_ARM#Installation" title="NixOS on ARM">generic installation steps</a> to get the installer image and install using the <a href="https://nixos.wiki/wiki/NixOS_on_ARM#NixOS_installation_.26_configuration" title="NixOS on ARM">installation and configuration steps</a>.
</p>
<h3><span id="Raspberry_Pi_.281.29"></span>Raspberry Pi (1)</h3>
<p>The ARMv6 image boots out-of-the-box.
</p>
<h3><span id="Raspberry_Pi_2"></span>Raspberry Pi 2</h3>
<p>The ARMv7 image should boot out-of-the-box, though the author hasn't personally tested this.
</p>
<h3><span id="Raspberry_Pi_3_.2F_3B.2B"></span>Raspberry Pi 3 / 3B+</h3>
<p><a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_3#Board-specific_installation_notes" title="NixOS on ARM/Raspberry Pi 3">Raspberry Pi 3#Board-specific installation notes</a>
</p>
<h3><span id="Raspberry_Pi_4B"></span>Raspberry Pi 4B</h3>
<p><a href="https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi_4#Board-specific_installation_notes" title="NixOS on ARM/Raspberry Pi 4">Raspberry Pi 4#Board-specific installation notes</a>
</p>
<h2><span id="Serial_console"></span>Serial console</h2>
<p>Your <code>configuration.nix</code> will need to add <code>console=ttyS1,115200n8</code> to the <code>boot.kernelParams</code> configuration to use the serial console.
</p>
<p><img alt="Breeze-text-x-plain.png" src="https://nixos.wiki/images/e/ef/xBreeze-text-x-plain.png.pagespeed.ic.CzagNXRrGf.png" width="16" height="16"></p><pre>/etc/nixos/configuration.nix
</pre><div dir="ltr"><pre><span>{</span> config<span>,</span> pkgs<span>,</span> lib<span>,</span> <span>...</span> <span>}:</span>
<span>{</span>
  boot<span>.</span><span>kernelParams =</span> <span>[</span>
    <span>"console=ttyS1,115200n8"</span>
  <span>];</span>
<span>}</span>
</pre></div>
<p>If the Raspberry Pi downstream kernel is used the serial interface is named <code>serial0</code> instead.
</p>
<h2><span id="Binary_Cache"></span>Binary Cache</h2>
<p>Depending on the architecture used, binary caches availability varies. Binary caches instructions are on the main <a href="https://nixos.wiki/wiki/NixOS_on_ARM#Binary_cache" title="NixOS on ARM">NixOS on ARM</a>&nbsp;page. The following table describes the architectures supported by each board. 
</p>
<table>

<tbody><tr>
<th> Raspberry Pi 1
</th>
<td> armv6
</td></tr>
<tr>
<th> Raspberry Pi 2
</th>
<td> armv7
</td></tr>
<tr>
<th rowspan="2">Raspberry Pi 3
</th>
<td> armv7
</td></tr>
<tr>
<td> AArch64
</td></tr>
<tr>
<th rowspan="2">Raspberry Pi 4
</th>
<td> armv7
</td></tr>
<tr>
<td> AArch64
</td></tr></tbody></table>
<h2><span id="Notes_about_the_boot_process"></span>Notes about the boot process</h2>
<p>The custom bootloader, part of the Raspberry Pi firmware, is abstracted away for NixOS by making it boot U-Boot instead.
</p><p>U-Boot gives us the ability to provide a generation selection menu during the boot process, in addition to storing the boot files on the main partition, rather than on the firmware partition.
</p>
<h3><span id="Raspberry_Pi_.28all_versions.29"></span>Raspberry Pi (all versions)</h3>
<p>USB keyboards and HDMI displays should work, though some issues have been reported (see Troubleshooting below).
</p><p>Using the 3.3v serial port via the pin headers (exact location depends on hardware version) will get u-boot output and, when configured, a Linux kernel console.
</p>
<h2><span id="Troubleshooting"></span>Troubleshooting</h2>
<h3><span id="Power_issues"></span>Power issues</h3>
<p>Especially with the newer power-hungry Raspberry Pi families (3, 4), it is important to have a <a rel="nofollow" href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/power/README.md">sufficient enough power supply</a> or <i>weirdness</i> may happen. Weirdness may include:
</p>
<ul><li> Lightning bolt on HDMI output "breaking" the display.</li>
<li> Screen switching back to u-boot text
<ul><li> Fixable temporarily when power is sufficient by switching VT (alt+F2 / alt+F1)</li></ul></li>
<li> Random hangs</li></ul>
<p>This problem is a hard problem. It is caused by the Raspberry Pi warning about power issues, but the current drivers (as of 
Linux 4.14) have a hard time dealing with it properly. If the power supply is rated properly AND the cable is not incurring too much power losses, it may be required to disable the lightning bolt indicator so the display driver isn't messed up.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> The lightning bolt indicator can be disabled by adding the line <code>avoid_warnings=1</code> in config.txt<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>
</p>
<p><strong> Note: </strong>A <i>properly rated</i> USB power supply, AND a good cable are necessary. The cable has to be short enough to not incur power losses through the length. Do note that thin and cheap cables usually have thinner copper wires, which in turn accentuates power losses.</p>
<h3><span id="Additional_Troubleshooting"></span>Additional Troubleshooting</h3>
<p>Additional troubleshooting information may be found <a rel="nofollow" href="https://elinux.org/R-Pi_Troubleshooting">at elinux.org</a>.
</p>
<hr><ol>
<li id="cite_note-1"><span><a href="#cite_ref-1">↑</a></span> <span><a rel="nofollow" href="https://logs.nix.samueldr.com/nixos/2017-12-20#1513784657-1513784714">https://logs.nix.samueldr.com/nixos/2017-12-20#1513784657-1513784714</a>;</span>
</li>
<li id="cite_note-2"><span><a href="#cite_ref-2">↑</a></span> <span><a rel="nofollow" href="https://www.raspberrypi.org/documentation/configuration/config-txt/README.md">https://www.raspberrypi.org/documentation/configuration/config-txt/README.md</a></span>
</li>
</ol>

<!-- 
NewPP limit report
Cached time: 20201118204625
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.016 seconds
Real time usage: 0.019 seconds
Preprocessor visited node count: 144/1000000
Preprocessor generated node count: 456/1000000
Post‐expand include size: 1767/2097152 bytes
Template argument size: 866/2097152 bytes
Highest expansion depth: 6/40
Expensive parser function count: 0/100
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    6.785      1 -total
 26.47%    1.796      1 Template:Note
 17.97%    1.219      1 Template:File
 17.95%    1.218      1 Template:META_Box_Blue
 10.17%    0.690      1 Template:META_Box
  8.31%    0.564      1 Template:ARM/breadcrumb
-->

<!-- Saved in parser cache with key nixoswiki-nixos:pcache:idhash:290-0!*!0!!en!5!* and timestamp 20201118204625 and revision id 4737
 -->
</div></div>]]>
            </description>
            <link>https://nixos.wiki/wiki/NixOS_on_ARM/Raspberry_Pi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25538764</guid>
            <pubDate>Fri, 25 Dec 2020 20:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mountain Peaks in WebGL]]>
            </title>
            <description>
<![CDATA[
Score 275 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25537377">thread link</a>) | @pheelicks
<br/>
December 25, 2020 | https://felixpalmer.github.io/peaks-of-austria/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/peaks-of-austria/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/peaks-of-austria/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25537377</guid>
            <pubDate>Fri, 25 Dec 2020 16:37:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Switching from Apple to Lenovo]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25536216">thread link</a>) | @ynv
<br/>
December 25, 2020 | https://ayedo.github.io/hardware/2020/12/25/switching-from-apple-to-lenovo.html | <a href="https://web.archive.org/web/*/https://ayedo.github.io/hardware/2020/12/25/switching-from-apple-to-lenovo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Some of my friends have been telling me that Windows machines got a lot better. I decided to give it a try, and bought a top of the line Lenovo X1 Carbon Gen 8. For all of you thinking about doing the same switch, you might want to read this first.</p>

<p>Even though Apple is known for overpricing, and taking advantage of their customer base, they do it in a larger scheme of things, and do not engage in business practices which have a low customer experience. Unfortunately, you can’t say the same about the Lenovo universe.</p>

<p>Just go to their <a href="https://www.lenovo.com/">website</a> for a minute. Try to figure out which Laptop to buy, without getting the feeling you are being scammed. Everything seems to be on sale all the time, there are laptops of different generations of the same product line being advertised to you. They lie to your face about the battery life-times. People who are buying these machines got used to this experience, and are proud of being able to navigate such websites. You really need to do your homework before buying anything.</p>

<p>For example: I bought the X1 with their standard FHD screen, and it feels older than my 7 years old MBP. When trying to figure out why, I found out that Lenovo has a “<a href="https://www.notebookcheck.net/Lenovo-s-Panel-Lottery-continues-with-3-different-14-inch-LowPower-displays.426538.0.html">panel lottery</a>”: They use different suppliers with remarkable quality differences for their displays. Which one you get is just based on luck. Turns out the panel I got is the same they use for their cheapest product line. This means I have a ghosting mouse pointer on a $2000 brand new machine. Nice.</p>

<p>Even if you are lucky with the screen: it does not come color calibrated out of the box! Good luck trying to find the correct color profile, unless you want to spend money on a calibration tool you’re only going to use once.
Then comes Windows:</p>

<p>Yeah, it got better, but wow, do they carry a lot of baggage around. When trying to calibrate the display I found out that Windows has no less than three different system configuration UIs, which are also intertwined in unexpected ways. On top of that Lenovo installed their own buggy configuration tool. Configuring Windows feels like walking on ice. Even with all this configuration might, it still was not possible to get the exact serial number of my display panel without installing a third party tool.</p>

<p>Microsoft is also constantly nagging you about something that marginally helps their bottom line, but costs you a lot of your user experience. Like their constant push to trick people into giving them their data, or the fact that they try to force you to use their browser whenever they can.</p>

<p>I’m still not sure if I ticked the right boxes so that Microsoft does not get my browsing behaviour. I feel stressed every time Microsoft wants something from me. How are they trying to scam me this time?</p>

<p>For me this reinforces my belief that people who like Windows are simply used to it, because they need it for work or playing games. There is no point arguing with this, as their added value is their own experience, and the fact they know the tools and tricks to make the system usable to them.</p>

<p>One friend even told me that one of his favourite improvements in newer Windows versions is that they made it a lot easier to completely reset the operation system. My Apple machine has never been reset since I bought it almost a decade ago, and works flawlessly.  His statement seems like a subtle warning as to what is expecting me in the near future using my new  machine.</p>

</div></div>]]>
            </description>
            <link>https://ayedo.github.io/hardware/2020/12/25/switching-from-apple-to-lenovo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25536216</guid>
            <pubDate>Fri, 25 Dec 2020 13:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mystery of Mistletoe’s Missing Genes]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25536070">thread link</a>) | @dnetesn
<br/>
December 25, 2020 | http://abstractions.nautil.us/article/656/the-mystery-of-mistletoes-missing-genes | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/656/the-mystery-of-mistletoes-missing-genes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>H</span>oliday-season traditions stretching back for centuries have linked wintertime romance to decorative&nbsp;sprigs of mistletoe. The way that the plantâ€™s rounded evergreen leaves and white berries tightly hug the branches of the trees on which it grows probably inspired that association. The truth&nbsp;about this botanical intimacy is&nbsp;less romantic: Mistletoe is a kind of parasite. Its leaves produce sugars by photosynthesis, but instead of roots, it has structures that pierce the host treeâ€™s vital tissues to suck out nutrients and water.</p>

<p>But that interdependence goes even deeper, and scientists are just starting to realize the ways in which mistletoes are unique at the molecular level because of it. The cells of all multicellular organisms rely on the organelles called mitochondria to make their biochemical fuel—all multicellular organisms except mistletoes, that is. Not only do their mitochondria produce little if any of this fuel, theyâ€™ve lost many of the genes needed to make it. In the few years since botanists discovered this anomaly, scientists worldwide have tried with no more than limited success to figure out how mistletoes pull off this trick.</p>
<p><strong>Cellular Powerhouses Go Offline</strong></p>
<p>The first hint that mistletoes were truly&nbsp;<em>sui generis</em>&nbsp;was presented in 2015 at the International Conference for Plant Mitochondrial Biology in WrocÅ‚aw, Poland, by&nbsp;<a href="https://scholar.google.com/citations?user=-zvgjbUAAAAJ&amp;hl=en" target="_blank">Elizabeth Skippington</a>, then a postdoctoral fellow in&nbsp;<a href="https://biology.indiana.edu/about/faculty/palmer-jeffrey.html" target="_blank">Jeffrey Palmer</a>â€™s lab at Indiana University. She astounded the small scientific audience with evidence later&nbsp;<a href="https://www.pnas.org/content/112/27/E3515" target="_blank">published in&nbsp;</a><a href="https://doi.org/10.1073/pnas.1504491112" target="_blank"><em>Proceedings of the National Academy of Sciences</em></a>&nbsp;that one mistletoe species (<em>Viscum scurruloideum</em>) had an extremely tiny mitochondrial genome and lacked key proteins thought to be required for respiration — the chemical pathway that enables mitochondria to make adenosine triphosphate (ATP), cellsâ€™ molecular fuel.</p>
<p>â€œIt felt like everybody was holding their breath,â€� said&nbsp;<a href="https://www.genetik.uni-hannover.de/en/institute/people/people/epv/section-v-plant-proteomics/graduate-teachingresearch-assistant/jennifer-senkler/?tx_t3luhepv_t3luhepvoe%5BdisablePersHomepages%5D=" target="_blank">Jennifer Senkler</a>, a plant biochemist with Leibniz University in Germany, who attended the talk. â€œIn the next break, everybody was chatting excitedly about this and speculating on how this could work.â€�</p>
<p>They wondered if perhaps Skippington missed the genes because they had become unrecognizable, or if there was some error in her methods. Or maybe the genes had moved into the nuclear genome—thatâ€™s something that can happen with mitochondrial genes, after all, and mistletoesâ€™ enormous&nbsp;genomes (about 24 times the size of ours) have thus far impeded whole-genome sequencing. Everyone was eager to solve the mystery of the missing genes.</p>
<p>â€œWe started joking about researchers falling off trees in the attempt to get their hands on mistletoe plants,â€� Senkler wrote in an email to&nbsp;<em>Quanta.</em>&nbsp;Indeed, as soon as she and her colleagues returned to Germany, â€œwe bought a long branch cutter and started collecting mistletoes.â€�<br></p>
<p>They werenâ€™t the only ones. Not far from Senklerâ€™s lab in Hannover, at the Max Planck Institute of Molecular Plant Physiology in Potsdam-Golm, the biochemist&nbsp;<a href="https://blogs.urz.uni-halle.de/cellphysiology/more-about-etienne/" target="_blank">Etienne Meyer</a>&nbsp;started some investigating of his own. And at the John Innes Center in Norwich, England,&nbsp;<a href="https://www.jic.ac.uk/people/janneke-balk/" target="_blank">Janneke Balk</a>&nbsp;similarly decided to dig into mistletoe mitochondria. Balkâ€™s team soon reached out to Meyerâ€™s, and the two labs joined forces, though they kept running their experiments in parallel for the most part to ensure the results were replicated. â€œThatâ€™s what makes the story even more solid,â€� Meyer said.<br></p>
<p>In the end, all three research teams came to&nbsp;<a href="https://doi.org/10.1016/j.cub.2018.03.036" target="_blank">the same conclusion</a>: Mistletoe mitochondria donâ€™t perform the same ATP-generating process as the mitochondria of all other plants, fungi and animals. The genes Skippington spoke of are truly gone, not mutated or repositioned. And as yet, no one knows how mistletoes survive without them.</p>
<p><strong>Metabolic Misers</strong></p>
<p>In all other multicellular life studied to date—and in most single-celled eukaryotes, for that matter—mitochondria produce ATP in a five-step process. Each step is performed by a separate suite of proteins, complexes I-V. â€œAnd one of these, the very first complex, is totally missing in mistletoes,â€� said&nbsp;<a href="https://www.su.se/english/profiles/gipe0376-1.379971" target="_blank">Gitte Petersen</a>, a botanist at Stockholm University in Sweden.</p>
<p>Trained as a plant systematist, Petersen at first thought that maybe this loss of complex I might be common. But when she and her colleagues&nbsp;<a href="https://doi.org/10.1186/s12862-019-1401-8" target="_blank">checked nine other parasitic plant groups</a>, the rest were normal. Something special seemingly happened in the mistletoes alone.</p>
<blockquote>â€œIn the next break, everybody was chatting excitedly about this and speculating on how this could work,â€� says&nbsp;Jennifer Senkler of&nbsp;Leibniz University.</blockquote>

<p>As for how mistletoes compensate for the loss of these incredibly important genes, â€œwe can only speculate,â€� Meyer said.</p>
<p>Experiments show that mistletoes make some ATP; itâ€™s just unclear whether their mitochondria play a large part in that. Meyer and Balkâ€™s collaboration found that the plants do produce more proteins&nbsp;<a href="https://doi.org/10.1016/j.cub.2018.03.036" target="_blank">for use in glycolysis</a>, an inefficient method of splitting apart sugars to make ATP thatâ€™s found in all cells. However, the scientists couldnâ€™t determine exactly how much ATP the plants generate that way.</p>
<p>Still, ramping up glycolysis enough to rival mitochondriaâ€™s usual ATP output would take a lot more sugar. Meyerâ€™s hunch is that the mistletoes steal sugar from their host, along with&nbsp;water and minerals. They might even photosynthesize more feverishly than other plants to make extra sugars to burn, although Meyer labels that idea â€œextremely hypothetical.â€�</p>
<p>Mistletoes may&nbsp;also just use energy with Scrooge-like miserliness. Both Senkler and Petersen pointed out that a parasitic lifestyle and slow growth could&nbsp;enable mistletoes to subsist on low amounts of ATP. In fact, â€œmistletoe might teach us a lesson on how to survive at energy-limiting conditions,â€� Senkler said.</p>
<p><strong>Too Complex to Keep?</strong></p>
<p>However mistletoes get by with their deficient mitochondria, the big unanswered question is why these plants did away with something so seemingly useful.</p>
<blockquote>â€œ[M]istletoe might teach us a lesson on how to survive at energy-limiting conditions,â€� says&nbsp;Jennifer Senkler of&nbsp;Leibniz University.
</blockquote>
<p>Senklerâ€™s suspicion is that complex I was too burdensome to keep. It consists of about 50 proteins that have to be made in different subcompartments of the cell, assembled and fit into the inner membrane of the mitochondria. The energy cost of all that is considerable, even if it means more energy in the long run, and â€œmistletoes seem to avoid processes that require much energy,â€� she said.</p>
<p>Ditching energy-expensive traits, or â€œreductive evolution,â€� is a common theme in parasites, Meyer noted. And losing this particular suite of proteins might have additional benefits. Because complex I spews highly reactive molecules that can cause cellular damage, losing it could make the plants more resilient to stress. Similar mitochondrial gene losses are frequently seen in cancer cells, which is partly why malignant cells can often survive conditions that other cells wouldnâ€™t.</p>
<p>But Petersen isnâ€™t convinced the loss is beneficial at all. It could be that something like a catastrophic mutation befell the mistletoes early in their groupâ€™s evolution, something that accidentally wiped out their ability to make complex I. â€œAnd then mistletoe just managed to cope with what happened,â€� she said, perhaps because mistletoeâ€™s parasitic lifestyle offered ways to compensate. She is curious about whether additional genetic sequencing might let researchers suss out when the loss happened and whether the plants were already parasitic.</p>
<p>If it does turn out that the plantsâ€™ loss of complex I was random bad luck, then perhaps mistletoes are just like the rest of us: Theyâ€™re doing whatever it takes to survive the holidays.</p>

<ul><li> is an award-winning science writer who trained as a molecular biologist. She the author of Venomous. </li></ul>
<p>Lead image:&nbsp;During the holiday season, sprigs of mistletoe appear everywhere as traditional decorations. Scientists have recently discovered a metabolic quirk of mistletoes that sets them apart from all other multicellular life. Credit:&nbsp;Nigel Cattlin / Science Source</p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/656/the-mystery-of-mistletoes-missing-genes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25536070</guid>
            <pubDate>Fri, 25 Dec 2020 12:25:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Differences Between macOS and Common Unix Systems]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25535971">thread link</a>) | @dongyx
<br/>
December 25, 2020 | https://www.dyx.name/posts/macunix.html | <a href="https://web.archive.org/web/*/https://www.dyx.name/posts/macunix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Discuss some differences between macOS and common Unix systems to help Unix users get familiar with macOS sooner.</p><div>
				
<h2 id="users-and-groups">Users and Groups</h2>

<p>macOS manages users and groups by directory services instead of <code>/etc/passwd</code> and  <code>/etc/group</code>.  Consider a local network, for example, the one in your office, there’re many computers in the network and each has its own files, accounts, etc. A directory service organizes these distributed resources into one single index and makes them look like a directory hierarchy.</p>

<p>For example, <code>/Hosts/PC1</code> represents a host in the network and <code>/Users/Smith</code> represents a user in the network.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>macOS uses the <code>dscl</code> command to interact with directory services.</p>

<p>To list all users on the system, we could run the following.</p>



<p>The first argument sets which datasource we want to retrieve from. A dot means the local datasource.</p>

<div><div><pre><code># List groups
dscl . -list /Groups
</code></pre></div></div>

<p>The <code>-list</code> option lets <code>dscl</code> print subitems of a resource.  Subitems of <code>/Users</code> are all users. Subitems of <code>/Groups</code> are all groups.</p>

<p>If we want to check the information about the resource instead of listing subitems we should use <code>-read</code>. For example, we could check the information of the user <code>Smith</code> like
the following.</p>

<div><div><pre><code># Retrieve the information of Smith
dscl . -read /Users/Smith
</code></pre></div></div>

<p><code>-read</code> prints keys and values of the specified resource. We could also specify the keys we want.</p>

<div><div><pre><code># Get the primary group ID and default shell of Smith
dscl . -read /Users/Smith PrimaryGroupID UserShell
</code></pre></div></div>

<p>To add a resource, we use <code>dscl . -create</code>. The following command adds a new user <code>belson</code>.</p>

<div><div><pre><code>sudo dscl . -create /Users/belson
</code></pre></div></div>

<p>It seems ok but it’s actually not. If we try to set a password for <code>belson</code> using <code>sudo passwd belson</code>, <code>passwd</code> will tell us the user doesn’t exist. Because <code>dscl</code> just adds a record to the data source but is doesn’t check the integrity. It doesn’t even assign a UID for <code>belson</code>. We must assign a UID and a primary group for <code>belson</code> after adding it to the datasource by ourselves.</p>

<div><div><pre><code>sudo dscl . -create /Users/belson UniqueID 511	# UID 511 for example
sudo dscl . -create /Users/belson PrimaryGroupID 20	# The staff group
</code></pre></div></div>

<p>Now, <code>belson</code> is a Unix user and you can set a password for him using <code>passwd</code>. However, you still can’t login as <code>belson</code> for we don’t assign him a shell.</p>

<div><div><pre><code>sudo dscl . -create /Users/belson UserShell /bin/bash
</code></pre></div></div>

<p>Well we can login as <code>belson</code> now but he doesn’t have a home directory. We must create the directory and specify it with <code>dscl</code>.</p>

<div><div><pre><code>sudo dscl . -create /Users/belson NFSHomeDirectory /Users/belson
sudo mkdir /User/belson
sudo chmod -R belson:staff /User/belson
</code></pre></div></div>

<p>Sounds hell right? But it’s not over. Run <code>dscl . -read /Groups/staff</code> and you will find that
neither the <code>GroupMembers</code> nor the <code>GroupMembership</code> attribute has any information about <code>belson</code>.  We have specified his primary group to <code>staff</code>. But as mentioned above, <code>dscl</code> doesn’t check the integrity. Bidirectional relationships must be maintained manually. This is the real hell.</p>

<p>To solve the user-group relationship problem, we could use <code>dseditgroup</code>. The following command adds <code>belson</code> to the <code>staff</code> group and it takes care of the integrity.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<div><div><pre><code>sudo dseditgroup -o edit -a belson -t user staff
</code></pre></div></div>

<p>We should make a summary here. To create a user <code>belson</code> in the group <code>staff</code>, we need:</p>

<div><div><pre><code>sudo dscl . -create /Users/belson
sudo dscl . -create /Users/belson UniqueID 511	# UID 511 for example
sudo dscl . -create /Users/belson PrimaryGroupID 20	# The staff group
sudo dscl . -create /Users/belson UserShell /bin/bash
sudo dscl . -create /Users/belson NFSHomeDirectory /Users/belson
sudo dseditgroup -o edit -a belson -t user staff
sudo mkdir /User/belson
sudo chmod -R belson:staff /User/belson
</code></pre></div></div>

<p>It is painful for a system administrator to type so many commands just to create a new user. You must miss <code>adduser</code> and <code>addgroup</code> in Debian so much.</p>

<p>Luckily, since Mac OS X 10.10, the <code>sysadminctl</code> command is provided. It’s a high-level interface of <code>dscl</code>. Type <code>sysadminctl</code> in the terminal to see its usage<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<div><div><pre><code>Usage: sysadminctl
	-deleteUser &lt;user name&gt; [-secure || -keepHome] (interactive || -adminUser &lt;administrator user name&gt; -adminPassword &lt;administrator password&gt;)
	-newPassword &lt;new password&gt; -oldPassword &lt;old password&gt; [-passwordHint &lt;password hint&gt;]
	-resetPasswordFor &lt;local user name&gt; -newPassword &lt;new password&gt; [-passwordHint &lt;password hint&gt;] (interactive] || -adminUser &lt;administrator user name&gt; -adminPassword &lt;administrator password&gt;)
	-addUser &lt;user name&gt; [-fullName &lt;full name&gt;] [-UID &lt;user ID&gt;] [-shell &lt;path to shell&gt;] [-password &lt;user password&gt;] [-hint &lt;user hint&gt;] [-home &lt;full path to home&gt;] [-admin] [-picture &lt;full path to user image&gt;] (interactive] || -adminUser &lt;administrator user name&gt; -adminPassword &lt;administrator password&gt;)
	-secureTokenStatus &lt;user name&gt;
	-secureTokenOn &lt;user name&gt; -password &lt;password&gt; (interactive || -adminUser &lt;administrator user name&gt; -adminPassword &lt;administrator password&gt;)
	-secureTokenOff &lt;user name&gt; -password &lt;password&gt; (interactive || -adminUser &lt;administrator user name&gt; -adminPassword &lt;administrator password&gt;)
	-guestAccount &lt;on || off || status&gt;
	-afpGuestAccess &lt;on || off || status&gt;
	-smbGuestAccess &lt;on || off || status&gt;
	-automaticTime &lt;on || off || status&gt;
	-filesystem status
	-screenLock &lt;immediate || off&gt; -password &lt;password&gt;

Pass '-' instead of password in commands above to request prompt.
'-adminPassword' used mostly for scripted operation. Use '-' or 'interactive' to get the authentication string interactivly. This preferred for security reasons
</code></pre></div></div>

<p>We use <code>sysadminctl</code> to delete <code>belson</code> first.</p>

<div><div><pre><code>sudo sysadminctl -deleteUser belson -secure
</code></pre></div></div>

<p>Using <code>dscl</code> to check the directory service, we could find that everything we did is removed.</p>

<p>Now, we add <code>belson</code> again with <code>sysadminctl</code>:</p>

<div><div><pre><code>sudo sysadminctl -addUser belson
sudo dseditgroup -o edit -a belson -t user staff
</code></pre></div></div>

<p>Two commands finish the job.</p>

<h2 id="filesystem-hierarchy">Filesystem Hierarchy</h2>

<p>If you check the root directory, you will see some traditional Unix things like <code>/usr</code>, <code>/var</code>, and <code>/etc</code>. You may also find mac-specified things like <code>/Library</code> <code>/Applications</code>, and <code>/cores</code>.</p>

<p>A list of mac-specified directories with their purposes in the root directory is here<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<table>
  <thead>
    <tr>
      <th>Directory</th>
      <th>Purpose</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/private</td>
      <td>Contains the tmp, var, etc, directories. <code>/tmp</code>, <code>/var</code>, <code>/etc</code> are symbolic links to these subdirectories</td>
    </tr>
    <tr>
      <td>/Library</td>
      <td>Contains support files for locally installed applications, among other things.</td>
    </tr>
    <tr>
      <td>/System</td>
      <td>Contains a subdirectory, Library, that holds support files for the system and system applications, among other things.</td>
    </tr>
    <tr>
      <td>/Network</td>
      <td>Contains network-mounted Application, Library, and Users directories, as well as a Servers directory that contains directories mounted by the auto mount daemon.</td>
    </tr>
    <tr>
      <td>/Users</td>
      <td>Contains home directories for the users on the system. The root user’s home directory is /var/root (actually /private/var/root).</td>
    </tr>
    <tr>
      <td>/Volumes</td>
      <td>Contains all visible mounted filesystems, including removable media and mounted disk images.</td>
    </tr>
  </tbody>
</table>

<p>We could make a list to compare some of them with Linux.</p>

<table>
  <thead>
    <tr>
      <th>macOS</th>
      <th>Linux</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/System/Library</td>
      <td>/lib</td>
    </tr>
    <tr>
      <td>/Library</td>
      <td>/usr/lib, /usr/local/lib</td>
    </tr>
    <tr>
      <td>/Users</td>
      <td>/home</td>
    </tr>
    <tr>
      <td>/Volumes</td>
      <td>/mnt, /media</td>
    </tr>
  </tbody>
</table>

<p>You may be confused here for the difference between <code>/Library</code> and <code>/usr/lib</code>. Which directory should we put libraries into?</p>

<p><code>/Library</code> is for macOS-specified softwares, like the data of things you download from the App Store, and BSD programs shipped with macOS, like modules of pre-installed Perl and of pre-installed Python.</p>

<p><code>/usr/lib</code> and <code>/usr/local/lib</code> are for Unix programs installed by yourself.</p>

<h2 id="booting">Booting</h2>

<p>In modern Linux, the first program launched by the kernel is <code>systemd</code>. In macOS it’s <code>launchd</code><sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p><code>launchd</code> manages two types of services, <code>LaunchDaemon</code> and <code>LaunchAgent</code>. <code>LaunchDaemon</code> will be launched after the system is booted. <code>LaunchAgent</code> will be launched after a user is logged-in.</p>

<p>If a program needs to be launched after the system is booted, a <code>.plist</code> file is required to be placed into <code>/Library/LaunchDaemons</code> or <code>/System/LaunchDaemons</code>.</p>

<p>If a program needs to be launched after a user logged-in, a <code>.plist</code> file is required to be placed into <code>/Library/LaunchAgents</code> or <code>/System/LaunchAgents</code>, or <code>~/Library/LaunchAgents</code> of the user.</p>

<p>The <code>launchctl</code> command is used to control services of <code>launchd</code>.</p>

<div><div><pre><code># to enable sshd
sudo launchctl load -w /System/Library/LaunchDaemons/ssh.plist

# to disable sshd
sudo launchctl unload -w /System/Library/LaunchDaemons/ssh.plist
</code></pre></div></div>

<h2 id="development">Development</h2>

<p>You bought a Mac for development. People told you that you need to do the following two things:</p>

<ul>
  <li>
    <p>Install Xcode from the app store</p>
  </li>
  <li>
    <p>Install command line tools using <code>xcode-select --install</code></p>
  </li>
</ul>

<p>You finished them, opened the terminal and found everything is familiar. You decided to write a classic Hello World with C to celebrate.</p>

<div><div><pre><code>#include &lt;stdio.h&gt;

int main(void)
{
	printf("%s\n", "hello, world");
	return 0;
}
</code></pre></div></div>

<p>If you’re using a 3rd party compiler, the compiler may tell you that <code>stdio.h</code> can’t be found.</p>

<p>No such fundamental file? You want to check <code>/usr/include</code> and you will find that even <code>/usr/include</code> doesn’t exist.</p>

<p>The reason is that header files are put into the package of Xcode in newer Xcode like Xcode 10. You can run <code>xcrun --show-sdk-path</code> to print the path<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<div><div><pre><code>$ xcrun --show-sdk-path
/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk
</code></pre></div></div>

<p>Then you can use <code>-isysroot</code> to specify the path for the compiler, for example:</p>

<div><div><pre><code>gcc -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk hello.c
</code></pre></div></div>

<h2 id="package-manager">Package Manager</h2>

<p>The first package installed to the system is usually a package manager. However, macOS has no default package manager. If you search online, you will find that <a href="https://brew.sh/">Homebrew</a> is the most popular package manager for macOS.</p>

<p>Homebrew is good for many people but not for one who wants things to go more like common Unix systems.</p>

<p>Homebrew can’t run as root. If you want to install python, you run <code>brew install python</code> instead of <code>sudo brew install python</code>. Homebrew installs packages to <code>/usr/local</code>. To achieve its goal about sudo-free, Homebrew changes the owner of all files and subdirectories under <code>/usr/local</code> to the user who installed Homebrew.</p>

<p>This brings security issues. Considering a malware …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dyx.name/posts/macunix.html">https://www.dyx.name/posts/macunix.html</a></em></p>]]>
            </description>
            <link>https://www.dyx.name/posts/macunix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25535971</guid>
            <pubDate>Fri, 25 Dec 2020 12:00:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planner 2.6 – An open-source Todoist alternative for Linux]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25535822">thread link</a>) | @rayrag
<br/>
December 25, 2020 | https://useplanner.com/release/2020/12/24/merry-christmas-everyone-planner-2-6-is-here/ | <a href="https://web.archive.org/web/*/https://useplanner.com/release/2020/12/24/merry-christmas-everyone-planner-2-6-is-here/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2 id="board-view-is-here">Board View is here</h2>

<p>For Todoist users, the Board View was introduced in this new update, a more visual way to organize your Planner projects. This new layout makes it easy to see the big picture of your projects and make progress from start to finish.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/board.png" alt="Planner 2.6 Planner Board"></p>

<p>To see your projects in the <b>Board View</b>, press the three dots icon in the top right, and select <b>View as board</b>. You’ll be able to rearrange your sections, create new ones, and drag your tasks to anywhere on your board.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/board-settings.png" alt="Planner 2.6 Planner Board 2"></p>

<h2 id="sub-project">Sub-project</h2>
<p>One of the most requested features comes to Planner 2.6, keep your ever-growing project list neat and organized with sub-projects.</p>

<p>You can collapse sub-projects under their “parent” projects to temporarily hide them from view. This helps to focus on the right projects at the right time, without getting distracted by everything else.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/sub-project.png" alt="Planner 2.6 Planner Board 2"></p>

<h3 id="how-to-turn-a-project-into-a-sub-project">How to turn a project into a sub-project</h3>

<ol>
  <li>Right click on a project.</li>
  <li>Select the <b>Move</b> option.</li>
  <li>Select a project.</li>
</ol>

<h2 id="new-features">New Features</h2>
<h3 id="quick-search">Quick Search</h3>

<p>A big update for the Quick Find feature is here, with new views and feactures.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/Quick%20Search.png" alt="Planner 2.6 Planner Board 2"></p>

<ul>
  <li>Quick Search now saves your last searches, so you can hop around without even typing.</li>
  <li>Added new <b>Tomorrow</b> view.</li>
  <li>Now it is possible to search between <b>Sections</b></li>
</ul>

<h3 id="task-defaults">Task defaults</h3>

<p>Added a new view in <b>Preferences</b> to edit task defaults.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/tasks-defaults.png" alt="Planner 2.6 Planner Board 2"></p>

<ul>
  <li>New tasks on top: Indicate the position where the new tasks were created.</li>
  <li>Underline completed tasks.</li>
  <li>Default priority: Select the default priority when creating a task.</li>
</ul>

<h3 id="add-tasks-projects-sections-asynchronously">Add tasks, projects, sections asynchronously</h3>

<p>Adding a task, project or section is a quick process but sometimes this process stops or does not respond mainly to problems with the internet connection. Planner 2.6 creates the tasks asynchronously with the possibility of being able to cancel the process at any time.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/AsyncTask.gif" alt="Planner 2.6 Planner Board 2"></p>

<h3 id="filter-your-projects-by-labels">Filter your projects by labels</h3>
<p>It is now possible to filter the tasks within a project by labels.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/filter-labels.gif" alt="Planner 2.6 Planner Board 2"></p>


<p>Labels have been added in the sidebar to make the use of filter by labels much faster.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/label-sidebar.png" alt="Planner 2.6 Planner Board 2"></p>

<h3 id="more-customization">More customization</h3>

<p>It is now possible to sort the position <b>Inbox</b>, <b>Today</b> and <b>Upcoming</b> by 
Drag &amp; Drop.</p>

<p><img src="https://useplanner.com/images/blogs/2020-12-24-merry-christmas-everyone-planner-2-6-is-here/ActionMoved.png" alt="Planner 2.6 Planner Board 2"></p>

<h3 id="code-cleanup--performance-improvement">Code cleanup &amp; performance improvement</h3>
<p>A giant code cleanup was done and resource usage was improved. Now Planner is faster and works much better.</p>

<p>Planner 2.6 is available for download now on <a href="https://appcenter.elementary.io/com.github.alainm23.planner/">AppCenter</a> and <a href="https://flathub.org/apps/details/com.github.alainm23.planner">Flathub</a>. We hope you’ll enjoy these improvements.</p>

<p>Planner is being developed with ❤️ and passion for Open Source. However, if you like Planner and want to support its development, consider donating to via:</p>
<ul>
  <li><a href="https://www.patreon.com/alainm23">Patreon</a></li>
  <li><a href="https://www.paypal.me/alainm23">PayPal</a></li>
</ul>



		<!-- <div class="author">
			
			
			<div class="square-image"><img src="https://avatars0.githubusercontent.com/u/33765137?v=4
" alt="Alain"/></div>
			<p class="blurb">Alain likes to discover and create new things.</p>
		</div> -->

		

		
			
			
			
		
	</div></div>]]>
            </description>
            <link>https://useplanner.com/release/2020/12/24/merry-christmas-everyone-planner-2-6-is-here/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25535822</guid>
            <pubDate>Fri, 25 Dec 2020 11:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Outer Orbit – old school Spacewar-for-one game]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25535626">thread link</a>) | @masswerk
<br/>
December 25, 2020 | https://www.masswerk.at/outerorbit/ | <a href="https://web.archive.org/web/*/https://www.masswerk.at/outerorbit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="about">
		<p><strong>About Outer Orbit</strong><br>
		<em>Outer Orbit</em> is an attempt to create a “Spacewar!-for-one” as a tribute to the line of heritage of digital video games. It combines elements of the most classic shooter games, <em>Spacewar!</em> (1961/62) <a href="https://www.masswerk.at/spacewar/">[1]</a>, the first known video game on a digital computer, <em>Computer Space</em> (1971) <a href="https://www.masswerk.at/rc2017/04/02.html" target="_blank">[2]</a> <a href="https://www.masswerk.at/icss/" target="_blank">[3]</a> <a href="https://en.wikipedia.org/wiki/Computer_Space" target="_blank" rel="noopener">[4]</a>, the first coin-operated digital video game, and <em>Asteroids</em> (1979) <a href="https://en.wikipedia.org/wiki/Asteroids_(video_game)" target="_blank" rel="noopener">[5]</a>:</p>
		<ul>
			<li>From <em>“<a href="https://www.masswerk.at/spacewar/" target="_blank">Spacewar!</a>”</em> it borrows the comic book spaceship, the central star, gravity and orbital mechanics,</li>
			<li>from <em>“<a href="https://www.masswerk.at/icss/" target="_blank">Computer Space</a>”</em> the game mechanics of the saucer opponents and the time-based gameplay,</li>
			<li>from <em>“<a href="https://en.wikipedia.org/wiki/Asteroids_(video_game)" target="_blank" rel="noopener">Asteroids</a>”,</em> well, the asteroids, which serve here just as additional obstacles to make the game a bit trickier.</li>
		</ul>
		<p>Enjoy!</p>
		<p><strong>Note:</strong> A wave has a fixed duration of 80 seconds. You may progress to the next wave/level, if you manage to outscore the saucers in a given level, i.e. shoot the saucers more often than your ship crashes, by this maintaining a positive balance. Mind that the balance is reset to zero at the start of each level.</p>
		<p><strong>Tip:</strong> Like in <em>Spacewar!</em> enter an orbit around the gravitational star by aligning your spaceship perpendicular to its center and firing your thruster for two or three seconds. — Do not attempt to destroy asteroids, dodge them.</p>
		<p><strong>Implementation Notes:</strong> The sound-scape is for the most a homage to <em>Computer Space,</em> less the background hum. The display font is based on definitions for a PDP-1 font renderer (early 1960s) and implemented in software. In order to bring the iterative machanics of a gravity based game to the modern age of asynchronous rendering, the game is computed internally in fixed time slices of an 1/100<sup>th</sup> of a second and the display rendered on demand.</p>
		<p><strong>Setting an Initial Level:</strong> Experienced players may want to select the initial level by specifying a wave as an URL-parameter, as in <a href="https://www.masswerk.at/outerorbit/?wave=30">https://www.masswerk.at/outerorbit/?wave=30</a> for a game starting at wave #30.</p>
		<p>© 2017–2020 Norbert Landsteiner, <a href="https://www.masswerk.at/">www.masswerk.at</a>.</p>
	</div></div>]]>
            </description>
            <link>https://www.masswerk.at/outerorbit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25535626</guid>
            <pubDate>Fri, 25 Dec 2020 10:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trading Time for Money]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25535366">thread link</a>) | @nicbou
<br/>
December 25, 2020 | https://nicolasbouliane.com/blog/trading-time-for-money | <a href="https://web.archive.org/web/*/https://nicolasbouliane.com/blog/trading-time-for-money">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
        <article>
            <p>
                Posted on <time datetime="2020-12-24 09:53:00">December 24, 2020</time>
            </p>
                        <p>According to conventional wisdom, if you earn 31€/hour, and a task costs less than that to outsource, then you should always pay someone else to do it. For example, if your cleaning person charges 15€/hour, you save 16€ for every hour you spend at work instead of cleaning your house.</p>
<p>I've encountered this advice quite often, particularly among the wealthier, productivity porn-loving, <em>4-Hour Work Week</em>-thumping entrepreneur crowd.<br></p>
<p>I don't think that advice is quite right.</p>
<h2>Your time is worth less than you think</h2>
<p>There is a hefty tax on converting time to money. In Germany, if you earned the average income (42 421€ per year)<sup><a href="https://www.statista.com/statistics/416207/average-annual-wages-germany-y-on-y-in-euros/">1</a></sup>, you'd lose roughly a quarter of it to income tax<sup><a href="http://www.parmentier.de/steuer/index.php?site=einkommensteuerrechnerjava">1</a></sup>. Your 31€/hour salary<sup><a href="https://www.statista.com/statistics/416207/average-annual-wages-germany-y-on-y-in-euros/">1</a>, <a href="https://clockify.me/working-hours">2</a></sup> is actually worth 24€/hour after taxes.</p>
<p>But there is more to account for: health insurance (7.3%), unemployment insurance (1.25%), public pension (9.3%) and nursing care insurance (1.775%)<sup><a href="http://www.parmentier.de/steuer/index.php?site=lohnsteuerrechnerjava">1</a></sup> are also deducted from your salary. When it's all said and done, you take home about 20€/hour. If you also pay church tax and get the most expensive health insurance, you keep 19€/hour.</p>
<p>So again, if you earn the average 31€/hour, and work the average 1386 hours per year, you save about 4€ per hour - not 16€ - by hiring a cleaning person who charges half your rate.</p>
<p>Taxes aren't the only thing that whittle away your disposable income. You also have some unavoidable expenses, namely rent, groceries and utilities. That's 550€, 150€ and 100€ per month for a single, thrifty Berliner. That's 35% of your take-home salary, so you're left with 12.50€/hour in disposable income. At this point, I'm including decimals, because they start to matter.</p>
<p>In other words, you must sell 72 minutes of your life to buy 60 minutes of your cleaning person's life, even though you earn twice as much.</p>
<p>Here's a recap for the mathematically inclined:</p>
<pre>hourly_disposable income = (
    (gross_income - income_tax)
    - health_insurance
    - unemployment_insurance
    - pension_insurance
    - nursing_care_insurance
    - (rent + groceries + utilities) * 12
) / hours_worked_per_year</pre>
<p>Keep in mind that this describes the reality in Germany, where people work much less, but pay higher taxes. You will get wildly different results in your own country.</p>
<h2>Outsourcing costs more than you think</h2>
<p>Eating out is often used as an example of trading money for time. It's faster than cooking your own food: no shopping, no cooking, no cleaning.<br></p>
<p>In Berlin, you can get a square meal for 10€. A croissant, a coffee and two square meals would set you back 20€ a day. By comparison, my grocery bill is 5€ a day. That's a 450€/month difference, or 37.5 hours of your time (see above), but you'd probably spend that much time between the supermarket and the kitchen anyway.<br></p>
<p>However, getting to&nbsp;the restaurant, ordering, waiting for your food, then waiting for the bill takes time too. Personally, I&nbsp;find cooking every other day more convenient  than eating out twice a day. Eating out only makes sense when I'm too tired to cook.<br></p>
<p>This also applies to hiring professionals. You still need time to find one and to work with their schedule. I can change the oil or the brakes on my motorcycle in about 30 minutes. It takes me about as long to drop my bike off at the dealership, but I&nbsp;have to do it during office hours, and wait a few days to get it back.<br></p>
<p>In short, outsourcing your work does not always make life easier. It can lighten your mental load, but so does working less by having lower expenses.<br> </p>
<h2>Time is not a liquid asset</h2>
<p>In practice, you don't get to choose how much of your time you sell.&nbsp;If your expenses are covered, you just can't stop going to work. If you need more money, you could work more, but rarely on your own terms, just when you need to. You couldn't sell an extra 2 hours of programming on a Thursday night, because you have nothing else going on.&nbsp; There's also a limit on how much time you can sustainably sell, regardless of demand - about 60 hours a week.<br></p>
<p>You can't choose which time you sell either. Most employers will only buy your office hours. You can't decide to work night shifts, or to work 80 hour weeks in the winter, then take the summer off. You can't even decide where to allocate the time you <em>didn't</em> sell. Your employer usually decides when you take your lunch breaks, and when you can use your holidays. If you're on call, even your free time isn't quite yours.</p>
<p>In other words, you don't really trade more time at the office for less time cleaning your house. You're stuck at the office for 40 hours a week regardless, so you're just using some of your fixed budget. However, if you <em>don't</em> hire a cleaning person, and you don't spend your money, then you can buy some&nbsp;of your time back later, either as a gap year, or as an early retirement.</p>
<p>As a freelancer, you have much more control over what time you sell, and in which amount. Nonetheless, you are still bound to standard contract lengths, to the limits of your body, and to cyclical demand in your industry. A freelance accountant likely won't take time off during tax season. A freelance developer will mostly find 3 to 6 month contracts.<br></p>
<p>Put shortly, time is not a liquid asset. You can't easily  sell more or less of it according to your needs.</p>
<h2>Time does not have a fixed value</h2>
<p>Let's pretend that your boss lets you work for as long as you need, whenever you need to. You could spend an extra hour at the office, and pay someone to save you an hour of cleaning.</p>
<p>I'd make that deal. Swearing at my computer brings me joy, but doing the dishes doesn't. I'd gladly trade a few hours of programming for a few hours of cleaning.</p>
<figure><img src="https://nicolasbouliane.com/images/_fullWidth2x/good-time.jpg" alt=""><figcaption>My definition of a good time</figcaption></figure>
<p>After 30 hours a week, I'd start to value my time at the office a bit more. I'd rather spend that time at home, sipping a beer on my balcony with a pie in the oven, so I&nbsp;wouldn't be so keen to sell it.</p>
<p>After 50 hours, I'd be selling my time at a much higher price. There's a point where work takes a toll on your body, and seeps into other aspects of your life.&nbsp;By then, menial work feels like a release, rather than a chore.</p>
<p>Unless you&nbsp;<em>really</em> like your job, there comes a point where you'd rather do something else, even if has a lower market value than your profession.<br></p>
<h2>The hidden benefits of doing it yourself</h2>
<p>The most understated benefit of doing things yourself is the skills and the tools you acquire along the way. Your cooking gets better and more diversified with every meal you cook. Bike repairs get cheaper and easier with every attempt. Those skills stay with you, and over time, the benefits compound. You can tackle bigger and bigger projects, and the results look better and better.</p>
<figure><img src="https://nicolasbouliane.com/images/_fullWidth2x/level-up.jpg" alt=""></figure>
<p>Outsourcing, on the other hand, doesn't get better and cheaper. It either gets better and more expensive, or cheaper and worse. This ties your quality of life to a single variable: your income. Your lifestyle is much more reliant on your ability to stay employed, because it's the only thing you can do.<br></p>
<p>Beyond that, doing things yourself is immensely rewarding. Wrenching on your own motorcycle feels good. Delighting your guests with a home-cooked meal feels good. Using shelves you built yourself feels good. These are direct products of your hard work, and symbols of the control you have over your environment.</p>
<p>I'd also argue that it gives you a greater appreciation for the world you live in. It allows you to see things beyond the surface. Musicians appreciate music on a different level,
 and the same can be said for gardeners, machinists, architects and 
every other kind of enthusiast. My fledgling interest in gardening quite literally made me see the forest for the trees.<br></p>
<p>Paying someone else to do it robs you of this joy. Climbing through the career ladder provides its own rewards, but those always felt too abstract to me. If I  indirectly make my company a little leaner, I&nbsp;get 4% more disposable income. Big whoop.</p>
<h2>Caveats</h2>
<p>Some tasks don't develop useful skills. They don't get easier, cheaper or more enjoyable with time. Chores are chores, and some work is just plain tedious. No matter how good I&nbsp;get at painting walls, I still hate it with a passion.&nbsp;My father fixed cars his entire life, and he won't change his oil in the winter, when the car is caked in&nbsp;slush.</p>
<p>Life is short, and the 40 hour work week isn't going anywhere, so it's okay to spare your free time for things you enjoy. That's worth paying a premium for.</p>
<p>Even if you enjoy doing something, the timing isn't always right.&nbsp;I found that my motorcycle's front rim was bent just before leaving for a 3 month trip. I already had a lot on my plate with work and trip preparations, so I paid a mechanic to do it. Outsourcing lets you solve multiple problems in parallel.</p>
<p>In some cases, the upfront cost of doing things yourself is just too high. I won't resurface my motorcycle's cylinder head at home, because the tools cost more than my net worth, and highly trained machinists will do it for 100€.&nbsp;Sometimes, it's better to let economies of scale do their thing.</p>
<p>In other cases, the running costs are too high. All those things you maintain will chip away at your free time. In aggregate, they can swallow your evenings. For example, think twice about running your own server to save a few euros per month. These needy buggers tend to require your attention at the most inopportune times. Outsourcing means someone else is taking care of it, and invoicing you once a month.</p>
<p>Sometimes, the risk isn't worth the potential savings. It's important to learn how to do things yourself, but don't bite off more than you can chew. Don't cause hundreds of euros worth of damage to save a few euros. Hire a professional, and let them do their job.&nbsp;If they cock up, <em>they</em> are liable to fix the mess, not you.</p>
<h2>Conclusion</h2>
<p>Yes, outsourcing has its time and place, but it's more expensive than it appears. Sometimes, it's better to do things yourself, and acquire useful skills …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nicolasbouliane.com/blog/trading-time-for-money">https://nicolasbouliane.com/blog/trading-time-for-money</a></em></p>]]>
            </description>
            <link>https://nicolasbouliane.com/blog/trading-time-for-money</link>
            <guid isPermaLink="false">hacker-news-small-sites-25535366</guid>
            <pubDate>Fri, 25 Dec 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The impact of Apple Silicon Macs on Broadway]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 279 (<a href="https://news.ycombinator.com/item?id=25534863">thread link</a>) | @da02
<br/>
December 24, 2020 | https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/ | <a href="https://web.archive.org/web/*/https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"><main><article role="article"><div><p>In a previous life, I was an electronic music designer working on Broadway shows in New York City. Broadway shows look glamorous and expensive on the outside, but it’s often quite the opposite on the inside –&nbsp;at least for the music department. One of the toughest parts of my job as an electronic music designer was to find the best performance-to-cost ratio for computer rigs powering keyboards, guitars, playback tracks, and more.</p><p>Over the past decade, Broadway has replaced large sections of traditional orchestras with synthesizers, playback systems, and electronic drum pads. I’m not in support of that, but that’s a story for another day. The point here is that Broadway’s reliance on computer-driven rigs has increased, while the typical budget required to build high-end stable rigs hasn’t increased at the same rate.</p><p>Some shows I’ve worked at set aside a $10,000-$12,000 budget for two keyboard rigs. That sounds like a lot of money at first, but it’s not. For live shows, it’s usually best to have a 1:1 backup in case the main rig fails. That fact alone means you have to design a rig that fits within 50% of the proposed budget. Furthermore, a high-quality keyboard controller alone is $1,500-2,000 –&nbsp;so that means there’s $3,000 left for a computer and everything else.</p><p>Due to budget constraints, many shows end up using Mac minis. Historically speaking, the Mac mini’s computing power has been a bottleneck for electronic music designers on Broadway. In a perfect world, we’d all like to use the best-sounding sample libraries for our work, but that was never feasible with the Mac mini. Thus, the compromise was always to reduce sound quality to fit within the Mac mini’s compute constraints.</p><p>Apple Silicon changes everything for Broadway electronic music designers. The new M1 Mac mini is capable of running high-end sample libraries and virtual instruments in a stable manner, and it’s only going to get better with M2, M3, and M4-series chips in the future. The performance per dollar characteristics of Apple Silicon machines are going to have a huge impact on Broadway’s sound, and I’m very excited to see, or hear, what happens.</p></div></article></main></div></div>]]>
            </description>
            <link>https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25534863</guid>
            <pubDate>Fri, 25 Dec 2020 07:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning to Play the Chaos Game]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25534794">thread link</a>) | @hardmath123
<br/>
December 24, 2020 | https://hardmath123.github.io/chaos-game-fractal-foliage.html | <a href="https://web.archive.org/web/*/https://hardmath123.github.io/chaos-game-fractal-foliage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="postcontent">
            <section>
                
                <center><em><p>I, Thomasina Coverly, have found a truly wonderful method whereby all the forms of nature must give up their numerical secrets and draw themselves through number alone…</p>
</em></center>
                <h4>Friday, December 25, 2020 · 7 min read</h4>
<p>It’s Christmastime again! Shall we talk about trees? This post is about my new
holiday hobby: hallucinating tree-shaped fractals using our old friend,
gradient descent.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/tree-building.gif" alt="Christmas tree"></p>
<hr>
<p>But — let me start at the beginning. For a variety of reasons, the cover
image of Douglas Hofstadter’s <a href="https://en.wikipedia.org/wiki/I_Am_a_Strange_Loop"><em>I am a Strange
Loop</em></a> has been on my mind
this month. I have been thinking a lot about this wonderful image created by
pointing a camera at a projector that displays what the camera is seeing. In
modern terms: what happens if you screen-share the screen sharing window? This
happens:</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/strange-loop.png" alt="from the cover of the book"></p>
<p>Such “feedback loop” recursions often rapidly converge to breathtaking
fixed-points. The NYC MoMath even has an <a href="https://momath.org/25-feedback-fractals-1/">art
installation</a> that lets you play
with a camera-and-projector setup to make <a href="https://twitter.com/momath1/status/824740594564075520">wonderful
patterns</a>.</p>
<p>As you can imagine, there is a mathematical theory here. At risk of ruining the
mystery, I will tell you about it, though without writing any equations. :-)
The theory is the theory of <a href="https://en.wikipedia.org/wiki/Iterated_function_system">Iterated Function
Systems</a>, which is
almost exactly what it sounds like. Start with a set of affine functions
(affine because that’s what camera-projector-systems do) and repeatedly apply
them to a set of points, taking the union at each step. Regardless of where you
start, you will soon end up with a fractal structure which is the fixed point
of the system. Why fractal? —because the self-similarity comes from the
infinitely-nested composition of the affine functions.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/Ifs-construction.png" alt="from Wikipedia"></p>
<p>There are theorems that ensure convergence towards and uniqueness of this fixed
point in the limit, but… it’s believable enough, don’t you think? Following
your intuition, you can build Sierpinski Triangles and <a href="https://en.wikipedia.org/wiki/Barnsley_fern">Barnsley
Ferns</a> and all sorts of other
beautiful structures using an IFS. I refer you to Section 8.2 of <a href="http://algorithmicbotany.org/papers/#abop"><em>The
Algorithmic Beauty of Plants</em> by Prusinkiewicz and Lindenmayer (yes, <em>that</em>
Lindenmayer)</a> for more botanical
connections.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/Fractal_fern_explained.png" alt="from Wikipedia"></p>
<hr>
<p>Now here is the question that has been on my mind: if I give you a picture of a
fractal-fern, can you give me a set of affine functions whose fixed point is
that fern? This is the <a href="https://en.wikipedia.org/wiki/Iterated_function_system#The_inverse_problem"><em>inverse
problem</em></a>
for IFSes. According to Wikipedia, this problem has real-world applications in
image compression, but it is <em>hard</em> to do in general.</p>
<p>Hmm. Interesting. Can our favorite tool, gradient descent, come to the rescue?
At least in an approximate sense? Recall that a two-dimensional affine function
is really just a 3x3 matrix (with 6 free parameters) that encodes the details
of the transformation. If we could easily compute images of IFS fixed points
from a set of matrices, then perhaps we could try to optimize the parameters of
these matrices to make the fixed point look the way we want it to.</p>
<p>The challenge, of course, is efficiently <em>finding</em> the fixed point —
repeatedly rasterizing and compositing affine transformations on images sounds
expensive — and doing so differentiably sounds like a scalability nightmare!
But there is a wonderful solution to this problem, which is to play the
so-called “<a href="https://en.wikipedia.org/wiki/Chaos_game">chaos game</a>.” Instead of
<em>densely</em> applying all the functions to all the points on the plane, you can
<em>sparsely</em> approximate the fixed point as follows: Start with a point — any
point! — and <em>randomly</em> select one of the affine functions of the IFS and
apply it to the point. Repeat this process with the new point. It turns out
that in the limit, the “trail” left behind by this wandering point converges to
the fixed point of the IFS. (This, too, is a theorem, but again I think it is
believable enough that I will not demand a proof.) This is what the “chaos
game” looks like for the Sierpinski triangle; notice how the salt-and-pepper
spattering of points soon converges boldly into the fractal we know and love
(it’s an animation — stare for a few seconds).</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/Sierpinski_chaos_animated.gif" alt="from Wikipedia"></p>
<p>So here is the plan: we start with a point, and play the chaos game with our
current IFS matrices to obtain a <em>point cloud</em> that stochastically approximates
the fixed-point. Then, we compare this <em>point cloud</em> to our target fern-image
to obtain a “loss.” Finally, we update our IFS matrix parameters to minimize
this loss, until at last the fixed-point converges to the target image. It’s
just “machine learning,” really: we’re learning to play the chaos game!</p>
<p>Here is an outline of the algorithm (with some details elided):</p>
<pre><code># initialize IFS
F = [random_3x3_affine() for _ in range(4)]
o = torch.optim.Adam(F, lr=0.0001)

for step in range(100_000):
    o.zero_grad()
    # start at origin
    v = torch.tensor([0., 0., 1.])

    # play the chaos game once
    trace = []
    for _ in range(200):
          # applying an affine function is just
        # a matrix multiplication!
        v = torch.matmul(random.choice(F), v)
        trace.append(v)

    # treat the trace as a point cloud
    loss = compare(target_image, trace)

    # update parameters
    loss.backward()
    o.step()
</code></pre>
<p>Ah! Actually, there is <em>one</em> detail that I <em>should</em> explain: how do you compare
a point cloud and an image? My idea is to convert the target image to a
<em>second</em> point cloud by uniformly sampling points from it, for example by
rejection-sampling. Then you can compare the two point clouds by the so-called
“chamfer distance,” which is the mean distance from each point to its nearest
neighbor in the opposite point cloud. This is quadratic-time to compute, and
the most expensive part of the whole operation, but with ~100 points in each
set it is quite doable.</p>
<blockquote>
<p>A pedagogical aside: notice that the “trick” here is really a <em>change in
representation.</em> This optimization problem is easier to solve on point clouds
than on raster images! An important lesson, that applies across the
ML-for-graphics domain… and more broadly to all differentiable programming
enterprises.</p>
</blockquote>
<hr>
<p>Remarkably, this zany scheme works quite well! Let’s try it with a heart. (A
heart, because it’s an easy low-entropy shape, but also because it felt
symbolically appropriate in relation to Hofstadter’s broader philosophical
project of souls-within-souls-within-souls.)</p>
<p>When we initialize the system with 4 random affine transformations, the trail
left behind by the chaos game is very unimpressive. The sparsity is because I
simulate only 200 steps of the chaos game for each step of gradient descent —
there’s a tradeoff between noise and computation time, of course, as there is
with any form of SGD.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/heart-samples-early.png" alt="chaos game on a heart"></p>
<p>Okay. Time to optimize! Here is what it looks like after 100K steps of
optimization with an Adam optimizer (that’s about 40 minutes of wall-time
computation on my old MacBook). It looks pretty good, don’t you think? The
chamfer distance scheme works!</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/heart-samples.png" alt="chaos game on a heart"></p>
<p>Now we can export the four affine matrices out from PyTorch and work out the
“true” fixed point with a more expensive offline computation (for example, by
simulating a few <em>million</em> steps of the chaos game). It looks like this — not
perfect, and indeed quite crayon-scribble-ey, but clearly <em>something</em>
interesting has happened, and the result is convincingly heartlike.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/heart-fractal.png" alt="extended chaos game on a heart"></p>
<p>Where is the fractal structure hidden in this heart? This needs some
vizualization tooling to see clearly. After a bit of JS-canvas-hacking: here is
a GIF of the heart that reveals its fixed-point structure.
Hearts-in-hearts-in-hearts!</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/heart.gif" alt="Heart"></p>
<p>I will admit to blinking a few times when I first saw this animation play out
in full — I did <em>not</em> expect it to work, and even now I find myself marveling
at this creation? discovery? of a heart encoded in 24 numbers.</p>
<hr>
<p>But it still doesn’t look <em>quite right</em> — the fractalness isn’t <em>obvious</em>.
How come? It’s because our affine transformations stretch and squash the heart
into almost unrecognizable blobs. A final, natural improvement is to force our
affine transformations to be <em>rigid</em>, so that there isn’t any squishing or
skewing in the fractal. This is actually not too bad to implement: the solution
to problems of constraint are typically reparametrizations, and indeed in this
case we can simply reparametrize the matrices in terms of a rotation, an
(isotropic) scale, and a translation. Now we’re down from 6 parameters per
matrix to just 4 — even more magical! The result is a much more “obviously”
fractal-ey fixed point, simply because your eye can more easily pick out the
structural recursion when it is made of rigid motions.</p>
<p>Let’s take it for a — pardon — <em>spin!</em></p>
<p>Since I promised you trees, here is some fractal foliage. The target image was
a picture of a maple leaf! I’d never thought about this before, but indeed a
maple leaf contains within it an echo of the whole tree. (Full disclosure: it
takes a couple of randomized restarts to get a really impressive result — the
low dimensionality of the fractal’s parametrization leads to the same
stuck-in-a-local-optimum woes that differentiable rendering folks face all the
time…)</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/foliage.gif" alt="Leaf"></p>
<p>This one uses just three matrices — experimentally, three matrices tend to be
enough to get really good results, and more just lead to very busy and crowded
fractals. (I don’t know if there is a word for number-of-maps–in-an-IFS, but
let’s call it the IFS’s <em>arity</em>. In this terminology, I like <em>ternary</em> IFSes.)</p>
<p>And finally, since I promised you Christmas trees…</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/christmas-tree.gif" alt="Christmas tree"></p>
<p>This last animation is actually absolutely <em>baffling</em> to me. In part, this is
because of how <em>treelike</em> the fractal turned out — here it is overlayed
against the silhouette I optimized against. Can you imagine this is encoded by
just 12 parameters? Odd.</p>
<p><img src="https://hardmath123.github.io/static/chaos-game/christmas-tree-match.png" alt="Tree vs. silhouette"></p>
<p>But even more bafflingly: the actual geometry of the recursion is <em>nothing</em>
like the tree recursion geometry you and I are used to from CS106! Compare the
GIF above to Barnsley’s Fern: while Barnsley turns each full leaf into two
smaller leaves with “semantic” affine maps, this Christmas tree does all sorts
of <em>bizarre</em> uninterpretable cartwheels and somehow almost magically works
itself out in the end. It is mesmerizing to me, …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hardmath123.github.io/chaos-game-fractal-foliage.html">https://hardmath123.github.io/chaos-game-fractal-foliage.html</a></em></p>]]>
            </description>
            <link>https://hardmath123.github.io/chaos-game-fractal-foliage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25534794</guid>
            <pubDate>Fri, 25 Dec 2020 06:55:23 GMT</pubDate>
        </item>
    </channel>
</rss>
