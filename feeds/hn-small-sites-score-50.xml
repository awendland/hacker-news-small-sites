<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 29 Dec 2020 17:09:15 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 29 Dec 2020 17:09:15 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[HN Readers]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/15-hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/15-hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily – Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper – bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
“Less annoying hacker news” with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd’s daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments – iOS only.<br>
4.8/5.0 – 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link – redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/15-hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -Os -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2-Acre Vertical Farm Run by AI and Robots Out-Produces 720-Acre Flat Farm]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 233 (<a href="https://news.ycombinator.com/item?id=25554941">thread link</a>) | @wrycoder
<br/>
December 27, 2020 | https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/ | <a href="https://web.archive.org/web/*/https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://www.plenty.ag/" target="_blank" rel="noopener">Plenty</a> is an ag-tech startup in San Francisco, co-founded by Nate Storey, that is reinventing farms and farming. Storey, who is also the company’s chief science officer, says the future of farms is vertical and indoors because that way, the food can grow anywhere in the world, year-round; and the future of farms employ robots and AI to continually improve the quality of growth for fruits, vegetables, and herbs. Plenty does all these things and uses 95% less water and 99% less land because of it.</p>
<p>In recent years, farmers on flat farms have been using new tools for making farming better or easier. They’re using drones and robots to improve crop maintenance, while artificial intelligence is also on the rise, with over 1,600 startups and total investments reaching tens of billions of dollars. Plenty is one of those startups. However, flat farms still use a lot of water and land, while a Plenty vertical farm can produce the same quantity of fruits and vegetables as a 720-acre flat farm, but on only 2 acres!</p>
<p>Storey said:</p>
<blockquote><p>Vertical farming exists because we want to grow the world’s capacity for fresh fruits and vegetables, and we know it’s necessary.</p></blockquote>
<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/GO0fRU46ZHc?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<p>Plenty’s climate-controlled indoor farm has rows of plants growing vertically, hung from the ceiling. There are sun-mimicking LED lights shining on them, <a href="https://www.intelligentliving.co/tiny-smart-robots-kill-weeds/">robots</a> that move them around, and artificial intelligence (AI) managing all the variables of water, temperature, and light, and continually learning and optimizing how to grow bigger, faster, better crops. These futuristic features ensure every plant grows perfectly year-round. The conditions are so good that the farm produces 400 times more food per acre than an outdoor flat farm.</p>

<p>Storey said:</p>
<blockquote><p>400X greater yield per acre of ground is not just an incremental improvement, and using almost two orders of magnitude less water is also critical in a time of increasing environmental stress and climate uncertainty. All of these are truly game-changers, but they’re not the only goals.</p></blockquote>
<p>Another perk of vertical farming is locally produced food. The fruits and vegetables aren’t grown 1,000 miles away or more from a city; instead, at a warehouse nearby. Meaning, many transportation miles are eliminated, which is useful for reducing millions of tons of yearly CO2 emissions and prices for consumers. Imported fruits and vegetables are more expensive, so society’s most impoverished are at an extreme nutritional disadvantage. Vertical farms could solve this problem.</p>
<p>Storey said:</p>
<blockquote><p>Supply-chain breakdowns resulting from COVID-19 and natural disruptions like this year’s California wildfires demonstrate the need for a predictable and durable supply of products can only come from vertical farming.</p></blockquote>
<figure id="attachment_39422" aria-describedby="caption-attachment-39422"><img loading="lazy" src="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1" alt="2-Acre Vertical Farm Run By AI And Robots Out-Produces 720-Acre' Flat Farm'" width="1024" height="576" srcset="https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=960%2C540&amp;ssl=1 960w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=711%2C400&amp;ssl=1 711w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?resize=585%2C329&amp;ssl=1 585w, https://i2.wp.com/www.intelligentliving.co/wp-content/uploads/2020/12/Reuters.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption id="caption-attachment-39422">(Credit: Reuters)</figcaption></figure>
<p>Plenty’s farms grow non-GMO crops and don’t use herbicides or pesticides. They recycle all water used, even capturing the evaporated water in the air. The flagship farm in San Francisco is using 100% renewable energy too.</p>
<p>Furthermore, all the packaging is 100% recyclable, made of recycled plastic, and specially designed to keep the food fresh longer to reduce food waste.</p>
<p>Storey told <a href="https://www.forbes.com/sites/johnkoetsier/2020/11/20/this-2-acre-vertical-farm-out-produces-750-acre-flat-farms/" target="_blank" rel="noopener">Forbes</a>:</p>
<blockquote><p>The future will be quite remarkable. And I think the size of the global fresh fruit and vegetable industry will be multiples of what it is today.</p></blockquote>
<p>Plenty has already received $400 million in investment capital from SoftBank, former Google chairman Eric Schmidt, and Amazon’s Jeff Bezos. It’s also struck a deal with Albertsons stores in California to supply 430 stores with fresh produce.</p>
<p>Ideally, the company will branch out, opening vertical farms across the country and beyond. There can never be too many places graced by better food growing with a less environmental cost.</p>
<p>Here’s a <a href="https://anchor.fm/techfirst/episodes/The-future-of-farms-is-vertical-400X-more-yield--95-less-water--99-less-space-emesrq/a-a3sf2o5" target="_blank" rel="noopener">TechFirst podcast</a> about the story behind Plenty:</p>

<p><span><iframe width="1400" height="788" src="https://www.youtube.com/embed/0uXdnjXIGjI?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<!-- AI CONTENT END 2 -->
</div></div>]]>
            </description>
            <link>https://www.intelligentliving.co/vertical-farm-out-produces-flat-farm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554941</guid>
            <pubDate>Sun, 27 Dec 2020 22:47:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperbezier Pen Tool]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25554205">thread link</a>) | @raphlinus
<br/>
December 27, 2020 | https://www.cmyr.net/blog/hyperbezier.html | <a href="https://web.archive.org/web/*/https://www.cmyr.net/blog/hyperbezier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        <h2 id="introduction">Introduction</h2>

<p>This post introduces a new model for a path drawing (pen) tool, with a particular focus on font design.</p>

<p>Although this tool works much like familiar pen tools (which are based on the manipulation of <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve">Bézier curves</a>), it is actually based on a new family of two-control-point curves, which we’ve been calling the <em>hyperbezier</em>.</p>

<p>This work is still in its early stages, and the demo below is quite barebones; my goal here is to get a simple version of this tool into the hands of designers and design-tool makers, so that more people can start to play around and evaluate it.</p>

<h4 id="contents">Contents</h4>



<h3 id="-background--motivation"><a id="background"></a> Background &amp; motivation</h3>

<p>The basis of this tool is a new mathematical model for fitting a curve to a set of points; that work was done earlier in the year by my collaborator <a href="https://raphlinus.github.io/">Raph Levien</a>. For the past year or so Raph has been excitedly talking to me about about things like <em>splines</em> and <em>G2 continuity</em> and the elegance of the <em>Euler spiral</em>, and I have for the most part been smiling politely and nodding. In the last few weeks however I have started trying to implement a simple drawing app around his new model, and the excitement is catching: this new tool feels like the first I have used that is a compelling alternative to traditional Bézier-curve based drawing tools.</p>

<p>It is likely that if you have ever used a computer drawing application then you have, at some point, used a <em>pen tool</em>: a tool that allows you to place a small number of points, which are then connected with a series of curves, the exact curvature being a function of the position of the points.</p>

<p>Tools like this— which take some fixed number of points and calculate a curve based on them— are called <em>splines</em>. If you are curious about the topic (particularly in the context of interactive design tools), a very accessible overview is Raph’s <a href="https://levien.com/phd/thesis.pdf">dissertation</a>; I won’t go into too much detail here, except to say that Raph has been revisiting this subject recently, and the result is the <a href="https://github.com/linebender/spline"><em>hyperbezier spline</em></a>. Like traditional (cubic) Bézier paths, a hyperbezier path is comprised of segments, each defined by two <em>on-curve</em> and two <em>off-curve</em> (or <em>control</em>) points; the curve passes through the two on-curve points, and the curvature itself is determined by the position of the two off-curve points.</p>

<p><img id="simple-cubic" src="https://www.cmyr.net/assets/hyperbez/hyperbez-simple-cubic1.png" alt="A simple cubic Bézier"></p>
<p>A Bézier path, consisting of two segments</p>

<p>If you’re generally curious about Béziers, <a href="https://pomax.github.io/bezierinfo/">A Primer on Béziers Curves</a> is an excellent resource. For our purposes it is enough to note that splines based on direct manipulation of Bézier control points (most pen tools) provide a high degree of control, but are difficult to use well. In particular, it can be tricky to maintain consistent curvature between adjoining segments of a path, which can lead to a ‘lumpy’ look; the following example is  contrived, but in practice consistently getting smooth feeling curves with Béziers is challenging.</p>


<p>A lumpy path. Mouseover to see the filled outline.</p>

<h3 id="-the-hyperbezier"><a id="hyperbezier"></a> The hyperbezier</h3>

<p>The core idea of the hyperbezier is the use of <em>auto-points</em>. These control points are adjusted automatically by the tool in order to maintain a smooth curve between neighbouring curve segments.</p>

<p>Let’s look at an example. With the path below you can drag points around, and double-click points to toggle their type.</p>

<p>The two green squares are <em>corner</em> points; curve segments that join at these points are allowed to change direction sharply. The two blue circles are <em>smooth</em> points; changing the curve on one side of the point can cause changes in the <em>auto</em> points (and hence the curve) on the other side.</p>

<p>The auto-points are indicated with dashed lines and terminating ‘x’s. The manual control points are indicated with solid lines, and terminating ‘o’s.</p>




<h5 id="playing-around">Playing around</h5>
<p>To get a better understanding of the spline’s behaviour, here are some things to try <em>(this requires a mouse)</em>:</p>
<ul>
  <li><em>double-click the bottom point to make it smooth</em>. When this point is smooth, the auto points beside it are adjusted so that the two curve segments join smoothly.</li>
  <li><a href="#" onclick="reloadHeart();return false;">reset,</a> or double-click the bottom point to turn it back into a corner. Now <em>doubleclick the top-left smooth point</em>. Making the top-left point a corner will replace the curve between them with a straight line. Two adjacent corners with only auto-points between them will always form a straight line, because a line is maximally smooth.
    <ul>
      <li>You should notice two small ‘x’s on this line. <em>Drag one of these auto points somewhere to position it manually</em>. You will notice that the remaining auto-point is repositioned as you drag.</li>
      <li><em>Drag the other auto-point</em>. With both control points positioned manually, and with corners at either end, you have full control of this segment.</li>
    </ul>
  </li>
</ul>

<!--(TK: SIMPLIFY ME, JUST INTRODUCE AUTO POINTS)The principal goal of the hyperbezier is to make it easier to maintain consistent curvature between adjoining segments of a path. This is achieved by letting the designer choose to have certain control points positioned automatically. These *auto-points* are adjusted in response to changes in adjoining segments so as to form a [smooth][smoothness] curve.-->

<!--In addition, on-curve points can be either *smooth* points or *corners*; if a point is smooth (marked by a green circle) then any auto points on either side of that point will be adjusted to maintain curvature with the segment on the other side. If a point is a corner (marked by a blue square) then the segment on one side of the point is not influenced by the curvature on the other side.-->

<!--Moving any on-curve point can cause subtle changes to the position of multiple auto-points; the example below is interactive, and you can drag the various points around, or toggle their type. Notice how the behaviour of the auto points changes if you toggle a nearby on-curve point between smooth and corner;

<iframe class="embedded-toy"
    title="Interactive hyperbezier toy"
    width="400"
    height="400"
    src="https://www.cmyr.net/misc/hyperbez/#AAE=eJxVzL0JgDAUBOCcYO8IjvImsFTQMmIpuEGmcJtARnlDpA0ELpCfq46P42BKZjNGkxWWeMhUddk_argeQWPdbrL6t2f3n-TV2WHdXQNsyEpvEhM=">
</iframe>
<div class = "img-caption">This demo requires a fairly recent browser</div>
-->

<h3 id="-the-toy-pen-tool"><a id="the-toy"></a> The toy pen tool</h3>

<p>If you’re curious to try drawing with this tool, <a href="https://cmyr.net/misc/hyperbez">There is a simple web app available here</a> (and embedded below).</p>




<p>Below are some examples of letterforms I’ve sketched in the process of getting this working. These may offend the actual type designers in the room, but I hope they will be useful illustrations.</p>

<p><a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxlkj3OgUEUhWe-fHqFBSiVSuVdwhuFKBQjQUQk3viPv4y8oqBRKpVKpdISLMESLIG4J8xhmkmenDn33Hvn3-hJma_jhvK6pSJ_H-rbStNdsQEWiP2E8GWhONsnHFhb-6YZ83WkrjIXhwnMCKVK5BktFd-aYsJgCXCV1Nc1gnU42ApqxhGwaxC-o6S0gLWXK3Dc0zvnYTqi19mB4vyMsEfTY0_YYGTHJeE0kkVrwjG8y1s2KSo-sfrWQuCERmeqivecxNUU3-c8jFixm_L8Pzu09veP4dEhCTf8_BZqyTF3aOq8IVzAhs-sDqyNtRJWfQBl00gu" onclick="return reloadMain(event, 'g');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-g-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0TsKwkAQBuDZWGiZRrEKuYB9OucGRmJhlzQmNiq-QVCCBLFQsLbKUXKUHMDC0lJkJji7ZJssH39mZncbYKyOCUWEtBmhJXhKijEqVZnLOM4Q_jgh7F4Ewpwwugp8rAk9TjqvIHxaK-z1B05bq1kuKZnvBdoHQnchG5240VYmK8xQiTPlXLV1R_gx5SMu-7nRF_wzbexMHN1jdGUf_8i_JAIL7lLsahBibaL3hjmgiYxBcail0xlXDrV0mRCnelq8q7gu1QSxvvatM50=" onclick="return reloadMain(event, 'h');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-h-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxd0rEKwjAQBuCkk2PHjn2EPkJeQQQpqNCCYEWQIiJ0KFTbKuri6NhH6CPkERwdHR0zOgq5K_b3liMfuUtyxBEUnviLYqxsNpVyftrErAclLUu79JfEjz3laE35VijRq25T4qSrpjA1cYj8ZDYZsF5x7xzY3RD7C-CgJNYz4OjMPEe-MofA9wtxMQL-dLuHwIpZxDAjl49UPCtzohykMCOdc_UU38HPe22BQ76Z2uHojsReCdxmxO8aL5wQu7hbT7hJBdxExANs0vsvUgqMLzuHP6M=" onclick="return reloadMain(event, 's');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-s-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJx1kquOAkEQRXs2K1auXNnrECv3A8pssjggEAgKSEgIgWQAA8EM4TEISHj8AgI5EjkSySfwCUgkj6qmq0jTpjInt27Vne539ep8PwMowL3qCrxZGuSRxkXwPANLdYSQAo9pdROxyjCtgccaKKY99hAHabLAhv8xWVSpi77jhuiGOeG0WCBaIfa7bIENwcNYaEdrxF-hwDPCUSgGJhZO_Ev4U5oklnbkY48fA_si8XaKWCWx6gnWoMV6PybODKfQOf5MeHetDwt_YCHTdgk__QYYOhKkhs4EQRux-qNKN659Nv52gbezlwn8tnO8sYx4ApWzkGnjrNOiVHYkMFB3ZFr79K2WzgVbDlNT" onclick="return reloadMain(event, 'm');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-m-small-fill.png"></a>
<a href="https://www.cmyr.net/misc/hyperbez/#AAE=eJxt0b0OgjAQB_CrA2FkMXH0EXyEDg5OBI1x0YGZOIBGIxETjHysPgKTs4s7j8BkHImLr-Fwld6BXUh-XP-9a3uAy4DWKj2J36UUHdtLaNDyGxQ9vd85Ihdrxr6vY8Wfs0D0od3JDP_CXHcCG20k3Twr9hhXO2R5kEAYYuR7xKqlCjFTxq8EubqwkEmKPEgYXyNkJ_uFPN_GOLiFEqLis32cWDYEWO2G5FZqr0HooMWbG6qAIiO1I4VWTlLBVtPlpDK29XaSWq7UbCl9LIW1y0eYIscLHkEeT0V8Ab6RQUE=" onclick="return reloadMain(event, 'r');"><img src="https://www.cmyr.net/assets/hyperbez/hyper-r-small-fill.png"></a></p>
<p>Some example paths, drawn in the tool.</p>

<!--. This is very much a demo; the idea is to explore the interaction model, and to get a sense for how it feels to draw with the tool, compared to the standard Bézier curves used in most pen tools. Spoiler: I think it feels *really good*. You [can play around with it yourself][hypertoy]; it is pretty rough around the edges, but it works.-->

<h4 id="-using-the-toy-pen-tool"><a id="toy-guide"></a> Using the toy pen tool</h4>

<p>The toy is very rough: you have a select and a pen tool, but there are no rulers or measurement tools, no transforms, no ability to select multiple points. The pen works much like the familiar Bézier pen:</p>

<p>General:</p>

<ul>
  <li><code>V</code> key sets selection (arrow) tool, <code>P</code> key sets pen tool</li>
  <li>holding the space bar hides UI and shows filled path</li>
  <li>the current drawing is stored as part of the URL; copy this somewhere to “save”</li>
</ul>

<p>Pen tool:</p>

<ul>
  <li>click to add a line segment ending in a corner point</li>
  <li>alt + click to add an automatic curve segment ending in a smooth point</li>
  <li>click + drag to add a curve segment ending in a smooth point, with a manual control point</li>
  <li>click on a line segment to insert a point there; alt makes it a smooth point</li>
  <li>alt + click on any existing point to toggle the type of that point</li>
</ul>

<p>Select tool:</p>

<ul>
  <li>drag a control auto-point to move it, converting it to a manual point if necessary</li>
  <li>double-click will toggle an on-curve point between smooth and corner</li>
  <li>alt + click on a line segment to add two auto points</li>
  <li>deleting an off-curve point makes that curve segment into a line segment</li>
  <li>arrow keys nudge the current selection by 1 px; adding shift makes it 10px, and ctrl/cmd makes it 100px.</li>
  <li>shift + any of the above moves all of the points in the current outline (I’m sorry)</li>
</ul>

<h3 id="-next-steps"><a id="next-steps"></a> Next steps</h3>

<p>The code for the spline, including the demo, is <a href="https://github.com/linebender/spline">open source and available on github</a>.</p>

<p>The intent of this demo is twofold: firstly to test out how the curve feels to use, and to start playing around with the UX of the pen tool, and secondly to share this research with the broader community of designers and design-tool creators. Although this work is quite rough, my personal feeling is that this spline shows tremendous promise. Anecdotally, as a mere casual user of design tools, I find it <em>significantly</em> easier to make good looking curves with the hyperbezier than I do with traditional Bézier pen tools.</p>

<p>Perhaps the biggest question will be figuring out the best interaction model: what set of mouse clicks, key presses and modifiers the user issues in order to control the state of the points. This has been a challenge for other new splines; the interaction model we use with Béziers is <a href="https://youtu.be/sT8Y7o-zsVw?t=68">familiar and long-established</a>, and people (especially graphic designers) are deeply comfortable with it. The interaction model used here for the hyperbezier is intentionally designed to feel similar to these existing tools, but other interaction models may be worth exploring.</p>

<p>In the coming weeks I hope to integrating the spline into <a href="https://github.com/linebender/runebender">Runebender</a>, a font editor, which will provide a much richer editing experience and will let us better explore how well the spline is suited to real-world use. In addition, Raph intends to do a more detailed writeup of the spline itself and the associated math, which derives both from the earlier Spiro spline and the classic model of elastica under tension.</p>

<p>If you’re curious about the spline, there are more details in the <a href="https://github.com/linebender/spline">github repo</a>; if you have questions you can open an issue there, ask them in our <a href="https://xi.zulipchat.com/">zulip chat server</a> or reach out on <a href="https://twitter.com/cmyr">on twitter</a>.</p>

<h3 id="thanks">Thanks</h3>

<p>This work was funded by <a href="https://fonts.google.com/about">Google Fonts</a>.</p>

<!--- this is particularly useful for fonts
* fix bug with click-drag
* rebuild example
* revisit "next steps": we want to encourage other folks to adopt this
* explicitly mention that all of this is open source
-->


      </article>

    </div></div>]]>
            </description>
            <link>https://www.cmyr.net/blog/hyperbezier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25554205</guid>
            <pubDate>Sun, 27 Dec 2020 20:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A first look at Ghidra’s Debugger – Game Boy Advance Edition]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25553105">thread link</a>) | @mr_golyadkin
<br/>
December 27, 2020 | https://wrongbaud.github.io/posts/ghidra-debugger/ | <a href="https://web.archive.org/web/*/https://wrongbaud.github.io/posts/ghidra-debugger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src=""></p><h2 id="overview">Overview</h2><p><a href="https://twitter.com/NSACyber/status/1339652646513291264">Yesterday</a> the NSA Twitter account announced that a new branch of Ghidra has been release with the long-awaited debugging capability. This will allow for single-step debugging of a program within <a href="https://hackaday.io/course/172292-introduction-to-reverse-engineering-with-ghidra">Ghidra</a> through a GDB stub or other various debug mechanisms. To celebrate this (and my being stuck at home quarantining…) I wanted to review how to build this version of Ghidra and give an example of how to use this debugger on a fun target.</p><p>This post will explain the following:</p><ul><li>How to build the latest (or any) version of Ghidra using a <a href="https://github.com/dukebarman/ghidra-builder">Docker Container</a></li><li>How to build the Ghidra Eclipse plugins</li><li>How to build a program <a href="https://github.com/SiD3W4y/GhidraGBA">loader</a> for Ghidra</li><li>Debugging a program with Ghidra using the GDB stub</li><li>Use the debugging capability to help us learn about how passwords are processed for a GBA game</li></ul><p>For this post, we’re going to be taking a look at the Game Boy Advance game Spiderman: Mysterio’s Menace. I’ve been very much inspired by all of the awesome work that <a href="https://youtu.be/VVbRe7wr3G4">stacksmashing and Liveoverflow have been doing regarding these topics</a>. This was a game that I spent a lot of time playing and it’s always fun revisiting childhood favorites from an RE perspective. The ultimate goal is to demonstrate how to properly load this ROM using a custom loader, and connect to an emulator’s GDB stub using Ghidra’s debugging features.</p><p><strong>RE Note/Tangent:</strong> When taking on a new reversing project, it’s important to try to compartmentalize goals and targets. For example, if we said we just want to <em>reverse</em> this game, that opens up endless possibilities. We could reverse engineer the collision detection, how enemy AI works, or how level maps are generated. For this post, we will pick a specific target and take a look at the password mechanism in use by this game.</p><p>I am doing all of this work on an Ubuntu 20.04 machine, with the latest updates.</p><h2 id="building-ghidra">Building Ghidra</h2><p>First things first, this debugger branch has not yet been included in an official release so we’re going to have to build it ourselves. Luckily for us <a href="https://github.com/dukebarman/ghidra-builder">dukebarman</a> has put together a docker container for us to do this, all we need to do is modify the <code>build_ghidra.sh</code> script to checkout the debugger branch, see the following line below:</p><div><p><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>git clone https://github.com/NationalSecurityAgency/ghidra -b debugger
</pre></td></tr></tbody></table></code></p></div><p>We are also going to build the Eclipse development extensions for this version of Ghidra, this will help us later on when we build a loader and write our analysis scripts. To do this we add the following line to the <code>build_ghidra.sh</code> script:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gradle prepDev
gradle eclipse -PeclipsePDE
</pre></td></tr></tbody></table></code></p></div><p>Next follow the instructions in the <code>README</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>cd ghidra-builder
sudo docker-tpl/build
cd workdir
sudo ../docker-tpl/run ./build_ghidra.sh
</pre></td></tr></tbody></table></code></p></div><p>This will take some time, so maybe go grab a coffee or two and come back to your freshly built Ghidra. The resulting build can be found in <code>workdir/out</code>:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls out/
ghidra_9.3_DEV_20201218_linux64.zip
</pre></td></tr></tbody></table></code></p></div><p>Unzip this file, and you can launch Ghidra via the <code>./ghidraRun</code> script. For this post, I will unzip this into the <code>ghidra-builder/workdir</code> directory because we’re going to be using the docker container to build a Ghidra loader for this version of Ghidra. If you’re following along, your workdir directory should look like this:</p><div><p><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>wrongbaud@wubuntu:~/blog/gba-re-gbd/ghidra-builder/workdir$ ls
build_ghidra.sh  ghidra  ghidra_9.3_DEV out  set_exec_flag.sh
</pre></td></tr></tbody></table></code></p></div><h2 id="building-eclipse-plugins">Building Eclipse Plugins</h2><p>Now that we have a new version of Ghidra built, we also need to build the GhidraDev plugin for Eclipse. The eclipse projects can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code> directory.</p><ol><li>Install <a href="https://www.eclipse.org/downloads/packages/installer">Eclipse</a><ul><li>Select the Java IDE</li></ul></li><li>Install CDT, PyDev, and Plugin Development Environment<ul><li>This can be done from the Eclipse marketplace</li></ul></li><li>Import the GhidraDevFeature and GhidraDevPlugin projects<ul><li>These can be found in the <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev/</code> directory</li><li><code>File</code> -&gt; <code>Import</code> -&gt; <code>General</code> -&gt; <code>Existing Projects into Workspace</code></li><li>Add <code>ghidra-builder/workdir/ghidra/GhidraBuild/EclipsePlugins/GhidraDev</code></li><li>Select “Search for nested projects”</li><li>Import the projects!</li><li><strong>Note:</strong> you may see some build errors when these are imported, you can ignore these as you are just exporting the plugin!</li></ul></li><li>With these projects loaded, we can now <a href="https://github.com/NationalSecurityAgency/ghidra/blob/debugger/GhidraBuild/EclipsePlugins/GhidraDev/GhidraDevPlugin/build_README.txt">export the plugin</a><ul><li><code>File</code> -&gt; <code>Export</code></li><li><code>Plug-in Development</code> -&gt; <code>Deployable Features</code></li><li><code>ghidradev.ghidradev</code></li><li>Select an archive location for the plugin to be exported to</li><li>Click Finish!</li></ul></li></ol><p>Now we have our Ghidra plugin, built for our custom version of Ghidra that we can load via <code>Help</code>-&gt;<code>Install New Software</code>.</p><p>And with that, we have built Ghidra from the <code>debugger</code> branch, and have also built the Eclipse development extensions so we can build plugins for our new version of Ghidra!</p><p><strong>Note:</strong> I just want to take a second to outline just how incredible the <a href="https://github.com/NationalSecurityAgency/ghidra/blob/15c1f43fa51f210836cb451aff587b227dffe0a7/DevGuide.md">help docs</a> are for Ghidra. From the P-Code manuals to the instructions on building and exporting these plugins - the project is very well documented.</p><h2 id="building-the-rom-loader">Building the ROM Loader</h2><p>To properly analyze this ROM in Ghidra, we are going to need to define all of the <a href="https://problemkaputt.de/gbatek.htm#gbamemorymap">memory regions and peripherals</a> for the Game Boy Advance. Luckily for us, <a href="https://github.com/SiD3W4y/GhidraGBA">SiD3W4y</a> on GitHub has already written one.</p><p>If you are a regular reader of this blog, a <a href="https://wrongbaud.github.io/posts/writing-a-ghidra-loader/">ghidra loader</a> may be a familiar subject to you. If not, the purpose of a Ghidra loader is to set up all of the necessary memory regions, identify any debug information or symbols that may be present in the file, and provide as much information as possible about the target file. The loader that was mentioned before outlines all of the basic peripherals of the GBA and is an excellent example loader to work with, let’s start by cloning it into the <code>ghidra-builder/workdir</code> directory. We’re doing this because we’re going to use the same docker container we built Ghidra with to build this loader.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>cd ghidra-builder/workdir
git clone https://github.com/SiD3W4y/GhidraGBA
sudo ../docker-tpl/run /bin/bash
dockerbot@797eb43ce05f:/files/GhidraGBA$ export GHIDRA_INSTALL_DIR=/files/ghidra_9.3_DEV/
dockerbot@797eb43ce05f:/files/GhidraGBA$ gradle
dockerbot@797eb43ce05f:/files/GhidraGBA$ cp dist/ghidra_9.3_DEV_20201218_GhidraGBA.zip ../ghidra_9.3_DEV/Extensions/Ghidra/
dockerbot@797eb43ce05f:/files/GhidraGBA$ exit
exit
</pre></td></tr></tbody></table></code></p></div><p>In case the above steps are confusing, what we are doing is:</p><ol><li>Launching the docker container</li><li>Building the GhidraGBA extension, providing the path to our installation</li><li>Copying it to Ghidra’s extensions directory (so it will show up under the Install Extensions menu)</li><li>Exiting the docker container</li></ol><p>Launch Ghidra via <code>ghidraRun</code> and go to <code>File</code>-&gt; <code>Install Extensions</code>. Select the GhidraGBA loader and click <code>OK</code>. You will need to restart Ghidra for the change to take effect. Now when you load a GBA ROM you should see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png" alt="GBA" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/gba.png"></p><p>After running the auto analysis, Ghidra seems to make a pretty quick sense of the ROM. There are a lot of functions defined and things are looking good. So the next step is to figure out some way to narrow down what we care about in this ROM image, in other words, we need to find our needle in the haystack. Let’s start by examining how the password system works in this game by entering a few passwords.</p><h2 id="analyzing-the-rom">Analyzing the Rom</h2><p>As mentioned before, our goal here is to try to understand the password system in use by this game. If we attempt to enter a password, the following screen is displayed:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png" alt="ROM1" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/rom-1.png"></p><p>Note that we have all of the consonants and no vowels and numbers “0-9”, and our passwords are only 5 characters long. This is a nice starting point for us as reverse engineers. We can use this information to help us narrow down functions of interest. For example- let’s look through the strings in the ROM and see if these values are represented in a string somewhere. If we open the strings window, <code>Window</code> -&gt; <code>Defined Strings</code>, and filter for the first 5 characters available to us as password characters we see the following:</p><p><img data-src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png" alt="" src="https://wrongbaud.github.io/assets/img/ghidra-dbg/strings-password-characters.png"></p><p>So far so good - we only have two instances of this string in use. One is located at <code>0x804c11fc</code> and one at <code>0x84b86f0</code>. Upon examination of the first one, we see that this string gets passed to a function in the subroutine located at <code>0x8003358</code>, see below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>undefined4</span> <span>passwd_1</span><span>(</span><span>int</span> <span>param_1</span><span>,</span><span>int</span> <span>param_2</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>uint</span> <span>uVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>auStack52</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack52</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>param_1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>param_1</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>param_1</span> <span>+</span> <span>0x8c</span><span>);</span>
  <span>uVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>*</span><span>(</span><span>undefined</span> <span>*</span><span>)(</span><span>param_2</span> <span>+</span> <span>iVar1</span><span>)</span> <span>=</span> <span>auStack52</span><span>[</span><span>uVar3</span> <span>&gt;&gt;</span> <span>(</span><span>uVar2</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span><span>];</span>
    <span>uVar2</span> <span>=</span> <span>uVar2</span> <span>+</span> <span>5</span><span>;</span>
    <span>iVar1</span> <span>=</span> <span>iVar1</span> <span>+</span> <span>1</span><span>;</span>
  <span>}</span> <span>while</span> <span>(</span><span>iVar1</span> <span>&lt;</span> <span>5</span><span>);</span>
  <span>return</span> <span>uStack4</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></p></div><p>Notice also the while loop that is looping while a variable is less than five, this is a good indicator that this function might be useful as we know that the password length is 5! Let’s label it <code>passwd_1</code> and move onto the other uses of our character string. The next one that we can see is in the function at <code>0x8002CEC</code>, the decompilation can be seen below:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td><pre><span>undefined8</span> <span>passwd_2</span><span>(</span><span>void</span><span>)</span>

<span>{</span>
  <span>int</span> <span>iVar1</span><span>;</span>
  <span>int</span> <span>iVar2</span><span>;</span>
  <span>uint</span> <span>uVar3</span><span>;</span>
  <span>undefined4</span> <span>in_lr</span><span>;</span>
  <span>undefined</span> <span>local_98</span> <span>[</span><span>5</span><span>];</span>
  <span>undefined</span> <span>local_93</span><span>;</span>
  <span>undefined</span> <span>auStack144</span> <span>[</span><span>36</span><span>];</span>
  <span>undefined</span> <span>auStack108</span> <span>[</span><span>8</span><span>];</span>
  <span>undefined</span> <span>auStack100</span> <span>[</span><span>72</span><span>];</span>
  <span>undefined4</span> <span>uStack4</span><span>;</span>
  
  <span>uStack4</span> <span>=</span> <span>in_lr</span><span>;</span>
  <span>FUN_08000b0c</span><span>(</span><span>0</span><span>,</span><span>1</span><span>,</span><span>0</span><span>,</span><span>0</span><span>);</span>
  <span>DAT_03001fd0</span><span>.</span><span>_0_2_</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>DISPCNT</span> <span>=</span> <span>0x1444</span><span>;</span>
  <span>FUN_0801e330</span><span>(</span><span>&amp;</span><span>DAT_0838277c</span><span>);</span>
  <span>iVar1</span> <span>=</span> <span>DAT_03001fe0</span><span>;</span>
  <span>FUN_080231f4</span><span>(</span><span>auStack144</span><span>,</span><span>"BCDFGHJKLMNPQRSTVWXYZ0123456789-"</span><span>,</span><span>0x21</span><span>);</span>
  <span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>=</span> <span>0</span><span>;</span>
  <span>FUN_080025f8</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002674</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_08002714</span><span>(</span><span>iVar1</span><span>);</span>
  <span>FUN_0800282c</span><span>(</span><span>iVar1</span><span>);</span>
  <span>iVar2</span> <span>=</span> <span>0</span><span>;</span>
  <span>uVar3</span> <span>=</span> <span>0</span><span>;</span>
  <span>do</span> <span>{</span>
    <span>local_98</span><span>[</span><span>iVar2</span><span>]</span> <span>=</span> <span>auStack144</span><span>[</span><span>*</span><span>(</span><span>uint</span> <span>*</span><span>)(</span><span>iVar1</span> <span>+</span> <span>0x8c</span><span>)</span> <span>&gt;&gt;</span> <span>(</span><span>uVar3</span> <span>&amp;</span> <span>0xff</span><span>)</span> <span>&amp;</span> <span>0x1f</span>…</pre></td></tr></tbody></table></code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrongbaud.github.io/posts/ghidra-debugger/">https://wrongbaud.github.io/posts/ghidra-debugger/</a></em></p>]]>
            </description>
            <link>https://wrongbaud.github.io/posts/ghidra-debugger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25553105</guid>
            <pubDate>Sun, 27 Dec 2020 18:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building my own HomeKit Thermostat]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25552889">thread link</a>) | @frenchie4111
<br/>
December 27, 2020 | https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1 | <a href="https://web.archive.org/web/*/https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_area">
    <div>
        
            <h2 id="post_title">Building my own HomeKit Thermostat</h2>
        

        <p>Iâ€™m pretty obsessed with controlling most of the electronics in my house from my
phone. One of the last remaining devices was the thermostat. I donâ€™t want a Nest
because it doesnâ€™t work with HomeKit, and I canâ€™t use an EcoBee because I donâ€™t
have a neutral wire. So I resolved to build my own.</p>

<p>If you are building your own thermostat, or any hardware really, and want some
help or just want to show it off, feel free to shoot me an email at mdl0394@gmail.com. 
Also I plan to continue to expand this project to have a screen and some buttons,
if you want to hear about that signup to my email list and Iâ€™ll let you know when
I do it.</p>



<h2 id="figuring-out-hot-to-turn-on-the-heat">Figuring out hot to turn on the heat</h2>

<p>So I turns out my heater runs on a really simple control protocol. There are just
two wires run from the heater to the current thermostat, when you connect them it
turns on, and when you disconnect it turns off. The only unfortunate part of it is
that the wires are 24vac, so to be safe I need to use a solid state relay for
switching.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/5897a162a777067bc7469e501a50029f58c9efe6/cc305/images/homekit_thermostat/old_thermostat_closeup.jpeg" alt="Old Thermostat Closeup showing two pins that need to be connected"></p>



<h2 id="the-prototype">The prototype</h2>

<p>I am building this whole thing on an esp32, with a big overkill relay I got on
amazon prime. I will link the exact parts below. The current thermometer is an
old tmp102 sparkfun board I had lying around, but itâ€™s off by around 6 degrees,
so in v2 I will be replacing it with hopefully a more accurate one.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/ec16c9863aa710ab4101208bd7eebc89d316fecb/23983/images/homekit_thermostat/breadboard.jpeg" alt="Fully wired breadboard">
<img src="https://d33wubrfki0l68.cloudfront.net/81db446d96ed6124330e190aba1321f981d07adc/8d0da/images/homekit_thermostat/wall_taped.jpeg" alt="Breadboard taped to wall"></p>

<p>After wiring it all together, and taping it to my wall for a day or two, I was
satisfied with the components, and wanted to get started on prettying it up a bit.</p>



<h2 id="the-code">The code</h2>

<p>The thermostat control runs on a pretty simple state machine. I am a big fan of
drawing things out ahead of time, so I drew this diagram for myself before coding.
In C this is implemented as two enums (actions, states) and a bunch of switch case
statements.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/6d7680c909d72c389d076e0390408d1e44382733/c2055/images/homekit_thermostat/state_machine.png" alt="State machine for thermostat control"></p>

<p id="expand_model_code">Click Here to toggle the code</p>
<div id="model_code">
<pre><code>// Enums:

typedef enum {
    TC_HEATER_MODE_OFF,
    TC_HEATER_MODE_ON,
    TC_HEATER_MODE_AUTO_ON,
    TC_HEATER_MODE_AUTO_OFF
} tc_heater_mode_t;

typedef enum {
    TC_HEATER_ACTIONS_SET_TO_AUTO,
    TC_HEATER_ACTIONS_SET_TO_OFF,
    TC_HEATER_ACTIONS_SET_TO_ON,
    TC_HEATER_ACTIONS_TEMPERATURE_CHANGE,
    TC_HEATER_ACTIONS_THRESHOLD_CHANGE
} tc_heater_action_t;

// ... Somewhere else:

switch (s_current_heater_mode) {
    case TC_HEATER_MODE_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_OFF;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_ON:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                s_current_heater_mode = TC_HEATER_MODE_AUTO_ON;
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                break;
        }
        break;
    case TC_HEATER_MODE_AUTO_ON:
    case TC_HEATER_MODE_AUTO_OFF:
        switch(tc_action) {
            case TC_HEATER_ACTIONS_SET_TO_AUTO:
                break;
            case TC_HEATER_ACTIONS_SET_TO_OFF:
                s_current_heater_mode = TC_HEATER_MODE_OFF;
                break;
            case TC_HEATER_ACTIONS_SET_TO_ON:
                s_current_heater_mode = TC_HEATER_MODE_ON;
                break;
            case TC_HEATER_ACTIONS_TEMPERATURE_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
            case TC_HEATER_ACTIONS_THRESHOLD_CHANGE:
                s_current_heater_mode = tc_update_auto_mode(s_current_heater_mode);
                break;
        }
        break;
}</code></pre>
</div>

<p>It was very important to me that the thermostat worked on homekit, thankfully
there are already great homekit (hap) resources for the esp32. After some digging
I decided on this homekit package, as itâ€™s a clean port of the expressif homekit
library to arduino. There are about 15 different homekit frameworks for arduino,
so at some point I just had to choose one and start running.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/09e7eb514a6c9878988e3897b1f9377a39d331c7/9fc55/images/homekit_thermostat/homekit.jpeg" alt="Homekit screenshot showing thermostat"></p>

<p>After a whole bunch of fucking around I managed to get my esp32 to show up as a thermostat from my phone.</p>

<p>A few gotchaâ€™s that I encountered along the way: (some specific to this library, some specific to homekit)</p>

<ul>
  <li>With this HomeKit library if you want to factory reset, you have to do it <em>after</em> you initialize. Also be sure to remove the device from homekit on your phone before factory resetting the device</li>
  <li>Be sure that you have unique id and pairing codes for your device, I have another esp32 on my homekit and they kept colliding</li>
  <li>Be sure that your device cid matches with the services you are providing, otherwise you will get annoying silent failures from homekit</li>
</ul>



<h2 id="making-things-pretty">Making things pretty</h2>

<p>After getting the code into a place I liked, all that was left was to make it
look less like a bomb strapped to my living room wall. I 3d printed an enclosure,
and soldered the correct wires in the correct places. Unfortunately my board
requires constant a 5V micro-usb power source, so as of right now I have it
powered off of a huge battery pack. Maybe in vN (for very large values of N)
I will go nest style with an internal LiPo and an AC-DC converter.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/da9845e5838dba97dbae170da8ae49eb191c9b6f/089ad/images/homekit_thermostat/soldered.jpeg" alt="Soldered together">
<img src="https://d33wubrfki0l68.cloudfront.net/a2686592824334db4590b4affc52e706eb1acd91/cfae7/images/homekit_thermostat/enclosure.jpeg" alt="3d printed enclosure">
<img src="https://d33wubrfki0l68.cloudfront.net/3d6c45942a18d64daa989a8b0baf0f3ab706a833/aa250/images/homekit_thermostat/pretty.jpeg" alt="Enclosure mounted to wall and plugged in"></p>



<h2 id="whats-next">Whatâ€™s Next?</h2>

<p>I have already bought a few parts for a planned v2, so stay tuned. In v2 I will be adding:</p>

<ul>
  <li>New thermometer board (Going to use this overpriced adafruit breakout here <a href="https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B00OKCQX96/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1</a>)</li>
  <li>Adding a small status display OLED screen <a href="https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0833PF7ML/ref=ppx_yo_dt_b_asin_title_o01_s03?ie=UTF8&amp;psc=1</a></li>
  <li>Add a few buttons to allow non-phone control of the device <a href="https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B0722LBKV7/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1</a></li>
</ul>

<div>
    <p>

    Thanks for reading! If you want to stay updated feel free to follow the <a href="https://staycaffeinated.com/feed.xml">RSS feed</a>, if you have any suggestions feel free to email me at <a href="mailto:mdl0394@gmail.com">mdl0394@gmail.com</a></p><p>
    

    You could also submit your email here, and I will personally email you whenever I post new things:

    </p>
</div>

<h2 id="parts-used--other-references">Parts used / Other references</h2>

<ul>
  <li>Way too big of a relay: <a href="https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07KXNCL91/ref=ppx_yo_dt_b_asin_title_o08_s00?ie=UTF8&amp;psc=1</a></li>
  <li>ESP32 Doit Devkit v1 boards: <a href="https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1">https://www.amazon.com/gp/product/B07Q576VWZ/ref=ppx_yo_dt_b_asin_title_o08_s01?ie=UTF8&amp;psc=1</a></li>
  <li>HomeKit framework esp-homekit-arduino-sdk <a href="https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome">https://github.com/Brawrdon/esp-homekit-arduino-sdk?utm_source=platformio&amp;utm_medium=piohome</a></li>
</ul>

    </div>
</div></div>]]>
            </description>
            <link>https://www.staycaffeinated.com/2020/12/27/building-my-own-homekit-thermostat-v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552889</guid>
            <pubDate>Sun, 27 Dec 2020 18:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS We Happily Pay For]]>
            </title>
            <description>
<![CDATA[
Score 367 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25552342">thread link</a>) | @frankdilo
<br/>
December 27, 2020 | https://francescodilorenzo.com/saas-we-pay-for | <a href="https://web.archive.org/web/*/https://francescodilorenzo.com/saas-we-pay-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We try to run a lean operation at <a href="https://mailbrew.com/">Mailbrew</a>, but we are suckers for great tools that improve our daily workflows, so we pay for quite a few of them each month.</p>
<p>Being small (just 3 people), the cost of switching services is almost negligible, so we try new stuff regularly and do switch when we see a clear improvement.</p>
<p>Here is a list of everything we <em>happily</em> pay for.</p>
<h3><a href="https://missiveapp.com/">Missive</a></h3>
<p><strong>$15/month ⨉ 3 = $45/month.</strong></p>
<p>Collaborative email on top of G Suite. The main thing we pay for is a comment box below each email thread. It allows us to quickly discuss emails without forwarding or copy/pasting in Slack. It also allows us to edit drafts collaboratively and have multiple team inboxes for invoices, support, and other stuff.</p>
<p>We pay for the Productive plan because of one feature: Rules. They allow us to automatically categorize emails and be more granular with notifications. </p>
<h3><a href="https://www.notion.so/product">Notion</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>It's our team wiki. We write memos, meeting notes, drafts for blog posts, and everything that needs to be shared async for feedback. We also used to put tasks here but recently moved to Linear (more on this below).</p>
<p>It's an amazing value, but we were close to ditching it because of how slow it has become. We still have to find something that delivers the same great feature set and flexibility while improving speed and reliability.</p>
<h3><a href="https://linear.app/">Linear</a></h3>
<p><strong>$8/month ⨉ 3 = $24/month.</strong></p>
<p>We put our tasks here. It's a newcomer, but it's so good that we have already committed to it for a year. </p>
<p>It completely revolutionized the way we work with its flexibility, speed, customizability, and great GitHub integration.</p>
<p>If you connect it to GitHub and open a pull request with a task-specific name, task and PR get linked. When the PR is merged, the task is automatically marked as done.</p>
<p>I would invest in this company if I had the chance. It's so much better than everything else I ever tried in this space.</p>
<h3><a href="https://vercel.com/">Vercel</a></h3>
<p><strong>$20/month ⨉ 3 = $60/month.</strong></p>
<p>Vercel deploys and hosts our frontends and serverless functions.</p>
<p>It's a bit pricier than we'd like, and the pricing does not really make sense. Why do we have to pay per team member instead of build minutes, bandwidth, and compute?</p>
<p>With all that being said, we love the product philosophy, simplicity, and integration with GitHub. Having automatic deploys for all commits, together with automatic task-linking to Linear for PRs, is code-review Nirvana.</p>
<h3><a href="https://savvycal.com/">SavvyCal</a></h3>
<p><strong>$12/month ⨉ 2 = $24/month.</strong></p>
<p>We use it to schedule our calls. It's a better Calendly, made by a solo indie developer that we're happy to support.</p>
<p>The product is super-intuitive, and its feature set is increasing at a great pace with features that massively improve our workflows.</p>
<h3><a href="https://plausible.io/">Plausible Analytics</a></h3>
<p><strong>$12/month.</strong></p>
<p>It's a privacy-focused website analytics tool that replaces Google Analytics.</p>
<p>The most impressive thing is how better the insights we get from it are, thanks to some great UX, despite its privacy-respecting stance.</p>
<p>No surprise, they have been <a href="https://www.indiehackers.com/product/plausible-insights">growing like crazy</a>.</p>
<h3><a href="https://mailbrew.com/">Mailbrew</a></h3>
<p><strong>$10/month.</strong></p>
<p>We pay for this, even if we are the ones making it, to test our Stripe Integration.</p>
<p>We use Mailbrew to receive a couple of digests with dedicated Twitter Searches that keep us updated on social mentions of our product.</p>
<h3><a href="https://super.so/">Super</a></h3>
<p><strong>$12/month.</strong></p>
<p>This turns Notion documents into their own websites with a dedicated domain. We use it for our <a href="https://mailbrew.com/press">press kit</a> and <a href="https://help.mailbrew.com/">support docs</a>.  </p>
</article></div>]]>
            </description>
            <link>https://francescodilorenzo.com/saas-we-pay-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552342</guid>
            <pubDate>Sun, 27 Dec 2020 16:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remembering the Nanjing Massacre]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25552140">thread link</a>) | @Beggers1960
<br/>
December 27, 2020 | https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ | <a href="https://web.archive.org/web/*/https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-449">

	<!-- .entry-header -->

	<div>
		


<p><img loading="lazy" data-attachment-id="464" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/ija_10th_army_entering_nanking/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" data-orig-size="950,633" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IJA_10th_Army_entering_Nanking" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg" alt="Nanjing Massacre" width="748" height="498" srcset="https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=748&amp;h=498 748w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=150&amp;h=100 150w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=300&amp;h=200 300w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg?w=768&amp;h=512 768w, https://rossk1992.files.wordpress.com/2020/12/ija_10th_army_entering_nanking.jpg 950w" sizes="(max-width: 748px) 100vw, 748px"></p>
<p>In 1937, before a shot was even fired in Europe, Imperial Japanese forces were engaged in a long, bloody conflict in China – and it is during this period that we catch a glimpse of the atrocities that would stain the 1940s.&nbsp;</p>
<p>The event, or series of events, we are looking at today is the Japanese occupation of Nanjing, commonly referred to as the ‘Rape of Nanjing’.</p>



<p>Anyone with a modicum of knowledge on the Second World War will know of the atrocities committed by Imperial Japanese forces. Their atrocious treatment of PoW’s and civilians throughout South East Asia, Oceania and China are well documented. Several years before those times however, when Japanese forces entered Nanjing, they let loose upon the people there.</p>
<h4>Crashing dominoes&nbsp;</h4>
<p>In the weeks preceding the Japanese occuptation of Nanjing, there had been bloody fighting between Chinese forces and Imperial Japanese troops. Indeed, for several years, the Imperial Japanese Army had been involved in a tit-for-tat conflict against both Communist and nationalist Chinese forces.</p>
<p>In August 1937, the <a href="https://en.wikipedia.org/wiki/Battle_of_Shanghai" target="_blank" rel="noopener">Battle of Shangai</a> set into motion a series of events that would lead to disaster for Chinese forces and civilians throughout the country. The Battle of Shanghai was a visceral, bloody engagement for both sides. However, by mid-November, Imperial Japanese forces had captured and subjugated the area.&nbsp;</p>
<figure data-shortcode="caption" id="attachment_462" aria-describedby="caption-attachment-462"><img loading="lazy" data-attachment-id="462" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/japanese_marines_during_the_battle_of_shanghai_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" data-orig-size="510,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Japanese_marines_during_the_Battle_of_Shanghai,_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=510" src="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg" alt="" width="510" height="352" srcset="https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg 510w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=150&amp;h=104 150w, https://rossk1992.files.wordpress.com/2020/12/japanese_marines_during_the_battle_of_shanghai_1937.jpg?w=300&amp;h=207 300w" sizes="(max-width: 510px) 100vw, 510px"><figcaption id="caption-attachment-462">Japanese marines advance during the Battle of Shanghai.</figcaption></figure>
<p>Despite sustaining heavy casualities after weeks of fighting, Japanese forces of the Central China Area Army and 10th Army were ordered to capture the city of Nanjing and the surrounding area. The subsequent advance prompted hysteria among Chinese civilians and military forces, with thousands of the latter desperately trying to avoid capture.&nbsp;</p>
<h4>Cry havoc! and let slip the dogs of war</h4>







<p>Upon entering the city, Japanese forces appear to enter a feral state, abandoning all reason and humanity and embarking on a campaign of terror, abuse and murder against the people of the old Chinese capital.</p>



<p>A truly ghastly affair, and throughout we see sadistic methods and practices by Japanese troops. Groups of individuals were buried alive, some were burned alive, and the lucky ones were simply executed en-masse.</p>



<p>Beheadings were commonplace throughout this event, and there are accounts (although hotly debated) of ‘contests’ between Japanese officers to see who could behead 100 people in the shortest time.</p>





<p>In 1937, Japanese media covered the story of Toshiaki Mukai and Tsuyoshi Noda of the Japanese 16th Division, who were both vying to reach this goal of 100 beheadings. Throughout the course of the war these two men are alleged to have murdered over 300 people between them, and upon Japan’s surrender in 1945 the officers were tried and executed for war crimes.</p>



<p>While crimes were being committed against the civilian population, scores of Chinese prisoners of war were ruthlessly executed. The execution of prisoners of war were also particularly sadistic and brutal.</p>



<p>Countless PoW’s were hanged, shot and beheaded, with many more being buried alive alongside civilians. To this day the number of Chinese PoW’s executed is still unknown.</p>
<figure data-shortcode="caption" id="attachment_458" aria-describedby="caption-attachment-458"><img loading="lazy" data-attachment-id="458" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/iwane_matsui_rides_into_nanjing/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" data-orig-size="498,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Iwane_Matsui_rides_into_Nanjing" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=498" src="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg" alt="Nanking Massacre" width="498" height="360" srcset="https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg 498w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=150&amp;h=108 150w, https://rossk1992.files.wordpress.com/2020/12/iwane_matsui_rides_into_nanjing.jpg?w=300&amp;h=217 300w" sizes="(max-width: 498px) 100vw, 498px"><figcaption id="caption-attachment-458">General Iwane Matsui rides into Nanjing.</figcaption></figure>
<h4>Accounts by westerners</h4>



<p>As hostilities had not yet erupted between western nations and Japan, there were a range of western civilians in the city during this event, and their accounts of the actions of Japanese soldiers are harrowing.</p>



<p>A surgeon, Robert O. Wilson, in the university hospital within the US safety zone, wrote home on several occasions detailing the events unfolding before his eyes.</p>



<p>“The slaughter of civilians is appalling. I could go on for pages telling of cases of rape and brutality almost beyond belief,” he wrote. “Two bayoneted corpses are the only survivors of seven street cleaners who were sitting in their headquarters when Japanese soldiers came in without warning and killed five of their number and wounded the two that found their way to the hospital.”</p>
<p>The Minnie Vautrin Diary detailing atrocities provides some of the most compelling and harrowing accounts of the Nanjing Massacre. Excerpts detailing what she witnessed can be found online, or the diary itself can be purchased.</p>



<p>In her diary she details the callous brutality of Japanese soldiers and, in particular, their treatment of Chinese women.</p>



<p>“A woman of almost 50 living down near San Pai Lou.&nbsp;She had three sons and two daughters-in-law. Four nights ago two soldiers came to the door at about 10pm, unable to push the door they forced their way in through a window and found themselves in Liu Lau Tai’s room.</p>





<p>“They demanded her daughters-in-law and when she refused and started to go for a military police they cut two gashes in her face and one in her heart.&nbsp;She died from these wounds.”</p>





<h4>Age old barbarism</h4>



<p>Japanese soldiers employed an age old weapon against the people of Nanjing, rape. Assault on women throughout the Nanjing Massacre were widespread and anywhere up to 20,000 women and girls were raped and brutalised.</p>







<p>John Rabe, leader of the Nanjing Safety Zone details his experiences in dealing with these cases during his time in the city.</p>



<p>“In one of the houses in the narrow street behind my garden wall, a woman was raped, and then wounded in the neck with a bayonet. I managed to get an ambulance so we can take her to Kulou Hospital.</p>





<p>“Last night up to 1,000 women and girls are said to have been raped, about 100 girls at Ginling College alone.</p>



<p>“You hear nothing but rape. If husbands or brothers intervene, they’re shot. What you hear and see on all sides is the brutality and bestiality of the Japanese soldiers.”</p>
<figure data-shortcode="caption" id="attachment_460" aria-describedby="caption-attachment-460"><img loading="lazy" data-attachment-id="460" data-permalink="https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/nanking_bodies_1937/" data-orig-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" data-orig-size="800,559" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nanking_bodies_1937" data-image-description="" data-medium-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300" data-large-file="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748" src="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg" alt="Nanjing Massacre" width="748" height="523" srcset="https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=748&amp;h=523 748w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=150&amp;h=105 150w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=300&amp;h=210 300w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg?w=768&amp;h=537 768w, https://rossk1992.files.wordpress.com/2020/12/nanking_bodies_1937.jpg 800w" sizes="(max-width: 748px) 100vw, 748px"><figcaption id="caption-attachment-460">Bodies littered the shore of the Qinhuai River.</figcaption></figure>



<h4>Relenting troops</h4>



<p>In January of 1938, after several weeks of bloodletting, refugees within the safety zones were ordered to return to their homes.</p>



<p>Japanese officials claimed at the time that ‘order had been restored’ and that daily life were to continue as normal. For the people of Nanjing subjected to relentless bouts of violence, however, life would never be the same again.</p>



<p>As order was gradually restored, the frequency of attacks and atrocities did dissipate.</p>
<h4>Guilt</h4>



<p>General Iwane Matsui, leader of the Japanese Expeditionary Force in China, began to realise the extent of the atrocities being committed by his men in Nanjing – albeit too late.</p>



<p>Speaking of his knowledge on the atrocities being committed, he is claimed to have stated to an aide:</p>



<p>“I now realise that we have unknowingly wrought a most grievous effect on this city. When I think of the feelings and sentiments of many of my Chinese friends who have fled from Nanjing and of the future of the two countries, I cannot but feel depressed.</p>



<p>“I am very lonely and can never get in a mood to rejoice about this victory … I personally feel sorry for the tragedies to the people, but the Army must continue unless China repents.</p>



<p>“Now, in the winter, the season gives time to reflect. I offer my sympathy, with deep emotion, to a million innocent people.”</p>



<p>Although an apparent admission of guilt on his part, Matsui’s lack of action on the issue, his burying of the head in sand, simply allowed the ordeal to continue far longer than it did.</p>



<p>Matsui was recalled to Japan following the massacre and retired. Upon Japan’s surrender in 1945, he was tried by the International Military Tribunal for the Far East and is executed.</p>



<h4>Aftermath</h4>



<p>The death toll in Nanjing is debated. Contemporary Japanese statistics could be considered laughable, amounting to only several hundred dead. A range of sources estimate that anywhere between 30,000 to 300,000 people were murdered during this month-long tirade of violence.</p>
<p>Modern Chinese sources (in particular the Chinese Government) claim that these numbers range even higher and are, in fact, closer to half-a-million.</p>




<p>The Nanjing War Crimes Tribunal in 1947 stated:</p>



<p>“More than 190,000 mass slaughtered civilians and Chinese soldiers killed by machine gun by the Japanese army, whose corpses have been burned to destroy proof.</p>



<p>“Besides, we count more than 150,000 victims of barbarian acts buried by the charity organisations. We thus have a total of more than 300,000 victims.”</p>



<p>Researchers state that the death toll numbers between 40,000 and 60,000 based on a number of sources from the time, including Red Army statistics and the Nanjing Safety Zone committee.</p>



<p>Regardless of the true number of casualties, the barbarism and horrific nature of this event are beyond comprehension. The callous behaviour of Japanese soldiers is a stain on the tapestry of 20th century history, and this behaviour continued for another several years until Japanese capitulation in the wake of Hiroshima &amp; Nagasaki.</p>


			
			
						</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://ramblinghistory.co.uk/2020/12/11/nanjing-massacre-remembered/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25552140</guid>
            <pubDate>Sun, 27 Dec 2020 16:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Central Bank Digital Currencies Are a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25550443">thread link</a>) | @simonebrunozzi
<br/>
December 27, 2020 | https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea | <a href="https://web.archive.org/web/*/https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1605643941671" id="item-5fb42c70669e655a2de5be01"><div><div><div data-block-type="2" id="block-36140108062efd62704e"><div><p><em>This text was published at </em><a href="https://mises.org/wire/why-central-bank-digital-currencies-are-bad-idea"><em>Mises Institute</em></a></p><p>The Central Banking Digital Currencies (CBDC) are being sold with the narrative of protecting consumers who are increasingly moving to cashless payments and as a result, robbing themselves of the privacy advantages of cash and exposing themselves to bank runs, payment network blackouts, and to foreign financial adversaries.</p><p>While these risks are real, they would be negligible had it not been for the central banking and financial regulators’ interventions into the market (more on that in the last couple of paragraphs), and CBDCs if anything make them worse and introduce some new, much bigger ones.</p><p>While the stated intention behind their design is to keep the commercial banks in the picture, CBDCs will bring the end-users of the future tokens closer to the central banks. This is because blockchains and blockchain-inspired distributed ledger technologies are built on a single, common, ledger, which is distributed either in a permissionless or permissioned manner. The permissionless distribution exposes a lot of information about the network participants, but in combination with proof-of-work verification makes it very difficult for an adversary to attack and overtake the network and e.g. change the inflation rate.</p><p>Permissioned network with no proof-of-work or similar consensus algorithm not only doesn’t provide the immutability feature but by having a single permissioned ledger gives potential control to those who grant the network privileges. As a result, the central bank as the ultimate permission issuer would have much stronger control over the monetary system and payment network than they have right now. This gives the central banks three very dangerous capabilities.</p><h2>Helicopter Money</h2><p>The reason why we’ve seen such an elevated business cycle over the past century is the central banking fiat money system. Unnatural expansion of the money supply causes booms, which are unsustainable and markets try to clear them when they are exposed as such.</p><p>Economists of the Austrian school understand, that the boom is the real problem and the economic crisis is the necessary and positive cleansing mechanism. Unfortunately, the (neo)Keynesian response to such an event is to prop the markets up by further monetary interventions.</p><p>However, the current design of the banking system requires the intermediary role of commercial banks in issuing credit to businesses. Central banks get frustrated when the commercial banks exercise caution in an economy, which hasn’t fully cleared the previous misallocations and hasn’t brought prices of capital goods to more sustainable levels.</p><p>Furthermore, since the predominant Keynesian narrative is that spending drives the economy (hint: it doesn’t - capital investments do), the central banks would like to spur more consumer spending by issuing money supply directly to consumers. Needless to say, commercial banks’ cautious approach to consumer credit in a period of growing unemployment doesn’t align well with the central bank’s goals either. During the COVID crisis, the governments managed to an extent to get around these hurdles by issuing benefits en masse, but those are complicated by logistics, bureaucracy, or legislation.</p><p>By closer integration of the monetary spigot to the end consumers and businesses, the central bank can much more easily issue credit, or just outright cashouts to the private individuals and commercial entities by simply “airdropping” new tokens to the existing token identities. They would not even compromise their stated intention of keeping the commercial banks in the picture - those would still serve as custodians of the token keys, and even have the ability to issue credit along the traditional lines.</p><p>This would lead to disastrous consequences. Economies get easily addicted to central banks’ money dope. With every new crisis, the chief monetarists had to increase intervention doses the same way as junkies have to do with their drug of choice. As with every addiction, the longer it lasts and the stronger it grows, the more difficult it is to cure it. And while monetary overdose such as we’ve seen in Zimbabwe or Venezuela might not come for a long time, if ever, junkies don’t perform well, as Japan’s three lost decades of BOJ’s interventions have demonstrated.</p><h2>Negative Interest Rates</h2><p>Hoarding is evil - or so the modern monetarists’ narrative goes. In the Keynesian framework, there is no space for the function of cash as a hedge in times of uncertainty. Savings accounts, in their minds, are just money that doesn’t work in spurring the miracles of spending- and monetary-driven economic growth. Negative interest rates are then potentially the most effective method of preventing hoarding by incentivizing account holders to spend their depreciating balances.</p><p>Currently, the central banks have to rely on commercial banks to pass the negative interest rates on their customers. Commercial banks instead are trying to convince the account holders to move their deposits from negative yielding accounts to interest yielding products and are consuming the negative rates on most of the outstanding cash balances.</p><p>With the central bank tokens being tied more tightly with their issuance authority, it would be much easier for the monetary interventionists to impose negative interest rates on all tokens in circulation. This would on a margin certainly increase the consumers’ and businesses’ propensity to spend and would also drive asset prices up as people would try to offload their cash savings. But to think of it as something beneficial is foolish. It was massive spending, record-low savings, and unsustainable asset valuations that led to the credit bubbles and crises of the past decades. To think that more of the same recipe would lead to a different, let alone better outcome is ludicrous.</p><h2>Financial Surveillance</h2><p>Third and final major implication of cash tokenization is the potential it creates for financial surveillance. The central banks are ostensibly introducing digital tokens to protect people’s privacy in the face of those reducing their anonymous cash usage. But the idea that any branch of government, let alone the one that imposes KYC/AML rules on the existing crypto token platforms, limits physical cash use to prevent tax avoidance, and uses financial surveillance to catch non-violent “criminals” cares about our privacy is laughable.</p><p>They’re not even hiding the fact, that tokenization of money would allow them to run what they call “data analytics”, but to think that they would not make the leap from aggregate analytics to individual data processing would be naive.</p><p>Of course, it’s not a coincidence, that China is the global leader in CBDCs. The surveillance potential of centralized tokenization is extremely attractive to the government that tries to keep tabs on every aspect of the lives of their underlings.</p><p>The proponents of the central banking tokens argue, that consumers need to be protected against targeted attacks on a country’s payment network. While such a risk exists - for example, if a country like Switzerland tried to provide anonymity for foreign depositors as it used to and as a result Visa and Mastercard would be pressured to shut down their payment networks for the country - if it materializes, the economy can always temporarily revert back to cash, supported by a vast network of local ATMs and bank branches.</p><p>If anything, the biggest attacks on the monetary exchange in the western world came from the governments themselves suspending or limiting cash withdrawals in times of liquidity crises as was the case in Cyprus or Greece, not to mention that those crises themselves were caused by central banking credit bubbles of the preceding periods.</p><p>Finally as was already mentioned, the argument about the protection of consumer privacy doesn’t pass the laugh test considering the history of continuous erosion of financial privacy by central banks and financial regulators.</p><p>In conclusion, the same characteristics for which people should oppose the transition to CDBCs give central banks the strongest reason to champion and implement them. And while the pretense of an investigation into the fiat money tokenization gives an impression of a debate on the topic, the reality is, there will be no debate and the digital currencies will go through and give central banks more control than they had before with all the disastrous consequences such control brings.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.forgac.me/blog/2020/11/17/three-reasons-why-central-bank-digital-currencies-are-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25550443</guid>
            <pubDate>Sun, 27 Dec 2020 11:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Chaos Communication Congress – Streams]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25549762">thread link</a>) | @doener
<br/>
December 27, 2020 | https://streaming.media.ccc.de/rc3/ | <a href="https://web.archive.org/web/*/https://streaming.media.ccc.de/rc3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streaming.media.ccc.de/rc3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25549762</guid>
            <pubDate>Sun, 27 Dec 2020 08:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kit FUI – User interfaces found in films]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25547352">thread link</a>) | @ChrisArchitect
<br/>
December 26, 2020 | https://www.saji8k.com/kit-fui/ | <a href="https://web.archive.org/web/*/https://www.saji8k.com/kit-fui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>User interfaces from film, television, video games and the designers that created them.</p>
				<p>Keep track of updates to Kit FUI on my <a href="https://www.saji8k.com/blog/">blog</a> or by following me on <a href="https://twitter.com/saji8k">Twitter</a> or <a href="https://www.facebook.com/saji8k">Facebook</a>.</p>
				<p>If you have suggestions for the site or would like to submit your work, send me a <a href="https://twitter.com/saji8k">tweet</a>.</p>
			</div>
		</div><div>
			<div>
				<h3>What is FUI?</h3>
				<p>Fantasy User Interfaces, Fictional User Interfaces, Fake User Interfaces, Futuristic User Interfaces, Film User Interfaces, Future User Interfaces. Regardless of what the F stands for, they all represent the same thing, the user interfaces (UIs) and heads up displays (HUDs) found in many popular movies and television shows.</p>
				<p>Most FUIs are not actual computer programs but simply animations being played back at the correct time or added in post production. These graphics and animations are designed in applications like Adobe Illustrator, Adobe After Effects and Maxon Cinema 4D.</p>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.saji8k.com/kit-fui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547352</guid>
            <pubDate>Sat, 26 Dec 2020 23:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run More Stuff in Docker]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 270 (<a href="https://news.ycombinator.com/item?id=25547205">thread link</a>) | @psxuaw
<br/>
December 26, 2020 | https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-03-10</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech/">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming/">programming</a>
			
		</span>
		
	</h6>
	<hr>
	<p>In 2020, <strong>Docker is the best medium for distributing and running most developer-facing software</strong>. It’s widely accepted that Docker is great for building and deploying the artifacts for your enterprise web app, but this is less well known when it comes to things like developer tools. However, running tools in containers has many benefits over installing and running them in the conventional way, and we should all start doing it more.</p>
<h2 id="why">Why?</h2>
<p>I install very few things on either my personal or work computer. I don’t have <code>terraform</code>, <code>aws</code>, <code>node</code>, or <code>pip</code> installed, but I use them all the time. I have a Docker image for each, and I run them in containers with minimal privileges. I’m definitely <a href="https://github.com/jessfraz/dockerfiles">not the only one</a>, but it’s not as popular as it should be. None of these tools actually need full access to my computer to do their work, but that is normally how they’re run.</p>
<p>Here are some benefits of running these tools in Docker.</p>
<h4 id="cross-platform">Cross-platform</h4>
<p>At this point in time, Docker is ubiquitous and you get cross-platform support for free, thanks to Docker Inc’s investments in that area (Docker for Mac &amp; Windows). This is useful both for people developing/distributing tools, and for people working on a team that needs to share tooling. You have one Docker image and it will run pretty much everywhere. OS package managers can be great, but they’re very much not cross-platform. Things like <code>pip install</code> will sometimes work cross-platform, but have other serious drawbacks.</p>
<p>While every platform has its own sandboxing mechanisms, running with Docker lets you specify runtime context and enforce a sandbox in a cross-platform way, which is useful when you expect anybody else to run the same command as you.</p>
<h4 id="sandboxed">Sandboxed</h4>
<p>When you <code>docker run</code>, you have to be explicit about privileges. A container is mostly sandboxed and unprivileged by default. It doesn’t have access to ambient environment variables. It doesn’t have access to the host system’s disk. A tool like <code>jq</code> just needs to read stdin and print to stdout. It doesn’t need access to my shell’s environment variables (or, if it does, I explicitly pass those through to the container). <code>yarn</code> should be fine operating on just the working directory, and maybe a cache directory. I don’t want it to have access to my ~/.aws directory (for <a href="https://securityboulevard.com/2020/01/malicious-npm-package-exfiltrating-data-from-unix-systems/">obvious reasons</a>).</p>
<p>Some tools do need access to things. I want my <code>aws</code> CLI to be able to read ~/.aws, so I grant that explicitly. This makes running the tool more verbose but less magical.</p>
<h4 id="simple-uniform-interface">Simple, uniform interface</h4>
<p>Running a program in a container is a lot like running it normally, but the user doesn’t need to jump through hoops to configure the system, build and install. The developer of the image jumps through those hoops and produces a runnable artifact with a simple interface. That interface is the same whether the tool was written in Python or Rust or C or anything else.</p>
<p>Downloading a pre-compiled binary is almost like this, except with worse odds. Maybe there’s a build for your architecture. If it was statically linked, you’re golden. Otherwise, use <code>ldd</code> to reverse engineer the fact that you need to install <code>libjpeg</code>.</p>
<p>A Docker image “just works”. It comes bundled with what it needs to run.</p>
<p>If you think about it, it’s pretty strange to execute <a href="https://github.com/aws/aws-cli/tree/0b3d9a4260fdda5c6a8b736439e0776bc2252f41#installation"><code>pip install awscli</code></a>. It’s immaterial to an end user that the tool is written in Python, and requiring him or her to set up and use Python tooling doesn’t make sense. I don’t mean to pick on <code>pip</code> or <code>awscli</code> in particular, but this is a poor mechanism for distributing non-library software. It leaves <a href="https://github.com/aws/aws-cli/issues?q=is%3Aissue+pip">far too much to chance</a>. It’s a clumsy and leaky interface for tool distribution. So is <code>npm install</code>. So is telling somebody to install your tool by installing golang, and then running <code>go build</code>. No, thanks. If I’m hacking on the project, then by all means. But don’t foist that on end users.</p>
<h4 id="facilitates-version-pinning">Facilitates version pinning</h4>
<p>When collaborating, it’s important that people run the same versions of software to get consistent results. Version pinning is essential to that. Pinning dependency manifests is good, but it’s not enough: it only covers the one situation of installing things with a language package manager. It may not cover using the same linter version, or the same version of <code>node</code>, <code>aws</code>, <code>ansible</code>, <code>terraform</code>, or any libraries installed at the OS level. Invoking <code>docker run node:13.10.1</code>, instead of whatever the user happens to have installed as <code>node</code>, solves this problem in general. Having the ability to specify the versions at the point of use, rather than out-of-band as part of some other installation process, is also convenient and tidy.</p>
<p>It’s easy to run different versions of a tool side by side with Docker. Docker solves this more generally than things like virtualenv for Python, rvm for Ruby, etc. You specify what version of the tool to use when you’re invoking it, and it pins a whole lot of context more than just the tool’s version, which is always preferable for reproducibility.</p>
<p>In one recent situation at work, we had a test case start failing when we upgraded our runtime from Python 3.6.5 to Python 3.6.8. Having the ability to easily run the tests with any version of Python made it easy to bisect and identify a change in 3.6.7 as the cause. This could have been debugged without Docker, but it was particularly natural and easy with Docker.</p>
<h4 id="reproducible">Reproducible</h4>
<p>Invoking a tool with <code>docker run</code> should specify everything needed to reproducibly run it somewhere else. It’s running some specific version of the tool? Okay. It needs my AWS credentials? Okay. It needs some specific combination of environment variables set? Okay.</p>
<p>I cringe when I see a Makefile or build instructions saying to run <code>yarn</code> or <code>terraform</code> or <code>go</code>. What version? What’s being assumed about my environment? Maybe this worked on your <a href="https://martinfowler.com/bliki/SnowflakeServer.html">unique snowflake of a machine</a> 18 months ago, but good luck with it now. (My laptop is a unique snowflake too. Everyone’s is, until we all figure out how to use NixOS.)</p>
<p>Running tools in Docker, there are few expectations of the runtime environment beyond having Docker installed. All the other requirements should be made explicit in the <code>docker run</code> command. The command that you’re running locally will work the same on your colleague’s machine, and in any CI with minimal configuration (or none). This is absolutely critical, especially when working on a team. This is a far more robust approach than expecting (requiring) anybody’s system, or a CI slave, to be set up “just so”.</p>
<h4 id="minimizes-global-state">Minimizes global state</h4>
<p>I have very few things installed on my host system beyond the base OS. There’s less to remember when setting up a new machine, fewer things to go wrong during upgrades, and fewer opportunities for conflicts over shared libraries.</p>
<h2 id="examples">Examples</h2>
<h4 id="one-offs">One-offs</h4>
<p>I have bash aliases for a bunch of tools that I run all the time. These are just for my own convenience. For anything shared with other people, I’d use a project’s Makefile (see below).</p>
<ul>
<li>
<p><strong>Some basics</strong></p>
<pre><code>alias aws='docker run --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 -e AWS_PROFILE mikesir87/aws-cli:1.18.11 aws'
alias jq='docker run -i --rm jess/jq jq'
alias terraform='docker run -it --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 hashicorp/terraform:0.12.23'
</code></pre><p>With these aliases, I can <code>AWS_PROFILE=... aws sts get-caller-identity | jq -r .Arn</code> as if they were “really” installed.</p>
</li>
<li>
<p><strong>zoom</strong></p>
<p>Here’s zoom (video conferencing):</p>
<pre><code>alias zoom='xhost +local:docker \
    &amp;&amp; docker run -it --rm -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    --device /dev/video0 --device /dev/snd:/dev/snd --device /dev/dri -v /dev/shm:/dev/shm \
    -v ~/.config/zoom/.zoom:/root/.zoom -v ~/.config/zoom/.config/zoomus.conf:/root/.config/zoomus.conf \
    jess/zoom-us'
</code></pre><p>Notice that <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5">port 19421</a> remains stubbornly closed unless we explicitly let the container claim it on the host.</p>
</li>
<li>
<p><strong>Snes9x</strong></p>
<p>I do this with other stuff, too. Here’s Snes9x (can you imagine <a href="http://www.snes9x.com/phpbb3/viewtopic.php?t=23603">installing it</a>?):</p>
<pre><code>alias snes9x='docker run -it --rm -u 1000:1000 -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    -v /run/dbus:/run/dbus -v /dev/shm:/dev/shm \
    --device /dev/snd --device /dev/dri --device /dev/input/js0 \
    -e PULSE_SERVER=unix:$XDG_RUNTIME_DIR/pulse/native -v $XDG_RUNTIME_DIR/pulse/native:$XDG_RUNTIME_DIR/pulse/native \
    --group-add $(getent group audio | cut -d: -f3) \
    -v ~/.config/snes9x:/.snes9x/ -v ~/Games/SNES:/SNES -v ~/.local/share:/.local/share \
    danniel/snes9x'
</code></pre></li>
</ul>
<h4 id="projects">Projects</h4>
<p>For things that are project-specific, or in a team setting, all useful commands should be codified in something like a Makefile. This wraps the complexity and verbosity of the <code>docker run</code> incantations, makes it possible to share them easily, and makes them passably ergonomic.</p>
<ul>
<li>
<p><strong>hugo</strong></p>
<p>When I’m writing an article for this site, I run <code>make hugo-watch</code> and load http://localhost:1313 in a web browser:</p>
<pre><code>hugo = docker run --rm -u $$(id -u):$$(id -g) -v "$$(pwd)":/src -v "$$(pwd)"/output:/target $(2) klakegg/hugo:0.54.0-ext-alpine $(1)

hugo-watch:
    mkdir -p output
    $(call hugo, server, -it -p 1313:1313)
</code></pre></li>
<li>
<p><strong>prettier</strong></p>
<p>To format a JavaScript project, we might have the make targets</p>
<pre><code>prettier = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" elnebuloso/prettier:1.19.1 $(1) "src/**/*.js"

format:
    $(call prettier)

format-check:
    $(call prettier, --check)
</code></pre><p>We would run <code>make format</code> to format the code and <code>make format-check</code> to check the style. It runs on my Linux box, it runs on my colleague’s Mac, and it runs in any Docker-equipped CI. None of those machines need to have <code>node</code>, <code>npm</code>, or <code>prettier</code> installed. We completely trivialize the issues of versioning and of synchronizing our environments: the version is specified once, here in the Makefile, and it’s obeyed everywhere.</p>
<p>In a language like Python, where libraries are forced to fight to the death for control of transitive dependency versions, lifting a tool like <code>black</code> or <code>flake8</code> out of the project’s requirements.txt, and into a self-contained Docker image, can be a big …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547205</guid>
            <pubDate>Sat, 26 Dec 2020 23:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost nuclear device atop of Nanda Devi]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25547123">thread link</a>) | @hudvin
<br/>
December 26, 2020 | https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device | <a href="https://web.archive.org/web/*/https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <div id="container">
                          
  <div>
    


<div id="story-f889b712-c891-4d7d-b740-a08c112f512d" data-public-preview="">
  <article data-story-url="" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc" data-story-headline="Nanda Deviâ€™s Nuclear Secret and a Botched CIA Operation" data-loader="story">
    
          <div>
    <figure>
        <img src="https://images.assettype.com/indynetwork%2F2020-09%2Fde00724b-9ea2-4f38-82dc-ca78b3e6dee0%2FImage_9.jpg?w=1500">
    </figure>
</div>
<div>
  <div>
    
    <div itemprop="articleBody" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc">
      
                        
              <div data-card-content-id="efdfb573-ba3e-4852-b9ee-0486b7498411" data-card-version-id="49dda451-df77-4ea6-9f9b-3d28a0f6cf13">
        
      <div id="inf-card-b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-id="b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-type="text">
          <div>
    <p>The past few months have seen a rise in volatility along the Indo-Tibetan border, with the forces of both India and China coming to blows. While these events are extraordinary in present times, the border has witnessed far more heated exchanges, most notably during the 1962 <a href="https://www.livehistoryindia.com/in-the-news/2020/06/21/across-the-karakorams">Indo-China</a> War.</p><p>The unforgiving terrain that marks the frontier creates an additional dimension to the already complex nature of these clashes, whether in regard to more conventional manoeuvres, or other irregular military activity which is far more frequent. This is the story of the latter kind of action, that of daring espionage against Communist China, played for the highest stakes with the greatest risks.</p>
  </div>
</div>



      <div id="inf-card-33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-id="33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-type="text">
          <div>
    <p>Cold, harsh, inviolate. Straddling between the <a href="https://www.livehistoryindia.com/snapshort-histories/2017/06/21/kumaon-echoes-of-the-past">Kumaon</a> and Garhwal districts of Uttarakhand, deep in the Himalayas, stands Nanda Devi. The second-highest mountain in India, towering at an astonishing 25,646 feet, it is named after the patron goddess of Uttarakhandâ€” the mountain being her temporal manifestation.</p><p>Its unique topographical environment makes it one of the most inaccessible places on Earth. Surrounded on three sides by massive mountain rampartsâ€”its natural fortifications measuring at no point below 17,000 feetâ€” only the narrow and dangerously steep Rishi Ganga river gorge allows access to it. The mountain in itself is a citadel of rock and ice, with steep, angled faces and avalanche-prone ridges guarding its summit. Its immense proportions make it far tougher to climb than Everest. It is at once a supremely magnificent and terrifyingly intimidating mountain.</p>
  </div>
</div>



      <div id="inf-card-67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-id="67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Map of the Nanda Devi Sanctuary, the thick hachures marking the semi-circular natural fortifications in the form of mountains that surround most of the Nanda Devi" src="https://images.assettype.com/indynetwork%2F2020-09%2F65d1a1da-2c67-4059-aeb0-c5437f7f191d%2FImage_3.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-id="ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-type="text">
          <div>
    <p>For much of the 19th and early 20th century, before it was finally summited in 1936, it was considered to be the third pole â€“ a point of virtual inaccessibility. However, this awe-inspiring creation of nature shelters a device, abhorrent to nature, manufactured by man. Somewhere high on the harrowing slopes of Nanda Devi, buried deep in snow, lies a lost nuclear listening device slowly depleting its plutonium cores. Containing 5kg of plutonium â€“ 1 kg less than the nuclear bomb dropped on Nagasaki â€“ with a predicted lifespan of 900 years, this nuclear trespasser has been forfeited to the mountain forever.</p><p>This is the story behind one of the most audacious acts of espionage in the 20th century.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5350a04d-7e5b-48a5-9ccc-0c0b06771394" data-card-version-id="b82a93e5-a227-4175-b91c-b1fe616b5c7c">
        
      <div id="inf-card-d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-id="d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-type="text">
          <div>
    <p><strong>Cold War In High Places</strong></p><p>The year was 1965, and the Cold War was reaching its apogee, with America stretching its geopolitical reach to all corners of the world in order to counter the communist influence. Closer to home, the War of â€™62 had left India intensely wary of its neighbour, China. To add fuel to simmering embers, China carried out its first nuclear test in 1964 in Xinjiang, a province that borders the northern tip of India. In this atmosphere of intense mutual suspicion and paranoia, the Pentagon began concocting a plan that would help both India and America keep a closer eye on China, especially with regard to its nuclear programme.</p><p>With satellites that could gather useful photographic intelligence still a few years away, Americaâ€™s Central Intelligence Agency (CIA) along with the Indian Intelligence Bureau (IB) planned on placing a powerful listening device at a point of extreme prominence along the Indo-Tibetan border. The site where the device would be placed was key as it would need to have uninterrupted access in order to intercept Chinese radio signals. This meant it would have to be positioned on a mountain that was high as well as close to the Tibetan plateau. With an unparalleled height advantage and an unobstructed view of China from its summit, there was no better choice than Nanda Devi.</p>
  </div>
</div>



      <div id="inf-card-21631012-ab2e-4940-a233-267421b9382d" data-story-element-id="21631012-ab2e-4940-a233-267421b9382d" data-story-element-type="text">
        <div>
     <hr>
  <div>
    <blockquote>To ensure the longevity and endurance of the device, which was supposed to work at an altitude of nearly 26,000 feet, it was decided that it would be nuclear-powered. </blockquote>
  </div>
  <hr>
</div>
  </div>



      <div id="inf-card-ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-id="ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-type="text">
          <div>
    <p>A System for Nuclear Auxiliary Power (SNAP) generator was designed so that it would power the telemetry functions of the device, a power unit similar to the ones being used in space at the time.</p><p>It was within the SNAP that seven plutonium fuel rods would be stored, made from a compound of Pu-238 and Pu-239. Once activated, the SNAP would constantly be converting radioactive heat energy created by the rods into electricity, which would power the multiple-sensor device as well as its six-foot-long antenna.</p><p>With the technical aspect settled, the question of who would carry and set up all this equipment remained. Only two expeditions had summited the mountain up until then, and more than a few climbers had died. There was no doubt that only the very best mountaineers could be trusted to carry a nuclear payload up one of the most difficult mountains in the world.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5aeaa671-5f93-450a-971d-b5690e92888f" data-card-version-id="58f0cfc2-71cc-46c3-a836-d90e638e4071">
        
      <div id="inf-card-a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-id="a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-type="text">
          <p><strong>League of Extraordinary Climbers</strong></p>
</div>



      <div id="inf-card-44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-id="44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Captain MS Kohli AVSM, leader of the covert climbing expeditions, now at the ripe old age of 88. " src="https://images.assettype.com/indynetwork%2F2020-09%2Faea6959e-2270-436f-bbd2-426467f4f81b%2FImage_8.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-id="9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-type="text">
          <div>
    <p>A group of 14 American and four Indian mountaineers was assembled. In totality, they represented the cream of a mountaineering generation. Among the Americans, some of the more famous climbers were Dr Robert Schaller, Tom Frost and Jim McCarthy. The Indian contingent consisted of Captain M S Kohli, Sonam Wangyal, H C S Rawat and G S Bhangu. All four had been members of the successful 1965 Indian Everest Expedition, which had put a record nine climbers on the summit. They were in fact enlisted for this covert expedition just a few days after returning from Everest. Together, the entire group was no less than a mountaineering dream team.</p><p>After having sworn their respective oaths of secrecy, the climbing team was flown to Mount McKinley in Alaska, the highest mountain in North America, to prepare for the arduous expedition ahead. While all of them were without doubt among the most experienced climbers at the time, they were rather new to the more idiosyncratic aspect of the expedition â€“ that of dealing with nuclear material.</p><p>American climber Jim McCarthy was appointed as the designated member of the team who would handle the plutonium rods. Through the summer of 1965, officials from Americaâ€™s Atomic Energy Commission trained McCarthy to load and unload the device without disturbing its deadly occupant. Other team members were briefed on the dangers of their special load as well, and ways to ensure minimum exposure to the deadly radioactive isotopes.</p><p>All climbers were going to be paid $1,000 per month, a hefty amount in the 1960s. While there would be personal gratification from having been of service to their respective nations, they were on no account to tell anyone about the nature of their expedition. The cover for the entire team was that they were a joint Indo-American mountaineering team conducting research for high-altitude flight for the American Air Force. Before departing for India, the covert operation was finally given its official codename: Operation Hat.</p>
  </div>
</div>



      <div id="inf-card-368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-id="368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-type="image">
  <div>
  <figure>
    <img alt="A Nanda Devi Temple at Munsiyari. This particular temple, and itâ€™s idol inside, is among the oldest of Uttarakhand" src="https://images.assettype.com/indynetwork%2F2020-09%2F49dfca8c-132b-43f5-b063-81b86f25e855%2FImage_5.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-id="5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-type="text">
          <div>
    <p><strong>Into the Sanctuary of the Goddess</strong></p><p>In an effort to attract minimal attention, most of the mountaineers were flown into base camp by helicopter in September 1965. However, the climbing equipment, rations, and of course the listening device itself â€” stored inside a solid lead casket â€” were transported in the time-honoured fashion, carried by nearly 150 <em>dotial</em> porters through the Rishi Ganga gorge. The special load did not go unnoticed among the porters, and apart from its unusual weight, many of them alleged to have felt heat emanating from the casket. Mounted on poles, some climbers later noted its uncanny resemblance to the Biblical Ark of the Covenant, in the manner it was transported as well as the supreme power it possessed.</p><p>After having established themselves at the base of the mountain, the mountaineers methodically began making their way up Nanda Devi. Establishing a series of camps along the climbing route, the team was finally positioned to make an attempt on the summit in the middle of October. It was then that catastrophe struck.</p><p>A violent storm hit the mountain and made it impossible to continue. The summit team, along with the device, was encamped just 2,000 feet below their objective. The extreme conditions, however, greatly endangered their position. Keeping in mind the extreme volatility of such storms, Captain Kohli â€” the leader of the climbing team â€” called for an immediate retreat.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="65e7e1e4-a3b0-4ec4-9aaa-c4696502703a" data-card-version-id="344b6037-e7b7-4181-b199-8bea1745da05">
        
      <div id="inf-card-6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-id="6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-type="text">
          <div>
    <p>Carrying the 56 kg listening device in deteriorating weather conditions at 23,000 feet was going to be a Herculean task. Prioritising the need for a quick descent to minimise the risk to the lives of his fellow climbers, Kohli decided to ditch the equipment in the high camp. He reasoned that another expedition could always be mounted when weather conditions improved, in order to retrieve the device. On the other hand, the life of a fellow climber was irreplaceable.</p><p>Thus, with all the climbers having safely descended, the expedition came to an end. Being late in the year, the weather window to climb Nanda Devi was now closed. Any new expedition would have to bide their time till the following year. The nuclear device too, abandoned on a high precipice of the mountain, would have to wait.</p><p><strong>Plan B</strong></p><p>With the arrival of spring in 1966, a second expedition was launched to locate the equipment, and most importantly the nuclear device, that had been left the previous autumn. The composition of the climbing team was more or less the same, and soon they were scouring the slopes of Nanda Devi, trying to find their highly valuable and potentially dangerous belongings. But it was all …</p></div></div></div></div></div></div></article></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</a></em></p>]]>
            </description>
            <link>https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547123</guid>
            <pubDate>Sat, 26 Dec 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dunning-Kruger Effect Is Probably Not Real]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25546787">thread link</a>) | @ingve
<br/>
December 26, 2020 | https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real | <a href="https://web.archive.org/web/*/https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I want the Dunning-Kruger effect to be real. First described in<a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.77.6.1121"> a seminal 1999 paper</a> by David Dunning and Justin Kruger, this effect has been the darling of journalists who want to explain why dumb people don’t know they’re dumb. There’s even<a href="https://youtu.be/BdnH19KsVVc"> video of a fantastic pastiche</a> of Turandot’s famous aria, <i>Nessun dorma,</i> explaining the Dunning-Kruger effect. “They don’t know,” the opera singer belts out at the climax, “that they don’t know.”</p>

<p>I was planning on writing a very short article about the Dunning-Kruger effect and it felt like shooting fish in a barrel. Here’s the effect, how it was discovered, what it means. End of story.</p>

<p>But as I double-checked the academic literature, doubt started to creep in. While trying to understand the criticism that had been leveled at the original study, I fell down a rabbit hole, spoke to a few statistics-minded people, corresponded with Dr. Dunning himself, and tried to understand if our brain really was biased to overstate our competence in activities at which we suck... or if the celebrated effect was just a mirage brought about by the peculiar way in which we can play with numbers.</p>

<p>Have we been overstating our confidence in the Dunning-Kruger effect?</p>

<h5><b>A misunderstood effect</b></h5>

<p>The most important mistake people make about the Dunning-Kruger effect, according to Dr. Dunning, has to do with who falls victim to it. “The effect is about us, not them,” he wrote to me. “The lesson of the effect was always about how we should be humble and cautious about ourselves.” The Dunning-Kruger effect is not about dumb people. It’s mostly about all of us when it comes to things we are not very competent at.</p>

<p>In a nutshell, the Dunning-Kruger effect was originally defined as a bias in our thinking. If I am terrible at English grammar and am told to answer a quiz testing my knowledge of English grammar, this bias in my thinking would lead me, according to the theory, to believe I would get a higher score than I actually would. And if I excel at English grammar, the effect dictates I would be likely to slightly underestimate how well I would do. I might predict I would get a 70% score while my actual score would be 90%. But if my actual score was 15% (because I’m terrible at grammar), I might think more highly of myself and predict a score of 60%. This discrepancy is the effect, and it is thought to be due to a specific problem with our brain’s ability to assess its skills.</p>

<p>This is what student participants went through for Dunning and Kruger’s research project in the late 1990s. There were assessments of grammar, of humour, and of logical reasoning. Everyone was asked how well they thought they did and everyone was also graded objectively, and the two were compared.</p>

<p>Since then, many studies have been done that have reported this effect in other domains of knowledge. Dr. Dunning tells me he believes the effect “has more to do with being <i>misinformed</i> rather than uninformed.” If I am asked the boiling point of mercury, it is clear my brain does not hold the answer. But if I am asked what is the capital of Scotland, I may think I know enough to say Glasgow, but it turns out it’s Edinburgh. That’s misinformation and it’s pushing down on that confidence button in my brain.</p>

<p>So case closed, right? On the contrary. In 2016 and 2017, two papers were published in a mathematics journal called <i>Numeracy</i>. In them, the authors argued that the Dunning-Kruger effect was a mirage. And I tend to agree.</p>

<h5><b>The effect is in the noise</b></h5>

<p>The<a href="https://scholarcommons.usf.edu/numeracy/vol9/iss1/art4/"> two</a><a href="https://scholarcommons.usf.edu/numeracy/vol10/iss1/art4/"> papers</a>, by Dr. Ed Nuhfer and colleagues, argued that the Dunning-Kruger effect could be replicated by using random data. “We all then believed the [1999] paper was valid,” Dr. Nuhfer told me via email. “The reasoning and argument just made so much sense. We never set out to disprove it; we were even fans of that paper.” In Dr. Nuhfer’s own papers, which used both computer-generated data and results from actual people undergoing a science literacy test, his team disproved the claim that most people that are unskilled are unaware of it (“a small number are: we saw about 5-6% that fit that in our data”) and instead showed that both experts and novices underestimate and overestimate their skills with the same frequency. “It’s just that experts do that over a narrower range,” he wrote to me.</p>

<p>Wrapping my brain around all this took weeks. I recruited a husband-and-wife team, Dr. Patrick E. McKnight (from the Department of Psychology at George Mason University, also on the advisory board of Sense About Science and STATS.org) and Dr. Simone C. McKnight (from Global Systems Technologies, Inc.), to help me understand what was going on. Patrick McKnight not only believed in the existence of the Dunning-Kruger effect: he was teaching it to warn his students to be mindful of what they actually knew versus what they thought they knew. But after replicating Dr. Nuhfer’s findings using a different platform (the statistical computing language R instead of Nuhfer’s Microsoft Excel), he became convinced the effect was just an artefact of how the thing that was being measured was indeed measured.</p>

<p>We had long conversations over this as I kept pushing back. As a skeptic, I am easily enticed by stories of the sort “everything you know about this is wrong.” That’s my bias. To overcome it, I kept playing devil’s advocate with the McKnights to make sure we were not forgetting something. Every time I felt my understanding crystallize, doubt would creep in the next day and my discussion with the McKnights would resume.</p>

<p>I finally reached a point where I was fairly certain the Dunning-Kruger effect had not been shown to be a bias in our thinking but was just an artefact. Here then is the simplest explanation I have for why the effect appears to be real.</p>

<p>For an effect of human psychology to be real, it cannot be rigorously replicated using random noise. If the human brain was predisposed to choose heads when a coin is flipped, you could compare this to random predictions (heads or tails) made by a computer and see the bias. A human would call more heads than the computer would because the computer is making random bets whereas the human is biased toward heads. With the Dunning-Kruger effect, this is not the case. Random data actually mimics the effect really well.</p>

<p>The effect as originally described in 1999 makes use of a very peculiar type of graph. “This graph, to my knowledge, is quite unusual for most areas of science,” Patrick McKnight told me. In the original experiment, students took a test and were asked to guess their score. Therefore, each student had two data points: the score they thought they got (self-assessment) and the score they actually got (performance). In order to visualize these results, Dunning and Kruger separated everybody into quartiles: those who performed in the bottom 25%, those who scored in the top 25%, and the two quartiles in the middle. For each quartile, the average performance score and the average self-assessed score was plotted. This resulted in the famous Dunning-Kruger graph.</p>

<p><img height="627" width="725" src="https://www.mcgill.ca/oss/files/oss/figure_1_3.png" alt=""></p>

<p>Plotted this way, it looks like those in the bottom 25% thought they did much better than they did, and those in the top 25% underestimated their performance. This observation was thought to be due to the human brain: the unskilled are unaware of it. But if we remove the human brain from the equation, we get this:</p>

<p><img height="451" width="1086" src="https://www.mcgill.ca/oss/files/oss/figure_2_1.png" alt=""></p>

<p>The above Dunning-Kruger graph was created by Patrick McKnight using computer-generated results for both self-assessment and performance. The numbers were random. There was no bias in the coding that would lead these fictitious students to guess they had done really well when their actual score was very low. And yet we can see that the two lines look eerily similar to those of Dunning and Kruger’s seminal experiment. A<a href="https://www.sciencedirect.com/science/article/pii/S019188690100174X"> similar simulation</a> was done by Dr. Phillip Ackerman and colleagues three years after the original Dunning-Kruger paper, and the results were similar.</p>

<p>Measuring someone’s perception of anything, including their own skills, is fraught with difficulties. How well I think I did on my test today could change if the whole thing was done tomorrow, when my mood might differ and my self-confidence may waver. This measurement of self-assessment is thus, to a degree, unreliable. This unreliability--sometimes massive, sometimes not--means that any true psychological effect that does exist will be measured as smaller in the context of an experiment. This is called attenuation due to unreliability. “Scores of books, articles, and chapters highlight the problem with measurement error and attenuated effects,” Patrick McKnight wrote to me. In his simulation with random measurements, the so-called Dunning-Kruger effect actually becomes <i>more</i> visible as the measurement error increases. “We have no instance in the history of scientific discovery,” he continued, “where a finding improves by increasing measurement error. None.”</p>

<h5><b>Breaking the spell</b></h5>

<p>When I plug “Dunning-Kruger effect” into Google News, I get over 8,500 hits from media outlets like <i>The New York Times</i>, <i>New Scientist</i>, and the CBC. So many simply endorse the effect as a real bias of the brain, so it’s no wonder that people are not aware of the academic criticism that has existed since the effect was first published. It’s not just Dr. Nuhfer and his <i>Numeracy </i>papers. Other academic critics have pointed the finger, for example, at regression to the mean.</p>

<p>But as Patrick McKnight points out, regression to the mean occurs when the same measure is taken over time and we track its evolution. If I take my temperature every morning and one day spike a fever, that same measure will (hopefully) go down the next day and return to its mean value as my fever abates. That’s regression to the mean. But in the context of the Dunning-Kruger effect, nothing is measured over time, and self-assessment and performance are different measures entirely, so regression to the mean should not apply. The unreliability of the self-assessment …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</a></em></p>]]>
            </description>
            <link>https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546787</guid>
            <pubDate>Sat, 26 Dec 2020 22:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of NPM scripts]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25546460">thread link</a>) | @efortis
<br/>
December 26, 2020 | https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
In 2016, Sam Saccone <a rel="noopener" target="_blank" href="https://www.kb.cert.org/vuls/id/319816">discovered a vulnerability</a> that
allows adversaries to run arbitrary scripts when installing an NPM package of
theirs. As mitigation, NPM co-founder Laurie Voss <a rel="noopener" target="_blank" href="https://blog.npmjs.org/post/141702881055/package-install-scripts-vulnerability">
suggests</a>:
</p>
<ul>
<li>
<b>Option 1</b>: adding <code>--ignore-scripts</code> when running <code><span>npm</span>
install</code>
</li>
<li>
<b>Option 2</b>: permanently adding <code>ignore-scripts=true</code> to <code>.npmrc</code>
</li>
</ul>
<p>
UI Drafter uses the latter because it avoids having to
remember the flag everytime. But that option disables NPM
<code>"scripts"</code>. Therefore, we end up with two alternatives:
</p>
<ul>
<li>
<b>Option A</b>: overriding: <code><span>npm</span> run --ignore-scripts=false
<b>test</b></code>
</li>
<li>
<b>Option B</b>: using this shell script or a <a href="#-Makefile">Makefile</a>:
</li>
</ul>
<pre><span>#!/bin/sh</span>

<span>case</span> <span>$1</span> <span>in</span>
  <b>dev</b>)   ./make-dev.js <span>;;</span>
  <b>test</b>)  mocha <span>"src/**/*.test.js"</span><span></span> <span>;;</span>
  <b>lint</b>)  eslint src <span>;;</span>
  <b>slint</b>) stylelint <span>"src/**/*.css"</span><span></span> <span>;;</span>

  <b>prod</b>)  <span>time</span> ./make-production.js <span>;;</span>
  <b>all</b>)   <span>$0</span> <b>test</b> &amp;&amp; <span>$0</span> <b>lint</b> &amp;&amp; <span>$0</span> <b>slint</b> &amp;&amp; <span>$0</span> <b>prod</b> <span>;;</span>

  *)     <span>echo</span> <span>"Invalid task: <span>$1</span>"</span><span>;</span> <span>exit</span> <span>1</span> <span>;;</span>
<span>esac</span>
</pre>
<p>Which can be ran as:</p>
<pre>./<span>make</span> <b>test</b>
</pre>
<p>
If the package is not globally installed, prefix the path. For example:
</p>
<pre><b>lint</b>) <span>node_modules/.bin/</span>eslint src <span>;;</span>
</pre>
<h3>Overriding at installation</h3>
<p>
If you need to install packages that install binary dependencies, or rely
on running an NPM script, override the <code>.npmrc</code>:
</p>
<pre><span>npm</span> install <span>--ignore-scripts=false</span> <i>package-name</i>
</pre>

<p>
EDIT: (Dec/27/2020) As suggested in the <a rel="noopener" target="_blank" href="https://news.ycombinator.com/item?id=25546460">Hacker News thread</a>:
</p>
<a id="-Makefile"></a>
<details>
<summary>
<h3>
Makefile
</h3>
</summary>
<pre><b>dev</b>:
	./make-dev.js
<b>test</b>:
	mocha <span>"src/**/*.test.js"</span>
<b>lint</b>:
	eslint src
<b>slint</b>:
	stylelint <span>"src/**/*.css"</span>

<b>prod</b>:
	sh -c 'time ./make-production.js'

<b>all</b>: test lint slint prod

<span>.PHONY: dev test lint slint prod all</span>
</pre>
<pre><span>make</span> <b>test</b>
</pre>
</details>
</article>
<article>
<hr>
<h2>Engineering Blog</h2>
<ul>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/isolated-tls-certificate-creation">Isolated Creation of Let's Encrypt TLS Certificates</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/bitwise-table-lookup">Bitwise Table Lookup</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering">More…</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546460</guid>
            <pubDate>Sat, 26 Dec 2020 21:06:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Pinterest SEO: An insider's guide]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25546430">thread link</a>) | @jmilinovich
<br/>
December 26, 2020 | https://blog.aesthetic.com/blog/pinterest-guide/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/pinterest-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>Pinterest is an extraordinarily powerful tool for consumers, but is still misunderstood by marketers. I worked at Pinterest for 2 years helping build their core content understanding technology, and learned a lot about what makes for a successful Pinterest marketing strategy. I hope this guide helps demystify how marketers can get the most from Pinterest as a marketing channel. </p><p>If you have any questions, please <a href="https://twitter.com/intent/tweet?text=Hey%20@jmilinovich">Tweet @jmilinovich</a>! </p><ol><li><a href="#Why-is-Pinterest-marketing-important">Why is Pinterest marketing important?</a></li><li><a href="#How-does-Pinterest-marketing-work">How does Pinterest marketing work?</a></li><li><a href="#How-to-create-a-Pinterest-marketing-plan">How to create a Pinterest marketing plan?</a></li><li><a href="#How-to-make-Pinterest-pins">How to make Pinterest pins?</a></li><li><a href="#How-to-make-Pinterest-Pins-popular">How to make Pinterest Pins popular?</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2>Pinterest as a distribution channel</h2><p>Pinterest is a powerful tool that helps people all over the world discover ideas for things to do in their lives. Whether it’s finding recipes, figuring out what to wear, finding new beauty tips or literally any other use case imaginable… people are doing it on Pinterest.</p><p>While search engines like Google focus on the bottom of the purchase funnel (ie, once someone knows that they have a need and are actively looking for it) and social networks like Facebook and Instagram focus on the top of the funnel (ie, when customers are passively looking to consume content with no intent), Pinterest is the only place on the internet that lets marketers reach consumer in the consideration phase. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/2514c6be4877df4b7599580c5af4d1c3c2f54f86/453eb/img/posts/pinterest-guide/consideration.png" alt="The marketing consideration funnel"></p><p>This creates a big opportunity for businesses to get their products, goods and services in front of potential buyers while they’re deciding what they want to buy, but haven’t made the decision yet. That’s one of the most powerful things about Pinterest- people go there to find ideas, not just to make purchasing decisions. This means that marketers are able to reach consumers before they’ve made up their mind on what they’re looking to do.</p><h2>Pinterest as a source of inbound links</h2><p>While the most clear first-order effect to a strong Pinterest presence is creating a powerful new referral traffic source, there’s also a misunderstood but very powerful second-order effect: creating more inbound links to your website. </p><p>Have you noticed how no matter what you search for, it seems that you almost always see Pinterest results on the first page of Google? Pinterest’s core growth strategy has been about getting excellent at SEO, or search engine optimization. Practically speaking this means that the company has spent a lot of effort creating millions of high quality landing pages with the explicit purpose of being indexed by Google. Each of these landing pages shows dozens of Pins, and each contains a link to that Pin’s page on Pinterest. </p><p>As your content becomes more popular, it will begin showing up on more of Pinterest’s SEO pages, which means that it will be more readily indexed by Google. Since Google gives Pinterest’s domain a high authority and quality score, this means that over time you will start to accumulate some of this authority if your Pins are shown in prominent places. So, getting good at Pinterest doesn’t just help improve your Pinterest referral traffic, it can also improve your traffic from places like Google! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbc3082cbd708936207fcc8fed30415b5077ee03/32add/img/posts/pinterest-guide/pinterest-results.png" alt="Example of Pinterest landing pages"></p><h2>Pinterest is a search engine</h2><p>The most important thing to understand about Pinterest is that at its core it’s a search engine, not a social network.  People don’t use Pinterest to “follow” specific brands but rather to follow interests and search for ideas. A “Pin” is simply a visual bookmark to a webpage, and under the hood Pinterest’s technology stack is focused on figuring out what interests a Pin is about, and which users are interested in which interests. Content on Pinterest isn’t temporal like other social networks, but evergreen like on Google.</p><h2>Help Pinterest understand your content</h2><p>This means that the most important thing to get right for Pinterest marketing is helping Pinterest understand what interests your Pins are about. This means that the key underlying concept for Pinterest marketing is to create Pins for all of your web content, and then make sure that Pinterest has a clear understanding of what interests they align to. </p><p>Once Pinterest understands what a given Pin is about, it can start showing it to users to see how they interact with it. If they engage with it (ie, Save it to one of their boards or Click on it to see the underlying content), Pinterest uses this as a positive sign that this is quality content and will begin showing it to more people. </p><p>As such, one of the most important things to get right is having a clear strategy for how to communicate to Pinterest what your Pins are about and getting engagement signals on the Pins early. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/db6e047a9650880cd7f0be4c4718c0791790c2e0/18ef8/img/posts/pinterest-guide/pinterest-interests.png" alt="Example of Pinterest interests"></p><h2>Choose your Interests</h2><p>The most critical thing to get right in your Pinterest marketing plan is determining what Interests are most important to your business. There are <a href="https://docs.google.com/spreadsheets/d/1HxL-0Z3p2fgxis9YBP2HWC3tvPrs1hAuHDRtH-NJTIM/edit#gid=118370875">over 10,000 interests on Pinterest today</a>, ranging from highly broad to highly specific. Start by brainstorming what interests your target audience has today, as well as what interests your content is actually about. Look for the overlap of these two sets and choose the 10-15 that have the most promise to focus in on first. </p><h2>Create your Boards</h2><p>Once you’ve chosen the interests that you want to focus on, the next step is to decide on the architecture of your Pinterest for Business account. Pinterest accounts for users and businesses alike are defined by the boards that they create and post Pins to. You can think of a board as a folder of visual bookmarks that are public by default. When someone looks at your Pinterest account, the fastest way that they will understand what you’re about is by the names of the boards that you create. </p><p>Start by creating boards whose names are the same as the 10-15 interests you chose to focus on. It’s OK if they have more words in them as well, but make sure that the Interest name itself is very prominent. Make sure that each board has a very specific description that explains the core ideas that you’ll be pinning to the board.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/dadf2e2890dde22bbff64a7ded8e0dcf6b592fe9/31afa/img/posts/pinterest-guide/boards.png" alt="Example of Pinterest boards"></p><p>Next, you need to decide what content to start posting onto these boards. </p><h2>Pinning existing content</h2><p>There are only two kinds of Pins on Pinterest: Pins from your own website, and Pins from other people’s websites. Both are equally important to a strong Pinterest strategy. The first thing you should do is to fill your boards with Pins that are already on Pinterest and were created by other people. Spend some time saving 20-30 Pins to each of your boards. As you do this, Pinterest will also begin recommending new Pins in your homefeed that are related to what you’ve been Pinning. </p><p>The reason you’re seeing the Pins that Pinterest is recommending to you is because Pinterest already knows a lot about them and has a high confidence that users like you will find them interesting. When you save them to your boards, you’re giving Pinterest even more signal about what your board is about. This is extremely important, because Pinterest learns a lot about new Pins based on the other Pins that it shows up on boards with. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/a3580f834d291668bd22cae46f7854ddb0106853/de8da/img/posts/pinterest-guide/existing-pin.png" alt="Example of Pinterest pins"></p><p>Each week you should also continue to save new, existing content to your boards to keep giving Pinterest more signal and context for what your Pins are about. </p><h2>Pinning your own content</h2><p>Once you create a good base of existing Pins on your boards, you can start to plan your strategy for getting your own original content into Pinterest. First, go through all of your existing website content and map out what content would be relevant for the Pinterest audience. Generally speaking, the best content will be things like blog posts or eCommerce product landing pages. You should skip things like your homepage, about page, contact us page or other informational pages that don’t provide highly specific and useful content about a specific concept. </p><p>On social networks, it’s important that you have a steady pace of posting content into your feed so that you stay top of mind and also don’t inundate followers by posting 100 things at once. Pinterest is much more like Google, however, where you want them to know about your content upfront and all at once. </p><p>You should post all of your existing, relevant content to Pinterest upfront and then consistently add new content as it’s published online. Save it to the most relevant board to give Pinterest a clear understanding of what your content’s about. You can also post it to more than one board if it’s relevant to multiple categories. </p><p>The Pins that perform best on Pinterest have been created specifically for Pinterest following their <a href="https://business.pinterest.com/en-gb/content/creative-best-practices/">creative best practices</a>. Practically speaking this means that each Pin will require some editing work within a graphics editor tool. Generally speaking, each Pin can take anywhere from 5-20 minutes to create by hand if using a tool like Photoshop, Canva or Adobe Spark. This can be quite burdensome, especially if you’re trying to create dozens or hundreds of Pins for your site. </p><p><a href="https://www.aesthetic.com/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=pinterest-guide">Aesthetic’s software</a> is able to generate on-brand Pinterest Pins from a company’s website automatically. Simply enter a URL, and our app will create dozens of variations of graphics to promote that webpage, including several that follow Pinterest’s best practices guide. We’ve seen our users cut down the time it takes to create a Pin by 95% using our tool. </p><p>Once you’ve created your Pin graphics, you can upload them into the Pinterest system. Add the URL for each Pin along with a detailed description that touches upon what the Pins about and ideally mentions the specific interests that it’s related to. Post these to the right boards, and you’re off to the races! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/4ab1dd02738de6695f0118fd169a78c4e10d21bb/09e8b/img/posts/pinterest-guide/aesthetic-pins.png" alt="Example of Pinterest pins made with Aesthetic"></p><p>Once you’ve uploaded your content to Pinterest, you will see the impressions slowly start to trickle in as the system understands more about what your content’s about. Generally speaking it can take months for new content on Pinterest to get enough exposure for Pinterest to determine whether it’s sufficiently interesting enough for it to be promoted more widely within the system.</p><p>Another option to fast track the distribution of your Pins is to run small budget ads for your own Pins, targeting the Interests that they’re related …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aesthetic.com/blog/pinterest-guide/">https://blog.aesthetic.com/blog/pinterest-guide/</a></em></p>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/pinterest-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546430</guid>
            <pubDate>Sat, 26 Dec 2020 21:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with IP address parsing]]>
            </title>
            <description>
<![CDATA[
Score 491 | Comments 144 (<a href="https://news.ycombinator.com/item?id=25545967">thread link</a>) | @mr_tyzic
<br/>
December 26, 2020 | https://blog.dave.tf/post/ip-addr-parsing/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/ip-addr-parsing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-12-25 00:00:00 +0000 UTC">December 25, 2020</time>
</p>
		


		

		<p>In my quest to write a fast IPv4+6 parser, I wrote a
slow-but-I-think-correct parser, to use as a base of comparison. In
doing so, I discovered more cursed IP address representations that I
was previously unaware of. Let’s explore together!</p>

<p>We start out simple, with IPv4 and IPv6 in what I’ll call their
“canonical form”: <code>192.168.0.1</code> and <code>1:2:3:4:5:6:7:8</code>. Various specs
call these “dotted quad” (more specifically, “dotted decimal”),
dot-separated fields each representing 1 byte; and “colon-hex”,
colon-separated fields each representing 2 bytes.</p>

<p>The first bits of complexity come from IPv6. In canonical form, common
addresses would end up with long runs of zeros in the middle. So, <code>::</code>
allows you to elide 1 or more 16-bit blocks of zeros: <code>1:2::3:4</code> means
<code>1:2:0:0:0:0:3:4</code></p>

<p>Next up, for cursed historical reasons, IPv6 permits you to write the
final 32 bits of the address in dotted quad form. Effectively, you can
splat an IPv4 address onto the end of IPv6 addresses!
<code>1:2:3:4:5:6:77.77.88.88</code> means <code>1:2:3:4:5:6:4d4d:5858</code>.</p>

<p>And of course, you can combine the two! <code>fe80::1.2.3.4</code> means <code>fe80:0:0:0:0:0:102:304</code></p>

<p>The existence of <code>::</code> introduces an annoying edge case in parsing: the
<code>::</code> can be at the start or end of the address, and the “empty” side
of the address is not one of the 16-bit fields. <code>::1</code> means
<code>0:0:0:0:0:0:0:1</code>, <code>1::</code> means <code>1:0:0:0:0:0:0:0</code>, and <code>::</code> means
<code>0:0:0:0:0:0:0:0</code>. This is a natural consequence of the <code>::</code> rule, but
it makes the parser slightly more annoying to write.</p>

<p>One final rule for IPv6: technically, each colon-hex field is 4 hex
digits, but you can elide leading zeros, as I’ve been doing so
far. Fully canonically, <code>::</code> is
<code>0000:0000:0000:0000:0000:0000:0000:0000</code>. My apologies to trypophobic
readers.</p>

<p>That’s it for IPv6, mostly. Now, on to IPv4!</p>

<p>Fun fact, the textual representation of IPv4 was never standardized in
any document before IPv6 needed a grammar for its weirdo “trailing
dotted quad” notation. So, it’s a de-facto standard that boils down to
mostly “what did 4.2BSD understand?”, and “what did other OSes keep
when they copied 4.2BSD?”</p>

<p>And hoo boy, strap yourselves in, because 4.2BSD sure had some whacky
opinions! Let’s use <code>192.168.140.255</code> as an example. That’s an IPv4
address that people would look at and go “yes, that sure is an IPv4
address.” How else can we write that exact same address?</p>

<p>This is the same IP address: <code>3232271615</code>. You get that by
interpreting the 4 bytes of the IP address as a big-endian unsigned
32-bit integer, and print that. This leads to a classic parlor trick:
if you try to visit <a href="http://192.168.140.255/">http://3232271615</a> , Chrome will load
<a href="http://192.168.140.255/">http://192.168.140.255</a>.</p>

<p>Okay, but that’s sort-of sensible, right? An IPv4 address is 4 bytes,
so printing it as a single number is a bit human-unfriendly, but
broadly plausible, right?</p>

<p>How about <code>0300.0250.0214.0377</code> ? That’s still the same
address. Dotted quad, except each field is written out in octal.</p>

<p>And if octal is supported, you might be wondering about hex. And you’d
be right! <code>192.168.140.255</code> is also <code>0xc0.0xa8.0x8c.0xff</code>, according
to 4.2BSD.</p>

<p>Now, remember before we had CIDR (Classless Inter-Domain Routing) ?
IPv4 addresses were Class A, Class B or Class C. It was a weird time.</p>

<p>And that weird time made it into IP addresses! The familiar
<code>192.168.140.255</code> notation is technically the “Class C” notation. You
can also write that address in “class B” notation as <code>192.168.36095</code>,
or in “Class A” notation as <code>192.11046143</code>. What we’re doing is
coalescing the final bytes of the address into either a 16-bit or a
24-bit integer field.</p>

<p>This, by the way, is why utilities like <code>ping</code> will accept weird
looking addresses like <code>127.1</code> for <code>127.0.0.1</code>. Unlike IPv6, it’s not
doing some kind of “missing fields are zero” expansion. <code>127.1</code> is the
Class A notation for “host 1 of network 127”, where the 1 is a 24-bit
number.</p>

<p>And finally, we come to one last bit of unspecified behavior: do IPv4
addresses permit an unlimited number of leading zeros in each quad? Or
is there a maximum of 3 digits? <code>001.002.003.004</code> is universally
recognized as valid. What about
<code>0000000001.0000000002.0000000003.000000004</code>?</p>

<p>You might also be wondering if either of these numbers should be read
in as octal, since we said earlier that a leading zero might be
interpreted as octal. It depends! There are implementations that do
both, but <em>most</em> modern implementations have abandoned the octal and
hex notation, and treat leading 0s as decimal.</p>

<p>The leading zero debate also infects IPv6, to some extent. Is
<code>000001::00001.00002.00003.00004</code> is a valid IPv6 address (“common”
form <code>1::1.2.3.4</code>, or <code>1::102:304</code>)? Most modern parsers seem to allow
an unlimited amount of leading zeros in their representations,
probably because they’re leaning on some “parse integer” library that
implements that behavior.</p>

<p>And so, we reach the bitter end. If you want to <em>truly</em> parse IP
addresses, this is the bullshit you have to put up with.</p>

<p>Currently, my slow reference parser jettisons a lot of old baggage,
and sticks to what I think is a sensible subset of these
possibilities. It understands:</p>

<ul>
<li>Classic v4 dotted decimal, with any number of leading zeros.</li>
<li>It does not process Class A/B notation, or hex or octal notation.</li>
<li>It does not process the “uint32 to the knee” representation.</li>
<li>For IPv6, it understands canonical colon-hex form, as well as ::
and trailing-IPv4 style (where the trailing IPv4 follows the same
rules as the previous tweet). Each field is allowed any number of
leading zeros.</li>
</ul>

<p>I’m on the fence about that last one, the “IPv6 with an embedded
dotted decimal” form. My reference parser (Go’s <code>net.ParseIP</code>)
understands it, but it’s not really that useful any more in the real
world. At the dawn of IPv6, the idea was that you could upgrade an
address to IPv6 by prepending a pair of colons, as in <code>::1.2.3.4</code>, but
modern transition mechanisms no longer offer anything as clear-cut as
this, so the notation doesn’t really show up in the wild.</p>

		
	</div>

	
</div></div>]]>
            </description>
            <link>https://blog.dave.tf/post/ip-addr-parsing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545967</guid>
            <pubDate>Sat, 26 Dec 2020 19:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Partial order and non-Boolean logic]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25545543">thread link</a>) | @okaleniuk
<br/>
December 26, 2020 | https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>
Numbers. Numbers are easy. All you need to know to sort them out is that
	</p>
	<ul>
	<li>
if 1 ≤ 2 and 2 ≤ 3 then 1 ≤ 3;
	</li>
	<li>
either 4 ≤ 5 or 5 ≤ 4...
	</li>
	<li>
...or both, but if 6 ≤ 6 and 6 ≤ 6 then 6 = 6.
	</li>
	</ul>
	<p>
Oh, shit! I forgot to put a smart face on. Let's start over.
	</p>
	<p>
A <b><span id="index_total_order">total order</span></b>, also known as <b><span id="index_linear_order">linear order</span></b> is a relation “≤” on a set <span>S</span>. For <span>a, b, c ∈ S</span>, the three properties hold.
	</p>
	<p>
The first one is called <b><span id="index_transitivity">transitivity</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The second one is <b><span id="index_connexity">connexity</span></b>.
	</p>
	<p>
a ≤ b ∨ b ≤ a
	</p>
	<p>
And the third one is <b><span id="index_antisymmetry">antisymmetry</span></b>.
	</p>
	<p>
a ≤ b ∧ b ≤ a ⇒ a = b
	</p>
	<p>
With rules established for <span>≤</span>, we can also tell either <span>a &lt; b</span> or <span>a &gt; b</span> or <span>a = b</span> for every <span>a</span> and <span>b</span>.
	</p>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Result</th></tr>
<tr><td>a = b</td>		<td id="e"></td></tr>
<tr><td>a &lt; b</td>	<td id="l"></td></tr>
<tr><td>a &gt; b</td>	<td id="g"></td></tr>
<tr><td>a ≠ b</td>	<td id="ne"></td></tr>
<tr><td>a ≤ b</td>	<td id="le"></td></tr>
<tr><td>a ≥ b</td>	<td id="ge"></td></tr>
</tbody></table>
	<p>
Real numbers are comparable. That implies that you can sort them. Of course, not only numbers are comparable. Names are comparable and sortable in alphabetical order. Skyscrapers are comparable and sortable by height. A lot of things are comparable and sortable.
	</p>
	<p>
But a few things aren't. Like the <a href="https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html">intervals, we use to represent numbers with errors</a>. We use them when we don't know the exact number <span>x</span> but we know its error <span>ε</span> and therefore have all the reasons to believe that it's jammed somewhere between <span>x<sub>1</sub></span> and <span>x<sub>2</sub></span> where
	</p>
	<p>
x<sub>1</sub> = x − ε
<br>
x<sub>2</sub> = x + ε
	</p>
	<p>
These intervals are helpful when we want to measure a computational error of some calculation or to see if some algorithm is stable enough. They aren't comparable or truly sortable though.
	</p>
	<p>
Consider two overlapping intervals. Let's say, <span>[3, 6]</span> and <span>[5, 8]</span>. We know that the fist interval actually means a number between  <span>3</span> and  <span>6</span>. The second — another number between <span>5</span> and <span>8</span>. Intuitively, the latter should be greater than the former. But what if it is  <span>5</span> and the former is  <span>6</span>? Then it's obviously less. There is a chance they are even equal. 
	</p>
	<p>
So there is some kind of order, for instance, <span>[6, 8]</span> is definitely greater than  <span>[3, 5]</span>. But this order doesn't hold for every possible pair of intervals.
	</p>
	<p>
This makes things unpleasant. For the very least, we can't now use binary logic since all the comparisons now return three states. E. g. <span>a ≤ b</span> can now be <span>true</span>, <span>false</span> or <span>none of the above</span>.
	</p>
	<p>
Consequently, this means the conventional <span>if... else</span> statement now has to be redesigned. And all the algorithms that use it.
	</p>
	<p>
We wouldn't have to give up binary logic completely if we agree to “split” the semantics of the predicates into two. For every predicate on the two intervals, we can still say whether the numbers they represent definitely suffice the predicate, or whether they possibly do so.
	</p>
	<p>
For instance, <span>[3, 5]</span> is definitely less than <span>[6, 8]</span>, and <span>[3, 6]</span> is possibly less than <span>[5, 8]</span>. The most unpleasant case for us is when intervals overlap. Everything is indefinite, and everything is possible then.
	</p>
<br>
	
	
<br>

<table>
<tbody><tr><th>Predicate</th><th>Deffinitely</th><th>Possibly</th></tr>
<tr><td>a = b</td>		<td id="de"></td>		<td id="pe"></td></tr>
<tr><td>a &lt; b</td>	<td id="dl"></td>		<td id="pl"></td></tr>
<tr><td>a &gt; b</td>	<td id="dg"></td>		<td id="pg"></td></tr>
<tr><td>a ≠ b</td>	<td id="dne"></td>	<td id="pne"></td></tr>
<tr><td>a ≤ b</td>	<td id="dle"></td>	<td id="ple"></td></tr>
<tr><td>a ≥ b</td>	<td id="dge"></td>	<td id="pge"></td></tr>
</tbody></table>

	<p>
Still, every <span>if... else</span> works. Within its semantics that is. However, the algebra behind the logic isn't yet Boolean. Now <span>¬ (a &lt; b) ≢ a ≥ b</span>. Computational algorithms may be technically built using the same building blocks as if the intervals were numbers but that's it.
	</p>

	<p>
Speaking of building stuff. Let's talk about programming. Programming non-Boolean interval logic in C++ or Python is fairly easy. You have to reimplement every predicate for the interval type — and you're golden!
	</p>
	<pre id="code_1">struct Interval {
    Number lb; // lower bound
    Number ub; // upper bound
}

// Interval-specific predicates.
bool coincide(const Interval&amp; l, const Interval&amp; r){
    return l.lb == r.lb &amp;&amp; l.ub == r.ub;
}

bool intersect(const Interval&amp; l, const Interval&amp; r){
    return (l.ub &gt;= r.lb &amp;&amp; l.lb &lt;= r.ub)
        || (r.ub &gt;= l.lb &amp;&amp; r.lb &lt;= l.ub);
}

// The "definite" interval logic.
// The relation should keep for every number in l and in r.
bool operator==(const Interval&amp; l, const Interval&amp; r){
    return l.lb == l.ub &amp;&amp; coincide(l, r);
}

bool operator&lt;(const Interval&amp; l, const Interval&amp; r){
    return l.ub &lt; r.lb;
}

bool operator&gt;(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l;
}

bool operator&lt;=(const Interval&amp; l, const Interval&amp; r){
    return l.lb &lt; r.ub &amp;&amp; l.ub == r.lb;
}

bool operator&gt;=(const Interval&amp; l, const Interval&amp; r){
    return r &lt;= l;
}

bool operator!=(const Interval&amp; l, const Interval&amp; r){
    return r &lt; l || l &lt; r;
}</pre>
	<p>
Nobody cares about the relationship between predicates being Boolean-ish. They are all just some arbitrary functions so with them, you can easily define either the “definite” logic or the “possible” one. You can have both if you define them for different but interchangeable types. It's all a little verbose but doable.
	</p>
	<p>
It gets a little bit more tricky in Rust which relies on the notion of order pretty much.
	</p>
	<p>
The comparison operators for a custom type are usually introduced using an <a href="https://doc.rust-lang.org/std/cmp/trait.Ord.html">std::cmp::Ord</a> trait. It requires that:
	</p>
	<p>
∀ a, b: (a &lt; b) ⊕ (a = b) ⊕ (a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
The first reads as for every <span>a</span> and <span>b</span>, one and only one is true: either <span>(a &lt; b)</span> or <span>(a = b)</span> or <span>(a &gt; b)</span>. This doesn't work for us. When intervals intersect, in “definite” logic none of the predicates are true. And in the “possible” logic, they all are.
	</p>
	<p>
Luckily, there is another more relaxed trait that represents not total order, but <span id="index_partial_order">partial order</span>: <a href="https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html">std::cmp::PartialOrd</a>. Which only requires <b><span id="index_asymmetry">asymmetry</span></b> (not even antisymmetry) and transitivity (we've seen it before):
	</p>
	<p>
a &lt; b ⇒ ¬(a &gt; b)
<br>
a ≤ b ∧ b ≤ c ⇒ a ≤ c.
	</p>
	<p>
Аnd for the “definite” logic, this works.
	</p>
	<pre id="code_2">impl std::cmp::PartialEq for RB32{
    // the same as operator == in C++ or __eq__(self, other) in Python
    fn eq(&amp;self, other: &amp;Self) -&gt; bool {
        self.lb == other.lb &amp;&amp; self.ub == other.ub
    }
}

impl std::cmp::PartialOrd for RB32{
    // this is usually enough to replace all the rest
    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;std::cmp::Ordering&gt; {
        if self.ub &lt; other.lb {
            Some(std::cmp::Ordering::Less)
        } else if self.lb &gt; other.ub {
            Some(std::cmp::Ordering::Greater)
        } else if self.lb == other.lb &amp;&amp; self.ub == other.ub {
            Some(std::cmp::Ordering::Equal)
        } else {
            None // this is what differentiates Ord and PartialOrd
        }
    }

    // but since in out logic, (a &lt; b) ∨ (a = b) ≢ a ≤ b,
    // we have to define ≤ and ≥ explicitly.
    fn le(&amp;self, other: &amp;Self) -&gt; bool {
        (self.lb == other.lb &amp;&amp; self.lb == self.ub) ||
        (self.ub == other.ub &amp;&amp; other.lb == other.ub)
    }
    fn ge(&amp;self, other: &amp;Self) -&gt; bool {
        (self.ub == other.ub &amp;&amp; self.lb == self.ub) ||
        (self.lb == other.lb &amp;&amp; other.lb == other.ub)
    }
}</pre>

	<p>
The code is less verbose than in C++ or Python, and it would have been even less so if we were relying on Boolean algebra. With it, you don't even have to write <span>le</span> or <span>ge</span> methods explicitly, <span>cmp</span> is enough. With Boolean algebra, Rust can deduce the rest for you.
	</p>
	<p>
Ok, but that was the “definite” logic. But what about the “possible”?
	</p>
	<p>
I'm afraid, for this particular task, Rust comes short. In the “possible” interval logic, the intersecting intervals may be <span>a &lt; b</span>, and <span>a = b</span>, and <span>a &gt; b</span>, all at the same time. Every predicate is true since everything is possible. You can't program that with Rust <a href="https://doc.rust-lang.org/std/cmp/enum.Ordering.html">Ordering</a>. However, this is not a flaw, this is a design choice.
	</p>
	<p>
Non-Boolean logics are rare, and relations more general than partial order are almost never useful. If you really really want this kind of logic, you can still implement it using functions and not operators. At the same time, you can expect that if a class implements the <span>std::cmp::Ord</span> trait, then all the sorting algorithms will work with it correctly. While in C++, a sorting algorithm will run on anything with the <span>operator&lt;</span> reloaded with no correctness guaranteed or even pinky-promised.
	</p>
	<h2>
Conclusion
	</h2>
	<p>
Non-Boolean logics are rare but not extinct. Interval logic is one example. Sometimes, you can implement a logic you want within total order or partial order but sometimes even that isn't enough and you need an even more general relation. With operator overloading, you have the freedom to go there but you also have less assurance when working within the total order.
	</p>

	


	
	</div></div>]]>
            </description>
            <link>https://wordsandbuttons.online/partial_order_and_non_boolean_logic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545543</guid>
            <pubDate>Sat, 26 Dec 2020 19:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s the best non-smart TV sold today?]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 257 (<a href="https://news.ycombinator.com/item?id=25544831">thread link</a>) | @thomas
<br/>
December 26, 2020 | https://helpatmyhome.com/best-non-smart-tv/ | <a href="https://web.archive.org/web/*/https://helpatmyhome.com/best-non-smart-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="What’s The Best Non-Smart TV Sold Today?"><div itemprop="text">
<p>With the industry-wide transition to smart TVs many of us have felt like there is no option but to get one. And the walls are closing in — it seems like almost every TV sold today is a smart one, which means a lack of control of what’s happening on our device, the possibility of the company deciding one day to show us ads (as Samsung as done), and the certainty that our viewing and usage data is being sent off to all sorts of third parties. </p>



<p>The solution? Buy a dumb TV!</p>



<h2><span id="What_Is_A_Dumb_TV">What Is A Dumb TV?</span></h2>



<p>The alternative to Smart TVs are, of course, non-smart TVs or, as people have taken to calling them, dumb TVs. These are televisions without an internet connection, without built-in HBO Max or Disney, without Amazon Alexa, and lacking apps of any kind. A dumb TV is the television equivalent of a flip phone. </p>



<p>Just because your TV is dumb doesn’t mean you can’t use Roku or Apple TV, etc. In this case you are simply opting to plug those devices into your TV via HDMI rather than having them built in. In almost all cases the plugged in device is better than having the software version built into your TV, so you are making your TV be smart instead of being forced to have one. </p>



<h2><span id="Why_Not_Buy_An_Old_TV">Why Not Buy An Old TV?</span></h2>



<p>You can definitely buy an old TV to solve this problem instead of hunting around for an increasingly rare non-smart in 2021. Televisions age pretty well, so as long as you can find something relatively high quality and made in the last 8 (or so) years you are good to go. </p>



<p>You’ll mainly need to ensure that your older model is in good physical condition, has enough HDMI ports to suit a current user, has no burn-in or wear issues, has a working remote, doesn’t have cracked or wrecked speakers, and that the color hasn’t gone crazy over time. You’ll also want to make sure your TV is an LED TV, so it’s power efficient and looks great, instead of using an outdated technology (like plasma). </p>



<p>For example, I have a Samsung dumb TV from 2012 (or so) that works perfectly well, has sufficient volume, and completely gets the job done. It was a good TV when I bought it, and it’s a great TV now, because it doesn’t have any of the features that I don’t want — and can’t avoid — today. </p>



<h2><span id="Just_Dont_Connect_It_To_the_Internet">Just Don’t Connect It To the Internet</span></h2>



<p>A smart TV can’ the smart without an internet connection so one thing you can do to get a dumb TV is to simply not connect it to your WiFi network. Your TV will will work since it’s connect through coax but the rest of the data cannot flow because the television doesn’t have an internet connection!</p>



<p>You can then go ahead and add a Nvidia Shield or Apple TV and connect that to the internet. This way the auxiliary devices will have internet connection <em>while you are using them</em>, but the TV itself (the hypervisor in this scenario) stays blissfully unaware of that internet connection. </p>



<p>Note, there have been scattered reports of some TVs, including those from Samsung, simply searching for open WiFi signals and attempting to connect to them, but this is an extreme and user-hostile example that hopefully won’t be repeated (assuming its true in the first place).</p>



<p>Some smart TV will force you to connect them to the internet for firmware updates and will resort to frequent nagging to get you to do this, but very few will force you to do it or not work entirely without the connection (yet). </p>



<h2><span id="Best_Dumb_TVs">Best Dumb TVs</span></h2>



<p>Here are some intelligent picks in non-smart TVs. </p>



<figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg" alt="" width="433" height="256" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-350x207.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-768x454.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1536x908.jpg 1536w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter.jpg 1782w" sizes="(max-width: 433px) 100vw, 433px"></figure><h2><span id="Sceptre_50-inch_4K_LED_TV">Sceptre 50-inch 4K LED TV</span></h2>



<p>Sceptre has generally been considered a mid-tier TV company, but they have done a good job of not transitioning entirely to Smart TVs. The <a href="https://amzn.to/3mZUDAp" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3mZUDAp" data-wpel-link="external">Sceptre U518CV-UM</a> is a 50-inch 4K that’s completely non-smart TV that is from the 2019 model year, so you are getting recent tech without the connectivity features that you don’t want.</p>



<ul><li>4K Television (3840×2160, UHD resolution)</li><li>Dimensions: 44.6 x 28.5 x 10.8 inches</li><li>Weight: 29.3 pounds</li></ul><p>Sceptre has the same non-smart TV in larger sizes as well, <a href="https://amzn.to/2VGHSyD" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VGHSyD" data-wpel-link="external">up to 65-inches</a> if you need the extra size or have a big room to fill. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg" alt="" width="341" height="207" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-350x213.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-768x466.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing.jpg 1258w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<h3><span id="Insignia_55-inch_Class_LED">Insignia 55-inch Class LED</span></h3>



<p>If you live near a Best Buy then you will have access to their house brand, Insignia. The Insignia 55-inch (NS-55D420NA20) is a LED-lit 1080p television that sells for about $300. It’s devoid of smart features but it has three HDMI ports and was first released in 2019. </p>



<p>This line of Insignia dumb TVs is sold from 19 inches up to 58 inches so there will be a TV for every room size. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg" alt="" width="451" height="275" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-350x214.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-768x469.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns.jpg 1170w" sizes="(max-width: 451px) 100vw, 451px"></figure></div>



<h2><span id="Samsung_Business_BER_43-Inch">Samsung Business BER 43-Inch </span></h2>



<p>This <a href="https://amzn.to/2VFc4di" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VFc4di" data-wpel-link="external">Samsung Business line TV</a> (model BE43R) is a full HD (1080p) LED TV that is part of Samsung’s commercial line, but doesn’t have the crazy price tag to reflect it. Commercial TV’s can get super experience for what seems like a normal TV — and for what will function like a normal TV if you are simply using it like one! The smartest feature this TV has is the ability to play images from a USB stick.</p>



<p>This TV has all the features you’d expect from a normal television, like HDMI input, and isn’t missing anything obvious. For example it still has integrated speakers and 1080p (1920×1080) resolution.</p>



<p>If you are open to commercial TVs there <a href="https://amzn.to/3gdIm8R" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3gdIm8R" data-wpel-link="external">are a huge number to explore</a>.</p>



<h2><span id="Dumb_TV_Alternatives">Dumb TV Alternatives</span></h2>



<p>Of course there are other ways to avoid a smart TV. Here are some bright ideas…</p>



<ul><li><strong>Projector:</strong> The smart device revolution has really come to projectors yet, so you can watch your TV and movies through a projector without having to worry about your privacy or ads</li><li><strong>Monitor:</strong> Computer monitors haven’t gotten smart (since they are connected to something smart) so if you watch television on a computer monitor you’ll have no need to worry about built-in Alexa or Google Home</li><li><strong>Business TV (aka Commercial Display):</strong> A <a href="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" target="_blank" rel="noreferrer noopener nofollow external" title="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" data-wpel-link="external">business-focused TV</a> (something you’d see hung in an office or airport and playing CNN all day on mute) is designed for simplicity and long-lasting performance. These haven’t yet gotten smart and will likely stay dumb for years as they need to have error- and update-free operation for years on end</li><li><strong>Outdoor TV:</strong> For some reason outdoor and weatherproof televisions have yet to go smart. Here is a <a href="https://amzn.to/3lMr0B0" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3lMr0B0" data-wpel-link="external">good example of one from Furrion</a>.</li></ul><h2><span id="FAQs">FAQs</span></h2>


<div><ol><li><strong>Can I use PiHole or a similar device to block the ads and privacy leaks from my smart TV?</strong><p>You'd think this would work, but manufacturers have gotten wise to the PiHole and other methods of blocking tracking and advertising injection so, no, you really can't. At this point many manufacturers will take measures like building ads into the core technology of their software so blocking ads will break other features. Also many manufacturers will hardcode their DNS to their preferred vendor, not allowing you to override their option with your PiHole. </p></li></ol></div></div></article></main></div></div></div>]]>
            </description>
            <link>https://helpatmyhome.com/best-non-smart-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544831</guid>
            <pubDate>Sat, 26 Dec 2020 17:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers automate this, so why don't airlines?]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 150 (<a href="https://news.ycombinator.com/item?id=25543861">thread link</a>) | @leejo
<br/>
December 26, 2020 | https://leejo.github.io/2020/12/26/EZY1952/ | <a href="https://web.archive.org/web/*/https://leejo.github.io/2020/12/26/EZY1952/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				<center>Lawyers Automate This, So Why Don't Airlines?</center>
			</p>
			<div>
				<center>
				
				
				

				December 26, 2020 (
				
				
					<a href="https://leejo.github.io/2020/11/19/some_kind_of_paypal_refund_scam/">Prev</a>
				
				/
				
					Next
				
			)

			
				</center>
			</div>
			<p>My working title for this blog post was “Why I’ll Never Fly With easyJet Again”, but that was far too clickbaity. Also it’s probably worth prefixing this post with two things. The first being the caveat that whether or not i ever fly with easyJet again is immaterial to their business, given that the model of budget airlines is one of opportunistic sales. Their loyalty programmes are minimal to non-existent<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (although that may change in the near future<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>) because the nature of their passengers is not one of loyalty. When you’re looking for a short haul cheap flight you’re unlikely to be attracted to schemes that only benefit you after years, or hundreds of thousands of air miles, worth of loyalty.</p>

<p>The reality of the budget airlines is they don’t have to worry about losing future passengers, thousands of them even, because there will always be enough replacement passengers. Budget airlines’ flights average above a 90% occupancy rate<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>So the point of me never flying with easyJet again is not because i am under any illusion that it will be detrimental to their business, it won’t, but rather to protect <em>myself</em> should the situation happen again. They’re not the first airline to make my “list”, but the others have reasons that aren’t interesting enough to require a blog post.</p>

<p>What i am hoping with this post is that it gives the reader enough information that, should they find themselves in a similar situation, they are more informed as to their options and the potential ramifications of the choice they make. This is going to affect more travelers when the UK leaves the EU.</p>

<p>The second prefix is that easyJet recently posted their first year of losses<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">4</a></sup>, due to the current global situation. I started writing this post sometime in 2019, way before the pandemic royally fucked the airline industry. It’s arguable that the airline industry being royally fucked was only a matter of time, and the consequences of <em>that</em> could mean the details here are now even more relevant - It may become even harder to claim refunds and compensation from them in the future. Airline companies will probably double down on their approach to handling compensation claims to avoid yet more financial loss.</p>

<p><strong>EZY1952</strong></p>

<p>On 23rd December 2018 my partner and I were due to fly from Geneva to Manchester on easyJet flight EZY1952, aircraft registration G-EZRU, which was scheduled to depart at 16:50 CET and arrive at 17:50 GMT. I had booked these flights a couple of months earlier, which combined with the date of our departure and return lead to a total cost of 619.38 CHF.</p>

<p>The 600+ CHF didn’t include any of the optional extras, priority boarding, seat choice, checked bags, etc. It was the “basic” cost of the “cheap” flights. This cost is four to five times more than the normal cost of this route, as I said due to the relatively late booking (two months in advance) and the dates of the flights. This route is normally far cheaper:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/typical_cost.png"></p>

<p>Anyway, given the alternatives and the limited options for our dates these were the flights we settled on and decide the cost was worth it to spend Xmas with the family. The flight was delayed by just a few minutes, which isn’t unusual for this route, but then took off as normal at 17:14:05 CET.</p>

<p>A few moments after take off, the literal wheels no longer being on the ground part of it, I felt my ears pop quite suddenly. That might not be taken as unusual either, but I live at altitude and my ears don’t normally pop on flights. The plane then spent several minutes in low cloud, another unusual thing given the cloud line is normally cut through quicker. I turned to my partner and suggested that something was off.</p>

<p>A couple of minutes later the pilot informed us that the flight would be returning to Geneva airport as the cabin pressure system, and its backup, had failed. Given the potentially catastrophic consequences of the cabin pressure system failing at cruising altitude, I considered that everyone on the plane had been very lucky.</p>

<p>The plane landed safely at Geneva airport at 17:41:00 CET, meaning a total flight time of about 25 minutes<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. I contacted my parents to let them know we wouldn’t be arriving as planned and would keep them informed as to any updates:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/messages_to_mum.png"></p>

<p>We remained on the plane, after the pilot informed us that the technical crew were going to look into the issue. We were then told the parts would be replaced/fixed and this would take three to four hours. At this point I knew that we would not be flying until the next day as a) it was now 19:00 and Geneva airport has strict limitations on flights after 22:00, and b) it would be massively irresponsible of the airline to let this plane fly without a more comprehensive test that would probably take longer than the three to four hour estimate<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<p>Since it was going to take a few hours all passengers disembarked and returned to the departure gate. I’m not sure how long we were on the plane, while it was on the ground, but looking at the evidence I kept afterwards it appears that we were on it for approximately one hour fifteen minutes. This is from the time it landed to receiving a text message from easyJet apologising for the delay:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/sorry_for_delay.png"></p>

<p>As soon as we got back into the gate I sat down and checked to see if there were any other flights available. Sure enough there was: we could get a one way easyJet flight to Liverpool, so I booked two seats for a total of 189.26 CHF. This flight would depart at 21:25 CET and arrive at 22:20 GMT, four hours and thirty minutes after our original arrival time.</p>

<p>It should be said at this point I was reasonably confident of a few things:</p>

<ul>
  <li>It was highly unlikely the original fight was going to depart that night</li>
  <li>In fact, it would probably be delayed until the next afternoon</li>
  <li>We would have all the inconvenience of that, and lose one third of our time in the UK</li>
  <li>Given the original arrival time was delayed by more than three hours we were covered by EU Regulation 261/2004</li>
  <li>So the airline would have to compensate €250 for each of us, which would at least cover the alternate flights I had booked</li>
</ul>

<p>I was correct on four out of five of these:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/delayed_overnight.png"></p>

<p>Our flight to Liverpool went without issue, and we weren’t the only people to have rebooked from the delayed flight as we overheard some other passengers explaining their situation to the cabin crew<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>.</p>

<p><strong>Contacting easyJet Customer Service</strong></p>

<p>The next day I used easyJet’s contact form to submit a claim under EC261/2004 regulations. I knew this was going to take a long time so figured I may as well start the process as soon as possible. My claim was made on the basis that the original flight had been delayed overnight and I had booked alternate travel arrangements to get to my destination.</p>

<p>I considered the cost of the original flights a sunk cost. I wasn’t actually interested in compensation and I just wanted the cost of the alternate flights refunded, which came in at less than half the amount of compensation EC261/2004 would give considering the length of the delay to the original flight.</p>

<p>The response from easyJet came back quickly, the next day: <em>As you were a no show on the flight we would not be able t reimburse the costs for alternate transport.</em> - well that didn’t read like a response by someone/thing that had actually looked into the details. We had shown up for the flight, given we were on it when the pressure systems failed, and clearly we wouldn’t show up for the <em>rescheduled</em> flight if we arranged alternate transport as we can’t be in two places at once.</p>

<p>I assumed this was just a first level response of “refuse all claims, through a semantic dispute, because this will cause a not insignificant number of people to give up”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>. The contact form doesn’t have a place to describe the reason for the claim in detail so I needed to call easyJet to explain.</p>

<p><strong>EU Regulation 261/2004</strong></p>

<p>I’ll spare you too much detail, as you can search for it if you want to (or read a summary on <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation">Wikipedia</a>). Essentially - EU 261/2004 allows compensation if your flight is from or to an EU/EAA area and is either delayed or cancelled [less than one week before the flight date]. The level of compensation depends on the distance of the flight.</p>

<p>In this particular case the delay was more than four hours, and the flight was less than 1,500km, so would qualify for €250 compensation (per passenger).</p>

<p>The regulation also says the passengers must be given assistance, and in this particular case of the flight being delayed overnight would mean hotel accommodation and transport between the airport and the hotel. This was Geneva two days from Xmas, so that would probably mean another €250.</p>

<p>So a reasonable estimate is easyJet would be paying in the region of €750 per passenger on this delayed flight. Given it was full (at least to my recollection) easyJet were looking at a bill of at least €100,000 for compensation + accommodation expenses<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup>.</p>

<p>To go off on a tangent slightly - all of this is going to be up in the air when the UK leaves the EU. Of course that depends what the UK government <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation#Brexit_and_British_Consumers">decide to do about it</a>. Given everything else on their plate don’t be surprised if this one gets forgotten about until the claims start to appear.</p>

<p><strong>Contacting easyJet Customer Service Again</strong></p>

<p>As my claim, via easyJet’s web form, was rejected relatively quickly I decided to pick up the phone and see if speaking to someone would make a difference. I explained the situation and they agreed to pass this on to someone who would look at it in more detail, given the time of year this would take a few days at the least.</p>

<p>A couple of weeks later I received an email stating “Unfortunately as you were a no show on the transferred flight there is no reimbursement for EUC216 Compensation”. But also “As a goodwill gesture I have created a flight voucher to the value of the 51.90 GBP”.</p>

<p>Slightly odd - no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leejo.github.io/2020/12/26/EZY1952/">https://leejo.github.io/2020/12/26/EZY1952/</a></em></p>]]>
            </description>
            <link>https://leejo.github.io/2020/12/26/EZY1952/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543861</guid>
            <pubDate>Sat, 26 Dec 2020 15:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want us to be compliant, not secure]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25543818">thread link</a>) | @_wldu
<br/>
December 26, 2020 | https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some years ago, I worked for an organization that was involved in federally funded research. Occasionally, government IT auditors (or contractors that they hired) would visit our facilities to audit our systems.</p><p>We used a wide variety of operating systems on several different hardware platforms. Windows, Mac, Linux and Unix systems were scattered throughout our buildings running on desktops, laptops, workstation, servers and embedded devices. We ran several different Linux distributions, multiple Unixes and had standardized on <a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> hashes to store user passwords.</p><p>Bcrypt was released in 1999 and is based on <a href="https://www.schneier.com/academic/blowfish/">Blowfish</a>. Blowfish is a fast, unpatented block cipher that was developed by <a href="https://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> in 1993. It’s been in the mainline Linux kernel since the 2.6 release.</p><p>Bcrypt is a fast and efficient password hash yet strong and hard to attack. At the time, it was the strongest password hash that we could use and as an added bonus, it worked on all of our Linux and Unix systems.</p><p>One particular year, the IT auditors realized that we were using bcrypt hashes to store user passwords. They said that it was not a <a href="https://csrc.nist.gov/publications/detail/fips/180/4/final">FIPS approved algorithm</a> and by using bcrypt hashes, we were noncompliant. They insisted that we switch to a SHA-2 based hash function right away.</p><p>We ran several tests that demonstrated how the SHA-2 hashes were much easier to crack than the bcrypt hashes (see below for a performance comparison on a semi-modern GPU). But the auditors were adamant. They did not care that the approved algorithms were weaker. Nothing would change their decision.</p><p>In their minds, it was a simple matter. Bcrypt was not on the list. It was not an approved hashing function. They would not discuss it further.</p><p>To satisfy the auditors, we switched all the systems to an approved SHA-2 hash function. This action probably made our systems more vulnerable to cyber attacks.</p><p>A colleague said, <em>“They want us to be compliant, not secure.”</em></p><div><pre><code data-lang="bash">$ hashcat -b -m <span>1800</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>1800</span> - sha512crypt $6$, SHA512 <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 5000<span>)</span>

Speed.#1.........:    <span>78810</span> H/s <span>(</span>51.36ms<span>)</span> @ Accel:512 Loops:128 Thr:32 Vec:1
</code></pre></div><div><pre><code data-lang="bash">$ hashcat -b -m <span>3200</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>3200</span> - bcrypt $2*$, Blowfish <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 32<span>)</span>

Speed.#1.........:     <span>7570</span> H/s <span>(</span>41.13ms<span>)</span> @ Accel:16 Loops:8 Thr:8 Vec:1
</code></pre></div><ul><li><a href="https://www.go350.com/tags/compliance">compliance</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543818</guid>
            <pubDate>Sat, 26 Dec 2020 14:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking out loud to yourself is a technology for thinking]]>
            </title>
            <description>
<![CDATA[
Score 373 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25543656">thread link</a>) | @headalgorithm
<br/>
December 26, 2020 | https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>This week, a woman</strong> was strolling in my street, walking in circles and speaking out loud to herself. People were looking at her awkwardly, but she didnâ€™t particularly mind, and continued walking vigorously and speaking.</p>
<p>Yes, that woman was me.</p>
<p>Like many of us, I talk to myself out loud, though Iâ€™m a little unusual in that I often do it in public spaces. Whenever I want to figure out an issue, develop an idea or memorise a text, I turn to this odd work routine. While itâ€™s definitely earned me a reputation in my neighbourhood, itâ€™s also improved my thinking and speaking skills immensely. Speaking out loud is not only a medium of communication, but a technology of thinking: it encourages the formation and processing of thoughts.</p>
<p>The idea that speaking out loud and thinking are closely related isnâ€™t new. It emerged in Ancient Greece and Rome, in the work of such great orators as Marcus Tullius Cicero. But perhaps the most intriguing modern development of the idea appeared in the essay â€˜On the Gradual Formation of Thoughts During Speechâ€™ (1805) by the German writer Heinrich von Kleist. Here, Kleist describes his habit of using speech as a thinking method, and speculates that if we canâ€™t discover something just by thinking about it, we might discover it in the process of free speech. He writes that we usually hold an abstract beginning of a thought, but active speech helps to turn the obscure thought into a whole idea. Itâ€™s not thought that produces speech but, rather, speech is a creative process that in turn generates thought. Just as â€˜appetite comes with eatingâ€™, Kleist argues, â€˜ideas come with speakingâ€™.</p>
<p>A lot of attention has been given to the power of spoken self-affirmation as a means of self-empowerment, in the spirit of positive psychology. However, as Kleist says, talking to oneself is also a cognitive and intellectual tool that allows for a wider array of possible use cases. Contemporary theories in cognition and the science of learning reaffirm Kleistâ€™s speculations, and show how self-talk contributes not only to motivation and emotional regulation, but also to some higher cognitive functions such as developing metacognition and reasoning.</p>
<p>If self-talk is so beneficial, why arenâ€™t we talking to ourselves all the time? The dynamic between self-talk and inner speech might explain the dubious social status of the former. Self-talk is often seen as the premature equivalent of <a href="https://aeon.co/essays/our-inner-narrator-gives-us-continuity-and-a-sense-of-self" rel="noopener">inner speech</a> â€“ the silent inner voice in our mind, which has prominent cognitive functions in itself. The tendency to express our inner thoughts in actual self-talk, typical of children, is internalised, and transforms to voiceless inner speech in adulthood, as the developmental psychologist Lev Vygotsky already speculated in the 1920s.</p>
<p>Self-talk is deemed legitimate only when done in private, by children, by people with intellectual disabilities, or in Shakespearean soliloquies</p>
<p>Vygotskyâ€™s view stood in opposition to a competing one from the psychological school known as behaviourism, which saw childrenâ€™s self-talk as a byproduct of (supposedly) less competent minds. But Vygotsky claimed that self-talk has an active mental role. He observed children performing tasks while speaking to themselves out loud, and reached the conclusion that their â€˜private-talkâ€™ is a crucial stage in their mental development. Gradually, a childâ€™s interaction with others turns into an uttered conversation with the self â€“ self-talk â€“ until it becomes muted inner speech in adulthood. Vygotskyâ€™s successors, such as the psychologist Charles Fernyhough, have <a href="https://charlesfernyhoughcom.wordpress.com/the-voices-within/" rel="nofollow noreferrer noopener">demonstrated</a> that inner speech goes on to facilitate an array of cognitive functions including problem solving, activating working memory and preparation for social encounters. It is inner speech rather than self-talk, then, that has been the focus of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4538954/" rel="nofollow noreferrer noopener">research</a> in adults.</p>
<p>However, the internalisation of self-talk isnâ€™t necessarily evidence of cognitive maturity: rather, it could represent the degeneration of an essential cognitive skill in the face of social pressure. The sociologist Erving Goffman noted that self-talk is taboo because it is a â€˜threat to intersubjectivityâ€™ and violates the social assumption that speech is communicative. As he wrote in his <a href="https://www.upenn.edu/pennpress/book/715.html" rel="nofollow noreferrer noopener">book</a> <em>Forms of Talk</em> (1981): â€˜There are no circumstances in which we can say: â€œIâ€™m sorry, I canâ€™t come right now, Iâ€™m busy talking to myselfâ€�.â€™ Self-talk is deemed legitimate only when done in private, by children, by people with intellectual disabilities, or in Shakespearean soliloquies.</p>
<p><strong>Yet self-talk enjoys</strong> certain advantages over inner speech, even in adults. First, silent inner speech often appears in a â€˜condensedâ€™ and partial, form; as Fernyhough has <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4538954/" rel="nofollow noreferrer noopener">shown</a>, we often tend to speak to ourselves silently using single words and condensed sentences. Speaking out loud, by contrast, allows the retrieval of our thoughts in full, using rhythm and intonation that emphasise their pragmatic and argumentative meaning, and encourages the creation of developed, complex ideas.</p>
<p>Not only does speech retrieve pre-existing ideas, it also creates new information in the retrieval process, just as in the process of writing. Speaking out loud is inventive and creative â€“ each uttered word and sentence doesnâ€™t just bring forth an existing thought, but also triggers new mental and linguistic connections. In both cases â€“ speech and writing â€“ the materiality of language undergoes a transformation (to audible sounds or written signs) which in turn produces a mental shift. This transformation isnâ€™t just about the translation of thoughts into another set of signs â€“ rather, it adds new information to the mental process, and generates new mental cascades. Thatâ€™s why the best solution for creative blocks isnâ€™t to try to think in front of an empty page and simply wait for thoughts to arrive, but actually to continue to speak and write (anything), trusting this generative process.</p>
<p>Speaking out loud to yourself also increases the dialogical quality of our own speech. Although we have no visible addressee, speaking to ourselves encourages us to actively construct an image of an addressee and activate oneâ€™s â€˜theory of mindâ€™ â€“ the ability to understand other peopleâ€™s mental states, and to speak and act according to their imagined expectations. Mute inner speech can appear as an inner dialogue as well, but its truncated form encourages us to create a â€˜secretâ€™ abbreviated language and deploy mental shortcuts. By forcing us to articulate ourselves more fully, self-talk summons up the image of an imagined listener or interrogator more vividly. In this way, it allows us to question ourselves more critically by adopting an external perspective on our ideas, and so to consider shortcomings in our arguments â€“ all while using our own speech.</p>
<p>You might have noticed, too, that self-talk is often intuitively performed while the person is moving or walking around. If youâ€™ve ever paced back and forth in your room while trying to talk something out, youâ€™ve used this technique intuitively. Itâ€™s no coincidence that we walk when we need to think: evidence <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4879139/" rel="nofollow noreferrer noopener">shows</a> that movement enhances thinking and learning, and both are activated in the same centre of motor control in the brain. In the influential subfield of cognitive science concerned with â€˜embodiedâ€™ cognition, one prominent claim is that actions themselves are constitutive of cognitive processes. That is, activities such as playing a musical instrument, writing, speaking or dancing donâ€™t start in the brain and then emanate out to the body as actions; rather, they entail the mind and body working in concert as a creative, integrated whole, unfolding and influencing each other in turn. Itâ€™s therefore a significant problem that many of us are trapped in work and study environments that donâ€™t allow us to activate these intuitive cognitive muscles, and indeed often even encourage us to avoid them.</p>
<p>Technological developments that make speaking seemingly redundant are also an obstacle to embracing our full cognitive potential. Recently, the technology entrepreneur Elon Musk declared that we are marching towards a near future without language, in which weâ€™ll be able to communicate directly mind-to-mind through neural links. â€˜Our brain spends a lot of effort compressing a complex concept into words,â€™ he said in a recent interview, â€˜and thereâ€™s a lot of loss of information that occurs when compressing a complex concept into words.â€™ However, what Musk chalks up as â€˜effortâ€™, friction and information loss also involves cognitive gain. Speech is not merely a conduit for the transmission of ideas, a replaceable medium for direct communication, but a generative activity that enhances thinking. Neural links might ease intersubjective communication, but they wonâ€™t replace the technology of thinking-while-speaking. Just as Kleist realised more than 200 years ago, there are no pre-existing ideas, but rather the heuristic process by which speech and thought co-construct each other.</p>
<p>So, the next time you see someone strolling and speaking to herself in your street, wait before judging her â€“ she might just be in the middle of intensive work. She might be wishing she could say: â€˜Iâ€™m sorry, I canâ€™t chat right now, Iâ€™m busy talking to myself.â€™ And maybe, just maybe, you might find yourself doing the same one day.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/talking-out-loud-to-yourself-is-a-technology-for-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543656</guid>
            <pubDate>Sat, 26 Dec 2020 14:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executable PNGs]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25543191">thread link</a>) | @todsacerdoti
<br/>
December 26, 2020 | https://djharper.dev/post/2020/12/26/executable-pngs/ | <a href="https://web.archive.org/web/*/https://djharper.dev/post/2020/12/26/executable-pngs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>
<time datetime="2020-12-26">Saturday, December 26, 2020</time>
</p>
<figure>
<a href="https://djharper.dev/img/peek.webm"><video src="https://djharper.dev/img/peek.webm" loop="true" width="100%" title="The pixels have been adjusted in colour slightly." autoplay=""></video></a>
<figcaption><br>It's an image <i>and</i> a program</figcaption>
</figure>
<p>A few weeks ago I was reading about <a href="https://www.lexaloffle.com/pico-8.php">PICO-8</a>, a fantasy games console with limited constraints. What really piqued my interest about it was the novel way games are distributed, you encode them into a PNG image. This includes the game code, assets, everything. The image can be whatever you want, screenshots from the game, cool artwork or just text. To load them you pass the image as input to the PICO-8 program and start playing.</p>
<p>This got me thinking, wouldn’t it be cool if you could do that for programs on Linux? No! I hear you cry, that’s a dumb idea, but whatever, herein lies an overview of possibly the dumbest things I’ve worked on this year.</p>
<h2 id="encoding">Encoding</h2>
<p>I’m not entirely sure what PICO-8 is actually doing, but at a guess it’s probably use <a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> techniques to ‘hide’ the data within the raw bytes of the image. There are a lot of resources out there that explain how Steganography works, but the crux of it is quite simple, your image your want to hide data into is made up of bytes, an image is made up of pixels. Pixels are made up of 3 Red Green and Blue (RGB) values, represented as 3 bytes. To hide your data (the “payload”) you essentially “mix” the bytes from your payload with the bytes from the image.</p>
<p>If you just replaced each byte in your cover image with the bytes from your payload, you would end up with sections of the image looking distorted as the colours probably wouldn’t match with what your original image was. The trick is to be as subtle as possible, or <em>hide in plain sight</em>. This can be achieved by <em>spreading</em> your payload bytes over the bytes of the cover image by using the <em>least significant bits</em> to hide them in. In other words, make subtle adjustments to the byte values so the colour changes are not drastic enough to be perceptive by the human eye.</p>
<p>For example if your payload was the letter <code>H</code>, represented as <code>01001000</code> in binary (72), and your image contained a series of black pixels</p>
<figure>
<a href="https://djharper.dev/img/byte-replace1.png"><img src="https://djharper.dev/img/byte-replace1.png" title="The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit"></a>
<figcaption><br>The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit</figcaption>
</figure>
<p>The output is two-and-a-bit pixels that are slightly less black than before, but can you tell the difference?</p>
<figure>
<a href="https://djharper.dev/img/pixels1.png"><img src="https://djharper.dev/img/pixels1.png" title="The pixels have been adjusted in colour slightly."></a>
<figcaption><br>The pixels have been adjusted in colour slightly.</figcaption>
</figure>
<p>Well, an exceptionally trained colour connoisseur might be able to, but in reality these subtle shifts can really only be noticed by a machine. Retrieving your super secret <code>H</code> is just a matter of reading 8 bytes from the resulting image and re-assembling them back into 1 byte. Obviously hiding a single letter is lame, but this can scale to anything you want, a super secret sentence, a copy of <em>War and Peace</em>, a link to your soundcloud, the go compiler, the only limit is the amount of bytes available in your cover image as you’ll require at least 8x whatever your input is.</p>
<h2 id="hiding-programs">Hiding programs</h2>
<p>So, back to the whole linux-executables-in-an-image thing, that old chestnut. Well, seeing as executables are just bytes, they can be hidden in images. Just like in the PICO-8 thing.</p>
<p>Before I could achieve this I decided to write my own <a href="https://github.com/djhworld/steg">Steganography library</a> and <a href="https://github.com/djhworld/stegtool">tool</a> to support encoding and decoding data into PNGs. Yes, there are lots of steganography libraries and tools out there but I learn better by building.</p>
<figure>
<div><pre><code data-lang="bash">$ stegtool encode <span>\
</span><span></span>--cover-image htop-logo.png <span>\
</span><span></span>--input-data /usr/bin/htop <span>\
</span><span></span>--output-image htop.png
$
$ <span>echo</span> <span>"Super secret hidden message"</span> | stegtool encode <span>\ </span>
--cover-image image.png <span>\
</span><span></span>--output-image image-with-hidden-message.png
$ stegtool decode --image image-with-hidden-message.png
Super secret hidden message</code></pre></div>
</figure>
<p>As it’s all written in <a href="https://www.rust-lang.org/">Rust</a> it wasn’t that difficult to compile to WASM, so feel free to play with it here:</p>

<p>Anyway, now that can embed data, including executables into an image, how do we run them?</p>
<h2 id="get-it-running">Get it running</h2>
<p>The simple option would be to just run the tool above, <code>decode</code> the data into a new file, <code>chmod +x</code> it and then run it. It works but that’s not fun enough. What I wanted was something similar to the PICO-8 experience, you pass something a PNG image and it takes care of the rest.</p>
<p>However, as it turns out, you can’t just load some arbitrary set of bytes into memory and tell Linux to jump to it. Well, not in a direct way anyway, but you <em>can</em> use some cheap tricks to fudge it.</p>
<h2 id="memfd-create">memfd_create</h2>
<p>After reading <a href="https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html">this blogpost</a> it became apparent to me you can create an in-memory file and mark it as executable</p>
<blockquote>
<p>Wouldn’t it be cool to just grab a chunk of memory, put our binary in there, and run it without monkey-patching the kernel, rewriting execve(2) in userland, or loading a library into another process?</p>
</blockquote>
<p>This method uses the syscall <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd_create(2)</a> to create a file under the <code>/proc/self/fd</code> namespace of your process and load any data you want in it using <code>write</code>. I spent quite a while messing around with the <a href="https://crates.io/crates/libc">libc</a> bindings for Rust to get this to work, and had a lot of trouble understanding the data types you pass around, the documentation for these Rust bindings doesn’t help much.</p>
<p>I got something working eventually though</p>
<figure>
<div><pre><code data-lang="rust"><span>unsafe</span><span> </span>{<span>
</span><span>    </span><span>let</span><span> </span>write_mode<span> </span><span>=</span><span> </span><span>119</span>;<span> </span><span>// w
</span><span></span><span>    </span><span>// create executable in-memory file
</span><span></span><span>    </span><span>let</span><span> </span>fd<span> </span><span>=</span><span> </span>syscall(libc::SYS_memfd_create,<span> </span><span>&amp;</span>write_mode,<span> </span><span>1</span>);<span>
</span><span>    </span><span>if</span><span> </span>fd<span> </span><span>==</span><span> </span><span>-</span><span>1</span><span> </span>{<span>
</span><span>        </span><span>return</span><span> </span><span>Err</span>(<span>String</span>::from(<span>"memfd_create failed"</span>));<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span>file<span> </span><span>=</span><span> </span>libc::fdopen(fd,<span> </span><span>&amp;</span>write_mode);<span> 
</span><span>
</span><span>    </span><span>// write contents of our binary
</span><span></span><span>    </span>libc::fwrite(<span>
</span><span>        </span>data.as_ptr()<span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span>libc::c_void,<span> 
</span><span>        </span><span>8</span><span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>data.len()<span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>file,<span>
</span><span>    </span>);<span>
</span><span></span>}<span>
</span></code></pre></div>
</figure>
<p>Invoking <code>/proc/self/fd/&lt;fd&gt;</code> as a child process from the parent that created it is enough to run your binary.</p>
<figure>
<div><pre><code data-lang="rust"><span>let</span><span> </span>output<span> </span><span>=</span><span> </span>Command::new(format<span>!</span>(<span>"/proc/self/fd/{}"</span>,<span> </span>fd))<span>
</span><span>    </span>.args(args)<span>
</span><span>    </span>.stdin(std::process::Stdio::inherit())<span>
</span><span>    </span>.stdout(std::process::Stdio::inherit())<span>
</span><span>    </span>.stderr(std::process::Stdio::inherit())<span>
</span><span>    </span>.spawn();<span>
</span></code></pre></div>
</figure>
<p>Given these building blocks, I wrote <a href="https://github.com/djhworld/pngrun">pngrun</a> to run the images. It essentially…</p>
<ol>
<li>Accepts an image that has had our binary embedded in it from the steganography tool, and any arguments</li>
<li>Decodes it (i.e. extracts and re-assembles the bytes)</li>
<li>Creates an in-memory file using <code>memfd_create</code></li>
<li>Puts the bytes of the binary into the in-memory file</li>
<li>Invokes the file <code>/proc/self/fd/&lt;fd&gt;</code> as a child process, passing any arguments from the parent</li>
</ol>
<p>So you can run it like this</p>
<figure>
<div><pre><code data-lang="bash">$ pngrun htop.png
&lt;htop output&gt;
$ pngrun go.png run main.go
Hello world!</code></pre></div>
</figure>
<p>Once <code>pngrun</code> exits the in-memory file is destroyed.</p>
<h2 id="binfmt-misc">binfmt_misc</h2>
<p>It’s annoying having to type <code>pngrun</code> every time though, so my last cheap trick to this pointless gimmick was to use <a href="https://en.wikipedia.org/wiki/Binfmt_misc">binfmt_misc</a>, a system that allows you to “execute” files based on its file types. I think it was mainly designed for interpreters/virtual machines, like Java. So instead of typing <code>java -jar my-jar.jar</code> you can just type <code>./my-jar.jar</code> and it will invoke the <code>java</code> process to run your JAR. The caveat is your file <code>my-jar.jar</code> needs to be marked as executable first.</p>
<p>So adding an entry to binfmt_misc for <code>pngrun</code> to attempt to run any <code>png</code> files that have the <code>x</code> flag set was as simple as</p>
<figure>
<div><pre><code data-lang="bash">$ cat /etc/binfmt.d/pngrun.conf
:ExecutablePNG:E::png::/home/me/bin/pngrun:
$ sudo systemctl restart binfmt.d
$ chmod +x htop.png
$ ./htop.png
&lt;output&gt;</code></pre></div>
</figure>
<h2 id="what-s-the-point">What’s the point</h2>
<p>Well, there isn’t one really. I was seduced by the idea of making PNG images run programs and got a bit carried away with it, but it was fun none the less. There’s something amusing to me about distributing programs as an image, remember the ridiculous cardboard boxes PC software used to come in with artwork on the front, why not bring that back! (lets not)</p>
<p>It’s really dumb though and comes with a lot of caveats that make it completely pointless and impractical, the main one being needing the stupid <code>pngrun</code> program on your machine. But I also noticed some weird stuff around programs like <code>clang</code>. I encoded it into this fun LLVM logo and while it runs OK, it fails when you try to compile something.</p>
<figure>
<a href="https://djharper.dev/img/DragonMedium.png"><img src="https://djharper.dev/img/DragonMedium.png" title="Clang/LLVM logo"></a>
</figure>
<figure>
<div><pre><code data-lang="bash">$ ./clang.png --version
clang version <span>11</span>.0.0 <span>(</span>Fedora <span>11</span>.0.0-2.fc33<span>)</span>
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /proc/self/fd
$ ./clang.png main.c
error: unable to execute command: Executable <span>""</span> doesn<span>'</span>t exist!</code></pre></div>
</figure>
<p>This is probably a product of the anonymous file thing, which can probably be overcome if I could be bothered to investigate.</p>
<h3 id="additional-reasons-why-this-is-dumb">Additional reasons why this is dumb</h3>
<p>A lot of binaries are quite large, and given the constraints of needing to fit them into an image, sometimes these need to be <em>big</em>, meaning you end up with comically large files.</p>
<p>Also most software isn’t just one executable so the dream of just distributing a PNG kinda falls flat for more complex software like games.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is probably the dumbest project I’ve worked on all year but it’s been fun, I’ve learned about Steganography, <code>memfd_create</code>, <code>binfmt_misc</code> and played a little more with Rust.</p>
</article>
</div></div>]]>
            </description>
            <link>https://djharper.dev/post/2020/12/26/executable-pngs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543191</guid>
            <pubDate>Sat, 26 Dec 2020 13:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manga Guide to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25541919">thread link</a>) | @joubert
<br/>
December 25, 2020 | http://lambda.bugyo.tk/cdr/mwl/ | <a href="https://web.archive.org/web/*/http://lambda.bugyo.tk/cdr/mwl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambda.bugyo.tk/cdr/mwl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541919</guid>
            <pubDate>Sat, 26 Dec 2020 06:57:48 GMT</pubDate>
        </item>
    </channel>
</rss>
