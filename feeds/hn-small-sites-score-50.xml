<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 12 Sep 2020 16:23:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 12 Sep 2020 16:23:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Technical Interview Is an Ego Trip]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24447182">thread link</a>) | @kowsheek
<br/>
September 11, 2020 | https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/ | <a href="https://web.archive.org/web/*/https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Early in my career, after a short initial interview at a consulting firm in Toronto, I was invited to a technical interview on the same day. Two of the senior developers from the team I would join would conduct the interview.</p><p>The interview started pleasantly with them describing the project they have been working on: a portal for university professors to communicate with their students. It was being built with ASP.NET MVC, a framework I had been working with for several years. I expressed that I was comfortable with the framework and I would be excited to work on the project. Then the technical examination began and on its conclusion I left the interview feeling humiliated.</p><p>Many years later, when I was preparing to take an interview, I looked back on this experience to realize that the line of questioning and approach had been an ego trip for those developers. I promised myself to <em>never</em> make any of my candidates feel the way I did.</p><p>What did those developers do wrong? Leaving aside their attitude towards me, their questions had no relevance to the role or the project. I did not know what a red-black tree was at the time but I definitely knew how to use ASP.NET MVC which they did not inquire about.</p><p>My golden rule for technical interviews is that, "Every step, conversation and question <em>must</em> be pertinent to the day-to-day of the role." While this may be obvious, I am sure that many hiring managers are still expecting candidates to arrive at technical interviews with Computer Science books memorized. This form of technical interviews should be made obsolete.</p><figure><blockquote><p lang="en" dir="ltr">Bigger button = more clicks on the CTA <a href="https://t.co/Ter7xJdNKM">pic.twitter.com/Ter7xJdNKM</a></p>— Vincent Déniel (@vincentdnl) <a href="https://twitter.com/vincentdnl/status/1291041278264713220?ref_src=twsrc%5Etfw">August 5, 2020</a></blockquote>

</figure><p>With my golden rule as guide, I conduct a much simpler interview process. Prior to an interview, my team and I review samples of code that the candidate shared with us (or had written on Github) to understand the quality of their code. And during the interview, I dive into three areas of discussions with the candidates: product building, process adherence and team work.</p><h3 id="product-building">Product Building</h3><p>I try to understand the candidate's interest and experience of building products by,</p><ol><li>Going through their past experience and asking about what technologies and products they built and how. I ask about previous products they have shipped from concept to market.</li><li>To understand their thought process for deriving solutions, I draw an UI and ask them to outline and explain what approaches, structures and technologies they would use to build it out.</li><li>I ask about how they keep up with technologies and how they improve their skills to gauge their passion for the work.</li></ol><h3 id="process-adherence">Process Adherence</h3><p>To better understand how the candidate does their work,</p><ol><li>I go over their experiences and ask about how they managed their product-building and what tools and processes they used.</li><li>I explain the process of working on our team and ask how they would change it and where they see inefficiencies to discuss their thinking.</li><li>Often, I will give them a scenario where the processes are failing the team to find what they would do to tackle inefficiencies and if they would be willing to speak up.</li></ol><h3 id="team-work">Team Work</h3><p>I also try to understand how a candidate works in a team,</p><ol><li>While going through their past experiences, I ask about how they collaborated and communicated with their teams.</li><li>I present a scenario where their knowledge in an area may be lacking and evaluate if and how they would leverage and collaborate with their team.</li><li>Another scenario I ask about is where they disagree with their team-members to evaluate how they manage conflict and focus on delivering results for the team.</li></ol><p>I do this within one interview to be mindful of the candidate's time and mine. I want to hire candidates for their will to learn, grow and challenge the status quo.</p><p>The technology landscape is such that once we have a set of baseline programming skills. What is needed then, is a willingness to challenge ourselves and stay open-minded because every developer will have to learn on the job almost all of the time. Given this, the technical interview is arcane, academic and as good as dead.</p><hr><h3 id="further-reading">Further Reading</h3><ol><li><a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">Tech Sector Job Interviews Assess Anxiety, Not Software Skills</a></li><li><a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">Technical interviews are garbage. Here’s what we do instead</a></li><li><a href="https://remotesynthesis.com/blog/whats-wrong-with-tech-interviews">What's Wrong with the Tech Interview Process?</a></li></ol>
                </div>
            </section>

                <section>
    <h3>Subscribe to blog.kowsheek</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447182</guid>
            <pubDate>Fri, 11 Sep 2020 20:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by obscurity is underrated]]>
            </title>
            <description>
<![CDATA[
Score 574 | Comments 371 (<a href="https://news.ycombinator.com/item?id=24444497">thread link</a>) | @pcr910303
<br/>
September 11, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444497</guid>
            <pubDate>Fri, 11 Sep 2020 16:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do you reason about a probabilistic distributed system?]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24444276">thread link</a>) | @ahelwer
<br/>
September 11, 2020 | https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/ | <a href="https://web.archive.org/web/*/https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        <h2 id="in-which-i-am-stunted-upon-by-coin-flips">In which I am stunted upon by coin flips</h2>
<p>Wasn’t too long ago that I felt pretty good about my knowledge of distributed systems.
All someone <em>really</em> needed in order to understand them, I thought, was a <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">thorough understanding of the paxos protocol</a> and a willingless to reshape your brain in the image of TLA+.
Maybe add a dash of conflict-free-replicated datatypes, just so you know what “eventual consistency” means.
Past that it’s just some optimizations and mashups which come easily to your TLA+-addled brain.</p>
<p>This belief proved surprisingly robust over a number of years, even surviving an aborted attempt at analyzing the <a href="https://github.com/ahelwer/tla-experiments/blob/master/Nano.tla">Nano cryptocurrency</a>.
It was only after encountering <a href="https://muratbuffalo.blogspot.com/2018/06/snowflake-to-avalanche-novel-metastable.html">the snowflake family of consensus protocols</a> that I realized my theory just wasn’t up to the challenge.
The issue was <em>probability</em>: snowflake protocols reach consensus by iteratively polling sets of other nodes at random, and the argument that consensus is eventually reached is a statistical argument deriving an upper bound on the probability of failure.</p>
<p>I didn’t <em>dislike</em> probability &amp; statistics, I just tried to keep my distance as much as possible.
All the algorithms in distributed systems I’d encountered so far involved <em>nondeterminism</em>, sure, but not probability.
I’d assumed nondeterminism was just a more flexible way of reasoning about probability.
This idea of mine would prove to be a source of great unnecessary confusion as I learned the art of reasoning about probabilistic distributed systems, so I’ll do you a favor and give you the core lesson of this entire post in one sentence:</p>
<p><strong>You cannot model probability with nondeterminism, and you cannot model nondeterminism with probability.</strong></p>
<h2 id="models-theyre-good-folks">Models: they’re good, folks!</h2>
<p>Have you ever been writing some multithreaded code, happily plugging in a mutex here, a semaphore there, or even just using some nice message-passing primitives to make your threads all get along?
Maybe you’ll be familiar, then, with what often comes next.
A scratch at the back of your mind, a thought - <em>“oh, wait…"</em> - as you realize something weird will happen if thread \(A\) manages to reach some step before thread \(B\) has finished its assigned task.
No worries! Slap on another WaitHandle, problem solved.
Except the problem wasn’t solved. Not really.
You consider it a bit more - what if thread \(C\) comes in with a message at this inopportune time?
You realize with dawning horror you’re actually tracing cracks in the foundation.
Patch them with mutexes! Semaphores! Anything!
Alas, you are beyond help. It’s around this time that your brain, catching a glimpse of the infinite plane of combinatorial state explosion, wisely ducks its head back down for the day and leaves you with a woozy, fuzzy, clenching feeling for having the gall to ask it to fix all this.</p>
<p>I’ve felt like this many times, and formal models are the only cure I’ve ever found.
Your brain isn’t built to hold massive state spaces in its working memory, so don’t even try.
Let a model checking program churn through all those states to find the bugs.
At this point I won’t even touch a multithreaded program or distributed system without whipping up a quick TLA+ spec of its desired workings.
I just specify all the possible events in the system, how those events affect the system state, what things I always want to remain true (the invariants), then let the model checker rip.
In TLA+, we model concurrency with nondeterminism; in a concurrent system, we have no idea whether thread \(A\) will execute a step before thread \(B\).
We can represent this with a nondeterministic state machine as follows:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/nondeterministic.svg" width="10000"> 
</figure>

<p>So you’ll be in state \(s_3\) if thread \(A\) executes its step before thread \(B\), and state \(s_4\) if thread \(B\) executes its step before thread \(A\).
Maybe \(s_3\) and \(s_4\) are even the same state, who knows.
The model checker will explore both of these possible execution orders, and <strong>in a well-designed concurrent system we should <em>never</em> end up in a bad state just because of a certain order of execution</strong>.</p>
<p>Readers might wonder how exactly this models concurrency, where steps can happen uh, concurrently.
The short answer is you have to ensure all the steps in your model are atomic or independent: either impossible in the real world for two of your steps to happen at the exact same time (for example, by assuming use of a lower-level hardware synchronization primitive) or impossible for execution of one step to directly affect the same variables as another step (for example, if the steps are executed on different computers within a timespan less than the network latency between them).
If the steps in your model satisfy this requirement, checking all possible execution orders accurately models concurrency.
If they don’t, you need to break the steps down further so they do.
This model nicely captures &amp; exposes all that is difficult about concurrency.</p>
<p>What questions can we ask about this sort of model?
The most important questions are <em>reachability queries</em> - can we reach a <em>bad state</em> (two caches disagreeing on a value, deadlock, dogs &amp; cats living together, etc.) from the starting state?
These questions are called <em>safety properties</em>, and if they are answered in the negative then the system is safe.
Another type of query is something like “are we always guaranteed to eventually end up in a good state?”
These are called <em>liveness properties</em>.
Turns out these two types of questions can get you pretty far in concurrent &amp; distributed systems.
Definitely far enough to make a whole career out of writing rock-solid software in places others would falter.
However, these questions also have a drawback: their answers are absolute.
True or false.
No probability involved, no room for nuance.</p>
<p>What if one of the threads flips a coin, and if it’s heads it does one thing, tails another?
Entire state spaces, bifurcated by a probabilistic event.
Maybe those state spaces contain further coin flips, or other types of randomness.
In this system your questions might change from the form “is it possible to reach a bad state” to “what is the probability of reaching a bad state?”
Unfortunately these types of questions just cannot be answered within the nondeterministic model used above.
<strong>You cannot model probability with nondeterminism.</strong>
We must use a new type of model, a state machine that handles probability directly.</p>
<h2 id="leaving-the-beautiful-pure-discrete-realm">Leaving the beautiful pure discrete realm</h2>
<p>TLA+ can’t handle probability at this time, so we’d have to use a specialized modeling language like <a href="http://www.prismmodelchecker.org/">PRISM</a> which handles probabilistic state machines.
Let’s look at the standard hello-world example for probabilistic state machines: the <a href="http://www.prismmodelchecker.org/bibitem.php?key=KY76">1976 Knuth-Yao method</a> for simulating a fair six-sided die with a series of coin flips.
This is really quite a neat problem and I encourage you to ponder it for a second before seeing how they did it!
Any sequence of \(n\) coin flips will give you an event which has probability \(\frac{1}{2^n}\) of occurring.
Simulating a fair six-sided die requires generating an event with probability \(\frac{1}{6}\) of occurring.
You might then reason this problem is impossible, because you cannot evenly divide \(2^n\) by \(6\) for any \(n\) (this follows from the uniqueness of prime factorization).
Indeed, there is no way to simulate a six-sided die with a finite number of coin flips.
We have to use an algorithm which is not guaranteed to ever terminate, although vanishingly unlikely not to do so.
Here it is:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/knuth-yao.svg" width="10000"> 
</figure>

<p>You can see that if you somehow only flip heads, or only flip tails, you’ll never reach one of the accepting states (here labeled with the die number they represent).
There are some fun ways to contextualize the probabilities of you only flipping heads or tails a certain number of times in a row.
For example, there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">around \(2^{268}\) subatomic particles in the observable universe</a>; if you manage to flip heads 268 times in a row, that’s the same as picking the correct subatomic particle out of a universe-wide random draw.
Maybe go look at the <a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field">Hubble Ultra-Deep Field</a> as you ponder this probability.
Another way is assuming you’re between the ages of 25-34 and live in the USA, your annual all-cause mortality rate is <a href="https://www.cdc.gov/nchs/products/databriefs/db355.htm">about 129/100,000</a>.
Assuming deaths are uniformly distributed throughout the year, this means your chances of dying today are about 1 in 283,000.
This is just 18 all-heads or all-tails coin flips in a row.
What I’m saying is that you really, really shouldn’t worry about having to flip the coin very many times.</p>
<p>This probabilistic state machine model we’ve created is called a <em>Discrete-Time Markov Chain</em>, or DTMC.
In DTMCs, every transition has an associated probability and the probabilities of all out-flowing transitions must sum to one for every state (accepting states can be thought to have a loopback with probability 1).
The above rumination on termination probabilities is summed up in <em>the long run theorem</em>: in the long run, every path in a finite Markov chain ends in an absorbing state, which is a state (or group of states) from which there is an entrance but no exit.
What questions can we ask of DTMCs?
The most interesting one - the reason why we’re here - is “what is the probability of eventually reaching a certain state?”
The long run theorem tells us we have a 100% chance of eventually reaching <em>one</em> of the Knuth-Yao state machine’s accepting states.
What about the probability of ending up in a specific accepting state?
It should be \(\frac{1}{6}\). Is it?</p>
<p>Let’s try to reason this out with basic probability.
What are the chances of ending up in accepting state \(1\)?
Well, you can get there by flipping \(HHT\).
The probability of that happening is \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8} \).
But you can also get there by flipping \(HHHHT\).
The probability of <em>that</em> happening is \(\frac{1}{2^5} = \frac{1}{32} \).
We have to add this to the first probability, so now our probability is \(\frac{1}{8} + \frac{1}{32} = \frac{5}{32}\).
But we can <em>also</em> get there …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</a></em></p>]]>
            </description>
            <link>https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444276</guid>
            <pubDate>Fri, 11 Sep 2020 16:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Erlang Developer Experience at WhatsApp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24443128">thread link</a>) | @anuragsoni
<br/>
September 11, 2020 | https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf | <a href="https://web.archive.org/web/*/https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443128</guid>
            <pubDate>Fri, 11 Sep 2020 14:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The lack of namespaces on crates.io is a feature]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24442731">thread link</a>) | @LinuxBender
<br/>
September 11, 2020 | https://samsieber.tech/posts/2020/09/registry-structure-influence/ | <a href="https://web.archive.org/web/*/https://samsieber.tech/posts/2020/09/registry-structure-influence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust doesn’t have namespaces in its package management system. It’s often viewed as a bug. But it’s not a bug, it’s a feature! While there are negative aspects of a flat package registry, there are also real benefits. Stability, continuity, and unity (discourages forks and fragmented identity). Proposals that seek to add namespacing without addressing the positive aspects they remove probably won’t be accepted.</p><p>I have noticed the benefits of the current system seem to only get mentioned in passing as objections to proposals and never outlined anywhere. This is an attempt to fix that by summarizing points raised across the various proposals I’ve read. While I don’t represent the crates.io team (I’m not even on the team) I hope to accurately represent trade-offs being considered.</p><h2 id="aspects-of-registry-structure">Aspects of Registry Structure</h2><p>How identity works in package management has far-reaching consequences. Most of the namespace proposals I’ve seen have been motivated by trying to address squatting and/or tweaking the current system of package identity. However, the structure of the crates.io registry affects more than just those areas. But we’ll start with the basics of identity and work from there.</p><h3 id="identity">Identity</h3><p>How do you refer to a package? A crate has at least three identities I can think of:</p><ul><li>The name on crates.io - there is exactly one crate per name</li><li>The name used in Cargo.toml - there is exactly one crate per name</li><li>The default name used in code - there is can be more than one per name, which is rare in practice</li><li>The actual name used in code - this can be controlled through Cargo.toml or externs statements, but renaming isn’t required</li></ul><p>The first two are called the <code>package.name</code> in Cargo.toml of the crate being published. The third can be overridden via <code>lib.name</code> in the package being published. The last is user-controlled. Usually, all of these names match, with the caveat that dashes are underscores in code (and crates.io doesn’t allow two crates with identical crates.io names after normalizing dashes to underscores).</p><p>Arguably, self-explanatory identities have a leg up on other identities from a discoverability perspective. E.g. <code>argparse</code> probably seems more reputable at first glance than <code>clap</code> if you’re going of name alone.</p><p>A flat registry makes identity management (naming a crate) harder. You either have to pick a GUID (haha, please don’t) or some memorable (but probably mostly or completely unrelated) identity. I see this as the main driving force for proposals seeking to add namespaces or otherwise address squatting.</p><h3 id="continuity">Continuity</h3><p>Currently, identity is continuous - a crate’s identity is immutable and that has real benefits. If you want to change the identity system at all you’ve got to ensure that identities don’t change out from under you. This is a strike against any namespace system that allows namespace ownership to unexpectedly change. Discontinuous identity has a couple of issues.</p><p>First, if a crate’s name can change, that’s bad for users. They have to go figure out the new name of the package if they want to update.</p><p>Second, if an identity’s crate can change (a consequence of the previous point if identities are reusable), then you’ve introduced a security vulnerability. Updating to a new package version with different content under different ownership is a real security risk. Doubly so if you don’t ban new minor versions on the last major version after an unintentional ownership change. Should people audit their crate? Yes! But the fewer foot-guns we have the better.</p><p>In addition to preventing security issues, proposals need to encourage transitions over transactions. Gradual moves over all-or-nothing moves. This could be seen more as compatibility than continuity. This drives things like the rust editions and the need for namespace proposals to be backward compatible.</p><h3 id="stability">Stability</h3><p>A core tenet of Rust is stability. The obvious definition is that things that compile yesterday should compile today (even with a new compiler).</p><p>A less obvious definition is that adding new dependencies shouldn’t stop you from compiling already working code. This is a major motivation for the orphan rule (though the orphan rule is more nuanced than that). This is a strike against schemes that encourage multiple distinct crates to have the same default name in code. I don’t think any proposal that encourages this could be approved. It also suggests that we ought to ban new instances of a crates default code name deviating from its package/Cargo.toml name.</p><p>In addition to code stability, crates.io should be stable too. It should be able to isolate itself from outside services. It currently depends on Github, but it doesn’t have to. This is a strike against any system that weds namespace identity to any externally managed system.</p><h3 id="squatting">Squatting</h3><p>The current identity system encourages squatting. I would define squatting as reserving a crate without actually using it. This is a natural outcome in the Rust ecosystem for a couple of reasons:</p><ul><li>Crates are easy to publish, so it’s easy to reserve a crate by publishing an empty crate</li><li>We have de-facto namespaces using prefixes - <code>serde-*</code> is one example.</li><li>There can only ever be one version of a package name. There is only one <code>http</code> crate for example. So package names are a scarce resource.</li></ul><p>There’s a lot of squatting on crates.io. I don’t have any hard numbers though.</p><p>We don’t have any structured support for squatting either, which makes it hard to separate bad actors from good actors. I think separating them out would require manual intervention, and the crates.io team is small and doesn’t have a lot of time to put towards that.</p><p>So what’s a bad actor? I consider someone who squats a bunch of crates to make or point or prevent their names from being used to be a bad actor. Crates.io has a policy against using automation to claim ownership of crates, but I haven’t heard much about it being enforced. Again, time is an issue. And this would probably extend to namespace ownership as well.</p><p>I do think there are legitimate uses. Reserving a set of extension crates for a project you’re working on is one example. My other example is reserving a crate you genuinely intend to work on (this one is a little more debatable).</p><h2 id="it-s-about-the-trade-offs">It’s about the Trade-offs</h2><p>With this system in mind, it’s hard to come up with a namespace proposal that doesn’t hurt the current system in some way.</p><p>I’d say the biggest tension is in code-level identities. They become either overlapping by chopping the namespace portion off or much longer by including the namespace portion. The previous points show why overlapping is generally considered a non-starter. And for longer identities, you need to come up with some new way to reference namespaces in code that’s doesn’t break things.</p><p>More to the point though, from what I’ve seen, most people proposing identity schemes propose it so that the ecosystem can support the overlapping crate identities (e.g. multiple http crates). And that’s exactly what the current system avoids doing.</p><p>Here’s <a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">an on-point quote from CAD97</a> summing up (hopefully fairly accurately) what namespaces mean to the parties involved:</p><blockquote><p>To the crates team, it seems to <em>primarily</em> mean that a project can put multiple packages together under an umbrella, such that you know the packages are for-sure by the project.</p><p>To the people who feel most slighted by the crates team’s approach here, namespaces <em>primarily</em> mean the ability to publish a crate with a desired name even if there’s already a package published that provides a crate with that name, by putting the package into a different namespace such that the names do not clash.</p><p>If the latter party asks about “namespaces” and means the latter, and the team answers and means the former, you can see where the miscommunication enters, especially since the crates team has now communicated here the position that <em>generally</em>, the <code>package.name == lib.name</code> falsehood should not be made more false; i.e., the latter group’s goal is an explicitly non-desired property from the crates team.</p></blockquote><h2 id="where-to-now">Where to Now?</h2><p>There have been other proposals for namespaces that are less about overlapping identity and more about curation and grouping related crates together. There are multiple proposals there, each with their trade-offs. Expect a follow-up post discussing some of those.</p><h2 id="appendix-a-highlights">Appendix A: Highlights</h2><p>There’s a nice set of a dozen or so comments I save as I reviewed past discussions:</p><p>Carol10Cents (of the crates.io team):</p><ul><li><a href="https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11">https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20</a></li></ul><p>kornel:</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26</a></li></ul><p>sgrif (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7</a></li></ul><p>CAD97:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633</a></li></ul><p>withoutboats (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10</a></li></ul><p>ag_dubs (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28</a></li></ul><p>pietroalbini (on the crates.io team):</p><ul><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791</a></li></ul><p>Random meeting notes:</p><ul><li><a href="https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT">https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT</a></li></ul><h2 id="appendix-b-previous-discussions">Appendix B: Previous Discussions</h2><p>There have been several attempts at this:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688">https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628</a></li><li><a href="https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3">https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320">https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320</a> (This was mine from last year after reading through the other proposals; my …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samsieber.tech/posts/2020/09/registry-structure-influence/">https://samsieber.tech/posts/2020/09/registry-structure-influence/</a></em></p>]]>
            </description>
            <link>https://samsieber.tech/posts/2020/09/registry-structure-influence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442731</guid>
            <pubDate>Fri, 11 Sep 2020 13:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Octo – Generate a serverless API from an SQL query]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24442294">thread link</a>) | @khalidlafi
<br/>
September 11, 2020 | https://octoproject.github.io/octo-cli/ | <a href="https://web.archive.org/web/*/https://octoproject.github.io/octo-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <a href="" title=" ">
    <img src="https://octoproject.github.io/octo-cli/assets/cover.png" alt=" ">
  </a>
  <br>
  <h4>Expose data from any database as web service.</h4>
  <p>
    Octo CLI makes the data available from any database as a web service on-demand, 
    simplifying the process of building data-driven applications.
     It can reduce costs, improve accessibility and performance.
  </p>
 

 <p><a href="" title=" ">
    <img src="https://user-images.githubusercontent.com/20528562/92949687-2b627080-f464-11ea-99e8-d3afad80922c.png" alt=" ">
  </a>
  </p>
     <div>
    <p><a href="https://github.com/octoproject/octo-cli" title="Documentation" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">View on Github</a>
    <a href="https://github.com/octoproject/octo-cli#examples" title="View on GitHub" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">Get started</a>
  </p></div>
</div></div>]]>
            </description>
            <link>https://octoproject.github.io/octo-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442294</guid>
            <pubDate>Fri, 11 Sep 2020 13:02:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checked exceptions: Java’s biggest mistake (2014)]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 238 (<a href="https://news.ycombinator.com/item?id=24440536">thread link</a>) | @flying_sheep
<br/>
September 11, 2020 | http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/ | <a href="https://web.archive.org/web/*/http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	<!-- .entry-header -->

		<div>
		<p>Checked exceptions have always been a controversial feature of the Java language.</p>
<p>Advocates claim they ensure checking &amp; recovery from failures. Detractors say “catch” blocks can almost never recover from an exception, and are a frequent source of mistakes.</p>
<p>Meanwhile, Java 8 and lambdas are here. Are checked exceptions becoming obsolete in the Java world?<span id="more-174"></span></p>
<h3>The Intent of Checked Exceptions</h3>
<p>In the mid 90’s, James Gosling at Sun came up with a new language.</p>
<p>At the time, C++ programming required every single function return to be checked for error. He decided there had to be a better way, and built the concept of “exceptions” into Java.</p>
<p>The intent of <strong>checked exceptions</strong> was to locally flag, and force developers to handle, possible exceptions. Checked exceptions have to be declared on a method signature, or handled.</p>
<p>This was intended to encourage software reliability &amp; resilience. There was an intent to “recover” from contingencies – predictable outcomes other than success, such as InsufficientFundsException on attempting a payment. There was less clarity, as to what “recovery” actually entailed.</p>
<p><strong>Runtime exceptions</strong>&nbsp;were also included in Java. Since null pointers, data errors, and illegal states/ accesses could occur anywhere in code, these were made subtypes of RuntimeException.</p>
<p>Runtime exceptions can be thrown anywhere, without requiring to be declared, and are much more convenient. But would it be correct to use them instead?</p>
<h3>The Drawbacks</h3>
<p>The crucial point here, is that runtime &amp; checked exceptions are functionally equivalent.&nbsp;There is no handling or recovery which checked exceptions can do, that runtime exceptions can’t.</p>
<p>The biggest argument against “checked” exceptions is that most exceptions can’t be fixed. The simple fact is, <strong>we don’t own the code/ subsystem that broke.&nbsp;</strong>We can’t see the implementation, we’re not responsible for it, and can’t fix it.</p>
<p>Particularly problematic were the areas of JDBC (SQLException) and RMI for EJB (RemoteException). Rather than identifying fixable contingencies as per the original “checked exception” concept, these forced pervasive systemic reliability issues, not actually fixable, to be widely declared.</p>
<p>For any method, the possibility of failure includes all sub-methods called by it. Potential failures accumulate up the call tree. Declaring these on method signatures no longer offers a specific &amp; local highlight for the developer to watch for – declared exceptions spread throughout the call tree.</p>
<p>Most EJB developers have experienced this – declared exceptions become&nbsp;required on methods through the tier,&nbsp;or entire codebase. Calling a method with different&nbsp;exceptions&nbsp;requires dozens of methods to be adjusted.</p>
<p>Many developers were told to catch low-level exceptions, and rethrow them again as higher (application-level) checked exceptions. This required vast numbers – 2000 per project, upwards – of non-functional “catch-throw” blocks.</p>
<p>Swallowing exceptions, concealing the cause, double logging, and returning ‘null’/ uninitialized data all became common. Most projects could count 600+ mis-coded or outright errors.</p>
<p>Eventually, developers rebelled against the vast numbers of “catch” blocks, and the source of error these had become.</p>
<h3>Checked Exceptions – incompatible with Functional Coding</h3>
<p>And then we get to Java 8, with its new <i><b>functional programming&nbsp;</b></i>features – such as lambdas, Streams, and function composition.</p>
<p>These features are built on generics – parameter &amp; return types are genericized, so that iteration &amp; stream operations ( <code>forEach</code>, <code>map</code>, <code>flatMap</code>) can be written which perform a common operation, regardless of item type.</p>
<p>Unlike data types, however, declared exceptions can’t be genericized.</p>
<p>There is no possibility in Java to provide a stream operation (like, for example, &nbsp;<code>Stream.map</code>) which takes a lambda declaring some checked exception, &amp; transparently passes that same checked exception to surrounding code.</p>
<p>This has always been a major points against checked exceptions – all intervening code, between a throw and the receiving “catch” block, is forced to be aware of exceptions.</p>
<p>The workaround, of “wrapping” it in a RuntimeException, conceals the original type of the exception – rendering the exception-specific “catch” blocks envisaged in the original concept useless.</p>
<p>Finally we can capture Java’s new philosophy in a nutshell, by noting that none of the new “functional interfaces” in Java 8 declare checked exceptions.</p>
<h3>Conclusion</h3>
<p>Exceptions in Java provided major benefits in reliability &amp; error-handling over earlier languages.&nbsp;Java enabled reliable server &amp; business software, in a way C/ C++ never could.</p>
<p>Checked exceptions were,&nbsp;in their original form, an attempt&nbsp;to handle&nbsp;<i>contingencies</i>&nbsp;rather than&nbsp;<i>failures</i>.&nbsp;The laudable goal was to highlight specific predictable points (unable to connect,&nbsp;file not found,&nbsp;etc) &amp; ensure developers handled these.</p>
<p>What was never included in the original concept, was to force a vast range of systemic &amp;&nbsp;unrecoverable failures to be declared. These <em>failures</em>&nbsp;were never correct to be&nbsp;declared as checked exceptions.</p>
<p>Failures are generally possible in code, and EJB, web &amp; Swing/AWT containers already cater for this by providing an outermost “failed request” exception-handler. The most basic correct strategy is to rollback the transaction &amp; return an error.</p>
<p>Runtime exceptions allow any exception-handling possible with checked exceptions, but avoid restrictive coding restraints. This simplifies coding &amp; makes it easier to follow best practice of&nbsp;<a href="http://wikijava.org/wiki/10_best_practices_with_Exceptions#Throw_early_catch_late" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://wikijava.org']);">throw early, catch late</a>&nbsp;where exceptions are handled at the outermost/ highest possible level.</p>
<p>Leading Java frameworks and influences have now definitively moved&nbsp;away from checked exceptions. Spring, Hibernate and modern Java frameworks/&nbsp;vendors&nbsp;use only runtime exceptions, and this convenience is a major factor in their popularity.</p>
<p>Personalities such Josh Bloch (Java&nbsp;Collections framework), Rod Johnson, Anders Hejlsberg (father of&nbsp;C#), Gavin King&nbsp;and&nbsp;Stephen Colebourn&nbsp;(JodaTime)&nbsp;have all come out against checked exceptions.</p>
<p>Now, in&nbsp;Java 8,&nbsp;lambdas are&nbsp;the&nbsp;fundamental step forward.&nbsp;These language features&nbsp;abstract the “flow of control” from functional operations within. As we’ve seen, this makes checked exceptions &amp; the requirement to “declare or handle immediately” obsolete.</p>
<p>For developers, it is always important to pay attention to reliability &amp; diagnose likely points of failure (contingencies) such as file open, database connection, etc. If we provide good error messages at this points, we will have&nbsp;created&nbsp;self-diagnosing software – a pinnacle of engineering achievement.</p>
<p>But we should do this with unchecked exceptions, and if we have to rethrow, should always use RuntimeException or an app-specific subclass.</p>
<p>As&nbsp;Stephen Colebourn says, if your projects&nbsp;are&nbsp;still using or advocating checked exceptions, your skills are 5-10 years out date.&nbsp;Java&nbsp;has moved&nbsp;on.</p>
<p><strong>How are you dealing with exceptions &amp; reliability? Add your thoughts now.</strong></p>
<p>References:<br>
– <a href="http://www.oracle.com/technetwork/articles/entarch/effective-exceptions-092345.html">Oracle: Barry Ruzek, Effective Java Exceptions<br>
</a>– <a href="http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://tutorials.jenkov.com']);">Jacob Jenkov: Checked or Unchecked Exceptions</a><br>
– <a href="http://googletesting.blogspot.co.nz/2009/09/checked-exceptions-i-love-you-but-you.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://googletesting.blogspot.co.nz']);">Google Testing blog: &nbsp;Checked exceptions, you have to go</a><br>
–&nbsp;<a href="http://www.artima.com/intv/handcuffs.html">Ander Hejlsberg on checked exceptions<br>
–</a>&nbsp;<a href="http://blog.joda.org/2010/09/checked-exceptions-bijava_9688.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://blog.joda.org']);">Stephen Colebourne: Remove checked exceptions from Java</a></p>
<p>Counter-argument: &nbsp;James Gosling<br>
– <a href="http://www.artima.com/intv/solid.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.artima.com']);">James Gosling on checked exceptions</a></p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440536</guid>
            <pubDate>Fri, 11 Sep 2020 08:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 170 (<a href="https://news.ycombinator.com/item?id=24439612">thread link</a>) | @zoozla
<br/>
September 10, 2020 | http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. The doc recommended I up the dosage, but I could see this would eventually lead me to a straitjacket.</p>



<p>Over the years I’ve tried different meds, various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as clinical depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and covid anxiety. My longest bouts of depression now last a day at most and even that doesn’t happen too often.</p>



<p>You can try it too: <a href="https://beta.wuju.app/">beta.wuju.app</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439612</guid>
            <pubDate>Fri, 11 Sep 2020 06:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I operated as a staff engineer at Heroku]]>
            </title>
            <description>
<![CDATA[
Score 359 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24437715">thread link</a>) | @craigkerstiens
<br/>
September 10, 2020 | http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html | <a href="https://web.archive.org/web/*/http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
      

      

      <div>
        <div>
          <p>I was incredibly lucky to spend 5 amazing years at Heroku. By the end of my time, I was operating in a Staff capacity, although I’m honestly completely unclear which titles at Salesforce actually map to Staff.</p>

<p>Because titles are unclear and because my role was a little amorphous, I chose not to submit a story to Will Lethain’s <a href="https://staffeng.com/stories/">great collection</a> at StaffEng.com. That being said, I added a few questions to his questionnaire that I hadn’t seen answered elsewhere, so I figured I’d post this.</p>

<p><strong><em>Tell us a little about your current role: where do you work, your title and generally the sort of work do you and your team do.</em></strong></p>

<p>Until recently, I was a Principal engineer at Salesforce, working for their Heroku product. I joined almost five years ago, working on the Heroku Add-ons product, and then transferred to the Heroku API team. For the last year and a half, I worked on the API team for the Salesforce Functions product, which runs on top of Heroku infrastructure.</p>

<p>The API team is at the center of defining how the Salesforce Functions product will work, so there are a lot of different tasks our team does. First and foremost, we write the code to store the state that the customer <em>intends</em> their infrastructure to converge to and then push that down into the infrastructure layer. If you’re interacting with Salesforce Functions, you’re going through our code. We also do a lot of reconciling what the infrastructure can do with the hopes and dreams of product. I did a balance of work, but more towards the “hopes and dreams” side of things.</p>

<p><strong><em>What does a “normal” Staff-plus engineer do at your company? Does your role look that way or does it differ?</em></strong></p>

<p>There is really no “normal” Staff engineer at Salesforce. I usually talk about four different approaches I see in the company, some of which line up with <a href="https://staffeng.com/guides/staff-archetypes">Will’s archetypes</a> and some which don’t. A lot of folks are a mix of these and rotate through them over a long career at the company.</p>

<p><em>Team(s) Lead/Right Hand</em></p>

<p>You are the primary technical point of contact for 10-20 engineers, across one or more teams. You are typically reporting to a manager of managers. Responsibilities vary based on individuals’ strengths and the strengths of their manager, but there are some common things you <em>must</em> do. If you’re not making your delivery timelines and this is a surprise to your organization, you and your manager have a problem. If product has a dream and no one knows what it would take to build it (time, resources, architecture), you have a problem. If you can’t answer “Why are we building this in this way?” then you have a problem.</p>

<p><em>Product Architect</em></p>

<p>If it’s on TechCrunch or promoted at our corporate conferences, there is an Architect for it. If the project (40+ engineers) fails to be a success, you share responsibility along with the (typically) VP+ engineering manager and Product owner. If you have any type of personal presence, you will be put on a stage and in front of customers. This is the level where you’re helping advocate with your VP for major initiatives to go after certain markets. If we made the wrong bet, some blame is with product, but it’s also on you, and the manager probably won’t look great.</p>

<p><em>Deep Diver</em></p>

<p>You have a lot of deep technical expertise on a particular component or system. You tend to stay on a single team or a single area of the organization. If you work in our legacy codebases, which are the core of our profitability, you are basically unfireable because you know so much. You may write code for some of the gnarliest problems of the legacy system you’re being kept around for, but you’ll often find yourself spending more time interfacing with other teams to explain why your system can’t do what they want and how we can work around it to deliver on a reasonable timeline. You will work closely with your Team Lead on a daily/weekly basis and occasionally have your entire day/week blown up because the Product Architect has identified a need for your expertise and all of a sudden you’re being trotted out to present to some team you’ve never heard of.</p>

<p><em>The Management</em></p>

<p>There are two variants. First, you’re pendulum’ing over to a line manager role, but since your IC title is the same grade as Director or VP, making you a manager would result in a massive pay cut. You’re likely managing a smaller team, given Salesforce targets 12-15 reports. In the second variant, you’re roughly an extension of a VP+ leader. Maybe you’re working on how we keep our many thousands of engineers communicating well. Maybe you’re advising an SVP on where to make technical investments - does our company really have enough of a competitive advantage to go after that market? Sure, the SVP/C-suite person is being told by Product that if you only give us $100 million we can do a ton. Is that true? Hey, we just bought a multi-billion dollar business (or we’re about to): Can you figure out what we should do with them? Many, including Will, call this fire-fighting, but that’s too narrow a view of how these roles really deliver value to large companies: it’s fast-paced opportunity scouting and truth-telling. That being said, you’ll most likely be looking for opportunities and the real truth within the more challenged parts of the business, so I see the fire-fighting analogy.</p>

<p><strong><em>How do you define success in your role?</em></strong></p>

<p>First and foremost, I am successful if the folks I work with understand how business decisions tie into their day-to-day work.</p>

<p>At a minimum, this involves a fair amount of understanding why we’re being asked to build something, running ahead of the team to make sure product plans are in place for us, working across teams to come up with an achievable plan and then championing IC concerns as they crop up.</p>

<p>But it also means pushing forward discussions about what kinds of risk are worth taking on in our code at the moment. Is now the right time to commit to this abstraction? Is now the time to address a performance issue with a re-architecture? We’re moving quickly, but also seeing a lot of incidents - what kinds of testing should we invest in?</p>

<p>Success looks like seeing conversations about timeline and priorities between ICs start from a shared background. Success looks like having no major blow ups about “How could you suggest we ship this hack?” Instead, folks can talk about technical choices through a business lens: “I know we’re currently low on staff compared to our product ambitions, but is this the right place to simplify?” Success looks like a team with a shared goal for the quality and resiliency of code that we’re writing. Success also looks like other ICs feeling confident in advocating for changes, since they see our team making technical decisions with a consistent goal in mind. When I talk with ICs in 1:1s, there should be no “I’m not sure why I’m doing X” when it comes to code, infrastructure and incidents.</p>

<p>Next, I am successful when my management chain clearly understanding the particular risks we’re taking on. All of the architectural decisions a team makes will be wrong, eventually. Whether technology changes, our customer base changes or the product itself changes, it’s only a matter of time before we regret those big choices. The key is understanding what bets we’re making and how long we think before we’ll need to revisit them.</p>

<p>Architecture in a large enterprise is a lot about risk management. A large org has a lot of existing momentum in the market and naturally becomes more cautious. I only have a few places where I can advocate for higher-risk bets and those bets are going to be far lower risk than at a start up. While I need to embrace the fact that our decisions will be wrong, I need to be able to speak to the ways in which we will likely be wrong, when we’ll know and what our mitigation strategy will be.</p>

<p>Third, I am successful if I’m saying the right “No”s to my manager. If the ICs that report to my manager end up feeling like “I told you so” or “We knew this was a bad idea” and that wasn’t surfaced for a discussion, that’s on me. As a Staff engineer, I have the responsibility to course correct my manager when we’re over-committed or committed to the wrong thing.</p>

<p>Finally, I’m successful if my organization has a healthy engineering culture. No one person owns culture, but that doesn’t mean we all don’t equally share the burden of building a world-class engineering organization.</p>

<p><strong><em>How do you spend your time day-to-day?</em></strong></p>

<p>While I do write code from time-to-time, it’s only after I’ve delivered on my obligations on these four functions.</p>

<p><em>Information gathering</em> - In order to help my team understand the context within which we’re building a thing, I need a lot of information. I almost unfailingly start my day with a list of longer emails and docs of all varieties to digest. I also spend a fair amount of time in cross-org chats with assorted managers &amp; ICs, whose purpose is a combination of information gathering and the coaching I mention below.</p>

<p><em>Planning</em> - Knowing a bunch of stuff isn’t helpful unless we actually do something with it, so I also spend a lot of time in planning activities. This is a lot of writing docs and running meetings. Planning activities are usually very collaborative – I rarely know the most on any one thing, but I can knit them all together into a plan.</p>

<p><em>Context sharing</em> - Knowing what we want to do isn’t helpful unless a lot of people understand the plan, so the final category of work that’s execution oriented is sharing all of that context. I attend meetings with other teams to share what we are doing, I review PRs to make sure we’re making small decisions in-line with larger goals, and hold standing team 1:1s to make sure each person feels confident in the direction we’re headed.</p>

<p><em>Coaching &amp; Culture</em> - The final category of work isn’t oriented towards delivering a product, but it’s still critically important to our organization’s long-term health to invest in our engineers. My personal …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</a></em></p>]]>
            </description>
            <link>http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437715</guid>
            <pubDate>Thu, 10 Sep 2020 23:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you ever wanted to know about terminals (2018)]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24436860">thread link</a>) | @n3t
<br/>
September 10, 2020 | https://xn--rpa.cc/irl/term.html | <a href="https://web.archive.org/web/*/https://xn--rpa.cc/irl/term.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h3><a href="https://xn--rpa.cc/index.html">ʞ</a> / <a href="https://xn--rpa.cc/irl/index.html">essays</a> /</h3>



<p>so here's a short tutorial on ansi escape codes and terminal control, because you philistines won't stop using ncurses and oh my god <em>WHY ARE WE STILL USING NCURSES IT IS THE TWENTY FIRST FUCKING CENTURY</em></p>

<p>the way terminal emulators handle fancy things like color and cursor shape aren't some mysterious opaque black box you can only access through a library. accessing these capabilities is actually extremely simple; they can even be hardcoded into a text file and displayed by <code>cat</code> or <code>less</code>. or even <a href="http://xn--rpa.cc/ansiglot">curl</a>! the way you do this is with something called <em>ANSI escape sequences.</em></p>

<p>almost all UI changes in a terminal are accomplished through in-band signalling. these signals are triggered with the ASCII/UTF-8 character <strong>‹ESC›</strong> (<code>0x1B</code> or <code>27</code>). it's the same <strong>‹ESC›</strong> character that you send to the terminal when you press the <code>Escape</code> key on your keyboard or a key sequence involving the <code>Alt</code> key. (typing <strong>‹A-c›</strong> for instance sends the characters <strong>‹ESC›</strong> and <strong>‹c›</strong> in very rapid succession; this is why you'll notice a delay in some terminal programs after you press the escape key — it's waiting to try and determine whether the user hit <code>Escape</code> or an alt-key chord.)</p>

<p>the simplest thing we can do with these escapes is to make the text <strong>bold</strong> (or "bright"). we accomplish this by sending the terminal the <strong>‹ESC›</strong> character followed by <code>[1m</code>. <code>[</code> is a character indicating to the terminal what kind of escape we're sending, <code>1</code> indicates bold/bright mode, and <code>m</code> is the control character for formatting escapes.</p>

<p>all text sent after this escape sequence will be bold until we explicitly turn it off again (even if your program terminates). there are two ways we can turn off bright mode: by clearing formatting entirely, using the <code>m</code> formatting command with no arguments or the argument <code>0</code>, or more specifically clearing the bold bit with the <code>21m</code> command. (you'll notice that you can usually turn off modes by prefixing the same number with <code>2</code>.)</p>

<p>in a C program, this might look like the following:</p>

<code><b>#include</b> <cite>&lt;unistd.h&gt;</cite>
<span>#define</span> szstr(str) str,sizeof(str)
<strong>int</strong> main() {
	write(1, szstr(<em>"plain text - \x1b[1mbold text\x1b[0m - plain text"</em>));
}
</code>

<p>the <code>\x1b</code> escape here is a C string escape that inserts hex character <code>0x1B</code> (<strong>‹ESC›</strong>) into the string. it's kind of ugly and unreadable if you're not used to reading source with explicit escapes in it. you can make it a lot less horrible with a handful of defines, tho:</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>     plain "0" /* or "" */
<span>#define</span>        no "2"
<span>#define</span>    bright "1"
<span>#define</span>       dim "2"
<span>#define</span>    italic "3"
<span>#define</span> underline "4"
<span>#define</span>   reverse "7"
<span>#define</span>      with ";"
<span>#define</span>  ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(    <em>"plain text - "</em>
		fmt(bright)     <em>"bright text"</em>     fmt(no bright) <em>" - "</em>
		fmt(dim)       <em>"dim text"</em>        fmt(no dim)    <em>" - "</em> 
		fmt(italic)    <em>"italic text"</em>     fmt(no italic) <em>" - "</em>
		fmt(reverse)   <em>"reverse video"</em>   fmt(plain)     <em>" - "</em>
		fmt(underline) <em>"underlined text"</em> fmt(no underline) )
	);
}
</code>

<p>the beauty of this approach is that all the proper sequences are generated at <em>compile time</em>, meaning the compiler turns all that into a single string interpolated with the raw escapes. it offers much more readability for the coder at zero cost to the end user.</p>

<p>but hang on, where's that semicolon coming from? it turns out, ansi escape codes let you specify multiple formats per sequence. you can separate each command with a <code>;</code>. this would allow us to write formatting commands like <code>fmt(underline with bright with no italic)</code>, which translates into <code>\x1b[4;1;23m</code> at compile time.</p>

<p>of course, being able to style text isn't nearly good enough. we also need to be able to color it. there are two components to a color command: what we're trying to change the color of, and what color we want to change it to. both the foreground and background can be given colors separately - despite what ncurses wants you to believe, you do not have to define """color pairs""" with each foreground-background pair you're going to use. this is a ridiculous archaism that nobody in the 21st fucking century should be limited by.</p>

<p>to target the foreground, we send the character <code>3</code> for normal colors or <code>9</code> for bright colors; to target the background, we send <code>4</code> for normal or <code>10</code> for bright. this is then followed by a color code selecting one of the traditional 8 terminal colors.</p>

<p>note that the "bright" here is both the same thing and something different from the "bright" mode we mentioned earlier. while turning on the "bright" mode will automatically shift text it applies to the bright variant of its color <em>if</em> it is set to one of the traditional 8 colors, setting a "bright color" with <code>9</code> or <code>10</code> will not automatically make the text bold.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span> fg "3"
<span>#define</span> br_fg "9"
<span>#define</span> bg "4"
<span>#define</span> br_bg "10"
<span>#define</span> with ";"
<span>#define</span>      plain ""
<span>#define</span>      black "0"
<span>#define</span>        red "1"
<span>#define</span>      green "2"
<span>#define</span>     yellow "3"
<span>#define</span>       blue "4"
<span>#define</span>    magenta "5"
<span>#define</span>       cyan "6"
<span>#define</span>      white "7"
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(
		<em>"plain text - "</em>
		fmt(fg blue) <em>"blue text"</em> fmt(plain)               <em>" - "</em>
		fmt(br_fg blue) <em>"bright blue text"</em> fmt(plain)     <em>" - "</em>
		fmt(br_bg red) <em>"bright red background"</em> fmt(plain) <em>" - "</em>
		fmt(fg red with br_bg magenta) <em>"hideous red text"</em> fmt(plain))
	);
}
</code>

<p>when we invoke <code>fmt(fg red with br_bg magenta)</code>, this is translated by the compiler into the command string <code>\x1b[31;105m</code>. note that we're using <code>fmt(plain)</code> (<code>\x1b[m</code>) to clear the coloring here; this is because if you try to reset colors with, for instance, <code>fmt(fg black with bg white)</code>, you'll be overriding the preferences of users who have their terminal color schemes set to anything but that exact pair. additionally, if the user happens to have a terminal with a transparent background, a set background color will create ugly colored blocks around text instead of letting whatever's behind the window display correctly.</p>

<p>now, while it is more polite to use the "8+8" colors because they're a color palette the end-user can easily configure (she might prefer more pastel colors than the default harsh pure-color versions, or change the saturation and lightness to better fit with her terminal background), if you're doing anything remotely interesting UI-wise you're going to run up against that limit very quickly. while you can get a bit more mileage by mixing colors with styling commands, if you want to give <em>any</em> configurability to the user in terms of color schemes (as you rightly should), you'll want access to a much broader palette of colors.</p>

<p>to pick from a 256-color palette, we use a slightly different sort of escape: <code>\x1b[38;5;<em>(color)</em>m</code> to set the foreground and <code>\x1b[48;5;<em>(color)</em>m</code> to set the background, where <em>(color)</em> is the palette index we want to address. these escapes are even more unwieldy than the 8+8 color selectors, so it's even more important to have good abstraction.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>       with ";"
<span>#define</span>      plain ";"
<span>#define</span> wfg(color) "38;5;" #color
<span>#define</span> wbg(color) "48;5;" #color
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(<em>"plain text - "</em>
		fmt(wfg(198) with wbg(232))
			<em>"rose text on dark grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(232) with wbg(248))
			<em>"dark grey on light grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(248) with wbg(232))
			<em>"light grey on dark grey"</em>
		fmt(plain))
	);
}
</code>
<p>here, the stanza <code>fmt(wfg(248) with wbg(232))</code> translates into <code>\x1b[38;5;248;48;5;232m</code>. we're hard-coding the numbers here for simplicity but as a rule of thumb, any time you're using 8-bit colors in a terminal, you should <em>always</em> make them configurable by the user.</p>

<p>the opaque-seeming indexes are actually very systematic, and you can calculate which index to use for a particular color with the formula <code>16 + 36 * r + 6 * g + b</code>, where <code>r</code>, <code>g</code>, and <code>b</code> are integers ranging between 0 and 5. indices 232 through 255 are a grayscale ramp from dark (232) to light (255).</p>

<p>of course, this is still pretty restrictive. 8-bit color may have been enough for '90s CD-ROM games on Windows, but it's long past it's expiration date. using true color is much more flexible. we can do this through the escape sequence <code>\x1b[38;2;<em>(r)</em>;<em>(g)</em>;<em>(b)</em>m</code> where each component is an integer between 0 and 255.</p>

<p>sadly, true color isn't supported on many terminals, urxvt tragically included. for this reason, your program should never rely on it, and abstract these settings away to be configured by the user. defaulting to 8-bit color is a good choice, as every reasonable modern terminal has supported it for a long time now.</p>

<p>but, for users of XTerm, kitty, Konsole, and libVTE-based terminal emulators (such as gnome-terminal, mate-terminal, and termite), it's polite to have a 24-bit color mode in place. for example:</p>

<code><span>#include</span> <em>&lt;stdio.h&gt;</em>
<span>#include</span> <em>&lt;stdint.h&gt;</em>
<span>#include</span> <em>&lt;stdbool.h&gt;</em>

<span>struct</span> color {
	<span>enum</span> color_mode { trad, trad_bright, b8, b24 } mode;
	<span>union</span> {
		<span>uint8_t</span> color;
		<span>struct</span> { <span>uint8_t</span> r, g, b; };
	}
};
<span>struct</span> style {
	unsigned <span>char</span> bold      : 1;
	unsigned <span>char</span> underline : 1;
	unsigned <span>char</span> italic    : 1;
	unsigned <span>char</span> dim       : 1;
	unsigned <span>char</span> reverse   : 1;
};
<span>struct</span> format {
	<span>struct</span> style style;
	<span>struct</span> color fg, bg;
};

<span>struct</span> format
	fmt_menu = {
		{0, 0, 0, 0, 0},
		{trad, 7},
		{trad, 4}
	},
	fmt_menu_hl = {
		{1, 0, 0, 0, 0},
		{trad_bright, 7},
		{trad_bright, 4},
	};

<span>void</span> apply_color(<span>bool</span> bg, <span>struct</span> color c) {
	switch(c.mode) {
		case trad: printf(<em>"%c%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color ); break;
		case trad_bright: printf(<em>"%s%u"</em>, bg ? <em>"9"</em> : <em>"10"</em>, c.color ); break;
		case b8: printf(<em>"%c8;5;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color); break;
		case b24: printf(<em>"%c8;2;%u;%u;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.r, c.b, c.g);
	}
}

<span>void</span> fmt(struct format f) {
	printf(<em>"\x1b["</em>);
	f.bold      &amp;&amp; printf(<em>";1"</em>);
	f.underline &amp;&amp; printf(<em>";4"</em>);</code></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xn--rpa.cc/irl/term.html">https://xn--rpa.cc/irl/term.html</a></em></p>]]>
            </description>
            <link>https://xn--rpa.cc/irl/term.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436860</guid>
            <pubDate>Thu, 10 Sep 2020 21:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TOML – Tom's Obvious, Minimal Language]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24436550">thread link</a>) | @pmoriarty
<br/>
September 10, 2020 | https://toml.io/en/ | <a href="https://web.archive.org/web/*/https://toml.io/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <section>
      <div>
        <div>
          <svg viewBox="0 0 128 128" xmlns="http://www.w3.org/2000/svg">
            <g>
              <polygon points="99.2359551 -7.08546829e-15 99.2359551 14.3820225 112.179775 14.3820225 112.179775 113.617978 99.2359551 113.617978 99.2359551 128 128 128 128 0"></polygon>
              <polygon points="32.3595506 41.7078652 32.3595506 25.8876404 95.6404494 25.8876404 95.6404494 41.7078652 71.9101124 41.7078652 71.9101124 110.741573 56.0898876 110.741573 56.0898876 41.7078652"></polygon>
              <polygon points="28.7640449 0 28.7640449 14.3820225 15.8202247 14.3820225 15.8202247 113.617978 28.7640449 113.617978 28.7640449 128 0 128 0 0"></polygon>
            </g>
          </svg>
          <p>
            
            <h2>
              [Tom's Obvious Minimal Language]
            </h2>
          </p>
        </div>
        <h3>
          A config file format <br>for humans.
        </h3>
        <p>
          TOML aims to be a minimal configuration file format that's easy to read due to obvious
          semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to
          parse into data structures in a wide variety of languages.
        </p>
      </div>
    </section>

    <section>
      <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML document

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00

[database]
enabled = true
ports = [ 8001, 8001, 8002 ]
data = [ ["delta", "phi"], [3.14] ]
temp_targets = { cpu = 79.5, case = 72.0 }

[servers]

[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"</code></pre>
    </section>
  </div>

  <section>
    <dl>
      <div>
        <dt>
          
          TOML prioritizes humans
        </dt>

        <dd>
          <p>TOML aims to be a minimal configuration file format that:</p>
          <ul>
            <li>
              <span>is easy to read</span> due to obvious semantics
            </li>
            <li>
              <span>maps unambiguously</span> to a hash table
            </li>
            <li>
              <span>is easy to parse</span> into data structures in a wide variety
              of languages
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML has useful native types
        </dt>
        <dd>
          <ul>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Key/Value Pairs</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Inline tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays of tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Integers &amp; Floats</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Booleans</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Dates &amp; Times, with optional offsets</span>
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML is widely supported
        </dt>
        <dd>
          <p>
            TOML already has implementations in most of the most popular programming languages in use
            today: C, C#, C++, Clojure, Dart, Elixir, Erlang, Go, Haskell, Java, Javascript, Lua,
            Objective-C, Perl, PHP, Python, Ruby, Swift, Scala...
            <a href="https://github.com/toml-lang/toml/wiki">and plenty more</a>.
          </p>
        </dd>
      </div>
    </dl>
  </section>

  <section>
    <header>
      <h2>
        A Quick Tour of TOML
      </h2>
    </header>

    <div>
      <div>
        <section>
          <div>
            <h3>Comments</h3>
            <p>TOML thinks all config files should support comments.</p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML comment

# This is a multiline
# TOML comment</code></pre>
        </section>

        <section>
          <div>
            <h3>Powerful Strings</h3>
            <p>
              There are four ways to express strings: basic, multi-line basic, literal, and
              multi-line literal. <span>Basic strings</span> are surrounded by
              quotation marks:
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = "I'm a string."
str2 = "You can \"quote\" me."
str3 = "Name\tJos\u00E9\nLoc\tSF."</code></pre>

          <p>
            <span>Multi-line basic strings</span> Multi-line basic strings are
            surrounded by three quotation marks on each side and allow newlines. Include a line
            ending backslash to automatically trim whitespace preceeding any non-whitespace
            characters:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = """
Roses are red
Violets are blue"""

str2 = """\
  The quick brown \
  fox jumps over \
  the lazy dog.\
  """</code></pre>

          <p>
            <code> str2</code> becomes
            <code>"The quick brown fox jumps over the lazy dog."</code>
            (a single sentence with no line breaks).
          </p>

          <p>
            <span> Literal strings</span> are surrounded by single quotes. No
            escaping is performed so what you see is what you get:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>path = 'C:\Users\nodejs\templates'
path2 = '\\User\admin$\system32'
quoted = 'Tom "Dubs" Preston-Werner'
regex = '&lt;\i\c*\s*&gt;'</code></pre>

          <p>
            Since there is no escaping, there is no way to write a single quote inside a literal
            string enclosed by single quotes. That's where
            <span>multi-line literal strings</span> come in:
          </p>
          <pre data-controller="snippet" data-snippet-copy="false"><code>re = '''\d{2} apps is t[wo]o many'''
lines = '''
The first newline is
trimmed in raw strings.
All other whitespace
is preserved.
'''</code></pre>
        </section>
      </div>

      <div>
        <section>
          <div>
            <h3>Numbers</h3>
            <p>
              Integers, floats, infinity, and even NaN are all supported. You can use scientific
              notation and even thousands separators.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># integers
int1 = +99
int2 = 42
int3 = 0
int4 = -17

# hexadecimal with prefix `0x`
hex1 = 0xDEADBEEF
hex2 = 0xdeadbeef
hex3 = 0xdead_beef

# octal with prefix `0o`
oct1 = 0o01234567
oct2 = 0o755

# binary with prefix `0b`
bin1 = 0b11010110

# fractional
float1 = +1.0
float2 = 3.1415
float3 = -0.01

# exponent
float4 = 5e+22
float5 = 1e06
float6 = -2E-2

# both
float7 = 6.626e-34

# separators
float8 = 224_617.445_991_228

# infinity
infinite1 = inf # positive infinity
infinite2 = +inf # positive infinity
infinite3 = -inf # negative infinity

# not a number
not1 = nan
not2 = +nan
not3 = -nan </code></pre>
        </section>

        <section>
          <div>
            <h3>Dates and Times</h3>
            <p>
              TOML features support for dates, times, and datetimes with and without offsets.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>#offset datetime
odt1 = 1979-05-27T07:32:00Z
odt2 = 1979-05-27T00:32:00-07:00
odt3 = 1979-05-27T00:32:00.999999-07:00

# local datetime
ldt1 = 1979-05-27T07:32:00
ldt2 = 1979-05-27T00:32:00.999999

# local date
ld1 = 1979-05-27

# local time
lt1 = 07:32:00
lt2 = 00:32:00.999999</code></pre>
        </section>
      </div>
    </div>
  </section>

  <section>
    <div>
      <h3>More Spec</h3>
      <p>
        <strong>TOML</strong> supports even more native types and syntax, read all about it:
      </p>
      
    </div>

    <div>
      <h3>Start coding</h3>
      <p>
        <strong>TOML</strong> is already implemented in over 40 programming languages:
      </p>
      
    </div>
  </section>
</div></div>]]>
            </description>
            <link>https://toml.io/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436550</guid>
            <pubDate>Thu, 10 Sep 2020 21:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Routers Work, Really?]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24435454">thread link</a>) | @turingbook
<br/>
September 10, 2020 | https://kamila.is//teaching/how-routers-work/ | <a href="https://web.archive.org/web/*/https://kamila.is//teaching/how-routers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
    <header>
        
    </header>


              <nav>
    
    <ul>
  <li><a href="#0-some-terminology">0. Some Terminology</a></li>
  <li><a href="#1-high-level-overview">1. High-level Overview</a>
    <ul>
      <li><a href="#the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</a></li>
    </ul>
  </li>
  <li><a href="#the-details-what-exactly-is-going-on">The details: What <em>exactly</em> is going on?</a>
    <ul>
      <li><a href="#life-of-a-packet-now-properly">Life of a Packet, Now Properly</a>
        <ul>
          <li><a href="#1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</a></li>
          <li><a href="#2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</a></li>
          <li><a href="#3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</a></li>
          <li><a href="#the-logic-applying-the-tables">The logic: Applying the tables</a></li>
        </ul>
      </li>
      <li><a href="#the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</a>
        <ul>
          <li><a href="#l3--routing-table">L3 / routing table</a></li>
          <li><a href="#l25--arp-table">L2.5 / ARP table</a></li>
          <li><a href="#l2--mac-table">L2 / MAC table</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#gimme-the-code">Gimme the code!</a></li>
  <li><a href="#next-steps">Next steps</a></li>
</ul>
</nav>

<p><strong>Work in progress</strong>: I still need to clean this up &amp; add the complete source code. ETA for a more or less done version is Soon(TM).<br>
<strong>Last updated</strong>: 2020/09/10 because how the eff did this end up on the front page of Hacker News? :D<br>
<strong>Suggestions welcome</strong>: <a href="https://github.com/AnotherKamila/kamila.is/issues/new?labels=teaching&amp;title=[teaching/how-routers-work]+Title">complain</a> if something is unclear or wrong!</p>

<p>This is the inside view of how exactly a router operates. You only need to know this if you are poking inside a router implementation. If that is the case, my condolences.</p>

<p>At the end of this exposition, I will give you the complete source code to a functional router (written in <a href="https://p4.org/">P4</a>, the new &amp; shiny software-defined networking thing). My aim is that you will understand every line of that.</p>

<p>I accompany my explanations below with some P4 code. I think it is useful to read it even if you’ve never seen P4, because it shows a bit more detail than the text and I believe that it is sufficiently pseudocode-ish. Here is a summary of what you need to know to read it:</p>
<ul>
  <li>everything happens per packet</li>
  <li><code>hdr</code> are the packet’s parsed headers</li>
  <li><code>standard_metadata</code> is how you tell the switch to do things with the packet (like send it on a specific port)</li>
  <li><code>meta</code> are user-defined in-memory variables which can be used e.g. for matching in tables</li>
</ul>



<ul>
  <li>Figuring out what should be done with packets is done by <em>the control plane/in the slow path/on the CPU/by the controller</em> or similar phrases. I will refer to all of this as “the control plane”.</li>
  <li>Actually forwarding the packets  is done by <em>the data plane/in the fast path/in the hardware/in the switch</em> and such. I will refer to this as “the data plane”.</li>
</ul>

<p><a href="https://news.ycombinator.com/item?id=24436585">Cyph0n on HN did a good job explaining this distinction.</a></p>



<p>A <em>switch</em> (or an L2 switch :-) ) is an L2-only<sup><a href="#fn1">1</a></sup> thing. It knows about L2 stuff such as MAC addresses and ports<sup><a href="#fn2">2</a></sup>. It does <strong>not</strong> know about anything like IP addresses. It has a <strong>MAC table</strong>: it maps MAC addresses to ports.</p>

<p>A <em>router</em> (or an L3 switch by some people’s vocabulary) operates on L3 only. It knows about L3 stuff such as IP addresses and interfaces and hosts. It does <strong>not</strong> know about L2 stuff such as MAC addresses or ports.<sup><a href="#fn3">3</a></sup> In fact, the routing parts of the router would not have to be changed at all if you decided to use something other than ethernet on L2. It has a <strong>routing table</strong> (details later): a table of subnets/prefixes and how to reach them.</p>

<p>What you normally call a router (that box sitting over there) is actually a router (for handling L3) and one or more switches (for handling L2), and some glue in between. They may in fact be separate chips in hardware.</p>

<p>You need glue to put together the L2 and the L3. This “L2.5” glue is ARP (or NDP for IPv6). It usually lives in the router, but it is glue, not routing, and you can think about it separately.</p>

<h2 id="the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</h2>

<p>When a packet arrives and needs to be sent further, these things have to happen to it:</p>

<ol>
  <li>It needs to be <em>routed</em>: the <strong>router</strong>, based on L3 information, decides where it needs to go, in L3 speak – it will decide which <em>host</em> to send it to, but not how. This corresponds to the <em><a href="https://en.wikipedia.org/wiki/Routing_table">routing table</a></em>.</li>
  <li>It needs to be passed down to L2: this is where the L2.5 ARP/NDP <strong>glue</strong> translates the L3-speak IP address to L2-speak MAC address. This is the <em>ARP table</em>.</li>
  <li>It needs to be <em>forwarded</em> on the correct port: the <strong>switch</strong> puts the packet on the correct port. This is the <em>MAC table</em>.</li>
</ol>



<h2 id="life-of-a-packet-now-properly">Life of a Packet, Now Properly</h2>

<h3 id="1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</h3>

<p>The packet has a destination IP address. This is matched in the <em>routing table</em>, using a longest-prefix match (LPM), i.e. it matches IP address prefixes. It may either be for a host the router is directly connected to (on some interface), or it may need to be sent further, through a <em>gateway</em> (through some interface). Therefore: <strong>The routing table maps a <em>prefix</em> to either <em>a next hop through a gateway and an interface</em>, or <em>a direct connection through an interface</em></strong>.</p>

<div><div><pre><code>routing_table : Prefix -&gt; NextHop (GatewayIP, Interface) | Direct Interface
</code></pre></div></div>

<p>Note that the next hop’s IP address is in the router’s memory only: it does not appear in the packet at any time.</p>

<p>The P4 code defining the IPv4 routing table is:</p>

<div><div><pre><code>action ipv4_through_gateway(ipv4_addr_t gateway, interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = gateway;  // send through the gateway
}

action ipv4_direct(interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = hdr.ipv4.dst_addr;  // send directly to the destination
}

table ipv4_routing {
    key = {
        hdr.ipv4.dst_addr: lpm;  // match prefixes
    }
    actions = {
        ipv4_through_gateway;    // ipv4_through_gateway(gateway, iface)
        ipv4_direct;             // ipv4_direct(iface)
        drop;
    }
    default_action = drop();     // If there is no route, drop it -- in reality, we might want to
                                 // send an ICMP "No route to host" packet.
                                 // Note that this is the default route, so control plane might
                                 // want to set a default gateway here instead of dropping.
    size = ROUTING_TABLE_SIZE;
}
</code></pre></div></div>
<p>(and the exact same thing for IPv6)</p>

<h3 id="2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</h3>

<p>If we did not drop the packet because there was no route, we now know the IP address and interface of the next hop. (Note that this is a host that is connected to us directly – it is sitting on the same wire.)
We need to translate this into an L2 MAC address in order to pass it to the switch. We do it via the ARP table:</p>

<div><div><pre><code>arp_table : (IPv4Address, Interface) -&gt; MACAddress
</code></pre></div></div>

<p>Note: <code>Interface</code> conceptually belongs there, but <code>IPv4Address</code> should be unique. We need to store the interface in the control plane anyway, because we want to pre-emptively re-send ARP requests when an entry is about to expire, but in the data plane it is not strictly necessary.</p>

<p>An interesting question arises here: What do we do if there is no match, i.e. when we don’t know the MAC address for the IP? First, we send an ARP request. Then, most routers drop the packet (relying on either retransmissions or “nobody will miss it”). Storing the packet until the ARP reply comes back (or until it expires) would also work, but usually isn’t done.
Sending ARP requests is normally done in the control plane, because the ARP requests need to be throttled and expired and such.</p>

<p>P4 code:</p>
<div><div><pre><code>action set_dst_mac(mac_addr_t dst_addr) {
    hdr.ethernet.dst_addr = dst_addr;
}

table ipv4_arp {
    key = {
        meta.ipv4_next_hop: exact;     // next_hop is the host we found in the routing step; we want to send to that
        // meta.out_interface: exact;  // conceptually this belongs here, but actually next_hop should be unique, so
                                       // we can leave it out
    }
    actions = {
        set_dst_mac;                // set_dst_mac(mac)
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;
}
</code></pre></div></div>

<p>IPv6 uses NDP instead of ARP, which is different but the same ;-)</p>

<h3 id="3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</h3>

<p>This is L2 / the switch. It works on each interface separately (it could be multiple chips in hardware). It gets a packet with some destination MAC address, and it decides on which port it should put it. It uses a <em>MAC table</em> to do it:</p>

<div><div><pre><code>mac_table : MACAddress -&gt; Port
</code></pre></div></div>

<p>P4 code:</p>

<div><div><pre><code>// note: we're operating on metadata.out_interface

action set_out_port(port_t ports) {
    standard_metadata.egress_spec = ports;
}

action broadcast() {
    // Implementation depends on the switch.
    // In v1model, use a multicast group corresponding to all ports on metadata.out_interface.
}

// we call it dmac -- see below why
table dmac {
    key = {
        hdr.ethernet.dst_addr: exact;
    }
    actions = {
        set_out_port;  // set_out_port(port)
        broadcast;     // no params, uses metadata.out_interface
                       // remember to set broadcast for 0xffffffffffff in the control plane
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;  // we can have at most as many ports as MAC addresses
}

</code></pre></div></div>

<p>Note: Real switches are a bit more complicated than that: for example, redundant links mean that a MAC address may be on more than one port. However, you will notice when you need to think about this. Normally considering the simple version is sufficient.</p>

<h3 id="the-logic-applying-the-tables">The logic: Applying the tables</h3>

<ol>
  <li>apply routing =&gt; find the next hop (either gateway or direct)</li>
  <li>apply ARP translation to the “next hop” host</li>
  <li>send out on the right port</li>
</ol>

<p>In P4:</p>
<div><div><pre><code>apply {
    routing.apply();  // fills out metadata.next_hop
    arp.apply();      // sets pkt.ethernet.dst_addr to the MAC of next_hop
    dmac.apply();     // sends out on the port for pkt.ethernet.dst_addr
}
</code></pre></div></div>

<p>(Note: While this is conceptually correct, we actually also want to apply the auxiliary table mentioned below. The full code contains that.)</p>

<h2 id="the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</h2>

<p>Starting at the bottom for a change:</p>

<h3 id="l3--routing-table">L3 / routing table</h3>

<p>Filled out by the control plane, depending on the context:</p>

<ul>
  <li>In your home router, it probably has only two entries: the local network (something like 192.168.0.0/24) =&gt; direct on the internal interface, and a default route via your ISP’s gateway on the external interface.
 In this case, the routing table is static and is filled out by the firmware according to the settings.</li>
  <li>In a small company router, there might be a direct network such as 10.0.0.0/24, a remote office in 10.0.1.0/24 via a VPN server, and a default route from the ISP.
 The default route and the direct route would also be filled …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kamila.is//teaching/how-routers-work/">https://kamila.is//teaching/how-routers-work/</a></em></p>]]>
            </description>
            <link>https://kamila.is//teaching/how-routers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435454</guid>
            <pubDate>Thu, 10 Sep 2020 19:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting Zoom's encrypted data with BPF]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24434031">thread link</a>) | @aaron-santos
<br/>
September 10, 2020 | https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes | <a href="https://web.archive.org/web/*/https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I originally wrote an earlier version of this post at the end of March, when I was working on adding uprobes support to <a href="https://github.com/redsift/redbpf">redbpf</a>. I wanted to blog about the work I was doing and needed an application to instrument for the purpose of this post. At that time Zoom's popularity was rising quickly, and I happened to read somewhere that it supported this creepy attention tracking feature that allowed meeting hosts to monitor if attendees were paying attention. I figured I could try to use uprobes to snoop into the data Zoom was sending to their servers and see how the tracking worked.</p><p>But then Zoom quickly started getting under a lot of fire. <a href="https://en.wikipedia.org/wiki/Zoombombing">Zoombombing</a> became a thing, several security issues were discovered and pretty much everyone started piling on the company. Considering all that, I was advised and ultimately decided not to publish the post.</p><p>Now things seem to have settled, Zoom <a href="https://blog.zoom.us/a-message-to-our-users/">improved their security</a> and by popular demand <a href="https://support.zoom.us/hc/en-us/articles/115000538083-Attendee-attention-tracking">got rid of attention tracking</a>. So I think I can finally publish this! I edited out the part about attention tracking (which no longer exists) and a couple of other things that could potentially get me in trouble.</p><p><strong>TLDR:</strong> I wrote a command line tool that uses BPF uprobes to intercept the TLS encrypted data that zoom sends over the network, and here I'm going to show the process I went through to write it. After I wrote this post I made the tool generic so that it can now instrument any program that uses OpenSSL. I published the code at <a href="https://github.com/alessandrod/snuffy">https://github.com/alessandrod/snuffy</a>.</p><h2>Instrumenting applications with uprobes</h2><p>Uprobes let you instrument user space applications by attaching custom code to arbitrary locations inside a target process. It's a bit like running an application in a debugger, setting breakpoints and fiddling around, but programmatically and without the overhead of a debugger.</p><p>An uprobe must be <a href="https://ingraind.org/api/cargo_bpf/#building">compiled</a> and <a href="https://ingraind.org/api/redbpf/load/struct.Loader.html">loaded</a> like any other BPF program, then it can be attached with the following API:</p><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>attach_uprobe</span><span>(</span><span>
</span><span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span>
</span><span>    fn_name</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>&amp;</span><span>str</span><span>&gt;</span><span>,</span><span>
</span><span>    offset</span><span>:</span><span> </span><span>u64</span><span>,</span><span>
</span><span>    target</span><span>:</span><span> </span><span>&amp;</span><span>str</span><span>,</span><span>
</span><span>    pid</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>pid_t</span><span>&gt;</span><span>,</span><span>
</span><span></span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>;</span></code></pre><p><a href="https://ingraind.org/api/redbpf/struct.UProbe.html#method.attach_uprobe">attach_uprobe()</a> parses the <code>target</code> ELF binary or shared library, looks up the function <code>fn_name</code>, and once the target is running it injects the probe code at the resolved address. If <code>offset</code> is non-zero, its value is added to the address of <code>fn_name</code>. If <code>fn_name</code> is <code>None</code>, then <code>offset</code> is interpreted as starting from the beginning of the target's <code>.text</code> section. Finally if a <code>pid</code> is given, the probe will only be attached to the process with the given id.</p><p>In the rest of the post I'm going to show some examples of uprobes, focusing on the code that gets compiled to BPF bytecode, loaded in the kernel and then injected in the target process (in our case zoom). I'm not going to show much of the user-space code that loads the probes. That part is pretty standard rust code that does some setup, then prints out the data coming from the probes as it receives it. If you're interested you can still find all the user-space code at <a href="https://github.com/alessandrod/snuffy/blob/master/src/main.rs">https://github.com/alessandrod/snuffy/blob/master/src/main.rs</a>.</p><h2>Poking into Zoom</h2><p>We're going to use uprobes to inspect the network traffic between the zoom client and the company's servers. Zoom uses <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> to encrypt the data. In order to intercept the <em>unencrypted</em> data, we need to find out which TLS library is used by the client, then attach uprobes to strategic places inside it.</p><p>Let's start with searching for common TLS symbols using <code>objdump</code>:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "ssl|gnutls"
</span>000000000080d5b0 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_blockUnknownSSLCertChanged()
<!-- -->000000000080d590 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_sslCertWarningChanged()
</code></pre><p>Those look like callbacks that get invoked when a certificate is invalid, and Zoom does indeed show a warning if you try to intercept its traffic with a tool like <code>mitmproxy</code>. The callbacks deal with certificates, not unencrypted buffers, so they are not useful to us.</p><p>Looking at the output of <code>ldd</code> we can see that Zoom links to <a href="https://doc.qt.io/qt-5/qtnetwork-index.html">Qt Network</a>, which includes some potentially relevant APIs:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "QNetworkReq"
</span>0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::QNetworkRequest(QUrl const&amp;)
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::~QNetworkRequest()
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkAccessManager::get(QNetworkRequest const&amp;)
</code></pre><p><code>QNetworkRequest(QUrl const&amp;)</code> looks like something that could be used to communicate with the backend and does <a href="https://doc.qt.io/qt-5/qnetworkrequest.html#setSslConfiguration">support TLS</a>. I tried attaching to it and other functions exported by the framework but none of them turned out to be invoked. Zoom supports a number of platforms and devices, it's possible that they use Qt just for the UI on linux, and then have some lower level networking code that can be shared with their other clients.</p><p>At this point it is pretty likely that zoom is linking statically to the TLS library. Let's see if in the <code>.rodata</code> section of the binary there's anything that could point us in the right direction:</p><pre><code><span>$ readelf -p .rodata /opt/zoom/zoom | grep -i ssl | wc -l
</span>739
<!-- -->$ # 😏
<!-- -->$ readelf -p .rodata /opt/zoom/zoom | grep -i 'openssl 1'
<!-- -->  [4a1b66]  OpenSSL 1.1.1g  21 Apr 2020
<!-- -->  [58cd50]  OpenSSL 1.1.1g  21 Apr 2020
</code></pre><p>Aha! The client is using OpenSSL version 1.1.1g (knowing this will turn out to be very useful), and the library is statically linked.</p><h2>Instrumenting OpenSSL</h2><p>OpenSSL exports two functions named <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_read.html">SSL_read</a> and <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_write.html">SSL_write</a>, which have the following signature:</p><pre><code><span>int</span><span> </span><span>SSL_read</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span><span>
</span><span></span><span>int</span><span> </span><span>SSL_write</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>const</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span></code></pre><p><code>SSL_read</code> reads encrypted data sent by a remote peer, decrypts it and stores the decrypted data in the provided buffer. <code>SSL_write</code> encrypts the given buffer and sends it to a remote peer. Attaching an uprobe where <code>SSL_read</code> <em>returns</em>, and one at the <em>entry</em> of <code>SSL_write</code>, we can therefore access unencrypted memory.</p><p>Here's the uprobes that do just that:</p><pre><code><span>use</span><span> </span><span>redbpf_probes</span><span>::</span><span>uprobe</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span><span>
</span>
<span></span><span>struct</span><span> </span><span>SSLArgs</span><span> </span><span>{</span><span>
</span><span>    ssl</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span>    buf</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>// temporary storage map</span><span>
</span><span></span><span>static</span><span> </span><span>mut</span><span> ssl_args</span><span>:</span><span> </span><span>HashMap</span><span>&lt;</span><span>u64</span><span>,</span><span> </span><span>SSLArgs</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>HashMap</span><span>::</span><span>with_max_entries</span><span>(</span><span>1024</span><span>)</span><span>;</span><span>
</span>
<span></span><span>fn</span><span> </span><span>output_buf</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>,</span><span> mode</span><span>:</span><span> </span><span>AccessMode</span><span>,</span><span> buf_addr</span><span>:</span><span> </span><span>usize</span><span>,</span><span> len</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>// Ignore how this is implemented for now. Assume it reads `len` bytes from `buf_addr`</span><span>
</span><span>  </span><span>// and sends them to our user-space process where they are hex-dumped.</span><span>
</span><span>  </span><span>...</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_write_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>parm3</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;=</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span>
<span>    </span><span>// This is where SSL_write begins, the buffer isn't encrypted yet</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Write</span><span>,</span><span> buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span>
<span>    </span><span>// store the function arguments so we can retrieve them once the</span><span>
</span><span>    </span><span>// function returns</span><span>
</span><span>    </span><span>unsafe</span><span> </span><span>{</span><span>
</span><span>        ssl_args</span><span>.</span><span>set</span><span>(</span><span>&amp;</span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>,</span><span> </span><span>&amp;</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uretprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_ret</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// the return value of SSL_read contains the length of the buffer</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>rc</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>// This is where SSL_read returns, the buffer is now decrypted</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>let</span><span> tgid </span><span>=</span><span> </span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>;</span><span>
</span><span>    </span><span>let</span><span> args </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>get</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span> </span><span>=</span><span> args </span><span>{</span><span>
</span><span>        </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Read</span><span>,</span><span> </span><span>*</span><span>buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span>        </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>delete</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Uprobes are annotated with the <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uprobe.html">#[uprobe]</a> attribute. Once they are triggered, they get passed a <a href="https://ingraind.org/api/redbpf_probes/kprobe/struct.Registers.html">Registers</a> argument through which they can access memory.</p><p>The <code>SSL_write_entry</code> probe is the simplest. It reads the registers containing the values of the <code>buf</code> and <code>num</code> arguments passed to <code>SSL_write</code>, and sends a copy of the buffer to user-space before it gets encrypted.</p><p>The <code>SSL_read_entry</code> probe is similar in that it reads the content of the <code>ssl</code>, <code>buf</code> and <code>num</code> arguments passed to <code>SSL_read</code>. It doesn't send the buffer to user-space though. Remember the data is decrypted <em>after</em> <code>SSL_read</code> returns, so we need a second uprobe that we attach to the <em>return address</em> of the function. That's what <code>SSL_read_ret</code> is for. It's similar to the other two probes, but is annotated with <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uretprobe.html">#[uretprobe]</a>, which means that it will trigger once the function it's attached to <em>returns</em>.</p><p>But why do we need two probes for <code>SSL_read</code>, why not just have <code>SSL_read_ret</code>? The answer is that when <code>SSL_read</code> returns, it's likely that the registers that used to contain the function arguments were modified, so we need to read their values at the start of the function and store them so we can retrieve them later. This is a very common pattern when writing BPF code.</p><p>Finally if zoom linked to OpenSSL dynamically or if debugging symbols were present, the user-space code to attach the probes would be as simple as:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Attach to SSL_read and SSL_write inside libssl.</span><span>
</span><span>    </span><span>// Let redbpf resolve the symbol addresses.</span><span>
</span><span>    </span><span>match</span><span> uprobe</span><span>.</span><span>name</span><span>(</span><span>)</span><span>.</span><span>as_str</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>"SSL_read_entry"</span><span> </span><span>|</span><span> </span><span>"SSL_read_ret"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_read"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        </span><span>"SSL_write_entry"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_write"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        _ </span><span>=&gt;</span><span> </span><span>continue</span><span>,</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Unfortunately since OpenSSL is statically linked and the symbols have been stripped, redbpf can't automatically resolve the addresses of <code>SSL_read</code> and <code>SSL_write</code>, instead we have to explicitly provide the offsets we want to attach to:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> zoom_binary </span><span>=</span><span> </span><span>"/opt/zoom/zoom"</span><span>;</span><span>
</span><span>    </span><span>// …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</a></em></p>]]>
            </description>
            <link>https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434031</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Removing email registration improved retention]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 167 (<a href="https://news.ycombinator.com/item?id=24433090">thread link</a>) | @tapneal
<br/>
September 10, 2020 | https://solitaired.com/email-registration-is-dead | <a href="https://web.archive.org/web/*/https://solitaired.com/email-registration-is-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/coverimage.png"></center><p>
In our last business, where we ran popular educational products like EasyBib, we learned the power of email registration. When users registered we found that they would come back and use our service more, and eventually subscribe. </p>
<h2 id="firststeptoimproveretentionaddregistration">First step to improve retention: Add registration</h2>
<p>When building our <a href="https://solitaired.com/">solitaire site</a> then, a fun side hobby of ours, adding in email registration and account creation was immediately on our roadmap. When we added the ability to create accounts and track past scores, we immediately saw that our sessions per user increased by 5%. It was a solid win!</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fivelift.png"></center>
<p>To encourage more registrations we introduced a leaderboard to see how you performed against other players. You could see how your time and number of moves compared to others who played the same game, and we encouraged sign ups to get your name on the leaderboard. This improved registrations by 22%, and we saw sessions per user increase another 3%. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/threelift.png"></center>
<p>All these features encouraged users to play more, compete against themselves and others, and return to the site.</p>
<h2 id="dosendingemailsmoveourkpis">Do sending emails move our KPIs?</h2>
<p>By now, we had learned that registration was a powerful feature in our game to drive loyalty and retention. Given that we were collecting emails as part of our standard registration process, we naturally thought emailing our user base, which had reached over 15,000 users, could naturally drive more return usage. </p>
<p>We started emailing our users to play a new game of the day feature we introduced. Open rates were a solid 17% on average, but click through rates to the game were 1%. This meant it drove about 26 more users to our site (15,000 * 17% * 1%). Moreover, these could have been users who would have gone back to Solitaired whether they read our email or not. </p>
<p>We saw a 0.5% improvement in returning users, but when we stopped sending emails, this didnâ€™t change suggesting the modest improvement was just noise.</p>
<h2 id="removingemailregistration">Removing email registration</h2>
<p>While registration, saving accounts, and leaderboards improved retention, sending emails clearly did not. </p>
<p>I was watching my sister play, who had become a solitaire addict after she QAing the game. She was obsessed with beating her personal bests and getting high scores for the game of the day. When I watched her play though, quizzically, she had not registered for an account. </p>
<p>I asked her why, she said she just didnâ€™t want to give her email away and get bombarded by more emails. I was dumbfounded, because after all, her brother (me), was the co-founder of the site and yet she still had these concerns.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/sister.png"></center>
<p>The lightbulb went off. Since sending emails did not provide value, and if anything was an additional cost,  what if we just asked for a username. While this creates issues with password recovery, we thought this would drive up registrations and improve retention. We also have a long term cookie so users wouldnâ€™t have to login again. </p>
<p>When we changed email sign ups simply to usernames, we saw registrations increase by a huge 36%! More importantly, we saw return users increase another 4.5%.</p>
<p>This meant email registration was holding us back from driving retention. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fourfivelift.png"></center>
<p>Digging in further, we're also seeing return visitors playing more games like <a href="https://solitaired.com/freecell">Freecell</a> and <a href="https://solitaired.com/spider">Spider</a>. Leaderboards and simple registration have encouraged users to try new games.</p>
<h2 id="weassumeemailisvaluable">We assume email is valuable</h2>
<p>Depending on your site and space, email surely can be valuable. For ecommerce sites, you can send targeted emails with special offers, for example. </p>
<p>Most of us assume email is beneficial to our businesses, and we rarely test to see if thatâ€™s the case. We have it because it gives us an owned channel to reach out and engage our users whenever we want. </p>
<p>However, we're forgetting a key fact: most of us also hate emails from commercial sites. They clog our inbox, and we instinctually either ignore or delete them. Every once in a while we might open one of those emails up, and even more rarely, we might click the call to action in the email. </p>
<p>Ask if requiring email addresses really moves important business metrics for your site. Sometimes they do. In our case, it just created a poor user experience which weâ€™re now happy to be rid of.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/email-registration-is-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433090</guid>
            <pubDate>Thu, 10 Sep 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Clojure Spec is and what you can do with it]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24432461">thread link</a>) | @icey
<br/>
September 10, 2020 | https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/ | <a href="https://web.archive.org/web/*/https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.pixelated-noise.com/assets/images/people/stathis-sideris.jpeg"></p><div><p>Stathis Sideris</p><p>2020-09-10</p></div></div>
<p>
<i>Pixelated Noise is a software consultancy and we're always looking for interesting projects to help out with. If you have unmet software development needs, we would be happy <a href="https://www.pixelated-noise.com/contact/">to hear from you</a>.</i>
</p>

<p>
This is the blog version of a talk I gave on the 2017-12-13 at the Athens
Clojure Meetup, which was kindly hosted by <a href="https://engineering.skroutz.gr/">Skroutz</a>. <a href="https://www.youtube.com/watch?v=T1qpIaB6_vM">The video of the talk</a> is
available (the talk was given in Greek, but there are English subtitles). This
blog entry is not an exact transcript of the talk, I've added links and more
information where appropriate (plus the "bonus" sections that were not in the
talk). Since the talk was given a while ago, some information will be outdated.
</p>

<p>
There are essentially two parts to this article: the "what it is" part which
introduces the basic concepts and mechanisms of spec, and also provides some
information so that non-Clojurians can see how spec fits into the larger picture
and the "what you can do with it" part which explores some more interesting use
cases that go beyond basic usage.
</p>

<div id="outline-container-orge99096d">
<h2 id="orge99096d">What is it?</h2>
<div id="text-orge99096d">
<p>
Clojure is a dynamic language that doesn't enforce the types of parameters or
the return values of functions. This has been a characteristic of the language
that has drawn criticism both internally and from other language communities and
has possibly been a factor impeding adoption in the past.
</p>

<p>
Spec in a way is the response to that, but it's a response that maybe the
community didn't expect because it does not take the traditional approach of
checking types statically. At a very fundamental level spec is a declarative
language that describes data, their type, their shape. Spec follows the general
philosophy of Clojure in that all of its functionality is available at runtime,
you can use it, introspect it, generate it – there is no extra step before
execution when the compiler checks your whole codebase for errors.
</p>
</div>

<div id="outline-container-org56f06dc">
<h3 id="org56f06dc">What does it look like?</h3>
<div id="text-org56f06dc">
<p>
Spec is still alpha, so the namespace in the <code>require</code> contains <code>.alpha</code> to indicate
that. The following spec defines a <code>username</code> "entity" and says that it has to be
a string:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
</pre>
</div>

<p>
<code>string?</code> is a simple function that exists in Clojure core, it's a
predicate function that you pass a string to and it returns <code>true</code> or
<code>false</code>, depending on whether the passed value is a string or not.
</p>

<p>
Once you've defined a spec the simplest usage of it is to ask whether
something is valid, by calling <code>valid?</code>, and passing the name of the
spec and then a value:
</p>

<div>
<pre>(println
 (<span>s</span>/valid? <span>::username</span> <span>"foo"</span>))
</pre>
</div>

<pre>true
</pre>
</div>
</div>

<div id="outline-container-orgfa7c72e">
<h3 id="orgfa7c72e">It's just predicates!</h3>
<div id="text-orgfa7c72e">
<p>
Many cases are covered by built-in predicates, but that doesn't mean
we can't use our own. If we need a spec that checks that a number is
above 5, we can simply write an anonymous function like this one,
and then use it normally as it if was a spec itself:
</p>



<pre>true
</pre>


<p>
And it works as expected with different inputs:
</p>



<pre>false
</pre>
</div>
</div>

<div id="outline-container-org6c5c14c">
<h3 id="org6c5c14c">Validate data</h3>
<div id="text-org6c5c14c">
<p>
So, we write a spec and it can validate our data. Let's draw this as a
diagram: the thing on the left that looks like a blueprint is a spec and the
curly braces on the right represents Clojure data (because very often data in
Clojure are maps and maps are written with curly braces). Read the weird arrow
in the middle as "validates":
</p>


<p><img src="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/validate-data.png" alt="validate-data.png">
</p>

<p>
It's not much of a diagram, but I'm trying to establish the visual language
for the rest of this article.
</p>
</div>
</div>

<div id="outline-container-orgea7799a">
<h3 id="orgea7799a">Collections specs</h3>
<div id="text-orgea7799a">
<p>
Specs can also be applied to collections by composing and nesting
more basic specs together. Here we define an entity called <code>usernames</code>
made up of a collection of <code>username</code>:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::usernames</span> (<span>s</span>/coll-of <span>::username</span>))

(println
 (<span>s</span>/valid? <span>::usernames</span> [<span>"foo"</span> <span>"bar"</span> <span>"baz"</span>]))
</pre>
</div>

<pre>true
</pre>


<p>
You would normally not define this as a separate entity for something that
simple, as <code>s/coll-of</code> can be used ad-hoc in your program.
</p>
</div>
</div>

<div id="outline-container-org81b3460">
<h3 id="org81b3460">Maps</h3>
<div id="text-org81b3460">
<p>
Maps are a bit more interesting. Other technologies such as <a href="https://github.com/plumatic/schema">plumatic
schema</a> (which at some point was the de facto way to validate data in
Clojure), ask you to define both the keys that have to be present in
a map and the data types of the values that correspond to the
keys. The resulting definition looks a bit like a rigidly-defined
class that you usually see in object-oriented languages. Spec very
deliberately moves away from this mentality: the maps are <b>not</b> like
objects, they are <b>not</b> fixed and do not necessarily exist in that one
shape. Instead, maps simply happen to be aggregations of some named
values.
</p>

<p>
This design decision is embodied in two ways:
</p>

<ul>
<li>A map spec written using <code>s/keys</code> which does not define the types of
the values of the map, we only define which existing entities make
up the map.</li>

<li>The name of the key inside the map has to be the same as the name
of the spec already defined elsewhere.</li>
</ul>

<p>
In this case we have defined some single-value specs like username,
password, last-login and comment, and they are aggregated together
in a map defined by the <code>::user</code> spec.
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println <span>::username</span>)

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000}))
</pre>
</div>

<pre>:my-project.users/username ;;this is what fully-qualified keywords look like
true
</pre>


<p>
Spec also encourages the use of qualified keywords: Until recently
in Clojure people would use keywords with a single colon but the two
colons (<code>::</code>) mean that keywords belong to this namespace, in this
case <code>my-project.users</code>. This is another deliberate choice, which is
about creating strong names (or "fully-qualified"), that belong to a
particular namespace, so that we can mix namespaces within the same
map. This means that we can have a map that comes from outside our
system and has its own namespace, and then we add more keys to this
map that belong to our own company's namespace without having to
worry about name clashes. This also helps with data provenance,
because you know that the <code>:subsystem-a/id</code> field is not simply an ID
– it's an ID that was assigned by subsystem-a.
</p>
</div>
</div>

<div id="outline-container-org3248f46">
<h3 id="org3248f46">Maps are open</h3>
<div id="text-org3248f46">
<p>
The other interesting thing about specs for maps is that they are
open. For example, if we use the same exact map as before, with the
same fields and an additional field called <code>::age</code>, it's still a valid
<code>::user</code>:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000
   <span>::age</span>        26}))
</pre>
</div>

<pre>true
</pre>


<p>
This happens because spec does not mind if you've defined four keys, if it
sees a fifth key the map does not become invalid. The reason for this is that
when we have a system that accumulates information this accumulation should
not break the system, the code that consumes the map should simply ignore the
keys it doesn't know about. If you're making a system and you're accumulating
extra options, parameters, whatever it is – your code should be able to
continue to run without having to change a lot of code locations, like you
would have to do in an object oriented language or Haskell.
</p>

<p>
This accumulation has also been described by the term "accretion"
and has been discussed in the excellent <a href="https://www.youtube.com/watch?v=oyLBGkS5ICk">Spec-ulation Keynote talk</a> by
Rich Hickey.
</p>

<p>
On the other hand, a lot of people who use spec to validate things coming from
outside their system need to be more strict with maps, and they have
complained about the openness of maps. We'll talk about proposed solutions to
this issue later.
</p>
</div>
</div>

<div id="outline-container-org0b68930">
<h3 id="org0b68930">Explain your problems</h3>
<div id="text-org0b68930">
<p>
Another usage of specs, beyond validation, is "explain" which
essentially can produce errors that tell you what's wrong with your
data. In this case we'll try to create an error by creating a user
that's invalid because it doesn't have a password – a required key:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(<span>s</span>/explain
 <span>::user</span>
 {<span>::username</span>   <span>"rich"</span>
  <span>::comment</span>    <span>"this is a user"</span>})
</pre>
</div>

<p>
We get an ok-ish error that tells us that for the particular map we
passed, the <code>::user</code> spec fails because it doesn't contain <code>::password</code>.
</p>

<pre>val: #:my-project.users{:username "rich", :comment "this is a user"} fails spec: :my-project.users/user predicate: (contains? % :my-project.users/password)
</pre>
</div>
</div>

<div id="outline-container-orgb0d0b9f">
<h3 id="orgb0d0b9f">Sequence specs - regular expressions for data</h3>
<div id="text-orgb0d0b9f">
<p>
A powerful mechanism in spec is sequences. We've already seen <code>s/coll-of</code> which
contains a uniform type of values (a collection of numbers for example) but
sequences are a bit more like regular expressions for data. In this case we
have a sequence with two things, which describe an ingredient for a recipe:
the first thing is a number for the quantity and the second thing is a unit
encoded as a keyword.
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::ingredient</span> (<span>s</span>/cat <span>:quantity</span> number? <span>:unit</span> keyword?))
</pre>
</div>

<p>
With <code>s/cat</code> we always have to give a name to each position. <code>s/cat</code>
allows to both validate the shape of the value passed, but it also
enables the "conform" operation, which is somehow similar to parsing
or destructuring. If we pass a vector of two elements – a number and
a keyword –  we get back a map with the defined names:
</p>

<div>
<pre>(prn (<span>s</span>/conform <span>::ingredient</span> [2 <span>:teaspoon</span>]))
</pre>
</div>

<pre>{:quantity 2, :unit :teaspoon}
</pre>


<p>
By using some of the other operators which are reminiscent of regular
expressions, this technique can become quite …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</a></em></p>]]>
            </description>
            <link>https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432461</guid>
            <pubDate>Thu, 10 Sep 2020 14:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 439 | Comments 210 (<a href="https://news.ycombinator.com/item?id=24429012">thread link</a>) | @Garbage
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429012</guid>
            <pubDate>Thu, 10 Sep 2020 04:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The amazing $1 microcontroller (2017)]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24426882">thread link</a>) | @appwiz
<br/>
September 9, 2020 | https://jaycarlson.net/microcontrollers/ | <a href="https://web.archive.org/web/*/https://jaycarlson.net/microcontrollers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Silcon Labs EFM8: Fantastic value and ease-of-use from the only 8-bit part with a totally-free cross-platform vendor ecosystem</h4><p>The <a href="https://jaycarlson.net/pf/silicon-labs-efm8/">EFM8</a> was the fastest 8-bit part in my round-up, and admittedly, my favorite 8-bit architecture to develop with overall. What these parts lack in brains they make up for in brawns — 14-bit ADCs, 12-bit DACs, lots of timers, and a 72 MHz core clock speed that gives you timing options not found in any other part in the round-up.</p><p>Plus, this is the only 8-bit part with a totally-free, cross-platform, vendor-provided ecosystem. Let that sink in.</p><p>Keil C51 is a silly compiler, but Silicon Labs does an excellent job hiding it under the hood — even when running its Eclipse-based Simplicity Studio on Linux or macOS.</p><p>Simplicity Configurator is the lightest-weight code generator in our round-up, using only 534 bytes of flash to house the entire DMX-512 receiver project. It was one of the easiest to use, and seemed to strike a good balance between abstraction, performance, and ease of use.</p><p>Debugging speeds are snappy with a J-Link debugger, but at $35, the official Silicon Labs USB Debug Adapter is one of the cheapest first-party debugger in the round-up, and clones of the hardware are even cheaper.</p><p>And call me old-fashioned, but I think the 8051 definitely has a place in 2017 — especially among hobbyists and students, where its bit-addressable memory, easy-to-use peripherals, and fuse-free configuration help get students comfortable with microcontrollers quickly.</p><h4>Microchip megaAVR &amp; tinyAVR 1-Series: Different strokes for different folks — still with the best 8-bit toolchain available</h4><p>The <a href="https://jaycarlson.net/pf/atmel-microchip-megaavr/">megaAVR</a> came in surprisingly flat for me: especially when compared with its lower-cost, new sibling, the <a href="https://jaycarlson.net/pf/atmel-microchip-tinyavr-1-series/">tinyAVR 1-Series</a>.</p><p>There’s no comparison when it comes to price: tinyAVR has incredible value — packing in a nice assortment of timers, analog peripherals (including a DAC), and a new 20 MHz internal oscillator — while costing 20-40% less than the megaAVR.</p><p>While the megaAVR has a perplexing debugging experience that requires two completely different interfaces and protocols to work with the part, the new one-wire UPDI interface the tinyAVR sports worked flawlessly in my testing.</p><p>But that’s the crux of the problem for the tinyAVR — by shedding many of its megaAVR roots, Microchip ended up with a wonderful microcontroller that will be challenging to use for a large base of Atmel fans: indie developers and hobbyists who use low-cost, open-source programmers (which don’t support the UPDI interface).</p><p>While the tinyAVR wasn’t the fastest part in the round-up (even among 8-bitters), it was the most efficient – both in terms of active-mode power and clock efficiency. Amazingly, the AVR only uses about twice as many instructions as 16- and 32-bit parts when performing 16-bit math.</p><p>Unfortunately, the AVR system as a whole is not without its issues. The Windows-only Atmel Studio is still buggy (especially with older megaAVR devices and AVR Dragon stuff in my tests), and there isn’t an under-$50 low-cost debugger available (other than hacking apart Xplained Mini dev boards).</p><p>In many ways, there seems to be a tacit demarcation Atmel creates between its hobbyist/indie developers, and the professional shops that use Atmel parts.</p><p>As a professional embedded developer, I most definitely have access to Windows computers, and I have no problem blowing a few billable hours’ worth of pay on a $140 debugger.</p><p>But even as popular as Atmel is among hobbyists, Atmel has largely stayed out of this space directly. Instead, they’ve secured small-volume AVR sales by relying on the open-source community to build their own tools for themselves: turning out a slew of hardware and software used to program the megaAVR devices.</p><p>While I applaud the efforts of these developers, these tools are inferior to Atmel’s. Their programming speeds are terrible, they don’t support the new tinyAVR 1-Series devices, and they have absolutely no debug capability.</p><p>Having said that, both the megaAVR and tinyAVR have the best toolchain available for 8-bit MCU development. The part supports a full, end-to-end Makefile-based GCC toolchain.</p><p>If you love printf() debugging, would never touch a proprietary toolchain, and hate IDEs, megaAVR and old tinyAVR parts are definitely for you. The older ones are still available in DIP packages, and as you probably know, there are a ton of low-cost programmers available across the world. The online community is massive, and as clunky as I find Atmel START to be, I have to applaud its support for Makefile-based project generation.</p><p>Consequently, the megaAVR remains the most open-source 8-bit microcontroller on the market — by a long shot.</p><p>But I’d really like to see Microchip provide a PicKit-priced debugger with UPDI support — and allow off-board debugging the way their PIC Curiosity Boards do.</p><p>I also hope these open-source projects can add UPDI support to their tools, so that hobbyists and indie developers can start integrating the tinyAVR into their projects — it’s a much better part, and if you’re an AVR user with access to Atmel Studio, you really ought to buy an Xplained Mini board and take it for a spin.</p><h4>STM32F0: A low-cost, no-nonsense part with arguably the best Arm development ecosystem tested</h4><p><a href="https://jaycarlson.net/pf/st-stm32f0/">The STM32F0</a> was the lowest-power Arm microcontroller in the round-up, and also one of the easiest to use. STM32CubeMX doesn’t generate the most compact code on Arm (that honor belongs to Cypress PSoC Creator and Infineon DAVE), but it has a snappy interface, and the generated code is easy enough to manipulate for your own goals.</p><p>I love the nearly-stock Eclipse-based environment that System Workbench for STM32 provides, and the ST-Link and excellent Discovery/Nucleo boards seals the deal for me.</p><p>Most pros have used ST parts in their work, but for all these reasons, any hobbyist looking at moving to Arm should probably pick up a dev board from this ecosystem, too. ST has a huge market footprint, so there’s tons of resources online — aimed at both hobbyists and professionals.</p><h4>SAM D10: Killer performance &amp; peripherals, but with runtime library hiccups</h4><p>The Microchip/Atmel <a href="https://jaycarlson.net/pf/atmel-microchip-sam-d10/">SAM D10</a> (and the broader D11/D20/D21 ecosystem) has good value (considering their analog portfolio includes a DAC, and they have good timing options), and the SAM D10 was the most efficient part tested when running at full speed.</p><p>Professionals will like the easy-to-use, well-documented header files, and hobbyists will appreciate the 1.27mm-pitch SOIC package options and GCC compilers that come with the Arm ecosystem. But before I grab this part for a project, Microchip really needs to fix the extremely slow, bloated peripheral library, and update their code-gen tool to do proper error-checking of clock and peripheral configurations.</p><p>As it is, whenever I use Atmel START on the D10, I want to STOP almost immediately. And there are no current, stand-alone peripheral drivers that Microchip has released for this part, so unless you want to do register programming from scratch, you’ll be relying on third-party, open-source projects — like Alex Taradov’s <a href="https://github.com/ataradov/mcu-starter-projects">code examples</a>.</p><h4>Infineon XMC1100: Interesting peripheral perks make this Cortex-M0 stand out</h4><p>The most interesting Arm chip was, without a doubt, the <a href="https://jaycarlson.net/pf/infineon-xmc1100/">Infineon XMC1100</a> — and I think professionals who may be wary of getting out of the ST/NXP/Atmel Arm ecosystem need to take a second look at these XMC1000 (and XMC4000) parts.</p><p>The timer options are amazingly flexible, and you can squeeze fantastic performance out of the USIC module.</p><p>I’m going to go out on a limb and recommend that serious hobbyists who are building motor / lighting control projects look into these parts, too. DAVE makes setting up these complex peripherals painless, and the 38-pin TSSOP chips will be substantially easier to solder than the 0.5mm QFNs and QFPs you usually end up with in these pin counts.</p><p>Like many of the parts reviewed here, the biggest problem for hobbyists and indie developers is the tiny online communities and lack of GitHub repos with open-source projects that use these chips. My advice — be bold, and post in the forums. Infineon employees monitor and usually respond within a day or so.</p><h4>PIC16: Tons of peripherals with a slower, power-efficient core</h4><p>When you compare the <a href="https://jaycarlson.net/pf/microchip-pic16-five-digit-enhanced/">PIC16</a> with other 8-bit parts out there, it’s obviously a part built for low-power applications, and not processing power. And while the development ecosystem is workable, there are other parts more friendlier pathways — especially for smaller shops, hobbyists, and students who need extremely low-cost tools (and free software).</p><p>To add fuel to the PIC-vs-AVR debate, my testing found that a 32 MHz PIC16 is roughly equivalent to an AVR part running at 1.4 MHz (in terms of math performance), and 9 MHz (in terms of bit-shuffling performance).</p><p>Having said that, the DMX-512 receiver seems a perfect match for the PIC16, and that’s where it looks best in my testing: the PIC16 was the lowest-power 8-bit part in my testing.</p><p>It’s also full of timers and digital logic-oriented peripherals that make it suitable for funky special-purpose projects that require some crafty use of configurable logic and and the numerically-controlled oscillator — these peripherals help offload the (relatively slow) CPU, at the expense of requiring more developer familiarity with the device and these peripherals.</p><p>The usual Microchip gotchas apply: clunky IDE, expensive compilers, and expensive debuggers.</p><p>The usual Microchip advantages apply: huge online community, seemingly infinite product lifetime guarantees, and DIP, SOIC, QFP, and QFN package availability.</p><h4>PIC24: An expensive MSP430 wannabe that doesn’t hit the mark</h4><p>The <a href="https://jaycarlson.net/pf/microchip-pic24/">PIC24</a> is nearly forgettable. In the biquad test, it’s marginally faster than the <a href="https://jaycarlson.net/pf/renesas-rl-78/">Renesas RL-78</a> but uses almost three times as much power. In the DMX-512 test, both the RL-78 and MSP430 beat it, too. It was also one of the least-endowed parts in the round-up (which really just means it’s expensive — higher-end PIC24 parts have no shortage …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jaycarlson.net/microcontrollers/">https://jaycarlson.net/microcontrollers/</a></em></p>]]>
            </description>
            <link>https://jaycarlson.net/microcontrollers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24426882</guid>
            <pubDate>Wed, 09 Sep 2020 22:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zink (OpenGL on Vulkan) performance better than expected]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 89 (<a href="https://news.ycombinator.com/item?id=24424462">thread link</a>) | @mfilion
<br/>
September 9, 2020 | http://www.supergoodcode.com/funday/ | <a href="https://web.archive.org/web/*/http://www.supergoodcode.com/funday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2 id="just-for-fun">Just For Fun</h2>

<p>I finally managed to get a complete piglit run over the weekend, and, for my own amusement, I decided to check the timediffs against a reference run from the IRIS driver. Given that the Intel drivers are of extremely high quality (and are direct interfaces to the underlying hardware that I happen to be using), I tend to use ANV and IRIS as my references whenever I’m trying to debug things.</p>

<p>Both runs used the same base checkout from mesa, so all the core/gallium/nir parts were identical.</p>

<p>The results weren’t what I expected.</p>

<p>My expectation when I clicked into the timediffs page was that zink would be massively slower in a huge number of tests, likely to a staggering degree in some cases.</p>

<p>We were, but then also on occasion we weren’t.</p>

<p>As a final disclaimer before I dive into this, I feel like given the current state of people potentially rushing to conclusions I need to say that <strong>I’m not claiming zink is faster than a native GL driver</strong>, only that <strong>for some cases, our performance is oddly better than I expected</strong>.</p>

<h2 id="the-good">The Good</h2>
<p><img src="https://zmike.github.io/assets/piglit-misc-bench.png" alt="piglit-misc-bench.png"></p>

<p>The first thing to take note of here is that IRIS is massively better than zink in successful test completion, with a near-perfect 99.4% pass rate compared to zink’s measly 91%, and that’s across 2500 more tests too. This is important also since timediff only compares between passing tests.</p>

<p>With that said, somehow zink’s codepath is significantly faster when it comes to dealing with high numbers of varying outputs, and also, weirdly, a bunch of <code>dmat4</code> tests, even though they’re both using the same softfp64 path since my icelake hardware doesn’t support native 64bit operations.</p>

<p>I was skeptical about some of the numbers here, particularly the <code>ext_transform_feedback</code> <code>max-varying-arrays-of-arrays</code> cases, but manual tests were even weirder:</p>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink  -auto -fbo  2.13s user 0.03s system 98% cpu 2.197 total
</code></pre></div></div>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris  -auto -fbo  301.64s user 0.52s system 99% cpu 5:02.45 total
</code></pre></div></div>

<p>wat.</p>

<p>I don’t have a good explanation for this since I haven’t dug into it other than to speculate that ANV is just massively better at handling large numbers of varying outputs.</p>

<h2 id="the-bad">The Bad</h2>

<p>By contrast, zink gets thrashed pretty decisively in <code>arb_map_buffer_alignment-map-invalidate-range</code>, and we’re about <strong>150x slower</strong>.</p>

<p>Yikes. Looks like that’s going to be a target for some work since potentially an application might hit that codepath.</p>

<h2 id="the-weird">The Weird</h2>
<p><img src="https://zmike.github.io/assets/piglit-fp64-bench.png" alt="piglit-fp64-bench.png"></p>

<p>Somehow, zink is noticeably slower in a bunch of other fp64 tests (and this isn’t the full list, only a little over half). It’s strange to me that zink can perform better in certain fp64 cases but then also worse in others, but I’m assuming this is just the result of different shader optimizations happening between the drivers, shifting them onto slightly less slow parts of the softfp64 codepath in certain cases.</p>

<p>Possibly something to look into.</p>

<p>Probably not in too much depth since softfp64 is some pretty crazy stuff.</p>

<h2 id="in-closing">In Closing</h2>
<p>Tests (and especially piglit ones) are not indicative of real world performance.</p>

  </div></div>]]>
            </description>
            <link>http://www.supergoodcode.com/funday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424462</guid>
            <pubDate>Wed, 09 Sep 2020 18:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classes are a way of writing higher order functions]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 147 (<a href="https://news.ycombinator.com/item?id=24422547">thread link</a>) | @stopachka
<br/>
September 9, 2020 | https://stopa.io/post/250 | <a href="https://web.archive.org/web/*/https://stopa.io/post/250">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Joe and I recently <a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">kicked off a re-read of SICP</a>. I can say that it is <em>the</em> most interesting textbook I have gone through. Imagine, you begin with just 4 or 5 constructs, and you end up building algebraic equation solvers, circuit simulators, and even logic programming languages. Because you start off with such few constructs, the added benefit is that you begin to see the fundamentally simple, shared essence in programming. </p><p>I wanted to give you one example that surprised me in the book. We tend to think that <strong>classes belong in a</strong> <strong>fundamentally different category</strong> <strong>from functions.</strong> </p><p>But are they so different? </p><p>For example, let’s say we have a class like this:</p><pre><code>class Person { 
  constructor(firstName, lastName) {
    this.fName = firstName; 
    this.lName = lastName;
  }
  getFullName() { 
    return this.fName + ' ' + this.lName;
  }
  setFirstName(firstName) {
    this.fName = firstName;
  }
}</code></pre><p>Well, if we think about it, this is really just a higher order function. a <code>Person</code> higher order function accepts arguments (constructor), and returns a list of functions that can manipulate those arguments (methods). We could write <code>Person</code> like this: </p><pre><code> function Person(firstName, lastName) {
  let fName = firstName; 
  let lName = lastName;

  function getFullName() { 
    return fName + ' ' + lName;
  }
  
  function setFirstName(firstName) { 
    fName = firstName
  }

  return function(method) { 
    switch (method) { 
      case 'getFullName': 
        return getFullName;
      case 'setFirstName': 
        return setFirstName;  
    }
  }
}</code></pre><p>Now, </p><pre><code>const person = new Person("Ben", "Bitdiddle")
person.getFullName()</code></pre><p>becomes</p><pre><code>const person = Person("Ben", "Bitdiddle")
person('getFullName')()</code></pre><p>Here, instead of invoking a method, we are “passing” a message. This is why by the way, many classic OO folks talk about object orientation really being about message passing.  </p><p>Yup, really. Classes are just higher order functions, which accept arguments (constructor) and return a list of functions that can manipulate those arguments (methods). </p><p>When you previously thought two concepts were different, but they turn out to be the same, you’re ripe to discover new ideas: you can find the deeper abstractions between them, apply ideas from across those seemingly different categories, and move between concepts more fluidly. So, not only are epiphanies like this fun, but they’re much more useful than you’d think. </p><p>If you liked this, there are a <em>ton</em> of similar epiphanies in the textbook. To experience it best, I suggest picking a partner and working through the book together.</p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Jacky Wang for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/250</link>
            <guid isPermaLink="false">hacker-news-small-sites-24422547</guid>
            <pubDate>Wed, 09 Sep 2020 16:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[State of Self-Serve Website Building in 2020]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24421780">thread link</a>) | @nreece
<br/>
September 9, 2020 | https://sprune.com/blog/state-of-self-serve-website-building-in-2020/ | <a href="https://web.archive.org/web/*/https://sprune.com/blog/state-of-self-serve-website-building-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h2 id="while-building-our-simple-new-website-we-evaluated-many-website-builder-options-and-realized-how-much-the-landscape-has-changed-for-self-serve-business-website-design-and-hosting-in-this-post-we-ll-review-three-most-practical-diy-approaches-suitable-for-a-simple-static-website-up-to-a-full-content-management-system-cms-">While building our <a href="https://sprune.com/">simple new website</a>, we evaluated many website builder options, and realized how much the landscape has changed for self-serve business website design and hosting. In this post, we'll review three most practical DIY approaches, suitable for a simple static website up-to a full Content Management System (CMS).</h2><p>Back in the day, small-businesses would hire a designer and a web developer to get their website custom made. Then came WordPress, and it changed self-serve website content management forever. However, over the years WordPress has become bloated with features and plugins, resulting in a slow browsing experience and software security issues.</p><p>Having a fast website is the number one success factor for any small-business digital strategy. A fast website makes website visitors less anxious, improves their engagement, results in more sales, and improves search engine rankings.</p><p>In the past few years, the web development community is understandably shifting to static hosting, which basically involves delivering pre-generated static HTML content pages, instead of serving them from a database on each request. This makes the browsing experience much faster, without any backend overhead or security issues.</p><p>Running a Software-as-a-Service (SaaS), a website CMS separate from our product web app allows content writers and team members to quickly and independently edit the website (e.g. marketing copy, pricing notes, FAQ etc.) or publish new content (e.g. blog posts) without involving a tech person or initiating the workflow for Continuous Integration and Delivery (CI/CD).</p><p>It's gotten so much easier and quicker to publish content on our own terms.</p><p>So, how can an indie maker, startup or small-business launch a neat and fast website in reasonably less time, that's still easy to maintain?</p><h3 id="simpler-cms">Simpler CMS</h3><p>There are several WordPress alternatives available now, which are easier, faster, and more suitable for small-medium scale publishing. I'll review my top choice to keep things simple.</p><p><a href="https://ghost.org/">Ghost</a> is a beautiful blogging web software, that we ended up using for our own website. It's clean, fast, has a decent selection of themes, and even has in-built support for newsletters. You can self-host it on a small server (one-click deployment on a $5 VM on <a href="https://www.vultr.com/">Vultr</a> or <a href="https://www.digitalocean.com/">DigitalOcean</a> will do), or you can use <a href="https://ghost.org/pricing/">managed Ghost hosting</a> if self-hosting seems hard to you.</p><p><a href="https://wikipedia.org/wiki/Headless_content_management_system">Headless CMS</a>s are also gaining momentum. They provide a backend to store the content, and an Application Programming Interface (API) to retrieve the stored content using client-scripts on a static website. Altogether, it's particularly useful for sites built with <a href="https://jamstack.org/">JAMstack</a> (JavaScript, APIs, Markup). Check-out the <a href="https://headlesscms.org/">list of headless CMSs</a> for Jamstack sites.</p><h3 id="website-builders">Website Builders</h3><p>Don't worry if you haven't heard of <a href="https://wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> editors from the past, like FrontPage or Dreamweaver. Some modern website builders offer a similarly visual but more end-to-end workflow, from drag-and-drop designing to one-click publishing, all from within the platform.</p><p><a href="https://webflow.com/">Webflow</a> is a fantastic platform to build a full responsive website with a blog, e-commerce store or any other dynamic section (e.g. knowledge base, team profiles etc.). Their gallery of high-quality templates is impressive to choose from. The intuitive website builder makes layouts and content management a breeze, but that's not where it ends. It generates a static website on each publish action, maintains a change history, and hosts the static website on a global Content Delivery Network (CDN) for fastest delivery. It even takes care of asset minification, and assigning &amp; renewing SSL certificates.</p><p><a href="https://versoly.com/">Versoly</a> is also a good option for quickly building blocks-based websites, landing pages, and publish blog posts etc.</p><p>A lot of use-cases only require a one-page website, or a static frontend to a Single Page Application (SPA).</p><p><a href="https://carrd.co/">Carrd</a> is awesome for such single-page responsive websites. It has a simple drag-and-drop builder, which also supports layout sections (emulating a multi-page site). Like Webflow, they also host the website, and take care of SSL certificates. Carrd is the quickest way to having a neat website up &amp; running, minus a blog.</p><h3 id="static-site-generators">Static Site Generators</h3><p>A more advanced option for building static websites is using a generator tool, that takes a bunch of pages and posts (written in plain-text or Markdown) saved in a local folder, and generates the formatted HTML website based on a template.</p><p>Static site generators provide the most freedom in changing a hand-coded template, its layout, styling or tags.</p><p><a href="https://gohugo.io/">Hugo</a> and <a href="https://jekyllrb.com/">Jekyll</a> are probably the most popular of this kind, but there are many <a href="https://www.staticgen.com/">more static site generators</a> out there. The generated static website can also be automatically published to a static hosting provider, like <a href="https://www.netlify.com/jamstack/">Netlify</a>.</p><p>Pages and posts can also be pushed to a remote repository like Git on <a href="https://github.com/">GitHub</a> or <a href="https://gitlab.com/">GitLab</a> for free, to have them auto-generate the static site on each change (commit), and even host it on their Pages service.</p><p>One other unique blogging platform that turns a folder into a blog, is <a href="https://blot.im/">Blot</a>.</p><h3 id="bonus-stock-media">Bonus: Stock Media</h3><p>Captivating images, videos, icons and fonts can add flair to a business website, as long as they're not excessive enough to dramatically increase the page size. Check-out the <a href="https://github.com/neutraltone/awesome-stock-resources">awesome stock resources</a> repository for a long list of public domain (free) stock media resources.</p><p>Overall, there are many smart options and public resources available for building a business website in less time &amp; effort than ever before. Good luck with your next one!</p>
			</section></div>]]>
            </description>
            <link>https://sprune.com/blog/state-of-self-serve-website-building-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421780</guid>
            <pubDate>Wed, 09 Sep 2020 15:02:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Code vs. Pro-Code: A New Hope]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24421767">thread link</a>) | @ochiba
<br/>
September 9, 2020 | https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/ | <a href="https://web.archive.org/web/*/https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>When it comes to building apps, no-code is having its moment. Typeform is a shining example of how no-code is well suited for simple use cases, and here at JourneyApps we use it extensively. However, therein lies the problem: No-code’s sweet spot is simple use cases. This limitation of no-code tools has been well analyzed. [<a href="https://journeyapps.com/blog/low-code-road-to-software-enlightenment-part-1/">1</a>][<a href="https://www.alexhudson.com/2020/01/13/the-no-code-delusion/">2</a>]</p>

<p>If you want to build more sophisticated custom software, you essentially have two options:</p>

<ol>
  <li>
    <p>Use a no-code/low-code tool and jump through nasty hoops to implement the sophisticated parts of your app — which most often means writing actual code that needs to conform to the constraints of the tool.</p>
  </li>
  <li>
    <p>Use pro-code tools such as Swift/Objective-C, or frameworks like Xamarin/MAUI, etc.</p>
  </li>
</ol>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/1.png" alt="image"></p>

<p><em>Image: building anything beyond basic logic with a visual programming language ends up looking like this</em></p>

<h3 id="a-big-problem-that-needs-solving">A Big Problem That Needs Solving</h3>

<p>Both of the above approaches (using pro-code, or using a low-code platform’s pro-code extensibility) are time-consuming, although for different reasons. Both also require senior developer talent, while senior developers are as scarce as hen’s teeth.</p>

<p>The result is that many companies are highly constrained while executing on ambitious software and digital initiatives.</p>

<p>These are the companies that we serve. Enterprise developers have been building custom apps using code on JourneyApps since 2009.</p>

<p>Towards the end of 2019 we wanted to up the ante. We wanted to offer a new app development paradigm for companies with a large app backlog, especially where a big chunk of that backlog consisted of ambitious B2E and B2B apps.</p>

<p>We set two high level goals for ourselves: help companies write great software much more productively (especially those whose core focus is not software), and let them do this using modern software technologies and best practices, without the typical barriers.</p>

<h3 id="key-tenets-of-what-we-set-out-to-build">Key Tenets of What We Set Out to Build</h3>

<p>We decided that the best thing we could do was to build a next-generation IDE (as a complement to our full-stack app platform) that has the <strong>power and flexibility of pro-code</strong> at its core, but also has the high <strong>development velocity and easy adoption of no-code/low-code platforms</strong>.</p>

<p>From the start, we decided that some things are non-negotiable:</p>

<h4 id="1-coding-should-be-easy">1. Coding should be easy</h4>

<ul>
  <li>Creating a new app shouldn’t require any configuration or setup.</li>
  <li>Developers should be able to start coding immediately.</li>
</ul>

<h4 id="2-coding-should-have-a-fast-feedback-loop">2. Coding should have a fast feedback loop</h4>

<ul>
  <li>We will have a first-class IDE with real-time error checking, keyboard shortcuts, IntelliSense, etc.</li>
  <li>Developers should have access to a real debugger.</li>
  <li>We will have live, stateful hot reload on an actual device in development mode — not a time-consuming compile &amp; deploy process.</li>
</ul>

<h4 id="3-coding-in-the-ide-should-be-fun-and-relevant">3. Coding in the IDE should be fun and relevant</h4>

<ul>
  <li>We will not use a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>: We will support open-source programming languages – preferably those with gradual typing.</li>
  <li>We will not use convoluted proprietary visual interfaces.</li>
  <li>We will not use a proprietary “app store”. Developers must be able to import open source packages.</li>
  <li>The IDE should be easily accessible to junior developers.</li>
</ul>

<h4 id="4-coding-should-be-as-efficient-as-possible">4. Coding should be as efficient as possible</h4>

<ul>
  <li>We will provide developers with powerful functionality that can be used with minimal lines of code, and customized as required. This will include things like bi-directional relational offline data sync, dozens of UI components including Excel-like data grids, full audit trails, a cross-platform BLE engine, to name just a few.</li>
  <li>We will offer full git support with either hosted git, or external git providers (e.g. GitHub)</li>
  <li>We will support unit testing.</li>
  <li>We will support multiple environments, with easy portability of changes as new versions of software are moved from one environment to the next.</li>
</ul>

<h4 id="5-there-should-always-be-an-escape-hatch">5. There should always be an escape hatch</h4>

<ul>
  <li>There will be APIs for everything.</li>
  <li>We will allow developers to easily mix in fully custom HTML in their UIs, and allow those custom HTML components to communicate bidirectionally with the rest of the frontend stack, when required.</li>
  <li>There will be a Node.js environment in our cloud backend where developers can build any custom backend functionality, without any configuration or setup.</li>
</ul>

<h4 id="6-the-platform-should-be-secure-by-design">6. The platform should be secure by design</h4>

<h3 id="a-foundational-decision-building-a-web-ide">A Foundational Decision: Building a Web IDE</h3>

<p>We were taking the time to figure out a new approach to app development from first principles, so we had to make big design decisions with significant trade-offs. One major early decision was whether to build a web-based IDE or an installable desktop IDE.</p>

<p>The obvious question is: “Why an IDE on the web?”. We strongly believe that the recent developments across browser technology, transpiled languages and new approaches to software development (such as declarative UI) have made it possible to not only reach a desktop-grade level of quality in a web IDE, but also capitalize on the inherent benefits of the web paradigm.</p>

<p>Using this approach, we would have an IDE that is evergreen, cross-platform, cross-device, backed by modern UI and most importantly, ready for the future. Oh, and there would be nothing to install. Perhaps the biggest win, however, would be our ability to innovate quickly due to the open nature of web technologies and how quickly they evolve.</p>

<p>We’ll discuss other key design decisions in separate posts.</p>

<h3 id="unveiling-the-solution">Unveiling the Solution</h3>

<p>Today, we’re incredibly proud to announce <a href="https://journeyapps.com/platform/oxide/">OXIDE</a>. It’s the fruit of a lot of hard work by the JourneyApps team over the past year.</p>

<p>OXIDE helps both junior and senior developers build sophisticated cross-platform apps using JavaScript or TypeScript, complemented by visual tools. Apps can run natively on mobile and desktop operating systems, or in the browser as PWAs. Under the hood, OXIDE uses CRDTs [<a href="https://blog.kevinjahns.de/are-crdts-suitable-for-shared-editing/">3</a>] to enable live co-editing in teams, and it is deeply integrated with both GitHub and npm. In OXIDE, developers can switch between visual editing and coding for UI layout and schema design. Developers also have access to a first-class code debugging tool.</p>

<p>OXIDE is a fundamental pillar of the broader JourneyApps platform. Therefore, all apps inherit other flagship JourneyApps technologies out of the box — technologies that have seen around 10 years of R&amp;D and battle-hardening:</p>

<ul>
  <li>All apps ship with an enterprise-grade BaaS, and it’s easy to integrate with other data sources (in part because the platform is not based on a DSL).</li>
  <li>All apps are offline-first: Data is automatically synced to user devices, and loaded from the local database on each view. Querying data is fast. This avoids complicated state management and/or query cache systems. (What happens when data volumes scale? The platform provides highly configurable <a href="https://docs.journeyapps.com/reference/container/introduction-to-sync-rules">selective syncing.</a>)</li>
  <li>Each app is automatically provisioned with a Node.js serverless compute environment so that developers of all skill levels can add server-side logic and functionality.</li>
  <li>Developers have access to a rich built-in UI component set that is designed to work with data, with very little development overhead. No tweaking of styles or adding event listeners and state management to each component — this is handled for you.</li>
</ul>

<p>In general, JourneyApps takes the complexity out of the development cycle. We take care of the hard problems of enterprise software development (hosting, offline data sync, mobile app builds, backend APIs, deployment tooling, audit trails, and more) so that developers can focus on core app requirements and maximize the rate of innovation at their companies.</p>

<p>Working in OXIDE looks like this:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/2.png" alt="image"></p>

<p>And here’s a view of a debugging session. The app can be seen on the bottom right (running on macOS), the Chrome developer tools on the top right, and OXIDE on the left:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/3.png" alt="image"></p>

<p>Try it out and let us know what you think — <a href="https://accounts.journeyapps.com/portal/free-trial?utm_source=engineering-blog&amp;utm_medium=internal&amp;utm_campaign=engineering-blog">start building</a>.</p>


            </div></div>]]>
            </description>
            <link>https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421767</guid>
            <pubDate>Wed, 09 Sep 2020 15:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling Word for Windows v1.1a]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24420215">thread link</a>) | @elvis70
<br/>
September 9, 2020 | https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a | <a href="https://web.archive.org/web/*/https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1596161668354" id="item-5f237e4f45d6b8696edfa45b"><div><div><div data-block-type="2" id="block-ad599947c0ce6afbff0d"><div><p>Opus is the code name that developers inside Microsoft used for Microsoft Word for Windows v1.1a - let’s compile it from source code and see if it runs! Microsoft Word for Windows v1.1a is © Copyright Microsoft 1989.</p><h2><strong>Contents</strong></h2><ol data-rte-list="default"><li><p>Introduction</p></li><li><p>Background</p></li><li><p>Can I Compile This Code?</p></li><li><p>Intel CPU History</p></li><li><p>DOS Memory Types</p></li><li><p>Installing DOS</p></li><li><p>Make The Disk Bootable</p></li><li><p>Configuring DOS</p></li><li><p>DOS Memory Management</p></li><li><p>Compiling Opus</p></li><li><p>Running Opus</p></li></ol><h2><strong>1. Introduction</strong></h2><p>This blog documents how to take the <a href="https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/">source code</a> and turn it into to a working Windows application. The compiler and development tools run in the MS-DOS operating system because there were no Windows development tools available in 1989. </p><p>Note: I’m going to refer to “DOS” throughout this blog. This means I’m talking about Microsoft MS-DOS although most of it equally applies to IBM PC-DOS and most other DOS variants.</p><p>If you are new to the DOS operating system, I recommend following along using a copy of Microsoft MS-DOS v6.22, a June 1994 version of DOS (the last major version released) and has all the tools we need to get this working (with possibly one exception that I’ll cover off later).  </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596330539417_20476"><div><h2><strong>2. Background</strong></h2><p>Development on the word processor called Microsoft Word for DOS was started by Richard Brodie and others in 1982. Richard was hired from Xerox Parc as he was familiar with the, at the time, futuristic word processor.</p><p>Word for DOS was first released in 1983 and bundled with an early version of MS-DOS. It used (primitive) graphics and supported the use of a mouse, but was released to mixed reviews.&nbsp;</p><p>Word v2.0 for DOS was released in 1985 and supported EGA graphics and had a spell-checker.&nbsp;</p><p>Word v3.0 for DOS was released in 1986 and supported Hercules graphics and additional printers, wow!&nbsp;</p><p>Word v4.0 for DOS was released in 1987 and supported VGA graphics and had both text and graphics modes.&nbsp;</p><p>Word v5.0 for DOS and OS/2 as a 16-bit application.&nbsp;</p><p>An upgrade to Word v5.5 in 1989 added Windows/Mac-like windows and menus, a forerunner of Word for Windows that would be released later that year.&nbsp;</p><p>Development of the first WYSIWYG* word processor for Microsoft Windows was done between 1988 and 1989, resulting in the version released by the Computer History Museum.</p><p>*WYSIWYG = What You See Is What You Get</p><p>Read more about the history and download the source code from the Computer History Museum here:</p><p><a href="https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/">https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/</a></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_58803"><div><h2><strong>3. Can I Compile This Code?&nbsp;</strong></h2><p>Yes! How? You could use a vintage PC or a relatively modern one that can boot in (legacy) BIOS mode or configure a hypervisor to run a virtual PC. All the tools you need are in the source code dump in the link above. They all run in DOS so let’s talk about how this is supposed to work.</p><p>I’ll be using VMware Fusion on a Mac to demonstrate but you can use any suitable old hardware or hypervisor that will run MS-DOS. Once DOS is installed, you’ll need to check how much memory is available. That requires a basic understanding of how DOS “sees” the hardware. Since the compiler appears to need expanded memory, I’ll describe how that type of memory is accessed and how to configure DOS to make it available to the compiler.</p><p>Also, the file set is quite large (for a DOS application), so I recommend you can make things easier by creating a CD-ROM image of the source files so they can be copied to the DOS machine in one go, however this also needs device drivers for it to work on the DOS operating system so I’ll cover that here also.</p><p>The source code is interesting as the proprietary compiler requires a computer with at least a 386 processor and 4Mb of RAM. This exceeds the specs of many PCs back in the day and certainly would have been considered “high end” at the time as most had 1MB of RAM tops with only 640KB available for use by typical DOS applications. Of that DOS itself uses a lot of memory and the apps use what’s left. So, how much memory does our machine have? How do we give it some more? More on this later.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_50297"><div><h2><strong>4. Intel CPU History</strong></h2><p>The reason DOS requires memory management is linked closely to the history of the CPUs it was designed to run on. Because a lot of the early programs were built with assembler /&nbsp; machine code, the DOS operating system was very tightly integrated with the CPU it ran on. As a result it inherited the limits of these CPUs and those CPUs imposed strange limits due to each generation of CPU needing to support the code base of all of the CPUs that preceded it.</p><p>In 1979 the 8-bit Intel 8086/8088 processors could address 1024KB or 1MB of RAM (8-bit data bus, 16-bit memory registers)</p><p>In 1982 the 16-bit Intel 80286 processor could address up to 16MB of RAM (16-bit data bus, 24-bit address space*)</p><p>In 1985 the 32-bit Intel 80386 (and later 486) processors could (theoretically) address up to 4096MB or 4GB of RAM**&nbsp;</p><p>Modern 64-bit processors have 40-bit, 52-bit and 64-bit addressable memory architectures so they can support from 1TB to 4PB of RAM!!!!!!!</p><p>Note*: a 24-bit address space is equivalent to 2 to the power of 24 × 1 byte = 16,777,216 bytes or 16MB.</p><p>Note**:&nbsp; a 32-bit address space is 2 to the power of 32 x 1 byte = 4,294,967,296 bytes or 4GB but a lot less than 1GB was usually installed in 386 PCs due to the motherboard limits (and massively high cost) of RAM at that time.</p><p>The history of DOS and Windows is littered with issues created by backward compatibility and memory management limits governed by early Intel processor architecture.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_41559"><div><h2><strong>5. DOS Memory Types</strong></h2><p>There are five memory areas addressable by DOS. Each of these are accessible using one or two device drivers invoked in the CONFIG.SYS at boot time. HIMEM.SYS provides access to Extended Memory and EMM386.EXE provides access to Expanded Memory. So here’s a quick guide to these memory types.&nbsp;</p><p><strong>Conventional Memory</strong>: is memory from 0 to 640 KB (or 651,264) also called the Lower Memory Area (LMA)</p><p><strong>Upper Memory Area</strong>: UMA is memory from 640KB to 1024KB or 1MB also referred to as the Upper Memory Area (UMA) also called Upper Memory Blocks (UMB)</p><p><strong>Extended Memory Specification</strong>: XMS is memory addresses from 1MB up to 64MB but this spec also defines the UMA because DOS does not have access to UMA without support from HIMEM.SYS</p><p><strong>Expanded Memory Specification</strong>: EMS uses a 64KB page frame defined in Upper Memory to provide access to memory above 1MB. DOS can use both XMS and EMS when the AUTO parameter is specified or is disabled when loading EMM386.EXE with the NOEMS parameter. EMM386 and other memory managers, emulate expanded memory in the extended memory area, not confusing at all!</p><p><strong>High Memory Area</strong>: HMA is 64KB just above 1MB that DOS can load itself into at boot time using DOS=HIGH in the CONFIG.SYS</p><p>Conventional memory is where the old school DOS applications reside. They can only use memory from 0-640Kb and because some of this is taken up by DOS itself, they may have access to less than 500KB of RAM at runtime. This often limits applications that run in so-called “real mode” that is to say 16-bit apps limited to conventional memory. Real mode is called because real memory addresses are mapped to addressable memory within the application.</p><p>This was fine for just a few short years until 640KB became a limiting factor for more complex applications AKA games! More memory was also needed for newly developed Windows applications so along came the Extended Memory Specification (XMS). Memory above the 1MB made addressable by 16-bit programs. This was introduced in 286 processors which implemented protected mode to get access to memory above those DOS limits but also supported conventional memory access in real mode, switching between modes when needed.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_20945"><div><h2><strong>6. Installing DOS</strong></h2><p>Your options are to use actual floppy disks and a USB floppy disk drive, create floppy disk images from your physical floppy disks or download floppy disk images from sites like WinWorld.</p><p>Your physical or virtual machine will need a minimum of 4MB of RAM and a maximum of 32MB and a maximum of 512MB hard disk with a single FAT16 partition on it. If the hard disk is physically larger than 512MB, limit the size of the first partition to the maximum size your version of DOS can address. For compatibility, limit this first partition to 512MB or less.</p><p>If the machine has the minimum specs shown above, boot from the first DOS diskette. In versions later than version 5.0, an installer will run. Follow the instructions choosing all the default values for now. We’ll experiment with install options in a later blog post. If you were not prompted for an installation you can often find the INSTALL.EXE app on the first diskette, or set things up manually by partitioning the hard disk manually. See the section below called “Make the boot disk bootable…”.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_12300"><div><h2><strong>7. Make The Hard Disk Bootable</strong></h2><p>If you boot from floppy in the previous step but don’t yet have an accessible hard disk or have a copy of DOS that does not include an installer then we can install it manually. </p><p>Run FDISK from the floppy disk and view the existing partition structure by choosing option 4 and press enter.</p><p>If there is an existing partition it should show that there is up to 511 Mbytes in a FAT16 filesystem and the status column should show that is it Active by having a “A” character in the Status column. </p><p>If not, we’ll create one; return to the main menu by pressing Escape.</p><p>Type option 1 then press enter. Type 1 and press enter again to create a new Primary Partition. It will complain if an existing partition is already there. If you are brave you can remove that and create anew one or just use the one that’s already there.</p><p>Once it’s done, return to the main menu and choose option 2 and make the new partition active, then exit FDISK. Back at the DOS prompt we need to format the disk to make that new partition readable and we need to transfer the DOS boot system to the disk using the “/s” switch on the format command. The “/v” option will prompt for a new volume name.</p><pre><code>format c: /s /v</code></pre><p>Follow the prompts and give it a valid 11-character volume name. This will create a bootable disk but before you reboot, create a …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a">https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a</a></em></p>]]>
            </description>
            <link>https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a</link>
            <guid isPermaLink="false">hacker-news-small-sites-24420215</guid>
            <pubDate>Wed, 09 Sep 2020 12:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: XML Fiddler – tool for quick XML exploration]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24419947">thread link</a>) | @masa331
<br/>
September 9, 2020 | https://masa331.github.io/xml_fiddler/ | <a href="https://web.archive.org/web/*/https://masa331.github.io/xml_fiddler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://masa331.github.io/xml_fiddler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419947</guid>
            <pubDate>Wed, 09 Sep 2020 11:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How WebAssembly Changes Software Distribution]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24419081">thread link</a>) | @ingve
<br/>
September 9, 2020 | https://desiatov.com/why-webassembly/ | <a href="https://web.archive.org/web/*/https://desiatov.com/why-webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="51"><p>If you had any experience with Windows and Internet Explorer in the 90s,
quite probably you remember <a href="https://en.wikipedia.org/wiki/ActiveX">ActiveX</a> controls. Most
frequently this involved bulky popups on pages with these controls having to display something
more complex than a few blocks of text.</p>
<p><img src="https://desiatov.com/activex-0f260342e5426a0cc883966575235fe3.gif" alt="Internet Explorer displaying an alert that requires ActiveX controls to be installed"></p>
<p>Or, remember <a href="https://en.wikipedia.org/wiki/Java_applet">Java applets</a>? They became
available in 1995, and later they weren’t limited to just Windows and Internet Explorer. I remember
I had to use Java applets on macOS as recently as 2013, which chronologically is closer to the
present time than the 90s are. (Feeling so old anyway! 👴)</p>
<p>
  <a href="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft's Application and Network Access Portal that displays a warning about user's browser not
allowing Java applets to run" title="" src="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg" srcset="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-e8976.jpg 148w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-63df2.jpg 295w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg 590w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg 624w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>Seems like ActiveX and Java applets were necessities mostly in the enterprise world, but
Macromedia Flash (later known as <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a>)
was certainly much more widely known to consumers. It was a requirement in the early days of streaming
video (even <a href="https://www.theverge.com/2015/1/27/7926001/youtube-drops-flash-for-html5-video-default">YouTube required
Flash</a>
to work back then!), but also a major driver in browser gaming in late 2000s and early 2010s.
We certainly could blame Flash for making our browser windows look like this:</p>
<p>
  <a href="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Browser page warning about Adobe Flash Player not being installed" title="" src="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg" srcset="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-e8976.jpg 148w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-63df2.jpg 295w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg 590w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg 606w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>While ActiveX has seemingly failed to reach a significant adoption, Microsoft made yet another
attempt with <a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight">Silverlight</a>:</p>
<p>
  <a href="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft Silverlight page with an installation button" title="" src="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg" srcset="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-e8976.jpg 148w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-63df2.jpg 295w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg 590w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg 831w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>In the meantime, Google was working on <a href="https://en.wikipedia.org/wiki/Google_Native_Client">its own thing for
Chrome</a>:</p>
<p>
  <a href="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Google Native Client plug-in settings in the Chrome browser" title="" src="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png" srcset="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-1a291.png 148w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-2bc4a.png 295w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png 590w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png 650w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>It would be fair to say that these attempts failed to establish wide adoption, especially
after both consumers and businesses started shifting to mobile. Here’s how all these forays ended
according to Wikipedia:</p>
<blockquote>
<p>Microsoft dropped ActiveX support from the Windows Store edition of Internet Explorer 10 in
Windows 8. In 2015 Microsoft released Microsoft Edge, the replacement for Internet Explorer with
no support for ActiveX, this marked the end of the technology in Microsoft’s web browser
development.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=ActiveX&amp;oldid=969259090#Platform_support">“ActiveX”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>Beginning in 2013, major web browsers began to phase out support for the underlying technology
applets used to run, with applets becoming completely unable to be run by 2015–2017. Java applets
were deprecated since Java 9 in 2017 and removed from Java SE 11 (18.9), released in September
2018.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Java_applet&amp;oldid=972322018">“Java applet”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>In July 2017, Adobe announced that it would declare Flash to be end-of-life at the end of 2020,
and will cease support, distribution, and security updates for Flash Player.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Adobe_Flash#End_of_life">“Adobe Flash”</a> article on
Wikipedia.</small></p>
<blockquote>
<p>There is no Silverlight plugin available for Microsoft Edge. It has not been supported by Google
Chrome since September 2015 or by Firefox since March 2017.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight#Demise">“Microsoft Silverlight”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>On October 12, 2016, a comment on the Chromium issue tracker indicated that Google’s Pepper and
Native Client teams had been destaffed.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Google_Native_Client&amp;oldid=973604804">“Google Native
Client”</a> article on
Wikipedia.</small></p>
<h2>But JavaScript solved all these problems, didn’t it?</h2>
<p>Most of these browser add-ons were introduced before modern JavaScript and HTML5 became available,
so one could argue you no longer need browser add-ons at all. Well, <a href="https://daringfireball.net/linked/2017/06/27/web-without-javascript">some
purists</a> even say browsers
should have never supported JavaScript or any scripting whatsoever in the first place. Nevertheless,
there are enough use cases for browser scripting and browser apps in general that are hard to avoid.
When looking at the history of browser plugins in general, it’s hard not to notice a few themes:</p>
<ul>
<li>Distributing productivity apps via browsers is convenient in a lot of cases.</li>
<li>Browser gaming made a lot of sense, especially for casual games.</li>
<li>In both of these scenarios browsers had to display something more complex than text and a few
static images.</li>
</ul>
<p>
  <a href="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Flash Element TD game screenshot with a classic tower defense battle field" title="" src="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" srcset="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-399a3.jpg 148w,
https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg 288w" sizes="(max-width: 288px) 100vw, 288px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>The modern casual <a href="https://en.wikipedia.org/wiki/Tower_defense">tower defense game genre</a>
arguably was reborn due to the popularity of Adobe Flash and browser gaming, with <a href="https://en.wikipedia.org/wiki/Flash_Element_TD">Flash Element
TD</a> being a classic example.</small></p>
<p>Even though native apps were (and in many situations still are) objectively better for users, early
browser apps were attempting to build their own ad-hoc app stores before the App Store existed.
You didn’t have to buy a CD with an application and install it and manage it on your disk. You
didn’t have to install updates manually and migrate your data. There was no need to uninstall apps,
you just close a corresponding browser tab and forget about it.</p>
<p>And when browser scripting capabilities became advanced enough, some people started seeing the
allure of making a browser version of their app the only version they provided. Browsers are
cross-platform, aren’t they? Just wrap your JavaScript app code in a browser-like container (say
<a href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>) and distribute that instead
of your native app. </p>
<p>But eventually not only the JavaScript APIs became more complex, the language itself could no longer
accommodate what developers wanted. Not everyone liked JavaScript syntax (remember
<a href="https://en.wikipedia.org/wiki/CoffeeScript">CoffeeScript</a>?) or semantics (I couldn’t help but
notice that <a href="https://en.wikipedia.org/wiki/TypeScript">TypeScript</a> has grown in popularity in recent
years). But it’s hard to transpile an arbitrary programming language to JavaScript, the latter was
not built with that goal in mind.</p>
<p>Corollary, the JavaScript interpreter itself has both memory and performance overhead. Having a
garbage collector built in makes it even harder to transpile languages with different memory models
to JavaScript. The allure of having only one language to write all your apps for all platforms is
still there, but why do you have to be confined to JavaScript itself, even as a target language?</p>
<h2>How WebAssembly actually started</h2>
<p>With the death of browser plugins, at least we can praise the interoperability efforts of browser
vendors. Some lowest common denominator of JavaScript is supported in all browsers, and there is a
clear incentive for the vendors to keep up. With the demand to go beyond JavaScript, there were
initial attempts to support low level programming with asm.js in 2013:</p>
<blockquote>
<p>Much of this performance gain over normal JavaScript [with asm.js was] due to 100% type consistency
and virtually no garbage collection (memory is manually managed in a large typed array).</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Asm.js">“asm.js”</a> article on Wikipedia.</small></p>
<p>Syntactically this still looked pretty much like JavaScript, but when you have a lot of low level code,
the resulting file can get big pretty quickly, and the size of your code is pretty important when your
users download it frequently. As you weren’t supposed to write asm.js code manually most of the time,
and it was designed primarily as compilation target, it made sense to invent a binary format for it.
That’s basically how WebAssembly started:</p>
<blockquote>
<p>WebAssembly was first announced in 2015, and the first demonstration was executing Unity’s Angry
Bots in Firefox, Google Chrome, and Microsoft Edge. The precursor technologies were asm.js from
Mozilla and Google Native Client, and the initial implementation was based on the feature set of
asm.js.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/WebAssembly#History">“WebAssembly”</a> article on
Wikipedia.</small></p>
<p>
  <a href="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Angry Bots is a 3rd-person shooter demo that features a marine-like character that walks
through some futuristic research base and defends from suicidal four-legged robots" title="" src="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png" srcset="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-1a291.png 148w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-2bc4a.png 295w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png 590w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-526de.png 885w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fa2eb.png 1180w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-08f6a.png 1770w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png 2567w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>Angry Bots is still available to play on the <a href="https://beta.unity3d.com/jonas/AngryBots/">Unity
website</a>.</small></p>
<h2>What WebAssembly got right</h2>
<p>Now you’re no longer restricted to JavaScript as a target language for browser apps. As soon as
<a href="https://llvm.org/">LLVM</a> got WebAssembly backend more or less ready, it allowed compilers built
on top of LLVM (for C, C++, Rust, Swift and many more) to adopt it without rewriting everything from
scratch. This unlocked the browser environment to a huge amount of pre-existing software that can
also run close to native speed if optimized well.</p>
<p>Not only can you run fun little projects such as <a href="https://sandspiel.club/">Sandspiel</a> and
<a href="https://orb.farm/">orb.farm</a> in your browser tab, but complex games such as <a href="https://www.continuation-labs.com/projects/d3wasm/">Doom
3</a> (at least its demo version) are available too.
Both <a href="https://blogs.unity3d.com/2018/08/15/webassembly-is-here/">Unity</a> and <a href="https://twitter.com/unrealengine/status/932624595722559490">Unreal
Engine</a> announced their support for
WebAssembly, and while we may not see AAA games running in browsers on their initial release date,
this still gives enough confidence in the maturity of the platform.</p>
<p>
  <a href="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="A pixel-art spherical fish tank filled with water, sand, algae, daphnia and fish." title="" src="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png" srcset="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-1a291.png 148w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-2bc4a.png 295w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png 590w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-526de.png 885w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fa2eb.png 1180w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-08f6a.png 1770w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png 3730w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>According to its creator, <a href="https://orb.farm/">orb.farm</a> is “a virtual ecosystem where different
species of creature can live, grow and die as part of a self-contained food chain”.</small></p>
<p>It’s obviously not limited to games, as we can see Apple folks compiling their <a href="https://twitter.com/lrz/status/1250453967957561344">C++ and Objective-C
code from iWork</a> to Wasm<sup id="fnref-1"><a href="#fn-1">1</a></sup>, or
<a href="https://1password.com/">1Password</a> using it in their browser extension getting substantial
performance improvements as a result:</p>
<blockquote>
<p>With our move to WebAssembly, page filling and analysis now runs at least twice as fast as before,
and those websites with a large number of fields are up to 13x faster in Chrome and up to 39x
faster in Firefox! It’s blazing fast. 🔥</p>
</blockquote>
<p><small><a href="https://blog.1password.com/1password-x-may-2019-update/">“1Password X: May 2019 update”</a>
article on <a href="https://blog.1password.com/">the 1Password blog</a>.</small></p>
<h2>Wasm is a general purpose virtual machine</h2>
<p>Not only you get performance improvements with WebAssembly compared to JavaScript, as it was
designed to run arbitrary code in your browser, it’s one of the most widely available secure sandbox
environments. And as a general purpose virtual machine, Wasm is not limited only to browsers.
<a href="https://www.cloudflare.com/">Cloudflare</a> uses it for edge computing on their CDN:</p>
<blockquote>
<p>We’re excited by the possibilities that WebAssembly opens up. Perhaps, by integrating with
Cloudflare Spectrum, we could allow existing C/C++ server code to handle arbitrary TCP and UDP
protocols on the edge, like a sort of massively-distributed inetd. Perhaps game servers could
reduce latency by running on Cloudflare, as close to the player as possible. Maybe, with the help
of some GPUs and OpenGL bindings, you could do 3D rendering and real-time streaming directly from
the edge.</p>
</blockquote>
<p><small><a href="https://blog.cloudflare.com/webassembly-on-cloudflare-workers/">“WebAssembly on Cloudflare
Workers”</a> on <a href="https://blog.cloudflare.com/">the Cloudflare
blog</a>.</small></p>
<p>With people realizing the wide applicability of the Wasm tech stack, it was no surprise when
<a href="https://wasi.dev/">WASI</a> (stands for WebAssembly System Interface) appeared. Where WebAssembly
itself is a “bare metal” platform, it does not supply any primitives such as memory allocation or
filesystem access, which WASI does provide. As Solomon Hykes, creator of Docker, <a href="https://twitter.com/solomonstre/status/1111004913222324225">puts
it</a>:</p>
<blockquote>
<p>If WASM+WASI existed in 2008, we wouldn’t have needed to created Docker. That’s how important it
is. Webassembly on the server is the future of computing. A standardized system …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://desiatov.com/why-webassembly/">https://desiatov.com/why-webassembly/</a></em></p>]]>
            </description>
            <link>https://desiatov.com/why-webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419081</guid>
            <pubDate>Wed, 09 Sep 2020 09:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Raspberry Pi to Add MIDI to a CV Synthesizer]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24418798">thread link</a>) | @qrv3w
<br/>
September 9, 2020 | https://schollz.com/raspberrypi/monotron/ | <a href="https://web.archive.org/web/*/https://schollz.com/raspberrypi/monotron/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
        <p><img src="https://schollz.com/img/monotron/main.jpg">
    </p></div>
    
    
    
    
    <p>I programmed the Raspberry Pi to control voltage and respond to MIDI so I can play the Korg Monotron with a keyboard.</p>
    <p>The Korg Monotron is a good sounding synthesizer for a relatively cheap price (~$50). One drawback of the Korg Monotron is that it uses a <a href="https://www.sweetwater.com/insync/ribbon-controller/">ribbon controller</a> to determine the pitch so it is very hard to control the pitch accurately, and almost impossible to be in tune by yourself.</p>
<p>Luckily, Korg has developed this little synth with hacking in mind. These instructions will show you how to use a Raspberry Pi as a cheap MIDI-to-CV controller so you can use the Korg Monotron just like any other MIDI instrument.</p>
<p>This is the first DIY MIDI-to-CV controller that allows you to <strong>automatically tune the Monotron</strong> voltage-to-frequencies <em>and</em> <strong>only has three components</strong> (and no PCBs!). Other solutions - like the <a href="http://beatnic.jp/manuals/monotron-midi/midi-kit.html">MIDI-IF kit</a> or <a href="https://github.com/elkayem/midi2cv">Arduino-based midi2cv</a> - require extensive soldering, dozens of components, and require manual tuning.</p>
<h2 id="overview">Overview</h2>
<p>Adding MIDI to the Korg Monotron basically requires converting MIDI input to voltage. The following introductions will work on several CV synthesizers (I think) and are not necessarily specific to the Monotron. Here we are using a cheap DAC (the MCP4725) to send voltages from the Raspberry Pi. The Raspberry Pi uses a Python script <a href="https://github.com/schollz/midi2cv/">midi2cv.py</a> which listens for MIDI and controls the DAC.</p>
<iframe width="100%" height="315" src="https://www.youtube.com/embed/TuBCexYkAv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>The magic trick here is that I added a tuning function into the Raspberry Pi (in <a href="https://github.com/schollz/midi2cv/">midi2cv.py</a>) so you can automatically determine the relationship between voltage and frequency to tune any CV synth. It works by connecting the audio output of your synth to the Raspberry Pi (via USB audio connector) and then computing the FFT to find the fundamental frequency of tones controlled by various voltages.</p>
<p><a href="https://www.instagram.com/p/CE5Xbw4hZBi/"><img src="https://schollz.com/img/monotron/example1.png" alt="Click for demo of the automatic tuning and MIDI keyboard."></a></p>
<p>Below is a step-by-step instruction to take a Korg Monotron and a Raspberry Pi and make it MIDI capable. There are only two solder points and no PCBs and no breadboards!</p>
<h2 id="requirements">Requirements</h2>
<ul>
<li><a href="https://www.amazon.com/gp/product/B07BC7BMHY/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B07BC7BMHY&amp;linkCode=as2&amp;tag=scholl-20">Raspberry Pi</a> (~$15 on ebay)</li>
<li><a href="https://www.amazon.com/gp/product/B01N905VOY/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01N905VOY&amp;linkCode=as2&amp;tag=scholl-20">USB audio adapter</a> (~$16, but ~$5 if you by used)</li>
<li><a href="https://www.amazon.com/gp/product/B00684KFAM/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00684KFAM&amp;linkCode=as2&amp;tag=scholl-20">Korg Monotron</a> (~$55)</li>
<li><a href="https://www.amazon.com/gp/product/B00SK8MBXI/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00SK8MBXI&amp;linkCode=as2&amp;tag=scholl-20">MCP4725</a> (~$5)</li>
<li><a href="https://www.amazon.com/gp/product/B01L5ULRUA/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01L5ULRUA&amp;linkCode=as2&amp;tag=scholl-20">Female-to-female jumper cables</a> (~$6)</li>
<li><a href="https://www.amazon.com/gp/product/B087767KNW/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B087767KNW&amp;linkCode=as2&amp;tag=scholl-20">Soldering iron</a> (~$17)</li>
<li>MIDI keyboard (optional)</li>
</ul>
<h2 id="part-1-hacking-the-monotron">Part 1: Hacking the Monotron</h2>
<p>We need to first be able to send voltages to the Korg Monotron. To do this we need to connect a wire with the hot voltage and a wire with the ground to the Monotron using soldering.</p>
<h3 id="solder-two-wires-to-the-monotron-pcb">Solder two wires to the Monotron PCB</h3>
<p>Simply unscrew the back of the Monotron and pull out the back. There are four screws, two of them are next to the batteries.</p>
<p><img src="https://schollz.com/img/monotron/screws.jpg" alt="Location of the four screws."></p>
<p>Take the Monotron apart, carefully, and you will see the back of the PCB has some gold pads with labels! Korg designed this PCB for us to hack :). Solder one wire to the <code>gate</code> pad and solder another wire to the <code>GND</code> pad (both wires should be female on the opposite end).</p>
<p><img src="https://schollz.com/img/monotron/pcb.png" alt="This is the back of the Monotron PCB before you solder."></p>
<p><img src="https://schollz.com/img/monotron/soldering.jpg" alt="The only two soldering connections you need to make."></p>
<p>I realize we are not using <code>pitch</code>, but for some reason <code>gate</code> also can be voltage-controlled and acts as a gate (if voltage &gt; 0) and pitch. If you want to watch someone solder, check out <a href="https://www.youtube.com/watch?v=iT__-bH8Q0o">this great Youtube video for how to solder to the Korg Monotron</a>.</p>
<p><img src="https://schollz.com/img/monotron/closed.jpg" alt="Wires sticking out of the hacked Monotron"></p>
<p>Now just close it up, and move the wires so they stick out under the volume control. You can screw everything back together, just make sure not to go too tight.</p>
<h3 id="hook-up-wires-to-the-raspberry-pi">Hook up wires to the Raspberry Pi</h3>
<p>First let’s wire up the the MCP4725 to the Raspberry Pi. Attach MCP4725 <code>SDA</code>, <code>SCL</code>, <code>GND</code>, <code>VDD</code> to the Raspberry Pi’s <code>GPIO 2 (SDA)</code>, <code>GPIO 3 (SCL)</code>, <code>Ground</code>, and  <code>5V power</code>, respectively. Check the Raspberry Pi <a href="https://www.raspberrypi.org/documentation/usage/gpio/">pin-out schematic</a> for more details.</p>
<p><img src="https://schollz.com/img/monotron/connections_pi.jpg" alt="Wiring between the MCP4725 and the Raspberry Pi"></p>
<p>Now attach the Monotron “<code>gate</code>” wire to the “<code>VOU</code>” of the MCP4725. Attach the Monotron “<code>GND</code>” wire to any ground pin of a Raspberry Pi (<a href="https://www.raspberrypi.org/documentation/usage/gpio/">schematic</a>).</p>
<p><img src="https://schollz.com/img/monotron/connections_all2.jpg" alt="Wiring the Monotron up to the Raspberry Pi with MCP4725."></p>
<p>That’s it! No extra breadboard or PCBs necessary!</p>
<h2 id="part-2-tuning-the-monotron">Part 2: Tuning the Monotron</h2>
<p>The Monotron uses a voltage controlled oscillator (VCO).The Monotron voltages can be modified by the <code>INT</code> and the trim pot and these will affect the frequencies for a given voltage. Every time these are altered (or anytime it seems out of tune), you need to tune it. That is, you need to determine which voltage will produce which frequency.</p>
<p>Luckily, instead of tuning each note manually, we can use the Raspberry Pi to self-calibrate it for us!</p>
<h3 id="installing-pre-requisites-on-raspberry-pi">Installing pre-requisites on Raspberry Pi</h3>
<p>Use <a href="https://www.raspberrypi.org/documentation/remote-access/ssh/unix.md">SSH to get into your Raspberry Pi</a> and install the following prerequisites:</p>
<pre><code>&gt; sudo apt update
&gt; sudo apt install python3 python3-pip python3-numpy portaudio19-dev sox gnuplot ffmpeg
&gt; sudo -H python3 -m pip install loguru click mido python-rtmidi adafruit-circuitpython-mcp4725 termplotlib aubio
</code></pre><p>Now download the <code>midi2cv.py</code> script:</p>
<pre><code>&gt; wget https://raw.githubusercontent.com/schollz/midi2cv/master/midi2cv.py
</code></pre><p>Great, now we are ready to tune the synth.</p>
<h3 id="gettin-in-tune">Gettin’ in tune</h3>
<p>Connect the USB audio to the Raspberry Pi. Then connect the headphone out of the Monotron into the recording line-in with a stereo 1/8” cable.</p>
<p><img src="https://schollz.com/img/monotron/tuning.jpg" alt="Connecting the Monotron to the Raspberry Pi for self-calibration."></p>
<p><strong>Important:</strong> Make sure to change the Monotron settings so it is outputting pure tones. Use the following settings for each knob (0 means all the left, 100 means all the way right):</p>
<ul>
<li><code>RATE</code>: 0</li>
<li><code>INT</code>: anywhere you want (don’t change it after tuning, though)</li>
<li><code>CUTOFF</code>: 100</li>
<li><code>TIME</code>: 0</li>
<li><code>FEEDBACK</code>: 0</li>
</ul>
<p>Now ssh into the Raspberry Pi and run the following Python script:</p>
<pre><code>&gt; python3 midi2cv.py --tune
</code></pre><p>This will take about 30 seconds as the Raspberry Pi cycles through voltages (1-5V) while recording in resulting audio. The audio is captured using the USB audio adapter. The captured audio is analyzed using a FFT to determine the fundamental frequency. These voltage-frequency pairs will then be plotted and fit with an exponential curve.</p>
<p><img src="https://schollz.com/img/monotron/calibration.png" alt="Frequency-voltage fitting after calibration of the Monotron."></p>
<p>The fit from this curve is saved onto the Raspberry Pi so that when you play the Monotron it will be able to convert the MIDI to frequency and then convert that to voltage.</p>
<p>Now you are ready to play!</p>
<h2 id="4-play-the-monotron">4. Play the Monotron!</h2>
<h3 id="using-a-midi-keyboard">Using a MIDI keyboard</h3>
<p>Simply attach a USB MIDI keyboard to the Raspberry Pi and then run:</p>
<pre><code>&gt; python3 midi2cv.py --play
</code></pre><p>Now the keyboard will automatically trigger the Raspberry Pi to set the voltage of the Monotron, in tune!</p>
<h3 id="using-midi-sequencing">Using MIDI sequencing</h3>
<p>A keyboard is not necessary to play the Monotron. You can use another program I wrote to sequence MIDI instruments from a simple text file: <a href="https://github.com/schollz/miti">miti</a>.</p>
<p>First make sure you have portmidi, and download the binary for <code>miti</code> (or you can <a href="https://github.com/schollz/miti">build it yourself</a>):</p>
<pre><code>&gt; sudo apt install libportmidi-dev
&gt; wget https://github.com/schollz/miti/releases/download/v0.4.1/miti_arm.tar.gz
&gt; tar -xvzf miti_arm.tar.gz
&gt; sudo mv miti /usr/local/bin/
</code></pre><p>Then create a new sequencing file. The sequencing is easy to write and understand and <a href="https://github.com/schollz/miti#documentation">documented thoroughly</a>. Here we will make a simple three-chord arpeggio.</p>
<p>In a file names <code>song1.miti</code> write:</p>
<pre><code>pattern a 

instruments midi through
tempo 120

legato 95
F2 A C F A C F A C F A C F A C F
E2 G C E G C E G C E G C E G C E
D2 F A C D F A C D F A C D F A C
D2 F A C D F A C D F A C D F A C
</code></pre><p>The “<code>midi through</code>” indicates that we will send the output to the MIDI through port. Now, in one terminal run the <code>midi2cv</code> program:</p>
<pre><code>&gt; python3 midi2cv.py --play
</code></pre><p>And in another terminal run <code>miti</code> to start sequencing:</p>
<pre><code>&gt; miti --play song1.miti
</code></pre><p>That’s it! You should hear some music. You can edit the <code>song1.miti</code> file in real-time to make any changes to the sequencing.</p>
<h2 id="questions">Questions?</h2>
<p>If you find any problems, feel free to let me know. Find me on instagram (<a href="https://instagram.com/infinitedigits">@infinitedigits</a>) or Twitter (<a href="https://twitter.com/yakczar">@yakczar</a>). DMs are open.</p>

    <p>
        <a href="https://schollz.com/raspberrypi/monotron/">
            <postamble datetime="2020-09-08" 2018-09-04=""><time datetime="2020-09-08 08:00:46">September 8, 2020</time></postamble>
        </a>
        &nbsp;/&nbsp;<a href="https://indieweb.xyz/en/midi" target="_blank">midi</a>&nbsp;<a href="https://indieweb.xyz/en/music" target="_blank">music</a>&nbsp;<a href="https://indieweb.xyz/en/programming" target="_blank">programming</a>&nbsp;<a href="https://indieweb.xyz/en/raspberry%20pi" target="_blank">raspberry pi</a>&nbsp;
    </p>
</div></div>]]>
            </description>
            <link>https://schollz.com/raspberrypi/monotron/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24418798</guid>
            <pubDate>Wed, 09 Sep 2020 08:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bayesian Stats Needs Monte-Carlo Methods]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24416908">thread link</a>) | @laplacesdemon48
<br/>
September 8, 2020 | https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods | <a href="https://web.archive.org/web/*/https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5f3999dd551f15457784cec9" data-item-id="5f3999dd551f15457784cec9">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1597610547002" id="item-5f3999dd551f15457784cec9"><div><div><div data-block-type="2" id="block-ce72701dbc5d55959e37"><div><div><p>This post emerged from a series of question surrounding a Twitter comment that brought up some very interesting points about how Bayesian Hypothesis testing works and the inability of analytic solutions to solve even some seemingly trivial problems in Bayesian statistics. </p><p>Comparing Beta distributed random variables is something that comes up pretty frequently on this blog (and in my book as well). The set up is fairly straight forward: model an A/B test as sampling from two beta distributions, sample from each distribution a lot, then compare the results.</p><p>This simulation approach often first appears as a clever little trick to solve a more complex math problem, but in fact is a primative form of Monte-Carlo Integration and turns out to one of the only ways to really solve this problem. By exploring this topic deeper in this post we'll see some of the myths that many people have about analytic solutions as well as demonstrating why Monte-carlo methods are so essential to Bayesian statistics.</p></div><h2>Background: A conversation about election results</h2><div><p>An interesting conversation happened on Twitter recently. It started with a retweet of mine regarding Nate Silver (well know author and election forecaster) posting his latest predictions for the 2020 presidential election showing that Biden has a 71% probability of winning versus Trump's 29%</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_4659"><div><div><p>After the last election there was quite a lot of criticism about Nate Silver's forecasting since his company (538) predicted that <a href="https://projects.fivethirtyeight.com/2016-election-forecast/">Hilary Clinton would win with a probability of 71%</a> in the 2016 presidential election.</p><p>This criticism has always annoyed me personally since, in statistical terms, 71% is generally not considered a strong belief in anything. So it is not inconsistent, nor suprising for someone to believe a candidate has 71% chance of success and they still lose. Even when looking at typical p-values, we wait for 95% percent certainty before making claims (and many feel this is a pretty weak belief). But for some reason whenever election polls come up, it seems even very statistically minded people suddenly think that 51% chance is a high probability.</p><p>I retweeted Nate Silver's forecast, mentioned my annoyance and provided an example of another case with a similar probability of winning:</p></div></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/willkurt&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. <br><br>For comparison if in an A/B test we had these results:<br><br>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials<br><br>This roughly how strong our belief in B is <a href=\&quot;https://t.co/bB4PiB5Tao\&quot;>https://t.co/bB4PiB5Tao</a></p>\u2014 Will Kurt (@willkurt) <a href=\&quot;https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw\&quot;>August 12, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/willkurt/status/1293575032975884288&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Will Kurt&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_6372"><div><blockquote><div dir="ltr" lang="en"><p>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. </p><p>For comparison if in an A/B test we had these results:</p><p>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials</p><p>This roughly how strong our belief in B is <a href="https://t.co/bB4PiB5Tao">https://t.co/bB4PiB5Tao</a></p></div>— Will Kurt (@willkurt) <a href="https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw">August 12, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_6436"><div><div><p>If you were running an A/B test and your A variant had 2 success in 15 trials and your B variant had 3 successes in 14 trails, you would be roughly 71% confident that B was the superior variant.</p><p>Even someone without much statistical training would likely be very skeptical of such a claim, but somehow during election forecasts even experience statisticians can look at Silver's post and think that Biden winning is a sure thing.</p></div><h2> How do we arrive at P(B &gt; A)?</h2><p><br>Twitter user <a href="https://twitter.com/mbarras_ing">@mbarras_ing</a> ask a really important follow up question, asking to explain this result:</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/mbarras_ing&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info \&quot;A has 2 successes in 15 trials, B has 3 successes in 14 trials\&quot;?</p>\u2014 Matthew Rhys Barras (@mbarras_ing) <a href=\&quot;https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw\&quot;>August 13, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/mbarras_ing/status/1293928326579589121&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Matthew Rhys Barras&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_7791"><div><blockquote><p dir="ltr" lang="en">I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info "A has 2 successes in 15 trials, B has 3 successes in 14 trials"?</p>— Matthew Rhys Barras (@mbarras_ing) <a href="https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw">August 13, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_7855"><div><div><p>I very strongly believe that all statistics, even quick off the cuff estimates, should be reproducible and explainable.</p><p>I've written a fair bit about approaching similar problems both <a href="https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing">on this blog</a> and <a href="https://www.amazon.com/Bayesian-Statistics-Fun-Will-Kurt/dp/1593279566">in my book</a>. The big picture is that we're going to come up with parameter estimates for the rate that A and B convert users and then compute the probability that B is greater than A. </p><p>Since we're estimating conversion rates we're going to use <a href="https://www.countbayesie.com/blog/2015/3/17/interrogating-probability-distributions">the Beta distribution</a> as the distribution of our parameter estimate. In this example I'm also assume a \(\text{Beta}(1,1)\) prior for our A and B variants.</p><p>The likelihood for A is \(\text{Beta}(2,13)\) and for B is \(\text{Beta}(3,11)\) so we can represent A and B as two random variables samples form these posteriors:</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p></div><p>We can now represent this in R, and sample from these distributions:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_9136"><div><pre><span>N</span> <span>&lt;</span><span>-</span> <span>10000</span>
<span>a_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>2</span><span>+</span><span>1</span>,<span>13</span><span>+</span><span>1</span>)
<span>b_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>3</span><span>+</span><span>1</span>,<span>11</span><span>+</span><span>1</span>)</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_9202"><p>And finally we can look at the results of this to compute the probability that B is greater than A:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_10612"><div><pre><span>sum</span>(<span>b_samples</span> <span>&gt;</span> <span>a_samples</span>)<span>/</span><span>N</span></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_10678"><div><p>In this case we get 0.7028 pretty close to 71% for Nate Silver’s problem.</p><h2><p>Can we solve this without R?</p></h2><p><br>This explains where we get our probabilities from, but there is an obvious question that comes up when you see this result, one raised by <a href="https://twitter.com/little_rocko">@little_rocko</a></p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/little_rocko&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>\u2014 Rocko (@little_rocko) <a href=\&quot;https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw\&quot;>August 16, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/little_rocko/status/1294938572299018242&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Rocko&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_12117"><div><blockquote><p dir="ltr" lang="en">this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>— Rocko (@little_rocko) <a href="https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw">August 16, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_12181"><div><div><p>This question is interesting because it asks two questions that don't necessarily have to be related:</p><p>- is there an easy way to solve this<br>- is there a non-"brute force" way solve this</p><p>Before moving on I want to mention that this little snippet of R involves a lot more abstraction then it seems at first glance. What we are really doing here is equalivant to using a Monte-Carlo simulation to integrate over the distribution of the difference between two Beta distributed random variables. After the next two sections it will be more clear that what's happening here is a surprisingly sophisticated operation that is, in my opinion, the easiest method of solving this problem as well as not truly a brute force solution.</p></div><h2><br>Analytic versus Easy</h2><div><p>When we see computational solutions to mathematical problems our first instinct is typically to feel that we are avoiding solving the problem <em>analytically.</em> An analytical solution is one that uses mathematical analysis to find a closed form solution.</p><p>A strivial example, suppose I wanted to find the value that minimized \(f(x) = (x+3)^2\)</p><p>In R I could brute force this by looking over a range of answers like this:</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_13626"><div><pre><span>f</span> <span>&lt;</span><span>-</span> <span>function</span>(<span>x</span>){  
  (<span>x</span><span>+</span><span>3</span>)<span>^</span><span>2</span>
}
<span>xs</span> <span>&lt;</span><span>-</span> <span>seq</span>(<span>-</span><span>6</span>,<span>6</span>,<span>by</span><span>=</span><span>0.031</span>)
<span>xs</span>[<span>which</span>.<span>min</span>(<span>f</span>(<span>xs</span>))]</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_13692"><div><div><p>As expected we get our answer of -3, but this solution takes a bit of work: we need to know how to code and we need a computer. It's also a bit messy because if we had iterated by an incredment that didn't include -3 exactly (say by 0.031) we would not get the exact answer.</p><p>If we know some basic calculus we know that our minimum has to be where the derivative is at 0. We can very easily work out that</p><p>$$f'(x) = 2(x+3)$$<br>And that</p><p>$$2(x + 3) = 0 $$</p><p>When</p><p>$$ x = -3 $$</p><p>Knowning basic calculus this later solution becomes much easier. </p><p>But even with the calculus is part is hard, often solving it once makes future solutions much easier. Take for example if you wanted to find the maximum likelihood for a normal distribution with a mean of \(\mu\) and standard deviation of \(\sigma\)</p><p>To solve this we start with our PDF for the normal distribution \(\varphi\):</p><p>$$\varphi(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$</p><p>Now computing the derivative of this is not necessarily "easy" but it's certainly something we can do. All we really care about is when</p><p>$$\varphi'(x) = 0$$</p><p>Which we can find out happens when (computing the deriviative of course is left as an exercise for the reader):</p><p>$$\frac{\mu-x}{\sigma}$$</p></div><div><p>This allows us to reallize the amazing fact that for any normal distribution we come across, we know that the maximum likelihood estimate is the sample is when \(x = \mu\)!</p><p>Even though our calculus might take us a bit of work, once this is done the problem of doing maximum likelihood estimation for any Normal distribution truly does become easy!</p></div><h3><br>Proposing an Analytic solution to our problem</h3><div><p>Let's revisit our original problem this time attempting to find an analytic solution. This is a very interesting case because arguably this is the simplest Bayesian hypothesis test you can imagine.</p><p>Recall that we have two random variable representing our beliefs in each test. These are distributed according the the posterior which we described earlier.</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p><p>Here is where I skipped some steps in reasoning. What we want to know is:</p><p>$$P(B &gt;A)$$</p></div><div><p>Which is not expressed in a particularly useful mathematical way. A better way to solve this is to consider this as the sum (or difference in this case) of two random variables. What we really want to know is:</p><p>$$P(B - A &gt; 0)$$</p><p>In order to solve this problem we can think of a new random variable \(X\) which is going to be the difference between B and A:</p><p>$$X = B - A$$</p><p>Finally we'll suppose we have a probability density function for \(X\) we'll call \(\text{pdf}_X\). If we know \(\text{pdf}_X\) our solution is pretty close, we just need to integrate between 0 and the max domain of this distribution:</p><p>$$P(B &gt; A) = P(B - A &gt; 0) = \int_{x=0}^{\text{max}}\text{pdf}_{X}(x)$$</p><p>Already this is starting to look a bit complicated, but there's one big problem ahead. Unlike Normally distributed random variables, we have no equivalent of the Normal sum theorem (we'll cover this in a bit) for Beta distributed random variables. </p><p>What does \(\text{pdf}_X\) look like? For starters we know it's not a Beta distribution itself. We can see this because we know the domain (or support) of this distribution is not \([0,1]\). Because they are Beta distributed, A and B can both take on values from 0 to 1, which means the maximum result of this difference is 1 but the minimum is -1. So whatever this distribution is, its domain is \([-1,1]\) meaning it cannot be a Beta distribution.</p><p>We can use various rules about sum of random variables to determine the mean and variance of this distribution, but without knowing the exact form of this distribution we are unable to solve the integral analytically. </p><p>Here we can see that even in this profoundly simple problem the analytical solution is frustratingly …</p></div></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</a></em></p>]]>
            </description>
            <link>https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416908</guid>
            <pubDate>Wed, 09 Sep 2020 03:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD PSB Vendor Locks EPYC CPUs for Enhanced Security at a Cost]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 253 (<a href="https://news.ycombinator.com/item?id=24416005">thread link</a>) | @virgulino
<br/>
September 8, 2020 | https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg" data-caption="AMD Platform Secure Boot Feature Cover"><img width="696" height="465" src="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-400x268.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-628x420.jpg 628w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AMD Platform Secure Boot Feature Cover" title="AMD Platform Secure Boot Feature Cover"></a><figcaption>AMD Platform Secure Boot Feature Cover</figcaption></figure></div>
            <!-- content --><p>Today we are going to discuss a change to server security that is going to make waves in the home lab and secondary markets for servers and components in the future. During our recent <a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/">Dell EMC PowerEdge C6525 review</a> we briefly mentioned that AMD EPYC CPUs in the system are vendor locked to Dell EMC systems. This is not a Dell-specific concern. We have confirmed that other vendors are supporting the feature behind this. For the large vendors, their platform security teams are pushing to build more secure platforms for their customers, and that is going to have future impacts on the secondary server market and home labs.</p>
<p>In this article, we are going to cover the basics of what is happening. We are going to discuss the motivations, and why this is going to be more common in the future. Finally, we are going to discuss what those in the industry can do to keep the secondary server market operating well. If you work with partners or resellers who dip into used parts bins or even have the potential to purchase grey market CPUs, send them this article or accompanying video. The current market has a large disconnect between what some large customers are asking for, and large vendors are delivering on and what others in the market know is happening.<span id="more-46716"></span></p>
<h2>Accompanying Video</h2>
<p>This is an important topic. To ensure that we can cover those who like to read/ skim and those who like to get information via audio, we have an accompanying video:</p>
<p><iframe title="Vendor Locking AMD EPYC CPUs Great for Security at a Cost" width="696" height="392" src="https://www.youtube.com/embed/kNVuTAVYxpM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Feel free to pop open that video on YouTube and check it out or to send to those who prefer not to read.</p>
<h2>Background: How we learned this was a “thing”</h2>
<p>In 2018 we did a <a href="https://www.servethehome.com/dell-emc-poweredge-r7415-review/">Dell EMC PowerEdge R7415 review</a> and as part of that review, we started our normal process of trying different CPUs in the system. Early in that process, we used an AMD EPYC 7251 CPU, the low-end 8-core model, and noticed something curious. It would not work in our other test systems after.</p>
<p>After a bit of research, we found it was because Dell EMC was vendor locking the chips to Dell systems. We did not know exactly why, but we were told was a security feature. At this point, and even to this day two years later, not every vendor takes advantage of all of the AMD EPYC security features. What that practically means is that what we saw with the Dell EMC system is not what we saw with other systems. For example, we were able to interchangeably use CPUs in Supermicro and Tyan systems, but we could not use those systems once they went into a Dell EMC server.</p>
<figure id="attachment_24514" aria-describedby="caption-attachment-24514"><a href="https://www.servethehome.com/dual-amd-epyc-7251-linux-benchmarks-least-expensive-2p-epyc/amd-epyc-7251-in-socket-and-carrier/" rel="attachment wp-att-24514"><img src="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg" alt="AMD EPYC In Socket And Carrier" width="800" height="533" srcset="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-696x464.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-630x420.jpg 630w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-24514">AMD EPYC In Socket And Carrier</figcaption></figure>
<p>We found we were not alone. Laboratories, VARs, and other organizations were finding that transferring AMD EPYC CPUs from one vendor’s system to another, was not the simple process it was on the Intel Xeon side. It did not always work.</p>
<p>We knew it was a security feature and thought that most who are buying servers would be informed of this by their sales reps or channel partners. After I personally got a lot of texts, e-mails, instant messaging, and comments on our C6525 video and article, I realized that this actually may be a situation where many people do not know what is going on.</p>
<figure id="attachment_46531" aria-describedby="caption-attachment-46531"><a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/dell-emc-poweredge-c6525-internal-view-nodes-partially-out/" rel="attachment wp-att-46531"><img src="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg" alt="Dell EMC PowerEdge C6525 Internal View Nodes Partially Out" width="800" height="519" srcset="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-696x452.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-647x420.jpg 647w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-46531">Dell EMC PowerEdge C6525 Internal View Nodes Partially Out</figcaption></figure>
<p>This experience that we had, apparently is one that is not overly common yet. That makes sense because the systems that utilize the enhanced security levels are still largely new, and being used by their first buyers. Also, AMD still has a smaller market share than Intel. A big reason, by the way, that Intel Xeon does not have this issue is that they do not have the security feature that AMD has. Vendors have come out and stated that their AMD EPYC systems are more secure than their Intel Xeon systems, and this behavior is a byproduct of that enhanced security.</p>
<p>Next, we are going to dive into the feature of AMD processors (and what will be more common in future CPUs from other vendors.)</p>
<h2>AMD EPYC Secure Processor Platform Secure Boot (PSB)</h2>
<p>Let us start with the high-level slide. This is effectively the same slide on the AMD Secure Processor that we saw with the AMD EPYC 7001 series launch, but this is from the EPYC 7002 series. AMD EPYC CPUs may be x86, but they have an embedded Arm Cortex-A5 microcontroller that runs its own OS that is independent of the main system. This AMD Secure Processor is the backbone of AMD’s security push as it provides features such as key management and hardware root of trust for the platform.</p>
<figure id="attachment_36705" aria-describedby="caption-attachment-36705"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-processor/" rel="attachment wp-att-36705"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg" alt="AMD EPYC 7002 Platform Secure Processor" width="1792" height="918" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg 1792w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-400x205.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-800x410.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-696x357.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-1068x547.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-820x420.jpg 820w" sizes="(max-width: 1792px) 100vw, 1792px"></a><figcaption id="caption-attachment-36705">AMD EPYC 7002 Platform Secure Processor</figcaption></figure>
<p>AMD spends time <a href="https://www.servethehome.com/amd-confirms-cts-labs-exploits-requiring-admin-access/">patching this solution</a>&nbsp;to make it more secure, but it is generally fairly hard to reach without some extremely low-level access in a system. We are going to come back to the “Enables hardware validated boot” line shortly, but it is important to understand that this secure processor underpins many of AMD’s best security features.</p>
<p>For example, at STH we use EPYC’s Secure Memory Encryption and Secure Encrypted Virtualization heavily. With AMD EPYC, we do not have to manually manage keys. Instead, the ephemeral keys are managed for us by the AMD Secure Processor. This is the basis for what is really the building wave of confidential computing offerings such as&nbsp;<a href="https://www.servethehome.com/google-cloud-confidential-computing-enabled-by-amd-epyc-sev/">Google Cloud Confidential Computing Enabled by AMD EPYC SEV</a>. Intel has its secure boot features and SGX that will be enhanced greatly with <a href="https://www.servethehome.com/the-2021-intel-ice-pickle-how-2021-will-be-crunch-time/">Ice Lake Xeons</a>, but for now, AMD has this capability while Intel does not. When big vendors say AMD is more secure, the AMD Secure Processor is a cornerstone of those offerings.</p>
<figure id="attachment_36704" aria-describedby="caption-attachment-36704"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-memory-encryption/" rel="attachment wp-att-36704"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg" alt="AMD EPYC 7002 Platform Secure Memory Encryption" width="1769" height="890" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg 1769w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-400x201.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-800x402.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-696x350.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-1068x537.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-835x420.jpg 835w" sizes="(max-width: 1769px) 100vw, 1769px"></a><figcaption id="caption-attachment-36704">AMD EPYC 7002 Platform Secure Memory Encryption</figcaption></figure>
<p>Let us discuss that “Enables hardware validated boot” line. While traditionally CPUs just fire up in whatever platform they are in, AMD has intelligence in their CPU due to the Arm-based AMD Secure Processor. EPYC CPUs are designed to be a bit more intelligent about the platforms they are in, and interact with server platform security to act as this root of trust that would not be possible if they effectively just booted up in any system.</p>
<p>Here is a statement from AMD describing the AMD Platform Secure Boot.</p>
<p><em>The AMD Platform Secure Boot Feature (PSB) is a mitigation for firmware Advanced Persistent Threats. It is a defense-in-depth feature. PSB extends AMD’s silicon root of trust to protect the OEM’s BIOS.&nbsp; This allows the OEM to establish an unbroken chain of trust from AMD’s silicon root of trust to the OEM’s BIOS using PSB, and then from the OEM’s BIOS to the OS Bootloader using UEFI secure boot. This provides a very powerful defense against remote attackers seeking to embed malware into a platform’s firmware.</em></p>
<p><em>An OEM who trusts only their own cryptographically signed BIOS code to run on their platforms will use a PSB enabled motherboard and set one-time-programmable fuses in the processor to bind the processor to the OEM’s firmware code signing key. AMD processors are shipped unlocked from the factory, and can initially be used with any OEM’s motherboard. But once they are used with a motherboard with PSB enabled, the security fuses will be set, and from that point on, that processor can only be used with motherboards that use the same code signing key. (<strong>Source</strong>: AMD statement to STH)</em></p>
<p>That is a lot to take in. We asked HPE about this. Their response mirrored what the above was describing. HPE firmware, when a system is first turned on, performs this binding process where the AMD EPYC CPU expects to see HPE signed firmware. If you alter the HPE firmware on the system, the check fails and the system will not work. That means if your HPE motherboard fails, you can replace it and put your CPU in another HPE motherboard with signed HPE firmware. It also means if the server platform’s firmware is not signed by HPE, the processor will see it as evidence of tampering and not work.</p>
<p><strong>Edit: 2020-09-09</strong> – HPE clarified that they are doing this in a different manner than Dell after initially confirming that they were using the AMD PSB feature. After this went live, HPE sent us the following:</p>
<p><em>HPE does not use the same security technique that Dell is using for a BIOS hardware root of trust. HPE does not burn, fuse, or permanently store our public key into AMD processors which ship with our products. HPE uses a unique approach to authenticate our BIOS and BMC firmware: HPE fuses our hardware – or silicon – root of trust into our own BMC silicon to ensure only authenticated firmware is executed.&nbsp; Thus, while we implement a hardware root of trust for our BIOS and BMC firmware, the processors that ship with our servers are not locked to our platforms. (<strong>Source</strong>: HPE)</em></p>
<p>What is at least interesting there is that HPE was initially claiming feature parity with Dell to us, and from the comments on this article were saying they used this feature in sales pitches, but now are saying they are not blowing the eFuses.</p>
<figure id="attachment_39258" aria-describedby="caption-attachment-39258"><a href="https://www.servethehome.com/pcie-gen4-hpe-proliant-dl325-gen10-plus-and-dl385-gen10-plus-amd-epyc-7002/hpe-proliant-dl325-gen10-plus-at-sc19-cpu-cover/" rel="attachment wp-att-39258"><img src="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg" alt="HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover" width="800" height="600" srcset="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-265x198.jpg 265w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-696x522.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-560x420.jpg 560w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-39258">HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover</figcaption></figure>
<p>Here is where the concern develops, and not necessarily for AMD, the OEM, or most of the initial customer base. Customers want more security. The OEMs want to create a secure hardware environment because that is what their customers want. AMD is implementing an advanced security solution beyond what Intel Xeons have giving the OEMs and end-customers what they want. Effectively, when these are sold as new systems, this is exactly what everyone involved wants.</p>
<p>If everyone is getting what they want, then where is the concern, that is what we are going to cover next.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416005</guid>
            <pubDate>Wed, 09 Sep 2020 02:02:27 GMT</pubDate>
        </item>
    </channel>
</rss>
