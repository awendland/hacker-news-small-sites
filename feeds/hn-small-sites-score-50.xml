<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 01 Feb 2021 12:48:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 01 Feb 2021 12:48:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Creating my awesome Windows 10 dev setup]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 98 (<a href="https://news.ycombinator.com/item?id=25965231">thread link</a>) | @indigodaddy
<br/>
January 29, 2021 | https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/ | <a href="https://web.archive.org/web/*/https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="background"><a href="#background">→</a>Background</h2><p>I recently got the chance to completely reset my Windows 10 machine, and took advantage of the
opportunity to create a dev environment I would love. These were my high-level goals:</p><ul><li>Make WSL my primary dev environment</li><li>Use VSCode as my primary editor</li><li>Have a beautiful terminal</li></ul><h2 id="wsl-%26-vscode"><a href="#wsl-%26-vscode">→</a>WSL &amp; VSCode</h2><p>To achieve this, I started by installing WSL 2. I went with an Ubuntu distro because that's what
I've had the most experience with in the past. You can find instructions on installing WSL and/or
upgrading it to WSL 2 in the <a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">official
docs</a>.</p><p>Next I installed <a href="https://code.visualstudio.com/">VSCode</a>, and the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack">Remote Development extension
pack</a>
which is where things start to get fun. With this extension pack installed, you can edit files in
the WSL filesystem seamlessly with VSCode.</p><h2 id="windows-terminal"><a href="#windows-terminal">→</a>Windows Terminal</h2><p>To get my beautiful terminal going, I installed <a href="https://devblogs.microsoft.com/commandline/windows-terminal-1-0/">Windows
Terminal</a> (WT), which is an
awesome new terminal experience for Windows from Microsoft.</p><p>Although I wanted WSL to be my primary dev environment, I still wanted working in Windows to be a
nice experience as well, so I wanted to make sure my PowerShell terminal was great too. To get that
going, I also installed the latest <a href="https://devblogs.microsoft.com/powershell/announcing-powershell-7-0/">PowerShell
7</a>.</p><p>Now it was time to setup my WT profiles. By default, WT creates a profile for WSL, PowerShell, cmd,
and Azure Cloud Shell. I'm not interested in using cmd or Azure Cloud Shell, and I'm going to be
using PowerShell 7 instead of PowerShell, so I disabled all but the WSL shell. To do this, simply
add the <code>"hidden": true</code> property to the profiles in the WT settings file (click the dropdown in the
header bar and then Settings or <span><kbd>Ctrl</kbd>+<kbd>,</kbd></span>).</p><h3 id="powershell-wt-profile"><a href="#powershell-wt-profile">→</a>PowerShell WT Profile</h3><p>Now to create my PowerShell 7 profile, I added the following object to the profiles array:</p><pre data-language="json" data-index="0"><code><span><span>{</span></span>
<span><span>  </span><span>"guid"</span><span>: </span><span>"</span><span>{346d54ee-6282-41c7-846a-0a2fa38ff66b}</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"name"</span><span>: </span><span>"</span><span>PowerShell</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"commandline"</span><span>: </span><span>"</span><span>pwsh.exe</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"icon"</span><span>: </span><span>"</span><span>%SystemRoot%</span><span>\\</span><span>Installer</span><span>\\</span><span>{8B844F39-E6EE-486B-BE85-96A485AE2B96}</span><span>\\</span><span>PowerShellExe.ico</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"startingDirectory"</span><span>: </span><span>"</span><span>D:</span><span>\\</span><span>code</span><span>"</span></span>
<span><span>}</span></span></code></pre><p>A few things to note:</p><ul><li>To generate a GUID, you can use the <a href="https://www.guidgenerator.com/online-guid-generator.aspx">Online GUID
Generator</a> website</li><li>I am using the <code>pwsh.exe</code> command instead of <code>powershell.exe</code> to use PowerShell 7</li><li>Follow these steps to find the icon path on your system:<ol><li>Open your Start menu and search for PowerShell 7</li><li>Right click on the app and click "Open file location"</li><li>In the file explorer that opens, right click the shortcut and click "Properties"</li><li>On the "Shortcut" tab, click the "Change Icon..." button and copy the file path</li></ol></li><li>I like to set the starting directory to be where I keep all my projects, and ideally this is near
the root of a drive to keep file paths as short as possible</li></ul><h3 id="ubuntu-wt-profile"><a href="#ubuntu-wt-profile">→</a>Ubuntu WT Profile</h3><p>Since I want to make WSL my primary environment, I moved its profile object to the top of the list
so that it will appear first in the new tab dropdown. Then I replaced the top-level <code>defaultProfile</code>
property with the WSL profile's <code>guid</code> property to make it the profile that is opened automatically
when WT launches.</p><p>Similarly to PowerShell, I wanted the starting directory to be <code>~/code</code>. If you try setting that
directly in the WT configuration, you'll find it doesn't work because WT doesn't know how to resolve
it. You can use an absolute path to get there instead, and you need to use a Windows file path that
WT can understand. You can access a WSL distro's file system from Windows using <code>\\wsl$\&lt;distro&gt;</code>, so, I added this property to the Ubuntu profile object: <code>"startingDirectory": "\\\\wsl$\\Ubuntu\\home\\blake\\code"</code> (where <code>Ubuntu</code> should be replaced with the name of your WSL
distro and <code>blake</code> with your WSL username).</p><h3 id="wt-theme"><a href="#wt-theme">→</a>WT Theme</h3><p>Finally, I wanted to get a new theme for my WT. I decided I would like to use the same colour scheme
as I was using for VSCode at the time, which was the <a href="https://marketplace.visualstudio.com/items?itemName=sdras.night-owl">Night
Owl</a> theme. So (naturally), <a href="https://chimerical.ca/posts/generate-windows-terminal-scheme">I
created</a> a <a href="https://marketplace.visualstudio.com/items?itemName=blake-mealey.generate-wt-scheme">VSCode
plugin</a> to
automatically generate a WT theme.</p><p>Here's what my terminal looks like with the Night Owl theme:</p><p><span>
      <a href="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Windows Terminal with Night Owl" title="Windows Terminal with Night Owl" src="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png" srcset="https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/63868/terminal.png 250w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/0b533/terminal.png 500w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/00d43/terminal.png 1000w,https://chimerical.ca/static/20a8faf4783f0c30ece0bcfc207c1fed/1628f/terminal.png 1232w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><h2 id="shell-profiles"><a href="#shell-profiles">→</a>Shell Profiles</h2><p>Next up I wanted to get my shell profiles started. We'll iterate on these more later on. Your shell
profile is a script that gets run when the terminal starts which can be used to configure the
current environment. For PowerShell, this will be a PowerShell script and for WSL it will be a bash
script.</p><h3 id="powershell-profile"><a href="#powershell-profile">→</a>PowerShell Profile</h3><p>Let's start with PowerShell again. You can run <code>echo $PROFILE</code> to see if a profile script already
exists. For me it did, and it was located at
<code>C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</code>. If it doesn't exist for you,
it's not a big deal. It seems that PowerShell looks in a <a href="https://devblogs.microsoft.com/scripting/understanding-the-six-powershell-profiles/">variety of
places</a> and you
can just create a script in the appropriate place and it should work. Here's what I added to my
profile script:</p><pre data-language="ps1" data-index="1"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value nano</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name edit </span><span>-</span><span>Value editor</span></span>
<span></span>
<span><span>function</span><span> </span><span>profile_alias</span><span> { editor $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name profile </span><span>-</span><span>Value profile_alias</span></span>
<span></span>
<span><span>function</span><span> </span><span>reload_alias</span><span> { </span><span>&amp;</span><span> $PROFILE }</span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name reload </span><span>-</span><span>Value reload_alias</span></span></code></pre><p>Let's break this down a bit. First of all, I am creating a couple aliases (<code>editor</code> and <code>edit</code>) for
my in-terminal editor. I prefer to use a terminal editor instead of a GUI editor because it reduces
context switching when working in the terminal, and is much faster to load the file to make a quick
edit. That said, if you wanted to use VSCode, you could replace <code>nano</code> with <code>code</code>.</p><p>The reason I create an alias for my editor command is so that I can change the editor at any time
and not have to change my muscle memory to use the new command. It also means I can create more
aliases that open the editor without having to change all of them if I change my editor.</p><p>Next, I add the <code>profile</code> alias which opens the profile script in my editor (the <code>editor</code> alias is
already coming in handy!). This is great because now I don't need to remember where my profile is
ever again, I can just run <code>profile</code> and can start editing it right away. I also add a <code>reload</code>
alias which simply reloads the shell using the profile script. This lets me use my changes to the
profile script without having to create a new terminal instance.</p><h3 id="bash-profile"><a href="#bash-profile">→</a>Bash Profile</h3><p>Now let's do the same thing for bash. In bash, the profile is a bash script located at <code>~/.bashrc</code>.
By default it contains a lot of stuff already, so I like to add my changes to the bottom of the
script. Here's what I added:</p><pre data-language="bash" data-index="2"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>nano</span><span>"</span></span>
<span><span>alias</span><span> editor=</span><span>"</span><span>$EDITOR</span><span>"</span></span>
<span><span>alias</span><span> edit=</span><span>"</span><span>editor</span><span>"</span></span>
<span></span>
<span><span>export</span><span> PROFILE=</span><span>"</span><span>~/.bashrc</span><span>"</span></span>
<span><span>alias</span><span> profile=</span><span>"</span><span>editor </span><span>$PROFILE</span><span>"</span></span>
<span><span>alias</span><span> reload=</span><span>"</span><span>source </span><span>$PROFILE</span><span>"</span></span>
<span></span>
<span><span>alias</span><span> explorer=</span><span>"</span><span>explorer.exe</span><span>"</span></span></code></pre><p>This is very similar to the PowerShell script. First, we create an <code>EDITOR</code> environment variable.
Some Linux programs respect the <code>EDITOR</code> variable, so it's a good idea to set it if you want more
programs to know which editor you want to use. Then we use <code>EDITOR</code> to create our <code>editor</code> and
<code>edit</code> aliases just like before.</p><p>Then, I add the same <code>profile</code> and <code>reload</code> aliases to edit and reload the profile script.</p><p>Finally, I added another alias which maps <code>explorer</code> to <code>explorer.exe</code> which makes it the same
command for opening the Windows File Explorer in WSL as in PowerShell.</p><h2 id="terminal-editor"><a href="#terminal-editor">→</a>Terminal Editor</h2><p>Let's revisit our terminal editor. I started with nano because it's a pretty intuitive and easy to
use editor for terminals. I don't have a lot of terminal editor experience, so I'm not very handy
with Vim, and even nano can be a bit awkward to use.</p><p>So, I did a bit of research to see if there were any editors that had more similar keyboard
shortcuts and navigation to a modern GUI text editor, like VSCode. I found
<a href="https://micro-editor.github.io/">micro</a> which is available cross-platform, which is perfect!</p><h3 id="powershell-editor"><a href="#powershell-editor">→</a>PowerShell Editor</h3><p>Let's install it. In PowerShell, it's most easily installed via <a href="https://scoop.sh/">scoop</a> or
<a href="https://chocolatey.org/">Chocolatey</a>. If you don't have either installed yet I'd highly recommend
you do, as it makes installing programs in Windows a much easier experience. I'm going to use scoop
for the purposes of this guide. With scoop installed, simply run <code>scoop install micro</code>. Now you can
run <code>micro</code> to edit your files.</p><p>Let's update our profile script to use it:</p><pre data-language="ps1" data-index="3"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Set-Alias</span><span> </span><span>-</span><span>Name editor </span><span>-</span><span>Value micro</span></span></code></pre><h3 id="ubuntu-editor"><a href="#ubuntu-editor">→</a>Ubuntu Editor</h3><p>To install on Ubuntu, we can run the install script from the micro website:</p><pre data-language="bash" data-index="4"><code><span><span>curl https://getmic.ro </span><span>|</span><span> bash</span></span></code></pre><p>Now we can update our bash profile to use it:</p><pre data-language="bash" data-index="5"><code><span><span>#</span><span> ~/.bashrc</span></span>
<span></span>
<span><span>export</span><span> EDITOR=</span><span>"</span><span>micro</span><span>"</span></span></code></pre><h3 id="micro-theme"><a href="#micro-theme">→</a>Micro Theme</h3><p>One issue you might notice once you start editing in micro is that it's theme clashes with your WT
theme. One option could be to port your WT theme to micro, but this is quite a bit of work. I found
using the built-in <code>simple</code> theme uses your terminal theme's background colour and seems to fit
quite well for me.</p><p>To do this, you'll have to configure micro for PowerShell and WSL separately. To configure it, open
micro, press <span><kbd>Ctrl</kbd>+<kbd>E</kbd></span> to open the command prompt, then enter the command <code>set colorscheme simple</code>.</p><h2 id="terminal-prompt"><a href="#terminal-prompt">→</a>Terminal Prompt</h2><p>Finally, to make our terminal really pretty, we need to customize the prompt. There's lots of
options out there for this, but the most popular one seems to be
<a href="https://github.com/ohmyzsh/ohmyzsh">ohmyzsh</a> for Bash and
<a href="https://github.com/JanDeDobbeleer/oh-my-posh">oh-my-posh</a> for PowerShell. I'm not a huge fan of
these because in my experience they slow down the terminal to a point which makes me frustrated to
use them, and since they are separate solutions for each environment they must be configured separately.</p><p>Enter <a href="https://starship.rs/">Starship</a>, a "blazing-fast," cross-platform alternative with a
delightfully simple prompt and some awesome customization (with the promise of even more coming in
future releases). Since WSL and PowerShell both have access to the Windows filesystem, we can even
store the Starship configuration in a central place and have both pull from it.</p><h3 id="powershell-starship"><a href="#powershell-starship">→</a>PowerShell Starship</h3><p>To install Starship for PowerShell, we can again use scoop: <code>scoop install starship</code>. To load
starship, we again need to edit our profile (now with our snazzy editor and single-command alias):</p><pre data-language="ps1" data-index="6"><code><span><span>#</span><span> C:\Users\blake\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</span></span>
<span></span>
<span><span>Invoke-Expression</span><span> (</span><span>&amp;</span><span>starship init powershell)</span></span></code></pre><p>Now we can run our <code>reload</code> alias and see the beautiful prompt immediately.</p><h3 id="bash-starship"><a href="#bash-starship">→</a>Bash Starship</h3><p>Installing Starship for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/">https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</a></em></p>]]>
            </description>
            <link>https://chimerical.ca/posts/creating-my-awesome-windows-10-dev-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25965231</guid>
            <pubDate>Sat, 30 Jan 2021 01:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Siliconpr0n: High Resolution Chip Maps]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25964865">thread link</a>) | @lelf
<br/>
January 29, 2021 | https://siliconpr0n.org/map/ | <a href="https://web.archive.org/web/*/https://siliconpr0n.org/map/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://siliconpr0n.org/map/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964865</guid>
            <pubDate>Sat, 30 Jan 2021 00:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1 supports “billion of colors” a.k.a. HDR 10-bit output]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25964501">thread link</a>) | @singhkays
<br/>
January 29, 2021 | https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/ | <a href="https://web.archive.org/web/*/https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When most people hear Apple in a sentence, their next thought is likely the color. This is because color has always played an exciting role in Apple’s history: from the original Mac to the iMac, from the G3 to the Cube, from Bondi Blue to Snow White. The introduction of color played a vital part in these products' success as it helped create strong visual brand recognition.</p>
<p>The prominent use of color no doubt stems from Steve Jobs obsessing over the smallest details. For instance, there was a time when Steve spent 30 minutes picking the <a href="https://www.businessinsider.com/steve-jobs-attention-to-detail-2011-10">perfect shade of gray for the restroom signs</a>! and another time <a href="https://www.businessinsider.com/steve-jobs-attention-to-detail-2011-10#he-insisted-on-making-the-circuit-board-inside-the-mac-look-great-2">when he insisted on making the circuit board inside the Mac look great</a>. An engineer told him:</p>
<blockquote>
<p>“The only thing that matters is how well it works. Nobody is going to see the PC board.”</p>
</blockquote>
<p>Jobs response was:</p>
<blockquote>
<p>“I want it to be as beautiful as possible, even if it’s inside the box. A great carpenter isn’t going to use lousy wood for the back of a cabinet, even though nobody’s going to see it.”</p>
</blockquote>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/imac-bondi-blue_huceafe297aecbba9378b496bc001e52df_413334_800x0_resize_q75_lanczos.jpg" alt="Apple iMac in Bondi Blue color"> <figcaption>
<p>iMac G3 in Bondi Blue released in 1998
<a href="https://en.wikipedia.org/wiki/IMac_G3">[Wikipedia]</a></p>
</figcaption>
</figure>
<p>For as long as we’ve had TVs, color has been an important metric to judge the display’s quality. We’ve witnessed technologies such as CRT, Plasma, and LCD compete to display the most life-like color. The newest technology to enter this fray is High Dynamic Range, aka HDR. The aim remains the same i.e. to recreate an image closer to that seen by the human eye. Traditionally, every video has been delivered in an 8-bit specification known as Rec. 709, displaying up to millions of shades of colors. HDR improves upon this by stepping up to 10 or 12-bit standard known as Rec. 2020 or BT.2020, representing 60 times more color combinations with smoother shade gradations aka “Billions of colors”.</p>
<p>Apple has generally been at the forefront of adopting the latest display technology. Some notable examples include - introducing high-resolution Retina Displays when 1366x768 was a very common resolution for Windows laptops, <a href="https://www.engadget.com/2015-10-30-apple-imac-5k-el-capitan-billions-colors.html">Shipping 2015 Retina iMacs</a> with 10-bit displays i.e. “Billions of colors”, <a href="https://www.apple.com/newsroom/2017/09/apple-tv-4k-brings-home-the-magic-of-cinema-with-4k-and-hdr/">Apple TV 4K, which was one of the first consumer devices to support Dolby Vision HDR in 2017</a>, <a href="https://www.apple.com/newsroom/2017/09/apple-tv-4k-brings-home-the-magic-of-cinema-with-4k-and-hdr/">automatic upgrades of HD titles to Dolby Vision</a> for iTunes users - a move that is still unrivaled, iPhone 12 which is the first smartphone to be able to <a href="https://www.apple.com/newsroom/2020/10/apple-introduces-iphone-12-pro-and-iphone-12-pro-max-with-5g/">record videos in the Dolby Vision HDR format</a>. Apple also sells <a href="https://www.apple.com/pro-display-xdr/">Pro Display XDR</a>, that costs upward of ~$5000 and ticks all the right boxes for any professional doing color-accurate work.</p>
<p>Therefore, with Apple’s color pedigree, it was surprising to see that on the M1 device specification page, there is <strong>no mention of whether M1 devices can output “Billions of colors”</strong>. In contrast, the Intel-based devices clearly outline this support.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-intel-specs-billion-colors_hue4b2c058caf5118a36b30d1926649546_845638_800x0_resize_lanczos_2.png" alt="Apple MacBook Pro specifications showing support for outputting &quot;Billions of colors&quot;"> </a><figcaption>
<p>Specs for the Intel MacBook Pro show that it can output “Billions of Colors”
<a href="https://support.apple.com/kb/SP794?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-macbook-m1-specs-no-billion-colors_hufcb26cf6ebf3e0e60f9bc6db156c32b7_671671_800x0_resize_lanczos_2.png" alt="Apple MacBook Pro specifications with no support for outputting &quot;Billions of colors&quot;"> </a><figcaption>
<p>No mention of “Billions of Colors” for M1 MacBook
<a href="https://support.apple.com/kb/SP824?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<p><strong>EDIT: 1/25/21</strong> - Adding specs for Mac Mini as that’s what was tested. The MacBook spec comparison was for apples-to-apples similar device class purposes.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-mac-mini-m1-specs-no-billion-colors_hub71ad38c795181026054e1d86db438a4_342818_800x0_resize_lanczos_2.png" alt="Apple Mac Mini M1 without any support for billions of colors"> </a><figcaption>
<p>No mention of “Billions of Colors” for M1 Mac Mini
<a href="https://support.apple.com/kb/SP823?locale=en_US">[Source: Apple Technical Specifications]</a></p>
</figcaption>
</figure>
<p>Even the trusty method of viewing the value in <code>"About this mac" -&gt; "System Report" -&gt; "Graphics/Displays"</code> doesn’t show anything. Usually, this would list a value of 30-bit here (<em>i.e. 10-bit per RGB channel</em>). On M1 devices, the below is what you see when connected to an HDR capable display i.e. no mention of whether the M1 Mini is outputting a 10-bit video signal.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_1200x0_resize_lanczos_2.png 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-system-report-graphics-displays_hud3ef95f76709c4dbd72a62676d98b432_176089_800x0_resize_lanczos_2.png" alt="Apple M1 Silcon system report graphics/displays"> </a>
</figure>
<p><strong>So I set about testing 10-bit output support myself.</strong></p>

<ul>
<li><strong>TV</strong> - 2017 Vizio M65-E0 (<a href="https://www.displayspecifications.com/en/model/dd6cb89">Display Specifications</a>)</li>
<li><strong>Monitor</strong> - Philips Brilliance P272P7VU 4K UHD 27" (<a href="https://www.displayspecifications.com/en/model/8e9287b">Display Specifications</a>)</li>
<li><strong>2020 Mac Mini M1</strong> connected through a HDMI cable</li>
</ul>

<p>For this test, I used my trusty 2017 Vizio M65-E0 TV that has a 10-bit panel. I connected the Mac Mini to my Denon AVR-X1300 receiver. The “Displays” settings on Mac OS immediately gave me an option of enabling HDR.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_1200x0_resize_lanczos_2.png 1200w,
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-m1-silicon-displays-hdr-setting_hu100dce8a4973912613c03351c1780442_357149_800x0_resize_lanczos_2.png" alt="Apple M1 Silcon displays hdr setting">
</figure>
<h3 id="apple-tv-hdr-test">Apple TV HDR test</h3>
<p>Next, I fired up the Apple TV app. Immediately on the “Library” tab, I saw another menu item for HDR titles that’s not visible when connected to a non-HDR display.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-hdr-library_hu3b7c672baae2ccb0a4e1d6375badaef7_1164358_800x0_resize_lanczos_2.png" alt="Apple TV app shows HDR category when HDR is enabled in display settings">
</figure>
<p>Then I used the Apple TV app to play 2017’s Wonder Woman and confirmed through the TV info that it received an HDR10 signal.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_1500x0_resize_q75_lanczos.jpg 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/apple-tv-m1-silicon-wonder-woman-hdr_hu22d7e59a5b922310df01bd3743499c12_426776_800x0_resize_q75_lanczos.jpg" alt="Apple TV app shows HDR category when HDR is enabled in display settings">
</figure>
<h3 id="youtube-hdr-test">YouTube HDR test</h3>
<p>Next, I played an HDR video from YouTube on Safari. I confirmed that I could select the HDR formats for this video, and the video was playing in HDR mode using “Stats for nerds” info. The “Color” values of <code>smpte2084 (PQ) / bt2020</code> confirmed that the video was playing in HDR mode.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1_hufb69e888db87e49daf1d80e0341a7c54_1524037_800x0_resize_lanczos_2.png" alt="YouTube plays in HDR mode on Apple Silicon M1"> </a>
</figure>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/youtube-hdr-video-apple-silicon-m1-stats-for-nerds_huf22d17bc9bfcb5b4dda91364e069c430_1417395_800x0_resize_lanczos_2.png" alt="YouTube stats for nerds confirms BT2020 color on Apple Silicon M1"> </a>
</figure>
<h3 id="spears-munsil-quantization-test">Spears Munsil quantization test</h3>
<p>I also found a video with an 8-bit and 10-bit quantization artifact test pattern <a href="https://www.avsforum.com/threads/10-bit-gradient-test-patterns.2269338/">here</a>. When I played this video on the TV, the 10-bit pattern was completely smooth.</p>
<p>NOTE: <em>In the image below, both 8-bit and 10-bit appear equally banded because of the 8-bit capture from my smartphone. In reality, the 10-bit pattern is completely smooth compared to the 8-bit pattern.</em></p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test.jpg" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_480x0_resize_q75_lanczos.jpg 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_800x0_resize_q75_lanczos.jpg 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_1200x0_resize_q75_lanczos.jpg 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_1500x0_resize_q75_lanczos.jpg 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test_hu5648bd94ff93c50402f187b249c09339_3258563_800x0_resize_q75_lanczos.jpg" alt="Spears Munsil Quantization Test video 8-bit vs 10-bit"> </a>
</figure>
<p><a href="https://www.avsforum.com/threads/10-bit-gradient-test-patterns.2269338/">Download test video from here</a></p>

<p>At this point, it’s clear that the Mac Mini can output an HDR10 signal when connected to an HDR capable display. Next, I explored if it can output a 10-bit signal / Billions of colors to a non-HDR 10-bit display. This was done by connecting to the Philips Brilliance P272P7VU monitor.</p>
<h3 id="10-bit-psd-test">10-bit PSD test</h3>
<p>The first test was done by displaying a 10-bit PSD file in “Preview”, which supports 10-bit files. <strong>If the M1 outputs a 10-bit signal, then the gradients in the file would be smooth.</strong> Opening the file in “Preview” confirmed the 10-bit output as the test pattern was completely smooth. I also opened the same file in another image viewer called “Pixea” and observed banding which most likely is because “Pixea” doesn’t support 10-bit files. In the image below, the same file is open in “Preview” on the left and “Pixea” on the right.</p>
<p>NOTE: <em>You might not observe the difference between the two images below as during the upload and publishing this image might get converted to 8-bit. On my machine the left image is completely smooth while the right displays banding.</em></p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_800x0_resize_lanczos_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/10-bit-psd-file_hu2e04932d088c1eadd295545f0133b37d_361696_800x0_resize_lanczos_2.png" alt="10-bit PSD file in a 10-bit viewer vs 8-bit viewer"> </a>
</figure>
<p><a href="https://imagescience.com.au/knowledge/10-bit-output-support">Download the 10-bit PSD file from here</a></p>
<h3 id="spears-munsil-quantization-test-1">Spears Munsil quantization test</h3>
<p>I also ran the “Spears Munsil” quntaization pattern on this monitor and observed the 10-bit pattern had less banding. I ran the test with the latest version of VLC Player - 3.12.1 that is a native Apple Silicon binary.</p>
<figure><a href="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor.png" target="_blank">
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_800x0_resize_lanczos_2.png 800w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_1200x0_resize_lanczos_2.png 1200w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_1500x0_resize_lanczos_2.png 1500w,
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/spears-munsil-quantaziation-test-monitor_huddcc9d57251e34ed89aea80b66069025_277365_800x0_resize_lanczos_2.png" alt="Spears Munsil Quantization Test shows 10-bit pattern has less banding"> </a><figcaption>
<p>Spears Munsil Quantization Test shows 10-bit pattern has less banding</p>
</figcaption>
</figure>
<h3 id="switchresx-test">SwitchResX test</h3>
<p>Using SwitchResX, I confirmed that the display was set to “Billions of colors” mode i.e. outputting a 10-bit signal.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_480x0_resize_lanczos_2.png 480w,
            
                   https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_800x0_resize_lanczos_2.png 800w,
            
                   
            
                   
            " src="https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/media/switchresx-billions-of-colors-apple-silicon-m1_huee04fcd05d04530d1903d0ac7fc3a7ac_714244_800x0_resize_lanczos_2.png" alt="YouTube plays in HDR mode on Apple Silicon M1">
</figure>

<p>Reach out if you have any questions! Feel free to follow me on</p>
<ul>
<li>Twitter - <a href="https://twitter.com/singhkays">@singhkays</a></li>
<li>LinkedIn - <a href="https://www.linkedin.com/in/singhkays/">https://www.linkedin.com/in/singhkays/</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964501</guid>
            <pubDate>Fri, 29 Jan 2021 23:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe's Vaccine Disaster]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 268 (<a href="https://news.ycombinator.com/item?id=25964197">thread link</a>) | @danielfoster
<br/>
January 29, 2021 | https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When European Commission President Ursula von der Leyen talks about politics, there is never a shortage of superlatives and grandiloquence. Until recently, that was also true when she was talking about the extremely sensitive issue of vaccines.</p>


<div>
<p>In late November, von der Leyen gushed about the contracts the European Union had signed with various producers, saying it meant that Europeans would have "access to the most promising future vaccines under development" against the coronavirus. When it became clear in December that the first people in the EU would be vaccinated soon after Christmas, she even injected a bit of pathos, tweeting "It's Europe's moment." When the vaccinations then began, she wrote of a "touching moment of unity" and a "European success story."</p><p>These days, though, von der Leyen is noticeably quieter – a silence that could have to do with the fact that the erstwhile "success story" might ultimately turn out to be the greatest disaster of her entire political career.</p>
</div>

<div>
<p>Europe is facing a vaccine disaster. Whereas countries like Israel, Britain and the United States. are quickly moving ahead with vaccinations, the EU is reeling from a string of setbacks. First, U.S. pharmaceutical giant Pfizer and its German partner BioNTech informed Brussels that it would be delivering far less vaccine than planned in the coming weeks. Then, the company AstraZeneca said it would only be delivering 31 million doses of its vaccine by the end of March instead of the 80 million Europe had been expecting. And again, the Commission was caught completely off guard.</p><p>Since then, frustration and anger has been growing across the EU. Europe, one of the most affluent regions in the world, is proving to be unable to quickly protect its citizens from a deadly disease, while other countries are showing how it is done.</p>
</div>

<div>
<p>And the boss is nowhere to be found.</p><p>The louder the criticism has grown, the less has been heard from the erstwhile loquacious Commission president. She has, at times, been like the phantom of Brussels. Requests for comment from the press have been systematically blocked by her communications department and she has essentially gone into hiding. This week, though, at the World Economic Forum, she wasn't able to entirely avoid the issue. "Now, the companies must deliver," she said. In other words, the companies are to blame, not us. Not me.</p><p>It is, to put it bluntly, a pattern that has occurred frequently throughout her career.</p>
</div>


<section data-area="contentbox">

</section>
<div>
<p>Whenever von der Leyen, a member of Chancellor Angela Merkel's Christian Democrats (CDIU), has taken on a new leadership position, she has never just been the new minister. She has always acted as though she would do everything different – better – than her predecessor. It has frequently sounded as though von der Leyen planned to reinvent whatever department or ministry she had just assumed control of, making it more functional and more glamorous at the same time. But by the time it became necessary to dive into the sordid details, she had usually moved on.</p><h3>Posing as the Mother of the Nation</h3><p>When von der Leyen was appointed family minister in 2005, she introduced a generous federally funded program for parental leave and expanded daycare offerings, essentially revolutionizing her party's family-policy image in the process. But when it came to addressing the difficulties associated with opening a huge number of new daycare facilities – that was left to her successor.</p><p>When she became minister of labor and social affairs in 2009, she promised a hot lunch for every child. The result, though, was a confusing collection of regulations. "Ursula von der Leyen was excellent at posing as the mother of the nation and launching illusory programs for the poor," says Ulrich Schneider, head of the federation of German welfare associations.</p>
</div>
<figure>
<div data-component="Image" data-zoom-id="47baac18-c864-44a9-a59c-2a631be7f8a1" data-settings="{&quot;id&quot;:&quot;88a76b76-b089-42e0-ab96-55e7ceb11a42&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;47baac18-c864-44a9-a59c-2a631be7f8a1&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg" srcset="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w488_r0.7463002114164905_fpx50_fpy40.28.jpg 488w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w616_r0.7463002114164905_fpx50_fpy40.28.jpg 616w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg 718w," width="706" height="946" sizes="706px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w488_r0.7463002114164905_fpx50_fpy40.28.jpg 488w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w616_r0.7463002114164905_fpx50_fpy40.28.jpg 616w, https://cdn.prod.www.spiegel.de/images/88a76b76-b089-42e0-ab96-55e7ceb11a42_w706_r0.7463002114164905_fpx50_fpy40.28.jpg 718w," title="AstraZeneca head Pascal Soriot in 2014" alt="AstraZeneca head Pascal Soriot in 2014">
</span>
</span>
</span>
</p><figcaption>
<p>AstraZeneca head Pascal Soriot in 2014</p>
<span>
Foto: Facundo Arrizabalaga / epa-efe / Shutterstock
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>And at the Defense Ministry? The bureau is still trying to clean up the messes that its former boss left behind.</p><p>In each instance, von der Leyen's departure was perfectly timed. Just as the time had come for evaluations, she had already climbed up to the next rung on her career ladder.</p><p>Which is why she is now faced with a real problem. First of all, there isn't really anywhere left to go from her current post in Europe's top position. And second, the pandemic has hit the fast-forward button on political developments, with the consequences of political decisions taking mere weeks to manifest themselves instead of several years. "I am absolutely stunned by how negligent Ursula von der Leyen has been in overseeing the start of vaccinations in recent months," says Lars Klingbeil, general secretary of Germany's Social Democrats (SPD).</p><p>Indeed, von der Leyen finds herself in an extremely difficult situation. The next several weeks could decide her political future.</p><p>On Tuesday of this week, she delivered a video address to the World Economic Forum, where she spoke about Donald Trump, the storming of the Capitol and the question as to whether democracy has been damaged in the last four years. She spoke about climate change, biodiversity, artificial intelligence and digitalization.</p><p>In the first several minutes of her talk, she only briefly mentioned the coronavirus pandemic, and it was fully 15 minutes before she even said the word "vaccine." Only to say things like: "We know that in a pandemic there is no time to lose."</p><h3>Bazaar Bargaining</h3><p>Initially, of course, things looked quite good on the vaccine front. Back in summer, nobody was willing to predict that the first vaccine would be approved in the EU as early as December and that vaccinations would begin. Nor that a second vaccine would quickly follow in January. Von der Leyen was also able to claim a significant success when the EU agreed on a joint vaccination strategy in June, despite the fact that the bloc's 27 member states had always defended sovereignty when it came to health care policy. For the Commission president, it represented a gain of both prestige and power. Fleetingly, at least.</p><p>The problems began soon thereafter. Negotiations with vaccine producers bogged down, and it wasn't until November that the EU was able to reach a purchase agreement with BioNTech/Pfizer and with Moderna, the manufacturers of the two most successful vaccines thus far introduced. The EU negotiating team, according to people familiar with the talks, was intent on pushing down the price. There was also allegedly an extended disagreement on liability issues, particularly with Pfizer.</p><p>While others simply acted with expedience and placed huge orders, the EU – right in the middle of the worst pandemic in a century – decided to bargain like they were at the bazaar. Von der Leyen, of course, didn't lead these negotiations personally. But she is the boss, and carries the political responsibility.</p><p>After a year of the pandemic, hundreds of millions of Europeans are tired, frustrated and desperate for an appointment to finally get vaccinated. No other issue is as important at the moment – for the economy, for society and for politics. And the time will come to assign blame for the missteps that have been made. The search for where to place that blame won't start down below among the army of EU bureaucrats. It will start at the top.</p>
</div>
<section>

</section>
<div>
<p>Given that truth, von der Leyen's press department has been energetic in its defense of the Commissions actions. After all, the EU has secured rights to 2.3 billion doses of vaccine, they have pointed out, with 760 million of them from BioNTech/Pfizer and Moderna.</p><p>But what use is that when the availability of the vaccine will remain so limited for the foreseeable future? When the producers are unable to deliver what they have agreed to – or can only deliver much later?</p><p>And what, actually, is in those contracts, which have thus far remained confidential? Are the deliveries promised by the producers legally binding? Or did the Commission agree to flimsy fine print such that it has no leverage against the producers?</p><p>Thus far, only the contract with the German company Curevac has been made public. It says that the producer will make "reasonable best efforts" to deliver the agreed upon number of doses within the negotiated time frame. Pascal Soriot, the head of AstraZeneca, is now claiming the same thing. The Curevac contract also says that the producer must inform purchasers as quickly as possible of possible delays, explain the causes for those delays and present a revised timeline for delivery. That, though, is all.</p><p>Should the AstraZeneca contract contain the same language, it would be politically explosive. Tiemo Wölken, a member of European Parliament with Germany's Social Democrats, believes the contract is similar in that regard. "The wording of the delivery requirement for Curevac is supposedly similar," he says. "As such, what Soriot is saying doesn't sound implausible."</p><p>That would be a huge embarrassment for von der Leyen, but it would come as welcome news for a man who isn't yet out of the firing line himself: German Health Minister Jens Spahn. At home, Spahn has been the subject of scathing critique for the flubbed beginning of the vaccination campaign. Spahn, who just recently warned the country that "10 difficult weeks" were still to come, is now able to deflect some of the criticism to Brussels – onto the shoulders of fellow CDU member Ursula von der Leyen.</p><h3>Moving Too Slowly</h3><p>There is a history to their vaccine-related relationship. In mid-June, Spahn pushed ahead with his counterparts from France, the Netherlands and Italy, reaching an initial agreement with AstraZeneca. They planned to share the order with all EU member states. But that's not how things worked out.</p><p>Several countries intervened, the Chancellery in Berlin got involved and, in late June, Spahn and the others handed over responsibility for the negotiations to the European Commission. Thereafter, say people involved in the process, the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802">https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/europe/europe-s-vaccine-disaster-commission-president-ursula-von-der-leyen-seeking-to-duck-responsibility-a-1197547d-6219-4438-9d69-b76e64701802</link>
            <guid isPermaLink="false">hacker-news-small-sites-25964197</guid>
            <pubDate>Fri, 29 Jan 2021 23:25:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baking with machine learning (2020)]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25963556">thread link</a>) | @pizza
<br/>
January 29, 2021 | https://sararobinson.dev/2020/04/30/baking-machine-learning.html | <a href="https://web.archive.org/web/*/https://sararobinson.dev/2020/04/30/baking-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>Like many people, I’ve been entertaining myself at home by baking a ton and talking about my sourdough starter as if it were a real person. I’m pretty good at following recipes, but I decided I wanted to take things one step further and understand the science behind what differentiates a cake from a bread or a cookie. I also like machine learning so I thought: what if I could combine it with baking??!</p>

<p>I’ll start by explaining why baking presents an interesting ML problem. Then I’ll show you how I collected my own dataset, trained a simple model, deployed it, built a little app to get predictions, and used the model to invent a new recipe. If you’re only here for the recipe, I suppose you can <a href="#recipe">skip ahead</a>.</p>

<p>Are videos more your thing? Here’s me <a href="https://www.youtube.com/watch?v=-4saaQZSmBw">speaking about</a> how I built this.</p>

<h2 id="why-would-you-use-machine-learning-for-baking">Why would you use machine learning for baking?</h2>

<p>Maybe you’re thinking, couldn’t you just read a book or even a <a href="https://lifehacker.com/how-to-free-yourself-from-recipes-with-a-few-golden-coo-1450617561" target="_blank">blog post</a> that explains the sugar, fat, and flour ratios that make up different baked goods? Sure, I could do that. But my attention span has been pretty short these days, and that approach doesn’t really scale. If I learn enough to start inventing my own recipes, that only directly benefits the people who can eat them, which is currently not many.</p>

<p>Now maybe you’re thinking, couldn’t we solve this with traditional programming? For example, if the typical flour:liquid ratio for bread is 5:3, I could write a program like this:</p>

<figure><pre><code data-lang="python"><span>ratio</span> <span>=</span> <span>flour_amt</span> <span>/</span> <span>water_amt</span>

<span>if</span> <span>ratio</span> <span>&gt;</span> <span>1.5</span> <span>and</span> <span>ratio</span> <span>&lt;</span> <span>2</span><span>:</span>
    <span>print</span><span>(</span><span>"It's bread!"</span><span>)</span></code></pre></figure>

<p>That <em>kind of</em> works, but it’ll quickly get unwieldy. What if the flour:water ratio is close, but not exactly 5:3? What if I want to predict more than just bread? And what if I don’t feel like converting ingredient amounts into ratios? I am lazy (in certain ways) and I want to input my ingredient amounts without doing any math, and then have something magically tell me what it thinks it is.</p>

<p>Enter 🌟 machine learning 🌟</p>

<p>This is a great fit for ML because I can gather recipe data and train a model to identify patterns in that data. Since a lot of people have written about baking ratios, I’m going to assume there are some high-level patterns about them that I can teach a model to learn.</p>

<p>Hopefully by now I’ve convinced you that this will be a fun problem to solve with machine learning. But maybe you’re <em>still</em> skeptical, and you’re wondering: what’s the point of this? Don’t you already know what you’re baking when you follow a recipe? It seems silly to have a model tell you what you already know. All of that is true if I simply input an existing recipe into my model and ask it for a prediction. Remember, though, that the whole reason I’m doing this is to learn things like what makes a cake a cake, and not a cookie. Then I can experiment with different ratios to create a new recipe. Maybe I want to invent something that my model thinks is 50% cake, 50% cookie.</p>

<h2 id="creating-the-dataset">Creating the dataset</h2>

<p>I couldn’t find an existing dataset of basic baking ingredients, so I decided to create my own very small one. Luckily there is no shortage of recipes on the internet, and I found 33 recipes each of breads, cakes, and cookies to make a dataset with 99 total recipes. To keep this problem relatively simple, I looked only at the following ingredients:</p>

<ul>
  <li>Flour: If a recipe called for different types of flour, I counted it it all towards the flour amount</li>
  <li>Sugar: I also combined different sugars (granulated, brown, etc.) as one amount</li>
  <li>Sourdough starter: If you know, you know</li>
  <li>Salt</li>
  <li>Yeast</li>
  <li>Milk</li>
  <li>Water</li>
  <li>Oil</li>
  <li>Eggs</li>
  <li>Baking powder</li>
  <li>Baking soda</li>
  <li>Butter</li>
</ul>

<p>I tracked it all in a spreadsheet that looks like this:</p>

<p><img src="https://sararobinson.dev/assets/media/spreadsheet.png" alt="Baking spreadsheet dataset"></p>

<p>I know, I’m using cups and teaspoons and not something more universal like grams. If my little model becomes a smash hit, I will try to add metric system support.</p>

<p>While collecting the data, I did my best to include various types of breads, cakes, and cookies so that the model could handle a diverse repertoire of baked goods.</p>

<h2 id="processing-data">Processing data</h2>

<p>I went into this thinking I could feed my ingredient inputs directly into my machine model, since ML model inputs need to be numeric. Not quite. There are a few problems with the data in its current form.</p>

<p>First, my spreadsheet has a mix of units: I’m using cups for some ingredients, teaspoons for others, and eggs are just eggs. I don’t want my model to think that 1 unit of flour is the same as 1 unit of yeast (can you imagine what would happen there?). Since the majority of my data is in cups, I decided to convert everything else to cups. For teaspoons, this was fairly straightforward since 1 teaspoon is around .02 cups. For eggs, after some research I settled on 1 egg being approximately .2 cups. It’s not perfect, but now everything is in the same units.</p>

<p>Next I needed a way to scale the data. Some recipes make 2 giant cakes, while others make a small loaf of bread. Converting all ingredient amounts to the same scale will ensure my model doesn’t give more weight to bigger recipes. I decided to scale amounts by converting each ingredient to a percentage of the total recipe. To do this I took the sum of each row, and then divided each ingredient by the sum to get its percentage. The bread recipe in the screenshot above becomes:</p>

<p><img src="https://sararobinson.dev/assets/media/scaled_inputs.png" alt="Scaled recipe inputs"></p>

<p>With my 99 recipes all converted to the same unit and scaled to percentages, it’s time to build and train a model.</p>

<h2 id="building-a-tensorflow-model">Building a TensorFlow model</h2>

<p>I’m going to use TensorFlow’s <a href="https://www.tensorflow.org/api_docs/python/tf/keras" target="_blank">Keras API</a> for this model, which makes the model code pretty short:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>16</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>num_ingredients</span><span>,)),</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>16</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>3</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>                
<span>])</span></code></pre></figure>

<p>My model output is a softmax array, which means it’ll output the probability a particular recipe is a bread, cake, or cookie (in that order). Softmax means that all the probabilities will add to 1. So a 97% confident bread prediction would look like the following:</p>

<figure><pre><code data-lang="python"><span>[</span><span>.97</span><span>,</span> <span>.02</span><span>,</span> <span>.01</span><span>]</span></code></pre></figure>

<p>After training, my model has reached 90% accuracy. Pretty cool! But can I trust it, or is it overfitting the training data?</p>

<p>🚨This is definitely not an ML best practice, but I will be testing my model on real-world, production data. Mostly because I got tired of copying enough recipes into my spreadsheet to make a test set. Do not try this at home 🚨</p>

<p>To test the model, I made up the following recipe:</p>

<ul>
  <li>Flour: 1 c</li>
  <li>Sugar: 1 c</li>
  <li>Salt: ½ tsp</li>
  <li>Eggs: 1</li>
  <li>Butter: 1 c</li>
</ul>

<p>The model predicts cookies with 84% confidence. Sounds reasonable. What about an edge case, like a bread without yeast or sourdough starter? Let’s try:</p>

<ul>
  <li>Flour: 4 c</li>
  <li>Salt: ½ tsp</li>
  <li>Water: 1.2 c</li>
  <li>Oil: 3 tsp</li>
  <li>Baking powder: 2 tsp</li>
</ul>

<p>My model says bread with 99% confidence, nice! If I instead wrote a series of if statements to handle that edge case, you can see how it would quickly get very long.</p>

<h2 id="deploying-the-model-to-ai-platform">Deploying the model to AI Platform</h2>

<p>I don’t want to be the only one who gets to use this model, so it’s time to deploy it. I’m going to deploy it to Google Cloud <a href="https://cloud.google.com/ai-platform/prediction/docs" target="_blank">AI Platform Prediction</a>. In order to do that, I need to use the TensorFlow <code>model.save()</code> method to save my model assets to a Cloud Storage Bucket. Then I can use gcloud to deploy my model from the command line, pointing it at the bucket path of my saved model.</p>

<p>When you save your TensorFlow model, you can pass it a local filepath or a Cloud Storage bucket. Here I’ll pass it my GCS bucket directly:</p>

<figure><pre><code data-lang="python"><span>model</span><span>.</span><span>save</span><span>(</span><span>'gs://my_gcs_bucket/path'</span><span>)</span></code></pre></figure>

<p>With that, I’m ready to deploy using gcloud (you can also deploy via the UI or the API):</p>

<figure><pre><code data-lang="python"><span>!</span><span>gcloud</span> <span>ai</span><span>-</span><span>platform</span> <span>versions</span> <span>create</span> <span>'v1'</span> \
<span>--</span><span>model</span> <span>'baking'</span> \
<span>--</span><span>origin</span> <span>'gs://path/to/saved/model'</span> \
<span>--</span><span>runtime</span><span>-</span><span>version</span> <span>2.1</span> \
<span>--</span><span>framework</span> <span>TENSORFLOW</span> \
<span>--</span><span>python</span><span>-</span><span>version</span> <span>3.7</span></code></pre></figure>

<p>When your model has deployed, you’ll see it in your cloud console like this:</p>

<p><img src="https://sararobinson.dev/assets/media/caip-prediction.png" alt="Cloud AI Prediction UI"></p>

<h2 id="building-a-web-app">Building a web app</h2>

<p>🙏 <em>Shout out to my teammate <a href="https://twitter.com/_davideast" target="_blank">David</a> for his help on the web app</em> 🙏</p>

<p>It would be fun if I had a basic web app to get predictions on my model. That way I could quickly experiment with different ingredient ratios. Remember that my model needs the ingredient inputs all converted to cups and then scaled as percentages of the total recipe. It would be mean if I made people do those calculations on their own, so this should probably be handled server side – a great use for <a href="https://cloud.google.com/functions" target="_blank">Cloud Functions</a>:</p>

<p><img src="https://sararobinson.dev/assets/media/arch-diagram.png" alt="Architecture diagram"></p>

<p>I’ll use the Python runtime and write a function that takes the ingredient inputs in their user-friendly units and converts them to cups and then to percentages. From the same function I can send that scaled input to my model and return a nice, readable prediction to the web app. A snippet of the function is below, and you can find it all in <a href="https://gist.github.com/sararob/1fb9fb132a93bdda95f7a71d2afd38ad" target="_blank">this gist</a>.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>get_prediction</span><span>(</span><span>request</span><span>):</span>

    <span>data</span> <span>=</span> <span>request</span><span>.</span><span>get_json</span><span>()</span>
    <span>prescaled</span> <span>=</span> <span>dict</span><span>(</span><span>zip</span><span>(</span><span>columns</span><span>,</span> <span>data</span><span>))</span>
    <span>scaled</span> <span>=</span> <span>scale_data</span><span>(</span><span>prescaled</span><span>)</span>
    
    <span># Send scaled inputs to the model
</span>    <span>prediction</span> <span>=</span> <span>predict_json</span><span>(</span><span>'gcp-project-name'</span><span>,</span> <span>'baking'</span><span>,</span> <span>scaled</span><span>)</span>
    
    <span># Get the item with the highest confidence prediction
</span>    <span>predicted_ind</span> <span>=</span> <span>np</span><span>.</span><span>argmax</span><span>(</span><span>prediction</span><span>)</span>
    <span>label_map</span> <span>=</span> <span>[</span><span>'Bread'</span><span>,</span> <span>'Cake'</span><span>,</span> <span>'Cookies'</span><span>]</span>
    <span>baked_prediction</span> <span>=</span> <span>label_map</span><span>[</span><span>predicted_ind</span><span>]</span>
    <span>confidence</span> <span>=</span> <span>str</span><span>(</span><span>round</span><span>(</span><span>prediction</span><span>[</span><span>predicted_ind</span><span>]</span> <span>*</span> <span>100</span><span>))</span>

    <span>if</span> <span>baked_prediction</span> <span>==</span> <span>'Bread'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's bread! 🍞"</span> 
    <span>elif</span> <span>baked_prediction</span> <span>==</span> <span>'Cake'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's cake! 🧁"</span>
    <span>elif</span> <span>baked_prediction</span> <span>==</span> <span>'Cookies'</span><span>:</span>
        <span>emoji</span> <span>=</span> <span>"It's cookies! 🍪"</span>

    <span>return</span> <span>"{} {}</span><span>% </span><span>confidence"</span><span>.</span><span>format</span><span>(</span><span>emoji</span><span>,</span> <span>confidence</span><span>)</span></code></pre></figure>

<p>And here’s the app! I will preface this by saying that I’m lucky to work with amazingly talented people. I <a href="https://twitter.com/SRobTweets/status/1255213096718786568" target="_blank">tweeted</a> an early version of this web app and <a href="https://twitter.com/_davideast" target="_blank">David</a> volunteered to make it look, well, a lot better:</p>

<p><a href="https://whatareyoubaking.com/" target="_blank"><img src="https://sararobinson.dev/assets/media/bakeml.gif"></a></p>

<p>If you want to play around with it yourself, <strong><a href="https://whatareyoubaking.com/" target="_blank">it’s here</a></strong>. I’m sure you’ll try to do something weird with it (this is the internet after all), just keep in mind that the model has been trained on minimal data and it only knows about 3 things: bread, cake, and cookies. So if you enter the ingredients for a brownie or anything else, it’ll do its best to slot it into the only 3 categories it knows about. Think of it …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sararobinson.dev/2020/04/30/baking-machine-learning.html">https://sararobinson.dev/2020/04/30/baking-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://sararobinson.dev/2020/04/30/baking-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25963556</guid>
            <pubDate>Fri, 29 Jan 2021 22:26:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird compiler bug – Same code, different results]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25962756">thread link</a>) | @zaitanz
<br/>
January 29, 2021 | https://blog.zaita.com/mingw64-compiler-bug/ | <a href="https://web.archive.org/web/*/https://blog.zaita.com/mingw64-compiler-bug/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>There are approximately 7.5x10^18 grains of sand on Earth. This story is about finding changes in an equation that has a difference of approximately 1e-18 out of hundreds of billions of calculations. That is 7 grains of sand that are different to what we expect across the entire planet Earth.</p>
<p>After spending days generating gigabytes of debug logs and GDB breakpoints, I finally discovered a very peculiar bug in the compiler. I thought this would be an interesting story to tell.</p>
<p><strong>Update: Thanks to gus_massa and wiml @ HackerNews for pointing out I had used associative instead of commutative</strong></p>
<h2>Background</h2>
<p>Back in 2008 I started developing a scientific modelling platform called the <a href="https://niwa.co.nz/fisheries/tools-resources/spatial-population-modelling">Spatial Population Model (SPM)</a>. This software is designed to model or simulate and ocean environments to approximate the health of fish stocks. The output of SPM is used to create scientific reports that are given to Governments for the setting of commercial fishing quota. </p>
<p>Due to the political nature of these reports, reproducibility and integrity of results is crucial. Scientists from around the world will use the software to re-run models across different Operating Systems and compilers to validate results.</p>
<p>Since it was 2008, it was decided that SPM would not be multi-threaded. This is because of: no C++ standard threading, average computer had 2 cores, incompatibility with auto-differentiation libraries) </p>
<p>Fast forward to 2020/21 where many-core systems are commonplace. I had recently acquired for myself an AMD 5950X 16c/32t CPU and was keen to apply it to some modelling work. SPM is still in use as a world leading spatial modelling platform and has received continual updates. I’ve had a long interest in bringing concurrency to SPM to invent new methods of scientific modelling that evolve the underlying mathematics. As a proof of concept, I wanted to start working through threading the internal gradient calculation. Models in SPM are user defined and can be enormous (&gt;100k lines of input text) so we’re unable to analytically determine the gradient function through auto-differentiation. We use an iterative approach tweaking model parameters to calculate the gradient. These tweaks are independent and therefore can be parallelised. </p>
<p>This seemed like a relatively straight forward piece of work. I would need to:</p>
<ol>
<li>Move all of the classes to be children of a new Model class</li>
<li>Remove all singletons</li>
<li>Keep the floating-point operations in the exact same order when calculate on the main thread (IEEE-754)</li>
<li>Support an arbitrary number of threads</li>
<li>Produce identical results regardless of the number of threads, Operating System or compiler</li>
</ol>
<h2>IEEE-754 or the floating-point nightmare</h2>
<p>The development of scientific modelling platforms like SPM requires a significant amount of thought and effort around reproducibility. Given the same input files, any user must be able to re-run your model and get the exact same answer out. This seems incredibly obvious, but it’s not…</p>
<p><a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE-754</a> is the standard for floating-point arithmetic. Floating point math in computers is an approximation. Whenever you see a floating point value it is highly unlikely to be completely accurate. Floating-point arithmetic is commutative, but not associative. So for floating-point numbers,
A + B = B + A always, but
A + (B + C) != (A + B) + C in many cases.
The order in which operations occur within your model will influence the output. While this is inconsequential for small programs or games; this continual adding of errors for scientific models where the number of operations is in the hundreds of billions is consequential. </p>
<p>Every thread we spawn must run the same operations in the exact same order. When the threads give their results back to the main thread, they must do so in a way that ensures that all future operations happen in the exact same order. This is regardless of the number of threads or number of parameters in the model.</p>
<p><em>Side Note: Within scientific models, we use double precision numbers (double) and not single precision (float). Single precision does not have enough precision to handle the number of calculations required. At the end of a model the error added by the approximation of floating-point math is very significant. This limits us to using CPUs over GPUs as the double precision performance of GPUs is not that much better than a modern CPU when you have to factor in the added complexity of writing GPU specific code.</em></p>
<h2>The first signs of trouble</h2>
<p>With my task list ready, I started to work through re-factoring the code. Everything was modified to use a central model class as the parent for the system. This allows me to spawn as many model classes as threads. Everything was compiling and running without crashes. Time to check the output..</p>
<div data-language="text"><pre><code>1999.818926297566804 // original score running no threads
1999.8189264475995515 // my new score running 32 threads</code></pre></div>
<p>A slight difference, nothing to be concerned about as I had probably changed the order of execution for some of the equations by threading them. I was testing with a small model that ran in &lt;5 seconds, so working through each of the instantiated classes to check the code won’t take too long. Another day down and nothing obvious was found. Time to run the application through GDB and the <a href="https://en.wikipedia.org/wiki/AddressSanitizer">Sanitizers</a> looking for issues… nope nothing there either.</p>
<p>A simple model will have recruitment/breeding, ageing and death. I started to reduce and simplify the processes in the model to see if I could identify any key process or parameter. I removed the random number generate and commented out a large amount of complex math… but still no luck.</p>
<h2>Down the rabbit hole of debug logging and GDB</h2>
<p>After three days of trying to find the issue, I had added a LARGE amount of debug logging and had resorted to doing step throughs in GDB looking for a point at which I would notice a change in the result. The log files were 20MBs+ and the model would only show issues after a few iterations… why not immediately?</p>
<p>Was I calling a function later in the model that had the issue? Or was the issue starting earlier but at a greater precision that I was printing. I was printing my debug output with a <a href="https://en.cppreference.com/w/cpp/io/manip/setprecision">precision</a> of 15. Time to increase the precision to 20. This is basically the maximum amount of precision you can print from a double with accuracy. I did a few more model runs and saw that the variation in results had moved to much earlier in the model… almost immediately.</p>
<p>The model would load the configuration file, then construct all of the user defined objects in memory. As part of constructing these objects a bunch of calculations would be run to build caches. To save on moving data between threads each thread would repeat the same process. Every new thread would get the configuration file that had been loaded, create all of the objects and run the initial calculations. GDB showed that even these initial calculates were having different results.</p>
<p>My working folder was littered with files named “fuck”, “fuck1” and “fuckN” each with more than 20MBs of debug output for a small model run. Diff was run across files to see where changes were occurring and how small they were… But still no luck.. everything was going wrong almost immediately but I had no idea why.</p>
<h2>Surely it’s not a compiler bug?</h2>
<p>SPM uses the GCC and MinGW64 compilers. This allows us to have near-identical code for Windows and Linux with common makefiles. I have always preferred <a href="https://jmeubank.github.io/tdm-gcc/">TDM-GCC</a> as this has a current release. In this instance, TDM-GCC 9.2.0 from March 2020. Running the sanitizers was done on OpenSuSe Tumbleweed Linux using GCC 10.2.1. These are both very modern versions of the GCC compiler suite. I have never been one to blame tools for a bug in my code.</p>
<p>At this point, I am way down the rabbit hole trying to find the cause of this bug. Some testing had shown me that:</p>
<ul>
<li>The original binary would produce the same result on every run</li>
<li>My new binary would produce the same result on every run, but different to the original</li>
<li>My new binary would produce the same result regardless of the number of threads.. from 1 to 100</li>
</ul>
<p>That last observation made me curious. Why did my new code produce a different result when I ran it with only one thread? What would make it different from the original binary. Having only 1 thread that was executing would eliminate any race conditions.</p>
<p>In the original binary, we do not create any threads. We load the model, build and run it. In the new code, even with one thread we create that thread, load the model, build and run it. What was I doing during the thread creation process that would cause this issue? Time for GBs of log files and GDB.</p>
<p>Stepping through every operation to validate the output lead me into what we call a selectivity. This is a static piece of code that takes an input, calls a standard simple piece of math and returns an output. These few lines of code had returned different results in a thread and not. Time to analyse the following code:</p>
<div data-language="c++"><pre><code>double CLogisticSelectivity::calculateResult(int Age) {
    double dRet = 0.0;
    double dTemp = (dA50-Age)/dAto95;

    if(dTemp &gt; 5.0)
      dRet = 0.0;
    else if (dTemp &lt; -5.0)
      dRet = dAlpha;
    else
      dRet  = dAlpha/(1.0+pow(19.0,dTemp));

    return dRet;
}</code></pre></div>
<p>If I gave the code Age = 1 then ran it I got the following results:</p>
<div data-language="text"><pre><code>Local  = 0.0010370292068795884059
Thread = 0.0010370292068795879722</code></pre></div>
<p>What gives? There is nothing in here that should be different in a thread. I am not passing in anything but an int with the value of 1. I edited the code to make dA50 and dAto95 local variables to remove any potential race conditions or thread wonkiness and still had the same error in output. Everything was initialized within the same function and the only external value was an Integer. Weird…</p>
<h2>Compiler bug? But how…</h2>
<p>Looking at the code, the only things that could create the bug were the operators and pow() call. These are part of the C++ standard offering so it’s highly unlikely that either of these would have an error. What next? Off to <a href="https://blog.zaita.com/mingw64-compiler-bug/%5Bhttps://godbolt.org/">GodBolt</a> …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.zaita.com/mingw64-compiler-bug/">https://blog.zaita.com/mingw64-compiler-bug/</a></em></p>]]>
            </description>
            <link>https://blog.zaita.com/mingw64-compiler-bug/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25962756</guid>
            <pubDate>Fri, 29 Jan 2021 21:24:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StrictMark: Markdown, Refactored]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25958444">thread link</a>) | @gritzko
<br/>
January 29, 2021 | http://doc.replicated.cc/%5EWiki/strictmark.sm | <a href="https://web.archive.org/web/*/http://doc.replicated.cc/%5EWiki/strictmark.sm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><a href="https://daringfireball.net/projects/markdown/">Markdown</a> is a wonderful lightweight markup: minimalistic,
easy to read and write. Markdown is supported by GitHub,
Bitbucket, Reddit, Diaspora, Stack Exchange, and many others.
It is not without issues though.  Markdown is precedent-based,
so to say.  It aimed to codify preexisting practices which
were... diverse.  For that reason, it is messy and inconsistent
between implementations.  </p>
<p>StrictMark is a rational <em>subset</em> of Markdown that implements
all the features with the shortest <em>formal</em> grammar possible.
Hence, uniform syntax and no ambiguities.  The idea is that
StrictMark can reuse all the existing Markdown support,
without sharing the weight of the legacy syntax and its
incidental complexity.</p>
<p>StrictMark is Markdown, refactored.</p>
<h2>Markdown critique</h2>
<p>Markdown implementations are inconsistent. Vim highlights it one
way, VS Code does it differently, and the resulting HTML is yet
another thing. A textbook fix for inconsistent implementations
is having a <em>formal grammar</em>.  That might be either a proper
<a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">eBNF</a> grammar or just some regexes in simpler cases.  There
must be something formal and unambiguous.  HTML has it, CSS has
it, every markup or programming language has it.  But Markdown.
Sadly, the syntax itself is so ambiguous that making a formal
grammar becomes a road of pain. For example, HTML (which is
hardly lightweight) has a uniform syntax for its <code>&lt;/elements&gt;</code>.
With Markdown, every element has its own syntax and those
syntaxes interact.  Markdown formal grammar was attempted in the
past, but if you ask me, the result was underwhelming. The <a href="https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form">PEG
based grammar</a> is 700 lines long. For a <em>minimalistic</em>
markup, that is <strong>a lot</strong>. So ironic.</p>
<p><a href="http://commonmark.org/">CommonMark</a> is a Markdown codification effort that produced
the most complete spec so far.  Still, that spec is
rule-and-exception based, no grammar.  The text of the spec is
full of "legalese":</p>
<blockquote><p>Â«An indented code block cannot interrupt a paragraph, so
there must be a blank line between a paragraph and a
following indented code blockÂ»</p></blockquote>
<p>Here it describes the specifics of interrelations between two
particular markup elements. But <code>N</code> elements produce <code>N*N</code>
relations!  Consider that ATX headings are always single-line
while Setext headings can be multiline. Why? Because the spec
says so. It is one big heap of rules and another one of
exceptions. That's why it advises a "parsing strategy" and
not a parser generator.</p>
<p>Whether the CommonMak spec has fixed all the corner cases and
ambiguities is unclear.  Or maybe clear, as the spec is actively
revised. So is the code.  The CommonMark C parser is 10KLoC of
hand-written code.  It has plenty of exceptions and tweaks.
While writing <a href="http://doc.replicated.cc/%5EWiki/ron.sm">RON</a> docs, I ran into issues immediately;
had to use the HEAD version which has those issues fixed.</p>
<p>Overall, that seemingly theoretical grammar problem causes
plenty of <em>accidental complexity</em>.  Markdown is messy and hard
to reason about;  it is not always clear how to interpret a
given construct.  That combinatorial mess may not be a problem
for its current uses, of course.  (Although, I highly doubt
that.) After all, the existing libcmark parser is fuzzed,
thus reasonably reliable.  Still, Markdown is a very shaky
base if you want to build on top of it.  To build something
more advanced than a README.  Like, full WYSIWYG editing or
diff highlighting or other complex behavior.</p>
<h2>StrictMark principles</h2>
<p>StrictMark's objective is to make a Markdown <em>subset</em> which is a
<em>proper markup language</em>. To  remove that incidental complexity
by rationalizing the grammar and making it formal.  This
document <a href="http://doc.replicated.cc/%5EWiki/strictmark.sm?@text">is StrictMark</a>.</p>
<p>One may ask, why do I want to make Markdown a proper language?
After all, there is HTML which is proper enough. Yes, HTML is a
widely supported standard, but it is hopelessly elephantine.
Let's think, who can afford to develop/support a proper HTML
engine?  That is roughly one-and-a-half companies in the world.
Hence the interest in a minimalistic hypertext markup language.</p>
<p>The next question is obvious.  If StrictMark is ever used at
some scale, would not it become elephantine, naturally?
Consider Wikipedia/Mediawiki markup.  Once neat and lean like
all such markups, it evolved into an elephantine <a href="https://en.wikipedia.org/w/index.php?title=Sneakers&amp;action=edit">mess</a>.
What about table support, for example?  Some people think it is
necessary, quite deservedly so.</p>
<p>I plan to prevent feature sprawl by enabling <a href="https://en.wikipedia.org/wiki/Transclusion">transclusion</a>.
A document may reference other documents and objects through
hyperlinks.  It can also <em>include</em> other objects and documents,
through hyperlinks.  The good old <code>&lt;img&gt;</code> tag is an example of
transclusion.  That will not even extend the syntax: StrictMark
reuses the image syntax for the general case of transclusion.
Once you need a table, you transclude a table!  It is up to the
renderer to deal with all those other data types.  CSV is a much
better format for tables than HTML or Markdown.</p>
<p>StrictMark is a backwards compatible subset of CommonMark, for
the most part.  Any existing CommonMark tooling will support
StrictMark reasonably well.  A StrictMark parser may not
understand arbitrary Markdown.</p>
<p>StrictMark principles:</p>
<ol><li><p>A formal grammar.  StrictMark is a <em>regular language</em> in its
structural part (i.e. blocks).  The inline markup syntax is
based on regex-defined <em>markers</em>.  That way, a decent parser
can be implemented in regexes only.</p></li>
<li><p>There is one way to do a thing, as uniform as possible.
Hence: spaces, not tabs!  Because spaces can replace tabs,
not the other way around. ATX headings only. Formatting
brackets are <code>*one char*</code> wide only. All block formatting is
indented uniformly.</p></li>
<li><p>Minimize ambiguity. Same character should not denote lists
and emphasis, etc.</p></li>
<li><p>No spooky action-at-a-distance.  Each line can be parsed
separately.  All the structural markup is 4-char-wide, hence
indents are uniform. This restriction makes the nesting
structure clear and unambiguous.</p></li>
<li><p>Inline markup has very limited nesting; it is of secondary
importance anyway.  There is clear markup precedence; a
<code>code</code> span wins over <code>strong</code>, <code>strong</code> wins over <code>emph</code>.</p></li>
<li><p>HTML is not the only output format.  It could be PDF, DOC,
TeX, whatever.  Hence, no HTML inserts. Use transclusion
for other formats.</p></li>
<li><p>If the StrictMark interpretation contradicts CommonMark or
CommonMark has an ambiguity then screw CommonMark.</p></li></ol>
<p>Interestingly enough, <a href="https://johnmacfarlane.net/beyond-markdown.html">similar ideas</a> were proposed in the
CommonMark community some years ago.</p>
<h2>Inline markup</h2>
<p>Markdown inline markup may seem like an easy part. Sadly, it is
not.  Due to very irregular and ambiguous syntax, implementing
it properly is difficult.  For that reason, StrictMark
rationalizes the inline markup in the following ways:</p>
<ol><li><p>All inline markup is seen as bracketing.  Brackets are
matched separately, using regular expressions; e.g.
<code>(?&lt;=\s)[*](?=\S)</code> is the opening bracket for STRONG.
Bracket pairs only become effective if they satisfy the
precedence rules.</p></li>
<li><p>Bracket precedence, lower to higher:</p>
<ol><li><p><code>_emphasized_</code>,</p></li>
<li><p><code>[link][1]</code>,</p></li>
<li><p><code>*strong*</code>,</p></li>
<li><p><code>\* escapes</code>, </p></li>
<li><p>`<code>code</code>`.</p></li></ol></li>
<li><p>An open bracket can be paired with any following closing
bracket of that kind.  A new open bracket will cancel any
preceding unmatched open bracket of its kind.</p></li>
<li><p>In case of overlap, higher-precedence brackets win; in case
of equal-precedence, the earlier range wins.</p></li>
<li><p>Higher-precedence brackets may nest in lower-precedence, but
not the other way around (the lower one is cancelled).  In
case of equal-precedence, the earlier range wins.</p></li>
<li><p>No double symbols, i.e. <code>*strong*</code> not <code>**strong**</code>.</p></li></ol>
<p>Compared to CommonMark, restrictions are many:</p>
<ul><li><p>no double-symbol syntax,</p></li>
<li><p>no arbitrary nesting,</p></li>
<li><p>only reference links, the label is 1 symbol long,</p></li>
<li><p>no way to put backticks inside a code span.</p></li></ul>
<p>That may seem restrictive, but again: inline formatting has a
supplementary role.  It must pull its own weight or it must not
be there.  The accurate bracket patterns are listed in the
grammar appendix.</p>
<h2>Links, images and transclusions</h2>
<p>The only form of links CommonMark supports is full reference
links.  The link label must be exactly one symbol long. This
approach:</p>
<ul><li><p>matches a common established practice of using numbered
references;</p></li>
<li><p>minimizes the visual noise in the text flow;</p></li>
<li><p>keeps reference definitions exactly 4 symbols long.</p></li></ul>
<p>Reference definitions can be placed anywhere.  It is nice to put
them at the end of a section or in the end of the document.
Example:</p>
<pre><code>    see [Replicated Object Notation][1]

    [1]: http://doc.replicated.cc/ron.sm "What is RON"
</code></pre>
<p>If you have more than 10 links, use letters. 
In case you have thousands of links, use Unicode symbols.</p>
<p>Transclusions and images use the same syntax as links, 
with an exclamation mark <code>!</code> prepended.
Example:</p>
<pre><code>    ![here is the table][T]
    [T]: /table?@tab "this might be any object"
</code></pre>
<h2>Block markup</h2>
<p>StrictMark has tree types of blocks:</p>
<ol><li><p>container blocks (lists, blockquotes, divs),</p></li>
<li><p>leaf blocks (paragraphs, headers, rulers, fenced code blocks).</p></li></ol>
<p>Container and entry blocks can contain other blocks, leaf blocks
can not.  Depending on the type of a leaf block, it can contain
text, metadata or nothing at all, </p>
<p>The block-related markup goes in the beginning of the
line, in blocks of four symbols.  That part of a line  is called
a <em>block stack</em>.  The allowed nesting pattern is
<code>(INDENT|QUOTE)* LIST? LEAF?</code>.  In absence of an explicit leaf
block, a formatted text paragraph is implied.</p>
<p>A block can be continued in the following lines; that is
signaled by indents (four spaces) in place of the block markup.
An empty line is considered to be a continuation line for the
container blocks in the stack, but not for the leaf block.</p>
<p>Example:</p>
<pre><code> #  Multiline
    header

 1. here the entry starts,
    and then it continues

    and continues...
 2. ...till the next entry.
</code></pre>
<p>Changes in blockstack depth cause container nesting changes.
Additional indent of less than 4 spaces is not meaningful.
That allows for easier line-by-line parsing and interpretation.
If an indent level starts with a bare indent, that creates a
generic container block (in other words, a <code>div</code>).  With
CommonMark, that should be a code block.  StrictMark generalizes
that slightly.</p>
<p>In case a block marker ends with a non-space symbol, the next
symbol must be …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://doc.replicated.cc/%5EWiki/strictmark.sm">http://doc.replicated.cc/%5EWiki/strictmark.sm</a></em></p>]]>
            </description>
            <link>http://doc.replicated.cc/%5EWiki/strictmark.sm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25958444</guid>
            <pubDate>Fri, 29 Jan 2021 15:46:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Johnson and Johnson single-shot vaccine appears 66% effective in global trial]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 252 (<a href="https://news.ycombinator.com/item?id=25957820">thread link</a>) | @heyheyheysome
<br/>
January 29, 2021 | https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Johnson &amp; Johnson's long-awaited vaccine appears to protect against COVID-19 with just one shot. It's not as strong as some of its two-shot rivals but still potentially helpful for a world in dire need of more doses.</p><div><p><span><span><div><div title="How the other vaccines in line for Canada's approval compare" role="button" tabindex="0"><div><div aria-labelledby="1850380867702-metadata-" title="How the other vaccines in line for Canada's approval compare"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/309/727/COVID-OTHER-VACCINESS-BIRAK-290121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Canada has other vaccines in line for approval -- how they compare to the ones already being rolled out and how COVID-19 variants are a complicating factor.<!-- --> <!-- -->2:03</span></span></span></p><p><span><p>Johnson &amp; Johnson's long-awaited vaccine appears to protect against COVID-19 with just one shot — it's not as strong as some of its two-shot rivals but still potentially helpful for a world in dire need of more doses.</p>  <p>J&amp;J said Friday that in the U.S. and seven other countries where their trial has been conducted, the single-shot vaccine was 66 per cent effective overall at preventing moderate to severe illness, and much more protective — 85 per cent — against the most serious symptoms.</p>  <p>There was some geographic variation. The vaccine worked better in the U.S. — 72 per cent effective against moderate to severe COVID-19 — compared to 57 per cent in South Africa, where it was up against an easier-to-spread mutated virus.</p>  <p>Dr. Matthew Oughton, an infectious disease&nbsp;specialist at Jewish General Hospital in Montreal, told CBC News the trial data "certainly looks promising for a single dose, which of course will certainly ease a lot of the logistics we've been dealing with so far with the current vaccines that have been granted approval."</p>  <p>He said by examining mixed populations across continents, the J&amp;J trial is not only "looking at differences in how different groups of people respond, that also means that they capture different viral variants, so they have a good sense of the real-world efficacy of this vaccine."</p>  <p>With vaccinations off to a rocky start globally, experts have&nbsp;been counting on a one-dose vaccine that would stretch scarce supplies and avoid the logistics nightmare of getting people to return for boosters.</p>    <h2>Greater protection&nbsp;vs. more shots</h2>  <p>But with some competing vaccines shown to be 95 per cent effective after two doses, the question is whether somewhat less protection is an acceptable tradeoff for getting more shots in arms quickly.</p>  <p>Matthew Miller, an associate professor at the Institute for Infectious Disease Research at McMaster University, told CBC News by email that the decision will depend on multiple factors, including "the procurement timelines for specific vaccines in each country" and how prevalent the newly circulating variants become.</p>  <p>"Some high-risk populations may need vaccines that confer higher degrees of protection, while less efficacious vaccines might be appropriate for lower-risk populations," he said.</p>  <p>The Canadian government signed an agreement with Johnson &amp; Johnson for up to 38 million doses of their vaccine, though as of earlier this month, officials said a vaccine schedule had not been finalized.</p>  <p><em><strong>WATCH \ Dr. Matthew Oughton, infectious diseases specialist, encouraged by data so far:</strong></em></p>  <p><span><span><div><div title="Johnson &amp; Johnson vaccine 'very promising,' says infectious disease specialist" role="button" tabindex="0"><div><div aria-labelledby="1850072131736-metadata-" title="Johnson &amp; Johnson vaccine 'very promising,' says infectious disease specialist"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/15/283/JNJ.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Calling the clinical trial 'thorough,' infectious disease specialist Dr. Matthew Oughton says Johnson &amp; Johnson's single-shot COVID-19 vaccine is also easier to handle logistically compared to approved vaccines in Canada.<!-- --> <!-- -->3:40</span></span></span></p>  <p>J&amp;J said that within a week, it will file an application for emergency use in the U.S., and then abroad. It expects to supply 100 million doses to the U.S. by June, and expects to have some ready to ship as soon as authorities give the green light.</p>  <p>The U.S. Food and Drug Administration has set a 50 per cent threshold for any COVID-19 vaccine to be considered for emergency use authorization.</p>  <h2>No deaths reported in the vaccine group</h2>  <p>The J&amp;J data comes from&nbsp;preliminary findings from a study of 44,000 volunteers that isn't completed yet. Researchers tracked illnesses starting 28 days after vaccination — about the time when people getting a two-dose vaccine would have needed another shot.</p>  <p>After day 28, no one who got vaccinated needed hospitalization or died, regardless of whether they were exposed to "regular COVID or these particularly nasty variants," Dr. Mathai Mammen, global research chief for J&amp;J's Janssen Pharmaceutical unit, told The Associated Press.&nbsp;When the vaccinated did become infected, they had a milder illness.</p>  <p>Dr. Anthony Fauci, director of the U.S. National Institute of Allergy and Infectious Diseases, also was particularly encouraged by the findings with respect to patients with the most serious symptoms.</p>  <p>"This really tells us that we have now a value-added vaccine candidate," said Fauci at a Friday briefing of U.S. health officials in President Joe Biden's administration.</p>    <p>Defeating the scourge that has killed more than two million people worldwide will require vaccinating billions, and the shots currently being rolled out in different countries&nbsp;require two doses a few weeks apart for full protection. Early data is mixed on exactly how well all the different kinds work, but shots made by Pfizer and Moderna appear to be about 95 per cent protective after the second dose.</p>  <p>But amid shortages, some countries have advised delaying the second dose of certain vaccines with little data on how that would affect protection.</p>  <h2>Company also testing 2-shot vaccine</h2>  <p>All COVID-19 vaccines train the body to recognize the new coronavirus, usually by spotting the spike&nbsp;protein that coats it. But they're made in very different ways.</p>  <p><em><strong>WATCH \ Canadian labs working hard to track new variatns:</strong></em></p>  <p><span><span><div><div title="Growing concern about COVID-19 variants in Canada" role="button" tabindex="0"><div><div aria-labelledby="1848895043807-metadata-" title="Growing concern about COVID-19 variants in Canada"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/940/735/boudjikanian-variant-concerns.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>COVID-19 numbers are falling, but Canadian health officials are becoming increasingly concerned about the presence of two coronavirus variants. A variant first found in the U.K. has been confirmed in three provinces while a variant first discovered in South Africa variant has been found in two provinces.<!-- --> <!-- -->4:15</span></span></span></p>  <p>J&amp;J's shot uses a cold virus like a Trojan horse to carry the spike gene into the body, where cells make harmless copies of the protein to prime the immune system in case the real virus comes along.</p>  <p>Rival AstraZeneca makes a similar cold virus vaccine that requires two doses. Both the AstraZeneca and J&amp;J vaccines can be stored in a refrigerator, making them easier to ship and&nbsp;use in developing countries than the frozen kind made by Pfizer and Moderna.</p>  <p>J&amp;J said its vaccine works consistently in a broad range of people: A third of participants were over age 60, and more than 40 per cent had other illnesses putting them at risk of severe COVID-19, including obesity, diabetes and HIV.</p>  <h2>Vaccine producers need to be 'nimble': Fauci</h2>  <p>J&amp;J said the vaccine is safe, with reactions similar to other COVID-19 shots, such as fever, that occur when the immune system is revved up.</p>  <p>"Gambling on one dose was certainly worthwhile," said&nbsp;Mammen, but J&amp;J has&nbsp;hedged its bets with a study of a two-dose version of its vaccine, which is still underway.</p>  <p>While it released few details, the company said there were no serious allergic reactions. But occasionally other COVID-19 vaccines trigger such reactions, which can be reversed if promptly treated — and authorities have warned people to be on the lookout regardless of which type of vaccine is used.</p>  <p>A handful of coronavirus variants have gained attention in recent weeks, a development that Fauci and the new director of the Centers for Disease Control described as one to be expected.</p>  <p>"I think we should be treating every case right now as if it's a variant," said the CDC's Dr. Rochelle Walensky.</p>  <p>"We will continue to see the evolution of mutants," said&nbsp;Fauci. "We will have to be nimble to adjust to make versions of the vaccine that are actually specifically directed to whatever mutations are prevalent at the time."</p>  <p>Friday's interim results come on the heels of another vaccine in final testing. Novavax reported this week that its vaccine appears 89 per cent effective in a U.K. study, and that it also seems to work — though not as well — against new mutated versions of the virus circulating in Britain and South Africa. A larger study in the U.S. and Mexico is still enrolling volunteers.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/johnson-johnson-covid-vaccine-trial-1.5893009</link>
            <guid isPermaLink="false">hacker-news-small-sites-25957820</guid>
            <pubDate>Fri, 29 Jan 2021 14:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pony – High-Performance Safe Actor Programming]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25957307">thread link</a>) | @ibraheemdev
<br/>
January 29, 2021 | https://www.ponylang.io/discover/ | <a href="https://web.archive.org/web/*/https://www.ponylang.io/discover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
      

      

<h2 id="what-is-pony">What is Pony?</h2>

<p>Pony is an open-source, object-oriented, <a href="https://en.wikipedia.org/wiki/Actor_model">actor-model</a>, <a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities-secure</a>, high-performance programming language.</p>

<p>If you are looking to jump in and get started with Pony <em>right now</em>, you can try it in your browser using the <a href="http://playground.ponylang.io/">Pony Playground</a>. Keep reading if you are interested in what makes Pony different and why you should consider using it.</p>

<p>If you are interested in the early history of Pony and how it came into existence, you’re in luck: <a href="https://www.ponylang.io/blog/2017/05/an-early-history-of-pony/">“An Early History of Pony”</a>.</p>

<h2 id="what-makes-pony-different">What makes Pony different?</h2>

<h3 id="pony-is-type-safe">Pony is type safe</h3>

<p><em>Really type safe</em>. There’s a mathematical <a href="https://www.ponylang.io/media/papers/fast-cheap-with-proof.pdf">proof</a> and everything.</p>

<h3 id="pony-is-memory-safe">Pony is memory safe</h3>

<p>There are no dangling pointers and no buffer overruns. The language doesn’t even have the concept of null!</p>

<h3 id="exception-safe">Exception-Safe</h3>

<p>There are no runtime exceptions. All exceptions have defined semantics, and they are <em>always</em> caught.</p>

<h3 id="data-race-free">Data-race Free</h3>

<p>Pony doesn’t have locks nor atomic operations or anything like that. Instead, the type system ensures at compile time that your concurrent program can never have data races. So you can write highly concurrent code and never get it wrong.</p>

<h3 id="deadlock-free">Deadlock-Free</h3>

<p>This one is easy because Pony has no locks at all! So they definitely don’t deadlock, because they don’t exist!</p>

<h3 id="native-code">Native Code</h3>

<p>Pony is an ahead-of-time (AOT) compiled language. There is no interpreter nor virtual machine.</p>

<h3 id="compatible-with-c">Compatible with C</h3>

<p>Pony programs can natively call C libraries. Our compiler is able to generate a C-header file for Pony libraries. Consequently, C/C++ programs can natively call Pony programs!</p>

<h2 id="why-pony">Why Pony?</h2>

<p>There’s plenty to love about Pony, but more than anything else, what we love most is that Pony makes it easy to write fast, safe, efficient, highly concurrent programs. How? The Pony type system introduces a novel concept: “reference capabilities”. <a href="https://tutorial.ponylang.io/capabilities/reference-capabilities.html">Reference capabilities</a> allow you to label different bits of data based on how that data can be shared. The Pony compiler will then verify that you are in fact correctly using the data based on the labels you provide. Reference capabilities combined with Pony’s actor model of concurrency makes for a powerful pairing. Let’s dig in and take a quick look:</p>

<h3 id="mutable-state-is-hard">Mutable state is hard</h3>

<p>The problem with concurrency is shared mutable data. If two different threads have access to the same piece of data then they might try to update it at the same time. At best this can lead to those two threads having different versions of the data. At worst the updates can interact badly resulting in the data being overwritten with garbage. The standard way to avoid these problems is to use locks to prevent data updates from happening at the same time. This causes big performance hits and is very difficult to get right, so it causes lots of bugs.</p>

<h3 id="immutable-data-can-be-safely-shared">Immutable data can be safely shared</h3>

<p>Any data that is immutable (i.e. it cannot be changed) is safe to use concurrently. Since it is immutable it is never updated and it’s the updates that cause concurrency problems.</p>

<h3 id="isolated-data-is-safe">Isolated data is safe</h3>

<p>If a block of data has only one reference to it then we call it <em>isolated</em>. Since there is only one reference to it, isolated data cannot be <em>shared</em> by multiple threads, so there are no concurrency problems. Isolated data can be passed between multiple threads. As long as only one of them has a reference to it at a time then the data is still safe from concurrency problems.</p>

<h3 id="every-actor-is-single-threaded">Every actor is single threaded</h3>

<p>The code within a single actor is never run concurrently. This means that, within a single actor, data updates cannot cause problems. It’s only when we want to share data between actors that we have problems.</p>

<h3 id="reference-capabilities-enforce-safe-data-handling">Reference capabilities enforce safe data handling</h3>

<p>By sharing only immutable data and exchanging only isolated data we can have safe concurrent programs without locks. The problem is that it’s very difficult to do that correctly. If you accidentally hang on to a reference to some isolated data you’ve handed over or change something you’ve shared as immutable then everything goes wrong. What you need is for the compiler to force you to live up to your promises. Pony reference capabilities allow the compiler to do just that.</p>

<p>If you ask us, that’s pretty damn cool and a hell of a reason to give Pony a try.</p>

<h2 id="why-not-pony">Why not Pony?</h2>

<p>There are many valid reasons to not use Pony. Amongst these are:</p>

<ul>
<li>Lack of API stability</li>
<li>Lack of high-quality 3rd party libraries</li>
<li>Limited native tooling</li>
</ul>

<h3 id="api-stability">API stability</h3>

<p>Pony is pre-1.0. We regularly have releases that involve breaking changes. This lack of stability is plenty of reason for many projects to avoid using Pony.</p>

<h3 id="batteries-required">Batteries required</h3>

<p>If your project is going to succeed or fail based on the size of community around the tools you are using, Pony is not a good choice for you. While it’s possible to write stable, high-performance applications using Pony, you will have to do a decent amount of work. The pool of open source, ready to use Pony libraries is very small. If it’s not in the standard library then odds are you are going to have to add it yourself, either by writing it from scratch in Pony or by wrapping an existing C library using Pony’s excellent <a href="https://tutorial.ponylang.io/c-ffi/">C-FFI</a> functionality.</p>

<h3 id="tooling">Tooling</h3>

<p>There’s a wide swath of tooling that some people have come to expect that isn’t currently available for Pony. We don’t have an IDE. You can use standard debuggers like GDB or LLDB but the experience still has some rough edges. If you are comfortable working with a basic text editor and using LLDB, VTune and other tools, you’ll probably be ok. Just don’t expect a full, robust ecosystem. We aren’t there yet.</p>

<p>If your project isn’t going to get a great deal of benefit from any of Pony’s strengths, then you shouldn’t use Pony. If you are writing a single threaded application without any overriding performance concerns, and you need access to a large community and wealth of libraries then you’re much better off selecting another language. However, we hope that you see enough potential in Pony to start playing around with it even if it isn’t right for your current project.</p>

<h2 id="the-pony-philosophy">The Pony Philosophy</h2>

<p>In the spirit of <a href="http://www.jwz.org/doc/worse-is-better.html">Richard Gabriel</a>, the Pony philosophy is neither “the-right-thing” nor “worse-is-better”. It is “get-stuff-done”.</p>

<h3 id="correctness">Correctness</h3>

<p>Incorrectness is simply not allowed. <em>It’s pointless to try to get stuff done if you can’t guarantee the result is correct.</em></p>

<h3 id="performance">Performance</h3>

<p>Runtime speed is more important than everything except correctness. If performance must be sacrificed for correctness, try to come up with a new way to do things. <em>The faster the program can get stuff done, the better. This is more important than anything except a correct result.</em></p>

<h3 id="simplicity">Simplicity</h3>

<p>Simplicity can be sacrificed for performance. It is more important for the interface to be simple than the implementation. <em>The faster the programmer can get stuff done, the better. It’s ok to make things a bit harder on the programmer to improve performance, but it’s more important to make things easier on the programmer than it is to make things easier on the language/runtime.</em></p>

<h3 id="consistency">Consistency</h3>

<p>Consistency can be sacrificed for simplicity or performance.
<em>Don’t let excessive consistency get in the way of getting stuff done.</em></p>

<h3 id="completeness">Completeness</h3>

<p>It’s nice to cover as many things as possible, but completeness can be sacrificed for anything else. <em>It’s better to get some stuff done now than wait until everything can get done later.</em></p>

<p>The “get-stuff-done” approach has the same attitude towards correctness and simplicity as “the-right-thing”, but the same attitude towards consistency and completeness as “worse-is-better”. It also adds performance as a new principle, treating it as the second most important thing (after correctness).</p>

<h2 id="guiding-principles">Guiding Principles</h2>

<p>Throughout the design and development of the language, the following principles should be adhered to.</p>

<ul>
<li><p>Use the get-stuff-done approach.</p></li>

<li><p>Simple grammar. Language must be trivial to parse for both humans and computers.</p></li>

<li><p>No loadable code. Everything is known to the compiler.</p></li>

<li><p>Fully type safe. There is no “trust me, I know what I’m doing” coercion.</p></li>

<li><p>Fully memory safe. There is no “this random number is really a pointer, honest.”</p></li>

<li><p>No crashes. A program that compiles should never crash (although it may hang or do something unintended).</p></li>

<li><p>Sensible error messages. Where possible use simple error messages for specific error cases. It is fine to assume the programmer knows the definitions of words in our lexicon, but avoid compiler or other computer science jargon.</p></li>

<li><p>Inherent build system. No separate applications required to configure or build.</p></li>

<li><p>Aim to reduce common programming bugs through the use of restrictive syntax.</p></li>

<li><p>Provide a single, clean and clear way to do things rather than catering to every programmer’s preferred prejudices.</p></li>

<li><p>Make upgrades clean. Do not try to merge new features with the ones they are replacing, if something is broken remove it and replace it in one go. Where possible provide rewrite utilities to upgrade source between language versions.</p></li>

<li><p>Reasonable build time. Keeping down build time is important, but less important than runtime performance and correctness.</p></li>

<li><p>Allowing the programmer to omit some things from the code (default arguments, type inference, etc) is fine, but fully specifying should always be allowed.</p></li>

<li><p>No ambiguity. The programmer should never have to guess what the compiler will do, or vice-versa.</p></li>

<li><p>Document required complexity. Not all language features have to be trivial to understand, but complex features must have full explanations in the docs to be allowed in the language.</p></li>

<li><p>Language features should be minimally intrusive when not used.</p></li>

<li><p>Fully defined semantics. The semantics of all language features must be available in the standard language docs. It is not acceptable to leave behavior undefined or “implementation dependent”.</p></li>

<li><p>Efficient hardware access must be available, but this does not have to pervade the whole language.</p></li>

<li><p>The standard library should be implemented in Pony.</p></li>

<li><p>Interoperability. Must be interoperable with other languages, but this may require a shim layer if non-primitive types are …</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ponylang.io/discover/">https://www.ponylang.io/discover/</a></em></p>]]>
            </description>
            <link>https://www.ponylang.io/discover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25957307</guid>
            <pubDate>Fri, 29 Jan 2021 14:03:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking about software engineering]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25956644">thread link</a>) | @funkisjazz
<br/>
January 29, 2021 | https://nintil.com/programming | <a href="https://web.archive.org/web/*/https://nintil.com/programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="mobile-panel">
<article>

<div>
<p>Though I'm right now not employed as a software engineer I have been writing code under various hats for the last few years (As a data scientist, ML engineer, and software engineer). Naturally me being me I have not just done the thing but also reflected about the thing. Questions like what's good software, what does being a good software engineer mean, how should meetings be ran, and so on. Here are some thoughts on that.</p>

<h2 id="the-cost-of-disagreement">The cost of disagreement</h2>
<p>In many cases a disagreement may be over something that both sides agree is not sizable. I can think something is 80% good whereas you think it's just 75% and I can think the opposite of your solution. But we can agree that the cost to resolve that disagreement can defeat the gains from actually choosing the best solution. So "I disagree but let's go ahead" is something that should be done in these cases, with a coin flip if needed. Consensus-driven decision making may be good at some stages, especially if paired with good processes around meetings but it can lead to gridlock.</p>
<p>I'm of course not the first one in proposing the "<a href="https://en.wikipedia.org/wiki/Disagree_and_commit">disagree and commit</a>" principle though I only learned this had a name very recently.</p>
<h2 id="meetings">Meetings</h2>
<p>Meetings can be terrible, meetings can be great. Bad meetings tend to occur because people show up without having thought much about what is to be discussed in the meeting. Isn't the point of the meeting to do the thinking? That's one way, perhaps the most common way of viewing meetings, and it's a lazy default because they don't impose homework on you. But doing the thinking in real time, with many voices to be sequentially heard and given a constrained time is not great for good decision making. Many times I've seen meetings that dragged on forever where disagreements would keep circling back and forth, or where we would simply be talking past each other.</p>
<p>A better way to run meetings, which I also tried, is to collate whatever is it that the outcome should be before the meeting. If it's an architecture design meeting, do the work, usually the meeting owner can do most of it, even if they know it won't be 100% perfect. Then ask for feedback a week ahead of the meeting. Incorporate the feedback to the document, repeat. Note down disagreements; have a literal "Standing disagreements" section in the document with the key points that are not quite agreed on, plus the reasoning behind them. Having everyone review the disagreements and having time to do so, on (digital) paper sets up a clearer goal for the meeting: Iron out specific points. During the meeting, a moderator would go one by one over those points and ask for a decision, then highlighting in bold which option was chosen. Then we would move to the next point and so on. Everyone liked this kind of meeting.</p>
<h2 id="ownership">Ownership</h2>
<p>Lack of ownership is the root of all evil (ok, some exaggeration here). Everyone's problem is no one's problem. In documentation, lack of ownership means finding obsolete documentation and no one person to go to to get it fixed; or what's worse, no system in place to enforce that the documentation is up to date (i.e. every document could disappear 6 months after it's published unless whoever uploaded or created it says otherwise in an email the system sends them after six months, documents shouldn't live rent free). Or having a team dedicated to tirelessly aggregating information so that everything everyone is doing is visible. We had something like this in my first job at the London Electric Vehicle Company (LEVC) and I suspect this may be more common in automotive or aerospace than in software or in biotech.</p>
<p>Apple had a very clever idea in defining <a href="https://twitter.com/michael_nielsen/status/1279478277585817600">Directly Responsible Individuals</a> (DRIs) for everything. Having a name accountable instead of a vague "the team" or "the process" makes it easy to make changes. I think many people are reluctant to blame individuals for mistakes they make, but well timed blame (feedback about what mistakes were made, potentially there being consequences for grave mistakes etc) can both help the blamed individual (They can know what to improve) and the team as a whole to succeed.</p>
<p>Something I once thought is that many decisions that involve estimates could be made into bets, either for small amounts of money or some kind of token. If you say X will be finished in a week and it takes longer, then you lose. This could be gamed by overestimating how long things take, but something like this seems like the right way to get better at making decisions involving uncertainty.</p>
<h2 id="questions-as-systemic-failures">Questions as systemic failures</h2>
<p>Every question asked in an internal Slack is a policy failure. It means the existing information systems failed to deliver an answer, and the user falls back to manually asking the hive mind's tacit knowledge. This has various problems: One, it introduces longer delays between question and answer, especially if whoever knows the answer is in another timezone. Two, it embraces tacit knowledge in a distributed and incoherent fashion: If there is no one true answer there can be many answers and that can lead to disagreements and wrong decisions. Instead, ideally there is a centralized repository of information where for each Q there is one and only one A, and a team dedicated to getting owners of various systems to actually codify their knowledge. This should work well with the ownership system above.</p>

<h2 id="good-software">Good software</h2>
<p>Good software is code that is readable, fast, flexible, and scalable. Out of these only speed is the one that is universally agreed on how to measure. The rest are fuzzy, as are most things in life.</p>
<p>Readable code pretty much depends on who is writing it; <a href="https://github.com/jayfoad/aoc2019apl/blob/master/p12.dyalog">Dyalog</a> looks like <a href="https://en.wikipedia.org/wiki/Brainfuck">Brainfuck</a> to me, and the many parenthesis in Lisps can make code hard to read to someone who is not a lisper (I did the experiment; I spent some time learning basic Clojure and while I remain not a Clojurian, the parenthesis become less of an issue). Lifetimes in Rust seem obscure until one know how they work.</p>
<p>Flexible code is code that is easier to extend. This is hard to quantify but anyone that has coded knows it when they see it; a given piece of code can just effortlessly do something new with a two line change, or it may need a thousand line change to work again. The former is more flexible than the latter. Moreover this flexibility shouldn't come at the expense of readability though sometimes this can be the case.</p>
<p>Scalable code is code that works well with small as well as big inputs, this can be achieved in a single machine or many.</p>
<p>The extent to which these matter depend on who is developing it (Readable code depends on individual preferences), and flexibility is not really needed if the end result is more or less fixed; but it's really desired in a startup that is constantly adapting. In that environment, speed may be sacrificed for extra flexibility.</p>
<p>The code that should be written absent any constraints is good code, but real life situations means that the right thing to do is to make tradeoffs and move ahead. Those decisions are at the heart of what experience in software engineering is.</p>
<h2 id="static-types">Static types</h2>
<p>Static typing is great. Early on in a codebase in Python back at Aiden.ai, we made the decision of going for static typing using myopia as much as we could. So instead of writing something like</p>
<pre><code><span>def </span><span>sum_one</span><span>(</span><span>x</span><span>):
  </span><span>return </span><span>x+</span><span>1
</span></code></pre>
<p>We would rather much write</p>
<pre><code><span>def </span><span>sum_one</span><span>(</span><span>x</span><span>:int)-&gt;int:
  </span><span>return </span><span>x+</span><span>1
</span></code></pre>
<p>Or even further, in some cases we would use <em>newtypes</em> to make these type annotations more meaningful, dataclasses to bundle data together, as well as exhaustive enumerations to ensure that all variants of an enum get handled, for example:</p>
<pre><code><span>class </span><span>Operation</span><span>(</span><span>Enum</span><span>):
  </span><span>Multiply="</span><span>Multiply</span><span>"
  Add="</span><span>Add</span><span>"
Value = Union[int,float]
</span><span>def </span><span>assert_never</span><span>(</span><span>x</span><span>: NoReturn) -&gt; NoReturn:
    </span><span>raise </span><span>AssertionError</span><span>(</span><span>f</span><span>"</span><span>Invalid value: </span><span>{x</span><span>!r</span><span>}")
</span><span>def </span><span>do_the_op</span><span>(</span><span>a</span><span>:Value,</span><span>b</span><span>: Value, </span><span>op</span><span>:Operation) -&gt; Value:
  </span><span>if </span><span>op is Operation.Multiply:
    </span><span>return </span><span>a*b
  </span><span>else if </span><span>op is Operation.Add:
    </span><span>return </span><span>a+b
  </span><span>else</span><span>:
    </span><span>assert_never</span><span>(op)   
  
</span></code></pre>
<p>So if we ever say remove an operation or add a new one, mypy will force us to handle it. This is enforced dynamically but most importantly also statically so the code won't pass tests if there is a missing variant.</p>
<p>All these typing (Plus a custom pandas typechecker I wrote, but that's another story) made it relatively easy to refactor, and add new features when we needed to do so. It would have been a huge pain to fly blind without the types. Python has a tendency to blow up in your face when you least expect it. Starting with types from day 1 is something I don't regret having gone for, it didn't make the coding any slower and saved a lot of time (Or so we imagine!).</p>
<p>There seems to be a trend now towards types everywhere. Javascript died (for any serious developer) to let Typescript rise and Ruby, while still around with the Sorbet type checker, got Crystal.</p>
<p>As a <a href="https://en.wikiquote.org/wiki/Theodore_Kaczynski#:%7E:text=Consistent%20failure%20to%20attain%20goals,low%20self%2Desteem%20or%20depression.&amp;text=text%20on%20wikisource-,The%20Industrial%20Revolution%20and%20its%20consequences%20have,disaster%20for%20the%20human%20race.&amp;text=The%20industrial%2Dtechnological%20system%20may%20survive%20or%20it%20may%20break%20down.">wise man</a> once said, <em>Python and its consequences have been a disaster for the human race</em>. Python has a tendency to blow up in your face, even with all the typing. The typechecker may be happy but it doesn't guarantee that if it thinks something is type T it's actually so, maybe what you thought was a number is actually a string and because of duck typing it can take a few function calls for the error to manifest itself.</p>
<h2 id="yolo-programming-vs-chill-programming">YOLO programming vs chill programming</h2>
<p>I believe there is a tradeoff between writing a lot of code and writing correct code. In a day you could write X lines of code or you could write X/2. Two days of programmer B will produce the same as one day of programmer A but probably the latter will have introduced fewer bugs. You can write more or less tests, you can be more or less sure that something you just wrote is actually correct.</p>
<p>As you can expect from the number of typos here, I'm more of a YOLO programmer than a chill programmer. I'm the guy that was once pushing to prod from a one-handed GitHub hot fix from my phone as I was having dinner in a hotel in Tokyo (That one did work!).</p>
<p>YOLO programming when the programming language …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/programming">https://nintil.com/programming</a></em></p>]]>
            </description>
            <link>https://nintil.com/programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956644</guid>
            <pubDate>Fri, 29 Jan 2021 12:42:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt browser: mouseless copy/paste]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25956152">thread link</a>) | @jmercouris
<br/>
January 29, 2021 | https://nyxt.atlas.engineer/article/visual-mode.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/visual-mode.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Tested with Nyxt 2 Pre-release 6.</p><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="By John Mercouris">
  <title>visual-mode: mouse-free copy</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>


</header>
<p>Nyxt has a new visual-mode (mouseless text selection)!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-select.png"></p>

<p>Visual mode is a mouseless way of selecting <span>any</span> text on any page (with as few keystrokes as possible). Conceptually based on <code>vi</code>'s visual mode, Nyxt adapts it for the web.</p>

<p>The first step is to run the <code>visual-mode</code> command.</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-enable.png"></p>
<p>After doing so, you will be presented with hints to select a starting paragraph for your cursor.</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-paragraph.png"></p>
<p>Upon selecting a paragraph, a cursor will appear. You can move the cursor around and press <code>shift-space</code> to toggle the mark (start/stop highlighting).</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-cursor.png"></p>
<p>Importantly, you can use all your favorite keybindings (move by word, move to next line, beginning of line, etc.)!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/visual-mode-select.png"></p>
<p>Eureka! Just like that, we have selected text, no mouse required!</p>

<p>A very special thank you to <span data-cites="kssytsrk">@kssytsrk</span> for this wonderful addition to Nyxt!</p>
<p>Thanks for reading :-)</p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/visual-mode.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956152</guid>
            <pubDate>Fri, 29 Jan 2021 11:14:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turbo Pascal: A Great Choice for Programming Under CP/M (2013)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25956128">thread link</a>) | @elvis70
<br/>
January 29, 2021 | https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>CP/M was blessed with many programming languages, each with their own strengths and weaknesses.  I think that Turbo Pascal stands out from these and I'm not alone.  When Turbo Pascal was released in 1983 by Borland, as their first software development application, it was quickly adopted by schools, universities, hobbyists and professional software developers.  Turbo Pascal combined ease of use, power, speed and a great manual all for the really low price of $49.95.</p>
<h2>Why Use Turbo Pascal Under CP/M?</h2>
<p>With TP you get an Integrated Development Environment (IDE), so that you can edit, compile and run all from the same application.  Since the IDE is only 34Kb there is plenty of space left on a disk for your source code and compiled programs.  This is particularly handy for single disk machines.  The editor is very functional and uses a subset of the Wordstar key combinations.</p>
<p>Pascal was designed to be easy to compile and because TP uses a single pass compiler, compilation speed is incredibly quick.  The downside of the compilation speed is that the code is quite a literal translation without much optimization.  However, for many applications this won't be much of an issue compared to the increased programmer productivity.</p>
<p>If you need parts of your program to run faster, you can always embed inline machine code into functions/procedures or access functions in external binaries.  The latter option allows you to create libraries in assembly language and use a jump table to access individual functions with the <code>external</code> keyword.</p>
<p>In 1986 Borland released Turbo Pascal 3.0 which added support for <em>overlays</em>.  The running code could now be swapped in and out from disk as needed.  With careful planning, you could escape the normal 64Kb limit and only be constrained by the capacity of the disk you are running the application from.</p>
<p>The standard library offers a good range of functions and TP keeps quite close to Standard Pascal as defined by Jensen &amp; Wirth in their '<a href="http://books.google.co.uk/books?id=xXSZbSLFTM8C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false">User Manual and Report</a>'.  As with all Pascal implementations, there are problems porting programs between implementations.  However, if you aren't using any of the operating system specific calls, then you can easily port to the MS-DOS and CP/M-86 versions.  My only gripe is that TP doesn't support procedures and functions passed as parameters.</p>
<p>Finally, Borland included a highly readable and very complete <a href="http://bitsavers.trailing-edge.com/pdf/borland/turbo_pascal/Turbo_Pascal_Version_3.0_Reference_Manual_1986.pdf">manual</a>.  It covered not just the IDE, language and libraries, but also detailed information on the memory layout and calling conventions from assembly language.  This meant that you could quickly get up and running with few additional resources.</p>
<h2>How to install</h2>
<p>First download <a href="http://www.retroarchive.org/cpm/lang/TP_301A.ZIP">Turbo Pascal 3.01a</a> for CP/M-80 and unzip the archive.</p>
<p>Put at least <code>TINST.*</code> and <code>TURBO.*</code> files onto a disk.  The real advantage of not copying all the files is seen if you only have a single drive.  The extra room will allow you to edit, compile and run your programs all from the same disk.  For instructions on how to create a virtual disk for z80pack look at: <a href="https://techtinkering.com/articles/emulating-a-cpm-system-with-z80pack/">Emulating a CP/M System With z80pack</a>.</p>
<p>Boot up your CP/M system, put in the disk with TP on it and change to this drive if necessary.  In my examples I am using <code>B:</code></p>
<p>Run the <code>TINST</code> program to set up the screen:</p>
<pre><code>B&gt; tinst
</code></pre>
<p>Press <code>S</code> for <em>Screen Installation</em> and select the appropriate terminal for your set up.  I'm using z80pack, so I select ANSI.  You probably don't want to alter this definition so say No to altering it.  Then enter the speed in Mhz of your machine.  If a suitable terminal isn't listed consult the TP manual for advice.</p>
<p>If you want to configure additional editor commands, you can do this via the <em>Command Installation</em> option.  At the very least, if you have them, you'll probably want to configure the page-up, page-down keys as well as the cursor keys to represent character-left, character-right, line-up and line-down.  If not press <code>Q</code> to quit.</p>
<h2>Usage</h2>
<p>To start the IDE run:</p>
<pre><code>B&gt; turbo
</code></pre>
<p>You should now be looking at the Turbo Pascal splash screen, showing the version, copyright message and which terminal is configured.  At the bottom you are asked whether to 'Include error messages'.  For the moment press <code>Y</code>.</p>
<p>Now you will be presented with the main screen.  You have a number of commands on this screen, which are accessed by a single letter.</p>
<p><img src="https://techtinkering.com/img/articles/turbo_pascal_cpm_main.png"></p><p>To work with a pascal source file, first press <code>W</code> and then enter a filename.  This is the file that the editor will open and it is also the file that the compiler will compile if you haven't selected a main file.</p>
<p>To edit the work file, press <code>E</code>.  The editor uses Wordstar key combinations which you can read more about in the manual.  For now the following keys will be useful to know:</p>
<table>
  <tbody><tr><th>Key command</th><th>Action</th></tr>
  <tr><td>CTRL-s</td><td>Character Left</td></tr>
  <tr><td>CTRL-d</td><td>Character Right</td></tr>
  <tr><td>CTRL-e</td><td>Character Up</td></tr>
  <tr><td>CTRL-x</td><td>Character Down</td></tr>
  <tr><td>CTRL-k s</td><td>Save Document</td></tr>
  <tr><td>CTRL-k d</td><td>Quit</td></tr>
</tbody></table>
<p>You can also use any keys that you configured above with the <em>Command Installation</em> option in <code>tinst</code>.</p>
<p>Files are edited in memory so to save them to disk you press <code>S</code> from the main menu.</p>
<p>To compile and run the work file, or main file if selected, press <code>R</code>.  Depending on what is set in the compiler options, this will either compile to a <code>com</code> file or will compile to memory.</p>
<h3>Hello, world!</h3>
<p>To try this with the traditional 'Hello, world!' program, set the work file to <code>hello.pas</code>, edit the file and enter the following, then quit the editor.</p>
<pre><code>program helloworld;
begin
  writeln('Hello, world!');
end.
</code></pre>
<p>Compile and run it by pressing <code>R</code> from the main menu.  You should see it compile and then say hello to the world.</p>
<h2>Video</h2>
<p>The following video shows the creation of a FizzBuzz program using Turbo Pascal and allows us to see just how quick and easy it is.</p>
<p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/acYu0sL9Ol0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<p>The source code for <code>fizzbuzz.pas</code> used in the video is as follows:</p>
<pre><code>program fizzbuzz(output);
var
  i: integer;
begin
  for i := 1 to 100 do
  begin
    if i mod 15 = 0 then
      write('FizzBuzz ')
    else if i mod 3 = 0 then
      write('Fizz ')
    else if i mod 5 = 0 then
      write('Buzz ')
    else
      write(i, ' ');
  end
end.
</code></pre>

<p>Get the <a href="http://bitsavers.trailing-edge.com/pdf/borland/turbo_pascal/Turbo_Pascal_Version_3.0_Reference_Manual_1986.pdf">Turbo Pascal 3.0 Manual</a> for CP/M-80, CP/M-86 and PC-DOS/MS-DOS from <a href="http://bitsavers.org/">bitsavers.org</a>.  It is a wonderfully well-laid out manual and you should have no problems using this to learn and get the most out of Turbo Pascal.  You may also want to take a look at a copy of the old Borland musuem page: <a href="http://edn.embarcadero.com/article/20792">Antique Software: Turbo Pascal v3.02</a>.</p>
<p>You are now ready to use Turbo Pascal to write and compile applications like it was 1986.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/2013/03/05/turbo-pascal-a-great-choice-for-programming-under-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25956128</guid>
            <pubDate>Fri, 29 Jan 2021 11:06:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantquake: 2020 and the Revenge Against the Nerds]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25953890">thread link</a>) | @apsec112
<br/>
January 28, 2021 | https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/ | <a href="https://web.archive.org/web/*/https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" alt="fbpx" src="https://www.facebook.com/tr?id=818746408901300&amp;ev=PageView&amp;noscript=1">

<!-- End Facebook Pixel Code -->
<meta name="generator" content="Powered by Slider Revolution 5.4.8.3 - responsive, Mobile-Friendly Slider Plugin for WordPress with comfortable drag and drop interface.">

		
				
		

		
	<!-- Global site tag (gtag.js) - Google Analytics -->



<!-- Hotjar Tracking Code for https://rhsfinancial.com/ -->





	<!--<div class="modal fade calendly_wrap" id="myModal">
		<div class="modal-dialog modal-lg modal-dialog-centered" role="document">
            <div class="modal-content">
                <div class="modal-body">
                    <div class="calendly-inline-widget" style="min-width: 320px; height: 500px;" data-url="https://calendly.com/rhs15minutes/consultation"></div>
					<script type="text/javascript" src="https://assets.calendly.com/assets/external/widget.js"></script>
                </div>
            </div>
		</div>
	</div>-->
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				
				
			</header>
						
			
		
				
			
			

									<main id="main">
				<div>
			
<section id="content">
			
	
					<article id="post-4844">
						
														
						
																									<div>
				
<p><span>2020, the most fascinating and boring year of my life, is over, and despite one of the most violent market crashes in history and the sharpest recession of all time, US equity investors clocked in another good year on the calendar. The S&amp;P 500 index finished the year up 18.4%; this despite being down by as much as 30% in March, making 2020 one of the wildest swinging markets in history.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/ccd34ab62ba3cdcc49abe8547f2cff73.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>But if you didn’t earn double digit returns last year you were in good company. The bull market was extremely concentrated in a narrow subset of stocks and most others floundered over the year. By my count, of the top 5,000 stocks trading on US exchanges (this includes over a thousand foreign stocks with US listings), only a little over half finished 2020 in positive territory and the median return was only 4.3%. If you didn’t have the good fortune to buy the few winners you were left behind, as happened with some of the industry’s best. Many of the world’s largest and previously most successful hedge funds and institutional money managers had a terrible 2020, including the top two: Ray Dalio’s Bridgewater Associates and Jim Simon’s Renaissance Technologies, each famous for their billionaire visionary founders, uniquely<span> <a href="https://www.bloomberg.com/news/articles/2019-11-12/the-unsolved-mystery-of-the-medallion-fund-s-success">secretive</a>/<a href="https://www.youtube.com/watch?v=HXbsVbFAczg">creepy</a></span> company culture, and astounding market-beating performance over decades, each suffered <em>negative double-digit</em> returns in their main funds in 2020. Similarly, some of the industry’s most highly regarded names such as <span><a href="https://www.institutionalinvestor.com/article/b1p9nxxx1d47xk/AQR-to-Liquidate-Some-Funds-After-Persistent-Outflows">AQR</a></span>, <a href="https://www.bloomberg.com/news/articles/2020-11-17/renaissance-two-sigma-see-losses-as-quant-giants-navigate-chaos"><span>Two Sigma</span></a>, and <span><a href="https://www.morningstar.com/articles/1012650/dfa-is-paying-the-price-for-its-conviction">Dimensional Fund Advisors</a></span> all suffered massive investor redemptions in the face of substantial underperformance in 2020.</span></p>
<p><span>All these fund managers pursue a variety of different strategies in a variety of different markets, but they all have one thing in common: they’re quants. They take a data-driven approach to investing, using mathematical models based typically on decades of market returns to execute their strategy, often employing teams of Ph.D mathematicians, computer scientists, and economists to crunch the numbers. They generally pay little attention to the “human interest” elements of investing like the executive bio or squishy concepts like “product market fit” or five year strategic plans. There are a lot of different ways to be a quant, but if you are one, or invested with one in 2020, you probably had a bad year. 2020 was the year of the swashbuckling stock-picker. As Bloomberg declared in a year-end article, <span><a href="https://www.bloomberg.com/news/articles/2020-12-30/human-run-hedge-funds-trounce-quants-in-year-defined-by-pandemic">Human-Run Hedge Funds Trounce Quants in Covid Year</a></span>. 2020 was the revenge&nbsp;<em>against</em> the nerds.</span></p>
<p><span>So what happened? Leo Tolstoy famously wrote, “All happy families are alike; each unhappy family is unhappy in its own way.” So it was with investing in 2020, there were many different investing strategies that went unhappily in 2020, and all the strategies that went happily looked pretty much the same. Let’s look at the unhappy families first and then return to the one thing that went well in 2020.</span></p>
<h3>Diversification</h3>
<p>2020 saw a repeat of something we’ve witnessed a few times in the last decade, not only did US stocks have an especially good year, they did substantially better than pretty much every other market. Investors who diversified across multiple asset classes therefore had much weaker returns.</p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020.png"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1024x619.png" alt="" width="1024" height="619" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-200x121.png 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-300x181.png 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-400x242.png 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-600x363.png 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-768x464.png 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-800x484.png 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1024x619.png 1024w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020-1200x726.png 1200w, https://rhsfinancial.com/wp-content/uploads/2021/01/Asset-Class-Returns-2020.png 1470w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p>
<p><span>Just about the only major asset that beat the S&amp;P 500 last year was gold. The shiny metal held its weight during the crisis in March and powered through the rest of the year. Emerging market stocks also put in a solid year, virtually tied with the US market, despite suffering an even harder crash in March. Most other major assets, however, had much more modest returns, including the stock markets of most other rich, industrialized nations. Investors diversified across these major markets still likely had reasonably positive returns, but were a far cry from the meteoric rise of the S&amp;P 500.</span></p>
<p><span>Of course, how investors allocated both across and within these asset classes was of tantamount importance to their outcomes in 2020, and generally these outcomes frustrated quants at every turn. Whether picking stocks within a market or allocating across asset classes, quants often rely on measures of valuation, volatility, or momentum to guide their process, based on the historical success of these metrics in predicting returns, and in nearly every case following the numbers led investors astray in 2020, starting with perhaps the most time-tested of financial strategies, value investing.</span></p>
<h3><span>Value and Fundamentals</span></h3>
<p><span>For investors like yours truly who believe markets ultimately have to have some <span><a href="https://rhsfinancial.com/2020/08/11/does-reality-matter-stock-market-2020/">relation to reality</a></span>, the following joke tweet from December is a little too on the nose.</span></p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg" alt="" width="960" height="395" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-200x82.jpg 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-300x123.jpg 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-400x165.jpg 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-600x247.jpg 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-768x316.jpg 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word-800x329.jpg 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/F-Word.jpg 960w" sizes="(max-width: 960px) 100vw, 960px"></a></p>
<p><span>Value investors ask the same seemingly reasonable question of investments we all ask when we’re considering buying a good or service: is the price I have to pay a good deal compared to the quality I’m getting? In practice this generally means value investors seek to buy assets whose prices are low relative to their cashflows or other economic fundamentals. Value investing has an intellectual pedigree going back to at least the 1920s with the classic writings of Graham and Dodd and is perhaps most famous for their most successful student, Warren Buffett (who also didn’t do so well last year). Value investing has been out of favor for several years now, especially in the US market, something I documented extensively in my <span><a href="https://rhsfinancial.com/2020/08/11/does-reality-matter-stock-market-2020/">two part</a> <a href="https://rhsfinancial.com/2020/08/19/does-reality-matter-part2/">series</a></span> last year on market valuations.</span></p>
<p><span>Last year was a miserable one for value investors. Within the US market, value stocks lagged the market in the first couple months, fell further during the crash, and recovered slower than the rest of the market. Though they rallied harder in the last two months of the year, value stock both large and small finished the year finished the year just barely above zero, as judged by the commonly followed Russell 1000 Value (large stocks) and Russell 2000 Value (small stocks) indexes.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,id:^RLVTR,include:true,,id:^RUJTR,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/273b52a1901248cfb2556266430d94d6.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>Applying the value effect around the world gave even worse results. Choosing between stock markets, the US started the year the most expensive market in the world, and those in Europe were among the cheapest. But as we saw, the US market became more expensive still, and European stock investors barely ended the year in positive territory. Value stocks within foreign markets similarly failed to keep up with their broader market aggregates. One index of value stocks around the world, the MSCI ACWI Value Index, finished the year up a mere 0.42%. Taking an even more expansive view of valuation and applying it across global assets, buying those stocks, bonds, commodities, and currencies measured as cheap and selling those measured as expensive would have lost you about 12% in 2020 (through November) according to <span><a href="https://www.aqr.com/Insights/Datasets/Value-and-Momentum-Everywhere-Factors-Monthly">AQR’s methodology</a></span>.</span></p>
<p><span>Skeptics of value investing often point out that value stocks are usually cheap for a reason: they’re junk. Indeed, if you simply sort the market based on a simple valuation metric like price to book ratio you’ll often find that the most undervalued stocks are in declining industries, have weak balance sheets and margins, and are projected to lose market share. Value investors often try to avoid “value traps” like this by augmenting their value factors with metrics to score some measure of “quality”, looking at profitability measures like return on equity, for example. Adding such quality filters would have only made things worse in 2020. Among the cheapest stocks in the market, the most profitable among them did the worst last year.</span></p>
<p><span>Professor Ken French keeps an invaluable <span><a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">online database</a></span> to quants that records the track records to different portfolios of stocks sorted on a variety of metrics. Looking at a double-sorted portfolio of the stocks that are in the lowest quintile of valuation and the highest quintile of profitability, here’s how such a portfolio did last year (through November) compared to the S&amp;P 500.</span></p>
<p><a href="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value.png"><img loading="lazy" src="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1024x546.png" alt="" width="1024" height="546" srcset="https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-200x107.png 200w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-300x160.png 300w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-400x213.png 400w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-600x320.png 600w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-768x409.png 768w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-800x426.png 800w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1024x546.png 1024w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value-1200x639.png 1200w, https://rhsfinancial.com/wp-content/uploads/2021/01/US-vs-High-Profit-Low-Value.png 1490w" sizes="(max-width: 1024px) 100vw, 1024px"></a><span>The most profitable, cheapest stocks in the US lost more than half of their value in the crash last year, before recovering to end up down “only” about 20% last year, a staggering 33.8% behind the S&amp;P 500.</span></p>
<p><span>Take a moment to consider how counterintuitive this ought to seem. I think most people, even without much financial savvy, would consider the strategy of “buy highly profitable companies at attractive valuations” to seem like a fairly reasonable one, the sort of things that might actually deliver superior results over the long run, and indeed if we look at the long run data it has, as we’ll see further down the page. You might even suspect that such a prudent strategy might shine especially during a period of great economic tumult and uncertainty, and indeed it often has historically. But that is absolutely&nbsp;<em>not</em> what happened during the chaos of 2020. And that wasn’t the only curveball 2020 threw quants either.</span></p>
<h3><span>Low Volatility/Risk Parity</span></h3>
<p><span>After value, low volatility strategies are some of the most commonly used quant approaches of the last decade. Research going back to the 70s shows that those stocks whose prices are relatively more stable tend to roughly keep up with the rest of the market or nearly so when times are good, but lose far less value during panics and bear markets. Thus, over the long run they’ve done about as good or better as the rest of the market with a lot less risk. That is… decidedly not what happened last year. Within the US market, two of the most popular quant funds of recent years have been the iShares US Minimum Volatility ETF and the Invesco S&amp;P 500 Low Volatility ETF, two ETFs that use a quantitative approach to pick the least volatile stocks within the US market. With tens of billions of dollars between them, here’s how these two flavors of low volatility stock investing did last year.</span></p>
<p><a href="https://ycharts.com/indices/%5ESPXTR/chart/#/?annotations=&amp;annualizedReturns=false&amp;calcs=id:total_return_forward_adjusted_price,include:true,,&amp;chartType=interactive&amp;correlations=&amp;dateSelection=range&amp;displayDateRange=false&amp;displayTicker=false&amp;endDate=12/31/2020&amp;format=indexed&amp;legendOnChart=false&amp;maxPoints=2000&amp;note=&amp;partner=basic_2000&amp;quoteLegend=true&amp;quotes=true&amp;recessions=false&amp;redesign=true&amp;scaleType=linear&amp;securities=id:^SPXTR,include:true,,id:USMV,include:true,,id:SPLV,include:true,,&amp;securityGroup=&amp;securitylistName=&amp;securitylistSecurityId=&amp;source=false&amp;splitType=single&amp;startDate=01/01/2020&amp;title=&amp;units=false&amp;useCustomColors=false&amp;useEstimates=false&amp;zoom=custom"><img src="https://media.ycharts.com/charts/e209c9c736d2bc0d5a747dbb1304a1a5.png" alt="^SPXTR Chart"></a></p>
<p><a href="https://ycharts.com/indices/^SPXTR">^SPXTR</a> data by <a href="https://ycharts.com/">YCharts</a></p>
<p><span>Yikes. Low volatility …</span></p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/">https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/</a></em></p>]]>
            </description>
            <link>https://rhsfinancial.com/2021/01/11/quantquake-2020-and-the-revenge-against-the-nerds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25953890</guid>
            <pubDate>Fri, 29 Jan 2021 04:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1938 vs. 1940 (2018)]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25952042">thread link</a>) | @diodorus
<br/>
January 28, 2021 | https://pecaquet.com/2018/10/08/1938-vs-1940/ | <a href="https://web.archive.org/web/*/https://pecaquet.com/2018/10/08/1938-vs-1940/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>A key defence of appeasement, and especially the 1938 Munich Agreement, is that it gave Britain and France time to rearm against the Nazi threat. It is actually an ex-post argument: Chamberlain himself sold his policies as a bid for peace, not time. He launched no rearmament effort until March 1939, when Hitler reneged on Munich. The idea has nevertheless achieved a surprising degree of acceptance, especially in Britain. It was worthwhile sacrificing Czechoslovakia in 1938 the better to be able to face Germany militarily in 1939/40, so it goes. Except it wasn’t.</p>
<p>In this post I set out why the Entente partners actually <em>lost&nbsp;</em>time at Munich in as few words as possible. The long argument can be found in <em>The Bell of Treason</em>or in my <em>International History Review&nbsp;</em>article on the subject. It is touched upon in the rest of the Munich literature, of course, though not with the full data.</p>
<p>The first reason Britain and France were worse off in 1939 than 1938 is that in 1939 they got a far weaker set of allies. In September 1938, they could count on Czechoslovakia and the Soviet Union. In September 1939, they only had Poland. Czechoslovakia had fully mobilised, possessed a well-equipped army, and could base its defence on a long fortification barrier. Poland was surprised in the middle of mobilization, its army was ill equipped, and – thanks to the Molotov-Ribbentrop pact of August 1939 – it was invaded from both sides. The longer explanation, again, is in my book.</p>
<p><img data-attachment-id="183" data-permalink="https://pecaquet.com/tank-factory/" data-orig-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png" data-orig-size="636,474" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tank factory" data-image-description="" data-medium-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=300" data-large-file="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=636" src="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=1100" alt="tank factory" srcset="https://pecaquet.files.wordpress.com/2018/10/tank-factory.png 636w, https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=150 150w, https://pecaquet.files.wordpress.com/2018/10/tank-factory.png?w=300 300w" sizes="(max-width: 636px) 100vw, 636px"></p>
<p><em>Nuremberg Panzer factory (Ullstein Bild – Photo12 / Collection Bernard Crochet)</em></p>
<p>The key data is military. France, and with it Britain, lost time because the one to one-and-a-half years between 1938 and 1939/40 helped Germany far more than it helped them. This was partly because the Germans were able to seized the large Czechoslovak stockpiles and factories. A third of the tanks that pierced the French front in May 1940, causing the French collapse, were built in Czechoslovakia. Germany faced dire raw-material and production bottlenecks in 1938, which were relieved through time gained, the Czech annexation, and the Molotov-Ribbentrop pact. Meanwhile, German rearmament proper had only begun in 1935 when Hitler had reintroduced conscription. By 1938, Germany had thus been forming new army divisions for three years. By 1939 this was four years and by 1940 almost five: half as long again as by 1938.</p>
<p>I set out the relative army numbers, in simplified form, in the table below. France did not need to re-arm because it was already armed at or close to its full potential. Its accretion in military strength between 1938 and 1939 was limited. Germany’s accrued power was considerable. The difference became even more marked by 1940. This does not count the relative value of the Czechoslovak or Polish armies nor any Soviet contribution. Britain’s expeditionary force only increased from two to five divisions in the interval, so it can be ignored.</p>
<table>
<tbody>
<tr>
<td>
<p>Divisions</p>
</td>
<td>France 1938</td>
<td>Germany 1938</td>
<td></td>
<td>France 1939</td>
<td>
<p>Germany 1939</p>
</td>
</tr>
<tr>
<td>Infantry – regular</td>
<td>
<p>35</p>
</td>
<td>36</td>
<td></td>
<td>37</td>
<td>
<p>54</p>
</td>
</tr>
<tr>
<td>Infantry – reserve</td>
<td>
<p>21</p>
</td>
<td>8</td>
<td></td>
<td>18</td>
<td>
<p>35</p>
</td>
</tr>
<tr>
<td>Motorized / armoured</td>
<td>
<p>9</p>
</td>
<td>13</td>
<td></td>
<td>10</td>
<td>
<p>13</p>
</td>
</tr>
<tr>
<td>Fortress</td>
<td>
<p>15</p>
</td>
<td>12</td>
<td></td>
<td>21</td>
<td>
<p>12</p>
</td>
</tr>
<tr>
<td>Cavalry</td>
<td>
<p>5</p>
</td>
<td>1</td>
<td></td>
<td>5</td>
<td>
<p>1</p>
</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Total</td>
<td>
<p>85</p>
</td>
<td>70</td>
<td></td>
<td>91</td>
<td>
<p>115</p>
</td>
</tr>
</tbody>
</table>
<p>After the war started, France was able to put together another twenty divisions, while Germany assembled another forty. So France’s position changed from an advantage of fifteen divisions in 1938, to a disadvantage of twenty-four by 1939, which became forty-five in May 1940. This is a quantitative, not a qualitative overview, but two additional factors are worth mentioning. First, the 1938 German tanks were all Panzer I and II models, fitted with inferior armour and firepower. The mark I Panzer did not even possess a canon, just a machinegun. The tanks that pierced the French front in 1940 were mark III and IV – still at the prototype stage in 1938. Second, the German army was only able to push through Belgium, in 1940, by taking its border fortresses with glider and parachute units. In 1938, these elite units were still being assembled.</p>
<p>Germany lacked the firepower to defeat France in 1938. Indeed, it faced defeat at the hands of a stronger coalition, possibly in short order. It also follows, finally, that it was not in a position to launch an attack on Britain. This goes to the core of the theory that Chamberlain bought time by helping muster the country’s air defences. Actually in 1938 Britain was already producing Spitfires and Hurricanes, and output rhythms were not sped up until the spring of 1939 – and even then still less than to a wartime pace – so that the time gained was close to nil. But the key is that the <em>Luftwaffe</em>, even in 1940, could only launch an assault on Britain from bases in Belgium and northern France. It was not possible to do that from Germany. So until France fell, there could be no Battle of Britain. And if Germany lacked the land forces to defeat France in 1938 or 39…</p>
<p>The Battle of Britain was this incredibly romantic moment, immortalized by Churchill. Seen more coldly, though, it was only one of many turning points in WWII, the first among which were the falls of Poland, then France. The Battle of Britain was not even “the end of the beginning” (that was reserved to El Alamein). I want to close this post with Churchill’s own words, making exactly the point I make in the preceding paragraph.</p>
<p>“The German armies were not capable of defeating the French in 1938 or 1939. The vast tank production with which they broke the French front did not come into existence until 1940, and, in the face of French superiority in the West and an unconquered Poland in the East, they could certainly not have concentrated the whole of their air-power against England as they were able to do when France had been forced to surrender. This takes no account either of the attitude of Russia or of whatever resistance Czechoslovakia might have made. I have thought it right to set out the figures of relative air-power in the period concerned, but they do not in any way alter the conclusions which I have recorded. For all the above reasons, the year’s breathing-space said to be “gained” by Munich left Britain and France in a much worse position compared with Hitler’s Germany than they had been at the Munich crisis.”</p>
<p>(Winston S. Churchill, <em>The Second World War&nbsp;</em>(6 vols, Boston, 1948-53), vol. I, p. 304).</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2018-10-08T07:13:06+00:00">October 8, 2018</time><time datetime="2018-10-08T17:35:38+00:00">October 8, 2018</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://pecaquet.com/2018/10/08/1938-vs-1940/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25952042</guid>
            <pubDate>Fri, 29 Jan 2021 00:53:50 GMT</pubDate>
        </item>
    </channel>
</rss>
