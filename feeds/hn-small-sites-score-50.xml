<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 06 Dec 2020 04:32:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 06 Dec 2020 04:32:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Time to Say Goodbye to Google Fonts]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 82 (<a href="https://news.ycombinator.com/item?id=25300396">thread link</a>) | @zwacky
<br/>
December 4, 2020 | https://wicki.io/posts/2020-11-goodbye-google-fonts/ | <a href="https://web.archive.org/web/*/https://wicki.io/posts/2020-11-goodbye-google-fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
  <div>
    <div>
      
      <p>
        
          November 30, 2020
        
      </p>

      <figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/goodbye-google-fonts.jpg" alt="Google Fonts"> 
</figure>

<p>I‚Äôve used Google Fonts in prototypes and in 10M+ MAU products. It‚Äôs incredibly easy to get started with and provides an amazing font discovery. That‚Äôs also why it‚Äôs currently still used on over <a href="https://trends.builtwith.com/websitelist/Google-Font-API">42M websites</a>!</p>
<p>This convenience has its price: Performance. Many <a href="https://blog.cloudflare.com/fast-google-fonts-with-cloudflare-workers/">have</a> <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">already</a> <a href="https://www.keycdn.com/blog/web-font-performance#disadvantages-of-web-fonts">pointed</a> <a href="https://blog.logrocket.com/self-hosted-fonts-vs-google-fonts-api/">out</a> the cost of multiple requests. If you want the remaining speed boost, then you‚Äôre best off downloading your used Google Fonts and self-host them.</p>
<p>This is nothing new. In fact it‚Äôs been advocated already for years. Even Google themselves <a href="https://www.youtube.com/watch?v=Mv-l3-tJgGk&amp;feature=youtu.be&amp;t=24m58s">advised others to self-host fonts</a> in their Google I/O ‚Äò18 talk about web performance.</p>
<h2 id="self-hosting-fonts-vs-google-fonts">Self-hosting fonts vs Google Fonts</h2>
<p>By nature Google Fonts, even with all its font and CSS optimisations, can‚Äôt be faster than self-hosted fonts.</p>
<p>Sia wrote <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">a great post</a> where she compared the performance between Google Fonts and self-hosted fonts without the impact of a CDN.</p>
<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/with-google-fonts.png" alt="Network flow with Google Fonts"> <figcaption>
            <p>Optimised Google Fonts loading with preconnect</p>
        </figcaption>
</figure>

<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/without-google-fonts.png" alt="Network flow with self-hosting fonts"> <figcaption>
            <p>Optimised self-hosting fonts with preload</p>
        </figcaption>
</figure>

<hr>
<h2 id="the-old-performance-argument">The old performance argument</h2>
<p>So if the bottom-line performance is in self-hosting fonts‚Äô favour: What was the argument that convinced us developers that Google Fonts is at least as performing as the self-host approach?</p>
<p>Google Fonts was designed to be distributed on a global CDN and reap the caching benefits from it. Users request fonts via said CDN. Chances are that they have downloaded the font resources at an earlier point already from a different site.</p>
<blockquote>
<p>‚Äú[‚Ä¶] Our cross-site caching is designed so that you only need to load a font once, with any website, and we‚Äôll use that same cached font on any other website that uses Google Fonts.‚Äù</p>
<p>‚Äî <a href="https://fonts.google.com/about">https://fonts.google.com/about</a></p>
</blockquote>
<h2 id="invalidating-the-old-performance-argument">Invalidating the old performance argument</h2>
<p>Since Chrome v86, released October 2020, cross-site resources like fonts can‚Äôt be shared on the same CDN anymore. This is due to the partitioned browser cache (Safari has had this for years already).</p>
<p>In <a href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">this Google post</a> they explain what the partitioned browser cache is. It got only introduced to prevent a possible cross-site tracking mechanism.</p>
<h2 id="cache-partitioning-in-other-browsers">Cache partitioning in other browsers</h2>
<p>Safari really cares about privacy. It circumvented this very cross-site tracking attack for years already. Then finally comes Chrome. Other browsers that are based off Chromium, still need to signal or implement the feature.</p>
<ul>
<li>‚úÖ <strong>Chrome</strong>: since v86 (October 2020)</li>
<li>‚úÖ <strong>Safari</strong>: since 2013</li>
<li>üö´ <strong>Firefox</strong>: planning to implement</li>
<li>üö´ <strong>Edge</strong>: most likely soon</li>
<li>üö´ <strong>Opera</strong>: most likely soon</li>
<li>üö´ <strong>Brave</strong>: most likely soon</li>
<li>üö´ <strong>Vivaldi</strong>: most likely soon</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Google Fonts resources will be redownloaded for every website, regardless it being cached on the CDN. Self-host your fonts for better performance. The old performance argument is not valid anymore.</p>
<p>Thanks for checking this post out!</p>


      
      <hr><div>
  <p><img src="https://wicki.io/images/me_huc890d15b6e9f2ce8978e9aa27127dd5e_67203_350x0_resize_q75_box.jpg" alt="Simon Wicki">
    
  </p>

  <div>
    <div>
      <p>
        <strong>Simon Wicki</strong> is a Freelance Frontend Developer in
				Berlin. Passionate and fluent in Vue, Angular, React and Ionic. Interested in 
				Tech, frontend &amp; non-fiction books
      </p>
      <p>
        <a href="https://twitter.com/zwacky" onclick="ga('send', 'event', 'clickout', 'bottom_cta', '\/posts\/2020-11-goodbye-google-fonts\/')" target="_blank">
          <img src="https://wicki.io/images/svg/twitter.svg" alt="Twitter" title="Twitter">
          Follow @zwacky
        </a>
      </p>
    </div>
  </div>
</div>

    </div>
  </div>
</div>


        </div></div>]]>
            </description>
            <link>https://wicki.io/posts/2020-11-goodbye-google-fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300396</guid>
            <pubDate>Fri, 04 Dec 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths as a Service]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25299598">thread link</a>) | @gdeglin
<br/>
December 3, 2020 | https://www.themostfamousartist.com/maas | <a href="https://web.archive.org/web/*/https://www.themostfamousartist.com/maas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          
            
              
                
                  
                
              
            
          

          <main>
            
              <section data-content-field="main-content">
                <div data-type="page" data-updated-on="1607097261878" id="page-5fc97f1d887b444c614b8d8c"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1607040806507_3851"><div><h2>Monoliths</h2><h2>-as-a-</h2><h2>Service</h2><p>We are the global <a href="https://community.themostfamousartist.com/">creative community</a> behind the most headline-worthy art stunts in the world‚Ä¶</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1607040806507_9210"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607041819948-XGLKS00TJZNS7Q9Y5B2A/ke17ZwdGBToddI8pDm48kKgzHX-v50OZTetcbLmgWuUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcUecxn97ackQPp7vN6eXy76HeX13iayLWBPrh_wlieguDDFqElwGSvRuYqUGd2Qj9/En4H_GdVQAEbxof.jpg" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607041819948-XGLKS00TJZNS7Q9Y5B2A/ke17ZwdGBToddI8pDm48kKgzHX-v50OZTetcbLmgWuUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcUecxn97ackQPp7vN6eXy76HeX13iayLWBPrh_wlieguDDFqElwGSvRuYqUGd2Qj9/En4H_GdVQAEbxof.jpg" data-image-dimensions="1100x619" data-image-focal-point="0.5,0.5" alt="En4H_GdVQAEbxof.jpg" data-load="false" data-image-id="5fc9831ae262c01594584f4a" data-type="image" src="https://www.themostfamousartist.com/En4H_GdVQAEbxof.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-aspect-ratio="56.47279549718574" data-block-type="5" id="block-yui_3_17_2_1_1607040806507_11756"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042187227-P8AU33UQURGTAANT1YC8/ke17ZwdGBToddI8pDm48kM8bRIq_Jlpy-TzDnLsZvCFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpza1AxxNfjW7BkJnaaYjyko9vKUJGGjt8ug7pUBGdtLuGURcg7iOHM7Nr4qX47O0bg/Screen+Shot+2020-12-03+at+5.32.18+PM.png" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042187227-P8AU33UQURGTAANT1YC8/ke17ZwdGBToddI8pDm48kM8bRIq_Jlpy-TzDnLsZvCFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpza1AxxNfjW7BkJnaaYjyko9vKUJGGjt8ug7pUBGdtLuGURcg7iOHM7Nr4qX47O0bg/Screen+Shot+2020-12-03+at+5.32.18+PM.png" data-image-dimensions="710x663" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-12-03 at 5.32.18 PM.png" data-load="false" data-image-id="5fc98488be6684539de0aaf9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042187227-P8AU33UQURGTAANT1YC8/ke17ZwdGBToddI8pDm48kM8bRIq_Jlpy-TzDnLsZvCFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpza1AxxNfjW7BkJnaaYjyko9vKUJGGjt8ug7pUBGdtLuGURcg7iOHM7Nr4qX47O0bg/Screen+Shot+2020-12-03+at+5.32.18+PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1607040806507_27247"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042450189-ITWLCGYG711MYOL884GL/ke17ZwdGBToddI8pDm48kB4r0hTEGhin2obdF0zE7a5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzms-7abpVor2v0Z_jpb6HxwUXnH_MpeGSWjCARzTWV2WkfmJhGMIgLexgogVlDfN4/image002.png" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042450189-ITWLCGYG711MYOL884GL/ke17ZwdGBToddI8pDm48kB4r0hTEGhin2obdF0zE7a5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzms-7abpVor2v0Z_jpb6HxwUXnH_MpeGSWjCARzTWV2WkfmJhGMIgLexgogVlDfN4/image002.png" data-image-dimensions="600x319" data-image-focal-point="0.5,0.5" alt="image002.png" data-load="false" data-image-id="5fc9858f8562787517514285" data-type="image" src="https://www.themostfamousartist.com/image002.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-aspect-ratio="111.9186046511628" data-block-type="5" id="block-yui_3_17_2_1_1607040806507_37744"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042839081-56GDULGPEO49ENLEB75H/ke17ZwdGBToddI8pDm48kEJc2EGurRIpVfMw4geeYwYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8GRo6ASst2s6pLvNAu_PZdLkWgqQttFkESsR54W-Vo-DqQFSZr6WbDVTBl4dDuN6FCj7ScNggbDYsBK08KsWg4Y/unnamed.png" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607042839081-56GDULGPEO49ENLEB75H/ke17ZwdGBToddI8pDm48kEJc2EGurRIpVfMw4geeYwYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8GRo6ASst2s6pLvNAu_PZdLkWgqQttFkESsR54W-Vo-DqQFSZr6WbDVTBl4dDuN6FCj7ScNggbDYsBK08KsWg4Y/unnamed.png" data-image-dimensions="685x1069" data-image-focal-point="0.5,0.5" alt="unnamed.png" data-load="false" data-image-id="5fc98713fedaa13a4859642c" data-type="image" src="https://www.themostfamousartist.com/unnamed.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-aspect-ratio="74.10881801125704" data-block-type="5" id="block-yui_3_17_2_1_1607040806507_100133"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043738456-SDNZQKP2DZ10HUJD0CNW/ke17ZwdGBToddI8pDm48kK60W-ob1oA2Fm-j4E_9NQB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0kD6Ec8Uq9YczfrzwR7e2Mh5VMMOxnTbph8FXiclivDQnof69TlCeE0rAhj6HUpXkw/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043738456-SDNZQKP2DZ10HUJD0CNW/ke17ZwdGBToddI8pDm48kK60W-ob1oA2Fm-j4E_9NQB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0kD6Ec8Uq9YczfrzwR7e2Mh5VMMOxnTbph8FXiclivDQnof69TlCeE0rAhj6HUpXkw/image-asset.jpeg" data-image-dimensions="2500x3333" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc98a93be6684539de1ae1c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043738456-SDNZQKP2DZ10HUJD0CNW/ke17ZwdGBToddI8pDm48kK60W-ob1oA2Fm-j4E_9NQB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0kD6Ec8Uq9YczfrzwR7e2Mh5VMMOxnTbph8FXiclivDQnof69TlCeE0rAhj6HUpXkw/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1607040806507_102695"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043772160-6AJ9ZOMWE3ANBTUQ6L7B/ke17ZwdGBToddI8pDm48kLB_yMpT-58X960ldGXfhF97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfUt7F94jAuNcGuXWqaIgpmYtJRtNO6b9ISO5qSF_BivoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-12-03+at+6.02.34+PM.png" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043772160-6AJ9ZOMWE3ANBTUQ6L7B/ke17ZwdGBToddI8pDm48kLB_yMpT-58X960ldGXfhF97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfUt7F94jAuNcGuXWqaIgpmYtJRtNO6b9ISO5qSF_BivoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-12-03+at+6.02.34+PM.png" data-image-dimensions="2242x1656" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-12-03 at 6.02.34 PM.png" data-load="false" data-image-id="5fc98ab281b71b40858d52d6" data-type="image" src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043772160-6AJ9ZOMWE3ANBTUQ6L7B/ke17ZwdGBToddI8pDm48kLB_yMpT-58X960ldGXfhF97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfUt7F94jAuNcGuXWqaIgpmYtJRtNO6b9ISO5qSF_BivoRwB-dUGsSquCnVTFQcaRg/Screen+Shot+2020-12-03+at+6.02.34+PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-aspect-ratio="86.11632270168855" data-block-type="5" id="block-yui_3_17_2_1_1607040806507_113021"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043820963-AXDZ2HUID2Q5XIXG8OFN/ke17ZwdGBToddI8pDm48kKmibDOp36EpI-R8w230T2h7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmFrKkuyfqIWRdt3lCufLMAX0Qfwyuk7RFPSxNYhV3IXAEkgv7Qmv4u2TS9vWgjv5P/EoWgkDoU8AEHjxE.jpg" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043820963-AXDZ2HUID2Q5XIXG8OFN/ke17ZwdGBToddI8pDm48kKmibDOp36EpI-R8w230T2h7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmFrKkuyfqIWRdt3lCufLMAX0Qfwyuk7RFPSxNYhV3IXAEkgv7Qmv4u2TS9vWgjv5P/EoWgkDoU8AEHjxE.jpg" data-image-dimensions="1241x1598" data-image-focal-point="0.5,0.5" alt="EoWgkDoU8AEHjxE.jpg" data-load="false" data-image-id="5fc98aeae262c0159459c0cc" data-type="image" src="https://www.themostfamousartist.com/EoWgkDoU8AEHjxE.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-aspect-ratio="86.67917448405254" data-block-type="5" id="block-yui_3_17_2_1_1607040806507_124725"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043851605-G5OT65D8N3HOWGDX05U5/ke17ZwdGBToddI8pDm48kB80eW4KK5wgMfkTp6SjTNtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxkEDnlqEYEiGVDb0kl5jpOJsm5iyfgdjNZyk67t96-U_4JMfIDDY8RGcVnRlrKExA/En86BBMXYAE9bUh.jpg" data-image="https://images.squarespace-cdn.com/content/v1/545815c3e4b0c42e0d7a6235/1607043851605-G5OT65D8N3HOWGDX05U5/ke17ZwdGBToddI8pDm48kB80eW4KK5wgMfkTp6SjTNtZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxkEDnlqEYEiGVDb0kl5jpOJsm5iyfgdjNZyk67t96-U_4JMfIDDY8RGcVnRlrKExA/En86BBMXYAE9bUh.jpg" data-image-dimensions="600x800" data-image-focal-point="0.5,0.5" alt="En86BBMXYAE9bUh.jpg" data-load="false" data-image-id="5fc98b0b2ae1264a0389776a" data-type="image" src="https://www.themostfamousartist.com/En86BBMXYAE9bUh.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607045462369_157150"><p><h2>Now that we have your attention‚Ä¶</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1607045462369_69251"><div><p>We are pleased to offer a small group of collectors </p><p>the opportunity to purchase an authentic alien monolith </p><p>from the studio of </p><p>‚ÄúThe Most Famous Artist‚Äù</p></div></div></div></div></div>
              </section>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.themostfamousartist.com/maas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299598</guid>
            <pubDate>Fri, 04 Dec 2020 06:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Manage My Random Daily Notes]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25299442">thread link</a>) | @hachibu
<br/>
December 3, 2020 | https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><p>For years, I kept track of random notes by creating a text or Markdown
file on my desktop. And at the end of the day, I would delete that file and
start over again the next day. Inspired by the minimalism of <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>,
I created a similar system to manage my own notes.</p><p>Keep reading for more details or skip to the code: <a href="https://github.com/hachibu/note.sh">github.com/hachibu/note.sh</a>.</p><h4 id="introduction">Introduction</h4><p>As I mentioned before, I used to keep a single notes file on my desktop, and I
would delete it everyday. I would use this notes file to keep track of random
thoughts and details related to my work and personal life. My notes file might
contain code snippets from work, inspirational quotes, or it might have my
latest and greatest open-source software idea, or maybe even the beginning of a
new blog post. Anyway, I loved the simplicity of it, and I didn‚Äôt want any more
apps, databases or logins in my life.</p><p>But it wasn‚Äôt until I started using <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>
that I considered writing a script to manage my own notes. The brilliant part
about <code>todo-txt-cli</code> is that it‚Äôs just text files stored in my Dropbox and a
small shell script to interface with those files.</p><p>Inspired by the minimalism of <code>todo-txt-cli</code>, I built <a href="https://github.com/hachibu/note.sh">note.sh</a>.
In total, the entire project consists of 1 Bash script, 1 environment variable
to configure the notes directory and 1 symlink to install it to your
<code>/usr/local/bin</code> directory.</p><h4 id="how-it-works">How It Works</h4><p>The way it works is that every time I run the script, it opens the note for that
day in my editor of choice. For example, if today was December 2, 2020 then the
script would open a file named <code>2020-12-02.md</code> in the notes directory.</p><p>I use Vim as my editor, and I have my notes stored on Dropbox so I can access
them on all of my computers. So, my shell RC file looks like this.</p><div><pre><code data-lang="shell"><span>export</span> <span>EDITOR</span><span>=</span><span>"vim"</span>
<span>export</span> <span>NOTE_DIR</span><span>=</span><span>"</span><span>$HOME</span><span>/Dropbox/Notes"</span>
</code></pre></div><p>And my Dropbox directory looks like this.</p><p><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/dropbox-screenshot.png" alt="Dropbox Screenshot"></p><p>For searching, the script accepts a pattern and runs a recursive grep over the
notes directory. I chose grep because I use this script on both Mac and Linux,
and I wanted the script to be as portable as possible.</p><h4 id="conclusion">Conclusion</h4><p>I‚Äôve been using this script for several months across several computers, and I
still love it. I don‚Äôt search as often as I thought I would, but it‚Äôs comforting
to know it‚Äôs all there if I need it. I also ended up creating an alias for my
script so all I need to type is the letter <code>n</code> to run the script.</p><p>In the future, I‚Äôd like to add a test suite to the code base, figure out how
to create a Homebrew formula, and add archiving for older notes.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299442</guid>
            <pubDate>Fri, 04 Dec 2020 05:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part I: Barbarian Couture]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25299176">thread link</a>) | @parsecs
<br/>
December 3, 2020 | https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a three part (II, III) look at the Dothraki, the fictional horse-borne nomads of the <em>Game of Thrones</em> / <em>A Song of Ice and Fire</em> series and the degree to which George R.R. Martin‚Äôs claim that they are ‚Äúan amalgam of a number of steppe and plains cultures‚Äù holds up to scrutiny.  This is something that I have been suggesting I would get to since (checks notes),<a href="https://acoup.blog/2019/05/04/new-acquisitions-that-dothraki-charge/"> May.  Of Last Year.</a>  So it is about time we actually get to it.</p>



<p>The plan is for this series to run in three parts.  Part I (this part) will discuss how the Dothraki <em>look</em> in the setting.  Part II will look at broader questions of social organization and culture (I am nearly certain this is one of those cases where there will be a IIa and a IIb, but my hope for brevity springs eternal).  Part III will look at military culture.  In all three parts I am going to use both the books and the show ‚Äì noting where they diverge ‚Äì in part because the heaviest characterization the Dothraki got in the show was when Martin was still significantly involved with it (meaning that large parts of it likely still reflect his vision), but also because the show is how the vast majority of people experience this particular fiction.  Both the original text and the show derived from it deserve to have their vision discussed.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>First, a <strong>content warning for this series</strong>: this is discussing <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> which features a lot of content which is not G-rated.  More to the point, it is a discussion of what ‚Äì I will argue ‚Äì Martin presents as one of, if not the most brutal and sexually violent society in that setting.  And that means those themes are going to come up here (less in this essay, but more in the other parts); we are going to remain serious and adult about those things of course, but they will be a part of this analysis nonetheless.  If that is not for you, by all means feel free to check out for a few weeks.</p>



<p>Before we get into the main point, <strong>I want to note that I am going to reference my series on the <a href="https://acoup.blog/2020/01/17/collections-the-fremen-mirage-part-i-war-at-the-dawn-of-civilization/">Fremen Mirage</a> <em>a lot</em> here</strong>, because there is a lot of Fremen stuff going on with how Dothraki society is depicted.  As a result, it may be useful to go back and read those, but just to recap, we may define the Fremen Mirage this way:</p>



<p><a href="https://acoup.blog/2020/02/21/collections-the-fremen-mirage-interlude-ways-of-the-fremen/"><strong>The Fremen Mirage is a literary trope, <em>unconnected to historical reality</em>, which presents societies as a contrast between unsophisticated, but morally pure, hyper-masculine and militarily effective ‚Äòstrong men‚Äô societies honed by ‚Äòhard times‚Äô (that is, the Fremen of the term) and a sophisticated but effeminate and decadent ‚Äòweak men‚Äô societies weakened by ‚Äògood times,‚Äô frequently with an implicit assertion of the superior worth of the former.</strong></a></p>



<p>Next, a note on citation here from the books.  My understanding is that different printings of the books have different pagination, which seems to be why the Wiki of Ice and Fire cites by chapter numbers (except that the chapters of the books, as printed, <em>aren‚Äôt numbered</em> in the print editions I‚Äôve seen, making this classical-style citation extremely cumbersome and inexact).  I am going to cite by the page numbers of my edition, which is the 2011 Bantam Books Trade Paperback Edition (the box set).  Hopefully that will be enough.</p>



<p>Finally, a note on my expertise here.  <strong>I am not a scholar of either the peoples of the Eurasian Steppe or the American Great Plains</strong>.  The former group does intrude into my period and study, as steppe nomads, in the form of Scythians, Sarmatians and Huns did interact (sometimes peacefully, sometimes violently) with the broader Mediterranean world.  Consequently, my knowledge of steppe peoples tend to be better that my knowledge of the Native American peoples of the Great Plains, but I have tried, within the limits of time and availability, to do my research. <strong> I actually think, in a strange sense, this is useful, because my own initial unfamiliarity with the topic has demonstrated to me just how <em>basic</em> the level of research and reading necessary to avoid the failures of this depiction are</strong>.  You do not, in turns out, need to be an experienced scholar on the topic; just a few books and a couple of emails is enough to already radically improve on what we see and read in <em>A Song of Ice and Fire</em>, much less the absolute <em>mess </em>of what we see in <em>A Game of Thrones</em>.</p>



<p>Writing this has been tricky.  I am well aware that both of these broad cultural groups (that is, Steppe peoples and Plains Native Americans) are often represented in popular culture only in the form of inaccurate and demeaning stereotypes.  I do not want to be just another link in that chain of poor understanding.  I have thus tried to root my argument here, wherever possible, in either the writings of specialist scholars (there will be more of that next week as we get into subsistence patterns, warfare, etc.) or primary evidence, particularly in terms of <em>period photographs</em>, when it comes to clothing and dress.  With luck I have not erred overmuch.</p>



<figure><img data-attachment-id="5355" data-permalink="https://acoup.blog/1024px-skythian_archer_plate_bm_e135_by_epiktetos/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg" data-orig-size="1024,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-skythian_archer_plate_bm_e135_by_epiktetos" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Scythians#/media/File:Skythian_archer_plate_BM_E135_by_Epiktetos.jpg">Via Wikipedia</a>, an Attic vase-painting of a Scythian archer (c. 500 BCE).  The Scythians, like the Huns and Mongols, were a Eurasian Steppe people, many of them horse-borne nomads of the same sort.  Far from being drab, their clothing was colorful and distinctive, including their particular hats, which show up not only in Greek but also in Persian artwork.</figcaption></figure>



<h2>‚Ä¶But, Why?</h2>



<p>But before we get into the issue proper, it is important to clear away the standard objections, both why subject <em>A Song of Ice and Fire</em> (and its spin-off properties) to critical analysis at all and also why, if we are going to do that, we are going to focus squarely in on the Dothraki.  The answer to the first is something that we‚Äôve rehearsed a number of times, but bears restating: for most of its readers (and the watchers of <em>A Game of Thrones</em>), <em>A Song of Ice and Fire</em> will be their primary exposure to the idea of the Middle Ages.  This is particularly true because of the reputation that the series has for being ‚Äò<a href="https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/">how it really was</a>,‚Äô a reputation that George R.R. Martin has consciously cultivated (as with his classic complaint of <a href="https://youtu.be/p-VxvKoDFIw">‚Äòwhat was Aragorn‚Äôs tax policy‚Äô</a> ‚Äì there is a rich irony that, had Martin understood rulership in the Middle Ages better, he would have understood why Aragorn‚Äôs tax policy was less important).  Martin has been quite open that he ‚Äú<a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">draw[s] inspiration from history</a>‚Äù and that fact has long been a selling point of the series over more obviously fantastical kinds of medieval-themed high fantasy as well as a <a href="https://ew.com/article/2015/06/03/george-rr-martin-thrones-violence-women/">response to some of the series‚Äô more controversial moments</a>.</p>



<p><strong>Naturally, that cloak of verisimilitude has tended to intensify the degree to which elements of <em>A Song of Ice and Fire</em> is taken by its readers and viewers as representative of the Middle Ages more generally.</strong>  And of course as I have noted in the (quite recent) past,<strong> <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">fiction is often how the public conceptualizes the past and that concept of the past shapes the decisions we make in the present</a></strong>.  In the case of <em>A Song of Ice and Fire</em> in particular, this vision of the past is <a href="https://acoup.blog/2019/06/12/new-acquisitions-how-it-wasnt-game-of-thrones-and-the-middle-ages-part-iii/">particularly worth interrogating</a> because it serves as the basis for a<a href="https://youtu.be/ek2O6bVAIQQ"> parable on power and violence</a>.</p>



<p>But <em>even if it didn‚Äôt</em>, it would still be worth discussing these aspects of the universe of <em>A Song of Ice and Fire</em>, because that is what we are supposed to do with cultural products, with <em>literature</em>.  <strong>I am sometimes baffled that the very fans who insist that their particular loves be treated seriously, as <em>art</em> are the same fans who react with frustration if one then sets out to interrogate those same genres the way one would interrogate serious art or literature</strong>.  This is it, after all!  This is what you (we, really) wanted!  A (quite unimpressive, I‚Äôll grant you) ivory tower academic is taking this genre seriously and subjecting it to serious criticism!  Isn‚Äôt that what emerging genres often hope for, to be taken seriously as ‚Äòhigh‚Äô literature?</p>



<p><strong>And of course we should take it seriously.</strong>  And here I want to speak briefly to the purpose of these sorts of endeavors, <strong>because the goal here is not to force anyone to dislike <em>A Song of Ice and Fire</em></strong>.   We‚Äôre not here to ‚Äòcancel‚Äô <em>ASOIF</em> any more than we were going to ‚Äòcancel‚Äô <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/"><em>AC:Valhalla</em> two weeks ago</a> (a game I continue to play, I might add).  Instead, discussing cultural products like this is a form of inoculation against their potentially negative aspects, because once a reader knows that, for instance, the depiction of a given culture in a work of fiction has relatively little to do with any real world culture, they can compartmentalize that to the fiction itself; <strong>it loses its power to mislead</strong> <strong>and so may be enjoyed in safety, as it were</strong>.  And there are good things in <em>A Song of Ice and Fire</em> and in the first six or so seasons of <em>Game of Thrones</em>; but we also need to be honest about the failings.</p>



<p>(Of course, more broadly, doing this as a practice exercise is a key part of building up that skill ‚Äì what we may term ‚Äòcritical reading‚Äô ‚Äì more generally, rendering the alert reader more resistant to this sort of thing, both in its unintended form (as, I suspect, in this case) or  in its more dangerous<em> intended form</em>.  Put another way, developing critical reading skills is one important way to make one‚Äôs self a harder target for misinformation, including historical misinformation.)</p>



<h2>A Dash of Pure Fantasy</h2>



<p>Alright, so <em>A Song of Ice and Fire</em> is worth looking at closely.  So why <em>this</em> part of the fiction?  It comes down to something <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">George R.R. Martin wrote</a>:</p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures‚Ä¶ Mongols and Huns, certainly, but also ‚Ä¶</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299176</guid>
            <pubDate>Fri, 04 Dec 2020 05:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PixelNeRF Neural Radiance Fields from One or Few Images]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25298426">thread link</a>) | @choppaface
<br/>
December 3, 2020 | https://alexyu.net/pixelnerf/ | <a href="https://web.archive.org/web/*/https://alexyu.net/pixelnerf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p id="paper-title">
            
            <h3>
                Neural Radiance Fields from One or Few Images
            </h3>
            <h3>
                <small title="Note: This is a joke">IEEE International Conference on Neural Radiance Fields (ICNeRF)</small>
            </h3>
        </p>

        
        
        <div>
            <div>
                <div id="dynamic-teaser">
                     <!-- row -->

                     <!-- row -->
                    <div id="teaser-dtu">
                        <div>
                            <p>3 Input Views</p>
                            
                            <p><strong>pixelNeRF</strong></p>
                            <p>3-view NeRF</p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_inputs.jpg">
                            </p>
                            
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_outputs_sm.gif">
                            </p>
                        </div> <!-- row -->
                    </div>
                </div> <!-- dynamic-teaser -->
                <!-- <img id="teaser" src="img/teaser.png" class="img-responsive" alt="teaser figure"> -->
                <p>
                    We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on
                    one or few input images.
                    The existing approach for
                    constructing neural radiance fields&nbsp;<a href="https://www.matthewtancik.com/nerf">[Mildenhall et al. 2020]</a>
                    involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time.
                    We take a step towards resolving these shortcomings
                    by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, enabling it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one).
                </p>

            </div>
        </div>
        <div id="overview-video">
            <div>
                <h4>Narrated Overview</h4>
                <p>
                    <iframe src="https://www.youtube.com/embed/voebZx7f32g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </p>
            </div>
        </div>
        <div>
            <div>
                <p>
                    Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision.
                    We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks with held-out objects as well as entire unseen categories.
                    We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes and real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.
                </p>
                <p><img src="https://alexyu.net/pixelnerf/img/pipeline.png" alt="pipeline">
            </p></div>
        </div>
        <div>
            <div>
                <h4>Feed-forward NeRF from One View</h4>
                <p>
                    Using multiview image supervision, we train a single pixelNeRF to 13 largest object categories
                    in ShapeNet in order to perform novel-view synthesis on unseen objects.
                    Our approach operates in <strong>view-space</strong>‚Äîas opposed to canonical‚Äîand requires <strong>no test-time optimization</strong>.
                    Nevertheless, in terms of image metrics, we significantly outperform existing methods quantitatively, as shown in the paper.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_000.gif" alt="shapenet results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_001.gif" alt="shapenet results animated">
                    </p></div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Scene-level Representation</h4>
                <p>
                    Since our method requires <strong>neither canonical space nor object-level information such as masks</strong>,
                    it can represent scenes with multiple objects, where a canonical space is unavailable,
                    without modification.
                    Our method can also <strong>seemlessly integrate multiple views</strong> at test-time to obtain better results.
                    SRN performs extremely poorly here due to the lack of a consistent canonical space.
                </p>
                <div>
                    <div>
                        <div>
                            <p>2 Input Views</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                    <div>
                        <div>
                            
                            <p>1 Input View</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Real-world Scenes</h4>
                <p>
                    We show that our method can also conduct wide-baseline view synthesis on more complex real scenes from the <a href="http://roboimagedata.compute.dtu.dk/?page_id=36">DTU MVS</a> dataset,
                    producing reasonable results when given only 1-3 views at inference time.
                    Moreover, it is feed-forward without requiring test-time optimization for each scene.
                </p>
                <div>
                    
                    <div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu_inputs.jpg" alt="DTU 3 input images">
                        </p>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu.gif" alt="DTU results animated">
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Generalization</h4>
                <p>
                    To demonstrate generalization capabilities,
                    we apply a model trained on ShapeNet planes, cars, and chairs to unseen ShapeNet categories.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_000.gif" alt="shapenet unseen category results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_001.gif" alt="shapenet unseen category results animated">
                    </p></div>
                </div>
                <p>
                    Separately, we apply a pretrained model on real car images after background removal.
                </p>
                
                
            </div>
        </div>
        <div>
            <div>
                <h4>Related Links</h4>
                <ul>
                    <li>
                        NeRF was introduced in <a href="https://www.matthewtancik.com/nerf">Mildenhall et al. (2020)</a>
                    </li><li>
                        Local image features were used in the related regime of implicit surfaces in
                        <a href="https://shunsukesaito.github.io/PIFu/">Saito et al. (2019)</a>
                        and
                        <a href="https://arxiv.org/abs/1905.10711">Xu et al. (2019)</a>
                    </li><li>
                        Our MLP architecture is
                        inspired by
                        <a href="https://avg.is.tuebingen.mpg.de/publications/niemeyer2020cvpr">DVR</a>
                    </li><li>
                        Parts of our
                        PyTorch NeRF implementation are taken from
                        <a href="https://github.com/kwea123/nerf_pl">kwea123</a>
                    </li><li>
                        Also see the concurrent work
                        <a href="https://arxiv.org/abs/2010.04595">GRF</a>
                        which also introduces image features for NeRF, showing image features can even improve NeRF when a large number of views are available.
                </li></ul>
            </div>
        </div>
        
        <div>
            <div>
                <h4>Acknowledgements</h4>
                <p>
                    We thank Shubham Goel and Hang Gao for comments on the text. We also thank
                    Emilien Dupont and Vincent Sitzmann for helpful discussions.
                    This website is inspired by the template of <a href="http://mgharbi.com/">Micha√´l Gharbi</a>.
                </p>
                <p>
                    Please send any questions or comments to <a href="https://alexyu.net/">Alex Yu</a>.
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexyu.net/pixelnerf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298426</guid>
            <pubDate>Fri, 04 Dec 2020 03:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A terminal-based workflow for research, writing, and programming]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25297268">thread link</a>) | @jerodsanto
<br/>
December 3, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p><a href="https://youtu.be/2SLZQQfMF8E"><img src="http://jacobzelko.com/assets/workflow_youtube_vid.jpg" alt=""></a></p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action-boom">My Workflow in Action <img title=":boom:" alt=":boom:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a5.png" height="20" width="20">
</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="floating-terminals">Floating Terminals</h3>

<p><img src="http://jacobzelko.com/assets/float_term.gif" alt=""></p>

<p>Floating terminals are immensely powerful and I love them!
This enables me to quickly pull up a terminal and do some changes without having to split tmux panes or get out of vim.
Furthermore, what is awesome is that you can use it as a sort of <code>vim-slime</code> tool to send lines of code to the floating terminal.
This is a great feature as it uses your last used floating terminal for its target - therefore, if you switch between projects a lot, just switch your floating terminal accordingly.
No need to keep opening and closing REPL sessions and such!</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I‚Äôll have to spend valuable time getting my workflow set back up‚Ä¶ Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It‚Äôs nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer ‚Äì works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>



<p>These are parts of my workflow that I used to use.
They have been retired for a variety of reasons but all in an effort to improve my workflow.
I have kept these around in case anyone finds it useful!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><strong>Rationale for deprecation:</strong> I used to use <code>vim-slime</code> but deprecated it from my workflow because of the flexibility of floating terminals.
Not only could I use floating terminals to send code, I could also quickly flip through terminals in one button press.</p>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297268</guid>
            <pubDate>Fri, 04 Dec 2020 00:05:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architectures for Mitigating AWS Outages]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25295307">thread link</a>) | @mmbleh
<br/>
December 3, 2020 | https://www.forelse.io/posts/architectures-for-mitigating-aws-outages/ | <a href="https://web.archive.org/web/*/https://www.forelse.io/posts/architectures-for-mitigating-aws-outages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>With the recent outage on AWS last week, there have been a lot of discussions about various architectures and how effective they would've been to combat the downtime. Since these vary a lot in cost, complexity, and tradeoffs, I want to go through a couple of them at a high level, then dive into one that was unfortunately missing from much of the conversation.</p>
<h2 id="multi-cloud">Multi-Cloud</h2>
<p>First were comments made about the value of going multi-cloud. The idea of this is to run your application in‚Ä¶ multiple clouds.
<img src="https://www.forelse.io/multi-cloud.png" alt="Multi-Cloud">
By spreading the load across multiple providers, you are insulated in case one of them goes down. In theory, it sounds great! Surely two cloud vendors won't go down at the same time! In practice, this is horrible at the application level for a multitude of reasons:</p>
<ul>
<li>The infrastructure is different for each cloud</li>
<li>Deployments gain a magnitude of complexity</li>
<li>Bandwidth charges to go between the two are outrageous</li>
</ul>
<p>Because of this, a multi-cloud architecture would not be a feasible option for high availability (outside a select few edge cases).</p>
<h2 id="multi-region">Multi-Region</h2>
<p>Next, there were talks about multi-region. An AWS Region is a group of multiple availability zones (AZ), with each AZ being one or more discrete data centers with independent power, networking, and connectivity. Operating in a single region across multiple AZs provides high availability, but doesn't provide DR. For that, you need multiple regions. A very simplified version of a multi-region setup looks like this:
<img src="https://www.forelse.io/multi-region.png" alt="Multi-Region">
This fixes a couple of the issues of going multi-cloud:</p>
<ul>
<li>Your application will stay in the same cloud, so the infrastructure will stay the same</li>
<li>Regions are completely separated, so you get the same availability benefits!</li>
<li>Region-to-region bandwidth charges are much lower than cloud-to-cloud fees!</li>
</ul>
<p>Unfortunately, most of the comments were around <em>Active-Active</em> multi-region. That is, distributing the load across multiple regions at the same time. This adds in a lot of complexities around keeping the persistence layer in sync. This also adds complexity around deployments and has a lot of places for things to go wrong. This can lead to more self-inflicted downtime than AWS has ever caused.</p>
<h2 id="multi-region-dr">Multi-Region DR</h2>
<p>This is the one that has been largely overlooked in recent days. It is the idea that only a single region is active at a time, and a secondary region is capable of taking over in the event of a disaster (hence DR). This shares the benefits listed above. However, it is able to largely mitigate the complexities of a full Active-Active setup. Under this setup, the secondary region doesn't need to be fully built - only persistent data needs to be replicated.</p>
<p><img src="https://www.forelse.io/multi-region-dr.png" alt="Multi-Region"></p>
<p>But wait, won't it take a while to deploy the full application stack in the event of a disaster? Yes‚Ä¶ yes it will. And this is okay! High-Availability is achieved by using multiple AZs is sufficient for most common outages. If an entire <em>region</em> has issues, like we saw last week, spending &lt;1 hour standing up a new stack from backups is still preferable to a &gt;8 hour outage. This process can be streamlined via automation, but even if it's a manual (but practiced) operation, the fact that you <em>actually have options</em> is important.</p>
<p>So let's dive into this a little more to explore what it looks like:</p>
<ul>
<li>Application is deployed as usual in the primary region</li>
<li>Using AWS managed services, backups and replication for persistent data is generally a configuration setting or two away:
<ul>
<li>Add a read replica to RDS in a different region</li>
<li>Create a Dynamo DB global table</li>
<li>Enable S3 bucket replication</li>
</ul>
</li>
<li>In the event of a fail-over, deploy the application in the other region (hopefully using Infrastructure-as-Code) and update DNS settings
<ul>
<li>This process should be regularly tested</li>
</ul>
</li>
</ul>
<p>Is this a silver-bullet? Absolutely not. It won't work for every workload, and definitely won't work for every type of outage. However, it is a relatively simple solution that can also be cost effective. And last week, it could've allowed clients to be back up and functioning long before services in us-east-1 were fully restored.</p>
<h2 id="summary">Summary</h2>
<p>In conclusion, outages happen. This does not diminish the value of AWS in any way, but it does make clear the importance of good architecture and planning. There are some very expensive and elaborate systems that can be designed to mitigate these outages, but which are overkill and impractical for most clients. Fortunately, there are other options that may offer an ‚Äúeffective enough‚Äù solution with reasonable tradeoffs, which should become ‚Äúbest-practice‚Äù when working in AWS.</p>

        </div></div>]]>
            </description>
            <link>https://www.forelse.io/posts/architectures-for-mitigating-aws-outages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25295307</guid>
            <pubDate>Thu, 03 Dec 2020 21:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI researcher Timnit Gebru resigns from Google]]>
            </title>
            <description>
<![CDATA[
Score 452 | Comments 727 (<a href="https://news.ycombinator.com/item?id=25292386">thread link</a>) | @apsec112
<br/>
December 3, 2020 | https://www.platformer.news/p/the-withering-email-that-got-an-ethical | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/the-withering-email-that-got-an-ethical">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd68f7405-78e2-4d46-9063-872e98660410_1024x683.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd68f7405-78e2-4d46-9063-872e98660410_1024x683.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d68f7405-78e2-4d46-9063-872e98660410_1024x683.jpeg&quot;,&quot;height&quot;:683,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:140598,&quot;alt&quot;:&quot;Timnit Gebru, speaking at TechCrunch disrupt in 2018 (Kimberly White/Getty Images)&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="Timnit Gebru, speaking at TechCrunch disrupt in 2018 (Kimberly White/Getty Images)"></a><figcaption>Timnit Gebru, speaking at TechCrunch disrupt in 2018 (Kimberly White/Getty Images)</figcaption></figure></div><p><em>This post is free for all to read thanks to the investment <strong>Platformer</strong> subscribers have made in independent journalism. If this work is meaningful to you, I invite you to become a subscriber today</em>.</p><p>Last week, a prominent a co-leader of the Ethical Artificial Intelligence team at Google sent an email to her colleagues. Timnit Gebru had been working on a research paper that she hoped to publish, but ran into resistance from her superiors at Google. And so she sent a letter expressing her frustration to the internal listserv Google Brain Women and Allies. </p><p>A few days later, Gebru was fired ‚Äî&nbsp;Google reportedly found the email ‚Äúinconsistent with the expectations of a Google manager.‚Äù It details the struggles Gebru experienced as a Black leader working on ethics research within the company, and presents a bleak view of the path forward for underrepresented minorities at the company. </p><p>Gebru is well known and respected in the AI ethics community; <a href="https://www.bloomberg.com/news/articles/2020-12-03/google-s-co-head-of-ethical-ai-says-she-was-fired-over-email?sref=ExbtjcSG">here are Shelly Banjo  and Mark Bergen on her background at Bloomberg</a>:</p><blockquote><p>Gebru, an alumni of the Stanford Artificial Intelligence Laboratory, is one of the leading voices in the ethical use of artificial intelligence. She is well-known for her work on a&nbsp;<a href="https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212" title="MIT">landmark study</a>&nbsp;in 2018 that showed how facial recognition software misidentified dark-skinned women as much as 35% of the time, whereas the technology worked with near precision on white men.</p><p>She has also been an outspoken critic of the lack of diversity and unequal treatment of Black workers at tech companies, particularly at&nbsp;<a href="https://www.bloomberg.com/quote/GOOGL:US" title="Company Overview">Alphabet Inc.</a>‚Äôs Google, and said she believed her dismissal was meant to send a message to the rest of Google‚Äôs employees not to speak up.</p></blockquote><p>Platformer received the email Gebru sent; she herself did not have access to her account after Google terminated her. It is published in full below. </p><p>Google did not immediately respond to a request for comment. But on Thursday morning, Jeff Dean, the head of Google research, emailed employees with his account of what happened. Dean said Gebru had issued ultimatum and would resign unless certain conditions were met. <strong>Platformer</strong> obtained Dean‚Äôs email as well; you can find it below Gebru‚Äôs. </p><blockquote><p>Hi friends,</p><p>I had stopped writing here as you may know, after all the micro and macro aggressions and harassments I received after posting my stories here (and then of course it started being moderated).</p><p>Recently however, I was contributing to a document that Katherine and Daphne were writing where they were dismayed by the fact that after all this talk, this org seems to have hired 14% or so women this year. Samy has hired 39% from what I understand but he has zero incentive to do this.</p><p>What I want to say is stop writing your documents because it doesn‚Äôt make a difference. The DEI OKRs that we don‚Äôt know where they come from (and are never met anyways), the random discussions, the ‚Äúwe need more mentorship‚Äù rather than ‚Äúwe need to stop the toxic environments that hinder us from progressing‚Äù the constant fighting and education at your cost, they don‚Äôt matter. Because there is zero accountability. There is no incentive to hire 39% women: your life gets worse when you start advocating for underrepresented people, you start making the other leaders upset when they don‚Äôt want to give you good ratings during calibration. There is no way more documents or more conversations will achieve anything. We just had a Black research all hands with such an emotional show of exasperation. Do you know what happened since? Silencing in the most fundamental way possible.</p><p>Have you ever heard of someone getting ‚Äúfeedback‚Äù on a paper through a privileged and confidential document to HR? Does that sound like a standard procedure to you or does it just happen to people like me who are constantly dehumanized?</p><p>Imagine this: You‚Äôve sent a paper for feedback to 30+ researchers, you‚Äôre awaiting feedback from PR &amp; Policy who you gave a heads up before you even wrote the work saying ‚Äúwe‚Äôre thinking of doing this‚Äù, working on a revision plan figuring out how to address different feedback from people, haven‚Äôt heard from PR &amp; Policy besides them asking you for updates (in 2 months). A week before you go out on vacation, you see a meeting pop up at 4:30pm PST on your calendar (this popped up at around 2pm). No one would tell you what the meeting was about in advance. Then in that meeting your manager‚Äôs manager tells you ‚Äúit has been decided‚Äù that you need to retract this paper by next week, Nov. 27, the week when almost everyone would be out (and a date which has nothing to do with the conference process). You are not worth having any conversations about this, since you are not someone whose humanity (let alone expertise recognized by journalists, governments, scientists, civic organizations such as the electronic frontiers foundation etc) is acknowledged or valued in this company.</p><p>Then, you ask for more information. What specific feedback exists? Who is it coming from? Why now? Why not before? Can you go back and forth with anyone? Can you understand what exactly is problematic and what can be changed?</p><p>And you are told after a while, that your manager can read you a privileged and confidential document and you‚Äôre not supposed to even know who contributed to this document, who wrote this feedback, what process was followed or anything. You write a detailed document discussing whatever pieces of feedback you can find, asking for questions and clarifications, and it is completely ignored. And you‚Äôre met with, once again, an order to retract the paper with no engagement whatsoever.</p><p>Then you try to engage in a conversation about how this is not acceptable and people start doing the opposite of any sort of self reflection‚Äîtrying to find scapegoats to blame.</p><p>Silencing marginalized voices like this is the opposite of the NAUWU principles which we discussed. And doing this in the context of ‚Äúresponsible AI‚Äù adds so much salt to the wounds. I understand that the only things that mean anything at Google are levels, I‚Äôve seen how my expertise has been completely dismissed. But now there‚Äôs an additional layer saying any privileged person can decide that they don‚Äôt want your paper out with zero conversation. So you‚Äôre blocked from adding your voice to the  research community‚Äîyour work which you do on top of the other marginalization you face here. </p><p>I‚Äôm always amazed at how people can continue to do thing after thing like this and then turn around and ask me for some sort of extra DEI work or input. This happened to me last year. I was in the middle of a potential lawsuit for which Kat Herller and I hired feminist lawyers who threatened to sue Google (which is when they backed off--before that Google lawyers were prepared to throw us under the bus and our leaders were following as instructed) and the next day I get some random ‚Äúimpact award.‚Äù Pure gaslighting.</p><p>So if you would like to change things, I suggest focusing on leadership accountability and thinking through what types of pressures can also be applied from the outside. For instance, I believe that the Congressional Black Caucus is the entity that started forcing tech companies to report their diversity numbers. Writing more documents and saying things over and over again will tire you out but no one will listen.</p><p>Timnit </p></blockquote><p>And here is the email that Jeff Dean sent out to Googlers on Thursday morning.</p><blockquote><p>Hi everyone,</p><p>I‚Äôm sure many of you have seen that Timnit Gebru is no longer working at Google. This is a difficult moment, especially given the important research topics she was involved in, and how deeply we care about responsible AI research as an org and as a company.</p><p>Because there‚Äôs been a lot of speculation and misunderstanding on social media, I wanted to share more context about how this came to pass, and assure you we‚Äôre here to support you as you continue the research you‚Äôre all engaged in.</p><p>Timnit co-authored a paper with four fellow Googlers as well as some external collaborators that needed to go through our review process (as is the case with all externally submitted papers). We‚Äôve approved dozens of papers that Timnit and/or the other Googlers have authored and then published, but as you know, papers often require changes during the internal review process (or are even deemed unsuitable for submission). Unfortunately, this particular paper was only shared with a day‚Äôs notice before its deadline ‚Äî we require two weeks for this sort of review ‚Äî and then instead of awaiting reviewer feedback, it was approved for submission and submitted.</p><p>A cross functional team then reviewed the paper as part of our regular process and the authors were informed that it didn‚Äôt meet our bar for publication and were given feedback about why. It ignored too much relevant research ‚Äî for example, it talked about the environmental impact of large models, but disregarded subsequent research showing much greater efficiencies.&nbsp; Similarly, it raised concerns about bias in language models, but didn‚Äôt take into account recent research to mitigate these issues. We acknowledge that the authors were extremely disappointed with the decision that Megan and I ultimately made, especially as they‚Äôd already submitted the paper.&nbsp;</p><p>Timnit responded with an email requiring that a number of conditions be met in order for her to continue working at Google, including revealing the identities of every person who Megan and I had spoken to and consulted as part of the review of the paper and the exact feedback. Timnit wrote that if we didn‚Äôt meet these demands, she would leave Google and work on an end date. We accept and respect her decision to resign from Google.</p><p>Given Timnit's role as a respected researcher and a manager in our Ethical AI team, I feel badly that Timnit has gotten to a place where she feels this way about the work we‚Äôre doing. I also feel badly that hundreds of you received an email just this week from Timnit telling you to stop work on critical ‚Ä¶</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.platformer.news/p/the-withering-email-that-got-an-ethical">https://www.platformer.news/p/the-withering-email-that-got-an-ethical</a></em></p>]]>
            </description>
            <link>https://www.platformer.news/p/the-withering-email-that-got-an-ethical</link>
            <guid isPermaLink="false">hacker-news-small-sites-25292386</guid>
            <pubDate>Thu, 03 Dec 2020 18:18:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futures explained in 200 lines of Rust]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25290818">thread link</a>) | @fanf2
<br/>
December 3, 2020 | https://cfsamson.github.io/books-futures-explained/introduction.html | <a href="https://web.archive.org/web/*/https://cfsamson.github.io/books-futures-explained/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This book aims to explain Futures in Rust using an example driven approach,
exploring why they're designed the way they are, and how they work. We'll also
take a look at some of the alternatives we have when dealing with concurrency
in programming.</p>
<p>Going into the level of detail I do in this book is not needed to use futures
or async/await in Rust. It's for the curious out there that want to know <em>how</em>
it all works.</p>
<h2><a href="#what-this-book-covers" id="what-this-book-covers">What this book covers</a></h2>
<p>This book will try to explain everything you might wonder about up until the
topic of different types of executors and runtimes. We'll just implement a very
simple runtime in this book introducing some concepts but it's enough to get
started.</p>
<p><a href="https://github.com/stjepang">Stjepan Glavina</a> has made an excellent series of
articles about async runtimes and executors, and if the rumors are right there
is more to come from him in the near future.</p>
<p>The way you should go about it is to read this book first, then continue
reading the <a href="https://stjepang.github.io/">articles from stejpang</a> to learn more
about runtimes and how they work, especially:</p>
<ol>
<li><a href="https://stjepang.github.io/2020/01/25/build-your-own-block-on.html">Build your own block_on()</a></li>
<li><a href="https://stjepang.github.io/2020/01/31/build-your-own-executor.html">Build your own executor</a></li>
</ol>
<p>I've limited myself to a 200 line main example (hence the title) to limit the
scope and introduce an example that can easily be explored further.</p>
<p>However, there is a lot to digest and it's not what I would call easy, but we'll
take everything step by step so get a cup of tea and relax.</p>
<p>I hope you enjoy the ride.</p>
<blockquote>
<p>This book is developed in the open, and contributions are welcome. You'll find
<a href="https://github.com/cfsamson/books-futures-explained">the repository for the book itself here</a>. The final example which
you can clone, fork or copy <a href="https://github.com/cfsamson/examples-futures">can be found here</a>. Any suggestions
or improvements can be filed as a PR or in the issue tracker for the book.</p>
<p>As always, all kinds of feedback is welcome.</p>
</blockquote>
<h2><a href="#reader-exercises-and-further-reading" id="reader-exercises-and-further-reading">Reader exercises and further reading</a></h2>
<p>In the last <a href="https://cfsamson.github.io/books-futures-explained/conclusion.html">chapter</a> I've taken the liberty to suggest some
small exercises if you want to explore a little further.</p>
<p>This book is also the fourth book I have written about concurrent programming
in Rust. If you like it, you might want to check out the others as well:</p>
<ul>
<li><a href="https://cfsamson.gitbook.io/green-threads-explained-in-200-lines-of-rust/">Green Threads Explained in 200 lines of rust</a></li>
<li><a href="https://cfsamson.github.io/book-exploring-async-basics/">The Node Experiment - Exploring Async Basics with Rust</a></li>
<li><a href="https://cfsamsonbooks.gitbook.io/epoll-kqueue-iocp-explained/">Epoll, Kqueue and IOCP Explained with Rust</a></li>
</ul>
<h2><a href="#credits-and-thanks" id="credits-and-thanks">Credits and thanks</a></h2>
<p>I'd like to take this chance to thank the people behind <code>mio</code>, <code>tokio</code>,
<code>async_std</code>, <code>futures</code>, <code>libc</code>, <code>crossbeam</code> which underpins so much of the
async ecosystem and and rarely gets enough praise in my eyes.</p>
<p>A special thanks to <a href="https://twitter.com/jonhoo">jonhoo</a> who was kind enough to
give me some valuable feedback on a very early draft of this book. He has not
read the finished product, but a big thanks is definitely due.</p>
<h2><a href="#translations" id="translations">Translations</a></h2>
<p><a href="https://stevenbai.top/rust/futures_explained_in_200_lines_of_rust/">This book has been translated to Chinese</a> by <a href="https://github.com/nkbai">nkbai</a>.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        
        <!-- Google Analytics Tag -->
        
        

        
        
        

        
        
        

        
        
        
        
        
        
        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://cfsamson.github.io/books-futures-explained/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25290818</guid>
            <pubDate>Thu, 03 Dec 2020 16:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase Beta: Auth, SQL Editor, Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25289233">thread link</a>) | @kiwicopple
<br/>
December 3, 2020 | https://supabase.io/beta | <a href="https://web.archive.org/web/*/https://supabase.io/beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><div><p><a href="https://supabase.io/"><img src="https://supabase.io/new/images/logo-dark.png"></a></p></div><div><div><div><p>Supabase is an opensource Firebase alternative.</p><p>Today, we're moving to <span>Beta</span></p></div></div></div><div><div><p><span>After the launch of our<!-- --> <a href="https://news.ycombinator.com/item?id=23319901" target="_blank">Alpha</a> <!-- -->Program in June,</span></p><p>we've been fortunate to work with thousands of early adopters on improving both our Open Source, and Hosted offerings. Companies like<!-- --> <a href="https://supabase.io/blog/2020/12/02/case-study-xendit" target="_blank">Xendit</a>,<!-- --> <a href="https://supabase.io/blog/2020/12/02/case-study-monitoro" target="_blank">Monitoro</a>, and<!-- --> <a href="https://supabase.io/blog/2020/12/02/case-study-tayfa" target="_blank">TAYFA</a> <!-- -->are using Supabase to ship more products, faster.</p><p>Alpha Program in Numbers</p><div id="alphaNumbers"><div><p><span>0</span></p><p>Forks of our repositories</p></div><div><p><span>0</span></p><p>Active Github contributors</p></div></div></div></div><div><div><p>Supabase <span>Beta</span> is starting now.</p><div><div><p>To deliver a production-ready platform, we've put extra effort into three areas of Supabase.</p></div><div><p>We received an incredible number of feature requests from our Alpha Users, and we're using these conversations build a simple, predictable Beta Pricing model.</p><div><div><p>04</p><p>New Features &amp; Integrations</p></div></div></div><div><p>Open Source is, and will always be, at the core of everything that we do. Find out how we've been working with the community to support existing OSS projects and Communities.</p></div><div><p>And finally, we're partnering with the best in the business to help us achieve our goal of becoming the default backend for every company. We'll be announcing the details soon, and we're excited to share what we have in store for 2021:</p></div></div></div></div><div><div id="performance"><div><div><div><p>We started Supabase to give developers a web-ready database that is delightful to use, without sacrificing speed and scale. Postgres makes this possible, handling massive amounts of data without sacrificing read and write speed.</p><p>We tweaked our stack obsessively during our Alpha program to tease out superior performance. We chose the hyper-scalable<!-- --> <a href="https://elixir-lang.org/" target="_blank">Elixir</a> <!-- -->to handle our<!-- --> <a href="https://github.com/supabase/realtime" target="_blank">Realtime engine</a>, and have supported the<!-- --> <a href="https://postgrest.org/en/v7.0.0/" target="_blank">PostgREST</a> <!-- -->team while they improved the performance of their auto-generated CRUD APIs.</p><p>We're publishing the results of our benchmarks here and we'll continue to seek gains throughout our Beta program and beyond. Our<!-- --> <a href="https://github.com/supabase/benchmarks/" target="_blank">benchmarks</a> <!-- -->are open source so that the community can better our methodologies and identify areas of improvement for the tools which we support at Supabase.</p></div><div><div id="performanceCharts"><div><p>Read (requests/s)</p><div><div><p>3.2<!-- -->x</p><p>more <!-- -->read<!-- -->s per second</p></div></div></div><div><p>Write (requests/s)</p><div><div><p>3.1<!-- -->x</p><p>more <!-- -->write<!-- -->s per second</p></div></div></div></div></div><div><p>Benchmarks were run from a neutral host (Digital Ocean Droplet 4 GB Memory / 80 GB Disk / SGP1 - Ubuntu 20.04 (LTS) x64) against a table/collection pre-populated with 1 million rows. The Supabase database and API used are each running on AWS EC2 t3a.micro instances.</p><p>Supabase is available in 7 different geographic regions. We're adding more regions as we build up multi-cloud support. Soon we'll offer read-replicas to scale your database right to the edge - reducing latency and giving your users a better experience.</p><p>One of our key metrics at Supabase is "Time to Value". How fast can a user go from sign up, to making their first API request? How fast can they go from development to production? We've built several case studies on our blog, demonstrating how Supabase enables them to build and scale their product in as little time as possible.</p></div></div></div></div></div><div><div id="security"><div><div><div><p>As an infrastructure provider, security has been a priority from day one. While we had to resolve brute force attacks on our customers' databases, we internally run pen tests to ensure that our own systems are air-tight.</p><p>Approaching the launch of our Beta period, we worked with security advisors and specialists globally to enforce new measures and processes:</p><ul><li>Employed DigitalXRAID to run a full Pen Test on both our internal and customer infrastructure. We immediately patched one medium priority issue and are currently in the process of resolving the minor and informational issues.</li><li>Published a disclosure policy so that ethical hackers can help us find vulnerabilities in our systems. We've received reports from this initiative already, and we'll continue to formalise our bounty program throughout the Beta.</li><li>We now run an ongoing internal Capture the Flag competition, where team members are challenged to breach various components of our systems.</li><li>Adopted the<!-- --> <a href="https://snyk.io/" target="_blank">Snyk</a> <!-- -->dependency monitor as part of our SSDLC on several key component of our system, to help locate potential vulnerabilities in third party Open Source dependencies.</li><li>Worked with several of the open source tools that we use to improve their own security. For example, PostgREST<!-- --> <a href="https://github.com/PostgREST/postgrest/pull/1600#issuecomment-735257952" target="_blank">now uses</a> <!-- -->"parametrized" inputs, where they were previously "escaped".</li></ul></div></div></div></div></div><div><div id="reliability"><div><div><div><p>During Alpha we experienced 2 availability incidents, neither affecting customer access to their data. These were:</p><ul><li>A third-party CDN API outage. As a result, subdomains were not created for new projects.</li><li>Cloud resource limits. We maxed out our Virtual Machines limits in some popular regions, and we hit the maximum number of subdomains allowed by our DNS provider. These limitations are artificial and our cloud providers quickly lifted them.</li></ul><p>Availability is one of our highest priority goals. We're continuing efforts to maximize uptime and ensure user data is backed up in a secure and encrypted location.</p><p>We're launching<!-- --> <a href="https://status.supabase.io/" target="_blank">https://status.supabase.io</a> <!-- -->to keep track of uptime across all of our services and critical infrastructure.</p><div><div><div><video src="https://supabase.io/new/videos/statusPage.mp4" autoplay="" loop="" muted="" playsinline="">Your browser does not support the video tag</video></div></div></div><p>For our Alpha &amp; Beta Users we take free, encrypted daily database backups up to 20GB. They are available to download at any time via the dashboard.</p></div></div></div></div></div><div><div id="newFeaturesAndIntegrations"><div><div><p><span>0<!-- -->4</span></p><h3>New Features &amp; Integrations</h3></div><div><div><p>If you're new to Supabase, here's a few of the things you get when you choose us as your backend.</p><ul><li><p>Auth</p><p>If you're new to Supabase, here's a few of the things you get when you choose us as your backend. We provide<!-- --> <a href="https://supabase.io/docs/client/auth-signup" target="_blank">Javascript</a> <!-- -->(and<!-- --> <a href="https://supabase.io/docs/gotrue/server/about#endpoints" target="_blank">HTTP</a>) APIs for your users to sign in and out of your application. You can define the rows in your database that logged-in users can access (e.g. only his or her shopping cart). We even provide account confirmation, recovery, and invite email templates which you can customize on the dashboard, and we handle the transactional emails for you. We support passwordless links, and we offer several OAuth providers including Google, GitHub, with more on the way.</p><div><div><video src="https://supabase.io/new/videos/tabAuthRules.mp4" autoplay="" loop="" muted="" playsinline="">Your browser does not support the video tag</video></div></div></li><li><p>Realtime</p><p>You can<!-- --> <a href="https://supabase.io/docs/guides/client-libraries#realtime-changes" target="_blank">subscribe to changes in your database</a> <!-- -->over websockets, receiving your data in realtime. Companies are using Supabase to build chat applications, trigger notifications, and pipe data to analytics dashboards whenever it changes in their database.</p></li><li><p>CRUD API</p><p>You can use your database immediately, without an ORM or an API backend. We support GraphQL-like<!-- --> <a href="https://supabase.io/docs/client/select#query-foreign-tables" target="_blank">querying from multiple tables</a> <!-- -->in a single request, and you can even<!-- --> <a href="https://supabase.io/docs/client/rpc" target="_blank">invoke complex functions</a>.</p></li><li><p>Quickstart Templates</p><p>If you're unfamiliar with SQL, we provide a set of Quickstart Templates to get you building quickly. Very soon you'll be able to deploy entire apps (front and back end) with just the click of a button.</p></li><li><p>Table View</p><p>View and edit your data like a spreadsheet from within the Supabase dashboard. Build your schema, create complex relationships, and import and export to csv.</p><div><div><video src="https://supabase.io/new/videos/tabTableEditor.mp4" autoplay="" loop="" muted="" playsinline="">Your browser does not support the video tag</video></div></div></li><li><p>SQL Editor</p><p>No need to install third party SQL tools, you can run queries directly from the Supabase Dashboard.</p><div><div><video src="https://supabase.io/new/videos/tabSqlEditor.mp4" autoplay="" loop="" muted="" playsinline="">Your browser does not support the video tag</video></div></div></li></ul></div></div></div></div></div><div><div id="betaPricing"><div><div><div><p>We're working closely with many open source projects, infrastructure providers, and of course our Alpha Users, to provide a predictable and sustainable pricing model.</p><p>Our key aims going into this exercise were:</p><ul><li>To continue offering free Supabase instances for Students, Hobbyists, and Early Adopters</li><li>To price based on <span>predictable</span> metrics (no shock bills at the end of the month)</li><li>To grow with our users, providing a pricing model that supports their growth and allow them to create value for their customers</li></ul><p>Whilst we're not yet ready to publish a standardized pricing model, we are committing to the following initiatives:</p><ul><li>All Alpha Users will receive credits equivalent of 2 years of base tier usage. These will automatically be credited to your account if you signed up prior to December 2020.</li><li>All Beta Users (new users from December 2020) will receive 1 year of base tier usage for free.</li><li>University (and participating code school) Students will be eligible for 2 years of base tier usage (Code Schools can contact<!-- --> <a href="mailto:rory@supabase.io" target="_blank">rory@supabase.io</a>)</li><li>Early stage startups participating in selected incubator programs can claim additional credits which can be applied to products outside of the base tier.</li></ul><p>The Supabase Base Tier constitutes a Supabase Instance running in a single region, on 2 vCPUs, 1 GiB Memory, with 2 GB of storage, and daily backups.</p></div></div></div></div></div><div><div id="openSource"><div><div><div><p>Great software is multi generational and stretches beyond any single company.</p><p>Supabase is a collection of many projects, and we rely on making contributors to help us build and improve. Because of this, we aim to make open source more accessible and attractive to anyone who wants to contribute.</p><p>Every dollar that is given to Supabase in<!-- --> <a href="https://github.com/sponsors/supabase/" target="_blank">sponsorship</a> <!-- -->will be funneled back to the community to support the next generation of Open Source maintainers.</p><p>One of the biggest barriers to Open Source is knowing exactly how to get started. We're<!-- --> <a href="https://supabase.io/blog/2020/12/02/supabase-striveschool" target="_blank">partnering with Strive School</a> <!-- -->to educate the next generation of programmers in Open Source - providing tutorials, Founder Office Hours, and other free resources.</p><p>If you teach programming, and you're interested in offering OSS tuition to your students, we're actively looking for more education partners. Email<!-- --> <a href="mailto:rory@supabase.io" target="_blank">rory@supabase.io</a> <!-- -->to find out more.</p><p>Come and get involved in<!-- --> <a href="https://github.com/supabase" target="_blank">our GitHub.</a> </p></div></div></div></div></div><div><div id="fundingPartners"><div><div><div><p>Building a platform that can offer all the amazing features of Firebase will take resources - more than most open source tools. Ours will be a long journey and it will require the help of many experienced engineers.</p><p>The partners we choose for this journey must be aligned with our ethos as an open source company. In a few weeks we'll release the full details of our Seed round. Today, we're happy to announce one key partner who needs no introduction: Mozilla.</p><p>Open source is at the very core of what Mozilla do - we're humbled and excited to work with them.</p><p>Follow us on<!-- --> <a href="https://twitter.com/supabase_io" target="_blank">Twitter</a> <!-- -->and we'll let you know when we announce the details of the round.</p></div></div></div></div></div><div><div id="scalingOurTeam"><div><div><div><p>We are extremely proud of our team. We're a mix of 11 engineers, from 8 different countries. Half of the team are previous founders - collectively we've founded 15 companies, generating millions in revenue.</p><p>We're also passionate about tech and open ‚Ä¶</p></div></div></div></div></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supabase.io/beta">https://supabase.io/beta</a></em></p>]]>
            </description>
            <link>https://supabase.io/beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-25289233</guid>
            <pubDate>Thu, 03 Dec 2020 14:40:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS just went multi-cloud]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 136 (<a href="https://news.ycombinator.com/item?id=25289152">thread link</a>) | @dwardu
<br/>
December 3, 2020 | https://acloudguru.com/blog/business/aws-just-went-multi-cloud-and-its-only-the-beginning | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/business/aws-just-went-multi-cloud-and-its-only-the-beginning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p><em>Don‚Äôt forget to&nbsp;<a href="https://get.acloudguru.com/reinvent2020">throw in your email address</a>&nbsp;to get an executive summary in your inbox from ACG each day of re:Invent!</em></p><p>AWS, you sneaky devils.</p><p>Look at the <a href="https://aws.amazon.com/eks/eks-anywhere/faqs/">FAQ for EKS Anywhere</a>, announced yesterday for a 2021 launch, and you‚Äôll find plenty of references to ‚Äúon-premises‚Äù, bare metal compute, and VSphere. AWS‚Äôs stated rationale for expanding access to their managed Kubernetes service is all about hybrid cloud, which traditionally has meant ‚Äúyour old busted servers plus AWS‚Äôs shiny goodness.‚Äù</p><p>But wait ‚Ä¶ EKS Anywhere<em>? </em>Does that really mean <em>anywhere</em>?</p><p>Could it mean ‚Ä¶ Azure?</p><p>Lo and behold, <a href="https://www.protocol.com/aws-multicloud-era">Protocol has obtained confirmation</a> that EKS Anywhere (and technically ECS Anywhere, but let‚Äôs be real, if you want to run on multiple cloud providers you‚Äôre using Kubernetes) <strong>will support workloads running on Azure and GCP as well as private data centers</strong>. AWS is giving you a single pane of glass that will let you roll out config updates, instrument monitoring, and connect other app services to container workloads on your cloud of choice.</p><p>That‚Äôs right: AWS just rolled out a multi-cloud container management service.</p><p>You are now permitted thirty seconds to pick your jaw off the floor.</p><h2 id="h-what-does-aws-gain-from-doing-this">What does AWS gain from doing this?</h2><p>This marks ‚Ä¶ shall we say ‚Ä¶ a bit of a departure from AWS‚Äôs classic ‚Äúone cloud to rule them all‚Äù rhetoric. After all, at various other times in Tuesday‚Äôs re:Invent keynote Andy Jassy unleashed <a href="https://aws.amazon.com/rds/aurora/babelfish/">a frontal assault on Microsoft SQL Server</a>, dunked gleefully on archnemesis-turned-punching-bag Oracle, and found GCP so unthreatening that he closed his presentation, without comment, on a song lyric that used ‚ÄúGoogle‚Äù as a verb.</p><p>And yet multi-cloud is here to stay, and Jassy knows it.</p><p>Check out my recent piece <a href="https://cloudirregular.substack.com/p/aws-hearts-multi-cloud-its-gonna">‚ÄúAWS Hearts Multi-Cloud‚Äù</a> for a full analysis of why, but here‚Äôs the gist. <a href="https://cloudpundit.com/2020/09/18/the-multicloud-gelatinous-cube/"><strong>Multi-cloud is a gravitational inevitability for enterprises</strong></a>. ACG‚Äôs recent <a href="https://acloudguru.com/blog/news/a-cloud-guru-unveils-state-of-cloud-learning-report">State of Cloud Learning Report</a> found that while about 75% of cloud shops still use AWS as their primary cloud provider, the same 75% also have at least some workloads running on Azure or another cloud. Could be due to acquisition, service envy, bet-hedging, or simple lack of coordination ‚Äì or all of the above. Reality is messy and getting more so.</p><p>AWS has a huge head start on the rest of the cloud industry, but 75% of people won‚Äôt think of AWS as their ‚Äúprimary‚Äù cloud provider forever. Not when there are so many best-of-breed services to choose from, both on other clouds and on focused SaaS providers like Snowflake and Datadog. And certainly not given that plenty of industries have active incentive to avoid deep integration with a cloud provider owned by Amazon.</p><p>So AWS has a limited window of opportunity to keep that central status in cloud teams‚Äô hearts. Providing higher-level, cross-cloud management tools is the easiest way to do it. The other cloud providers certainly get this; Azure isn‚Äôt hamstrung by an inability to admit the validity of AWS workloads, and they‚Äôre rushing into the breach with tools like Arc and Sentinel.</p><h2 id="h-this-is-only-the-beginning">This is only the beginning</h2><p>Really, the amazing thing is that AWS spun the ‚ÄúAnywhere‚Äù releases so adroitly, and described them so diffusely, that it took a day to confirm that multi-cloud was really their intent. And they can‚Äôt keep playing both sides much longer. They need to signal to large customers that yes, they get that Azure isn‚Äôt going away, and they‚Äôll provide the tools to continue deserving the status of <em>preferred </em>cloud provider even if they can‚Äôt be the <em>only </em>cloud provider.</p><p>If you think that‚Äôs a bridge too far, you haven‚Äôt been paying attention to what makes AWS tick. I closed my last multi-cloud piece by pointing out that AWS created ECS because they have great engineers; they sell EKS because they are smart. As long as they are willing to cannibalize their own offerings in pursuit of customer value, they will remain hard to beat.</p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">My ears are perking up at <a href="https://twitter.com/ajassy?ref_src=twsrc%5Etfw">@ajassy</a>'s comments about working with third parties, not being afraid of cannibalizing yourself, etc ‚Ä¶ are we revving up to the announcement of AWS's much-ballyhooed multicloud play? <a href="https://twitter.com/hashtag/reinvent?src=hash&amp;ref_src=twsrc%5Etfw">#reinvent</a></p>‚Äî Forrest Brazeal @re:Invent 2020 (@forrestbrazeal) <a href="https://twitter.com/forrestbrazeal/status/1333806720993333250?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote> </div></figure><p>Lo and behold, Jassy echoed the same themes in his keynote. And while he never used the word ‚Äúmulti-cloud‚Äù (not yet!), you can be sure that EKS Anywhere isn‚Äôt a one-off or an accident. It‚Äôs the first glimpse of a massive strategic shift. Because once you realize what yesterday‚Äôs emphasis on ‚Äúhybrid, open-source‚Äù rhetoric really means, it‚Äôs clear that AWS‚Äôs multi-cloud play is just beginning.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/business/aws-just-went-multi-cloud-and-its-only-the-beginning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25289152</guid>
            <pubDate>Thu, 03 Dec 2020 14:32:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CoScreen 1.0 ‚Äì radically different pair/team programming]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25289090">thread link</a>) | @coscreen
<br/>
December 3, 2020 | https://blog.coscreen.co/launch-of-coscreen-1-0-for-macos-private-alpha-for-windows/ | <a href="https://web.archive.org/web/*/https://blog.coscreen.co/launch-of-coscreen-1-0-for-macos-private-alpha-for-windows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Today is as big day for us as we're launching the entirely newly designed &amp; developed 1.0 version of CoScreen for macOS and our private beta for Windows. A big thanks goes out to the hundreds of users who have helped us to iterate over the first versions as part of our private beta over the last 6 months!</p><p><strong>Get CoScreen for free here: <a href="https://coscreen.co/">https://coscreen.co</a></strong></p><p>These early insights and our own internal usage of CoScreen have been instrumental to our code and design reviews, bug fixing, stand-ups, and feature development since the pandemic hit. Now we want more teams to benefit from CoScreen and are therefore offering CoScreen entirely for free for the next six months.</p><blockquote><em>"CoScreen makes coding, pairing and video chatting as easy as a single click while keeping all our existing dev tools."</em><br><strong>M<em>icha√´l Ohayon, Development Manager at Publicis Sapient</em></strong></blockquote><h2 id="the-struggle-of-remote-engineering-teams">The struggle of remote engineering teams</h2><p>Today's video chat solutions are great if you enjoy awkward full-screen conversations, but are a productivity killer for development teams. The pandemic has turned endless, boring in-office meetings into endless, boring video calls. It‚Äôs also just too painful for engineering teams to wrangle with complex pull requests using a brittle string of tools like Zoom, Skype, Tmux, GNU screen, and a variety of IDEs.</p><h2 id="the-solution-coscreen"> The solution: CoScreen</h2><blockquote>"<em>I am full time pairing with a teammate, and CoScreen is the best pairing tool we‚Äôve used so far.‚Äù </em><br><strong>Camille Neuner, Software Engineer at a large insurance provider</strong></blockquote><p>CoScreen is a desktop app that enables multiple users to share application windows with each other at the same time. You can think of it like a shared desktop where any user can interact with any shared window as if it were their own via remote mouse and keyboard to allow them to collaborate like never before (they can even copy and paste code across windows of different users).</p><p>In addition to built-in video chat, and remote control, we're also launching <a href="https://coscreen.co/slack">a Slack integration</a> so that you can embed CoScreen into your daily workflow. Integrations with VS Code and other IDEs will follow soon.</p><p>CoScreen enables pair/mob/team programming like no other solution and we believe it can reduce the <a href="https://blog.rescuetime.com/context-switching">cost of context switching</a> by up to 80% so you can focus on what actually matters - reviewing code, troubleshooting bugs, or building major new features.</p><figure><img src="https://blog.coscreen.co/content/images/2020/09/CoScreen-SevenDegreesOfCollaboration.png" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b7a7fd9f-bf5f-440a-9ec5-7b23b15644bf/Screen_Shot_2020-09-14_at_4.20.50_PM.png" srcset="https://blog.coscreen.co/content/images/size/w600/2020/09/CoScreen-SevenDegreesOfCollaboration.png 600w, https://blog.coscreen.co/content/images/size/w1000/2020/09/CoScreen-SevenDegreesOfCollaboration.png 1000w, https://blog.coscreen.co/content/images/2020/09/CoScreen-SevenDegreesOfCollaboration.png 1323w" sizes="(min-width: 1200px) 1200px"><figcaption>CoScreen introduces the 7th degree of team interactivity through multi-user screen sharing &amp; remote control</figcaption></figure><h2 id="how-coscreen-gives-your-more-control-and-keeps-you-save">How CoScreen gives your more control and keeps you save</h2><p>CoScreen uses P2P whenever you and a second participant can connect directly (e.g. when no corporate firewalls or proxies are between the two of you) so none of your window and control data touches our servers.</p><p>Otherwise, up to a dozen participants can collaborate using our enterprise-grade, HIPAA-compatible video infrastructure with hundreds of servers around the globe that run the awesome open-source framework <a href="https://jitsi.org/">Jitsi</a>. All video data is encrypted using DTLS-SRTP during transmission and in addition, we‚Äôre planning to support end-to-end encryption soon.</p><blockquote><em><em><em>‚ÄúCoScreen makes developing and debugging mobile apps much easier as a team than any other tool we've tried‚Äù</em></em></em><br><em><em><em><strong>Kevin Zhang, Senior Software Engineer at Salesforce</strong></em></em></em></blockquote><p>With the help of UX experts who originally designed Slack, we've also created a new, minimalistic UI that never gets in your way. We're making our new macOS version publicly available today for free. The Windows alpha is already in final internal testing and you can sign up for early access for it and our future Linux and web clients.</p><h3 id="can-t-wait-see-for-yourself-how-coscreen-works-">Can‚Äôt wait? See for yourself how CoScreen works:</h3><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/054wVitjVJ0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>We‚Äôll keep sign-ups open as long as our infrastructure allows and we‚Äôre working hard to support other platforms, offer the best performance in terms of latency and quality (it's already much better than Zoom‚Äôs), and further reduce CPU and memory usage.</p><blockquote><em><em><em>"CoScreen has turned 'meetings' into 'doings.'"</em></em></em><br><em><em><em><strong>Brett Bertola, UX Engineer at InMoment</strong></em></em></em></blockquote><p>Thanks again to everyone who has supported us with feedback and advice. Get the latest release of CoScreen at https://coscreen.co and keep telling us what you think - via the built-in feedback feature in CoScreen or via e-mail to hello@coscreen.co!</p><p><em>Max, Jason, Till &amp; the entire CoScreen team</em></p>
			</section></div>]]>
            </description>
            <link>https://blog.coscreen.co/launch-of-coscreen-1-0-for-macos-private-alpha-for-windows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25289090</guid>
            <pubDate>Thu, 03 Dec 2020 14:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UX, Then Architecture, Then Tools]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25288166">thread link</a>) | @Fiveplus
<br/>
December 3, 2020 | https://morethancoding.com/2013/03/12/ux-then-architecture-then-tools/ | <a href="https://web.archive.org/web/*/https://morethancoding.com/2013/03/12/ux-then-architecture-then-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-805">
	<!-- .entry-header -->

	<div>
		<p>Imagine you are building your dream house. Would you trust a general contractor who talks like this?</p>
<blockquote><p>First, we‚Äôre going to pick out the material for the kitchen counter and the glass for the windows. Let‚Äôs just guess the amounts of each to buy for now.</p>
<p>Then we‚Äôve got to buy some of that new concrete everyone‚Äôs been talking about. I suppose a truckload will do it for now, but we could always order more later. I just can‚Äôt wait to try it out!</p>
<p>After putting the beams in place we should decide how many floors the house should have. And right at the end we should decide what style the house will be. Sometime before you move in we should get planning permission, and I‚Äôll probably contact an architect for some drawings after you‚Äôve settled in.</p></blockquote>
<p>It sounds ludicrous because there‚Äôs a well-established method for building houses, and it‚Äôs based on common sense. You start with a vision, get a set of plans, pour a foundation, build the framework, fill in the internal stuff, and finally finish all the little details.</p>
<p>Putting any step out of order would cause complete chaos. Finishing the walls before the electrical would mean you‚Äôd have to punch holes in all your walls in order to run wires around the house. Cleaning it before it is completely finished would be a wasted effort given the amount of dust builders cause while they work.</p>
<p>However many coders <strong>build their systems backwards</strong>. They become enamored with the latest whizz-bang framework or charmed by the reportedly speedy performance of the newest database. And they lead their thinking with those choices as they build new features, whether those technologies are appropriate or not.</p>
<p>More importantly, using a technology-first design typically means that the user experience (UX) will be left until last. And if you put your users last in your order of priorities, it will unfortunately be very evident in your system‚Äôs lack of usability.</p>
<h3>UX First</h3>
<p>The first order of business in application design is deciding what its users will experience. This should be a high-level vision sketched out on paper or in simple digital mockups, and it should express the flow of the system from the user‚Äôs perspective.</p>
<p>It doesn‚Äôt matter if you‚Äôre building a web application for senior citizens or a system-level tool for serious computing nerds. <strong>The UX must be designed first.</strong></p>
<table>
<tbody>
<tr>
<td>
<p><b>Type of System</b></p>
</td>
<td>
<p><b>Your First Thought Should NOT Be‚Ä¶</b></p>
</td>
<td>
<p><b>Your First Thought SHOULD Be‚Ä¶</b></p>
</td>
</tr>
<tr>
<td>Online music player</td>
<td>‚ÄúI‚Äôm going to design the database schema!‚Äù</td>
<td>‚ÄúLet‚Äôs design the UX‚Äù</td>
</tr>
<tr>
<td>Social media plugin</td>
<td>‚ÄúLet me start hacking around with some online social media APIs!‚Äù</td>
<td>‚ÄúLet‚Äôs design the UX‚Äù</td>
</tr>
<tr>
<td>Multiplayer Game</td>
<td>‚ÄúSuperFastDB is apparently really scalable, I‚Äôll start testing it today!‚Äù</td>
<td>‚ÄúLet‚Äôs design the UX‚Äù</td>
</tr>
<tr>
<td>Virus Checker</td>
<td>‚ÄúI‚Äôve been dying to write a new virus scanning algorithm, so I‚Äôm jumping right into that!‚Äù</td>
<td>‚ÄúLet‚Äôs design the UX‚Äù</td>
</tr>
<tr>
<td>GPS Device</td>
<td>‚ÄúI‚Äôm going to research the latest in OLED technology right away!‚Äù</td>
<td>‚ÄúLet‚Äôs design the UX‚Äù</td>
</tr>
</tbody>
</table>
<h3>Then Comes The Architecture</h3>
<p>Once the UX has been designed and the vision of the system has been defined, an architecture should be laid out to make sure that the code that eventually gets written will actually meet the needs of the users. The choices made in the UX design radically shape and inform a system‚Äôs architecture.</p>
<p>A good UX design will cater for less obvious things that might be part of the overall user experience. A well-written specification might include requirements such as ‚Äúthe overall load time for page loads must be less than 200 msec‚Äù because the designers know the consequences of <a href="http://blog.kissmetrics.com/loading-time/">slow page load speeds</a>. It might also call for close-to-zero downtime, so the architecture might end up requiring a <a href="http://www.informationweek.com/cloud-computing/infrastructure/amazon-outage-multiple-zones-a-smart-str/240009598">multi-datacenter deployment</a>.</p>
<h3>Last But Not Least, The Tools</h3>
<p>Now it‚Äôs finally playtime! Once the UX has been defined and the architecture has been laid out, the process of picking the right technologies, frameworks and libraries can begin. The crucial point is that now the tools are being chosen with the UX and architecture in mind, so any tool that doesn‚Äôt fulfill the needs of either can be quickly disregarded.</p>
<h3>This Does Not Mean ‚ÄúWaterfall‚Äù</h3>
<p>If you think that this design sequence requires an outdated <a href="http://en.wikipedia.org/wiki/Waterfall_model">Waterfall-like</a> approach to accommodate it, think again! This is completely appropriate for <a href="http://en.wikipedia.org/wiki/Agile_software_development">Agile</a> development. The implementation of a whole new product, an <a href="http://agile101.net/2009/08/10/the-difference-between-agile-themes-epics-and-user-stories/">epic</a> or even a single user story should follow the UX -&gt; architecture -&gt; tools sequence. When beginning the development of a product or epic,&nbsp;<a href="http://uxdesign.smashingmagazine.com/2012/11/06/design-spikes-fit-big-picture-ux-agile-development/">spikes</a> should be used to design the UX and the architecture. And individual user stories should include enough details for the engineer to know what the UX for that story should be once it is fully implemented, and the engineer should also estimate enough points to cater for architectural planning to be done once work on that story begins.</p>
<p>Tools are great fun to research and to experiment with. Programmers love discovering new ones and finding ‚ÄúThe Next Big Thing‚Äù in the framework jungle, and having lots of tools at your disposal is wonderful when the time comes to build a system that satisfies the UX and the architecture. Just don‚Äôt begin the entire design process with them. So remember: UX first, then architecture, then tools.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://morethancoding.com/2013/03/12/ux-then-architecture-then-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25288166</guid>
            <pubDate>Thu, 03 Dec 2020 12:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sockets in Your Shell]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25287144">thread link</a>) | @signa11
<br/>
December 3, 2020 | https://who23.github.io/2020/12/03/sockets-in-your-shell.html | <a href="https://web.archive.org/web/*/https://who23.github.io/2020/12/03/sockets-in-your-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Something I learned recently and I thought was <em>amazing</em> - you can create sockets straight from your shell! Well, assuming you use bash or zsh - from some surface level digging, I couldn√¢‚Ç¨‚Ñ¢t find anything for fish.</p>

<p>Here√¢‚Ç¨‚Ñ¢s how it works:</p>

<h2 id="bash">bash</h2>
<p>Bash supports tcp and udp connections out of the box, and does so with an imaginary device in <code>/dev</code>. Enter</p>
<div><div><pre><code><span>$ </span><span>echo</span> <span>"text!"</span> <span>&gt;</span> /dev/<span>$PROTO</span>/<span>$HOST</span>/<span>$PORT</span>
</code></pre></div></div>
<p>And you√¢‚Ç¨‚Ñ¢ll create a connection to <code>HOST:PORT</code>. <code>$PROTO</code> can be <code>tcp</code> or <code>udp</code>. If the connection can√¢‚Ç¨‚Ñ¢t be made, writing to/reading the file will fail.</p>

<p>Along with being easy to access from the terminal, it√¢‚Ç¨‚Ñ¢s <em>very</em> handy for scripts, especially if you don√¢‚Ç¨‚Ñ¢t have <code>nc</code>/<code>telnet</code>. For example, if a local build of a web app runs on port 8000, you can check if it√¢‚Ç¨‚Ñ¢s running with:<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<div><div><pre><code><span>#!/bin/bash</span>
<span>if </span><span>exec </span>3&gt;/dev/tcp/localhost/8000 <span>;</span> <span>then
	</span><span>echo</span> <span>"server up!"</span>
<span>else
	</span><span>echo</span> <span>"server down."</span>
<span>fi</span>
</code></pre></div></div>
<p>And then use that information somewhere else.</p>

<p>If you√¢‚Ç¨‚Ñ¢re unfamiliar, <code>exec</code> without any arguments is used to redirect file descriptors and files. By associating fd 3 with <code>/dev/tcp/localhost/4000</code>, it attempts to create a file there and thus a connection. We use <code>&gt;</code> to open the socket for writing, although we don√¢‚Ç¨‚Ñ¢t need to write anything in this case.</p>

<p>By using <code>&lt;&gt;</code> we can open a file for reading and writing, and use it to create a super simple curl:</p>
<div><div><pre><code><span>#!/bin/bash</span>
<span>exec </span>3&lt;<span>&gt;</span>/dev/tcp/<span>"</span><span>$1</span><span>"</span>/80
<span>echo</span> <span>-e</span> <span>"GET / HTTP/1.1</span><span>\n</span><span>"</span> <span>&gt;</span>&amp;3
<span>cat</span> &lt;&amp;3
</code></pre></div></div>
<div><div><pre><code>$ ./simplecurl www.google.com
HTTP/1.1 200 OK
Date: Thu, 03 Dec 2020 00:57:30 GMT
Expires: -1
....
&lt;google website&gt;
</code></pre></div></div>

<p>I√¢‚Ç¨‚Ñ¢m sure you can see the power of being able to open sockets with bash alone. Go play around with it!</p>

<h2 id="zsh">zsh</h2>
<p>zsh has an external module you can load in order to use it√¢‚Ç¨‚Ñ¢s socket capabilities. It doesn√¢‚Ç¨‚Ñ¢t support udp like bash, but it√¢‚Ç¨‚Ñ¢s more powerful in a few ways!</p>

<p>To load the module, put the following in your <code>.zshrc</code> or run it in your shell:</p>


<p>We now have access to the zsh networking builtin - <code>ztcp</code>!</p>

<p><code>ztcp</code> allows creating connections, like bash, but also allows listening for connections.</p>

<p>Straight from the zsh docs, we can create a connection between two machines with <code>ztcp</code>:</p>

<div><div><pre><code><span># host machine:</span>
ztcp <span>-l</span> 7128
<span>lfd</span><span>=</span><span>$REPLY</span>
ztcp <span>-a</span> <span>$lfd</span>
<span>talkfd</span><span>=</span><span>$REPLY</span>

<span># client machine</span>
ztcp HOST 7128
<span>talkfd</span><span>=</span><span>$REPLY</span>
</code></pre></div></div>

<p>The <code>$REPLY</code> variable here is a file descriptor returned by the last <code>ztcp</code> command, referring to the socket/connection it just created.</p>

<p>So, <code>talkfd</code> on both machines is a file descriptor for talking to the other:</p>
<div><div><pre><code><span># host machine</span>
<span>echo</span> <span>-e</span> <span>"hello!"</span> <span>&gt;</span>&amp;<span>$talkfd</span>

<span># client machine</span>
<span>read</span> <span>-r</span> line &lt;&amp;<span>$talkfd</span><span>;</span> print <span>-r</span> - <span>$line</span>
<span>&gt;</span> hello!
</code></pre></div></div>

<p>Again, there√¢‚Ç¨‚Ñ¢s a lot more you can do, especially with the ability to listen for connections.</p>

<p>Hope this was as interesting to you as it was to me!</p>

<hr>


</div></div>]]>
            </description>
            <link>https://who23.github.io/2020/12/03/sockets-in-your-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25287144</guid>
            <pubDate>Thu, 03 Dec 2020 09:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In-Database Machine Learning [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25285983">thread link</a>) | @redwrasse
<br/>
December 2, 2020 | https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf | <a href="https://web.archive.org/web/*/https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25285983</guid>
            <pubDate>Thu, 03 Dec 2020 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the US Banning Crypto Wallets?]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 112 (<a href="https://news.ycombinator.com/item?id=25283610">thread link</a>) | @mkmccarty3
<br/>
December 2, 2020 | https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5fc557916457125654ede725" data-item-id="5fc557916457125654ede725">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1606768551080" id="item-5fc557916457125654ede725"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_4996"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image-dimensions="834x466" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baa31d106d256baa5ca2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-98c39078cd9c52d11cda"><div><p>Just as Bitcoin was guiding cryptocurrency markets skyward with a renewed push for an all-time high valuation, prices came crashing down without warning.</p><p>Wait ‚Äî <em>was there a warning</em>?</p><p><a href="https://twitter.com/brian_armstrong/status/1331744884856741888">In a tweet</a> with what some deemed suspicious timing, Coinbase CEO Brian Armstrong let loose an alarming rumor. The United States Treasury, with Secretary Mnuchin at the helm, is poised to ban the use of anonymous non-custodial crypto wallets before the year's end.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_22941"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://twitter.com/brian_armstrong/status/1331745659989360640">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image-dimensions="589x256" data-image-focal-point="0.5,0.5" alt="brian armstrong tweet.PNG" data-load="false" data-image-id="5fc6bc78e2dcb1274dd6fb85" data-type="image">
          </p>
        
          </a>
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_23230"><div><p>What is a non-custodial crypto wallet, you ask? Simple ‚Äî any crypto wallet that is self-hosted (i.e., you own and hold the private keys) fits the description.</p><p>So, if you currently use a cold storage wallet like a Ledger Nano S or a software wallet such as MetaMask, you may soon find yourself running afoul of new regulations.</p><p>While this all seems pretty bad for Bitcoin when you consider the sheer amount of people using non-custodial crypto wallet storage, there are a couple silver linings worth considering.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_25472"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image-dimensions="1306x735" data-image-focal-point="0.5,0.5" alt="wallet guide.PNG"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_25761"><div><p>At the core of the rumored regulations is what appears to be a bank-centric push to force all current and future cryptocurrency users toward intermediary platforms.</p><p>What this means for you is, if the rumors are true, you will need to share KYC information (identification data) with exchanges you use before withdrawing or depositing from your self-hosted wallet. This push will make it so your currently anonymous crypto wallet will be inextricably linked to your real-world identity.</p><p>OK ‚Äî so there go crypto wallets, right? You might as well delete your Exodus wallet, shut down the MetaMask, and turn everything over to the bankers lying in wait.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_7734"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baf2ad3e6411922cd0a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_8023"><div><p><strong>Wrong.</strong> Try as they might, there is simply <strong>no way</strong> to enforce data collection on the use of non-custodial wallets. Such regulations appear more symbolic than anything else ‚Äî they might scare newbies looking to enter the market discreetly, but anyone who understands how cryptocurrency storage works, especially when using hardware wallets, knows there are options outside of centralized exchanges.</p><p>Consider the scenario where the US Treasury makes good on their threat to enforce data collection on crypto wallets. Now, Coinbase requires you to KYC your wallet before allowing you to withdraw freshly purchased BTC. What are your options?</p><p>For one thing, you can use a decentralized exchange to trade crypto. Uniswap has already surpassed Coinbase in terms of trading volume ‚Äî if crypto wallets regulations come into play, expect Uniswap to get much more action.</p><p>Moreover, with the push toward DeFi in the cryptocurrency industry, along with endless options for swapping liquidity, the likelihood that centralized exchanges stay relevant gets slimmer every day.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_15299"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6bbd593ad1a48120388ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_15588"><div><p>Satoshi Nakamoto never envisioned cryptocurrency as a way for governments to collect private data. That's why blockchains are built to enable censorship-free financial access.</p><p>As CoinDesk noted <a href="https://www.coindesk.com/crypto-wallet-regulations-industry-pros">in a recent analysis of the situation</a>, there exists a revealing difference in the language used to refer to crypto wallets by regulators and crypto investors.</p><p>Regulators call crypto wallets <em>unhosted wallets,</em> whereas investors refer to them as <em>self-hosted wallets</em>. The difference here is all about privacy ‚Äî crypto users believe in financial independence, freedom from oversight, and digital asset autonomy.</p><p>On the other hand, an unhosted wallet points to the view that such wallets lack hosting ‚Äî a situation that should be remedied by regulation and the cooperation of centralized institutions.</p><p>This seemingly small difference in language does indeed point to a large divide in exactly how each side views the purpose of storing crypto assets.</p><p>As Armstrong noted in his original Twitter thread, the crypto industry has been preparing for this eventuality for at least a few months. In fact, they've known long enough to form a lobby, and have responded to the rumors by sending the US Treasury a plea to leave crypto alone.</p><p>The regulation is expected to come into effect before the year's end, mostly owing to the US election results and the impending changing of the guard. As such, the rush is on for Mnuchin to push through regulations before time is up.</p><p>Does data-collection on self-hosted crypto wallets amount to the US government declaring a ban on cryptocurrency wallets we know them?</p><p><strong>Not really</strong>.</p><p>Moreover, can the government enforce these regulations and push people onto the centralized platforms decentralized blockchains were built to avoid?</p><p>The answer there is clearer: <strong>certainly not.</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_28135"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image-dimensions="1442x669" data-image-focal-point="0.5,0.5" alt="beginners guide to bitcoin cover.png" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>Each of these strategies is simple to implement, even for novice investors, but that doesn‚Äôt mean these strategies aren‚Äôt used by professions.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>

    

    

    <section id="comments-5fc557916457125654ede725">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://blog.shrimpy.io/blog/coinbase-vs-uniswap">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Coinbase vs. Uniswap ‚Äî Which Exchange Is Better?</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-12-02">December 2, 2020</time></p><!--

            Tags

            --><p><span>coinbase, uniswap, review, general, notlatest</span></p><!--

            Comments

            --></div>
        </div>
      </a>
    

    
      <a href="https://blog.shrimpy.io/blog/machine-learning-for-crypto-portfolio-management-case-study-week-30">
        <div>
          <p>Next</p>
          <h4>Machine Learning for Crypto Portfolio Management Case Study: Week 30</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-11-30">November 30, 2020</time></p><!--

            Tags

            --><p><span>data, notlatest, topsection</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283610</guid>
            <pubDate>Thu, 03 Dec 2020 00:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Topology to Classify Labelled Graphs]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25279820">thread link</a>) | @Topolomancer
<br/>
December 2, 2020 | https://bastian.rieck.me/blog/posts/2020/topology_graphs/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/topology_graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I have written at lengths about certain aspects of topological data
analysis, but I have neglected to discuss one of its main applications,
i.e. the classification of graphs. In this post, I will therefore take
you on a quick tour of our ICML paper <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">A Persistent Weisfeiler‚ÄìLehman Procedure for Graph Classification</a>.</p>
<p>Let us assume that we are given a graph with node label information. The
graph could, for instance, be a molecule, whose nodes are atoms such as
carbon or oxygen, and whose edges indicate chemical bonds. The goal
could now be to classify a given molecule into a set of classes, such as
‚Äòtoxic‚Äô, ‚Äòcarcinogen‚Äô, etc. How can we achieve such a classification?
One of the simplest techniques dates back to the 1960s and involves
calculating an <em>iterative fingerprint</em> of the graph! This procedure was
suggested by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler">Boris Weisfeiler</a>
and Andrei Lehman&nbsp;(sometimes also transliterated as ‚ÄòLeman‚Äô) in
their seminal article <a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">The reduction of a graph to canonical form and the
algebra which appears therein</a>.</p>
<p>At its core, the algorithm is an iteration scheme that works like this:</p>
<ol>
<li>For a node $v$, collect its label and the labels of adjacent nodes in
a multiset.</li>
<li>Assign this multiset a new label by hashing it‚Äîwith the proviso
that the hashing function is <a href="https://en.wikipedia.org/wiki/Perfect_hash_function"><em>perfect</em></a>, i.e.
it maps distinct labels to distinct values with no collisions.</li>
<li>Replace all node labels by their multiset hashes.</li>
</ol>
<p>Intuitively, each step of the algorithm accumulates more information
from nodes that are further removed from the current node. The hashed
multiset label is thus an expression of the neighbourhood around
a node‚Äîand after a sufficiently large number of iterations, the
hashed labels will not change any more.</p>
<p>For example, suppose you are dealing with this simple graph&nbsp;(to
prevent confusion of node labels and node IDs, I used <em>colours</em> to
indicate node labels in this example):</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_graph.svg" alt="Weisfeiler--Lehman example graph" height="128"> 
</figure>

</div>
<p>Tabulating the neighbourhood of each node then results in the following
table:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_1.svg" alt="Weisfeiler--Lehman multiset example (before hashing)" height="128"> 
</figure>

</div>
<p>Now for the hashing step. In this example, <em>perfect hashing</em> means
choosing a set of colours that is distinct for every distinct
combination of neighbourhood labels and vertex labels:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_2.svg" alt="Weisfeiler--Lehman multiset example (after hashing)" height="128"> 
</figure>

</div>
<p>Notice how nodes A, B, and G are hashed to the same colour‚Äîbecause
in the first iteration of the algorithm, they cannot be distinguished.
How can we use the information about the hashed labels in a subsequent
comparison task? The answer is lies in <em>counting</em> them in a histogram
vector, which is indexed by the unique labels‚Äîthis is where our
requirement of the perfect hashing function is helpful. For the
previously-shown graph, it looks like this:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_feature_vector.svg" alt="Weisfeiler--Lehman subtree feature vector" height="128"> 
</figure>

</div>
<p>The <em>fingerprint</em> of this graph, according to the first iteration of the
Weisfeiler‚ÄìLehman scheme is therefore $(3, 1, 2, 1)$. Further iterations
just make the feature vector longer&nbsp;(technically, the initial
labels already give rise to a feature vector of counts). This procedure
can now be repeated for higher-order iterations and the resulting
feature vectors can be compared across graphs by evaluating, for
example, their dot product. More formalisations of this idea have
resulted in the very successful <a href="https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf">Weisfeiler‚ÄìLehman Graph
Kernels</a>
publication. This method arguably constitutes the basis for graph neural
networks‚Äîin fact, these networks can be seen as a parametrised
version of the Weisfeiler‚ÄìLehman iteration scheme. But I digress‚Äîif
you are interested in these aspects, please read <a href="https://towardsdatascience.com/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751">Michael Bronstein‚Äôs
article on going beyond graph
isomorphism</a>
for more details.</p>
<p>Now, despite its great practical utility, this feature vector is lacking
some <em>structural</em> information about the graph. It does not know whether
a certain label contributes much to the topological structure of
a graph‚Äîsuch as a ring of carbon atoms would in molecule‚Äîor not. To
this end, we introduced a notion of topological relevance for each node
label! Briefly put, we first developed a distance metric that would
permit us turn any <em>labelled</em> graph into a <em>weighted</em> graph. We then
calculate a persistence barcode, a topological descriptor of the graph.
This descriptor assesses the relevance of a topological feature created
by some node label. We use the topological relevance of each feature as
an additional <em>weight</em> for the previously-shown feature vector. In
essence, labels that contribute a large amount of topological structure
in a graph are assigned a higher weight than labels that only contribute
a meagre amount!</p>
<p>Here is a graphical depiction of our process:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/p_wl_pipeline.svg" alt="Persistent Weisfeiler--Lehman pipeline" height="128"> 
</figure>

</div>
<p>If you want to brush up your understanding of the barcode calculation,
head on over to <a href="https://christian.bock.ml/">Christian‚Äôs website</a>; he has
an <a href="https://christian.bock.ml/posts/persistent_homology">excellent article on persistent
homology</a>.</p>
<p>The neat thing about our approach is that we can easily integrate
information about <em>cycles</em> into the feature vector‚Äîthis is
a functionality that the original Weisfeiler‚ÄìLehman Graph Kernels
Framework lacks. Moreover, these cycles turn out to be crucial in
improving classification performance‚Äîwe get an increase of more than
3% in classification accuracy by considering them in some data sets!</p>
<p>If this has whet your appetite, I invite you to <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">read our
paper</a> or <a href="https://github.com/BorgwardtLab/P-WL">take
a look at the code</a>. If you want
to learn more about graph classification using graph kernels, take
a look at our <a href="https://arxiv.org/abs/2011.03854">recent survey on graph kernels</a>,
which will hopefully be officially announced in time for NeurIPS 2020.
In the best tradition of Fermat, I would very much like to cover the
content of the survey here, but this blog is too small to contain all of
it‚Äîmaybe for a subsequent post?</p>
<p>Until next time!</p>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/topology_graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279820</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A founder‚Äôs guide to understanding users]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25279814">thread link</a>) | @mgadams3
<br/>
December 2, 2020 | https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44 | <a href="https://web.archive.org/web/*/https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="9bcd">Four steps to ensure your customer discovery &amp; development efforts result in great products that solve real customer problems</h2><div><div><div><p><a href="https://medium.com/@mgadams?source=post_page-----c68feaecac44--------------------------------" rel="noopener"><img alt="Mike Adams" src="https://miro.medium.com/fit/c/96/96/1*Myw6S5WzM6_5PfbkyNAwUQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4ad5">When building any technology product, one of the most common pieces of advice is ‚Äútalk to your users.‚Äù</p><p id="cec4">But the default way most of us talk to customers and prospects is unscientific and fraught with confirmation bias, putting us in danger of being lied to and wasting months building something nobody wants.</p><p id="ee5b">I learned this truth the hard way over the past decade founding multiple companies ‚Äî but it wasn‚Äôt until I was working on my <a href="http://grain.co/utm_source=medium" rel="noopener">third startup</a> that I came to understand a better way to actually understand users.</p><p id="a218">When I first started building start-ups a decade ago, I never anticipated how applicable Yoda‚Äôs wisdom about the value of failure would be as a founder.</p><p id="3a5b">When I first started out, we had an idea, turned it into a UI, and hired developers to make it real. After nearly a year and tens of thousands of dollars ‚Äî we launched it.</p><p id="d4d8">Ghost town. Crickets. Nobody wanted what we‚Äôd built.</p><p id="998b">I determined that the missing piece of the puzzle was my <a rel="noopener" href="https://mgadams.com/want-to-learn-to-code-start-with-excel-4f5902fb1b2f?source=collection_home---6------0-----------------------">lack of technical ability</a>, so I enrolled as one of the first dozen students at a now-famous<a href="https://www.hackreactor.com/" rel="noopener"> coding bootcamp</a> and actually got a job as a software engineer at a <a href="http://opentable.com/" rel="noopener">real company</a>.</p><p id="3b53">So surely when I started my <a href="https://twitter.com/missionu?lang=en" rel="noopener">next start-up</a>, this time things would be different. This time we talked to dozens of potential users and industry experts before we built anything. This time it worked. Sort of.</p><p id="d494">Our mission was compelling as we launched to <a href="https://www.inc.com/magazine/201806/leigh-buchanan/missionu-career-training-school.html" rel="noopener">fanfare</a> and raised <a href="https://techcrunch.com/2017/09/14/missionu-raises-8-5m-to-build-an-alternative-one-year-education-program/" rel="noopener">$11.5M</a> within 10 months of founding the company. However, after just two years we were acqui-hired, our investors got their money back, and the product was immediately <a href="https://www.insidehighered.com/digital-learning/article/2018/05/23/missionu-self-styled-alternative-higher-education-closes-after" rel="noopener">shut down</a>.</p><p id="6863">I was gutted, still am TBH.</p><p id="0f28">But with hindsight, I could look back to my original research notes and see I had ignored several fatal warnings. I had listened to what they said ‚Äî exactly as they said it, but I did not realize until much later that I failed to actually understand what they meant.</p><p id="9305">So if I wanted to avoid failing a third time, I needed to figure out what I was missing about how to <em>really</em> understand users.</p><p id="9c98">Marty Cagan, Silicon Valley Product Group founder and former PM at early eBay, says there are ‚Äú<a href="https://svpg.com/the-inconvenient-truth-about-product/" rel="noopener">two inconvenient truths about product</a>.‚Äù</p><p id="b881">Truth #1: <strong>At least half of our ideas are just not going to work</strong>:</p><p id="ed0c">Truth #2: <strong>Even the good ideas take several iterations to become viable.</strong></p><p id="3d8c">My experience has also been that there‚Äôs simply no escaping these inconvenient truths ‚Äî I only wish I would have learned about them sooner.</p><p id="30d3">It doesn‚Äôt matter how smart or experienced we may be, statistically speaking, most of our ideas are simply not going to work. And the successful ones take time and hard work to turn into a real product that gets widely adopted by a market.</p><p id="de93">Your ideas are not nearly as important as your process ‚Äî and the best process starts with understanding what the customers you wish to serve <em>already</em> do to solve their problems today and even more importantly, understanding why.</p><p id="9883">Yet, even as a 3rd time founder, I fell into the trap of ignoring the two inconvenient truths <em>again.</em></p><p id="87c7">Confirmation bias is a hell of a drug.</p><p id="f8b7">When we started <a href="http://grain.co/?utm_source=medium" rel="noopener">grain.co</a> two years ago, we began with a specific product solution in mind, built prototypes, and got feedback from users. They told us they‚Äôd love to use it but after months turning prototypes into a product, few actually did.</p><p id="a400">So we started over from scratch, but this time with a different approach:</p><ol><li id="2be7">Focus on a very specific user type with a very specific job to be done.</li><li id="bb56">Interview dozens of them only to understand how and why they solve their problem today.</li></ol><p id="0128">Our goal was not to validate whether the merit of a specific solution but to observe existing customer behaviors and desires as a means of generating new ideas for potential product solutions.</p><p id="3dec">This is what is known as <strong>generative research</strong>.</p><p id="4699">As you listen to your target market describe what they do today to solve their problems, you can better understand potential customers‚Äô existing incentives, behaviors, and desires in anticipation for how they‚Äôd react to a new solution.</p><p id="331b"><a href="https://twitter.com/robfitz" rel="noopener">Rob Fitzpatrick</a> has famously coined this generative research phase ‚Äú <a href="http://momtestbook.com/" rel="noopener">The Mom Test</a>,‚Äù which is a set of simple rules to ask good questions so that even your Mom can‚Äôt lie to you in her answers to protect your ego.</p><p id="7e65">Generative research questions are focused on understanding existing behavior. For example, here are some questions from an interview guide we used at <a href="http://grain.co/" rel="noopener">Grain</a> to understand how our prospective users already document and share information from live meetings:</p><ul><li id="fcb3">What‚Äôs your current process to document and share information from a video meeting?</li><li id="fa1f">How important is it that the information you document and share is accurate?</li><li id="6568">What measures do you currently take to ensure accuracy of captured information?</li><li id="33f9">What can happen if your documentation is inaccurate?</li><li id="32f3">How often are you in conversations where you don‚Äôt need to document or share anything?</li><li id="cda6">Which types of conversations are the most important for you to document and share?</li></ul><p id="9e72">Be sure to avoid hypothetical questions about what people <em>might</em> do. Don‚Äôt try to validate your future product with questions that begin with ‚Äúwould you use this‚Äù or ‚Äúwhat do you think about the possibility of‚Äù ‚Äî that‚Äôs what we call leading the witness, and it will inevitably bias your data and waste your time building the wrong thing. At this stage, you simply need to observe what users are <em>already doing,</em> not what they might theoretically do.</p><figure><div></div></figure><p id="69d3">I recently connected with <a href="https://twitter.com/robfitz" rel="noopener">Rob</a> where he shared an updated model of 3 ways where users will lie to you if you‚Äôre not careful:</p><ol><li id="afa0">Asking the wrong questions</li><li id="6697">Remembering the wrong thing</li><li id="6a57">Making the wrong decision ‚Äújustified‚Äù by what you think you heard</li></ol><p id="ecb1">Rob and most other researchers suggest asking for permission from their interviewees to record these interviews and take time-annotated notes that will help them to accurately remember and codify behavioral patterns that could eventually help to define <a href="https://www.uxmatters.com/mt/archives/2019/02/the-pitfalls-of-personas-and-advantages-of-jobs-to-be-done.php" rel="noopener">‚Äújobs to be done‚Äù</a> that product, engineering, and design teams can build for with confidence.</p><p id="556d">After gaining insights about the problems your target market faces in generative research, you may be confident enough to test out a specific product solution to see if these users would actually value it.</p><p id="4717">This is the concept behind <strong>evaluative testing</strong>.</p><p id="f326">At this early stage, you want to put an <em>ultra-lightweight implementation </em>of a product solution in front of your target users to see how they react. While the closer to reality your prototype is the better, it doesn‚Äôt need to be a fully functional product yet: designs on paper, prototypes, mock-ups-anything like that will work.</p><p id="b1b0">Your goal at this stage is to get clear qualitative signals that users:</p><ol><li id="9f21">understand the proposed product solution</li><li id="fcda">express unmistakable excitement about the prospect of the product as a superior solution to the status quo</li></ol><p id="2033">Unfortunately, all too many product teams speed through this testing or skip it all together and simply march ahead to engineering and delivery. Depending on the complexity of the market and the problem you‚Äôre trying to solve, this stage could take months or, in some cases, years.</p><p id="d10d">That might sound discouraging and time-consuming, but I know this for certain: the success of your product will be <strong><em>directly proportiona</em>l</strong> to the quality of work done in this initial customer discovery phase. It‚Äôs worth doing it, and it‚Äôs certainly worth doing it well.</p><p id="0fd4">Even if your team creates something that people want, if customers can‚Äôt figure out how to use it, the product is dead in the water. This is why product teams conduct usability testing throughout the build process.</p><p id="ee09">The traditional approach to usability interviews is to set up a test environment, where we watch as a user navigates the product. An interviewer encourages a user to explain what they see, think, and observe. The interviewer also offers prompts for what the user might consider next if they get stuck using the product. Usability issues in the product become self-evident in most of these cases.</p><p id="8825">My friend <a href="https://medium.com/u/b2d49a9606e3?source=post_page-----c68feaecac44--------------------------------" target="_blank" rel="noopener">Behzod Sirjani</a>, has created a framework for conducting usability testing interviews where he recommends asking the participant about their:</p><ol><li id="084d">Expectation (about what will happen)</li><li id="4d83">Reaction (to what happens)</li><li id="64e1">Reflection (on the difference between 1 and 2)</li></ol><figure><div></div></figure><p id="ec98">A less scientific and more agile approach to identifying lower-hanging usability issues is concierge onboarding. In concierge onboarding, someone from your team guides ‚Äî via video call is best ‚Äî new users through setting up the product and answers the questions in real-time. Concierge onboarding helps the team member understand the steps users are asked to take and the ways those steps directly lead to value.</p><figure><div></div></figure><p id="2293">In a recent Zoom call with Behzod, he told me how at Slack it was essential to turn usability interviews into video highlights of moments of user struggle to help his team form a shared understanding of the problem and gain alignment around solutions that will actually work.</p><p id="5379">The best product teams never stop this work of generative and evaluative testing for new features. Even as their initial research and testing turns into a real product, they know the importance of creating a customer discovery and product delivery engine that never stops learning and growing.</p><p id="b7d9">It‚Äôs much more common for product teams to continually learn and discover from their existing users than it is for them to gather insights from completely unbiased non-users. But a balance between the two groups ‚Äî existing and new ‚Äî is ideal. New users can give you a better understanding of your initial product experience, and existing ‚Äúpower users‚Äù can offer you insights that come from living with a product for weeks or months.</p><p id="1af9">Great product teams develop long-standing relationships of trust with their most active users. You‚Äôll often see the people on these teams setting up recurring feedback sessions to gain insight and listen to users‚Äô concerns and ideas. The point of these interviews is to find out what‚Äôs delightful and what‚Äôs frustrating, what‚Äôs there and working well, and ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</a></em></p>]]>
            </description>
            <link>https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279814</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vector 0.11 Release: K8s, ARC, and metrics collection]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25278771">thread link</a>) | @zhs
<br/>
December 2, 2020 | https://vector.dev/releases/0.11.0/ | <a href="https://web.archive.org/web/*/https://vector.dev/releases/0.11.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><li><div><p><a href="https://github.com/timberio/vector/pull/3099" target="_blank" title="View pull request..."><i></i> 3099</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Cleanup `list` command</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3190" target="_blank" title="View pull request..."><i></i> 3190</a></p></div><h4><span title="Filter to 'buffers' changes only">buffers</span><span title="Filter to 'sinks' changes only">sinks</span>Upgrade all VecBuffer sinks to allow setting `max_bytes`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3236" target="_blank" title="View pull request..."><i></i> 3236</a></p></div><h4><span title="Filter to 'socket source' changes only">socket source</span>Add max_length to UDP</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3151" target="_blank" title="View pull request..."><i></i> 3151</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'stdin source' changes only">stdin source</span>Instrument "stdin" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3241" target="_blank" title="View pull request..."><i></i> 3241</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Add received and invalid line events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3278" target="_blank" title="View pull request..."><i></i> 3278</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Provide error context on parse error</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3187" target="_blank" title="View pull request..."><i></i> 3187</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'kafka source' changes only">kafka source</span>Instrument "kafka" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3300" target="_blank" title="View pull request..."><i></i> 3300</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3317" target="_blank" title="View pull request..."><i></i> 3317</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'prometheus source' changes only">prometheus source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3315" target="_blank" title="View pull request..."><i></i> 3315</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'syslog source' changes only">syslog source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3264" target="_blank" title="View pull request..."><i></i> 3264</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'http source' changes only">http source</span>Add internal events for `http` source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3351" target="_blank" title="View pull request..."><i></i> 3351</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Make sourcetype templatable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3254" target="_blank" title="View pull request..."><i></i> 3254</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'statsd source' changes only">statsd source</span>Add events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3345" target="_blank" title="View pull request..."><i></i> 3345</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'docker source' changes only">docker source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3312" target="_blank" title="View pull request..."><i></i> 3312</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'splunk_hec source' changes only">splunk_hec source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/2913" target="_blank" title="View pull request..."><i></i> 2913</a></p></div><h4><span title="Filter to 'data_dog_metrics sink' changes only">data_dog_metrics sink</span>Add DataDog's `distribution` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3327" target="_blank" title="View pull request..."><i></i> 3327</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Add configuration for source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3337" target="_blank" title="View pull request..."><i></i> 3337</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field (#3300)</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3328" target="_blank" title="View pull request..."><i></i> 3328</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Add source configuration to Humio sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3356" target="_blank" title="View pull request..."><i></i> 3356</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logplex source' changes only">logplex source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3417" target="_blank" title="View pull request..."><i></i> 3417</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Add more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3421" target="_blank" title="View pull request..."><i></i> 3421</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'ansi_stripper transform' changes only">ansi_stripper transform</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3419" target="_blank" title="View pull request..."><i></i> 3419</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3418" target="_blank" title="View pull request..."><i></i> 3418</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3439" target="_blank" title="View pull request..."><i></i> 3439</a></p></div><h4><span title="Filter to 'aws_s3 sink' changes only">aws_s3 sink</span>Add additional canned ACLs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3434" target="_blank" title="View pull request..."><i></i> 3434</a></p></div><h4><span title="Filter to 'codecs' changes only">codecs</span><span title="Filter to 'console sink' changes only">console sink</span>Add "text" encoding for metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3436" target="_blank" title="View pull request..."><i></i> 3436</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Even more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3286" target="_blank" title="View pull request..."><i></i> 3286</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Rewrite parser, improve error handlings </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3476" target="_blank" title="View pull request..."><i></i> 3476</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'startup' changes only">startup</span><span title="Filter to 'shutdown' changes only">shutdown</span>Add events for starting, stopping, and reloading</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3502" target="_blank" title="View pull request..."><i></i> 3502</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add Heartbeat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3373" target="_blank" title="View pull request..."><i></i> 3373</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span><span title="Filter to 'compression' changes only">compression</span>Add support for gzip compression</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3475" target="_blank" title="View pull request..."><i></i> 3475</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span>Sync all data before finishing</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3521" target="_blank" title="View pull request..."><i></i> 3521</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3486" target="_blank" title="View pull request..."><i></i> 3486</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket source' changes only">socket source</span>Add and unify events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3523" target="_blank" title="View pull request..."><i></i> 3523</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'regex_parser transform' changes only">regex_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3553" target="_blank" title="View pull request..."><i></i> 3553</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'grok_parser transform' changes only">grok_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3598" target="_blank" title="View pull request..."><i></i> 3598</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add the ability to store pod labels flat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3602" target="_blank" title="View pull request..."><i></i> 3602</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Store pod labels flat by default, remove the switch</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3586" target="_blank" title="View pull request..."><i></i> 3586</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Add `file` label</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3582" target="_blank" title="View pull request..."><i></i> 3582</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add more `main` events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3593" target="_blank" title="View pull request..."><i></i> 3593</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3490" target="_blank" title="View pull request..."><i></i> 3490</a></p></div><h4><span title="Filter to 'wasm transform' changes only">wasm transform</span>Implement some UX improvements for WASM</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3610" target="_blank" title="View pull request..."><i></i> 3610</a></p></div><h4><span title="Filter to 'kuberentes platform' changes only">kuberentes platform</span>Adds new Helm template variable for podsLabels.</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3607" target="_blank" title="View pull request..."><i></i> 3607</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Multiline support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3577" target="_blank" title="View pull request..."><i></i> 3577</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tag_cardinality_limit transform' changes only">tag_cardinality_limit transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3554" target="_blank" title="View pull request..."><i></i> 3554</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'coercer transform' changes only">coercer transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3655" target="_blank" title="View pull request..."><i></i> 3655</a></p></div><h4><span title="Filter to 'http sink' changes only">http sink</span>Increase rate_limit_num to its maximum</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3690" target="_blank" title="View pull request..."><i></i> 3690</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span>Add a new options to control the auto concurrency limiter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3720" target="_blank" title="View pull request..."><i></i> 3720</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Fix TcpEventSent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3730" target="_blank" title="View pull request..."><i></i> 3730</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'swimlanes transform' changes only">swimlanes transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3699" target="_blank" title="View pull request..."><i></i> 3699</a></p></div><h4><span title="Filter to 'socket sink' changes only">socket sink</span>Add IPv6 supports</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3726" target="_blank" title="View pull request..."><i></i> 3726</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3782" target="_blank" title="View pull request..."><i></i> 3782</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Enhance checkpoint errors with file name</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3812" target="_blank" title="View pull request..."><i></i> 3812</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'reduce transform' changes only">reduce transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3809" target="_blank" title="View pull request..."><i></i> 3809</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'dedupe transform' changes only">dedupe transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3807" target="_blank" title="View pull request..."><i></i> 3807</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tokenizer transform' changes only">tokenizer transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3846" target="_blank" title="View pull request..."><i></i> 3846</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Support `summary` statistic</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3725" target="_blank" title="View pull request..."><i></i> 3725</a></p></div><h4><span title="Filter to 'datadog_metrics sink' changes only">datadog_metrics sink</span>Support datadog `distribution` metric </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3850" target="_blank" title="View pull request..."><i></i> 3850</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Regularize internal event messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3824" target="_blank" title="View pull request..."><i></i> 3824</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'security' changes only">security</span>Enable tls by default  for `papertrail` and `datadog_logs` sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3861" target="_blank" title="View pull request..."><i></i> 3861</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Improve retry error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3989" target="_blank" title="View pull request..."><i></i> 3989</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Accept more timestamp patterns in `to_timestamp`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4018" target="_blank" title="View pull request..."><i></i> 4018</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Include container_name in kubernetes_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3833" target="_blank" title="View pull request..."><i></i> 3833</a></p></div><h4><span title="Filter to 'gcp_stackdriver sink' changes only">gcp_stackdriver sink</span>Insert timestamp into stackdriver message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3778" target="_blank" title="View pull request..."><i></i> 3778</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>GraphQL client</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4075" target="_blank" title="View pull request..."><i></i> 4075</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_timestamp` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4090" target="_blank" title="View pull request..."><i></i> 4090</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `contains` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4092" target="_blank" title="View pull request..."><i></i> 4092</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `slice` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4093" target="_blank" title="View pull request..."><i></i> 4093</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `tokenize` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4020" target="_blank" title="View pull request..."><i></i> 4020</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add container_image and pod_node_name annotations</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4034" target="_blank" title="View pull request..."><i></i> 4034</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Emit warning on incomplete UDP sent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4170" target="_blank" title="View pull request..."><i></i> 4170</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `strip_ansi_escape_codes` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4188" target="_blank" title="View pull request..."><i></i> 4188</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha2` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4198" target="_blank" title="View pull request..."><i></i> 4198</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha3` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4215" target="_blank" title="View pull request..."><i></i> 4215</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>add field's value in warn message when failing to parse</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4236" target="_blank" title="View pull request..."><i></i> 4236</a></p></div><h4><span title="Filter to 'docker platform' changes only">docker platform</span>Added distroless-libc and distroless-static docker container bases</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4186" target="_blank" title="View pull request..."><i></i> 4186</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `parse_duration` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4032" target="_blank" title="View pull request..."><i></i> 4032</a></p></div><h4><span title="Filter to 'prometheus sink' changes only">prometheus sink</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4049" target="_blank" title="View pull request..."><i></i> 4049</a></p></div><h4><span title="Filter to 'auth' changes only">auth</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'aws service' changes only">aws service</span>Add EKS Web Identity Support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4191" target="_blank" title="View pull request..."><i></i> 4191</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Initial GraphQL topology</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4288" target="_blank" title="View pull request..."><i></i> 4288</a></p></div><h4><span title="Filter to 'console sink' changes only">console sink</span>Improve error handling</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4220" target="_blank" title="View pull request..."><i></i> 4220</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_number` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4383" target="_blank" title="View pull request..."><i></i> 4383</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Bidirectional source/transform/sink GraphQL types</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4429" target="_blank" title="View pull request..."><i></i> 4429</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Improve error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4412" target="_blank" title="View pull request..."><i></i> 4412</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span><span title="Filter to 'sinks' changes only">sinks</span>Option to specify `quantiles`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4037" target="_blank" title="View pull request..."><i></i> 4037</a></p></div><h4><span title="Filter to 'security' changes only">security</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>add TLS settings to influxdb_logs and influxdb_metrics sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4068" target="_blank" title="View pull request..."><i></i> 4068</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Add a tags configuration options to add user-defined tags</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4544" target="_blank" title="View pull request..."><i></i> 4544</a></p></div><h4><span title="Filter to 'debian platform' changes only">debian platform</span>Add vector user to adm in debian packaging</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/3557" target="_blank" title="View pull request..."><i></i> 3557</a></p></div><h4><span title="Filter to 'statsd sink' changes only">statsd sink</span>Support all socket types in statsd sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3032" target="_blank" title="View pull request..."><i></i> 3032</a></p></div><h4><span title="Filter to 'sinks' changes only">sinks</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'compression' changes only">compression</span>Add compression level</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4182" target="_blank" title="View pull request..."><i></i> 4182</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Allow using custom selectors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4406" target="_blank" title="View pull request..."><i></i> 4406</a></p></div><h4><span title="Filter to 'aws service' changes only">aws service</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'auth' changes only">auth</span>Support assume_role with EKS web identity</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4580" target="_blank" title="View pull request..."><i></i> 4580</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>Rename "identifier_fields" to "group_by"</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4579" target="_blank" title="View pull request..."><i></i> 4579</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>"concat_newline" strategy merges using newline</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4586" target="_blank" title="View pull request..."><i></i> 4586</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Advanced container filtering</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4428" target="_blank" title="View pull request..."><i></i> 4428</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Add `parse_url` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4164" target="_blank" title="View pull request..."><i></i> 4164</a></p></div><h4><span title="Filter to 'datadog_logs sink' changes only">datadog_logs sink</span><span title="Filter to 'networking' changes only">networking</span>Support datadog logs new HTTPS transport</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4385" target="_blank" title="View pull request..."><i></i> 4385</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span><span title="Filter to 'auth' changes only">auth</span>Basic auth support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4174" target="_blank" title="View pull request..."><i></i> 4174</a></p></div><h4><span title="Filter to 'datadog service' changes only">datadog service</span>Added region configuration parameter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4408" target="_blank" title="View pull request..."><i></i> 4408</a></p></div><h4><span title="Filter to 'windows platform' changes only">windows platform</span>Correctly handle service restart</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4557" target="_blank" title="View pull request..."><i></i> 4557</a></p></div><h4><span title="Filter to 'statsd source' changes only">statsd source</span>Add support for all socket types</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4647" target="_blank" title="View pull request..."><i></i> 4647</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'internal_metrics source' changes only">internal_metrics source</span>Updated internal metrics names to match standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4481" target="_blank" title="View pull request..."><i></i> 4481</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logfmt_parser transform' changes only">logfmt_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4701" target="_blank" title="View pull request..."><i></i> 4701</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span><span title="Filter to 'metrics' changes only">metrics</span>Add `namespace` to `Metric` </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4734" target="_blank" title="View pull request..."><i></i> 4734</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Force daemonset to redeploy when configmap is updated</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4581" target="_blank" title="View pull request..."><i></i> 4581</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Topology added/removed GraphQL subscriptions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4652" target="_blank" title="View pull request..."><i></i> 4652</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API host metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4733" target="_blank" title="View pull request..."><i></i> 4733</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span>annotate logs with query parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4751" target="_blank" title="View pull request..."><i></i> 4751</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Expose the performance related parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4735" target="_blank" title="View pull request..."><i></i> 4735</a></p></div><h4><span title="Filter to 'reload' changes only">reload</span>Resolve port conflict in sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4835" target="_blank" title="View pull request..."><i></i> 4835</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Add the ability to set conatiner ports at vector-agent Helm chart</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4480" target="_blank" title="View pull request..."><i></i> 4480</a></p></div><h4><span title="Filter to 'aws_ec2_metadata transform' changes only">aws_ec2_metadata transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4819" target="_blank" title="View pull request..."><i></i> 4819</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Adds optional file output to generator</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4831" target="_blank" title="View pull request..."><i></i> 4831</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add `namespace` option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4859" target="_blank" title="View pull request..."><i></i> 4859</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>display full error chain</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4884" target="_blank" title="View pull request..."><i></i> 4884</a></p></div><h4><span title="Filter to 'logdna sink' changes only">logdna sink</span>Support template syntax in hostname and tags field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4881" target="_blank" title="View pull request..."><i></i> 4881</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Add TLS and authentication options</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4873" target="_blank" title="View pull request..."><i></i> 4873</a></p></div><h4><span title="Filter to 'gcp_pubsub sink' changes only">gcp_pubsub sink</span>Add configurable endpoint</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4928" target="_blank" title="View pull request..."><i></i> 4928</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Kind/type for `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4836" target="_blank" title="View pull request..."><i></i> 4836</a></p></div><h4><span title="Filter to 'journald source' changes only">journald source</span>Restart journalctl on errors, save checkpoint on shutdown</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4998" target="_blank" title="View pull request..."><i></i> 4998</a></p></div><h4><span title="Filter to 'sources' changes only">sources</span>make scrape interval configurable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4945" target="_blank" title="View pull request..."><i></i> 4945</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Humanized formatting for `vector top` metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4958" target="_blank" title="View pull request..."><i></i> 4958</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Batch events processed total</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5002" target="_blank" title="View pull request..."><i></i> 5002</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Added batch subscriptions for component bytes and errors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5004" target="_blank" title="View pull request..."><i></i> 5004</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API batch support + tests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5018" target="_blank" title="View pull request..."><i></i> 5018</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API version + hostname queries</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4887" target="_blank" title="View pull request..."><i></i> 4887</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add PodIPs into Pod Metadata events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4999" target="_blank" title="View pull request..."><i></i> 4999</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>More debug info on more HTTP requests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5026" target="_blank" title="View pull request..."><i></i> 5026</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>add internal option to ignore missing files</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5034" target="_blank" title="View pull request..."><i></i> 5034</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Edited a few vector top error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4902" target="_blank" title="View pull request..."><i></i> 4902</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>compile-time program result type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5008" target="_blank" title="View pull request..."><i></i> 5008</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>support enum variants for function arguments</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5015" target="_blank" title="View pull request..."><i></i> 5015</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>use path arguments for `del` and `only_field` functions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5039" target="_blank" title="View pull request..."><i></i> 5039</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Renamed docker source to docker_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5053" target="_blank" title="View pull request..."><i></i> 5053</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>expressions no longer return an option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5074" target="_blank" title="View pull request..."><i></i> 5074</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Rename `version` -&gt; `versionString` in GraphQL schema</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5056" target="_blank" title="View pull request..."><i></i> 5056</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>undefined path or variable return null</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5016" target="_blank" title="View pull request..."><i></i> 5016</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add I/O (throughput) columns to `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5146" target="_blank" title="View pull request..."><i></i> 5146</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Expire checkpoints</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5153" target="_blank" title="View pull request..."><i></i> 5153</a></p></div><h4><span title="Filter to 'kafka source' changes only">kafka source</span>Include kafka metadata as optional keys</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4918" target="_blank" title="View pull request..."><i></i> 4918</a></p></div><h4><span title="Filter to 'sampler transform' changes only">sampler transform</span>Add rating by `index`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5095" target="_blank" title="View pull request..."><i></i> 5095</a></p></div><h4><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Support basic-auth credentials in endpoint configuation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5171" target="_blank" title="View pull request..."><i></i> 5171</a></p></div><h4><span title="Filter to 'api' changes only">api</span> Allow querying transform outputs on transform components</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4615" target="_blank" title="View pull request..."><i></i> 4615</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span>Expose internal metrics cardinality as a internal metric counter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5218" target="_blank" title="View pull request..."><i></i> 5218</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add test for component links</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5204" target="_blank" title="View pull request..."><i></i> 5204</a></p></div><h4><span title="Filter to 'loki sink' changes only">loki sink</span>Allow tenant_id to be templatable on loki sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5059" target="_blank" title="View pull request..."><i></i> 5059</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>improve arithmetic type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4699" target="_blank" title="View pull request..."><i></i> 4699</a></p></div><h4><span title="Filter to 'mongodb_metrics source' changes only">mongodb_metrics source</span>Renamed mongo metrics to new naming standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4681" target="_blank" title="View pull request..."><i></i> 4681</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `ConnectionOpen` gauge</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4806" target="_blank" title="View pull request..."><i></i> 4806</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sinks</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4833" target="_blank" title="View pull request..."><i></i> 4833</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sources</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4996" target="_blank" title="View pull request..."><i></i> 4996</a></p></div><h4><span title="Filter to 'shutdown' changes only">shutdown</span>Extend `Resource` to sources </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5048" target="_blank" title="View pull request..."><i></i> 5048</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Beautify reports of conflicting `Resource` usage</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5098" target="_blank" title="View pull request..."><i></i> 5098</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>add _total suffix to events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4922" target="_blank" title="View pull request..."><i></i> 4922</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Emit `FileOpen` in `file` sink and source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5183" target="_blank" title="View pull request..."><i></i> 5183</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Incorrect Log Level Message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5005" target="_blank" title="View pull request..."><i></i> 5005</a></p></div><h4><span title="Filter to 'config' changes only">config</span>Allow JSON and YAML config formats in addition to TOML</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5296" target="_blank" title="View pull request..."><i></i> 5296</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Enable TLS subscription connections in vector top</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5021" target="_blank" title="View pull request..."><i></i> 5021</a></p></div><h4><span title="Filter to 'pulsar sink' changes only">pulsar sink</span>introduce encoding schema and pulsar avro schema</h4></li></div></div>]]>
            </description>
            <link>https://vector.dev/releases/0.11.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278771</guid>
            <pubDate>Wed, 02 Dec 2020 17:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Materialize Raises a $32M Series B]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25277511">thread link</a>) | @austinbirch
<br/>
December 2, 2020 | https://materialize.com/materialize-series-b/ | <a href="https://web.archive.org/web/*/https://materialize.com/materialize-series-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today we <a href="https://www.prnewswire.com/news-releases/materialize-raises-40-million-to-simplify-streaming-data-with-sql-and-speed-up-real-time-analytics-301180777.html">announced</a> that we raised a $32M Series B round of funding led by Kleiner Perkins. This follows a $8.5m Series A last year led by Lightspeed Venture Partners, bringing our total funding to-date to a little over $40 million. With our Series B, <a href="https://www.kleinerperkins.com/people/bucky-moore/" target="_blank" rel="noopener noreferrer">Bucky Moore</a> joins <a href="https://lsvp.com/?team=ravi-mhatre/" target="_blank" rel="noopener noreferrer">Ravi Mhatre</a> on our board of directors.</p>
<p>At Materialize, we believe that at every business it will soon be essential for all information to be always up-to-date. Whether it‚Äôs delivering personalized experiences, accurately identifying fraud, building predictive AI, or discovering new business opportunities, the ability to run complex queries on multiple streams of data and keep their answers up to date is critical to making better decisions about the changing world around us.</p>
<p>While the past decade has seen a groundswell in the adoption of streaming platforms, they are still too difficult to use. Current systems require users to make tradeoffs between dumbing down their queries, waiting for hours-long batch ETL pipelines to finish, or building and orchestrating sprawling microservices. We believe users should not have to make these tradeoffs.</p>
<p>Materialize‚Äôs mission is to make queries against streaming data simple. We support industry standard SQL: write queries with multi-way joins, correlated subqueries, and complex aggregations, and we‚Äôll keep the answers always up to date for you. In a world where ‚Äúreal-time‚Äù has become an empty buzzword, Materialize provides answers that are up to date within milliseconds. All of this comes in <a href="https://materialize.com/docs/install/" target="_blank" rel="noopener noreferrer">a single binary</a> that is easy to install, easy to use, and easy to deploy. With Materialize, users can get interactive and always-up-to-date answers about their changing data using only their existing SQL skills.</p>
<p>While Materialize is a young company, it is built on top of the award winning Timely Dataflow project, spanning almost a decade of cutting-edge research on stream processing led by my co-founder Frank McSherry. Starting from this solid foundation, $40 million dollars of capital gives us the resources to build the no-compromise streaming database that lets every developer build streaming applications.</p>
<p>With this new round of funding, we are well equipped to deliver on <a href="https://materialize.com/blog-roadmap/" target="_blank" rel="noopener noreferrer">an ambitious roadmap</a>, including a fully-managed cloud service with tiered storage and replication. We‚Äôre also excited to continue work on broadening the suite of SQL tools that we support, as well as investing in a SQL optimizer, performance and benchmarking work, and in making Materialize more resilient and battle-tested. If you‚Äôre interested in working on any of these challenges, Materialize <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">is hiring</a> across the board.</p>
<p>And finally, while it is exciting to build Materialize, it has been even more exciting to see how Materialize is being used to build applications that previously would have required months of development, using just a few simple SQL queries. If you‚Äôre as excited about Materialize as we are, we‚Äôd love for you to get involved. <a href="https://materialize.com/quickstart/" target="_blank" rel="noopener noreferrer">Download</a> and try Materialize, try <a href="https://materialize.com/docs/katacoda/?intro-wikipedia" target="_blank" rel="noopener noreferrer">a demo</a> in your browser, <a href="https://join.slack.com/t/materializecommunity/shared_invite/zt-jjwe1t45-klG9k7V7xibdtqA6bcFpyQ" target="_blank" rel="noopener noreferrer">join the community</a> and say hello, or <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">apply</a> to join our growing team today!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/materialize-series-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277511</guid>
            <pubDate>Wed, 02 Dec 2020 15:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rga: Ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz]]>
            </title>
            <description>
<![CDATA[
Score 671 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25277280">thread link</a>) | @angrygoat
<br/>
December 2, 2020 | https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/ | <a href="https://web.archive.org/web/*/https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small><time datetime="2019-06-16T00:00:00.000Z">Jun 16, 2019</time> ‚Ä¢ <a href="https://github.com/phiresky/blog/commits/master/posts/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg.md">Last Update <time datetime="2019-06-16T00:00:00.000Z">Oct 21, 2019</time></a></small></p><p><a href="https://github.com/phiresky/ripgrep-all">rga</a> is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and enables it to search in pdf, docx, sqlite, jpg, zip, tar.*, movie subtitles (mkv, mp4), etc.</p><p><a href="https://github.com/phiresky/ripgrep-all"><img src="https://img.shields.io/badge/repo-github.com%2Fphiresky%2Fripgrep--all-informational.svg" title=""></a>
<a href="https://crates.io/crates/ripgrep-all"><img src="https://img.shields.io/crates/v/ripgrep-all.svg" title=""></a>
<a href="https://www.reddit.com/r/rustjerk/top/?sort=top&amp;t=all"><img src="https://img.shields.io/badge/concurrency-fearless-success.svg" title=""></a></p><h2 id="examples">Examples</h2><h3 id="pdfs">PDFs</h3><p>Say you have a large folder of papers or lecture slides, and you can‚Äôt remember which one of them mentioned <code>GRU</code>s. With rga, you can just run this:</p><div><pre>~$ rga "GRU" slides/
<span>slides/2016/winter1516_lecture14.pdf</span>
Page 34:   <span></span><span>GRU</span>                            LSTM
Page 35:   <span></span><span>GRU</span>                            CONV
Page 38:     - Try out <span></span><span>GRU</span>-RCN! (imo best model)

<span>slides/2018/cs231n_2018_ds08.pdf</span>
Page  3: ‚óè   CNNs, GANs, RNNs, LSTMs, <span></span><span>GRU</span>
Page 35: ‚óè 1) temporal pooling 2) RNN (e.g. LSTM, <span></span><span>GRU</span>)

<span>slides/2019/cs231n_2019_lecture10.pdf</span>
Page 103:   <span></span><span>GRU</span> [Learning phrase representations using rnn
Page 105:    - Common to use LSTM or <span></span><span>GRU</span>

</pre></div><p>and it will recursively find a string in pdfs, including if some of them are zipped up.</p><p>You can do mostly the same thing with <a href="https://pdfgrep.org/"><code>pdfgrep -r</code></a>, but you will miss content in other file types and it will be much slower:</p><div><p>Searching in 65 pdfs with 93 slides each</p><div><div><svg width="600" height="200" viewBox="0 0 600 200" version="1.1"><defs><clipPath id="recharts2-clip"><rect x="105" y="5" height="160" width="490"></rect></clipPath></defs><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="165" x2="595" y2="165"></line><g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="171" x2="105" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="105" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="105" dy="0.71em">0</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="227.5" y1="171" x2="227.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="227.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="227.5" dy="0.71em">5</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="350" y1="171" x2="350" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="350" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="350" dy="0.71em">10</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="472.5" y1="171" x2="472.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="472.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="472.5" dy="0.71em">15</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="595" y1="171" x2="595" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="595" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="595" dy="0.71em">20</tspan></text></g></g></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="105" y1="5" x2="105" y2="165"></line><g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="31.666666666666668" x2="105" y2="31.666666666666668"></line><text type="category" width="100" orientation="left" height="160" x="97" y="31.666666666666668" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">pdfgrep</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="85" x2="105" y2="85"></line><text type="category" width="100" orientation="left" height="160" x="97" y="85" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (first run)</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="138.33333333333334" x2="105" y2="138.33333333333334"></line><text type="category" width="100" orientation="left" height="160" x="97" y="138.33333333333334" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (subsequent runs)</tspan></text></g></g></g><g><g><g><path name="pdfgrep" fill="#8884d8" width="469.41999999999996" height="42" x="105" y="10.333333333333334" radius="0" d="M 105,10.333333333333334 h 469.41999999999996 v 42 h -469.41999999999996 Z"></path></g><g><path name="rga (first run)" fill="#8884d8" width="72.27500000000003" height="42" x="105" y="63.66666666666667" radius="0" d="M 105,63.66666666666667 h 72.27500000000003 v 42 h -72.27500000000003 Z"></path></g><g><path name="rga (subsequent runs)" fill="#8884d8" width="2.2539999999999907" height="42" x="105" y="117" radius="0" d="M 105,117 h 2.2539999999999907 v 42 h -2.2539999999999907 Z"></path></g></g></g></svg><div><ul><li><svg width="14" height="14" style="display:inline-block;vertical-align:middle;margin-right:4px" viewBox="0 0 32 32" version="1.1"><path stroke="none" fill="#8884d8" d="M0,4h32v24h-32z"></path></svg><span>run time (seconds, lower is better)</span></li></ul></div></div></div></div><p>On the first run rga is mostly faster because of multithreading, but on subsequent runs (with the same files but any regex query) rga will cache the text extraction, so it becomes almost as fast as searching in plain text files. All runs were done with a warm FS cache.</p><h3 id="other-files">Other files</h3><p>rga will recursively descend into archives and match text in every file type it knows.</p><p>Here is an example directory with different file types:</p><pre><code>demo
‚îú‚îÄ‚îÄ greeting.mkv
‚îú‚îÄ‚îÄ hello.odt
‚îú‚îÄ‚îÄ hello.sqlite3
‚îî‚îÄ‚îÄ somearchive.zip
    ‚îú‚îÄ‚îÄ dir
    ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ greeting.docx
    ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ inner.tar.gz
    ‚îÇ&nbsp;&nbsp;     ‚îî‚îÄ‚îÄ greeting.pdf
    ‚îî‚îÄ‚îÄ greeting.epub</code></pre><p>(see the actual directory <a href="https://github.com/phiresky/ripgrep-all/tree/master/exampledir/demo">here</a>)</p><div><pre>~$ rga "hello" demo/

<span>demo/greeting.mkv</span>
metadata: chapters.chapter.0.tags.title="Chapter 1: <span></span><span>Hello</span>"
00:08.398 --&gt; 00:11.758: <span></span><span>Hello</span> from a movie!

<span>demo/hello.odt</span>
<span></span><span>Hello</span> from an OpenDocument file!

<span>demo/hello.sqlite3</span>
tbl: greeting='<span></span><span>hello</span>', from='sqlite database!'

<span>demo/somearchive.zip</span>
dir/greeting.docx: <span></span><span>Hello</span> from a MS Office document!
dir/inner.tar.gz: greeting.pdf: Page 1: <span></span><span>Hello</span> from a PDF!
greeting.epub: <span></span><span>Hello</span> from an E-Book!
</pre></div><p>It can even search jpg / png images and scanned pdfs using OCR, though this is disabled by default since it is not useful that often and pretty slow.</p><div><pre>~$ # find screenshot of crates.io
~$ rga crates ~/screenshots --rga-adapters=+pdfpages,tesseract
<span>screenshots/2019-06-14-19-01-10.png</span>
<span></span><span>crates</span>.io I Browse All <span></span><span>Crates</span>  Docs v
Documentation Repository Dependent <span></span><span>crates</span>

~$ # there it is!
</pre></div><h2 id="setup">Setup</h2><p>Linux, Windows and OSX binaries are available in GitHub releases. See <a href="https://github.com/phiresky/ripgrep-all#installation">the readme</a> for more information.</p><p>For Arch Linux, I have packaged <code>rga</code> in the AUR: <a href="https://aur.archlinux.org/packages/ripgrep-all/"><code>yay -S ripgrep-all</code></a></p><h2 id="technical-details">Technical details</h2><p>The code and a few more details are here: <a href="https://github.com/phiresky/ripgrep-all">https://github.com/phiresky/ripgrep-all</a></p><p><code>rga</code> simply runs ripgrep (<code>rg</code>) with some options set, especially <code>--pre=rga-preproc</code> and <code>--pre-glob</code>.</p><p><code>rga-preproc [fname]</code> will match an <span>"<!-- -->adapter<!-- -->"</span> to the given file based on either it‚Äôs filename or it‚Äôs mime type (if <code>--rga-accurate</code> is given). You can see all adapters currently included in <a href="https://github.com/phiresky/ripgrep-all/tree/master/src/adapters">src/adapters</a>.</p><p>Some rga adapters run external binaries to do the actual work (such as pandoc or ffmpeg), usually by writing to stdin and reading from stdout. Others use a Rust library or bindings to achieve the same effect (like sqlite or zip).</p><p>To read archives, the <code>zip</code> and <code>tar</code> libraries are used, which work fully in a streaming fashion - this means that the RAM usage is low and no data is ever actually extracted to disk!</p><p>Most adapters read the files from a <a href="https://doc.rust-lang.org/std/io/trait.Read.html">Read</a>, so they work completely on streamed data (that can come from anywhere including within nested archives).</p><p>During the extraction, rga-preproc will compress the data with ZSTD to a memory cache while simultaneously writing it uncompressed to stdout. After completion, if the memory cache is smaller than 2MByte, it is written to a <a href="https://docs.rs/rkv/0.9.6/rkv/">rkv</a> cache. The cache is keyed by (adapter, filename, mtime), so if a file changes it‚Äôs content is extracted again.</p><h2 id="future-work">Future Work</h2><ul><li>I wanted to add a photograph adapter (based on object classification / detection) for fun, so you can grep for <span>"<!-- -->mountain<!-- -->"</span> and it will show pictures of mountains, like in Google Photos. It worked with <a href="https://pjreddie.com/darknet/yolo/">YOLO</a>, but something more useful and state-of-the art <a href="https://github.com/aimagelab/show-control-and-tell">like this</a> proved very hard to integrate.</li><li>7z adapter (couldn‚Äôt find a nice to use Rust library with streaming)</li><li>Allow per-adapter configuration options (probably via env (RGA_ADAPTERXYZ_CONF=json))</li><li>Maybe use a different disk kv-store as a cache instead of rkv, because I had some <a href="https://github.com/phiresky/ripgrep-all/blob/05835c1c42bc3575023a81e5494c5530078730fc/src/preproc_cache.rs#L30">weird problems</a> with that. SQLite is great. All other Rust alternatives I could find don‚Äôt allow writing from multiple processes.</li><li>Tests!</li><li>There‚Äôs some more (mostly technical) todos in the code I don‚Äôt know how to fix. Help wanted.</li><li>Other <a href="https://github.com/phiresky/ripgrep-all/issues">open issues</a></li></ul><ul><li><a href="https://pdfgrep.org/">pdfgrep</a></li><li><a href="https://gist.github.com/phiresky/5025490526ba70663ab3b8af6c40a8db">this gist</a> has my proof of concept version of a caching extractor to use ripgrep as a replacement for pdfgrep.</li><li><a href="https://gist.github.com/ColonolBuendia/314826e37ec35c616d70506c38dc65aa">this gist</a> is a more extensive preprocessing script by <a href="https://github.com/ColonolBuendia">@ColonolBuendia</a></li><li><a href="https://github.com/wofr06/lesspipe">lesspipe</a> is a tool to make <code>less</code> work with many different file types. Different usecase, but similar in what it does.</li></ul></div></div>]]>
            </description>
            <link>https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277280</guid>
            <pubDate>Wed, 02 Dec 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Netflix]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 98 (<a href="https://news.ycombinator.com/item?id=25277041">thread link</a>) | @leopold_a
<br/>
December 2, 2020 | https://www.forourposterity.com/against-netflix/ | <a href="https://web.archive.org/web/*/https://www.forourposterity.com/against-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It has become fashionable to lambast big tech corporations and social media sites, the Facebooks and Twitters and Googles, blaming them for a litany of social ills. Seemingly escaping this ire has been the‚Äîin my view‚Äîmost pernicious by far: Netflix.</p><p>Simply put, Netflix (and its imitators) produce too many TV shows that are too good‚Äîand too easy to binge. Consequently, too many great minds spend their time watching TV rather than thinking and inventing and creating.</p><h2 id="the-greatness-we-lose">The Greatness We Lose</h2><p>Consider the writer Matthew Yglesias. He just wrote an excellent <a href="https://www.amazon.com/One-Billion-Americans-Thinking-Bigger/dp/0593190211/">book</a>, which partially inspired my <a href="https://www.forourposterity.com/canada-and-mexico-should-join-the-union/">last post</a>. Recently, Yglesias <a href="https://web.archive.org/web/20200912220900/https://twitter.com/mattyglesias/status/1304904789055156225">tweeted</a>:</p><blockquote>Someone asked ‚Ä¶ ‚Äúhow‚Äôd you get this book written without taking time off work?‚Äù and the dumb boring answer was basically ‚Äúdidn‚Äôt watch much TV for six months.‚Äù</blockquote><p>He adds,</p><blockquote>I am perfectly aware that the difference between times when I‚Äôm most productive &amp; creative and times when I‚Äôm not is how much of the week I waste on watching television, yet tonight I‚Äôm almost certainly going to finish season two of Hannibal.</blockquote><p>Yglesias, turn off the TV! Write more books instead! Heck, write more tweets, if you prefer!</p><p>Just think of all the original ideas Yglesias could be contributing if he continued to abstain from watching TV. Of them we are being robbed. That is an epic <a href="https://applieddivinitystudies.com/murder-of-wilbur/">tragedy</a>.</p><h2 id="why-modern-tv-is-different">Why Modern TV Is Different</h2><p>I don‚Äôt mean to pick on Yglesias. In fact, I don‚Äôt blame him. Modern shows are just too good. As a result, it‚Äôs become accepted‚Äîeven the norm‚Äîamong elite, educated classes to watch inordinate amounts of TV.</p><p>Modern shows are different from classic TV in two key ways. First, they are much more engrossing. Netflix shows are just on a different level in terms of quality than what TV once offered. Second, they are bingeable. Instead of tuning in for an hour each week, Netflix encourages viewers to enter the dark hole of watching episode after episode after episode. This becomes a vicious cycle. Viewers binge late into the night, lose sleep, and then don‚Äôt feel energetic enough to do much in their free time the next day besides‚Ä¶watching more Netflix.</p><p>Movies were always pretty engrossing. But the boundless quantity of content on Netflix‚Äîas well as their deliberate addictiveness‚Äîputs it on a different level.</p><p>To be sure, the broad America public has always watched <a href="https://www.theatlantic.com/technology/archive/2018/05/when-did-tv-watching-peak/561464/">extraordinary amounts</a> of television, in particular retirees. For them, the improved quality of modern shows is surely an upgrade. But I do think Netflix has distinctly changed the culture around TV among the young and educated.</p><p>As an undergraduate at Columbia, it was extremely common for students to spend much of their free time engorging themselves on Netflix. Many were caught in that maelstrom of bingeing, losing sleep, and then bingeing more. What was most shocking was this practice‚Äôs sheer acceptability. Watching dozens of hours of Netflix a week wasn‚Äôt something out of the ordinary, something people were embarrassed by. Rather, Netflix bingeing was a core part of the culture, something people would make countless memes about and base their identities on. Amazingly, people‚Äôs chief complaint was often that they had exhausted all of Netflix‚Äôs content (how do you even do that?!).</p><p>Yglesias got his start blogging in college. Would the next Yglesias be able to do the same? Or would his free time and energy instead be sucked up by the latest, ever-more addictive Netflix show? What a loss for civilization that would be.</p><h2 id="for-a-new-temperance-movement">For a New Temperance Movement</h2><p>Again, I don‚Äôt blame the students. I am victim to the same human follies. But I do blame the culture we have created. We don‚Äôt tell our bright young minds that it‚Äôs alright to waste away your days drinking or abusing drugs. Sure, some end up doing so regardless, but the cultural tabu keeps those impulses in check. Why do we tell them it‚Äôs alright to waste away your days watching Netflix?</p><p>Indeed, there has been considerable pushback against video games, which for some are a similar time suck. While many still struggle, this cultural pushback has kept video games in check. At least among the educated classes, Netflix and its imitators have become the far greater time suck.</p><p>For those who can enjoy TV in moderation‚Äîgreat. Modern shows are often meaningful art worth appreciating. The problem with modern TV is that for many, it is closer to alcoholism than a one-off drink. One you watch that first episode‚Äîtake that first drink‚Äîit often doesn‚Äôt stay at one episode‚Äîas it doesn‚Äôt stay at one drink.</p><p>Perhaps it is time for a modern TV-temperance movement. It would be worth encouraging moderation in TV consumption in general. But given that many TV habits resemble alcoholism, it may be appropriate to take a more radical approach: advocating TV-abstinence. Although complete avoidance of TV may be difficult at first, once it becomes a habit, I think most wouldn‚Äôt miss much. But they would enjoy an abundance of reclaimed time and energy. And the rest of us would enjoy the wonderful works they create with that newfound time and energy.</p><h2 id="brains-in-vats">Brains in Vats</h2><p>The culture we establish around Netflix matters not just for the present, but for what comes next. As entertainment technology relentlessly advances, are we destined to become brains in vats, nominally pumped full of artificial bliss but doomed to lives of passivity and complacency?</p><p>Look, if that‚Äôs what the Europeans want to do, they should go for it. But part of what makes America special is a certain harshness‚Äîfirst embodied in the Puritans and their quest to settle America‚Äôs unforgiving wilderness. Great achievements, new ideas, ingenious inventions emerge from a culture that prizes travail and perseverance, not one that prioritizes comfort and ephemeral satisfaction.</p><p>A blithe acceptance of Netflix has insidiously infiltrated our culture. We should push back. Let‚Äôs look to the stars, not the next episode.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to For Our Posterity</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
              <h2><span id="cove-count"></span> Comments</h2>

    <p>Sign in or become a For Our Posterity member to join the conversation.<br>
    Just enter your email below to get a log in link.</p>
    

  


  


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.forourposterity.com/against-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277041</guid>
            <pubDate>Wed, 02 Dec 2020 15:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Escape the Modern Rat Race]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25276844">thread link</a>) | @durmonski
<br/>
December 2, 2020 | https://durmonski.com/psychology/escape-the-modern-rat-race/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/escape-the-modern-rat-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2020-11-30T06:06:37+00:00">30/11/2020</time></p>
<p><em>The worst thing about our modern culture is the growing ignorance towards what‚Äôs really valuable in the world. From an early age, we join a long-distance rat race where the competition is measured not by who we are, but by what we own. Therefore, the desire for material possessions and attention from our peers become our chief goals. Survival, it seems to us, is based on how well we portray our qualities to the outside world ‚Äì even if we don‚Äôt necessarily possess them.</em></p>



<p>Living a normal life according to our society, even if we don‚Äôt always admit it, is tightly connected to the acquisition of funds. One of the most talked-about traits promoted by institutions regardless of our location is the value of money. Of course, this is not directly mentioned by the media outlets or by our neighbors, it‚Äôs beautifully camouflaged by what money can buy.</p>



<p>As soon as we understand that all breathing humans worship money and stuff, the sooner we start to desire <a href="https://durmonski.com/psychology/why-we-hate-cheap-things/" target="_blank" aria-label="luxury items (opens in a new tab)" rel="noreferrer noopener">luxury items</a>. Not so much because they are useful, but because these fancy goods make us look like we are more.</p>



<p>And so it happens, that directly after we come into being, these values and principles get embedded in our brains and later influence our decisions. We want better and more beautiful things. But most of all, we want others to <em>see</em> that we actually own these marvelous objects.</p>



<p>This game of competitive signaling has become unbearable only recently. When the number of available choices vastly increased and the way we communicate with others (compare ourselves with them) significantly improved.</p>



<p>In this post, we‚Äôll look at why we‚Äôre stuck in this competitive rat race. Why the desire to acquire new things is never tamed and what we can do about it. </p>



<p>By bringing awareness to the problems, I want to liberate more people from the destructive components of this never-ending race to the bottom.</p>







<h2>What is Rat Race Life?</h2>



<p>A modern rat race categorizes as an endless pursuit ‚Äì often quite exhausting ‚Äì where you earn small rewards by conspicuous behavior reinforced by acquiring more financial gains or possessions ‚Äì or both. However, these gains never feel satisfactory enough. As new things constantly appear on the horizon ‚Äì new products and new competitors who are also part of the race ‚Äì the only way we can stay ahead of the curve is by constantly investing resources in this rivalry.</p>



<p>In a way, participating in this vain competition is required. After all, our survival is tightly related to the tools, the resources we personally own, plus the relationship we form with others. That‚Äôs why we stay devoted to the race ‚Äì because deep inside, our genes are focused on survival and replication.</p>



<p>That‚Äôs the general concept of the modern rat race. Or in the words of Tyler Durden, the protagonist in the masterpiece Fight Club, ‚ÄúWe buy things we don‚Äôt need with money we don‚Äôt have to impress people we don‚Äôt like.‚Äù But to really grasp the reasons we commit to a life of struggle over resources, we need to go a step deeper.</p>



<p>Let‚Äôs unpack the modern rat race ideology further‚Ä¶</p>







<h2>Why and How The Rat Race Was Formed?</h2>



<p>The first reference of the expression rat race was used in the 1930s during aviation training. As stated by Popular Science magazine in 1941, ‚ÄòA rat race is ‚Ä¶ a simple game of ‚Äúfollow the leader.'‚Äù<span id="easy-footnote-1-12306"></span><span><a href="#easy-footnote-bottom-1-12306" title="&amp;#8220;<a aria-label=&quot;Rat-race (opens in a new tab)&quot; rel=&quot;noreferrer noopener nofollow&quot; href=&quot;https://www.etymonline.com/search?q=rat+race&quot; target=&quot;_blank&quot; class=&quot;ek-link&quot;>Rat-race</a>&amp;#8220;. Online Etymology Dictionary."><sup>1</sup></a></span> Or in other words, the expression meant that the trainee fighter pilot had to copy all the actions performed by the senior pilot. </p>



<p>A decade later, the term changed its original meaning.</p>



<p>Nowadays, the expression is more closely related to how we live our lives day by day. We don‚Äôt simply ‚Äúfollow the leaders‚Äù, we compete with them. We want to be like them. To have what they have and to eventually beat them in the game of resources.</p>



<p>This fierce rivalry for wealth is inspired and fueled by three main motivators:</p>







<h3>1. The Genes Want to Survive</h3>



<p>We, our actions, are highly influenced by the desires of the microorganisms that form our bodies ‚Äì our genes. According to Richard Dawkins, the author of <a aria-label="The Selfish Gene (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/the-selfish-gene/" target="_blank">The Selfish Gene</a>, ‚Äúthe main goal of the body is to propagate copies of the genes which ride inside it.‚Äù To achieve this feat, the body is required to strictly follow two commands: survive and replicate.</p>



<p>There is nothing more important for the genes. We live to live another day and to copy ourselves.</p>







<h3>2. Universal Recognition of Money</h3>



<p>Different religions exist in different countries but we are all loyal to one and only lord ‚Äì the money lord. Or as Yuval Noah Harari writes in his bestseller, <a aria-label="Sapiens (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/sapiens-a-brief-history-of-humankind/" target="_blank">Sapiens</a>, ‚ÄúMoney is the most universal and most efficient system of mutual trust ever devised.‚Äù</p>



<p>During the years of our existence, we form a love-hate relationship with money. On the one hand, we hate it when we see people who are willing to do whatever it takes to earn more and to gain more power. We have movies, literature, songs, and words that mock the aggressive pursuit of more cash.</p>



<p>On the other hand, however, we adequately recognize the need for this resource. Since money is the currency that can literally save our lives from misery and decay, we have no other choice but to obey some sort of rules to gain more of this finite resource. Even so, while it surely exists, our desire to get more money is usually not directly expressed. Throughout our lives, we learn to successfully decoy our desire for wealth. That‚Äôs actually why money is a taboo subject.</p>







<h3>3. Technological Advancements</h3>



<p>High-tech gizmos and the internet greatly exceeded our expectations. These two innovations enabled us to connected like no other species.</p>



<p>At first, we used the Wi-Fi connection to send emails and to communicate better. Now, we use it to showcase our self-worth and to advertise our qualities to the whole world. All of this, done with the underlying desire to feel more desirable by others.</p>







<hr>



<p>The three above-mentioned notes can be portrayed in the following way:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg" alt="the-modern-rat-race" srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg"><figcaption>The cravings for money, survival, being appreciated by others is something we don‚Äôt verbally express. We show it by the stuff we obtain and the things we say/do.</figcaption></figure>







<p>Our inner eagerness to survive forces us to obtain money. And cash, supports our existence. But for most, the comfort of holding large chunks of capital in the bank is not enough. We also want to be seen as wealthy.</p>



<p>After all, just owning money is not enough to increase your chances of survival ‚Äì meeting new friends that will help you along the way and also potential mates. That‚Äôs why, we‚Äôre also eager to parade with what we have.&nbsp;&nbsp;</p>



<p>Just as the peacock spreads its feathers to show its impeccable genes, we, through our actions and the things we acquire, show the world our features hoping that they‚Äôll pick us. This our way of saying to others, ‚ÄúLook at me, my qualities and traits are so good that I can afford to spend $50,000 on a car. You should want to hang around with me.‚Äù</p>



<p>Our possessions are an advertisement, a way of showing off. They reinforce the image we desire to portray. And by going around and talking about ourselves, we want to signal to others ‚Äì in a non-verbal way in most of the cases ‚Äì why we are a worthy choice.</p>



<p>This is also called competitive signaling.</p>







<h2>What is Competitive Signaling?</h2>



<p>The way you spend your money can say a lot about how you want to position yourself in modern competition. </p>



<p>If you think carefully about everything before you buy it, and you‚Äôre not interested in high-end goods, your income is either average or you‚Äôre careless of what others think of you. In contrast, if you focus primarily on obtaining premium goods, you‚Äôre probably either rich or you want to be perceived as rich.<span id="easy-footnote-2-12306"></span><span><a href="#easy-footnote-bottom-2-12306" title="The last two are completely different things."><sup>2</sup></a></span></p>



<p>Thorstein Veblen, an American economist and sociologist, argued that the demand for luxury goods is driven largely by a single social motive: ‚Äúflaunting one‚Äôs wealth.‚Äù</p>



<p>For example, Nissan is a car. It‚Äôs an average, not-flashy, automobile that will help you go from point A to point B, faster. Porsche, on the other hand, is an art museum on wheels. It can also get you from point A to point B, but while driving around town in this beast on wheels you radiate a completely different vibe. You present yourself as a modern, high-paid individual with taste and ambition. Figuratively speaking, the amount of cash that each of them has in the bank ‚Äì the person owning a Nissan and the person owning a Porsche ‚Äì can be exactly the same. On the outside though, they appear quite different.&nbsp;&nbsp;</p>



<p>The more interesting thing to consider, if say the individuals in the above example really do have the same amount of cash stashed, is how they approach buying domestic goods ‚Äì a set of dishes, blankets, or say cleaning products. Since these goods are not to be seen by others, they both, even the person owning a sports car, will most probably end up getting the same cheap things.<span id="easy-footnote-3-12306"></span><span><a href="#easy-footnote-bottom-3-12306" title="This, of course, says a lot more things about their personality. For example, you can have an average income and still get a flashy car. But then, the things that are not visible by others will probably be average to compensate. Conversely, if you&amp;#8217;re <em>really</em> rich, you&amp;#8217;ll probably buy luxury domestic goods, too."><sup>3</sup></a></span></p>



<p>With this, we can conclude that the available products on the market are a mix of personal value and signaling value.</p>



<p>The car you have is simultaneously a way to move faster in the city and also a representation of your hierarchy in the world. Each product on the market, nowadays, comes with these qualities.</p>



<p>And if we can put this in a graph, it will look something like this:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg" alt="luxury-goods-vs-useful-goods" srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg"><figcaption>Above the line the products don‚Äôt get more useful, they do something else. Luxury goods help you display, publicly, your wealth. The ‚Äúscientific term‚Äù for this is conspicuous consumption.<span id="easy-footnote-4-12306"></span><span><a href="#easy-footnote-bottom-4-12306" title="<a aria-label=&quot;Conspicuous consumption (opens in a new tab)&quot; href=&quot;https://en.wikipedia.org/wiki/Conspicuous_consumption&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener nofollow&quot; class=&quot;ek-link&quot;>Conspicuous consumption</a>, Thorstein Veblen"><sup>4</sup></a></span></figcaption></figure>







<p>At some point, certain products become a beacon of your self-worth. If you want to signal to others that you have more money, which internally means that you want to show that you‚Äôre smarter, slimmer, better than others in a way, you‚Äôll eventually lean towards goods that are considered a luxury.</p>



<p>The extra you‚Äôre paying for a Porche, for example, has more to do with the message you want to convey to others, not with the usefulness of the product itself.<span id="easy-footnote-5-12306"></span><span><a href="#easy-footnote-bottom-5-12306" title="We all know that Porche is certainly a great vehicle. But there are still cheaper alternatives that will do the same job in terms of helping you move from point A to point B."><sup>5</sup></a></span></p>



<p>You might be ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/psychology/escape-the-modern-rat-race/">https://durmonski.com/psychology/escape-the-modern-rat-race/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/psychology/escape-the-modern-rat-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276844</guid>
            <pubDate>Wed, 02 Dec 2020 14:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Cybersecurity Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25276033">thread link</a>) | @atum47
<br/>
December 2, 2020 | https://eloeffler.gitlab.io/eloeffler/proto-vcser/ | <a href="https://web.archive.org/web/*/https://eloeffler.gitlab.io/eloeffler/proto-vcser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="indexgreeter">
    
<p>    Marwin Mueller, age 65, owns Spass GmbH. An SME in Luzern which has an annual turnover of close to 1.000.000 CHF and an annual profit of 200.000 CHF.  </p>
<p>    Spass GmbH has been operating in the hospitality industry for the last 30 years and is managing renouned hotels and villas in the Luzern Lake area.  </p>
<p>    Anne Kingston, age 29, is Marwins assistant and accountant. She has joined a year back and during her interactions, she mentioned to Marwin that she is a single mom of a six year old boy named Ryan.  </p>
<p>    Anne is a pleasant and helping personality. She likes plants and playing video games.  </p>
<p>    Marwin is very proud of his business achievements and sometimes acts as an arrogant boss. He is a bit insensitive to kids, due to his experiences. In general, he gets along with Anne and they form a great team at Spass. In the past year, Anne took over most of the office tasks at Spass. She is technology savvy and Marwin likes this quality of Anne's over his other staff.  </p>
<p>    Marwin and Anne worked on important digital initiatives at Spass like listing its properties on booking portals, creating their own website, launching social media accounts and enabling online banking at UBC Bank in Luzern.  </p>
<p>    This gave Marwin an edge over his competitors and Spass has seen a 30% increase in revenues and profits this year.  </p>
<p>    Today, Marwin remembers that two weeks back, Anne came to him and wanted a 1 week vacation to spend time with her son Ryan on occasion of his birthday.  </p>
<p>    Once again, Marwin and Anne had arguments on Anne's vacations in peak season and Marwin blamed Ryan for this.  At the end, Marwin reluctantly agreed to the holidays.</p>
<p>Since then, Anne did not turn up for work. She is not reachable on her mobile and her house is locked.</p>
<p>Marwin has just found that his bank account is debited with 2.000 CHF every day since Anne left.</p>
<p>Marwin has no idea what is happening and he is worried. Therefor, as trusted friends, he has requested that you come here and help him.</p>
<p>Marwin believes it is not a good idea to report the incident immediately to the police or bank as it can damage his reputation.</p>
<p>Now it's Friday. It's 7pm and the UBC Bank is already closed for the weekend.</p>
<p>You need to analyze the gaps Anne might have in her Cybersecurity awareness and secure the Online Banking to stop the money transfers.</p>
<p>Also, try to find out where Anne might be.</p>
<p>All the very best.
  </p></div></div>]]>
            </description>
            <link>https://eloeffler.gitlab.io/eloeffler/proto-vcser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276033</guid>
            <pubDate>Wed, 02 Dec 2020 13:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National parks of New Zealand in 3D]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25275588">thread link</a>) | @pheelicks
<br/>
December 2, 2020 | https://felixpalmer.github.io/new-zealand-3d/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/new-zealand-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/new-zealand-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275588</guid>
            <pubDate>Wed, 02 Dec 2020 12:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux kernel heap quarantine versus use-after-free exploits]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25274928">thread link</a>) | @kmwyard
<br/>
December 2, 2020 | https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html | <a href="https://web.archive.org/web/*/https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It's 2020. Quarantines are everywhere ‚Äì and here I'm writing about one, too.
But this quarantine is of a different kind.</p>

<p>In this article I'll describe the <strong>Linux Kernel Heap Quarantine</strong> that I developed
for mitigating kernel use-after-free exploitation. I will also summarize
the discussion about the prototype of this security feature on the Linux Kernel
Mailing List (LKML).</p>



<p>Use-after-free (UAF) vulnerabilities in the Linux kernel are very popular for
exploitation. There are many exploit examples, some of them include:</p>
<ul>
  <li><a href="https://seclists.org/oss-sec/2016/q4/607">CVE-2016-8655</a></li>
  <li><a href="https://www.openwall.com/lists/oss-security/2017/02/26/2">CVE-2017-6074</a></li>
  <li><a href="https://a13xp0p0v.github.io/2017/03/24/CVE-2017-2636.html">CVE-2017-2636</a></li>
  <li><a href="https://ssd-disclosure.com/ssd-advisory-linux-kernel-af_packet-use-after-free/">CVE-2017-15649</a></li>
  <li><a href="https://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html">CVE-2019-18683</a></li>
</ul>

<p>UAF exploits usually involve <strong>heap spraying</strong>.
Generally speaking, this technique aims to put attacker-controlled bytes at a defined memory
location on the heap. Heap spraying for exploiting UAF in the
Linux kernel relies on the fact that when <code>kmalloc()</code> is called, the slab
allocator returns the address of memory that was recently freed:</p>

<center><a href="https://a13xp0p0v.github.io/img/no_quarantine.png"><img src="https://a13xp0p0v.github.io/img/no_quarantine.png" width="60%"></a></center>


<p>So allocating a kernel object with the same size and attacker-controlled
contents allows overwriting the vulnerable freed object:</p>

<center><a href="https://a13xp0p0v.github.io/img/uaf.png"><img src="https://a13xp0p0v.github.io/img/uaf.png" width="70%"></a></center>


<p>Note: Heap spraying for out-of-bounds exploitation is a separate technique.</p>



<p>In July 2020, I got an idea of how to break this heap spraying technique for UAF
exploitation. In August I found some time to try it out. I extracted the slab
freelist quarantine from <a href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">KASAN</a> functionality and called it <code>SLAB_QUARANTINE</code>.</p>

<p>If this feature is enabled, freed allocations are stored in the quarantine
queue, where they wait to be actually freed. So there should be no way for them
to be instantly reallocated and overwritten by UAF exploits.
In other words, with <code>SLAB_QUARANTINE</code>, the kernel allocator behaves like so:</p>

<center><a href="https://a13xp0p0v.github.io/img/with_quarantine.png"><img src="https://a13xp0p0v.github.io/img/with_quarantine.png" width="60%"></a></center>


<p>On August 13, <a href="https://www.openwall.com/lists/kernel-hardening/2020/08/13/7">I sent</a> the first early PoC to LKML and started deeper research of
its security properties.</p>



<p>For researching the security properties of the kernel heap quarantine, I developed
two <code>lkdtm</code> tests (<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/7">code is available here</a>).</p>

<p>The first test is called <code>lkdtm_HEAP_SPRAY</code>. It allocates and frees an object
from a separate <code>kmem_cache</code> and then allocates 400,000 similar objects.
In other words, this test attempts an original heap spraying technique for UAF
exploitation:</p>

<div><div><pre><code><span>#define SPRAY_LENGTH 400000
</span>    <span>...</span>
    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>...</span>
    <span>pr_info</span><span>(</span><span>"Original heap spraying: allocate %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>if</span> <span>(</span><span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"FAIL: attempt %lu: freed object is reallocated</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>
    
    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span>
        <span>pr_info</span><span>(</span><span>"OK: original heap spraying hasn't succeeded</span><span>\n</span><span>"</span><span>);</span>
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is disabled, the freed object is instantly
reallocated and overwritten:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000002b5b3ad4 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: FAIL: attempt 0: freed object is reallocated
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is enabled, 400,000 new allocations don't overwrite
the freed object:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000009909e777 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: OK: original heap spraying hasn't succeeded
</code></pre></div></div>

<p>That happens because pushing an object through the quarantine requires <strong>both
allocating and freeing memory</strong>. Objects are released from the quarantine as
new memory is allocated, but only when the quarantine size is over the limit.
And the quarantine size grows when more memory is freed up.</p>

<p>That's why I created the second test, called <code>lkdtm_PUSH_THROUGH_QUARANTINE</code>.
It allocates and frees an object from a separate <code>kmem_cache</code> and then performs
<code>kmem_cache_alloc()+kmem_cache_free()</code> for that cache 400,000 times.</p>

<div><div><pre><code>    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>

    <span>pr_info</span><span>(</span><span>"Push through quarantine: allocate and free %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>push_addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>push_addr</span><span>);</span>

        <span>if</span> <span>(</span><span>push_addr</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"Target object is reallocated at attempt %lu</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span> <span>{</span>
        <span>pr_info</span><span>(</span><span>"Target object is NOT reallocated in %d attempts</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>);</span>
    <span>}</span>
</code></pre></div></div>

<p>This test effectively pushes the object through the heap quarantine and
reallocates it after it returns back to the allocator freelist:</p>

<div><div><pre><code>  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000008fdb15c3 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182994
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000004e223cbe of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 186830
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000007663a058 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182010
</code></pre></div></div>

<p>As you can see, the number of the allocations needed for overwriting
the vulnerable object is almost the same. That would be good for stable
UAF exploitation and should not be allowed.
That's why I developed <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6"><strong>quarantine randomization</strong></a>. This randomization
required very small hackish changes to the heap quarantine mechanism.</p>

<p>The heap quarantine stores objects in batches. On startup, all
quarantine batches are filled by objects. When the quarantine shrinks,
I randomly choose and free half of objects from a randomly chosen batch.
The randomized quarantine then releases the freed object at an unpredictable moment:</p>

<div><div><pre><code>   lkdtm: Target object is reallocated at attempt 107884
   lkdtm: Target object is reallocated at attempt 265641
   lkdtm: Target object is reallocated at attempt 100030
   lkdtm: Target object is NOT reallocated in 400000 attempts
   lkdtm: Target object is reallocated at attempt 204731
   lkdtm: Target object is reallocated at attempt 359333
   lkdtm: Target object is reallocated at attempt 289349
   lkdtm: Target object is reallocated at attempt 119893
   lkdtm: Target object is reallocated at attempt 225202
   lkdtm: Target object is reallocated at attempt 87343
</code></pre></div></div>

<p>However, this randomization alone would not stop the attacker:
the quarantine stores the attacker's data (the payload) in the sprayed objects!
This means the reallocated and overwritten vulnerable object contains the payload
until the next reallocation (very bad!).</p>

<p>This makes it important to <strong>erase heap objects before placing them in the heap quarantine</strong>.
Moreover, filling them with zeros gives a chance to detect UAF
accesses to non-zero data for as long as an object stays in the quarantine (nice!).
That functionality already exists in the kernel, it's called <code>init_on_free</code>.
<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/5">I integrated it</a> with <code>CONFIG_SLAB_QUARANTINE</code> as well.</p>

<p>During that work I found a bug: in <code>CONFIG_SLAB</code>, <code>init_on_free</code> happens too
late. Heap objects go to the KASAN quarantine while still "dirty." I provided the fix
in a <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/4">separate patch</a>.</p>

<p>For a deeper understanding of the heap quarantine's inner workings, I provided an <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/8">additional
patch</a>, which contains verbose debugging (not for merge).
It's very helpful, see the output example:</p>

<div><div><pre><code>   quarantine: PUT 508992 to tail batch 123, whole sz 65118872, batch sz 508854
   quarantine: whole sz exceed max by 494552, REDUCE head batch 0 by 415392, leave 396304
   quarantine: data level in batches:
     0 - 77%
     1 - 108%
     2 - 83%
     3 - 21%
   ...
     125 - 75%
     126 - 12%
     127 - 108%
   quarantine: whole sz exceed max by 79160, REDUCE head batch 12 by 14160, leave 17608
   quarantine: whole sz exceed max by 65000, REDUCE head batch 75 by 218328, leave 195232
   quarantine: PUT 508992 to tail batch 124, whole sz 64979984, batch sz 508854
   ...
</code></pre></div></div>

<p>The heap quarantine <code>PUT</code> operation you see in this output happens during kernel memory freeing.
The heap quarantine <code>REDUCE</code> operation happens during kernel memory allocation, if the quarantine
size limit is exceeded. The kernel objects released from the heap quarantine return to the allocator
freelist ‚Äì they are actually freed.
In this output, you can also see that on <code>REDUCE</code>, the quarantine releases some part of
a randomly chosen object batch (see the <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6">randomization patch</a> for more details).</p>



<p>I made <a href="https://www.openwall.com/lists/kernel-hardening/2020/10/01/7">brief performance tests</a> of the quarantine PoC on real hardware and in virtual machines:</p>
<ol>
  <li>
    <p>Network throughput test using <code>iperf</code> <br>
server: <code>iperf -s -f K</code> <br>
client: <code>iperf -c 127.0.0.1 -t 60 -f K</code></p>
  </li>
  <li>
    <p>Scheduler stress test <br>
<code>hackbench -s 4000 -l 500 -g 15 -f 25 -P</code></p>
  </li>
  <li>
    <p>Building the defconfig kernel <br>
<code>time make -j2</code></p>
  </li>
</ol>

<p>I compared vanilla Linux kernel in three modes:</p>
<ul>
  <li><code>init_on_free=off</code></li>
  <li><code>init_on_free=on</code> (upstreamed feature)</li>
  <li><code>CONFIG_SLAB_QUARANTINE=y</code> (which enables <code>i‚Ä¶</code></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</a></em></p>]]>
            </description>
            <link>https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274928</guid>
            <pubDate>Wed, 02 Dec 2020 09:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25272533">thread link</a>) | @bdr
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/? | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: ‚Äúwill,‚Äù ‚Äúexpect,‚Äù ‚Äúwould,‚Äù ‚Äúintend,‚Äù ‚Äúbelieve,‚Äù or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that‚Äîalbeit growing more slowly‚Äîmay have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack‚Äîa niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to ‚Äúback into‚Äù $66B worth of vertical markets‚ÄîCRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate‚Äîvia chatting with other team members within the context of a personal or shared inbox‚Äîand coordinate‚Äîvia tagging, rules, and 3rd-party integrations‚Äîhow they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat‚Äîbased on the cost of switching away to another email product‚Äîwill become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user‚Äîtoday, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years‚Äîa company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front‚Äîboth because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front‚Äôs consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That‚Äôs up 40% from Front‚Äôs Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front‚Äôs last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn‚Äôt grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front‚Äôs relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front‚Äôs revenue comes from expansion versus bringing on new customers‚Äîbased on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front‚Äôs -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front‚Äôs organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 ‚Äì 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front‚Äôs bear, base, and bull cases hinge largely on whether the company‚Äôs growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front‚Äôs growth slows even further, with the company reaching a ‚Ä¶</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/?">https://sacra.com/research/front-inside-the-startup-slackifying-email/?</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272533</guid>
            <pubDate>Wed, 02 Dec 2020 02:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NN-SVG: Generate publication-ready NN-architecture schematics]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25272360">thread link</a>) | @tzm
<br/>
December 1, 2020 | https://alexlenail.me/NN-SVG/AlexNet.html | <a href="https://web.archive.org/web/*/https://alexlenail.me/NN-SVG/AlexNet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <div id="collapsable">
                        <div id="AlexNet" role="tabpanel">


                            <h4>Style:</h4>
                            <div id="rendererType">
                                <p><label for="rendererType">Renderer</label></p><p><label>
                                         webGL
                                    </label>
                                </p>
                                <p><label>
                                         SVG
                                    </label>
                                </p>
                                <p><small>The SVG renderer is required to download SVG, however the WebGL renderer is required to show tensor dimensions.</small>
                            </p></div>

                            
                            <p>
                                <label for="color1">Color 1</label>
                            </p>
                            <p>
                                <label for="color2">Color 2</label>
                            </p>
                            <p>
                                <label for="color3">Color 3</label>
                            </p>
                            <p><label for="rectOpacity">Tensor Opacity</label>
                                
                            </p>
                            <div>
                            <p><label for="strideOpacity">Filter Opacity</label>
                                
                            </p>
<!--                             <div>
                                <label for="borderWidth">Border Width</label>
                                <input type="range" id="borderWidth" name="" min="0.01" max="3" step="0.01" value="1" style="position: relative; top: 3px;">
                            </div> -->
                            <p><label for="betweenLayers">Spacing Between Layers</label>
                                
                            </p>

                            <hr>
                            <p>
                                <label for="logDepth">Log Feature-Map Depth Scaling</label>
                            </p>
                            <p><label for="depthScale">Depth Size Scaling</label>
                                
                                <span id="depthSpan">10</span>
                            </p>
                            <p>
                                <label for="logWidth">Log Feature-Map Width Scaling</label>
                            </p>
                            <p><label for="widthScale">Width Size Scaling</label>
                                
                                <span id="widthSpan">10</span>
                            </p>
                            <p>
                                <label for="logConvSize">Log Convolutional Filter Size Scaling</label>
                            </p>
                            <p><label for="convScale">Convolutional Filter Scaling</label>
                                
                                <span id="convSpan">1</span>
                            </p>

                            <hr>
                            <p>
                                <label for="showDims">Show Tensor Dimensions</label>
                            </p>
                            <p>
                                <label for="showConvDims">Show Conv Dimensions</label>
                            </p>

                            <hr>
                            <h4>Architecture:</h4>
                            <div id="architecture">
                                <p>Height | Width | Depth | filter Height | filter Width</p>
                                
                                
                                
                                
                                
                                
                                
                            </div>

                            <hr>
                            

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexlenail.me/NN-SVG/AlexNet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272360</guid>
            <pubDate>Wed, 02 Dec 2020 01:46:02 GMT</pubDate>
        </item>
    </channel>
</rss>
