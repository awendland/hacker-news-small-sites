<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 24 Dec 2020 12:50:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 24 Dec 2020 12:50:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[This Community is Available in the App]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25502828">thread link</a>) | @rukshn
<br/>
December 21, 2020 | https://ruky.me/2020/12/22/this-community-is-available-in-the-app/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/22/this-community-is-available-in-the-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Yesterday‚Äôs <a href="https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">post</a> was an awesome one, I learned a lot in JavaScript and and I was happy to see people doing what I thought impossible. Writing a simple todo app within 280 chars, in plain js.</p>
<p>After I finished writing the post, I wanted to share it on Reddit JavaScript community, r/javascript at the same time I shared it on HackerNews.</p>
<p>I have seen lot of comments on HackerNews criticizing the new Reddit design, using JavaScript and breaking in their mobile website, and constant nags pushing the users to their mobile app.</p>
<p>I was one of those few who liked their new design on desktop, no page loads between posting something, lot of white spaces, I feel most of the average users would be feeling the same, except for the tech community. But as a service Reddit should be looking at the common denominator, not the outliers.</p>
<p>I‚Äôm annoyed with the mobile app nag, when I visit the mobile website, Reddit is always asking me to download the mobile app. But I just cancel it and move along in the mobile browser.</p>
<p>But what happened yesterday just took me off the ledge. When I visited the r/javascript community on my iPad, I was greeted with this screen.</p>
<figure><img data-attachment-id="73" data-permalink="https://ruky.me/2020/12/22/this-community-is-available-in-the-app/img_0041/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=1536%2C2048&amp;ssl=1" data-orig-size="1536,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_0041" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=768%2C1024&amp;ssl=1" loading="lazy" width="768" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>This community is only available in the app.</figcaption></figure>
<p>Why do you block me from from visiting the community from my mobile device?</p>
<p>Will the whole mobile website is scrapped and you end up with a landing page to download the mobile app?</p>
<p><strong>If you want to visit a popular subreddit</strong>, <strong>install our up and use it, or else login. </strong></p>
<p>I‚Äôve managed to see the subreddit by requesting the desktop website, but I‚Äôm sure they will figure out a way, by checking the screen size to block this as well.</p>
<p>I understand that, as a company, you need to push to gain as much users as possible on their mobile devices, that‚Äôs the best way to track, to send notifications and keep you hooked and keep coming back. If I had a company like Reddit I might have done the same.</p>
<p>But for blocking users from their mobile devices, a service they once offered is a very dark pattern, instead what they should do is introduce some awesome features that will make the users download the app by themselves so they can enjoy those features. Not forcing the app though their throats.</p>
<p>Anyone else experienced a similar experience on Reddit mobile?</p>
<p><em>Only after writing the and checking the screenshot again made me see that they allow you to see the subreddit by logging in. But that is obscured and they intend to push users to download the app.</em></p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2020/12/22/this-community-is-available-in-the-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502828</guid>
            <pubDate>Tue, 22 Dec 2020 04:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Blind Passwords a.k.a. Horcruxing]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25502703">thread link</a>) | @phantom_rehan
<br/>
December 21, 2020 | https://kaizoku.dev/double-blind-passwords-aka-horcruxing | <a href="https://web.archive.org/web/*/https://kaizoku.dev/double-blind-passwords-aka-horcruxing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1607775961422/elXIChWIZ.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Before we get into Horcruxing, here's a quick prologue on online security hygiene. You can skip to the  <a href="#double-blind-passwords-aka-horcruxing">Horcruxing section</a>  if it seems redundant.</p>
<h3 id="rules-for-strong-online-security">Rules for Strong Online Security</h3>
<p>1.
<strong>Longer passwords (atleast 16 characters) are better than shorter ones</strong></p>
<pre><code>=&gt; cutesamantha15101995 &gt; cutesamantha
</code></pre><p>2.
<strong>Randomized passwords are better than personally identifiable passwords</strong></p>
<pre><code>=&gt; process-cancel-stingy-garnet &gt; cutesamantha15101995
</code></pre><p><strong>NOTE: </strong> <code>process-cancel-stingy-garnet</code> is technically a passphrase - basically an easy-to-remember password in comparison to randomized strings like <code>B6fSpxMj&amp;f6DU@5^k</code></p>
<p>3.
<strong>Have a <em>significantly</em> different password for each account</strong></p>
<p>Having the same password for different accounts is like using the same key for different locks. It beats the whole point of having multiple locks! Also, having different passwords but with only one easily guessable word different (like the ones below) still poses the same risk. The passwords should be <strong><em>significantly</em></strong> different.</p>
<pre><code>bounce-unfold-stunning-chute        process-cancel-stingy-facebook
symptom-untouched-unpaid-arena  &gt;   process-cancel-stingy-twitter
sediment-tweak-annually-koala       process-cancel-stingy-gmail
</code></pre><p>4.
<strong>Use 2FA/MFA wherever possible</strong></p>
<p>Both Google and Facebook offer a 2FA feature where you need the second factor only when you login from a new device or a new location, instead of needing 2FA every time. That's a rare combination of convenience &amp; security right there! 
Most other sites also offer some variation of 2FA.</p>
<p><strong>NOTE</strong>: Use the  <a target="_blank" href="https://play.google.com/store/apps/details?id=org.shadowice.flocke.andotp">andOTP</a>  (or any other) app's TOTP as the second factor since it cannot be spoofed or spied on lock-screen like the SMS OTP and does not require a mobile network or internet connection. You can also use Biometrics (finger print or face recognition)</p>
<blockquote>
<p>Woah! How do I create a long password for each of the bazillion websites out there, <em>and</em> have them significantly different <em>and</em> remember them? Security seems like such a pain in the ass!</p>
</blockquote>
<h3 id="enter-password-manager">[enter] <strong>PASSWORD MANAGER</strong></h3>
<p>A password manager helps you manage all your passwords in one place, either in the form of a browser extension, mobile app, or website. Good password managers will offer a browser extension and a mobile app with one-click auto-fill-login-page feature by removing the hassle of copy pasting or typing your login details. A few smart ones even detect phishing pages and warn you indirectly, by not showing the login details for such web pages.</p>
<p>They enable all the above measures for strong online security with ease. While I agree it takes some effort to set it up for the very first time. But, after that, it just flows like butter. </p>
<p><br>
For example, password generator in <a target="_blank" href="https://bitwarden.com/">BitWarden</a> lets you custom design your random password in different flavours.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1607770748804/m93T3kqUH.png?auto=compress" alt="BitWarden's password generator"></p>
<h3 id="yay-im-secure">YAY! I'm Secure!</h3>
<p>You meticulously move all your passwords and secrets to a trusted password manager. Finally, you can rest easy knowing that your digital life is truly secure. Or, is it?  <br></p>
<p><strong>What if </strong></p><ul>
<li>your master password (the password to your password manager) is compromised due to a security breach or you left it in plaintext on a post-it/ email/ notes app</li>
<li>someone gained temporary access to your unlocked system (computer or phone) when you stepped away to get that last coffee for the day and your password manager is still logged in for everyone to see</li>
</ul>
<p>The answer: you're <strong><em>screwed</em></strong>. The cost of putting all your eggs in one basket is that it could all go into oblivion in one fell swoop. How do you overcome this challenge now? </p>
<h3 id="double-blind-passwords-aka-horcruxing">Double Blind Passwords (aka Horcruxing)</h3>
<p>For all his faults, Voldemort did one good thing for us muggles. He gave us the concept of a horcrux. For the uninitiated, a horcrux is any object in which you store a piece of your soul, putting the proverbial eggs of your soul into different baskets, to gain quasi-immortality. </p>
<p><strong>The basic idea</strong>: You split your password into 2 parts - one which is stored in the password manager, and the other which is stored in your head (aka horcrux).</p>
<p>Basically, at any given point in time, you and your password manager know only a piece of the password. It's double-blind. In effect, just like You-Know-Who, you're splitting your password (soul) into pieces and storing them in different places.</p>
<h4 id="before">BEFORE</h4>
<pre><code>
<span>username: rick</span>
<span>password: rollthepeople1732</span>


<span>username: rick</span>
<span>password: rollthepeople1732</span>
</code></pre><h4 id="after">AFTER</h4>
<pre><code>
<span>username: rick</span>
<span>password: roll-the-people-venus</span>


<span>horcrux: papel</span>


<span>username: rick</span>
<span>password: roll-the-people-venuspapel</span>
</code></pre><p>The horcrux adds an additional layer of security that only you can unlock. It's a kind of 2FA. Again, the longer the horcrux the better. But, a simple word should also be fine as long as only you know the horcrux.</p>
<p>If it feels like too much effort, use a horcrux only for the most important logins - your social media, bank accounts etc. </p>
<h3 id="one-last-thing">One Last Thing</h3>
<p>Security is never absolute. One can try to secure a system as tightly as possible, but never really say that it is fully secure (if you see someone claiming otherwise, it's mostly marketing bullshit). If we cannot make systems completely secure, the next best thing to do is to make them as secure as possible and a good way to do it is <a target="_blank" href="https://en.wikipedia.org/wiki/Defense_in_depth_(computing">Defense In Depth</a> - basically make sure that even if one layer of security is breached, there exist other layers to mitigate further damage - which is what we've tried to achieve all along.</p>
<h3 id="summary">Summary</h3>
<p>1.
Use a good password manager </p>
<blockquote>
<p>I use BitWarden (since it is open source and costs just $10 a year for the PRO features)</p>
</blockquote>
<p>2.
Use TOTP/ biometrics instead of SMS-based OTP</p>
<blockquote>
<p>I use andOTP (since it is open source)</p>
</blockquote>
<p>3.
Use a horcrux (a double-blind password) for the most important logins</p>

<p>P.S. Keep in mind that horcruxing only works fine until you connect your brain to NeuraLink and accidentally upload your thoughts online for everyone to see. :P</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://kaizoku.dev/double-blind-passwords-aka-horcruxing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502703</guid>
            <pubDate>Tue, 22 Dec 2020 03:58:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Engineering Axioms]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25500815">thread link</a>) | @mnouquet
<br/>
December 21, 2020 | https://martinrue.com/my-engineering-axioms/ | <a href="https://web.archive.org/web/*/https://martinrue.com/my-engineering-axioms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <h3>My Engineering Axioms</h3>

            <p>A few months back I gave a talk in which I shared a list of my personal engineering axioms ‚Äì things that, over the years, I've come to think of as generally true and useful to have in mind when writing code, building things, and working with others.</p>

            <p>Axiom is a fancy word, but popping a few layers off the etymology stack we arrive neatly at the ancient Greek word <a href="https://en.wiktionary.org/wiki/%E1%BC%80%CE%BE%CE%AF%CF%89%CE%BC%CE%B1">·ºÄŒæŒØœâŒºŒ±</a>, or "that which is thought fit or worthy". I like that, and consider each item on the list at least worthy of consideration.</p>

            <p>Of course they're <b>my</b> engineering axioms ‚Äì things I believe to be useful based on my own experience. Your experience may well differ. Maybe you already knew about <a href="https://martinrue.com/zzuy-a-lesson-in-perseverance/">zero termination</a>, or have better tools than <a href="https://martinrue.com/give-yourself-more-playtime/">scissors to remove bugs</a> from your programs.</p>

            <p>In any case, I thought it would be fun to share the list here, with a few brief clarifications. Some things are pretty unsurprising, but hopefully others will generate some provocative thoughts and/or interesting disagreements.</p>

            <h4>1. Change is constant.</h4>

            <p>This one shouldn't be too controversial. Almost everything is always changing, including the rate of change itself. We need to acknowledge not only that our ability to respond to change is crucial, but that how well we do it (time, cost, quality, reliability) is often a dimension of our competitiveness.</p>

            <h4>2. Your product is an asset, but code is a liability.</h4>

            <p>Your product solves your customer's problem(s), and therefore is your asset. The code itself is the cost of creating the asset. The more code you have, the more it needs to be read, tested, changed, and understood. This is especially relevant when you consider axiom 1. Accept new code (and dependency on external code) conservatively. The best code is code you don't have to write.</p>

            <h4>3. Duplication is less costly than premature abstraction.</h4>

            <p>Until you have a high degree of confidence that your abstraction is going to pay for itself because it solves a real, abstract problem you really do have, don't do it. Wait and learn more. Until then, repeating code can help avoid dependency, which itself makes the code easier to change independently or delete. A premature abstraction creates complexity through dependency and indirection, and can become a bottleneck to your ability to respond to change.</p>

            <h4>4. Code should be easy to delete.</h4>

            <p>Write code to be removable, which in large part is the same as saying "decoupled". For sure not all code needs to be similarly removable, but minimising dependencies, having clear boundaries via well-defined interfaces, and having a thoughtful overall system design allows parts to be removed/changed more easily. I once heard someone use the expression "code spent", as an alternative to "code written" and I love that. I like the implication that removing code is reducing future cost.</p>

            <h4>5. Existing code exerts a powerful influence.</h4>

            <p>The very fact it's there suggests it's correct and necessary. Hopefully it is, but not always. We need to maintain both the confidence to change it, and the ability to reason about whether we should. Don't let the existence of code itself create doubt that it can't be removed. As per axiom 4, it should be easy to remove, and the system design should be good enough to enable us to understand whether we still need it.</p>

            <h4>6. Accidental complexity is one of the biggest risks.</h4>

            <p>Accidental complexity is complexity that can be avoided, and occurs due to things like poor design, bad decisions, and not prioritising an appropriate level of simplicity within a system. If simplicity is not a goal, accidental complexity is more likely to occur as a system grows, and will gradually negatively affect almost everything from changing the system to even being able to understand it. The 2006 paper <a href="http://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> is a worthwhile read on this subject.</p>

            <h4>7. Technical excellence can be shadowed by bad personal skills.</h4>

            <p>Unless you're working completely alone, it's not just your ability to solve technical problems, to write good code, etc, that matters. To the contrary, they matter even less if you make the people around you unhappy and less productive. Just like learning to write good code, you have to learn "to people" good as well. Empathy is a big part of this, as is recognising that people are different ‚Äì be caring, be understanding, help others and ask for help yourself, be nice. Be an engineer others want to work with.</p>

            <h4>8. You are not your code. Be kind to the coder, not to the code.</h4>

            <p>Code is merely a moment in time that captured what we thought we knew about something. It's not you. You may have wrote it, but since that moment (even if it was 3 minutes ago) you've grown, but the code has not. A conversation about code, good or bad, should never be personal. Keep it professional. Talk about the code, or about the problem, but don't make it about the person who wrote it. Use "we" instead of "you". Sometimes I try to pretend I wrote the code someone else wrote, which helps me avoid accidentally sounding personal.</p>

            <h4>9. Treat people who know less than you with respect and patience.</h4>

            <p>We all start somewhere, and the journey is a lot more joyful when you're surrounded by patient people who want you to succeed, rather than those who make you feel like you don't belong. If you struggle with this, it may be helpful to remember that the newbie programmer almost certainly does something better than you do ‚Äì perhaps they're fluent in another language, or cook amazingly, or play a sport. Just imagine yourself in the reverse role. How would you like them to treat you, the total newbie? Again: be an engineer others want to work with.</p>

            <h4>10. The only true authority stems from knowledge, not from position.</h4>

            <p>Knowledge and understanding of the problem, the domain, the customer, are all far more important than whatever the first 3 letters on your business card are. <a href="https://youtu.be/cISYzA36-ZY?t=85">Even if it does have a watermark</a>. Understand how something works from first principles, build a solid understanding, and authority will follow.</p>

            <h4>11. Teaching is a form of learning in disguise.</h4>

            <p>If you think you know something, try teaching it. Often the very act of trying to explain what you know to someone else forces you to formalise your own thoughts much more clearly. Writing things down seems to have a similar effect. I've lost count of the number of times I've begun explaining something only to find I don't quite understand it as well as I thought.</p>

            <h4>12. Lift the skills of people around you, not just yourself.</h4>

            <p>A great team is never a great because of one amazing person. It's a great team because everyone challenges each other and everybody grows together. When you learn something cool, share it ‚Äì help the people around you get better. As they do the same, everybody benefits and nobody gets left behind. It's also far more fun. Secondary benefit: axiom 11.</p>

            <h4>13. The longer you wait the more you'll know.</h4>

            <p>I'm still learning this and trying hard to avoid my almost default desire to decide quickly. The truth is, the longer you delay non-essential decisions the more information you'll have to lean on when the time comes to make it. Of course you can't always procrastinate a decision, but often you can, and as a minimum you should at least consider whether not knowing the answer right now is actually OK.</p>

            <h4>14. A good type system is worth its weight plus some.</h4>

            <p>Having gone backwards and forwards through various static and dynamic languages over my career, I'm currently of the opinion that a good type system is worth its overhead. A good type system shouldn't carry all that much overhead. If the type system is designed well, it can almost feel like a dynamic language (via features like inference and flow analysis) while removing a whole class of issues that the compiler can handle far better and quicker than you can. Developments like ownership in Rust are a nice example of how this has gone even further than people would have imagined years back.</p>

            <h4>15. The right team of people trumps everything else.</h4>

            <p>Having a team of people who just want to work together and build great things makes a lot of other problems easier to deal with. The word "right" here is highly subjective and contextual, but at least anecdotally, empathy, respect, and friendship have been recurring elements of great teams I've been part of.</p>

            <h4>16. Stick to boring technology, unless there's a good reason not to.</h4>

            <p>Boring tech is often older and better understood. There's battle-hardened experience of how to use it effectively, better understanding of its failure modes, and it's easier to find people and resources on how to best apply it. I really like Dan McKinley's idea of <a href="https://mcfunley.com/choose-boring-technology">innovation tokens</a>. You only get 3. Use them to adopt or build brand new stuff ‚Äì ideally stuff that will make you better at your core competency ‚Äì but any more than 3 and the risk of never reaching stability/maturity starts to grow.</p>

            <h4>17. Have the smallest team possible, but no smaller. Grow it carefully.</h4>

            <p>A play on a well-known quote, and your mileage may vary on this one. In my career so far, I've reliably seen smaller teams be more effective than larger ones. There's a balance to be found, for sure, which depends on the magnitude and complexity of the problem you're solving. That said, smaller teams benefit from less communication overhead, less room for miscommunication, and more space for everyone's voice to be heard. In a smaller team, it also feels more personal, and I feel more responsible, and I like that.</p>

            <h4>18. Rest.</h4>

            <p>I'm happy to see the gradual de-sexification of ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martinrue.com/my-engineering-axioms/">https://martinrue.com/my-engineering-axioms/</a></em></p>]]>
            </description>
            <link>https://martinrue.com/my-engineering-axioms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500815</guid>
            <pubDate>Mon, 21 Dec 2020 23:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write code. Not too much. Mostly functions.]]>
            </title>
            <description>
<![CDATA[
Score 619 | Comments 260 (<a href="https://news.ycombinator.com/item?id=25500671">thread link</a>) | @brundolf
<br/>
December 21, 2020 | https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>There's a well-known quote by author <a href="https://en.wikipedia.org/wiki/Michael_Pollan">Michael Pollan</a>:
        "Eat food. Not too much. Mostly plants." I like it because it doesn't
        attempt to be dogmatic: it encapsulates some basic guiding principles that get
        you 90% of the way there 90% of the time. Wikipedia describes the book the quote
        is from (emphasis mine):</p>
      <blockquote>
        <p>He explains...the notion that nutritionism and, therefore, the whole Western
          framework through which we intellectualize the value of food <strong>is more a religious
and faddish devotion to the mythology of simple solutions than a convincing and
reliable conclusion of incontrovertible scientific research</strong>.</p>
      </blockquote>
      <p>That...sounds familiar.</p>
      <h2 id="write-code">Write code </h2>
      <p>Code, like food, has value. I think those of us who write it can (hopefully)
        agree on that. Some, though, are so afraid of writing/eating
        <em>too much</em> that they avoid writing/eating what they should.</p>
      <p>In the context of programming, I think this translates to an unhealthy fear
        (again, for some) of duplication. A little bit of duplication - writing
        something in a way that doesn't completely maximize conciseness - isn't the end
        of the world. Sometimes it's the best path forward. Sometimes it's okay to
        copy-and-modify here and there, especially when you're still figuring out what
        your application will end up being.</p>
      <h2 id="not-too-much">Not too much </h2>
      <p>Of course too much code, like too much food, can also be a bad thing. This is
        a well-trodden topic so I don't feel the need to go too far into it here.</p>
      <p>Just be aware of your project's "appetite": write what needs to be written,
        and then try not to over-indulge.</p>
      <h2 id="mostly-functions">Mostly functions </h2>
      <p>By "functions" here I mean "pure functions". You could make a case that pure
        functions aren't the "plants" of code, though I feel
        that they are. In my experience most codebases have a pure functional
        subset, and I believe writing that subset in a pure-functional style is nearly
        always a win for the long-term health of the project.</p>
      <p>Of course the qualifier is "mostly": this isn't a dogma. Writing a 100%
        functional system ("going vegan", if you will) often requires you to jump
        through a bunch of extra hoops to get all the functionality you need. Looking
        at it solely from the perspective of health, those extra complications may not
        be worth it.</p>
      <p>And then different projects have different needs: just as an athlete may need
        a larger percentage of protein, or individuals may have certain nutrient
        deficiencies, a project may only have a very small functional subset, or may not
        be able to afford to return new values each time due to data size or
        performance-sensitivity. There's nothing wrong with that.</p>
      <h2 id="%22real-code%22">"Real code" </h2>
      <p>Pollan later qualifies his snappy statement a bit further:</p>
      <blockquote>
        <p>He contends that most of what Americans now buy in supermarkets, fast food
          stores, and restaurants is not in fact food, and that a practical tip is to eat
          only those things that people of his grandmother's generation would have
          recognized as food.</p>
      </blockquote>
      <p>At the risk of stretching the analogy, maybe the equivalent is
        "code only those things that people at a junior level would recognize for what
        they do". Code in simple, straightforward terms. Don't get too clever,
        "manufacturing artificial ingredients". Use the primitives that are there, when
        possible. Write what is simple, and natural, and human.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500671</guid>
            <pubDate>Mon, 21 Dec 2020 22:53:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing JSON at the CLI: A Practical Introduction to jq and more]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25498364">thread link</a>) | @sequoia
<br/>
December 21, 2020 | https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/ | <a href="https://web.archive.org/web/*/https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><p><code>jq</code> is a command line tool for parsing and modifying JSON. It is useful for extracting relevant bits of information from tools that output JSON, or REST APIs that return JSON. Mac users can install <code>jq</code> using homebrew (<code>brew install jq</code>); see <a href="https://stedolan.github.io/jq/download/">here</a> for more install options.</p>
<p>In this post we'll examine a couple "real world" examples of using <code>jq</code>, but let's start with...</p>
<h2 id="-code-jq-code-basics">
    <a href="#-code-jq-code-basics">
      
    </a>
    <code>jq</code> Basics</h2><p>The most basic use is just tidying &amp; pretty-printing your JSON:</p>
<pre><code>$ USERX=<span>'{"name":"duchess","city":"Toronto","orders":[{"id":"x","qty":10},{"id":"y","qty":15}]}'</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.'</span>
</code></pre>
<p>outputs</p>
<pre><code>{
  <span>"name"</span>: <span>"duchess"</span>,
  <span>"city"</span>: <span>"Toronto"</span>,
  <span>"orders"</span>: [
    {
      <span>"id"</span>: <span>"x"</span>,
      <span>"qty"</span>: <span>10</span>
    },
    {
      <span>"id"</span>: <span>"y"</span>,
      <span>"qty"</span>: <span>15</span>
    }
  ]
}
</code></pre>
<p>I like this pretty-printing/formatting capability so much, I have an alias that formats JSON I've copied (in my OS "clipboard") &amp; puts it back in my clipboard:</p>
<pre><code><span>alias</span> jsontidy=<span>"pbpaste | jq '.' | pbcopy"</span>
</code></pre>
<p>The <code>'.'</code> in the <code>jq '.'</code> command above is the simplest jq "filter." The dot takes the input JSON and outputs it as is. You can read more about filters <a href="https://stedolan.github.io/jq/manual/#Basicfilters">here</a>, but the bare minimum to know is that <code>.keyname</code> will filter the result to a property matching that key, and <code>[index]</code> will match an array value at that index:</p>
<pre><code>$ <span>echo</span> <span>$USERX</span> | jq <span>'.name'</span>
<span>"duchess"</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.orders[0]'</span>
{
  <span>"id"</span>: <span>"x"</span>,
  <span>"qty"</span>: 10
}
</code></pre>
<p>And <code>[]</code> will match <em>each</em> item in an array:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[].id'</span>
<span>"x"</span>
<span>"y"</span>
</code></pre>
<p>Filtering output by value is also handy! Here we use <code>|</code> to output the result of one filter into the input of another filter and <code>select(.qty&gt;10)</code> to select only orders with <code>qty</code> value greater than 10:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[]|select(.qty&gt;10)'</span>
{
  <span>"id"</span>: <span>"y"</span>,
  <span>"qty"</span>: 15
}
</code></pre>
<p>One more trick: filtering by <strong>key</strong> name rather than value:</p>
<pre><code>$ ORDER=<span>'{"user_id":123,"user_name":"duchess","order_id":456,"order_status":"sent","vendor_id":789,"vendor_name":"Abe Books"}'</span>
$ <span>echo</span> <span>$ORDER</span> | jq <span>'.'</span>
{
  <span>"user_id"</span>: 123,
  <span>"user_name"</span>: <span>"duchess"</span>,
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>,
  <span>"vendor_id"</span>: 789,
  <span>"vendor_name"</span>: <span>"Abe Books"</span>
}
$ <span>echo</span> <span>$ORDER</span> | jq <span>'with_entries(select(.key|match("order_")))'</span>
{
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>
}
</code></pre>
<p>(cheat sheet version: <code>with_entries(select(.key|match("KEY FILTER VALUE")))</code>)</p>
<p>Check out <a href="#more-resources">more resources</a> below to learn about other stuff jq can do!</p>
<h2 id="a-usecase-debugging-some-prometheus-metrics">
    <a href="#a-usecase-debugging-some-prometheus-metrics">
      
    </a>
    A Usecase: Debugging Some Prometheus Metrics</h2><p>I have a prometheus metric showing up locally that doesn't look quite right:</p>
<pre><code>async_task_total{task_name="/Users/duchess/charmoffensive/toodle-app/pkg/web/page/globals.go(189):(*GlobalsPopulator).Populate"} 6
</code></pre>
<p>The fact that the <code>task_name</code> value is a <em>filename</em> is a red flag‚Äì<a href="https://prometheus.io/docs/practices/naming/#labels">it's bad to have labels with high cardinality</a> and I'm not sure how many of these there are. I want to find out:</p>
<ol>
<li>What do these <code>task_name</code> labels look like in production?</li>
<li>How many unique values are there for these labels?</li>
</ol>
<h3 id="1-getting-the-label-values-in-production">
    <a href="#1-getting-the-label-values-in-production">
      
    </a>
    1. Getting the label values in production</h3><p>At my company there is a <abbr title="Command Line Interface">CLI</abbr> tool we'll call <code>pquery</code> that allows prometheus metrics to be queried from the command line, and it outputs JSON‚Äìhow conventient! I use this tool in the following examples. You don't have this tool, but fear not: <a href="https://learndevops.substack.com/p/hitting-prometheus-api-with-curl">this wonderful post</a> explains how to query prometheus using <a href="https://curl.se/">curl</a> which is essentially what <code>pquery</code> does.</p>
<p>Using <code>pquery</code> we can view prometheus metrics from our various clusters. But even if we filter for this exact metric name, it's more data than we can easily look at. We'll use <code>wc -l</code> (wordcount: count lines) to get a rough idea of how much data we're working with:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | wc <span>-l</span>
316117
</code></pre>
<p>316,117 lines of JSON! Oof! We want to iterate over the metrics. But what jq filter do we need to access the array of metrics? I find <code>head</code> useful for figuring out what the top level keys are for a large json structure:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | head -n 20
{
    <span>"data"</span>: {
        <span>"result"</span>: [
            {
                <span>"metric"</span>: {
                    <span>"__name__"</span>: <span>"async_task_total"</span>,
                    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
                    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
                    <span>"namespace"</span>: <span>"noweb"</span>,
                    <span>"netpol"</span>: <span>"toodle-app"</span>,
                    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
                    <span>"release"</span>: <span>"toodle-app"</span>,
                    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
                },
                <span>"value"</span>: [
                    1600981630.344,
                    <span>"2"</span>
</code></pre>
<p>You can also use <code>jq 'keys'</code> if you just want the key names:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'keys'</span>
[
  <span>"data"</span>,
  <span>"status"</span>
]
</code></pre>
<p>Anyway we can see from above that <code>.data.result</code> is the "filter" path for the metrics themselves. Let's get the <strong>first result</strong> (<code>[0]</code>) of this array so we can see what one metric looks like:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'.data.result[0]'</span>
{
  <span>"metric"</span>: {
    <span>"__name__"</span>: <span>"async_task_total"</span>,
    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
    <span>"namespace"</span>: <span>"noweb"</span>,
    <span>"netpol"</span>: <span>"toodle-app"</span>,
    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
    <span>"release"</span>: <span>"toodle-app"</span>,
    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
  },
  <span>"value"</span>: [
    1600981906.069,
    <span>"2"</span>
  ]
}
</code></pre>
<p>Oops! That <code>app</code> value (<code>toodle-app-alpha</code>) indicates a mistake: I'm only interested in results from the <code>toodle-app</code> app, <em>not</em> from other apps that may also emit this metric (such as the <code>alpha</code> deployment we see here). We could <code>select</code> for this using jq, but <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/"><code>promql</code> already lets us filter by metric names</a> so we'll do that instead: <code>pquery 'async_task_total{app="toodle-app"}'</code>.</p>
<p>We're interested in the <code>task_name</code> value in the <code>metric</code> object, so let's pluck that from <strong>each</strong> item in the array above:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(146):(*areaCategoryView).fetchData"</span>
{... + 18009 more lines}
</code></pre>
<blockquote>
<p>üìù Update: It was pointed out to me that as this is a post about <code>jq</code>, not about <code>promql</code>, a <code>jq</code> solution is more appropriate here. I'd originally used promql because it's more efficient to filter on the server when possible. Here's the <code>jq</code> version which uses the <a href="https://stedolan.github.io/jq/manual/#select(boolean_expression)"><code>select</code> filter</a>:</p>
<pre><code>$ pquery <span>'async_task_total'</span> \
| jq <span>'.data.result[].metric | select(.app == "toodle-app").task_name'</span>
</code></pre>
<p>Back to the post...</p>
</blockquote>
<p>Eighteen thousand values for that label!? That's bad!! But wait a tic‚Äìif other labels are varying, some of these may actually be duplicates. Let's sort them and see:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | head -n10
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
</code></pre>
<p>Yep: most of these are actually not unique names. <code>uniq</code> to the rescue!</p>
<pre><code>$  pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
{... more}
</code></pre>
<p>Now I've got a full list of all the <em>distinct</em> values for this label, which answers my first question.</p>
<h3 id="how-many-unique-values-are-there-for-these-labels-">
    <a href="#how-many-unique-values-are-there-for-these-labels-">
      
    </a>
    How many unique values are there for these labels?</h3><p>Well that's pretty easy at this point...</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq | wc <span>-l</span>
92
</code></pre>
<p>Ninety-two! Not so bad. Mystery solved, and I can say with reasonable confidence "the cardinality of these labels isn't terribly high, I'm ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</a></em></p>]]>
            </description>
            <link>https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25498364</guid>
            <pubDate>Mon, 21 Dec 2020 19:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I rewrote a Clojure tool in Rust]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25497050">thread link</a>) | @praveenperera
<br/>
December 21, 2020 | https://timofreiberg.github.io/clojure-vs-rust/ | <a href="https://web.archive.org/web/*/https://timofreiberg.github.io/clojure-vs-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            
<p>2020-12-20</p>


<p>About two years ago, I wrote a quite complicated diff tool in Clojure.<br>
It was complicated enough that I struggled to fit the algorithm in my head and the inputs were large enough that I had to make some efforts to improve performance.</p>
<p>About half a year later, I started learning Rust, ported the current state of the Clojure program into Rust, was very happy with the change<sup><a href="#hooked-on-rust">1</a></sup> and continued exclusively with Rust.<br>
While working on that project, I've developed some opinions about the two languages, especially about error handling and performance:</p>
<p>I think that these are areas where Rust excels, while they are among the weaker spots of Clojure<sup><a href="#not-hating-on-clojure">2</a></sup>.</p>
<p>To put my experience in context:
I had a bit more than one year of experience in Clojure when I moved to Rust.
The diff tool was by far the largest Clojure program I've ever written, and it was only about 3000 lines.<br>
When I started writing Rust, reimplementing the existing Clojure code was among my first Rust code.
I've continued learning Rust since then and have mostly stopped writing Clojure.<br>
If things have changed in Clojure recently, please let me know and I'll update the article.</p>
<h2 id="error-handling"><a href="#error-handling" aria-label="Anchor link for: error-handling">üîó</a>Error Handling</h2>
<p>The error handling requirements in this project were not very complicated.
All errors just needed to be logged and returned to the user.<br>
The only slightly unusual requirement was that parsing and validation logic should show all errors for each row in both uploaded excel files
(instead of just the first error) so I had to accumulate errors.</p>
<h3 id="error-handling-in-clojure"><a href="#error-handling-in-clojure" aria-label="Anchor link for: error-handling-in-clojure">üîó</a>Error Handling in Clojure</h3>
<p>Error handling in Clojure is not opinionated.<br>
<a href="https://lispcast.com/clojure-error-messages-accidental/">Similar to error messages</a>
, what error handling idioms exist in Clojure seem to me to be largely accidental or inherited from Java.</p>
<p>The standard library mostly supports <a href="https://clojuredocs.org/clojure.core/ex-info">exceptions</a>.<br>
There are some libraries that support returning error values instead of throwing exceptions like the error handling library <a href="https://github.com/adambard/failjure"><code>failjure</code></a>.<br>
Others, like the parsing library <a href="https://github.com/Engelberg/instaparse"><code>instaparse</code></a>, return their own custom error values<sup><a href="#insta-result">3</a></sup>.</p>
<p>I used failjure to help accumulate errors in a nicer way (and because it appealed to my Haskell-influenced taste).</p>
<p>Let's look at a Clojure function from my diff tool that uses <a href="https://github.com/adambard/failjure#attempt-all">attempt-all</a> to parse and validate the input data.
If any errors occur, all errors are aggregated into a string:</p>
<pre><code><span>(</span><span>defn </span><span>parse
  </span><span>[country-mapping data]
  #_"</span><span>   üëá the attempt-all function exits early 
           if any binding returned a failure</span><span>"
  (</span><span>fail/attempt-all
   </span><span>[headers (</span><span>header-row</span><span> data)
    parsed (</span><span>map
             </span><span>#(</span><span>parse-rule</span><span> headers country-mapping %)
             (</span><span>content-rows</span><span> data))
    #_"</span><span>           üëá list of failures is aggregated here</span><span>"
    failed-parses (</span><span>-&gt;&gt;</span><span> parsed
                    (</span><span>filter</span><span> fail/failed?)
                    (</span><span>map</span><span> fail/message))
    #_"</span><span>          üëá this can return a failure,
                    triggering an early exit</span><span>"
    parse-result (</span><span>if </span><span>(</span><span>empty?</span><span> failed-parses)
                   parsed
                   #_"</span><span>üëá a single failure value containing the
                         list of failures concatenated into a string</span><span>"
                   (</span><span>fail/fail
                    </span><span>(</span><span>let </span><span>[msg (</span><span>str
                               </span><span>"</span><span>Failed to parse </span><span>"
                               (</span><span>count</span><span> failed-parses)
                               "</span><span> rules:</span><span>")]
                      (</span><span>str</span><span> msg "</span><span>\n</span><span>" failed-parses))))
    #_"</span><span>          üëá This can also return a failure</span><span>"
    spec-result (</span><span>util/check-specs </span><span>"</span><span>Rules</span><span>"
                                  </span><span>:rule/id
                                  ::spec/rule</span><span>
                                  parse-result)]
   #_"</span><span>üëá if everything was successful, this is returned</span><span>"
   spec-result
   #_"</span><span>üëá if any failure occurred, this is returned</span><span>"
   (</span><span>fail/when-failed </span><span>[failure]
                       (</span><span>do
                         </span><span>(</span><span>log/warn
                           </span><span>(</span><span>str </span><span>"</span><span>Failed to parse data </span><span>"
                             data "</span><span>:</span><span>\n</span><span>" (</span><span>fail/message</span><span> failure)))
                         failure))))
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The identifier-expression pairs in the square brackets use the same syntax as Clojure's <a href="https://clojuredocs.org/clojure.core/let"><code>let</code>-form</a>
which makes it look familiar.</li>
<li>I can optionally add an error handling function to the very end, which is helpful to, e.g., log the argument of the function, as I did here.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I can't see which functions can actually fail. I have to read them to find out.</li>
<li>Since the Clojure ecosystem doesn't have a uniform error handling style, I have to manually convert exceptions or other errors like <code>instaparse</code> error values to <code>failjure</code> errors.</li>
</ul>
<p>My verdict is:<br>
Since Clojure is a Lisp, it's possible to use most kinds of error handling and make it look fine, if you really want to.
The most pragmatic solution in most cases will be to use exceptions.</p>
<p>I found that readability could suffer when using less explicit error handling, especially in a dynamic language.</p>
<p>Due to the freedom of choice in error handling approacher, I was tempted to experiment more than with a more opinionated language.</p>
<h3 id="error-handling-in-rust"><a href="#error-handling-in-rust" aria-label="Anchor link for: error-handling-in-rust">üîó</a>Error handling in Rust</h3>
<p>Rust is quite opinionated about error handling.
The Rust community has worked on developing and improving common idioms, some of which were incorporated into the standard library, thereby improving the baseline error handling.</p>
<p>There's no improvement without change though, and the frequent changes have been a source of complaints.
While backwards compatibility was never broken, people that wanted their code to be idiomatic had to update it anyway.
Old tutorials and guides have therefore also become outdated.</p>
<p>There are lots of good, up-to-date articles about error handling in Rust<sup><a href="#rust-error-handling-links">4</a></sup>, which help learn the current idioms.</p>
<p>In Rust, functions that can error return the <a href="https://doc.rust-lang.org/std/result/index.html"><code>Result</code></a> type<sup><a href="#panic-ref">5</a></sup>.<br>
There are several libraries that make creating your own errors or handling errors from libraries easier, but they (mostly) just use the types from the standard library instead of introducing new stuff that's incompatible with the rest of the ecosystem.</p>
<p>Let's look at the same function as before, but this time in Rust:</p>
<pre><code><span>pub fn </span><span>parse</span><span>(
    </span><span>workbook</span><span>: &amp;</span><span>mut</span><span> Workbook,
    </span><span>country_mapping</span><span>: CountryMapping,
) -&gt; Result&lt;Vec&lt;Rule&gt;&gt; {
    </span><span>let</span><span> range = workbook
        .</span><span>worksheet_range</span><span>("</span><span>Rules</span><span>")
        </span><span>// this question mark triggers an early exit
        // there are two because we have an Option
        // containing a Result                    üëá
        </span><span>.</span><span>ok_or</span><span>(format_err!("</span><span>Missing Rules sheet</span><span>"))??;
        </span><span>//                               üëá
    </span><span>let</span><span> range = </span><span>skip_to_header_row</span><span>(range)?;
    </span><span>let</span><span> parsed = RangeDeserializerBuilder::new()
        .</span><span>has_headers</span><span>(</span><span>true</span><span>)
        .</span><span>from_range</span><span>(&amp;range)
        </span><span>//                                    üëá
        </span><span>.</span><span>context</span><span>("</span><span>Failed to read Rules sheet</span><span>")?;
    </span><span>let</span><span> rules = </span><span>collect_errs</span><span>(parsed.</span><span>map</span><span>(|</span><span>parse_result</span><span>| {
        parse_result
            </span><span>// üëá mapping a lambda over the error value
            </span><span>.</span><span>map_err</span><span>(|</span><span>e</span><span>| e.</span><span>into</span><span>())
            </span><span>// üëá this would be called flatMap in some other languages
            </span><span>.</span><span>and_then</span><span>(|</span><span>row</span><span>| row.</span><span>parse</span><span>(&amp;country_mapping))
    }))
    </span><span>// üëá this converts a list of errors into a single error
    //    containing a string
    </span><span>.</span><span>map_err</span><span>(|</span><span>es</span><span>| {
        format_err!(
            "</span><span>Failed to parse {} rules:</span><span>\n</span><span>{}</span><span>",
            es.</span><span>len</span><span>(),
            </span><span>// üëá very elegant...
            //    this would just be one .joinToString call in Kotlin
</span><span>            es.</span><span>into_iter</span><span>()
                .</span><span>map</span><span>(|</span><span>e</span><span>| e.</span><span>to_string</span><span>())
                .collect::&lt;Vec&lt;_&gt;&gt;()
                .</span><span>join</span><span>("</span><span>\n</span><span>")
        )
   </span><span>// üëá
    </span><span>})?;
    Ok(rules)
}
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The standard library, every Rust library I've ever seen and my own application code is always using the same <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a> type, which keeps things pretty compatible.</li>
<li><a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">The <code>?</code> operator</a> makes fallible functions visible but keeps it succinct.<br>
It also automatically converts error types where possible, which reduces the need for manual type conversion.</li>
<li>The error type I'm using here from the library <a href="https://docs.rs/anyhow/*/anyhow/index.html"><code>anyhow</code></a> supports a <a href="https://docs.rs/anyhow/*/anyhow/trait.Context.html"><code>.context</code></a> method, which gives otherwise unhelpful low-level errors the necessary context.<br>
This is usually done in exception-based languages by catching, wrapping and rethrowing, but this looks a lot more pleasant.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I have to keep the error types compatible, which I accomplish in this case by not distinguishing between different error types at all<sup><a href="#anyhow-usecase">6</a></sup>.<br>
I still have to return a single error value, which means I have to manually and verbosely convert the list of errors into a single one - in this case a newline-delimited string.</li>
<li>If I want to log something when this entire function returns an error or add some <code>.context</code> to it, I would like to have the equivalent of a <code>try/catch</code>-block around the entire function body.<br>
This doesn't exist yet<sup><a href="#try-blocks">7</a></sup>, the current best practice seems to be do move the entire body into an inner function or lambda.</li>
</ul>
<p>My verdict is:<br>
In Rust, you will use the <code>Result</code> type and you will like it<sup><a href="#and-you'll-like-it">8</a></sup>.<br>
The main design decisions are whether you use some of the helper libraries and how you design your error types.</p>
<p>Designing the error types can be a challenge though, especially because it's a bit different than designing e.g. Java exception hierarchies.<br>
I was lucky that keeping up to date with the evolving error handling idioms wasn't too hard for me as I was not under time pressure and often worked in my spare time with learning as my primary objective.
It might have been painful for teams maintaining bigger production systems.<br>
The large number of error handling tutorials and articles should hopefully make it easier to learn now than it was a few years ago.</p>
<p>The learning curve aside:
To me, Rust's error handling feels like part of the secret sauce that makes it the most promising language for correctness that I know of.</p>
<h2 id="performance"><a href="#performance" aria-label="Anchor link for: performance">üîó</a>Performance</h2>
<p>The part of the program that caused performance issues was the diff algorithm and, to a slightly lesser extent, a data normalization step before that.<br>
The type of performance problems I had were mostly being CPU bound, having to generate and compare a lot of temporary data.
The large amount of data also often caused memory issues in both languages.</p>
<h3 id="clojure-performance"><a href="#clojure-performance" aria-label="Anchor link for: clojure-performance">üîó</a>Clojure Performance</h3>
<p>In ‚Ä¶</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timofreiberg.github.io/clojure-vs-rust/">https://timofreiberg.github.io/clojure-vs-rust/</a></em></p>]]>
            </description>
            <link>https://timofreiberg.github.io/clojure-vs-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497050</guid>
            <pubDate>Mon, 21 Dec 2020 17:23:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix's Metaflow: Reproducible machine learning pipelines]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 97 (<a href="https://news.ycombinator.com/item?id=25497008">thread link</a>) | @ChefboyOG
<br/>
December 21, 2020 | https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>From training to deployment with Metaflow and Cortex</h4></p><div content-type="article"><p>If we were to design an optimal machine learning pipeline, it would be:</p><ul role="list"><li><strong>Scalable</strong>. As workloads increased, it would scale up without issue.</li><li><strong>Reproducible</strong>. We would be able to draw a line from any model to its data.</li><li><strong>Configurable</strong>. It wouldn‚Äôt lock us into particular frameworks or tools.</li></ul><p>Typically, pipelines will tradeoff in at least one of these areas. A pipeline might be scalable, but will rely on a platform that puts limits on data scientists. Or, a pipeline will be completely configurable, but will also be glued together by a mess of ad hoc code and will be impossible to reproduce.</p><p>In this piece, I want to introduce a way to build this kind of ideal pipeline without any tradeoffs. To do this, we‚Äôll be using <a href="https://metaflow.org/" target="_blank">Metaflow, the open source data science framework from Netflix</a>, and <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex, our open source deployment platform for machine learning</a>. </p><p>Let‚Äôs start by defining our pipeline.</p><h3>Defining a pipeline in Metaflow</h3><p>Metaflow is a data science framework that provides a single API for managing different pieces of the infrastructure stack. It places an emphasis on scalability, reproducibility, and usability.</p><div><p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/XV5VGddmP24" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></div><p>At a high level, Metaflow allows us to define pipelines as DAGs, called ‚Äúflows,‚Äù in which data undergoes a sequence of transformations called ‚Äùsteps.‚Äù These steps persist transformed data as ‚Äúdata artifacts,‚Äù which are accessible by subsequent steps throughout the flow. </p><p>For example, say we had a training flow that loaded data (probably produced by another flow), trained multiple models with different strategies, evaluated the different models, and saved the top performer:</p><p>This is just a snapshot of our full pipeline, which I‚Äôll be adding to in the next section, but even with just this snippet we have a repeatable training pipeline that can scale to run on many machines. We also have, thanks to Metaflow‚Äôs Client API, a way to version, audit, and reproduce these training runs.</p><p>For example, to instantiate a given step from a previous flow, we can simply pass in the flow name, run id, and step name to the Metaflow Client:</p><p>To access an artifact from a particular run, the logic is very similar:</p><p>This means that every time a flow is executed, Metaflow automatically versions and records it using a standard taxonomy. As a result, we can trace any given model‚Äôs lineage from raw data to final export. </p><p>There is much more to Metaflow, and I‚Äôd encourage you to check out their <a href="https://docs.metaflow.org/" target="_blank">documentation</a> to learn more, but as an introduction, this should serve to get us started. </p><p>Now, let‚Äôs talk a bit about triggering deployments in Metaflow.</p><h3>Deploying models with Cortex</h3><p>In this section, I‚Äôm going to take our training flow from before and add a step for deploying our model as a production API on AWS. To do this, we‚Äôre going to use Cortex.</p><p>Cortex is a deployment platform for machine learning. On the surface, it provides simple interfaces for building prediction services, deploying them to production, and managing an inference cluster. </p><p>Under the hood, Cortex automates all of the cloud infrastructure needed for inference‚Äîautoscaling, GPU/ASIC support, load balancing, prediction tracking, etc‚Äîand implements a automated deployment process in which model serving code is packaged, versioned, and deployed to the cluster.</p><p>We can trigger a deployment using Cortex‚Äôs Python client within our training flow like this:</p><p>You‚Äôll notice the client includes a deploy() method, which takes a configuration object for defining our API. This configuration works with the Metaflow client to extract the location of the model, and the metadata of the flow for logging purposes. Now, when we audit our deployments, we can connect it all the way back to the run that produced it, extending our lineage from data to deployment.</p><p>The configuration object also references a predict.py script, which is where the actual prediction service is defined. A Cortex predictor looks like this:</p><p>The structure is very simple. We initialize our model in the init() function, which runs on initial deployment, and we generate predictions in the predict() function. Similar to steps in Metaflow, these Python methods can contain whatever logic you want to implement.</p><p>Now, when we run the flow, the model will be trained, evaluated, and deployed to production with zero downtime or extra configuration needed. </p><p>Because Cortex provides native support for A/B testing and traffic splitting, we can even run complex deployment strategies without breaking Metaflow‚Äôs lineage.</p><p>For example, if after selecting a best model, we wanted to test how the model performed in different formats‚Äîsay ONNX vs TensorFlow‚Äîwe could export two versions of the model, deploy them both in an A/B test, and log their performance. Because our training flow is connected to our deployment, we can then pass this information back and forth between Cortex and Metaflow without issue.</p><h3>An easier path to production machine learning</h3><p>Over the years, a number of end-to-end data science platforms have been released, and most of them fall into the same traps:</p><ul role="list"><li>Providing a smooth interface, with zero transparency into what‚Äôs happening under the hood, killing reproducibility and auditing.</li><li>Solving one part of the stack well, like training, but ‚Äúbolting on‚Äù under-developed solutions for other parts, like deployment.</li><li>Locking data scientists and machine learning engineers into a narrow stack by only supporting specific frameworks and integrations.</li></ul><p>The result is a platform that makes production machine learning easy‚Äîif you stay strictly within the confines of the system. When you have a diverse set of problems to solve, however, this is difficult to do.</p><p>Metaflow and Cortex represent a fundamentally different, human-centric approach. The emphasis is not on providing a magic solution to a narrow set of problems, but on providing an easy interface for building solutions to any problem.</p><p>If you‚Äôre interested in digging into either platform, check out the links below:</p><ul role="list"><li><strong>Metaflow documentation: </strong> <a href="https://docs.metaflow.org/" target="_blank">https://docs.metaflow.org/</a></li><li><strong>Metaflow GitHub: </strong><a href="https://github.com/Netflix/metaflow" target="_blank">https://github.com/Netflix/metaflow</a></li><li><strong>Cortex documentation: </strong><a href="https://docs.cortex.dev/" target="_blank">https://docs.cortex.dev/</a></li><li><strong>Cortex GitHub: </strong><a href="https://github.com/cortexlabs/cortex" target="_blank">https://github.com/cortexlabs/cortex</a></li></ul><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497008</guid>
            <pubDate>Mon, 21 Dec 2020 17:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chef cofounder on CentOS: It‚Äôs time to open source everything]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25493606">thread link</a>) | @ashitlerferad
<br/>
December 21, 2020 | https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/ | <a href="https://web.archive.org/web/*/https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Commentary: Red Hat has been in hot water about changing the way CentOS operates, but that model looks like the exact right way for open source entrepreneurs to operate.</p><div data-component="lazyloadImages">
<figure><span></span><figcaption></figcaption></figure>
<p>Red Hat switched up CentOS to make it less of a Red Hat Enterprise Linux (RHEL) clone and more of a feeder project into RHEL (as Fedora was always supposed to be, yet wasn‚Äôt). Some people are mad, as <a href="https://www.zdnet.com/article/red-hat-resets-centos-linux-and-users-are-angry/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Steven J. Vaughan-Nichols has written</a> on sister site ZDNet. Some people, like former Disney employee Justin Garrison, <a href="https://twitter.com/rothgar/status/1337818039799070722" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">think</a> it sounds perfect (the hipper, slightly edgier version of RHEL). If you‚Äôre a billion-dollar company upset that Red Hat appears to be trying to charge for something you value, the <a href="https://www.zdnet.com/article/goodbye-centos-hello-rocky-linux/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">founder of CentOS has a new way for you to get something for nothing</a>: Rocky Linux.</p>

<p>But if you‚Äôre an open source entrepreneur wondering what this means for you, well, Chef cofounder and System Initiative CEO <a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Adam Jacob has you covered</a>. In a series of tweets, he walks through how Red Hat‚Äôs CentOS strategy can play out for you. (He should know, as the company he co-founded, Chef, <a href="https://www.techrepublic.com/article/why-chefs-100-open-source-move-is-smart-business/" data-absolute="true">last year open sourced everything</a>.)</p>
<p>Let‚Äôs observe.</p>
<h2>Open source all the things</h2>
<p><a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob‚Äôs first rule</a>? Open it up. Completely. ‚ÄúIf I do an open source strategy for a company ever again, I will own the upstream, it will be fully open source, and I‚Äôll happily collaborate with anyone downstream.‚Äù But not just an open upstream‚Äìit‚Äôs also important to, ‚ÄúProduce a commercial distribution [and c]ollaborate on downstream non-commercial ones, in the open,‚Äù he <a href="https://twitter.com/adamhjk/status/1337062321982758912" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">argued</a>.</p>
<p>What does he mean by ‚Äúupstream‚Äù and ‚Äúdownstream‚Äù? In open source, think of the <a href="https://opensource.stackexchange.com/questions/993/what-does-upstream-mean" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">upstream</a> as the parent, the head, the initial open source project. Downstream might be forks or distributions (packaging up of a particular build of the upstream code) of the upstream.</p>
<p>What Red Hat announced was basically that CentOS would move from being downstream to upstream. It becomes a place, as <a href="https://twitter.com/adamhjk/status/1337062318451068929" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob noted</a>, that others <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">like Facebook</a> can collaborate with Red Hat in a way they simply couldn‚Äôt before (as Fedora wasn‚Äôt closely enough aligned with RHEL). CentOS as a downstream RHEL community was mostly one of users, of consumers, not of collaborators. It was somewhere to get RHEL, but rebranded CentOS, for free.</p>
<p>As such, Jacob pointed out, ‚ÄúThey weren‚Äôt invested in it beyond using it.‚Äù And when someone removes the downstream they get mad ‚Äúbecause it‚Äôs like someone threatened the water supply,‚Äù <a href="https://twitter.com/adamhjk/status/1337062319558434822" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">he argued</a>. It‚Äôs therefore far better to condition people to participate as collaborators with an open source project, and through the commercial distribution to also condition users to become customers, if they want the certified distribution.</p>
<h2>Open source + cloud</h2>
<p>One way that open source companies are doing this model to fantastic effect is by open sourcing their upstream and creating a cloud distribution (read: managed service). A variety of companies have embraced this model to greater or lesser extents.</p>
<p>Yugabyte, for example, ditched its Open Core model a year ago and open sourced 100% of its database code. A year later, CTO Karthik Ranganathan told me in an interview, ‚ÄúIt increased our adoption like crazy,‚Äù growing the number of Yugabyte clusters 10x, but it also has dramatically accelerated their business without them losing any known pipeline. Could someone take that upstream and create a competitive downstream competitor? Of course. But no one should be able to out-Yugabyte on their home turf.</p>
<p>Or take Redis Labs. The company has fiddled with licensing over the last few years, but has kept core Redis completely open while encouraging a growing community (which includes downstream competitors) to lend a hand to improving the code. While Redis Labs doesn‚Äôt publish results, its business is booming, even as 10 or so other companies have created competitive downstream managed service offerings.</p>
<p>Which brings us back to Jacob: ‚ÄúRun an open upstream from the jump. Produce a commercial distribution. Collaborate on downstream non-commercial ones, in the open.‚Äù</p>
<p>That‚Äôs the strategy. That‚Äôs the magic. You don‚Äôt need to go Open Core or any other permutation of kind-of, sort-of open source. You can open source everything and just ensure you have a rock-solid managed cloud service. This reliance on cloud is what‚Äôs driving MongoDB, Confluent, DataStax, Redis Labs, and others to great success. It can be your model, too.</p>
</div></div>]]>
            </description>
            <link>https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493606</guid>
            <pubDate>Mon, 21 Dec 2020 10:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Commutation and Scalability]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25493577">thread link</a>) | @Ygg2
<br/>
December 21, 2020 | https://pijul.org/posts/2020-12-19-partials/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-12-19-partials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Sunday, December 20, 2020</p>
<p>I just finished the implementation of an important feature of Pijul: clones, pushes and pulls on partial repositories. In this post, I explain why this matters.</p>
<h2 id="change-commutation">Change commutation</h2>
<p>Pijul is based on <em>changes</em>, also called <em>patches</em> or <em>diffs</em>.
This doesn‚Äôt mean that its only internal datastructure is patches, quite to the contrary: it was only by departing from a patch-only internal representation that we were able to solve the algorithmic challenges inherent to patch-based systems.</p>
<p>However, being change-based does mean that the core operations of Pijul are defined on changes, and that Pijul is designed in such a way that changes satisfy basic intuitive properties, similar to algebraic operations. One basic thing is that applying a change is an <em>associative</em> operation, like matrix multiplication: applying $A$ and $B$ at once, and then later $C$, is the same as applying $A$, and then $B$ and $C$ at once. In matrix multiplication, $(AB)C = A(BC)$. Moreover, in Pijul, all changes are invertible (whereas only some matrices are): for any change $A$, there is an ‚Äúinverse change‚Äù $A^{-1}$ such that applying $A^{-1}$ after $A$ is the same as applying neither. Of course, both $A$ and $A^{-1}$ will appear in the log, but the contents of the repository will be the same as applying neither $A$ nor $A^{-1}$.</p>
<p>There is another property that users want from version control systems, and that is <strong>commutation</strong>.
Matrix multiplication rarely commutes<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
In Git, commutation is usually <em>simulated</em> using branches and rebase: indeed, rebasing a branch A on top of another branch B really means commuting the commits of A since the divergence between A and B, and the commits of B since the divergence. However, that commutation isn‚Äôt perfect, since the commits must change their hash when rebased.</p>
<p>Things are simpler in Pijul, because any two changes that <em>could have been written independently</em> always commute, meaning that if the two changes could be written without knowledge of each other, they can be applied in any order.</p>
<p>This of course raises a potential concern:</p>
<blockquote>
<p>If I can apply $A$ and $B$ in any order, how do I know which order is the <strong>right</strong> one?</p>
</blockquote>
<p>In Pijul, this question <strong>does not matter</strong>: both orders will yield <strong>the exact same result</strong>, the only difference is that the log will list the changes in the order in which they were applied. And I‚Äôm not saying that it doesn‚Äôt matter because I‚Äôm careless, but because it truly is the same thing.</p>
<blockquote>
<p>I disagree: it does matter, I still prefer to have a ‚Äú<em>linear</em>‚Äù order for my changes/commits.</p>
</blockquote>
<p>Indeed, everybody wants to see the order of operations in a repository, for many reasons. For example:</p>
<ul>
<li>We want to keep a record of the operations performed on our repository.</li>
<li>We want to go back in time.</li>
</ul>
<p>And in fact, Pijul allows you to do exactly that, but in a more rigorous way than Git. Indeed, take the scenario where Alice and Bob work together, Alice makes a change $A$ while Bob makes $B$. When they put their work together, Alice applies Bob‚Äôs change, resulting in the log $AB$, while Bob applies Alice‚Äôs change, resulting in the log $BA$. In this case, there is no ‚Äútrue‚Äù linear history, since they worked on different things, and took different steps at different times. However, both of them want to be able to go back in time, step-by-step, and not just ‚Äú<em>step-by-step-according-to-Bob‚Äôs-order</em>‚Äù.</p>
<h2 id="commutation-and-massive-repositories">Commutation and massive repositories</h2>
<p>One of the biggest challenge for Pijul up to the recent releases was scalability: even modestly-sized repositories like Pijul‚Äôs source code would use a lot of disk space. This was even more disappointing since, as I‚Äôm about to explain, commutation was suposed to allow it to scale to gigantic repository sizes‚Ä¶ in theory. The same problem also made massive tests impossible, meaning that getting past the ‚Äú0.x releases‚Äù seemed more and more impossible as time passed.</p>
<p>Now that this phase is mostly behind us, the cool bits of the theory finally become practical.</p>
<p>In particular, in Pijul, each change contains a reference to the files it modifies. Note that, because we want operations on repositories (such as renaming files) to commute with edits inside files, we don‚Äôt identify files and directories by name, but by a unique identifier made from the hash of the change that introduced that file or directory.</p>
<p>For repositories with multiple projects, this makes it possible to clone and pull just parts of a repository, and work on that part as if we had the entire thing. Indeed, imagine we have a repository with the following log:</p>
<ol>
<li>A, adding file <em>x</em></li>
<li>B, editing <em>x</em></li>
<li>C, adding file <em>y</em></li>
<li>D, adding file <em>z</em></li>
<li>E, renaming <em>x</em> to <em>w</em></li>
<li>F, editing <em>y</em> and <em>z</em></li>
</ol>
<p>All these changes do not necessarily commute; however, since B and C touch completely different files (namely, <em>x</em> and <em>y</em>), they could be produced in parallel, and hence they commute. This means that we can pull only the changes related to a specific file, say <em>x</em>, and make the following history: A, B, E<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>Moreover, any change made on top of that sequence will commute with C, D and F: indeed, if we edit file <em>x</em> again, producing a change G, then since G can be made in parallel to C, D and F, we can push G after any patch that comes after B in that history, for example getting history ‚ÄúABCDEFG‚Äù.</p>
<p>Note that this is done without changing the changes nor their hash.</p>
<h2 id="another-trick-for-large-files">Another trick for large files</h2>
<p>As explained in previous posts on this blog, Pijul changes have a bit more information than diffs, and operate on graphs rather than files. This means that changes can be split into two parts, a short-ish one with a binary specification of the graph operations, and then the new content inserted by the change.</p>
<p>The change format is designed to be downloadable in two stages: one can download the operations without downloading the contents. One issue with this is security: if we don‚Äôt download the contents, how can we make sure that the hash is right? This is done by including a hash of the change in the ‚Äúoperations‚Äù section of the change, and letting the hash of a change be the hash of the ‚Äúoperations‚Äù section.</p>
<p>This makes it possible for someone to make five versions of a large binary file in a day, where each change deletes the entire file, and adds it again, the operation sections only contain the length of the different versions, not the actual bytes. In order to get the latest version of the file, a client will therefore only have to download the latest change completely, and only the operations section of the previous ones.</p>
<p>Note that this makes the following ‚Äúattack‚Äù possible: a server might trick a client into believing that the server has a change with hash $A$, which inserts $n$ bytes into a file, and then another change with hash $B$, deleting all these bytes. When the client downloads $A$ and $B$, it doesn‚Äôt need to download the contents. However, if the client later decides to unrecord $B$, the contents of $A$ will have to be downloaded, and the client will be able to tell that the hash of $A$ was incorrect. This should make it impossible to unrecord $B$ without also unrecording $A$. However, if $A$ made other edits, and other changes depend on $A$, this could be problematic.</p>
<h2 id="what-is-next">What is next?</h2>
<p>There is one remaining painpoint for very large repositories, and this is the fact that in order to clone a repository with a very large history, one must download and apply all the changes, one by one. Even though our apply function is quite fast<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, this can still be problematic for dozens or hundreds of thousands of changes.</p>
<p>In my next post, I will talk about a solution to this problem, which I have started to implement.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Matrices that are simultaneously diagonalizable do, for example, but for two arbitrary matrices $A$ and $B$, $AB$ is often different from $BA$. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Note that in this case, we could also pull A, E, B, since renaming a file commutes with editing it. However, we must start with A, since adding a file could not be possibly done in parallel to editing or renaming it. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The complexity of apply is in $O(|p| |c| \log |H|)$, where $|p|$ is the size of the change, $|c|$ is the size of the largest conflict in which $p$ is involved, and $|H|$ is the number of edits made since the start of the repository. <a href="#fnref:3" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://pijul.org/posts/2020-12-19-partials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493577</guid>
            <pubDate>Mon, 21 Dec 2020 10:14:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Lisp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25493495">thread link</a>) | @wheresvic4
<br/>
December 21, 2020 | https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019 | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  It's 2019 and Lisp stories are on fire at HackerNews. While there exist multiple Lisp dialects, Common Lisp is the
  oldest and most mentioned. Thus, if you're looking to get started with programming in Common Lisp, then there are 2
  options:
</p>

<ul>
  <li>Use <a href="https://portacle.github.io/">portacle</a> to get up and running with SBCL + Emacs.</li>
  <li>
    Use
    <a href="https://github.com/roswell/roswell">roswell</a> to install multiple Lisp implementations + build and bundle
    lisp applications. Roswell installs SBCL by default.
  </li>
</ul>

<p>
  As for me, I did not feel like learning a brand new text editor just to get started with Lisp so I went with Roswell.
  Follow the instructions on installing Roswell for your platform. In my case, I decided to install it under
  <code>$HOME/bin</code> on my linux machine via:
</p>

<pre>$ sudo apt install rlwrap
$ mkdir $HOME/bin
$ git clone -b release https://github.com/roswell/roswell.git
$ cd roswell/
$ sh bootstrap
$ ./configure --prefix=$HOME/bin
$ make
$ make install</pre>

<p>
  Make sure to add the roswell path to your <code>~/.bashrc</code> (note that roswell installed itself under
  <code>~/bin/bin</code> and if this looks odd to you, install it under <code>$HOME/apps</code> or something of the
  sort):
</p>

<pre>if [ -d "$HOME/bin/bin" ] ; then
  PATH="$HOME/bin/bin:$PATH"
fi</pre>

<p>
  Open a new terminal and setup roswell:
</p>

<pre>$ which ros
/home/xxx/bin/bin/ros
$ ros --version
roswell 19.06.10.100
$ ros setup </pre>

<p>
  We will now setup VSCode to run lisp. First install the
  <a href="https://marketplace.visualstudio.com/items?itemName=mattn.Lisp">vscode-lisp</a> extension. Open a new file
  and type the following in:
</p>

<pre>(defun main ()
  (format t "Hello world"))
</pre>

<p>
  Then <a href="https://code.visualstudio.com/docs/editor/integrated-terminal">launch a terminal</a> inside VSCode. In
  the terminal run <code>rlwrap ros run</code> to start the REPL (Read/Eval/Print Loop). Select the above defined
  function and use the "Run Selected Text in Active Terminal" from the Command Palette (F1) to run your code!
  Note that you can exit the REPL via: <code>(SB-EXT:EXIT)</code>. The <code>rlwrap</code> utility remembers previously
  typed commands which makes for a much nicer REPL experience.
</p>

<p>
  What is amazing about Roswell is that is comes with a scripting / build ability that allows you to easily distribute
  your application. To see this in action first create a roswell script via <code>ros init hello-world</code>. Then add
  in the following code so that your script looks like the following:
</p>

<pre>#!/bin/sh
#|-*- mode:lisp -*-|#
#|
exec ros -Q -- $0 "$@"
|#
(progn ;;init forms
  (ros:ensure-asdf)
  ;;#+quicklisp(ql:quickload '() :silent t)
  )

(defpackage :ros.script.hello-world.3774807541
  (:use :cl))
(in-package :ros.script.hello-world.3774807541)

(defun helloWorld
  ()
  (format t "Hello world")
)

(defun main (&amp;rest argv)
  (declare (ignorable argv))
  (helloWorld))
;;; vim: set ft=lisp lisp:
</pre>

<p>
  We can now simply run this script via <code>ros hello-world.ros</code> but more interestingly, we can actually compile
  a binary via <code>ros build hello-world.ros &amp;&amp; ./hello-world</code>.
</p>

<p>
  Interestingly enough, I am not a complete noob to Common Lisp, I actually programmed it 15 years ago during my
  undergrad years. A colleague and I
  <a href="https://smalldata.tech/api/to/847c726edff337b818ba86914d9e71b6">compared an experimental genetic algorithm against an ant colony optimization algoritm on a path-finding problem</a>. Once I had lisp running I opened up the project and basically executed <code>ants.lisp</code> in the REPL, ran
  <code>(INITIALIZE-ANT-WORLD)</code> followed by <code>(DISPATCH-ANTS)</code> and voila, my ants were able to find
  their food!
</p>

<p>
  No guide to getting started with Lisp would be complete without a list of further reading that will keep you busy for
  the next 100 years so here we go:
</p>

<ul>
  <li>
    A very basic Lisp <a href="https://lisp-lang.org/learn/first-steps">tutorial</a> which also features an excellent
    <a href="https://lisp-lang.org/books/">list</a> of Lisp books
  </li>
  <li>
    <a href="https://smalldata.tech/api/to/3c02f249908494a961ac4b28e33f1ec5">A road to common lisp</a> - Steve Losh's excellent guide to
    getting into Lisp programming. The following is a small snippet of useful information from the post:
    <ul>
      <li>
        Files are files on your hard drive.
      </li>
      <li>Packages are containers of symbols. They are orthogonal to files.</li>
      <li>
        Systems are collections of code, instructions on how to load that code, dependency lists, and metadata. They are
        orthogonal to packages.
      </li>
      <li>
        Projects are high-level collections of "stuff" such as code, documentation, maybe some image assets,
        etc. They are (mostly) orthogonal to systems.
      </li>
      <li>Common Lisp itself knows about files and packages.</li>
      <li>ASDF adds systems.</li>
      <li>Quicklisp adds the internet.</li>
    </ul>

    This guide also provides a very nice review of libraries and is definitey worth a read.
  </li>
  <li>
    Another <a href="https://smalldata.tech/api/to/cb5d30e9026cba3d1d0b838611d1624c">article</a> that recommends roswell and provides
    instructions for Atom integration along with project and library management.
  </li>
</ul>

<p>
  Well, that's about it - Lisp is beautiful and I'm off to wrap my head around some 15 year old code that doesn't look
  too bad, go functional programming!
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F08%2F16%2Fgetting-started-with-lisp-in-2019&amp;t=Getting%20started%20with%20Lisp%20in%202019">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493495</guid>
            <pubDate>Mon, 21 Dec 2020 09:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Herald ‚Äì Bluetooth contact tracing protocol]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25492423">thread link</a>) | @npad
<br/>
December 20, 2020 | https://vmware.github.io/herald/ | <a href="https://web.archive.org/web/*/https://vmware.github.io/herald/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div>
  <div>
    <div>
      <div>
        
        <p>Herald provides reliable Bluetooth communication and range finding across a wide range of mobile devices, allowing Contact Tracing and other applications to have regular and accurate information to make them highly effective.</p>        
      </div>
      
    </div>
  </div>
</div> <!-- /home-hero -->



<!--
<div class="section pb-0">
    <div class="section-content">
      <div class="row">
        <div class="col">
          <h2 class="text-center"></h2>
          <p></p>
  
          <ul>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
--> 

<div>
  <div>
    <div>
      <p>
        <h2>Herald solves risk estimation problems</h2>
      </p>          
    </div>
    <p><img src="https://vmware.github.io/herald/images/EstimationBenefits.png" alt="Herald estimation benefits">
  </p></div>
</div>

<div>
  <div>
    
    
    
<div>
  
    <div>
      
      <div>
        <div>
          
          <h5>Detect nearby phones</h5>
          
          
<p>100% detection of phones in the foreground and background across iOS and Android devices. <a href="https://vmware.github.io/herald/efficacy/herald">Herald supports</a>) 100% of the phones in the UK that support advertising, as well as the 35% of Android phones (<a href="https://vmware.github.io/herald/efficacy/statistics">~14% of all phones overall</a>) that cannot act as ‚Äòadvertisers‚Äô and so remain unseen by advertising-only based protocols.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Provide regular distance readings</h5>
          
          
<p>Herald performs distance estimations every few seconds, with higher frequency on modern phones. This allows for a more accurate data and risk picture over time. Maximum frequency can be configured to optimise battery use. At <a href="https://vmware.github.io/herald/efficacy/herald">~4s per reading battery use is 6-11% over 8 hours</a>), depending on the age of the phone and its battery capacity.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Interoperate internationally</h5>
          
          
<p>By providing a common packet header we allow for <a href="https://vmware.github.io/herald/payload/interop">international interoperability</a> amongst all contact tracing applications, whether designed for centralised or decentralised contact matching and risk scoring.</p>

          
        </div>
      </div>
    </div>
    
        
</div>

  </div>
</div>

<div>
  <div>
    
    
    <div>

    
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New guides added to website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/guides">New guides added to website</a>
                </h5>
                <p>
                    We‚Äôve been busy getting ready for the upcoming V1.1 release. For this release we‚Äôve dramatically changed
our documentation on this website.


                </p>
            </article>
        </div>
    </div>
</div>
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New logo and website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/website">New logo and website</a>
                </h5>
                <p>
                    Quite a few things have happened in the first month since Herald was published as Open Source Software
under the MIT license. [29 Nov 2020 NOTE: Code now under the Apache-2.0 license]


                </p>
            </article>
        </div>
    </div>
</div>
        
         
</div>
    
  </div>
</div>


<div>
  <div>
    
<p>
A lot of work has gone in to mobile app based contact tracing protocol 
research, design, testing and collaboration worldwide. We'd like to thank 
all of those in VMware Pivotal Labs and elsewhere worldwide that have 
assisted with various national and state governments to use mobile contact 
tracing to help save lives. ‚ù§Ô∏è
</p>
  </div>
</div>

<div>
  <div>
    
<p>

All Herald works are Copyright 2020 Herald Authors.
</p>
<p>
The code for Herald (Android, iOS, Analysis Scripts, Calibration tool) are Apache-2.0 licensed. The documentation for Herald, including this website, are under the Creative Commons Attribution 4.0 International Public License.
</p>
<p>
See LICENSE.txt and NOTICE.txt for details.
</p>
  </div>
</div>


<div>
  <div>
    
<div>
  <div>
    <p>Herald Project is released as open source software and provides community support through our GitHub project page.
        If you encounter an issue or have a question, feel free to reach out on the <strong><a href="https://vmware.github.io/herald/issues">GitHub issues page for Herald Project</a></strong>.</p>
    <p>The Herald project team welcomes contributions from the community ‚Äî please see our <strong><a href="https://github.com/vmware/herald/blob/master/contributing.md">contributing documentation</a></strong>.</p>
  </div>
</div>



  </div>
</div>
      <div>
    <div>
        <div>
            <div>
                <h5>Getting Started</h5>
                <p>To help you get started, see the documentation.</p>
            </div>
            
        </div>
    </div>
</div>




<!-- JS -->







    </div>
  </div></div>]]>
            </description>
            <link>https://vmware.github.io/herald/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492423</guid>
            <pubDate>Mon, 21 Dec 2020 05:44:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Recovery Legend (1986)]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25491790">thread link</a>) | @signa11
<br/>
December 20, 2020 | https://www.ee.ryerson.ca/~elf/hack/recovery.html | <a href="https://web.archive.org/web/*/https://www.ee.ryerson.ca/~elf/hack/recovery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h4>This classic article from Mario Wolczko first
appeared on Usenet in 1986.  </h4>

Have you ever left your terminal logged in, only to find when you
came back to it that a (supposed) friend had typed "<kbd>rm -rf
~/*</kbd>" and was hovering over the keyboard with threats along the
lines of "<em>lend me a fiver 'til Thursday, or I hit return</em>"?
Undoubtedly the person in question would not have had the nerve to
inflict such a trauma upon you, and was doing it in jest.  So you've
probably never experienced the worst of such disasters....<p>


It was a quiet Wednesday afternoon.  Wednesday, 1st October, 15:15
BST, to be precise, when Peter, an office-mate of mine, leaned away
from his terminal and said to me, "<em>Mario, I'm having a little
trouble sending mail.</em>" Knowing that msg was capable of confusing
even the most capable of people, I sauntered over to his terminal to
see what was wrong.  A strange error message of the form (I forget
the exact details) "<kbd>cannot access /foo/bar for userid 147</kbd>"
had been issued by msg.  My first thought was "<em>Who's userid 147?;
the sender of the message, the destination, or what?</em>" So I leant
over to another terminal, already logged in, and typed</p><blockquote>        <kbd>grep 147 /etc/passwd</kbd></blockquote>

<p>only to receive the response</p><blockquote>        <kbd>/etc/passwd: No such file or directory.</kbd></blockquote>

Instantly, I guessed that something was amiss.  This was confirmed
when in response to<blockquote>        <kbd>ls /etc</kbd></blockquote>

<p>I got</p><blockquote>        <kbd>ls: not found.</kbd></blockquote>

I suggested to Peter that it would be a good idea not to try anything
for a while, and went off to find our system manager.<p>

When I arrived at his office, his door was ajar, and within ten
seconds I realised what the problem was.  James, our manager, was
sat down, head in hands, hands between knees, as one whose world has
just come to an end.  Our newly-appointed system programmer, Neil, was
beside him, gazing listlessly at the screen of his terminal.  And at
the top of the screen I spied the following lines:</p><blockquote>
        <kbd># cd <br>
        # rm -rf *</kbd>
</blockquote>

<p>Oh, shit, I thought.  That would just about explain it.</p><p>


I can't remember what happened in the succeeding minutes; my memory
is just a blur.  I do remember trying <kbd>ls</kbd> (again),
<kbd>ps</kbd>, <kbd>who</kbd> and maybe a few other commands beside,
all to no avail.  The next thing I remember was being at my terminal
again (a multi-window graphics terminal), and typing</p><blockquote>
        <kbd>cd /<br>
        echo *</kbd>
</blockquote>
<p>I owe a debt of thanks to David Korn for making <kbd>echo</kbd> a
built-in of his shell; needless to say, <kbd>/bin</kbd>, together
with <kbd>/bin/echo</kbd>, had been deleted.  What transpired in the
next few minutes was that <kbd>/dev</kbd>, <kbd>/etc</kbd> and
<kbd>/lib</kbd> had also gone in their entirety; fortunately Neil had
interrupted <kbd>rm</kbd> while it was somewhere down below
<kbd>/news</kbd>, and <kbd>/tmp</kbd>, <kbd>/usr</kbd> and
<kbd>/users</kbd> were all untouched.</p><p>


Meanwhile James had made for our tape cupboard and had retrieved what
claimed to be a dump tape of the root filesystem, taken four weeks
earlier.  The pressing question was, "<em>How do we recover the
contents of the tape?</em>".  Not only had we lost
<kbd>/etc/restore</kbd>, but all of the device entries for the tape
deck had vanished.  And where does <kbd>mknod</kbd> live?  You
guessed it, <kbd>/etc</kbd>.  How about recovery across Ethernet of
any of this from another VAX?  Well, <kbd>/bin/tar</kbd> had gone,
and thoughtfully the Berkeley people had put <kbd>rcp</kbd> in
<kbd>/bin</kbd> in the 4.3 distribution.  What's more, none of the
Ether stuff wanted to know without <kbd>/etc/hosts</kbd> at least.
We found a version of <kbd>cpio</kbd> in <kbd>/usr/local</kbd>, but
that was unlikely to do us any good without a tape deck.</p><p>


Alternatively, we could get the boot tape out and rebuild the root
filesystem, but neither James nor Neil had done that before, and we
weren't sure that the first thing to happen would be that the whole
disk would be re-formatted, losing all our user files.  (We take dumps
of the user files every Thursday; by Murphy's Law this had to happen
on a Wednesday).  Another solution might be to borrow a disk from
another VAX, boot off that, and tidy up later, but that would have
entailed calling the DEC engineer out, at the very least.  We had a
number of users in the final throes of writing up PhD theses and the
loss of a maybe a weeks' work (not to mention the machine down time)
was unthinkable.</p><p>


So, what to do?  The next idea was to write a program to make a
device descriptor for the tape deck, but we all know where
<kbd>cc</kbd>, <kbd>as</kbd> and <kbd>ld</kbd> live.  Or maybe make
skeletal entries for <kbd>/etc/passwd</kbd>, <kbd>/etc/hosts</kbd>
and so on, so that <kbd>/usr/bin/ftp</kbd> would work.  By sheer
luck, I had a <kbd>gnuemacs</kbd> still running in one of my windows,
which we could use to create <kbd>passwd</kbd>, etc., but the first
step was to create a directory to put them in.  Of course
<kbd>/bin/mkdir</kbd> had gone, and so had <kbd>/bin/mv</kbd>, so we
couldn't rename <kbd>/tmp</kbd> to <kbd>/etc</kbd>.  However, this
looked like a reasonable line of attack.</p><p>


By now we had been joined by Alasdair, our resident UNIX guru, and as
luck would have it, someone who knows VAX assembler.  So our plan
became this: write a program in assembler which would either rename
<kbd>/tmp</kbd> to <kbd>/etc</kbd>, or make <kbd>/etc</kbd>, assemble
it on another VAX, <kbd>uuencode</kbd> it, type in the uuencoded file
using my gnu, <kbd>uudecode</kbd> it (some bright spark had thought
to put <kbd>uudecode</kbd> in <kbd>/usr/bin</kbd>), run it, and hey
presto, it would all be plain sailing from there.  By yet another
miracle of good fortune, the terminal from which the damage had been
done was still <kbd>su</kbd>'d to root (<kbd>su</kbd> is in
<kbd>/bin</kbd>, remember?), so at least we stood a chance of all
this working.</p><p>


Off we set on our merry way, and within only an hour we had managed
to concoct the dozen or so lines of assembler to create
<kbd>/etc</kbd>.  The stripped binary was only 76 bytes long, so we
converted it to hex (slightly more readable than the output of
<kbd>uuencode</kbd>), and typed it in using my editor.  If any of you
ever have the same problem, here's the hex for future reference:</p><blockquote>
   <kbd>070100002c000000000000000000000000000000000000000000000000000000<br>
        0000dd8fff010000dd8f27000000fb02ef07000000fb01ef070000000000bc8f<br>
		8800040000bc012f65746300</kbd>
</blockquote>

<p>

I had a handy program around (doesn't everybody?) for converting
ASCII hex to binary, and the output of <kbd>/usr/bin/sum</kbd>
tallied with our original binary.  But hang on---how do you set
execute permission without <kbd>/bin/chmod</kbd>?  A few seconds
thought (which as usual, lasted a couple of minutes) suggested that
we write the binary on top of an already existing binary, owned by
me...problem solved.

So along we trotted to the terminal with the root login, carefully
remembered to set the umask to 0 (so that I could create files in it
using my gnu), and ran the binary.  So now we had a <kbd>/etc</kbd>,
writable by all.  From there it was but a few easy steps to creating
<kbd>passwd</kbd>, <kbd>hosts</kbd>, <kbd>services</kbd>,
<kbd>protocols</kbd>, (etc), and then <kbd>ftp</kbd> was willing to
play ball.  Then we recovered the contents of <kbd>/bin</kbd> across
the ether (it's amazing how much you come to miss <kbd>ls</kbd> after
just a few, short hours), and selected files from <kbd>/etc</kbd>.
The key file was <kbd>/etc/rrestore</kbd>, with which we recovered
<kbd>/dev</kbd> from the dump tape, and the rest is history.</p><p>


Now, you're asking yourself (as I am), what's the moral of this
story?  Well, for one thing, you must always remember the immortal
words, <strong>DON'T PANIC</strong>.  Our initial reaction was to
reboot the machine and try everything as single user, but it's
unlikely it would have come up without <kbd>/etc/init</kbd> and
<kbd>/bin/sh</kbd>.  Rational thought saved us from this one.</p><p>


The next thing to remember is that UNIX tools really can be put to
unusual purposes.  Even without my <kbd>gnuemacs</kbd>, we could have
survived by using, say, <kbd>/usr/bin/grep</kbd> as a substitute for
<kbd>/bin/cat</kbd>.</p><p>


And the final thing is, it's amazing how much of the system you can
delete without it falling apart completely.  Apart from the fact that
nobody could login (<kbd>/bin/login</kbd>?), and most of the useful
commands had gone, everything else seemed normal.  Of course, some
things can't stand life without say <kbd>/etc/termcap</kbd>, or
<kbd>/dev/kmem</kbd>, or <kbd>/etc/utmp</kbd>, but by and large it
all hangs together.</p><p>


I shall leave you with this question: if you were placed in the same
situation, and had the presence of mind that always comes with
hindsight, could you have got out of it in a simpler or easier way?
Answers on a postage stamp to:</p><pre>Mario Wolczko
------------------------------------------------------------------------
Dept. of Computer Science       ARPA:   miw%uk.ac.man.cs.ux@cs.ucl.ac.uk
The University                  USENET: mcvax!ukc!man.cs.ux!miw
Manchester M13 9PL              JANET:  miw@uk.ac.man.cs.ux
U.K.                            061-273 7121 x 5699
------------------------------------------------------------------------
</pre>

<hr>

<address><a href="https://www.ee.ryerson.ca/~elf/hack/index.html">Hacker's Wisdom</a>: Unix Recovery
Legend</address>

<!-- hhmts start -->
Last modified: Thu Mar  7 13:47:40 EST 1996
<!-- hhmts end --></div>]]>
            </description>
            <link>https://www.ee.ryerson.ca/~elf/hack/recovery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491790</guid>
            <pubDate>Mon, 21 Dec 2020 03:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cakelisp: A Programming Language for Games]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25491568">thread link</a>) | @makuto
<br/>
December 20, 2020 | https://macoy.me/blog/programming/CakelispIntro | <a href="https://web.archive.org/web/*/https://macoy.me/blog/programming/CakelispIntro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><em>Update:</em> See the <a href="https://news.ycombinator.com/item?id=25491568">Hacker News thread</a>, <a href="https://www.reddit.com/r/programming/comments/kh6ox0/cakelisp_a_programming_language_for_games/">/r/programming</a>, <a href="https://www.reddit.com/r/ProgrammingLanguages/comments/kh6gh2/cakelisp_a_programming_language_for_games/">/r/ProgrammingLanguages</a>, and <a href="https://www.reddit.com/r/gamedev/comments/kh1p0a/cakelisp_a_programming_language_for_games/">/r/gamedev</a> posts for discussions on this article and Cakelisp.</p>
<p>I have been working on a new programming language since the end of August 2020. It is hosted on <a href="https://github.com/makuto/cakelisp/">Github</a>, and mirrored on <a href="https://macoy.me/code/macoy/cakelisp/">my site</a>.</p>
<p>If you want to see a working example first, <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame.cake</a> is a simple audio looper with Ogre 3D graphics and SDL for windowing, input, and audio. This demo supports code hot-reloading and doesn't require an external build system, only Cakelisp. You can also check <a href="https://macoy.me/code/macoy/cakelisp/src/branch/master/runtime/Macros.cake">Macros.cake</a>, which demonstrates some use-cases for compile-time code.</p>
<p>I figured showing non-trivial examples would be much more interesting. It also proves that Cakelisp is working.</p>

<p>Cakelisp is built for me first, but it should appeal to fellow programmers who know what they're doing and want to try a more powerful language.</p>
<p>Cakelisp might be for you if you want‚Ä¶</p>
<ul>
<li><strong>Uncompromised performance</strong></li>
<li><strong>Trust in you, the programmer</strong></li>
<li><strong>Powerful code generation</strong></li>
</ul>
<p>If any of the things in that list don't make sense to you, or you think you're already getting them in language <em>X</em>, then Cakelisp isn't for you, and that's okay! We have different domains and different problems, so it makes some sense to use different languages and methodologies.</p>
<p>While many languages have these features, few have the combination of all three. Lisp has extremely powerful code generation, but makes serious performance compromises. C is great for performance but can require extremely repetitive code writing to accomplish tasks a simple code generator could handle. Rust is fast (well, apart from compilation, which is very important for iterative development to be productive), but doesn't trust the programmer.</p>

<p>My goal is to "have my cake and eat it too", meaning all three of these features in one coherent package. Importantly, there isn't one dominating principle in Cakelisp (no <a href="https://www.youtube.com/watch?v=TH9VCN6UkyQ">Big Idea</a>). I've found that the small things like removing the need for header files, no longer dealing with external build systems, or being able to run Cakelisp files like scripts, end up making a big difference when combined in one package.</p>
<p>It is useful to go over the goals in detail so you can understand my decisions.</p>
<h2 id="uncompromised-performance">Uncompromised performance</h2>
<p>This means no garbage collection, no type boxing/unboxing, etc. Fewer abstractions (besides the ones you create) between you and what the computer is actually doing. Idiomatic usage of the language should result in performance comparable with C (in most cases, it should be identical, because it's only a thin layer on C).</p>
<h2 id="trust-in-you-the-programmer">Trust in you, the programmer</h2>
<p>While languages like Rust offer benefits in terms of security and stability, they cost programmers in terms of productivity. It makes sense to value safety so highly if your code is safety-critical (operating systems, aerospace, automotive, etc.), but it's much less valuable when safety isn't as important (e.g. in games).</p>
<p>In a perfect world all programs would be as robust as space flight software, but in reality, that level of robustness is unnecessary for most programs. It's important to realize that the safety focus is just one way of doing things, not the <em>One True Way</em> or anything.</p>
<h2 id="powerful-code-generation">Powerful code generation</h2>
<p>In my opinion, most languages offer far too little opportunity for the programmer to automate the actual writing of code. This power also relates to trusting in the programmer, because gone wild, the code can become incomprehensible.</p>
<p>The company I work for has what I consider to be a state-of-the-art code generator built for the company's use-case: multi-platform MMOs. It's used very effectively on serialization, RPC, automatic commands, monitoring, automatic documentation, and more.</p>
<p>To give more credence to the use of code generation in games, <a href="https://docs.unrealengine.com/en-US/ProgrammingAndScripting/GameplayArchitecture/index.html">Unreal</a> and <a href="https://www.youtube.com/watch?v=wiJqUWfR90I">Naughty Dog</a> also rely on code generation.</p>
<h2 id="simplify-project-setup-and-management">Simplify project setup and management</h2>
<p>I want to dramatically reduce time wasted on C++ project set-up and "code logistics". This includes setting up build systems, creating header files, adding and managing new C/C++ 3rd party libraries, and other things of that ilk.</p>
<h2 id="gain-more-power">Gain more power!</h2>
<p>Every language has limitations. The lack of straightforward, all-powerful code generation was my primary gripe with C++.</p>
<p>For example, automatically creating function and structure bindings using C++ template metaprogramming is very complex. These are two very useful tools in game development: function bindings for commands, scripting languages, and RPC; structure bindings for serialization or game monitors.</p>
<p>I also wanted features like hot-reloading (being able to load new versions of the code without restarting the program/losing runtime state). Cakelisp made it possible to implement hot-reloading entirely in "user-space", thanks to code modification.</p>
<h2 id="have-my-cake-and-eat-it-too.">"Have my cake and eat it too."</h2>
<p>By this I mean lose little-to-nothing on metrics I care about, which include build time, runtime performance, overall complexity, and various other things. I looked into several languages in my <a href="https://macoy.me/code/macoy/LanguageTests">LanguageTests</a> experiment and found they all had major drawbacks I couldn't accept.</p>
<h2 id="unexpected-freedom">Unexpected freedom</h2>
<p>I did not realize when I started Cakelisp how freeing it felt. All of the sudden, I got to decide what made sense to <em>me</em>, not what made sense to previous language designers.</p>
<h3 id="freedom-in-syntax">Freedom in syntax</h3>
<p>A simple example is type declarations. In C:</p>

<p>The same variable, in Cakelisp:</p>

<p>In my opinion C type declarations are much harder to parse than my explicit type declarations. You need to work backwards from the name to properly interpret the type. The parentheses do add more typing, but they're more clear, machine-parseable, and can be read naturally (e.g. read left to right "pointer to constant character" vs. C's "constant character pointer", which seems worse in my mind).</p>
<p>My form also handles arrays as part of the type: <code>(var my-array ([] 5 int))</code> rather than <code>int myArray[5];</code>, another way it is more consistent, readable, and parsable.</p>
<p>I chose to swap the order of name and type because it places more emphasis on the name. A well-written program will convey more useful information in the name than in the type, so it makes sense to me to have it come first for the reader.</p>
<h3 id="freedom-in-process">Freedom in process</h3>
<p>I also found that having an executable which preprocesses my code exactly how I want it opens the door to a huge amount of awesome features:</p>
<ul>
<li>Compile-time code execution. "Macros" and "Generators" are defined in-line with the rest of your code, making them feel like a natural part of your code. Defining them in-line makes it acceptable to add one-off macros, whereas adding such a thing to an external code generator would quickly become unmaintainable</li>
<li>Build optimization. A recent idea I discovered is automatically creating precompiled headers for large batches of 3rd-party headers. This would be a complex task that would need to be integrated in whatever build system you use, whereas Cakelisp can have it built-in</li>
<li>Other data processing. Compile-time code execution means you can do things like prepare assets, download 3rd-party code, run tests, etc. without having to set up all these additional tools</li>
</ul>

<p>I was inspired by Naughty Dog's use of <a href="https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp">Game Oriented Assembly Lisp</a>, GOOL, and <a href="https://www.youtube.com/watch?v=oSmqbnhHp1c">Racket/Scheme</a> (on their modern titles). I've also taken several ideas from Jonathan Blow's <a href="https://www.youtube.com/user/jblow888">talks on Jai</a>.</p>
<p>I'm a software engineer in the game industry. I've been working since July 2015 at a studio that makes cross-platform MMOs. The company has a custom engine written in C (with some C++).</p>
<p>I <a href="https://macoy.me/code/macoy/LanguageTests">experimented</a> with other languages before deciding I needed to write my own.</p>

<p>Now that my goals are clear, I will show you how I approached achieving them.</p>
<h2 id="notation">Notation</h2>
<p>Cakelisp uses an <a href="https://en.wikipedia.org/wiki/S-expression">S-expression</a>-style notation. Here is some Cakelisp code from <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame</a>:</p>

<p>There are a few things you can notice from reading this code:</p>
<ul>
<li>Types. Cakelisp is strongly- and explicitly-typed. I prefer reading code with explicit types because I can better imagine what the computer is actually doing, and what possibilities I have with each variable</li>
<li>Name-type order. I talked about this in a previous section. I wanted to emphasize the name of a variable for conveying meaning, especially when you may have many variables of the same type</li>
<li>Explicit <code>return</code>. I find I prefer code where return points are made explicit. Lisp will implicitly return the result of the last evaluation</li>
<li>Lisp-y style. The parentheses, plus keywords like <code>unless</code>, <code>defun</code>, <code>var</code>, <code>at</code>, and <code>incr</code>. I matched Lisp only when I didn't have strong opinions for a better notation. I am not trying to create something which is compatible with existing Lisps</li>
<li>C types and function calls. Cakelisp has seamless C interop, which means Cakelisp's "standard library" <em>is</em> C's standard library. No bindings had to be written to use the C types or make the function calls</li>
</ul>
<p>You can read more Cakelisp code in <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/src">Gamelib</a>.</p>
<p>You should think of Cakelisp more as "C in S-expressions" rather than "Lisp with C performance". If you know C, you'll have a relatively smooth transition to Cakelisp. If you only know Lisp, you're going to have a rougher time.</p>
<h3 id="why-s-expressions">Why S-expressions?</h3>
<p>When I set out to make Cakelisp, I decided on S-expressions syntax for several reasons:</p>
<ul>
<li>Parsability. S-expressions shift the burden of creating a syntax tree onto the programmer. This does result on more work for the human, but I value its extremely explicit nature. It also facilitates simpler tokenization, domain-specific-language implementation, and external tool support</li>
<li>Consistency. There are only four types of tokens in Cakelisp: open and close parenthesis, symbol, and string. The consistency is admittedly limiting, so things like paths (<code>myThing-&gt;member.member</code>) become much more verbose to type, unfortunately. However, this limitation keeps Cakelisp code parsable, and has an elegant feel that I appreciate</li>
</ul>
<p>I don't believe there is one notation to rule them all, especially after I've encountered the disadvantages of using S-exprs. I'm still happy with the decision though, and it does give Cakelisp a novel and distinguishing characteristic from the many ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macoy.me/blog/programming/CakelispIntro">https://macoy.me/blog/programming/CakelispIntro</a></em></p>]]>
            </description>
            <link>https://macoy.me/blog/programming/CakelispIntro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491568</guid>
            <pubDate>Mon, 21 Dec 2020 02:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoLisp Chess]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25491356">thread link</a>) | @simonpure
<br/>
December 20, 2020 | https://software-lab.de/chess/README | <a href="https://web.archive.org/web/*/https://software-lab.de/chess/README">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>|<n>|<b>|<q>|<k>|<b>|<n>|<r>|
      +---+---+---+---+---+---+---+---+
    7 |<p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|
      +---+---+---+---+---+---+---+---+
    6 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    5 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    4 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    3 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    2 | P | P | P | P | P | P | P | P |
      +---+---+---+---+---+---+---+---+
    1 | R | N | B | Q | K | B | N | R |
      +---+---+---+---+---+---+---+---+
        a   b   c   d   e   f   g   h

For a local installation, supply instead of "pil" the actual path like "./pil"
or "../pil21/pil".

The pieces are indicated by the letters 'K'ing, 'Q'ueen, 'R'ook, 'B'ishop,
k'N'ight and 'P'awn, with black pieces in angular brackets.

You can enter your moves with the field names (in lower case) for the "from" and
"to" positions:

: (go e2 e4)

Castling may be entered by just specifying the king's move:

: (go e1 g1)

To promote a pawn to some piece other than a queen, you can specify a class:

: (go h7 h8 +Knight)

To undo one or several moves, enter

: (go -)

and to redo them

: (go +)

To switch sides (and have the computer play against itself), call 'go' without
arguments:

: (go)

The initial board position can be restored with

: (main)

The global variable '*Depth' holds the maximal depth of the alpha-beta tree
search. It defaults to 5. You may change it to some smaller value for a faster
response, or to a larger value for a deeper search:

: (setq *Depth 7)

The same effect can be achieved by passing the desired depth as the first
argument to 'main':

: (main 7)

The second (optional) argument to 'main' is your color ('NIL' for white and 'T'
for black).

To setup some given board position, call 'main' with a list of triples, with
each describing:

   1. The field
   2. The piece's classes
   3. An optional flag to indicate that the piece did not move yet

: (main 5 NIL
   (quote
      (a2 (+White +Pawn) T)
      (b1 (+White +King))
      (d4 (+Black +King)) ) )
   +---+---+---+---+---+---+---+---+
 8 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 7 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 6 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 5 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 4 |   | - |   |<k>|   | - |   | - |
   +---+---+---+---+---+---+---+---+
 3 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 2 | P | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 1 | - | K | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
     a   b   c   d   e   f   g   h

At any time, you can print the current board position in the above format to a
file with

: (ppos "file")

which later can be restored with

: (load "file")


   === PilBox and Web App ===

If you have the PilBox App installed on your Android device, just type "chess"
in the settings and press the "Download" button.

To start the Web application, use

   $ pil chess/main.l -chess~main -go +

Alternatively, you can start it with German localization as

   $ pil chess/main.l -'chess~main "DE" "de"' -go +

then point your browser to http://localhost:8080

In both cases you can interact with the chess board in this way:

   √¢‚Ç¨‚Äù To enter a move, drag a piece to the new field.
   √¢‚Ç¨‚Äù A click on the board does an auto-move and then switches sides.
   √¢‚Ç¨‚Äù The search depth can be changed with a drop-down menu.
   √¢‚Ç¨‚Äù The "New" button starts a new game, and the "Undo" and "Redo" buttons
     navigate in the history.
   √¢‚Ç¨‚Äù The text "White" or "Black" indicate who is to move next. It changes to
     "White ..." or "Black ..." while the computer is thinking.
   √¢‚Ç¨‚Äù After a move, the moved piece and the old and new positions are indicated
     above that text.

The "Setup" button switches to edit mode and allows you to change the position
manually:

   √¢‚Ç¨‚Äù A click on a piece removes it from the board.
   √¢‚Ç¨‚Äù Dragging a piece moves it to another field.
   √¢‚Ç¨‚Äù A new piece can be placed on the board by dragging it from the setup area.
   √¢‚Ç¨‚Äù The "Clear" button removes all pieces from the board.
   √¢‚Ç¨‚Äù The "New" button sets up all pieces for a new game.
   √¢‚Ç¨‚Äù The "Game" button switches back to play mode.

As in any PilBox app, you can go to the settings (wheel icon on top right) and

   √¢‚Ç¨‚Äù switch to another language in the "Language" tab or
   √¢‚Ç¨‚Äù view the App's source code by clicking on the app name "chess" in the
     "PILs" tab.


   === Credits and Copying ===

The pieces and board colors are from https://chessboardjs.com

The icon is from
   https://commons.m.wikimedia.org/wiki/File:Chess logo.PNG

(MIT/X11 License)
</k></p></r></n></b></k></q></b></n></div></div>]]>
            </description>
            <link>https://software-lab.de/chess/README</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491356</guid>
            <pubDate>Mon, 21 Dec 2020 01:51:16 GMT</pubDate>
        </item>
    </channel>
</rss>
