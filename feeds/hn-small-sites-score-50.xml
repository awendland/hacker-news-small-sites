<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 23 Jul 2020 12:21:36 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 23 Jul 2020 12:21:36 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Invert, Always, Invert]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23905221">thread link</a>) | @anupj
<br/>
July 21, 2020 | https://www.anup.io/2020/07/20/invert-always-invert/ | <a href="https://web.archive.org/web/*/https://www.anup.io/2020/07/20/invert-always-invert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.anup.io/content/images/size/w300/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 300w,
                            https://www.anup.io/content/images/size/w600/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 600w,
                            https://www.anup.io/content/images/size/w1000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 1000w,
                            https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg" alt="Invert,  always, invert">
            </figure>

            <section>
                <div>
                    <blockquote>man muss immer umkehren - Carl Gustav Jacob Jacobi</blockquote><p>(loosely translated - Invert, always, invert)</p><p>Today, we will look at one of my favourite mental models called - The<strong><em> Inversion principle</em></strong>. <a href="https://fs.blog/mental-models/#what_are_mental_models">Mental models</a> are a set of simple, abstract but useful principles that help us make sense of the world around us.</p><p>I came across the Inversion principle on the <a href="https://fs.blog/2013/10/inversion/">Farnam Street blog</a>. It is also a favourite of Charlie Munger (Vice Chairman of Berkshire Hathaway and Warren Buffets mate) - "...it is in the nature of things that many hard problems are best solved when they are addressed backward", he pontificates.</p><p>In another interview, he recalls how, as an Air Force meteorologist during World War II, instead of asking what would keep pilots safe, he asked what would kill them and focussed all his efforts "on trying to predict snow, ice or fog—and to ignore pretty much everything else.".</p><p>I could write a book on all the other cool stuff Charlie Munger has said so I'll stop here.</p><h3 id="what-is-it">What is it?</h3><p>Inversion is based on the maxim - invert, always, invert. It is about considering an inverse (usually a negative) outcome and listing the reasons for these. It forces you to either stop doing certain things or avoid the actions that lead to the negative outcomes. It gives us <em><em>new possibilities</em> and capabilities</em> that we might not have considered otherwise.</p><p>The algorithm for inversion is very simple:</p><ul><li><strong>Define the problem</strong> - what is it that &nbsp;you're trying to achieve?</li><li><strong>Invert it </strong>- what would guarantee the failure to achieve this outcome?</li><li>Finally, <strong>consider solutions to avoid this failure</strong></li></ul><p>This is very abstract and vague, so let's look at a few examples:</p><ol><li>Instead of asking how do we increase the adoption of a product or feature? You could instead consider - what are some of things preventing adoption? This would lead to a list like this that you could potentially fix:</li></ol><ul><li>Slow load time i.e. performance issues</li><li>Not enough marketing, or marketing on the platform, or to the wrong audience</li><li>The user guide instructions are not clear ... you get the idea</li></ul><p>2. &nbsp;Following the inversion principle it is <em>better to ask</em> what is preventing me from reading all the unread books on my kindle/bookshelf, instead of asking how can i read more books? Possible reasons and something you could give up:</p><ul><li>I spend a lot of time on social media</li><li>I watch too many shows on Netflix or Disney +</li><li>Spend a lot of time on reddit or browsing hacker news</li></ul><p>3. Instead of wondering how do I always choose a winning stock during investing, ask yourself how do you prevent losses in the long term?</p><ul><li>Am I diversifying enough to prevent long term loss?</li><li>Am I investing &nbsp;based on sound principles, or am I speculating? </li></ul><p>Hopefully this &nbsp;gives you a flavour of how powerful inversion is as a mental model. I should add that it is NOT a silver bullet and it won't always give you concrete answers, but it will act as a forcing function to avoid obvious lapses in judgment. I'll leave you with another one of my favourite quotes about Inversion from Charlie.</p><blockquote>"It is remarkable how much long-term advantage people like us have gotten by trying to be consistently not stupid, instead of trying to be very intelligent."</blockquote><hr><p>Further reading:</p><figure><blockquote><a href="https://fs.blog/2014/06/avoiding-stupidity/">Avoiding Stupidity is Easier than Seeking Brilliance</a></blockquote>
</figure><figure><a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/"><div><p>Putting Mental Models to Practice Part 3: Better Trial and Error</p><p>Instrumental rationality is the sort of thinking that allows you to achieve your goals. We take a closer look at what decision science says is the ‘best’ way to pursue this purpose.</p><p><img src="https://commoncog.com/blog/favicon.png"><span>Commonplace - The Commoncog Blog</span></p></div><p><img src="https://commoncog.com/blog/content/images/2018/12/burst-530182-unsplash--1-.jpg"></p></a></figure><p>Thanks for taking the time to read this post, if you found it useful and if you have any comments or more tips, please hit me up on twitter (@<a href="https://twitter.com/anup">anup</a>).</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Anup Jadhav</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.anup.io/2020/07/20/invert-always-invert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905221</guid>
            <pubDate>Tue, 21 Jul 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brick Block – by Oskar Stålberg (desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23904991">thread link</a>) | @thdrdt
<br/>
July 21, 2020 | http://oskarstalberg.com/game/house/index.html | <a href="https://web.archive.org/web/*/http://oskarstalberg.com/game/house/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
    <canvas id="canvas" oncontextmenu="event.preventDefault()" height="100%" width="100%"></canvas>
	<div id="loadingBox">
	  
	  
	  <p id="loadingInfo">Loading...</p>
	</div>
		
    


  

</div>]]>
            </description>
            <link>http://oskarstalberg.com/game/house/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904991</guid>
            <pubDate>Tue, 21 Jul 2020 07:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Many Faces of an Undying Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23904104">thread link</a>) | @grugagag
<br/>
July 20, 2020 | http://jakob.space/blog/thoughts-on-lisps.html | <a href="https://web.archive.org/web/*/http://jakob.space/blog/thoughts-on-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>July 20, 2020 ❖ Tags: <a href="http://jakob.space/blog/tag/tag/opinion.html">opinion</a>, <a href="http://jakob.space/blog/tag/tag/programming.html">programming</a>, <a href="http://jakob.space/blog/tag/tag/lisp.html">lisp</a>, <a href="http://jakob.space/blog/tag/tag/common-lisp.html">common-lisp</a>, <a href="http://jakob.space/blog/tag/tag/scheme.html">scheme</a></p><article><p>
This is a post I've been meaning to write for a while now: one anecdotally
comparing programming languages in the Lisp family. I consider myself to be a
Lisp hacker. Perhaps that much was obvious from the letter λ adorning my
website's header, a reference to the λ-calculus which inspired John McCarthy to
design the first LISP [1]. Yet, "Lisp hacker" likely means little unless you,
too, consider yourself to be a Lisp hacker. Calling yourself one seems carry
some level of unstated meaning. Indeed, some identify with more specific groups.
"Schemer," or "Guiler," or "Racketeer," or "Clojurist." But "Lisp Hackers" ⊇
"Schemers". There is commonality shared among all, or at least most, of these
programming languages, and the Lisp hackers recognize and appreciate that
commonality – the characteristics that make a programming language a Lisp.
Homoiconic syntax, powerful metaprogramming facilities, and editor support that,
in my opinion, is unparalleled. (Yes, I am alluding to GNU Emacs.) This article,
however, is concerned with the differences. In it, I will be considering the
specifics of each dialect, and whether or not those specifics make for a
language I would want to use to develop a new piece of software.
</p><p>
I'm specifically concerned with game development at the time of writing this
article. An idea for a turn-based tactics game came to me and I felt a Lisp
would be the best tool for realizing it, but the decision to use "a Lisp" still
leaves me with several choices. When I enumerate the notable design choices
behind each dialect, and talk about the approaches I prefer, my opinions will
be, in some capacity, framed as partial answers to the question of "will I be
able to comfortably use this to write a video game?" As such, there are a few
things I am specifically interested in:
</p><ul>
<li><b>Ergonomics</b>, or "a measure of the friction [one experiences] when trying to get
things done" [2].</li>
<li><b>Expressiveness</b>, or the ease with which code may be understood by a reader.</li>
<li><b>Performance</b>, which is nontrivial to properly quantify [3]. I won't be rigorous
with this; a one-off run with <code>time</code> can give a good idea of the order of
magnitude for execution time.</li>
<li><b>Ease of distribution</b>, which is difficult to define, but with which I associate
platform agnosticism, a runtime that won't bloat my tarballs by several
gigabytes, and a lack of baroque and difficult to obtain dependencies.</li>
<li><b>Ability to interface with other libraries</b>, as I'll want to be able to
draw to the screen, and play sounds, and so on.</li>
</ul><p>
For each dialect, I'm allowing myself to use nonstandard functions. I'm aiming
for an evaluation of the practical aspects of each language, and if you were
writing software, you'd likely be using more than what's included in the R5RS or
ANSI CL standards. Though, if these nonstandard functions are specific to a
single implementation, I will avoid them. SRFI's and QuickLisp are fair game,
but CHICKEN's Eggs are not. Ah, I'm already getting ahead of myself. Yes, I will
be comparing Scheme and Common Lisp. I almost have to – the history of Lisp
tends to be spun as a schism between Common Lisp and Scheme. I will be speaking
of a few others as well. I've mostly chosen dialects for which there exists some
"game engine" type library. For R7RS (CHICKEN), there is <a href="http://alex-charlton.com/projects/Hypergiant/">Hypergiant</a>, for R6RS
(Guile) there is <a href="https://dthompson.us/projects/chickadee.html">Chickadee</a>, for Common Lisp there is <a href="http://www.xelf.me/">Xelf</a>, and for Fennel there
is, of course, <a href="https://love2d.org/">LÖVE</a>.
</p><figure>
<img src="http://jakob.space/static/image/lisp-personality-test.png" alt="lisp-personality-test.png">

<figcaption><span>Figure 1: </span>My take on the drawing in Conrad Barski's <i>Land of Lisp</i>. From left to right: Common Lisp, Scheme, <del>Haskell</del> Fennel.</figcaption>
</figure><p>
What follows are my opinions, so I'd like to lead with the background that
motivated them. My earliest "serious" experience with Lisp was with Peter
Seibel's <i>Practical Common Lisp</i>, which I picked up in high school following a
failed attempt at reading <i>Structure and Interpretation of Computer
Programs</i>.<sup><a id="fnr.1" href="#fn.1">1</a></sup> The portion of the latter book that I did manage was enough to
convince me that learning <span>a</span> Lisp would be valuable, but that learning Common
Lisp may be more tractable than learning Scheme. The summer following my first
year of university, I taught myself Scheme to do <a href="http://summerofcode.withgoogle.com/">GSoC</a> for <a href="https://guix.gnu.org/">GNU Guix</a>. Guile
quickly grew on me, and I soon began <a href="http://jakob.space/blog/transition-to-haunt.html">using Haunt</a> for my personal website. I've
been unknowingly using Emacs Lisp since much earlier – not in the sense of
writing packages – my old man taught me how to use Emacs when I was nine, but I
was <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Easy-Customization.html">mostly shielded from having to write <code>setq</code> forms</a>. I've also used <a href="https://docs.hylang.org/en/stable/">Hy</a>, <a href="https://fennel-lang.org/">Fennel</a>,
… well, I'm wildly off track now. Point being, I've used many Lisps, and I've
subconsciously acknowledged the differences between them, but never turned that
acknowledgment into coherent thought.
</p><p>
To aid in the comparison, I've written the same raytracer in several dialects of
Lisp. My reasons for choosing a raytracer are that:
</p><ul>
<li>I'm reasonably familiar with how they work.</li>
<li>Performance matters, and differences in performance is noticeable.</li>
<li>It's nontrivial, but several implementations of a raytracer is also more
tractable than, say, several implementations of a high-performance database.</li>
</ul><p>
Another consideration was the number of advancements in raytracing that build
upon the same basic structure, potentially giving me a way to compare the ease
with which a change to a system can be made, but writing these raytracers took
enough out of me that I didn't want to play with them any more.
</p><p>
This was not nearly as telling of a comparison as I had hoped. Once I'd
completed the first raytracer, everything that followed had the same structure.
Regardless, writing these raytracers gave me an idea of the characteristics I
was interested in, especially performance. For anyone who would like to look at
the code, the implementations are available <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo">here</a>.
</p><p>
<b>Table of Contents</b>
</p><ul>
<li><a href="#org9a5541d">The Issue of Rendering an Image</a></li>
<li><a href="#orga8f893b">Scheme</a>
<ul>
<li><a href="#org4538c39">R7RS</a></li>
<li><a href="#org47b9bd9">R6RS</a></li>
<li><a href="#org3eedb31">Conclusions on Scheme</a></li>
</ul></li>
<li><a href="#org9e27a4b">Common Lisp</a>
<ul>
<li><a href="#org0df9ac3">Conclusions on Common Lisp</a></li>
</ul></li>
<li><a href="#org4d7f824">Fennel</a>
<ul>
<li><a href="#org3eb9b83">Conclusions on Fennel</a></li>
</ul></li>
<li><a href="#org0fbbf7a">Lisps I've Neglected</a>
<ul>
<li><a href="#org1bb9256">Emacs Lisp</a></li>
<li><a href="#orga47743c">Gerbil Scheme</a></li>
<li><a href="#orgcca7e64">Racket</a></li>
<li><a href="#org883fd6d">Janet</a></li>
<li><a href="#org965e8ce">Clojure</a></li>
</ul></li>
</ul><div id="outline-container-org9a5541d">
<h2 id="org9a5541d">The Issue of Rendering an Image</h2>
<div id="text-org9a5541d">
<p>
Well, if we're writing a raytracer, then, we had better have some way of seeing
the results. The issue is portability. Ideally, I'd like to be able to run the
raytacers on different implementations of each language, but none of them have
standardized support for drawing graphics. An idea I had was to render the image
to the terminal using ANSI escape sequences, but I thought the resulting images
would be quite shitty. Instead, I decided to go the <a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0-getting-started">route that tinyrenderer
takes</a>, which is to output to an image file. Initially, the image format I went
with was the venerable PNG. This was a mistake. Even if it did lead to a rather
elegant CRC procedure in Scheme.
</p>

<div>
<pre>(<span>define</span> (<span>chunk-crc</span> bytes)
  (<span>define</span> (<span>process-byte</span> crc byte)
    (bitwise-xor (vector-ref png-crc (bitwise-and #xff (bitwise-xor crc byte)))
                 (arithmetic-shift crc -8)))
  (reduce process-byte bytes #xffffffff))
</pre>
</div>

<p>
Realizing PNG was needlessly complex, I went on to write a <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo/tree/master/write-bmp.scm">BMP encoder</a>, which
was fine until I came across <a href="https://nullprogram.com/blog/2017/11/03/">an article</a> from Chris Wellons about rendering video
with C by encoding frames as <a href="http://netpbm.sourceforge.net/doc/">Netpbm</a> images. I decided to scrap my BMP encoder
and go with PPM instead. Netpbm is text-based: the issue with a PNG or BMP
encoder in Scheme, for example, is that you're dealing with a binary format.
Glancing over the standards now, it seems there are, indeed, standardized
procedures for dealing with binary data in both R6RS and R7RS. Regardless,
dealing with those binary structures and having to consider endianness is a
pain. PPM is <span>dead</span> simple. In fact, I'd wager that if all you had access to were
the examples on the <a href="https://en.wikipedia.org/wiki/Netpbm">Wikipedia</a> page, you'd be able to write an encoder. Here's
the Scheme implementation:
</p>

<div>
<pre>(<span>define</span> (<span>write-ppm</span> width height pixels)
  <span>"Encode the WIDTH by HEIGHT image given as PIXELS into the portable pixmap</span>
<span>format (PPM), writing the result to `(current-output-port)'."</span>
  (<span>define</span> (<span>delimit-values</span> values)
    (<span>cond</span> ((null? values)
           (newline))
          ((= 1 (length values))
           (display (car values))
           (delimit-values (cdr values)))
          (<span>else</span>
           (display (car values))
           (display <span>" "</span>)
           (delimit-values (cdr values)))))

  
  (delimit-values '(<span>"P3"</span>))

  
  (delimit-values (list width height))

  
  (delimit-values '(<span>"255"</span>))

  
  (<span>for-each</span> delimit-values (vector-&gt;list pixels)))
</pre>
</div>

<p>
If you do away with my nice formatting, that's twelve lines of code, all of
which are R5RS-compatible. We have access to the Netpbm suite, too, so if we
want a PNG, we can always <code>./write-ppm | pnmtopng &gt; test.png</code>. Netpbm is a
real hidden gem. Well, hidden to me, at least.
</p>
</div>
</div><div id="outline-container-orga8f893b">
<h2 id="orga8f893b">Scheme</h2>
<div id="text-orga8f893b">
<p>
If you aren't familiar with Scheme, it has somewhat of a self-imposed<sup><a id="fnr.2" href="#fn.2">2</a></sup>
reputation for appealing to academic types. It's also one of the most
opinionated languages I know of; all the specs of interest lead with an
assertion that "programming languages should be designed not by piling feature
on top of feature, but by removing the weaknesses and restrictions that make
additional features appear necessary." The way that Scheme embraces purity and
simplicity makes it clear it was designed by math nerds. (Hey, I'm a math nerd,
too. Take it easy.)
</p>

<p>
As I've just mentioned, there are specs. A few, to be sure. The evolution of
Scheme standards begins in a linear fashion: RRS → RRRS → R3RS → R4RS → R5RS. I
like to think of this as "classic Scheme". But when it came time to revise R5RS,
the ratification of the subsequent R6RS caused some controversy. It was
"bloated", or whatever. Something like that. So when it came time to design R7RS
(small), the Scheme Language Steering Committee decided to let the language
fork, beginning with the earlier R5RS as a blank slate [4]. That way, the nerds
that hated everything about R6RS could have their way, and the nerds that liked
R6RS could have their way. Scheme was divided, but at peace. Oh, and nowadays
there's a work-in-progress <a href="https://bitbucket.org/cowan/r7rs-wg1-infra/src/default/R7RSHomePage.md">R7RS-large</a>. ಠ_ಠ
</p>

<p>
I'm not going to talk about R7RS-large here. It's just too …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jakob.space/blog/thoughts-on-lisps.html">http://jakob.space/blog/thoughts-on-lisps.html</a></em></p>]]>
            </description>
            <link>http://jakob.space/blog/thoughts-on-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904104</guid>
            <pubDate>Tue, 21 Jul 2020 03:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essays on programming I think about a lot]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23903737">thread link</a>) | @jchook
<br/>
July 20, 2020 | https://www.benkuhn.net/progessays/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/progessays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Every so often I read an essay that I end up thinking about, and citing in conversation, over and over again.</p><p>Here’s my index of all the ones of those I can remember! I’ll try to keep it up to date as I think of more.</p><p>(Some of them are extremely well-known. I’m leaving them here anyway just in case you’re one of <a href="https://xkcd.com/1053/" target="_blank">the lucky 10,000</a>.)</p><p>I’m curious what essays are in this category for other folks—post yours in the comments!</p><hr><p><a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>:</p><blockquote><p>I approach software with a deep-seated belief that computers and software systems can be understood. …</p><p>In some ways, this belief feels radical today. Modern software and hardware systems contain almost unimaginable complexity amongst many distinct layers, each building atop each other. …</p><p>In the face of this complexity, it’s easy to assume that there’s just too much to learn, and to adopt the mental shorthand that the systems we work with are best treated as black boxes, not to be understood in any detail.</p><p>I argue against that approach. You will never understand every detail of the implementation of every level on that stack; but you can understand all of them to some level of abstraction, and any specific layer to essentially any depth necessary for any purpose.</p></blockquote><hr><p><a href="https://mcfunley.com/choose-boring-technology" target="_blank">Choose Boring Technology</a>:</p><blockquote><p>Let’s say every company gets about three innovation tokens. You can spend these however you want, but the supply is fixed for a long while. You might get a few more after you achieve a certain level of stability and maturity, but the general tendency is to overestimate the contents of your wallet. Clearly this model is approximate, but I think it helps.</p><p>If you choose to write your website in NodeJS, you just spent one of your innovation tokens. If you choose to use MongoDB, you just spent one of your innovation tokens. If you choose to use service discovery tech that’s existed for a year or less, you just spent one of your innovation tokens. If you choose to write your own database, oh god, you’re in trouble.</p></blockquote><hr><p><a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction" target="_blank">The Wrong Abstraction</a>:</p><blockquote><ol start="4"><li><p>Time passes.</p></li><li><p>A new requirement appears for which the current abstraction is almost perfect.</p></li><li><p>Programmer B gets tasked to implement this requirement.</p><p><em>Programmer B feels honor-bound to retain the existing abstraction, but since isn’t exactly the same for every case, they alter the code to take a parameter….</em></p></li><li><p>… Loop until code becomes incomprehensible.</p></li><li><p>You appear in the story about here, and your life takes a dramatic turn for the worse.</p></li></ol></blockquote><hr><p><a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" target="_blank">Falsehoods Programmers Believe About Names</a>:</p><blockquote><ol start="32"><li>People’s names are assigned at birth.</li><li>OK, maybe not at birth, but at least pretty close to birth.</li><li>Alright, alright, within a year or so of birth.</li><li>Five years?</li><li>You’re kidding me, right?</li></ol></blockquote><hr><p><a href="https://sockpuppet.org/blog/2015/03/06/the-hiring-post/" target="_blank">The Hiring Post</a>:</p><blockquote><p>Nothing in Alex’s background offered a hint that this would happen. He had Walter White’s resume, but Heisenberg’s aptitude. None of us saw it coming. My name is Thomas Ptacek and I endorse this terrible pun. Alex was the one who nonced.</p><p>A few years ago, Matasano couldn’t have hired Alex, because we relied on interviews and resumes to hire. Then we made some changes, and became a machine that spotted and recruited people like Alex: line of business .NET developers at insurance companies who pulled Rails core CVEs out of their first hour looking at the code. Sysadmins who hardware-reversed assembly firmware for phone chipsets. Epiphany: the talent is out there, but you can’t find it on a resume.</p><p>Our field selects engineers using a process that is worse than reading chicken entrails. Like interviews, poultry intestine has little to tell you about whether to hire someone. But they’re a more pleasant eating experience than a lunch interview.</p></blockquote><hr><p><a href="https://blog.pragmaticengineer.com/the-product-minded-engineer/" target="_blank">The Product-Minded Engineer</a>:</p><blockquote><p>Proactive with product ideas/opinions • Interest in the business, user behavior and data on this • Curiosity and a keen interest in “why?” • Strong communicators and great relationships with non-engineers • Offering product/engineering tradeoffs upfront • Pragmatic handling of edge cases • Quick product validation cycles • End-to-end product feature ownership • Strong product instincts through repeated cycles of learning</p></blockquote><hr><p><a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to" target="_blank">Write code that is easy to delete, not easy to extend</a>:</p><blockquote><p>If we see ‘lines of code’ as ‘lines spent’, then when we delete lines of code, we are lowering the cost of maintenance. Instead of building re-usable software, we should try to build disposable software.</p></blockquote><blockquote><p>Business logic is code characterised by a never ending series of edge cases and quick and dirty hacks. This is fine. I am ok with this. Other styles like ‘game code’, or ‘founder code’ are the same thing: cutting corners to save a considerable amount of time.</p><p>The reason? Sometimes it’s easier to delete one big mistake than try to delete 18 smaller interleaved mistakes. A lot of programming is exploratory, and it’s quicker to get it wrong a few times and iterate than think to get it right first time.</p></blockquote><hr><p><a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a>:</p><blockquote><p>Back to TCP. Earlier for the sake of simplicity I told a little fib, and some of you have steam coming out of your ears by now because this fib is driving you crazy. I said that TCP guarantees that your message will arrive. It doesn’t, actually. If your pet snake has chewed through the network cable leading to your computer, and no IP packets can get through, then TCP can’t do anything about it and your message doesn’t arrive. If you were curt with the system administrators in your company and they punished you by plugging you into an overloaded hub, only some of your IP packets will get through, and TCP will work, but everything will be really slow.</p><p>This is what I call a leaky abstraction. TCP attempts to provide a complete abstraction of an underlying unreliable network, but sometimes, the network leaks through the abstraction and you feel the things that the abstraction can’t quite protect you from. This is but one example of what I’ve dubbed the Law of Leaky Abstractions:</p><p><strong>All non-trivial abstractions, to some degree, are leaky.</strong></p><p>Abstractions fail. Sometimes a little, sometimes a lot. There’s leakage. Things go wrong. It happens all over the place when you have abstractions. Here are some examples.</p></blockquote><hr><p><a href="https://blog.nelhage.com/post/reflections-on-performance/" target="_blank">Reflections on software performance</a>:</p><blockquote><p>It’s probably fairly intuitive that users prefer faster software, and will have a better experience performing a given task if the tools are faster rather than slower.</p><p>What is perhaps less apparent is that having faster tools changes how users use a tool or perform a task. Users almost always have multiple strategies available to pursue a goal — including deciding to work on something else entirely — and they will choose to use faster tools more and more frequently. Fast tools don’t just allow users to accomplish tasks faster; they allow users to accomplish entirely new types of tasks, in entirely new ways. I’ve seen this phenomenon clearly while working on both Sorbet and Livegrep:</p></blockquote><hr><p>Brandur Leach’s series on using databases to ensure correct edge-case behavior: <a href="https://brandur.org/acid" target="_blank">Building Robust Systems with ACID and Constraints</a>, <a href="https://brandur.org/http-transactions" target="_blank">Using Atomic Transactions to Power an Idempotent API</a>, <a href="https://brandur.org/job-drain" target="_blank">Transactionally Staged Job Drains in Postgres</a>, <a href="https://brandur.org/idempotency-keys" target="_blank">Implementing Stripe-like Idempotency Keys in Postgres</a>.</p><blockquote><p>I want to convince you that ACID databases are one of the most important tools in existence for ensuring maintainability and data correctness in big production systems. Lets start by digging into each of their namesake guarantees.</p></blockquote><blockquote><p>There’s a surprising symmetry between an HTTP request and a database’s transaction. Just like the transaction, an HTTP request is a transactional unit of work – it’s got a clear beginning, end, and result. The client generally expects a request to execute atomically and will behave as if it will (although that of course varies based on implementation). Here we’ll look at an example service to see how HTTP requests and transactions apply nicely to one another.</p></blockquote><blockquote><p>In APIs <em>idempotency</em> is a powerful concept. An idempotent endpoint is one that can be called any number of times while guaranteeing that the side effects will occur only once. In a messy world where clients and servers that may occasionally crash or have their connections drop partway through a request, it’s a huge help in making systems more robust to failure. Clients that are uncertain whether a request succeeded or failed can simply keep retrying it until they get a definitive response.</p></blockquote><hr><p><a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/" target="_blank">Notes on Distributed Systems for Young Bloods</a>:</p><blockquote><p>Distributed systems are different because they fail often • Implement backpressure throughout your system • Find ways to be partially available • Use percentiles, not averages • Learn to estimate your capacity • Feature flags are how infrastructure is rolled out • Choose id spaces wisely • Writing cached data back to persistent storage is bad • Extract services.</p></blockquote><hr><p><a href="http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf" target="_blank">End-to-End Arguments in System Design</a>:</p><blockquote><p>This paper presents a design principle that helps guide placement of functions among the modules of a distributed computer system. The principle, called the end-to-end argument, suggests that functions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. Examples discussed in the paper include bit error recovery, security using encryption, duplicate message suppression, recovery from system crashes, and delivery acknowledgement. Low level mechanisms to support these functions are justified only as performance enhancements.</p></blockquote><hr><p><a href="https://vimeo.com/36579366" target="_blank">Inventing on Principle</a>:</p><blockquote><p>I’ve spent a lot of time over the years making creative tools, using creative tools, thinking about them a lot, and here’s something I’ve come to believe: Creators need an immediate connection to what they’re creating.</p></blockquote><p>I can’t really excerpt any of the actual demos, which are the good part. Instead I’ll just endorse it: this talk dramatically, and productively, raised my bar for what I think programming tools (and tools in general) can be. Watch it and be amazed.</p><hr><p>Post the essays you keep returning to in the comments!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/progessays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903737</guid>
            <pubDate>Tue, 21 Jul 2020 02:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Strong Opinions, Weakly Held’ Doesn't Work That Well]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23903172">thread link</a>) | @shadowsun7
<br/>
July 20, 2020 | https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>There’s a famous thinking framework by ‘futurist’, ‘forecaster’, and scenario consultant Paul Saffo called ‘strong opinions, weakly held’. The phrase itself became popular in tech circles in the 2010s — I remember reading about it on Hacker News or a16z.com or one of those thinky tech blogs around the period. It’s still rather popular today.</p><p>Saffo’s framework — laid out in his original <a href="https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/">2008 blog post</a> — goes like this:</p><blockquote>I have found that the fastest way to an effective forecast is often through a sequence of lousy forecasts. Instead of withholding judgment until an exhaustive search for data is complete, I will force myself to make a tentative forecast based on the information available, and then systematically tear it apart, using the insights gained to guide my search for further indicators and information. Iterate the process a few times, and it is surprising how quickly one can get to a useful forecast.<p>Since the mid-1980s, my mantra for this process is “strong opinions, weakly held.” Allow your intuition to guide you to a conclusion, no matter how imperfect — this is the “strong opinion” part. Then – and this is the “weakly held” part – prove yourself wrong. Engage in creative doubt. Look for information that doesn’t fit, or indicators that pointing in an entirely different direction. Eventually your intuition will kick in and a new hypothesis will emerge out of the rubble, ready to be ruthlessly torn apart once again. You will be surprised by how quickly the sequence of faulty forecasts will deliver you to a useful result.</p><p>This process is equally useful for evaluating an already-final forecast in the face of new information. It sensitizes one to the weak signals of changes coming over the horizon and keeps the hapless forecaster from becoming so attached to their model that reality intrudes too late to make a difference.</p><p>More generally, “strong opinions weakly held” is often a useful default perspective to adopt in the face of any issue fraught with high levels of uncertainty, whether one is venturing a forecast or not. Try it at a cocktail party the next time a controversial topic comes up; it is an elegant way to discover new insights — and duck that tedious bore who loudly knows nothing but won’t change their mind!</p></blockquote><p>On the face of it, it all sounds very reasonable and smart. And ‘strong opinions weakly held’ is such a catchy phrase — which probably explains its popularity.</p><p>The only problem with it is that it doesn’t seem to work that well.</p><h2 id="swimming-upstream-against-the-architecture-of-the-mind">Swimming Upstream Against the Architecture Of The Mind</h2><p>How do I know that it doesn’t work that well? I know this because I’ve tried. I tried to use Saffo’s framework in the years between 2013 and 2016, and when I was running my previous company I attempted it with my boss, whenever we convened to <a href="https://commoncog.com/blog/what-uncertainty-feels-like/">discuss company strategy</a>.</p><p>Eventually I read Phillip Tetlock’s <a href="https://commoncog.com/blog/the-forecasting-series/"><em>Superforecasting</em></a>, and then I gave up on ‘Strong Opinions, Weakly Held’.</p><p>Why does the framework not work very well? From experience, Saffo’s approach fails in two ways.</p><p>The first way is if the person <em>hasn’t</em> read Saffo’s original post. This is, to be fair, most of us — Saffo’s original idea is so quotable it has turned into a memetic phenomenon, and I’ve seen it cited in fields far outside tech. In such cases, the failure mode is that ‘Strong Opinions, Weakly Held’ turns into ‘Strong Opinions, Justified Loudly, Until Evidence Indicates Otherwise, At Which Point You Invoke It To Protect Your Ass.’</p><p>In simpler terms, ‘strong opinions, weakly held’ sometimes becomes a license to hold on to a bad opinion strongly, with downside protection, against the spirit and intent of Saffo’s original framework.</p><p>Now, you might say that this is through no fault of Saffo’s, and is instead the problem of popularity. But my response is that if an idea has certain affordances, and people seem to always grab onto those affordances and abuse the idea in the exact same ways, then <em>perhaps you shouldn’t use the idea in the first place.</em> This is especially true — as we’re about to see — if there are better ideas out there.</p><p>The second form of failure is if the person has taken the time to look up the original intention of the phrase. In this situation, the failure mode is when you attempt to integrate new information into your judgment. Saffo’s framework offers no way for us to do this.</p><p>Here’s an example. Let’s say that you’ve decided, along with your boss, to build a particular type of product for a particular subsection of the self-service checkout market. You both come to the opinion that this subsection is the best entry-point to the industry: it is relatively lucrative, and you think that it is the easiest customer segment to service.</p><p>What happens to your opinion when you <em>slowly</em> discover that the subsegment is overcrowded? Of course, you don’t find out immediately — what happens instead is that you spot little hints, spread over the course of a couple of months, that many competitors are entering the market at the same time. These are tiny things like competitor brochures lying in the corner table of a client’s office, or pronouncements by industry groups that “they are looking to engage vendors for large deployments”, and then much later, clearer evidence in the form of increased competition in deals.</p><p>“Well,” I can hear you say, “‘Strong opinions weakly held’ means that you should change your opinion when you encounter these tiny hints!”</p><p>But at which point do you change your mind? At which point do you switch away from your strong opinion? At which point do you think that it’s time to reconsider your approach?</p><p>The problem, of course, is that <em>this is not how the human brain works.</em></p><p>Both forms of failure stem from the same tension. It’s easy to have strong opinions and hold on to them strongly. It’s easy to have weak opinions and hold on to them weakly. But it is quite difficult for the human mind to vacillate between one strong opinion to another.</p><p>I don’t mean to say that people <em>can’t</em> do this — only that it is very difficult to do so. For instance, Steve Jobs was famous for arguing against one position or another, only to decide that you were right, and then come back a month later holding exactly your opinion, as if it were his all along.</p><p>But most people aren’t like Jobs. Psychologist Amos Tversky used to joke that by default, human brains fall back to “yes I believe that, no I don’t believe that, and maybe” — a three-dial setting when it comes to uncertainty. People then hold on to their opinion for as long as their internal narratives allow them to. Saffo’s thinking framework implies that you sit in ‘yes I believe that’ territory, and then rapidly switch away to ‘maybe’ or to ‘no’, depending on the information you receive.</p><p>Perhaps you may — like Jobs! — be able to do this. But if you are like most people, the attempt will feel a lot like whiplash.</p><p>So, you might ask, what to do instead?</p><h2 id="use-probability-as-an-expression-of-confidence">Use Probability as an Expression of Confidence</h2><p>The gentler answer lies in <em>Superforecasting.</em> In the book, Tetlock presents an analytical framework that is easier to use than Saffo’s, while achieving many of the same goals.</p><ol><li>When forming an opinion, phrase it in a way that is very clear, and may be verified by a particular date.</li><li>Then state the probability you are confident that it is correct.</li></ol><p>For instance, you may say “I believe that Tesla will go bankrupt by 31 December 2021, and I am about 76% confident that this is the case.” Or you can be slightly sloppier with the technique — with my boss, I would say: “I think this subsegment is a good market to enter, and I think we would know if this is true within four months. I believe this on the order of 70% ish. Let’s check back in September.”</p><p>(My boss was an ex-investment banker, so he took to this like a duck to water.)</p><p>Tetlock’s stated technique was developed in the context of a geopolitical forecasting tournament called the Good Judgment Project. In 2016, when I read <em>Superforecasting</em> for the first time, I remember thinking that geopolitical forecasting wasn’t particularly relevant to my job running an engineering office in Vietnam. But I also glommed onto the book’s <a href="https://commoncog.com/blog/how-the-superforecasters-do-it/">ideas around analysis</a>, because it was too attractive to ignore.</p><p>The truth is that Tetlock’s ideas are not unique to his research group. Annie Duke’s <em><a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets">Thinking in Bets</a></em> proposes the same approach, but drawn from poker, and the ‘rationalist’ community <a href="https://www.lesswrong.com/">LessWrong</a> has long-held norms around stating the confidence of their opinions.</p><p>More importantly, Duke and LessWrong have both discovered that the <em>fastest</em> way to provoke such nuanced thinking is to ask: “Are you willing to bet on that? What odds would you take, and how much?”</p><p>You’d be surprised by how effective this question is.</p><p>Why is it so effective? Why does it succeed where ‘Strong Opinions, Weakly Held’ does not?</p><p>The answer lies in the ‘strong opinion’ portion of the phrase. First: by forcing you to state your opinion as a probability judgment — that is, a percentage — you are forced to calibrate the strength of your belief. This makes it easier to move away from it. In other words, you are forced to let go of the ‘yes, no, maybe’ dial in your head.</p><p>Second: by framing it as a bet, you suddenly have skin in the game, and are motivated to get things right.</p><p>Of course, you don’t actually <em>have</em> to bet — you can merely propose the bet as a thinking frame. Later, as new information trickles in, you are allowed to update the % confidence you have in your belief. This allows you to see the world in shades of grey; it also allows you to communicate that confidence to those around you.</p><h2 id="revisiting-the-hierarchy-of-practical-evidence">Revisiting The Hierarchy of Practical Evidence</h2><p>I have one final point to make about this approach.</p><p>Long term readers of this blog would know that my shtick is “apply a technique to my career or to my life, over the period of a couple of months, and report on its efficacy.” Over time, I’ve noticed that techniques are more likely to be effective when they come from believable practitioners. This is what led to my <a href="https://commoncog.com/blog/the-hierarchy-of-practical-evidence/">Hierarchy of Practical Evidence</a>.</p><p>Saffo’s and Tetlock’s …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903172</guid>
            <pubDate>Tue, 21 Jul 2020 00:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximum Entropy Intuition for Fundamental Statistical Distributions]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23902712">thread link</a>) | @yetanothermonk
<br/>
July 20, 2020 | https://longintuition.com/2020/07/20/max-entropy-intuition.html | <a href="https://web.archive.org/web/*/https://longintuition.com/2020/07/20/max-entropy-intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Imagine you wake up tomorrow in an empty white room, <em>a la</em> The Matrix. You don’t remember how you got there. <em>Anything can happen.</em></p>

<ul>
  <li>If Keanu Reeves appears, you’d probably think this is related in some way to the Matrix.
    <ul>
      <li>If Keanu appears and then Laurence Fishburne (Morpheus) appears, you’d think—okay, this is almost definitely related to the Matrix.</li>
    </ul>
  </li>
  <li>On the other hand, if Obama and Clinton appear in your white room, in your head, you’d think, okay, the Matrix-related possibilities are less likely; the politics-related possibilities are more likely, whatever those are.</li>
</ul>

<p>For the first few seconds in that empty white room, without knowing anything, everything is pretty much equally likely to us. In statistics, we call this a <strong>uniform distribution</strong>. It’s a good starting point when we know nothing. However, once we get new information, we shift probability mass from the less likely events to the more likely events, conditional on what we’ve just learned—in the Neo case, from Obama/Clinton related probabilities to Matrix-related probabilities; in the Obama/Clinton case, from Matrix-related probabilities to political event-related probabilities.</p>

<p>Often, in statistics education, we learn distributions in a vacuum of intuition. But, inevitably, we ask ourselves:</p>

<ul>
  <li>Why do we use the statistical distributions we use? For example, why is the Normal Distribution everywhere?</li>
</ul>

<p>We’ll find that statistical distributions aren’t pulled out of thin air. The statistical distributions we’re most familiar with—uniform, exponential, Normal—are exactly determined when we want to maximize our information gain from very simple and very few initial constraints.</p>

<p>We’ll find that we can use our intuition from the Matrix example to help us understand where these statistical distributions come from!</p>



<p>First, we need some intuition as to what expected information gain means.</p>

<p>Let’s start with the commonplace notion of an “average”. The average, in mathematical terms, is a sum of the value of each event weighted by the probability of that event occurring.</p>

<p>For example, if we have a rigged die with a heavy “six” side, we would expect the next value to be higher than the next value if we used a fair die. The higher frequency of occurrence of sixes pulls up the <strong>expected value</strong> (also known as the <strong>average</strong>, <strong>mean</strong>, or <strong>mathematical expectation</strong>).</p>

<p>Mathematically, what happens is we weigh the value of each event by the probability of that event occurring, and the sum gets us a rough idea of where the next numerical value will land.</p><p>

\[\text{mathematical expectation} = p(x) \cdot x \text{ for all } x \\ = \sum_i p(x_i) * x_i\]

</p><p>This basic concept of weighing things by the probability of those things occurring is a very useful concept. We can also weigh the <em>information gain</em> of an event occurring by the probability of that event occurring to get an expected information value across all the events we care about. But how do we measure information gain?</p>

<p>Intuitively we know that the more surprising something is, the more information it contains. In other words, <em>the informational value of an event is proportional to all the choices it killed off by virtue of that event occurring</em>.</p>

<p>The information value of an event is related to how much probability mass it moves versus itself once that thing occurs.</p>

<h2 id="leverage-can-be-surprising">Leverage Can Be Surprising</h2>

<p>One interesting way to think about this is leverage. Roughly, leverage means how much mass you move versus your own mass. In financial markets, if you outlay $1 million for $5 million of exposure, you’re levered 5 times. For our purposes, we want a good way to formalize our intuitional understanding of information; I haven’t seen information talked about in leverage terms elsewhere and I think it’s an… informative way to look at things.</p><p>

\[\text{leverage} \propto \frac{\text{exposure controlled}}{\text{initial outlay}}\]

</p><p>When we talk about “how much probability mass an event moves” or the amount of choices an event kills by virtue of its occurrence, this is in some sense a leverage ratio. What this looks like is the total amount of probability (normalized, we say 1, but it could just as well be some arbitrary sum, like 10000) divided by the probability of that particular event (p). The 10,000 factor cancels out when we divide the total by the individual probability, so we just get</p><p>

\[\text{info} \propto \frac{1}{p}\]

</p><p>Binary is, in a sense, the ultimate form of compression. Boiling things down to the most informative, basic essence of truth or falsity is a beautiful feature of a bit. We can count the number of bits needed to represent a value by taking its logarithm, base two, so we get</p><p>

\[\text{info} \propto \log_2{\frac{1}{p}}\]

</p><p>And if we weigh this by the probability of that particular event happening, we get</p><p>

\[\text{info} \propto p \cdot \log_2{\frac{1}{p}}\]

</p><p>And if we use the simplified version, we get</p><p>

\[\text{info} = p \cdot \log_2{\frac{1}{p}} \\ = p \cdot (\log_21 - \log_2p) \\ =-p \cdot \log_2p\]

</p><p>Awesome! We’ve built the definition of informational entropy from nothing other than a… bit… of intuition. Similar to our understanding for the mathematical expected value of a set of events, we can talk about the mathematical expected information for a set of events.</p><p>

\[\text{mathematical information expectation} = \sum_i -p(x_i) * \log_2{p(x_i)}\]

</p><p>Why is this useful? It turns out that the major statistical distributions maximize the expected information gain subject to certain constraints (each major distribution corresponding to different constraints).</p>

<p>Stated in a different way:</p>

<p>Take that our goal is to model the probability distribution for data we’re looking at.</p>

<p>We generally know a few things about the data—these will be our constraints—and we want to pick the probability distribution that maximizes our expected information gain (aka, maximizes our subsequent surprise, or <strong>entropy</strong>)—because if we had a distribution that had any less expected information gain than **the maximum entropy distribution, we’ve inadvertently encoded some information extra to our constraints into our distribution.</p>

<p>So the maximum entropy distribution is the closest thing we can get to a zero-knowledge guess, subject to what we know about the data (our constraints).</p>



<p>We found at the beginning of our journey that the uniform distribution—where we prescribe to each event an equal amount of probability mass—makes intuitive sense as the distribution we should pick when we don’t know anything at all. This isn’t saying that everything in reality has equal probability of occurring—a bit subtle; it’s just saying that, <em>given what we currently know</em> (assumed to be nothing), no one event is more likely than any other event.</p>

<p>What if we work from the mathematical end? What do we find if we just start out with very few, very basic assumptions and work forward?</p><p>

\[\text{information, the quantity we want to maximize: } \\ f(x)=-\int_a^b p(x) \cdot \log_2p(x)\,dx \\ \text{unity constraint: }g(x)=\int_a^b p(x)\,dx - 1 = 0\]

</p><p>In English, we want to maximize the information subject to the unity constraint, and we want to see what p(x) looks like.</p>

<p>Mathematically, we’re going to want to find the local extrema (local minima and maxima) of the information function along the unity constraint. Analogous to minimization and maximization in single-variable calculus, we want to find the points at which the derivative of our information function is zero along the constraint function. Intuitively, this should make sense—we want the extrema, and if the slope of the information function is (for example) greater than zero along the constraint, we would just walk along that direction, increasing our expected information gain along the way, all the while getting closer to a local maximum.</p>

<p>Finding where the derivative of f is zero along g is equivalent to saying the directional derivative of f along a vector s that lies on constraint g is zero.</p>

<p>Because the directional derivative of f along that vector s is zero, we know that the projection of the gradient of f on g is zero (aka, the dot product of the gradient of f and g is zero).</p>

<p>Therefore, we know that the gradient of f is parallel to the norm of the surface of g, so the gradient of f is parallel to the gradient of g.</p>

<p>In other words, the gradient of f is some scalar multiple of the gradient of g!</p>

<p>If we find where this occurs, we’ll have found the extrema.</p>

<p>If the above calc-related ideas sounds a bit unfamiliar, ping me at longintuition@protonmail.com so I know that there’s demand for me writing something on gradients.</p>

<p>Anyway, mathematically, we’re trying to do this:</p><p>

\[\nabla f(x) = a \cdot \nabla g(x)\]

</p><p>Which is equivalent to:</p><p>

\[\frac{\partial f}{\partial p(x)} = a \cdot \frac{\partial g}{\partial p(x)}\]

</p><p>Taking the derivative with respect to a function requires a bit of variational calculus, specifically the Euler Lagrange equation. Thankfully, we have some pretty easy functional derivatives here:</p><p>

\[\frac{-1-\ln(p(x))}{\ln(2)}=a \cdot 1\]

</p><p>Let’s simplify! We want to get an expression for p(x):</p><p>

\[-1-\ln(p(x))=a \cdot \ln(2) \\ 1 + \ln(p(x)) = -a \cdot \ln(2) \\ \ln(p(x)) = -1-a \cdot \ln(2) \\ \implies p(x) = e^{-1-a\ln(2)} \\ p(x) =e^{-1} \cdot e^{-a\ln(2)} \\ p(x) = e^{-1} \cdot 2^{-a}\]

</p><p>We’ll plug this expression into our unity constraint:</p><p>

\[\int_a^b p(x)\,dx=1 \\ \int_a^b e^{-1} \cdot 2^{-a} \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot \int_a^b \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot (b-a) = 1 \\ e^{-1} \cdot 2^{-a} = \frac{1}{b-a}\]

</p><p>This looks like p(x)!</p><p>

\[p(x)=\frac{1}{b-a}\]

</p><p>which is the PDF of a continuous uniform distribution!</p>

<p>This is super promising—the probability distribution that maximizes our surprise given we know basically nothing aside from a unity constraint is the uniform probability distribution!</p>

<p>What we’ve just done is confirm mathematically a very solid intuition we explored at the beginning of the piece!</p>



<p>Very rarely do we know absolutely nothing about the data …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://longintuition.com/2020/07/20/max-entropy-intuition.html">https://longintuition.com/2020/07/20/max-entropy-intuition.html</a></em></p>]]>
            </description>
            <link>https://longintuition.com/2020/07/20/max-entropy-intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902712</guid>
            <pubDate>Mon, 20 Jul 2020 22:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I asked GPT-3 to make a presentation for me]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23901059">thread link</a>) | @bemmu
<br/>
July 20, 2020 | http://www.bemmu.com/gpt3-presentation | <a href="https://web.archive.org/web/*/http://www.bemmu.com/gpt3-presentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			<div id="posts">
	
				<article>
					<header>	
						<section>
							<time pubdate="pubdate" datetime="2020-07-20">2020-07-20</time>
						</section>
					</header>
					

					<div id="droparea"><p>I told GPT-3 I would be presenting at a Hacker News meetup in Japan, and asked it to generate a presentation for me. Here's what it came up with, read by yours truly.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vZalOEmdHFo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>There's also a tweet-sized version <a href="https://twitter.com/bemmu/status/1285284131656445952">here</a>, and the slides are also on SlideShare <a href="https://www.slideshare.net/bemmu/this-presentation-was-generated-by-gpt3">here</a>.</p>
<h2>Details</h2>
<p>I used the <a href="https://openai.com/blog/openai-api/">OpenAI API</a> to generate one slide and one image caption at a time, asking GPT-3 about three times for each and picking the best output. When it generated image caption, I would go online to find a matching image, or if none was available I'd try to splice up an image using <a href="https://www.photopea.com/">Photopea</a> and <a href="https://www.remove.bg/">Remove.bg</a>.</p>
<p>My starting prompt was:</p>
<pre><code>A presentation was given at the Hacker News event in Kansai. 
The title of the presentation was
</code></pre>
<p>When it generated bullet points, I let it generate several and then picked the best 5 out of what it came up with. Once it generated a slide, I edited that into the prompt as well so it could continue generating more slides for the same presentation, and re-ran it to generate the next slide. </p>
<p>Piecewise concatenated output from OpenAI:</p>
<pre><code>"Strategies for Learning to Code in Japan" and the subtitle was 
"Fairly easily and rather effortlessly achieve practical software 
development skills."

The first presentation slide had a picture of a man playing a violin 
in front of a wall of violins, and the title of the slide was "Violin 
skills are of almost no value". Text under the slide said: "a metaphor 
for how useful programming ability can be for starters".

The next slide suggested a number of strategies for how to best use 
ones time to achieve productivity quickly:

1. Nobody figures out how to code perfectly their first time.
2. It's mostly luck.
3. Learn just the right skills, in the right order.
4. Avoid perfectionism.
5. Not doing something is sometimes the best way to learn something.

The next slide had a picture of a monkey drawn in crayon, and
and the words "All problems are pretty much the same." written 
under the monkey drawing. The text of that slide was:
"Not only are all software development problems more or less 
the same, but the best way to solve them is usually so simple, 
that a monkey could do it."

The next slide had a picture of a monkey, a sand hourglass, 
and a spoon and the words "Let's get started then!" written 
under it.

The text of that slide was: "Just like a monkey makes sand castles 
with an hourglass, all our time is of limited duration, so let's get 
started to code a product for clients. Software development is 
actually a bunch of often complicated problems. But that's not a big 
deal, is it!?" and the color of the text was red.

The next slide had a picture of a happy architect with a blueprint 
in one hand and blue pencil in the other hand, standing in front of a 
huge complex, and the words "Looking smart is the social norm".

The text of that slide was:
"Almost all developers feel the pressure (for whatever reason) to have the
look of the competent coder, most likely due to peer pressure. So it might
be counter-productive to cut corners during the development phase." and
the color of the text was purple.

The next slide had a sign: "DANGER do not enter" and this text under it: 
"If you don't need your code to run during actual product development, 
stuff it in a module in a separate directory." The color of the text 
was orange.

The next slide just had the text: Richard Feynman was reported to have 
said: "What I cannot create, I do not understand," something that has 
been paraphrased in the programming world as "If you don't regularly turn 
code into poetry, you probably aren't a good programmer."

The next slide had a picture of a happy runner and this sentence next 
to it: "If you've written 500 lines of code and have an actual working 
program that doesn't crash, sprint to the finish line." 
and the color of text was green.

The next slide had a picture of a swordsman catching a bullet and 
this text: "A happy ending to all of our code." and the color of 
text was yellow. The text of the slide was: "So you built a program
and it worked in like 10 minutes. All your code was beautiful." 
and the color of text was blue.

The final slide had the title of the presentation: "Why you should 
always code like it's your last day on Earth". Next to it was a picture 
of a person with their whole life ahead of them staring into a terminal, 
a ball and chain attached to each leg, and a long nose and a beard. The 
text of the slide was:
"If you always think like it's the last day on Earth (your last day coding), 
it'll push you just enough to get you to finish whatever you might need 
to finish."

The last remark at the last slide of the presentation was:
"So now that you know it's impossible to not 
learn to code, go write something, anything.
So stop writing nuclear missile designs, or the best 
ad blocker ever, and just get started on whatever.

The next slide had the text "And then when you finally do finish this nice 
feature, you should always make sure you drink the required amount of alcohol." 
with a background image of whiskey bottles. The decorative text on that slide 
was: "But don't drink too much alcohol and end up like me."

And the concluding remark of the presentation:
"So basically just go ahead before you wake up in a cold sweat from a scary 
dream about the future, coding-less, uh, eating those annoying squares of tofu."
The background image of that slide was a plate of tofu next to a glass of beer
and the font color was orange to emphasize the suggestion to drink.
</code></pre></div>

				</article>
	
			</div>
			
		</div></div>]]>
            </description>
            <link>http://www.bemmu.com/gpt3-presentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901059</guid>
            <pubDate>Mon, 20 Jul 2020 19:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for great product managers]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23900783">thread link</a>) | @AlexDReeve
<br/>
July 20, 2020 | http://reeve.blog/blog/principles/ | <a href="https://web.archive.org/web/*/http://reeve.blog/blog/principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p><strong>Edit 07.20.20:</strong><br>This post was #1 on <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a> today, which did 2 things: First, it crashed this site (sorry, won’t happen again). Second, it catalyzed some great dialogue <a href="https://news.ycombinator.com/item?id=23900783">here</a>. If you’d like to continue the conversation, hit me up on <a href="https://twitter.com/AlexDReeve">Twitter</a>.</p>



<hr>



<p>A few years ago, I read&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://amzn.to/2C4RbBY">Principles</a>&nbsp;by Ray Dalio, and I became enamored with the concept of codifying my own. So, I borrowed the idea and started noting them down.</p>



<p>This list—pieced together over the past few years—reflects what I believe are some of the most important principles for product managers. I can’t claim credit for inventing these; they are the summation of what I’ve learned through experience, coaching, and osmosis. This list wouldn’t exist if not for the incredible people I’m fortunate to work with and from whom I’ve learned so much.</p>



<p><strong><strong>Product Management is a broad function, so I’ve tried to distill this down to the top 3-4 across 6 categories:</strong>&nbsp;</strong>These principles are very much a “living” list. I don’t intend for this list to be exhaustive—nor does it reflect the entire scope of the product manager role—and these principles will continue to develop over time.</p>



<h3>Leading Your Team</h3>



<p><strong><strong>1.</strong>&nbsp;<strong>Your team should be able to repeat the vision, goal, and value</strong>. </strong>If your team can’t, you probably haven’t communicated it enough or aren’t aligned.</p>



<p><strong>2. You should know what game you’re playing, and how you keep score</strong>. Credit to Adam Nash for this framing, see here for his <a href="https://adamnash.blog/2011/12/16/be-a-great-product-leader/">fantastic article</a>.</p>



<ul><li><strong>The game you’re playing:</strong> Your vision for the product, your product’s value to the customer, your competitive advantage, and how you’ll win.</li><li><strong>How you’ll keep score</strong>: What does winning mean? How will you measure success? What’s your “compass” to tell whether you’re traveling in the right direction?</li></ul>



<p><strong><strong>3. Your team should know the path to reach the goal.&nbsp;</strong></strong>You need not detail execution to the point of false precision, but you and your team must understand the high-level milestones. If the milestones aren’t clear because of unknows, these unknowns should be explicit.</p>



<h3>Making Decisions</h3>



<p><strong>4. Decisions should be documented, explained, and widely communicated</strong>. It should&nbsp;<em>feel&nbsp;</em>like over-communication. If you don’t feel like you’re over-communicating, you probably aren’t communicating enough.</p>



<p><strong>5. Decisions, and what you prioritize, need evidence.&nbsp;</strong>It’s your job to make sure this evidence exists. Inevitably, you will base some decisions on your judgment in place of data. Judgment-weighted decisions are okay, provided it’s explicitly communicated.</p>



<p><strong>6. Stakeholders should be involved early and often, and alignment should be explicit.&nbsp;</strong>You’re looking for either a “yes, I agree with this decision, or a “no, I disagree, but I can commit to moving forward.” Escalate quickly and cleanly to resolve misalignments.</p>



<h3>Communication Effectively</h3>



<p><strong>7. There is no such thing as over-communication.</strong> “Fluff” communication = enough communication.</p>



<ul><li>If you’re not sick of saying it, you probably aren’t saying it enough. Constant communication might feel like “fluff,” but it isn’t. Evangelism is a critical part of the role—and it’s your job to make sure the organization is aligned and swimming in the same direction.</li><li>Marty Cagan, in <a href="https://amzn.to/3eMLBS0">Inspired</a>, said it best: <em>Evangelize continuously and relentlessly. There is no such thing as over‐communicating when it comes to explaining and selling the vision. Especially in larger organizations, there is simply no escaping the need for near‐constant evangelization. You’ll find that people in all corners of the company will at random times get nervous or scared about something they see or hear. Quickly reassure them before their fear infects others.</em></li></ul>



<p><strong>8. You, the product manager, should have a uniquely high communication bar.  </strong>Most functions have a primary “output” that isn’t communication: Designers design, engineers code, etc. For you, communication&nbsp;<em>is</em>&nbsp;a primary “output,” and it should be exceptional.</p>



<p><strong>9. You have to own the narrative.&nbsp;</strong>When there’s a narrative vacuum, people will “creatively” fill in the blanks themselves—and you might not like it. Losing control of the narrative can be incredibly disruptive to your team’s ability to deliver.</p>



<h3>Being an Effective Operator</h3>



<p><strong><strong>10.</strong>&nbsp;<strong>Strong relationships enable strong collaboration.&nbsp;</strong></strong>“Have strong relationships” sounds obvious, but the importance of relationships “up,” “down,” and “across” can’t be overstated. Without a solid mix of relationships and credibility, you won’t succeed.</p>



<p><strong><strong>11. Don’t be in the weeds managing every nuance of every project; save this for emergencies</strong>. </strong>Swim in your lane, and give your team space to do their job(s). Focus on:</p>



<ul><li>Setting the goal, i.e., “what game are we playing?” and lead/help the team in figuring out how to get there (milestones, dependencies, alignment, etc.).</li><li>Leading the team. E.g., establish the communication cadence (updates, Slack channels, syncs), meeting rhythm, high-level project milestones, success metrics.</li><li>Don’t pester. Establish the right communication channels upfront, and let your team keep you updated. See “maker’s schedule” under (12).</li></ul>



<p><strong><strong>12. Greatness is achieved in the agency of others</strong></strong>. Product managers follow the “manager’s<a rel="noreferrer noopener" target="_blank" href="http://www.paulgraham.com/makersschedule.html">&nbsp;schedule</a>.”<strong> </strong>Engineers &amp; designers follow the “maker’s schedule.” Help your team be great “makers”—keep them unblocked; respond effectively to unfolding situations.</p>



<p><strong>13. Your job is to create clarity</strong>:<strong> </strong>This is some sound advice that I got early on (thank you, Greg!). As a product manager, constantly think about how you can <em>create clarity</em> for your team: Clearer product requirements, resolving edge cases, answering questions, etc.</p>



<ul><li>If you’re drowning in questions, you probably aren’t proactively communicating effectively, or the product requirements lack clarity. Some questions are natural, so use your judgment.</li></ul>



<p><strong>14. Be on top of your shit.</strong> Until I figure out how to better articulate this, I’ll say it ineloquently as “just be on it.” Know your business, your product, your team, be responsive, communicate relentlessly, make good decisions, own your results, get 1% better every day.</p>



<h3>Managing Your Time</h3>



<p><strong>15. 80% of your role is discovering the right product &amp; driving organizational alignment, and 20% is answering clarifying questions for the “makers” on your team. </strong>Product teams are in a constant cycle of discovery and delivery, which run in parallel: </p>



<ul><li>In an ideal world, engineers are ~80% delivery, ~20% discovery; product managers are ~80% discovery, 20% delivery.</li><li>In large complex organizations, this is a difficult target to achieve, but strive to spend 80% of your time on discovering the right product (ideation, validation, testing, etc.) and communication (driving organizational alignment, creating clarity).</li><li>“Organizational alignment” is an intentionally broad term, including everything from 1-1 meetings to executive strategy reviews to product “deep dives” to all-hands presentations.</li></ul>



<p><strong>16. Ensuring that you have time set aside for strategy and “focus” work is your responsibility. </strong>Getting sidetracked with 1,000 emails and Slack messages is natural, but it can’t be an excuse. Make sure you have time set aside for focused work.</p>



<h3>Running Effective Meetings</h3>



<p><strong>17. Send agenda items beforehand. At the start of the meeting, collect input,</strong> <strong>and align on the goal. </strong>Meetings are expensive; when people are meeting, they often aren’t making. Own the meetings you run, and make sure they’re productive.</p>



<p><strong>18. Use “DAD” to help structure and run meetings</strong>. Most meetings are a mix of Discussion, Actions, and Decisions: Document any decisions, communicate topics of discussion and enumerate any action items.</p>



<p><strong>19. “ABFU,” or Always Be Following Up (terrible, I know).</strong> Make sure you (or someone else) sends notes to all relevant stakeholders within ~24 hours. They don’t need to be perfect, but make sure they exist and that you communicate them.</p>



<p><strong>20. Be deeply curious, and ask the “dumb” questions.</strong> Asking the right questions, even if they seem dumb, is a catalyst for creating clarity. Ask questions openly, in earnest, and let everyone else hear the answer. You probably weren’t the only one with that question.</p>



<h3>Running Projects &amp; Other</h3>



<p><strong><strong>21.</strong>&nbsp;<strong>Every project includes a mix of Discovery, Design, and Delivery (and iteration); you should make sure these run in sequence.&nbsp;</strong></strong>While we expect and&nbsp;<em>desire</em>&nbsp;some overlap, aspire not to make sweeping changes to design during delivery (as an example).</p>



<p><strong>22. Be responsive; if you’re not, you might be holding things up. </strong>As the hub between every other function, and often the decision-maker, you have to keep the wheels greased for your team. One idea: ~2 hours for Slack, ~2 days for email (but much faster for anything urgent).  </p>



<hr>



<h4>Further Reading</h4>



<ul><li><a href="https://amzn.to/3em4Fqi">Principles</a>, by Ray Dalio, which inspired this exercise.</li><li><a href="https://amzn.to/3eMLBS0">Inspired</a> by Marty Cagan. If there’s one book on Product Management you should read, it’s this. At some point, I’ll publish my ~3,000 words of notes from it!</li></ul>

			<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://reeve.blog/blog/principles/"
    dc:identifier="https://reeve.blog/blog/principles/"
    dc:title="22 Principles for Great Product Managers"
    trackback:ping="https://reeve.blog/blog/principles/trackback/" />
</rdf:RDF>-->
</div></article></main></div></div></div>]]>
            </description>
            <link>http://reeve.blog/blog/principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900783</guid>
            <pubDate>Mon, 20 Jul 2020 18:56:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Look at Early Japanese Typewriters (2016)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898649">thread link</a>) | @caust1c
<br/>
July 20, 2020 | https://filthyplaten.com/2016/07/23/__trashed/ | <a href="https://web.archive.org/web/*/https://filthyplaten.com/2016/07/23/__trashed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg"><img data-attachment-id="2747" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg"><img data-attachment-id="2746" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender-7/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg" data-orig-size="3264,566" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1469299298&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1396 1396w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1024 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
A little while ago a friend of mine by the name of John Munroe sent me this great little Olivetti 32 ‘Katakana’ typewriter. I’d been keeping an eye out for such a machine for a number of years now, but as you may expect – such typewriters are generally non existent in markets that are available to Australia.</p>
<p>I spoke to John a little while back after he found a Royal that was set up for Japanese somewhere online, and I asked him to keep an eye out for one for my foreign language collection. John lives in Tokyo, and was confident that he’d come across another one pretty quickly.</p>
<p>And quickly he did. It wasn’t long before he managed to get his hands on this magnificent Olivetti Lettera 32. Of all the L32’s I have had, after this guy was cleaned up I found that &nbsp;types nicer than any other machine I have ever owned of this model.</p>
<p>So John Munroe. I owe you heaps, and much more than a huge, huge thank you!</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg"><img data-attachment-id="2748" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-side/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg" data-orig-size="1000,601" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti side" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
I’m very grateful to John for sending me this machine. Back when I was at high school, we were required to study two languages. Japanese and German. I was far better at German than Japanese, but I have long had a fascination with Japanese &nbsp;culture. My sister also lived there for 10 years and is fluent in Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg"><img data-attachment-id="2749" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard-overview/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard overview" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Katakana is only one piece of Japanese written language, and is often used to articulate English words into Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg"><img data-attachment-id="2750" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg" data-orig-size="1000,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The history of the Katakana keyboard dates right back to the late 1800’s. But it really came into existence in the 1920’s &nbsp;when some members of society in Japan were pushing for a simplified or reduced version of the Japanese language. The idea was to use that Katakana syllabary in a gestalt structure that is closer to the structure of European languages. While earlier keyboards were designed with a full set of Katakana glyphs (Kana), later they used dead keys on keyboards to allow the completion of characters.</p>
<p>This Olivetti has a couple of dead keys. Note the placement of the ‘P’ key? Right next to that… On the left, is the first dead key to be found on the keyboard. If found this positioning especially peculiar.</p>
<p><b>But wait..</b></p>
<p>What about the English characters on this typewriter?</p>
<p>Ahhhh yes… Well… That decreases the Kana (Katakana means Fragmented Kana) characters used one this keyboard.. Right?</p>
<p>The thing about katakana is, that it is also used in circumstances where English words are crammed into Japanese language – in the way that in English we italicise foreign language words.</p>
<p>So what does this typewriter do?</p>
<p>John’s suggestions that it is a typewriter that would be in use by telegraph operators to move between Japanese and English is a pretty sound one. Katakana can be used as a simplified Japanese language.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg"><img data-attachment-id="2752" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender2/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg" data-orig-size="1024,194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender2" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
But it could also be used in a studio to produce Katakana segments for English words on this machine – when the writer was using a different keyboard featuring other kana – Say… Hiragana. But I don’t think so. The push in Japanese society was based around making language more universal. Contentiously, several key developments occurred when there was a push in Japanese society towards using English langauge more universally. Although the by the late 40’s – post World Ward 2, there was also a push towards using French.</p>
<p>Either way, in the 20’s the first Typewriters &nbsp;were being produced based to write a &nbsp;in romanized gestalt structure in Katakana. Just for reference, the company that produced these first machines was Underwood – who Olivetti eventually bought and absorbed into their organization.</p>
<p><b>Let’s not mention Kanji.&nbsp;</b></p>
<p>No… Let’s. Let’s talk about Kanji.</p>
<p>Written Japanese language can be something of a horror to people that grew up outside of Japan. Even inside of it, there’s plenty of things that can – and do – often go wrong. It’s not that romanised languages are perfect – but the diverse structure in Japanese (a problem also shared with Chinese languages) often causes complexities. The positive thing about Kanji is that it allows for quite an efficient expression with more nuance.</p>
<p>So… Like every other language in existence, there’s plenty of people that take a much more puritanical view to their language and many &nbsp;in Japan resisted change. The problem was that there wasn’t much of a way to easily produce written documents on a machine. Considering that the Japanese language has thousands of characters – it obviously wasn’t going to be easily presented on the keyboard unless the keyboard was huge.</p>
<p>Enter item number 2 that is new to my collection. &nbsp;Welcome to the Nippon Type.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg"><img data-attachment-id="2751" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg" data-orig-size="1000,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Over a century ago the Japanese started producing heavy and lumbering machines that had thousand of typeface characters that operated wtih a feed mechanism which pulled characters out of a grill. It involved moving the carriage over the top of the grill and positioning it above the character and then feeding it upwards to a type hammer that pushed it against the page and the ribbon. It then drops the hammer back, and the character falls back into the grill.</p>
<p>This mechanism improved dramatically in later years, and instead of a moving carriage, the grill floated on a rack which moved under the carriage.</p>
<p>Eventually a character board was put in front of the carriage, allowing the user to type by moving the arm that was connected to the grill, that has a stylus on the end that the user points at a desired character with.</p>
<p>The characters are grouped into syllabary or kana, and kept together in an order that is predictable. As you can see in the photo below such groups are colored to make it easier for the typist.</p>
<p><b>Enter the Nippon Type.&nbsp;</b></p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg"><img data-attachment-id="2753" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-front/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg" data-orig-size="1000,605" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon front" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><b><br>
</b></p>
<p>On the left of the machine is a solid arm that has a black knob that operates the character pulling mechanism. The small black lever next to that is the space bar. This allows the typist to quickly use operate with their left hand, while swinging the arm with the stylus with their right – selecting characters and quickly tapping it in.</p>
<p>The carriage has a large black lever that operates like every other carriage lever. Interestingly, the machine is set up to type right to left with the characters positioned to be read along the page, rather than down it as was traditional. Maybe the Katakana brigade made some in-roads there.</p>
<p>Interestingly, the typewriter also has a group of Roman characters grouped on the machine, allowing the user to type in English – or at use least English word. These are also regarded as Kana – and known as Romaji.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg"><img data-attachment-id="2754" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-elements_/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon elements_" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The characters are kept in a smooth moving tray that feels like it is floating under the machine. When the mechanism operatingarm is pulled down on the machine you can feel the tray Bing pulled into alignment to the closest character. Then the mechanism starts and the hammer makes a solid thump as it punches a character piece against the platen. It’s a surprisingly noisy operation. But quick.</p>
<p>To reduce the noise around the typewriter the rear of the machine has a noise deadening bulkhead that is supposed to absorb some of the noise.</p>
<p>But it isn’t anywhere near as fast as typing on a keyboard. The efficiencies that most typewriters produce for writers are all but wiped out by the movement which is more energy consuming than writing Kana by hand by hand.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg"><img data-attachment-id="2757" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-back/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg" data-orig-size="1000,656" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon back" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
This machine belonged to a former Australian Journalist that had been living in Japan and working there. I bought this machine off his daughter who was moving house on the day that I arrived to collect it. I can understand the appeal of this machine to a journalist in a foreign country. It would give a great refer ace board to access all the Japanese Kana on, which would make it quicker to learn and access. Obviously it has some great advantages over handwriting for legibility as well</p>
<p>The interesting thing about this machine is that – unlike the lumbering and heavy old &nbsp;Japanese typewriters of the early years, this beast is surprisingly light – weighing less than an Olympia SM4 in its case.</p>
<p>Sadly though, some of the type elements are missing, so the machine isn’t complete. Although interestingly enough, type elements can still be ordered.</p>
<p>Anyway, this is just a brief look at that crazy world that is Japanese typewriting. I hope you found these machines interesting. I’ll have a closer look at both and maybe their history in another post.</p>
<p>Thanks for reading.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://filthyplaten.com/2016/07/23/__trashed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898649</guid>
            <pubDate>Mon, 20 Jul 2020 15:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Problem with Tor]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23897288">thread link</a>) | @worldofmatthew
<br/>
July 20, 2020 | https://worldofmatthew.com/post/tor-german-avoid/ | <a href="https://web.archive.org/web/*/https://worldofmatthew.com/post/tor-german-avoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>
<div>
<p>Over the past year, relay operators have done a good job in diversifying the range of network that they use to host their relays. The problem is that the move away from popular ASNs has not always translated to a move away from popular countries.</p>
<p>This is where we come to Germany, which has the highest amount of Tor relay capacity in the World at 167Gbps, in contrast France is in 2nd place with 64.5Gbps of capacity aka more than 100Gbps lower than Germany.</p>
<h2 id="the-problem-with-germany">The problem with Germany</h2>
<p>The German state is that exactly in love with the Tor network. This is the state who started <a href="https://itnomad.wordpress.com/2006/09/10/germany-crackdown-on-tor-node-operators/">raiding Tor relay operators in 2006</a>, <a href="https://blog.torservers.net/20180704/coordinated-raids-of-zwiebelfreunde-at-various-locations-in-germany.html">illegally seized</a> documents from German exit relay operator; torservers.net in 2018, tried to pass a <a href="https://www.privateinternetaccess.com/blog/germany-considers-amendment-to-law-which-makes-it-illegal-to-run-a-tor-node-or-website/">really vague law in order to the running of Tor relays</a> and now are about to vote on a <a href="https://www.privateinternetaccess.com/blog/new-german-law-would-force-isps-to-allow-secret-service-to-install-trojans-on-user-devices/">law to hijack traffic</a> to download Trojans on the computer of anyone they target.</p>
<p>This is the aggressive anti-privacy shit that most people would expect of somewhere like Russia. This might not be what you expect from a country that claims to love the right to privacy and pushed for the GDPR.</p>
<p>In reality, the German government has a double standard when it comes to the right to privacy. They will fully support that right if it's company's violating your privacy (especially, if they are American because protectionism) but in contrast, the German will give itself as many powers as it can to spy on its own citizens and those abroad.</p>
<p>Now you know how the Germans hate privacy, you will almost certainly be asking about alternative locations.</p>
<h2 id="but-tor-is-encrypted">But Tor is encrypted?</h2>
<p>The high number of high-speed relays and exits in Germany mean that it is not too uncommon to get both a German guard and exit. This gives the state an easier time if they want to target someone using traffic correlation attacks.</p>
<p>That also does not take in account the planned German law that will allow authorities to redirect traffic to state-owned servers, to infect users with viruses/Trojans. This is especially a concern for third-world users of Tor who are going to mainly accessing non-HTTPS sites on a computer without the best security.</p>
<h2 id="what-alternatives-are-there-to-germany">What alternatives are there to Germany?</h2>
<p>The current country with the best privacy to cost ratio is Luxembourg, where a 200Mbit can be gotten <a href="https://gcorelabs.com/pricing/hosting/">for 3.25 EUR per month</a>. Or if you have the money than Switzerland would be more ideal but you would not want to waste a Switzerland VPS on a non-exit relay.</p>
<p>Or if you are cheap, you could get a VPS from a country who hates the western spy powers like Russia or Moldova which will still help enhance the security of the Tor network by decreasing the chances that someone's traffic will just travel though one spying block which will make traffic correlation attacks much harder.</p>
</div>

</article>
</div></div>]]>
            </description>
            <link>https://worldofmatthew.com/post/tor-german-avoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897288</guid>
            <pubDate>Mon, 20 Jul 2020 12:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Got Hacked, Is Mastodon Immune?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23896994">thread link</a>) | @yogthos
<br/>
July 20, 2020 | https://mikestone.me/twitter-got-hacked-is-mastodon-immune | <a href="https://web.archive.org/web/*/https://mikestone.me/twitter-got-hacked-is-mastodon-immune">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Unless you've been hiding under a rock the last week or so, you probably know that Twitter got “hacked”. So, is Mastodon immune from having the same thing happen to it?</p>

<p>Before we can determine if Mastodon is in any better place than Twitter, we have to understand how Twitter's “hack” occurred.</p>

<p><a href="https://www.cnet.com/news/twitter-says-hackers-got-access-to-internal-tools-for-hijacking-spree/" rel="nofollow">CNET Reports</a>:</p>

<blockquote><p>We detected what we believe to be a coordinated social engineering attack by people who successfully targeted some of our employees with access to internal systems and tools</p></blockquote>

<p>Social engineering is <a href="https://en.wikipedia.org/wiki/Social_engineering_(security)" rel="nofollow">defined</a> as, “The psychological manipulation of people into performing actions or divulging confidential information.”</p>

<p>I would argue, and I'm sure most people would agree with me, that no one is perfectly immune from social engineering. It's part of being human, and as long as humans are involved in the situation, it's going to be a vulnerability.</p>

<p>I would also argue Mastodon's distributed nature makes such a coordinated and far reaching attack much less likely.</p>

<p>The attackers in this case targeted high profile individuals, and gained access to Twitter's own internal tools using social engineering. Obviously Mastodon has it's own internal tools, but those tools on <a href="https://mastodon.social/" rel="nofollow">mastodon.social</a> have absolutely no effect on <a href="https://fosstodon.org/" rel="nofollow">Fosstodon</a>, and vise versa.</p>

<p>If attackers wanted to coordinate a similar attack on Mastodon, they'd have to stick to individuals on a particular instance, or they'd have to socially engineer moderators/administrators on multiple instances.</p>

<p>No, this isn't an impossible task. After all, more than one individual was compromised in the Twitter hack. I do think it's more difficult though.</p>

<p>Twitter's response to this whole mess is also worth taking a look at. When Twitter discovered the “hack”, they immediately locked out all access to verified Twitter accounts. This caused a whole lot of problems for a whole lot of people, but I'm not going to talk about this now.</p>

<p>If Mastodon were to be “hacked” in the same way, the same outcome would not occur. Just because one instance of Mastodon is compromised does not mean that they all are. If one instance has to lock down accounts to reduce risk, the rest can continue to operate as they always have.</p>

<p>For the time being, Mastodon remains a small enough presence in the social media sphere that this kind of attack hasn't been worth the time. It is growing, and in time it very well may grow to a point where it is. While Mastodon isn't entirely immune to this kind of attack, it is more difficult and less rewarding. That makes is less of a target, even if all other things are equal.</p>

<p>Day 68 of the <a href="https://mikestone.me/tag:100DaysToOffload" rel="nofollow"><span>#</span><span>100DaysToOffload</span></a> Series:</p>
</div></div>]]>
            </description>
            <link>https://mikestone.me/twitter-got-hacked-is-mastodon-immune</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896994</guid>
            <pubDate>Mon, 20 Jul 2020 12:17:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – a Zilog Z80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23896816">thread link</a>) | @segfaultbuserr
<br/>
July 20, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I originally imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will expand on it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>That program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added that version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> has "Image views" where it shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters.</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The chip/layer view can also be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain "macros", which are tokens that expand into named net's and bus' values, and those are updated in real time, as the simulation runs.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image.png" alt=""><figcaption>Dynamic annotations showing U and V bus values (~ means "inverted")</figcaption></figure></div>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image-1.png" alt=""><figcaption>Waveform view can display signals in a variety of formats</figcaption></figure></div>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896816</guid>
            <pubDate>Mon, 20 Jul 2020 11:41:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TileDB closes $15M Series A for universal data engine]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 61 (<a href="https://news.ycombinator.com/item?id=23896131">thread link</a>) | @k-rus
<br/>
July 20, 2020 | https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14 | <a href="https://web.archive.org/web/*/https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Cambridge, MA, July 14, 2020: <a href="https://tiledb.com/">TileDB, Inc.</a> has secured a $15M Series A investment round led by <a href="https://twobearcapital.com/">Two Bear Capital</a>, joined by <a href="https://uncorrelated.com/">Uncorrelated Ventures</a> and all existing investors: <a href="https://nexusvp.com/">Nexus Venture Partners</a>, <a href="http://www.intelcapital.com/">Intel Capital</a>, and <a href="https://bigpi.vc/">Big Pi Ventures</a>. The funding will help the company expand go-to-market and product development for its “universal data engine,” a novel database that goes beyond tables to manage any complex data and beyond SQL to analyze the data with any tool, all serverless and at planet scale. Montana philanthropist and Two Bear Capital Managing Partner Mike Goguen will join TileDB’s Board of Directors.</p>
<p>The Series A financing comes after TileDB was chosen by customers who experienced two key pains: scalability for complex data and deployment. Whole-genome population data, single-cell gene data, spatio-temporal satellite imagery, and asset-trading data all share multi-dimensional structures that are poorly handled by monolithic databases, tables, and legacy file formats. Newer computational frameworks evolved to offer “pluggable storage” but that forces another part of the stack to deal with data management. As a result, organizations waste resources on managing a sea of files and optimizing storage performance, tasks traditionally done by the database. Moreover, developers and data scientists are spending excessive time in data engineering and deployment, instead of actual analysis and collaboration.</p>
<p>“We flipped the data management model,” said Dr. Stavros Papadopoulos, CEO and original creator of TileDB. “We invented a database that focuses on universal storage and data management rather than the compute layer, which we’ve instead made `pluggable.` We cleared the path for analytics professionals and data scientists by taking over the messiest parts of data management, such as optimized storage for all data types on numerous backends, data versioning, metadata, access control within or outside organizational boundaries, and logging. On top, we developed numerous APIs for fast direct data access and efficient integrations with a growing set of popular tools such as Spark, Dask, MariaDB and PrestoDB. Finally, we built a serverless infrastructure for easy, secure cross-organizational sharing and scalable compute, called TileDB Cloud.”</p>
<p>According to Scott Soenen, VP of Product Engineering at Capella Space: “The partnership with TileDB gelled perfectly with our desire to deliver a new level of innovation in open data programs aimed at the geospatial community. Open data alone isn’t enough. It’s also about easy access to compute resources and versatility of analytics. TileDB Cloud removes multiple manual steps in data access for the geospatial developer community and offers intuitive self-service and interactive analytics."</p>
<p>“We have chosen TileDB as the storage engine to power our cellxgene project at CZI, which is an interactive data explorer for single-cell transcriptomics datasets,” said Bruce Martin, Director of Engineering, Chan Zuckerberg Initiative. “TileDB provides an easy and powerful way to manage our huge array data on various backends, including cloud object stores. The serverless infrastructure of TileDB Cloud opens the door to extreme scale with very low engineering efforts on our part, allowing us to focus more on scientific discoveries instead.”</p>
<p>Magnus Isaksson, Director of Bioinformatics, Helix shared, “The synergy between our two companies has enabled us to take an innovative approach to storing and analyzing genomic data at population-scale. We were excited to find TileDB after extensive diligence of potential solutions that could meet Helix's needs and advance our vision to revolutionize population health via the power of genomics."</p>
<p>“Many of the world’s most urgent problems - from COVID to climate change - require the analysis of large volumes of data in order to find solutions. TileDB’s technology addresses the infrastructure deficit that adds friction, delay, and cost to generating the key insights and discoveries needed from this data,” said Mike Goguen, Managing Partner at Two Bear Capital and lead investor. “We are excited to partner with Stavros and TileDB to build an enduring company delivering massive value for the developers and enterprise customers working to solve these and other critically important problems.”</p>
<p><br>
To learn more about TileDB visit <a href="https://tiledb.com/">our website</a>, check out the open-source <a href="https://github.com/TileDB-Inc/TileDB">TileDB Embedded</a> storage engine on Github or sign up on <a href="https://tiledb.com/cloud">TileDB Cloud</a>.</p>
<p>--------------------------------------------------------------------------------------</p>
<p><strong>About Two Bear Capital</strong></p>
<p>Two Bear Capital (TBC) was founded and is led by venture capitalist and Montana philanthropist Michael Goguen. With professionals in Whitefish, MT, the San Francisco Bay area and San Diego, CA, TBC invests in early stage companies with disruptive innovations at the intersections of biotech, bioinformatics, machine learning / AI and cybersecurity that could deliver dramatically better solutions to the most critical problems affecting human health, security and wellness. To learn more, visit <a href="http://www.twobearcapital.com/">www.twobearcapital.com</a> and follow TBC on LinkedIn.</p>
<p><strong>About Uncorrelated Ventures</strong></p>
<p><a href="https://uncorrelated.com/">Uncorrelated Ventures</a> was founded by <a href="https://www.baincapitalventures.com/team/salil/">Salil Deshpande</a> in 2020 with Bain’s backing to focus on open source and infrastructure software, both traditional and decentralized. Over 14 years as general partner and managing director at Bay Partners and Bain Capital, Salil invested $350M+ into 50+ companies early, including MuleSoft, DynaTrace, Buddy Media, SpringSource, Redis Labs, SysDig, Jambool, Dropcam, Tealium, Sonatype, Frame, DataStax, Netdata, Quantum Metric, Philz Coffee, Upgrade and DeFi projects Compound and Maker. Salil was on the Forbes Midas List of the 100 best-performing venture investors worldwide in 2013, 2014, 2015, 2016, 2017, 2018, and 2019.</p>
<p><strong><br>
About Nexus Venture Partners</strong></p>
<p>Nexus Venture Partners is a leading early-stage venture capital firm partnering with extraordinary entrepreneurs building product-first companies. With $1.5B under management, Nexus operates as one team across the US and India. The Nexus family includes Aryaka, Biz2Credit, Cloud.com, Clover Health, Delhivery, Druva, Gluster, H2O.ai, Hasura, Headspin, Kaltura, Mezi, Observe.ai, OLX, Paysense, Postman, Pubmatic, Rancher, Snapdeal, Unacademy, Whitehatjr, and Zomato. For more information, visit <a href="http://www.nexusvp.com/">www.nexusvp.com</a>.</p>
<p><strong>About Intel Capital</strong></p>
<p>Intel Capital invests in innovative startups targeting artificial intelligence, autonomous vehicles, datacenter and cloud, 5G, next-generation compute, and a wide range of other disruptive technologies. Since 1991, Intel Capital has invested US$12.9 billion in more than 1,582 companies worldwide, and 692 portfolio companies have gone public or participated in a merger. Intel Capital curates thousands of business development introductions each year between its portfolio companies and the Global 2000. For more information on what makes Intel Capital one of the world’s most powerful venture capital firms, visit www.intelcapital.com or follow @Intelcapital.</p>
<p><strong>About Big Pi Ventures</strong></p>
<p>Big Pi Ventures is a seed-stage fund investing in innovative technology companies connected to Greece and engaged primarily in enterprise/B2B software, materials and life sciences. Big Pi is managed by seasoned investment professionals and successful entrepreneurs that assist companies in attracting highly technical and loyal human capital. Find out more about our fund, portfolio, and career opportunities by visiting <a href="http://www.bigpi.vc/">www.bigpi.vc</a>.</p></div></div></div>]]>
            </description>
            <link>https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896131</guid>
            <pubDate>Mon, 20 Jul 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft@Home]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23895789">thread link</a>) | @networked
<br/>
July 20, 2020 | https://minecraftathome.com/minecrafthome/ | <a href="https://web.archive.org/web/*/https://minecraftathome.com/minecrafthome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p><span>Server outage resolved and supporting our infrastructure</span><br>

        Between 23:54 UTC yesterday (2020-07-20) and 15:35 UTC today, we suffered from a catastrophic SQL failure which forced us to restore from backup.</p><p>

There may be some credit issues where the system granted more or fewer credits than you expect for work done during this time.<br>
I can't apologize enough. If our BOINC deployment was architected for scale rather than for low cost, we could've avoided this.</p><p>

There are several enhancements to our infrastructure and upgrades we'd like to make, such as migrating services to Kubernetes and potentially using a managed SQL service.</p><p>

<span><b><span color="red">You can help!</span> Please consider visiting our Patreon page, reviewing the current set of benefits, and making a contribution of any size; any amount helps - <a href="https://patreon.com/minecraftathome" rel="nofollow">patreon.com/minecraftathome</a></b></span></p><p>

All contributions go towards covering infrastructure cost and quality-of-life improvements to ensure the project's longevity.
        <br>
        <span>21 Jul 2020, 20:10:54 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=44"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>That was fast</span><br>

        The origin of the panorama image used in the Minecraft main menu from beta version 1.8.1, released in September 2011, has remained a mystery until now.</p><p>

<b><span>In less than 24 hours after launching the panorama application; a volunteer host for Minecraft@Home, in a sheer stroke of luck, found the world seed, 25357015387625.</span></b><br>
This was approximately </p><p><span color="red">93 days of processing time at a total of 54.5 exaFLOPs</span> compressed into the last 24 hours.</p><p>

The specific host which located the seed belongs to the user <a href="https://minecraftathome.com/minecrafthome/show_user.php?userid=2558" rel="nofollow">vanos0512</a>.<br>
Thank you to the 137 users who contributed 181 hosts with 231 GPUs over the last 24 hours. You all accomplished this.</p><p>

<img src="https://i.imgur.com/f6lGCEn.png"></p><p>

Here are the details if you want to generate this world for yourself:<br>
<b>Minecraft version:</b> <i>Beta 1.7</i><br>
<b>Either of these two valid world seeds:</b> <i>2151901553968352745 or 8091867987493326313</i><br>
<b>Co-ordinates:</b> <i>x60, y76, z-67</i></p><p>

<a href="https://www.youtube.com/watch?v=caLCZNLPgrM" rel="nofollow">See the video released by EarthComputer announcing the finding.</a>
        <br>
        <span>18 Jul 2020, 15:32:11 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=42"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Enjoy the scenery</span><br>

        <span>Minecraft@Home is now <span color="red">over one month old</span>! To celebrate this milestone, I present a new research focus; the panorama project.</span></p><p>

If you were here during beta-testing, you might have received a very early version of panorama tasks, and the eagle-eyed among you may have seen the application details <a href="https://minecraftathome.com/minecrafthome/server_status.php" rel="nofollow">on the server status page</a>.</p><p>

<span><b>The panorama app is a CUDA-only app for Linux and Windows with an Nvidia driver version of 418.96 or higher.</b></span></p><p>

This project attempts to find the world seed of the iconic panorama image which appeared in the background of the main menu of Minecraft between 2011 and 2018. The first phase of this project will only last a few days, and we shall update you with their progress in the coming weeks.</p><p>

<img src="https://i.imgur.com/3dyexWe.png"></p><p>

Right now, the application is quite substantial. Unlike the OpenCL applications for the Kaktwoos project, <b>if you allow BOINC to run tasks always; you may experience some stuttering or lag in your desktop environment while running these tasks</b>. These tasks do not have checkpointing support, but run in around 1 hour on an average host to mitigate the majority of lost cycles.</p><p>

<span>As always, <a href="https://minecraftathome.com/minecrafthome/prefs.php?subset=project" rel="nofollow">you can change which projects of which you decide to participate in your user preferences</a>.</span></p><p>

Let us know if you have any questions, and as always join the discussion over on <a href="https://discord.gg/xVFh9bp" rel="nofollow">the Discord server.</a>
        <br>
        <span>17 Jul 2020, 15:31:43 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=39"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Kaktwoos 2.03 and Badges!</span><br>

        You may have seen many workunits just disappear from existence today.</p><p>

<img src="https://munin.kiska.pw/munin-cgi/munin-cgi-graph/Munin-Node/Munin-Node/results_minecraftathome-pinpoint=1594193183,1594247603.png?&amp;lower_limit=&amp;upper_limit=&amp;size_x=400&amp;size_y=200"></p><p>

Worry not! We realised there were far too many workunits scanning duplicate seeds, so we've scaled back the original workunits to the correct seed ranges <span><i>(no in-progress results were touched, so none of you should have lost any credit)</i></span>.</p><p>

We have located some promising seed candidates which were missed from processing and can be used as an input to this job, so they are currently set as the highest priority.</p><p>

Also, <span><b>we now have badges</b></span>! If you view the forums, any comments in threads, or on the leaderboards; you will see the new badges.<br>
We're open to suggestions for future badges, so please leave us some comments on this thread.
        <br>
        <span>8 Jul 2020, 21:06:03 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=30"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Profile creation and OpenCL vendor pinning</span><br>

        In the last news post, I advised everyone to create a profile in order to be eligible for 'user of the day' selection.<br>
Unfortunately, there was an issue with the ReCaptcha implementation which prevented this. This issue is now resolved.</p><p>

Now, you are able to <a href="https://minecraftathome.com/minecrafthome/create_profile.php" rel="nofollow">create a profile here</a>.</p><p>

Also, good news for hosts with OpenCL capable hardware from more than one vendor <i>(e.g. an Intel iGPU and an Nvidia GPU)</i><br>
The latest update to the kaktwoos app should ensure the tasks run on the correct device.<br>
If you are a user with a multi-vendor host, please keep an eye on your results and let us know if you're having any issues.</p><p>

As always, please get involved with the conversation in the <a href="https://minecraftathome.com/minecrafthome/forum_index.php" rel="nofollow">message boards</a>, and <a href="https://discord.gg/xVFh9bp" rel="nofollow">join the Discord</a>!
        <br>
        <span>3 Jul 2020, 16:57:49 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=22"> Discuss</a>
        </span></p></div><hr>
    <p><a href="https://minecraftathome.com/minecrafthome/old_news.php">... more</a></p><p><small>
    News is available as an <a href="https://minecraftathome.com/minecrafthome/rss_main.php">RSS feed &nbsp; <img src="https://minecraftathome.com/minecrafthome/img/rss_icon.gif" alt="RSS"></a>
        </small></p></div></div>]]>
            </description>
            <link>https://minecraftathome.com/minecrafthome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895789</guid>
            <pubDate>Mon, 20 Jul 2020 08:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demo of OpenAI's GPT-3 generating tweets given a word]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23895706">thread link</a>) | @hardmaru
<br/>
July 20, 2020 | https://thoughts.sushant-kumar.com/hong%20kong | <a href="https://web.archive.org/web/*/https://thoughts.sushant-kumar.com/hong%20kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
	<blockquote>
		<p><span>“</span>Diplomasms: The mounting suspicion that someone doesnâ€™t like it here; The Objective Hating of Hong Kong.<span>”</span></p>
	</blockquote>

		</div></div>]]>
            </description>
            <link>https://thoughts.sushant-kumar.com/hong%20kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895706</guid>
            <pubDate>Mon, 20 Jul 2020 08:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why GPT-3 Matters]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 153 (<a href="https://news.ycombinator.com/item?id=23895481">thread link</a>) | @teruakohatu
<br/>
July 20, 2020 | https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/ | <a href="https://web.archive.org/web/*/https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <!-- TOC -->
        
        <p><img src="https://leogao.dev/images/gpt3/title.png" alt="Number of Parameters of GPT-3 compared to previous models. (<a href='https://www.willstats.com/'>Edited by WillStats</a>, <a href='https://arxiv.org/abs/1910.01108'>Original 1</a>, <a href='https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/'>Original 2</a>)"></p>
<p><span>The sheer scale of the new GPT-3 model</span> is hard to overstate; it’s an entire <em>order of magnitude</em> larger than Microsoft’s <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">already-massive 17B parameter Turing-NLG</a>.<sup><a href="#fn1" id="fnref1">[1]</a></sup> Loading the entire model’s weights in fp16 would take up an absolutely preposterous 300GB of VRAM, not even including the gradients. But, with massive size comes massive generalization ability: GPT-3 is competitive in many benchmarks <em>without even tuning on the target task</em>. And when I say many, I mean <em>many</em>—the full, 72-page paper contains an extensive evaluation of GPT-3 on many NLP datasets. Through the <a href="https://openai.com/blog/openai-api/" target="_blank" rel="noopener">OpenAI API</a>, a vast array of impressive demos have sprung up taking advantage of the generalization capabilities of GPT-3 to do extremely disparate tasks. Perhaps the most impressive part, though, is that even at such a massive scale, the model still scales smoothly in performance instead of plateauing, implying that still-larger models would perform <em>even better</em>. Throughout the rest of this post, my goal is to distill this massive (in multiple ways) paper down to a digestible size, and shed some light on why it matters.</p>

<p>The following table summarizes some of the largest autoregressive Transformer models of the past few years. I’ve excluded models like <a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet</a> and BERT-derivatives because they don’t have the same unidirectional autoregressive training target.</p>
<table>
<thead>
    <tr><th></th>
    <th>Parameters</th>
    <th>Layers</th>
    <th>Hidden Size</th>
    <th>Attn Heads</th>
    <th>Attn Head Dimension</th>
    <th>Context Length</th>
</tr></thead>
    <tbody><tr>
        <th><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">GPT</a></th>
        <td>0.110B</td>
        <td>12</td>
        <td>768</td>
        <td>12</td>
        <td>64</td>
        <td>512</td>
    </tr>
    <tr>
        <th><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">GPT-2</a></th>
        <td>1.542B</td>
        <td>48</td>
        <td>1600</td>
        <td>25</td>
        <td>64</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM</a></th>
        <td>8.3B</td>
        <td>72</td>
        <td>3072</td>
        <td>32</td>
        <td>96</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a></th>
        <td>17B</td>
        <td>78</td>
        <td>4256</td>
        <td>28</td>
        <td>152</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener">GPT-3</a></th>
        <td>175.0B</td>
        <td>96</td>
        <td>12288</td>
        <td>96</td>
        <td>128</td>
        <td>2048</td>
    </tr>

</tbody></table>
<p>While GPT-3 isn’t that much deeper, its width is nearly <strong>3x</strong> that of <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a>, which—since parameter count scales approximately proportional to the square of the hidden size—explains where most of the extra parameters come from. It also has double the context size, at 2048 tokens, which is impressive (and memory-expensive!), though not the biggest context size across all models; some models have even longer contexts, like <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL</a>, which incorporates longer contexts by passing context vectors between segments, and <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html" target="_blank" rel="noopener">Reformer</a>, which uses locality-sensitive hashing to enable sparser attention. Similarly, GPT-3 uses <a href="https://arxiv.org/abs/1904.10509" target="_blank" rel="noopener">sparse attention layers</a> in every other layer, though the exact details are left somewhat ambiguous. It’s also interesting to note that the smaller GPT-3 versions trained for comparison with GPT-2 are slightly shallower and wider, with GPT-3-XL having only 24 layers but a hidden size of 2048.<sup><a href="#fn2" id="fnref2">[2]</a></sup> GPT-3 also reuses the BPE tokenization of GPT-2. Overall, GPT-3 is essentially just a downright massive version of GPT-2.</p>

<p><img src="https://leogao.dev/images/gpt3/tdata.png" alt="Weighted Training Data (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The training data is a reweighted mix of Common Crawl, WebText2 (a larger version of the original that <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">also includes links sampled in the period of Jan-Oct 2018</a>), two book corpora, and English Wikipedia. Some of these components, such as Wikipedia, were seen more than 3 times during training; others, like the massive Common Crawl component, had less than half of their data seen. The authors claim that this is to help raise the overall quality of the corpus by prioritising known-good datasets. Also, in contrast to the original WebText, this new corpus is not filtered by language, but English still constitutes 93% of the dataset by words simply due to its prevalence. Altogether, the dataset is 500 billion tokens, or 700GB<sup><a href="#fn3" id="fnref3">[3]</a></sup>, after filtering and cleaning. The paper also provides a detailed description of the filtering process of the dataset, which the GPT-2 paper didn’t.</p>
<p>The authors also attempted to remove any data that overlapped with the train and test sets of the evaluations. Unfortunately, due to a bug, some were missed, so to compensate the paper provides a fairly good analysis of the impact of this leakage.</p>

<p><img src="https://leogao.dev/images/gpt3/perf-small.png" alt="Zero-, One-, and Few-shot performance of GPT-3 scaling with parameter count (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The Evaluation section of GPT-3 is very comprehensive, evaluating on a massive battery of NLP tasks in the Zero-shot (given only a natural language description in the generation context), One-shot (a single example in the generation context), or Few-shot (a small handful of examples in the generation context) settings. This setting is worth emphasizing as perhaps one of the biggest differences in ability between GPT-2 and its predecessors, because being able to <em>infer the task</em> from just one or a few examples is a massive step forward in generalization. Whereas previous models all relied on task-specific tuning, GPT-3 can be “tuned” merely by giving it instructions <em>in plain English</em>! In fact, the paper doesn’t even attempt to fine-tune on the target task, leaving that to future work.<sup><a href="#fn4" id="fnref4">[4]</a></sup> However, one crucial conclusion is that in almost all tests, performance continues to get better with larger models, even across 4 entire orders of magnitude, whereas fine-tuning only improves on one task and <a href="https://arxiv.org/pdf/1901.11373.pdf" target="_blank" rel="noopener">risks catastrophic forgetting and overfitting</a>.</p>
<p>Without going too much into the individual tests, the general result is this: on most tasks, GPT-3 achieves performance significantly worse than fine-tuned SOTA (i.e SuperGLUE, CoQA, Winograd, to name a few), but beating fine-tuned SOTA for some other tasks (i.e PhysicalQA, LAMBADA, Penn Tree Bank). GPT-3 does particularly well on PTB in particular, taking the SOTA perplexity from 35.76 down to 20.5—a massive improvement. GPT-3 can also finally do some arithmetic, something GPT-2 was unable to do well.<sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p><img src="https://leogao.dev/images/gpt3/newsgen-small.png" alt="People are unable to separate GPT-3 generated news articles from real ones (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>Impressively, and perhaps somewhat alarmingly, people are unable to distinguish GPT-3 generated news stories from real ones, only exacerbating the ethical concerns already raised by GPT-2. The paper analyzes the result of the release of GPT-2, and concludes that the release of GPT-2 has not led to widespread use of LMs for misinformation due to the difficulty of controlling output and variance in output quality, both among low-to-mid skill adversaries and “advanced persistent threats”—adversaries with “high skill and long-term agendas”—such as state actors. However, the paper also acknowledges that with further development, LMs will eventually become advanced enough for these adversaries.</p>
<p>The authors also investigate gender bias in GPT-3, showing that GPT-3 is male leaning; however, the authors claim that some preliminary evidence on the Winogender dataset (which tests coreference resolution on the same sentence but with different gendered pronoun) seems to suggest that larger models are more robust to bias issues. Similar issues appeared for race and religion, with the sentiment of coöccurrent terms varying significantly with race. The authors claim that this issue also got better with the larger models—although, without proper hypothesis testing, it’s difficult to draw any solid conclusions here.</p>

<p>GPT-3 has already been used for a smorgasbord of different applications through the OpenAI API. You can ask it to <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank" rel="noopener">write</a> <a href="https://twitter.com/hturan/status/1282261783147958272" target="_blank" rel="noopener">code</a>, turn <a href="http://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener">natural language commands into shell commands</a>, and simulate <a href="https://www.aiwriter.email/" target="_blank" rel="noopener">chatting with famous people</a>. You can ask it to <a href="https://twitter.com/QasimMunye/status/1278750809094750211" target="_blank" rel="noopener">answer medical questions</a>, or <a href="https://www.gwern.net/GPT-3#navy-seal-copypasta" target="_blank" rel="noopener">write parodies of the navy seal copypasta</a>. You can ask it to <a href="https://andrewmayneblog.wordpress.com/2020/06/13/openai-api-alchemy-summarization/" target="_blank" rel="noopener">summarize passages for second graders</a>, or <a href="https://www.gwern.net/GPT-3#transformer-poetry" target="_blank" rel="noopener">write poetry</a>.</p>
<p>It’s important to remember all these are done by the <em>exact same model</em> trained <em>only</em> on modelling text; all that’s different is that it has been “asked nicely” to do different things. These apps showcase the versatility of GPT-3 across many disparate domains—something that, if it were done with GPT-2, would require days or even weeks of extensive data engineering and fine tuning, rather than 15 minutes of prompt crafting. This new paradigm of programming through crafting plain-English prompts, jokingly dubbed <a href="https://twitter.com/karpathy/status/1273788774422441984" target="_blank" rel="noopener">“Software 3.0”</a>, has achieved results that are already impressive, but even more impressive when viewed through the lens of <strong>generalization</strong>; GPT-3 wasn’t trained to do any of these things in particular, but it could still be asked<sup><a href="#fn6" id="fnref6">[6]</a></sup> to do them, and fairly well at that!</p>

<p><img src="https://leogao.dev/images/gpt3/perf_scaling_compute.png" alt="Performance continues to scale with compute. (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>But why does GPT-3 matter, if it can’t even beat SOTA across all benchmarks? Why should we care about a model so large that a small computing cluster is necessary even just to run inference at a reasonable speed?</p>
<p>One thing about GPT-3 is that it’s doing reasonably well on tasks it has <em>never even seen</em>, and sometimes tasks not even anticipated by the developers of the model. Additionally, instead of reaching a point of diminishing returns, GPT-3 shows that the trend of larger models performing better continues for at least another order of magnitude, with no signs of stopping. Even though GPT-3 is unwieldy, and even though it still doesn’t quite reach human level performance across the board, GPT-3 shows that it’s <em>possible</em> for a model to someday reach human levels of generalization in NLP—and once the impossible becomes possible, it’s only a matter of time until it becomes practical.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Back when I talked about <a href="https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/">large Transformer language models like GPT-2, CTRL, and Megatron-LM late last year</a>, I touched briefly on the trend of Language Models getting bigger, and covered some of the issues that simply more compute might not fix. My general anticipation was that the model size arms race would soon be at a temporary standstill, with focus being diverted to better decoding strategies for text generation (perhaps via RL-based methods). I most certainly had not expected that OpenAI would be back at it so soon with such a massive model.</p>
<p>This was such a surprise that I dropped everything to read the paper and work on this post, including a more theory-oriented post that I’ve been working on for a few months now. It will probably be finished <span>soon™</span>, after I recover from GPT-3 shock. Stay tuned! <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>It’s likely that this was done for easier model parallelism—bigger matrix multiplications are much easier to parallelize than sequentially-applied layers à la <a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener">GPipe</a>.</p>
<p>This could have other advantages too, though. After <a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener">EfficientNet</a> came out, I independently ran some experiments of the same concepts to Transformer models, and the result was that for the same amount of compute, wider models had a sizeable advantage over deeper ones—which corroborates the choice here to …</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</a></em></p>]]>
            </description>
            <link>https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895481</guid>
            <pubDate>Mon, 20 Jul 2020 07:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23895211">thread link</a>) | @xanthine
<br/>
July 19, 2020 | https://vectorly.io/docs/technology/ | <a href="https://web.archive.org/web/*/https://vectorly.io/docs/technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<p><img src="https://vectorly.io/docs/img/vector-graphics.png" alt="Drawing"></p>

<p>Vectorly is developing a new kind of video compression technology, which uses computer vision and vector graphics to reduce bitrates for video content by an order of magnitude (or more) compared to HEVC, while <strong>improving video</strong> quality. </p>
<p>This would be primarily effective for "vector friendly" video content, which would include animations, screen-casts, many e-learning videos and potentially 3d gaming content. </p>
<p>By leveraging existing vector-graphics rendering capabilities on all devices, this codec wouldn't require end-users, OEMs or browsers to install special software to enable playback of these videos.</p>
<p><strong>We are still in the early phases of developing this technology</strong>.</p>
<p>You can learn more about the technology in our <a href="https://files.vectorly.io/Vectorization+Whitepaper+v06.20.pdf">whitepaper</a></p>
<h2 id="the-core-idea">The Core Idea</h2>
<p>The core insight behind this project was that you could use vector-graphics based animations to simulate "videos" in a way that is indistinguishable from a traditional raster-graphics based video format such as an h264 video stream in an MP4 container.</p>
<h3 id="raster-graphics">Raster Graphics</h3>
<p>Normal videos, like the ones you see on Netflix or YouTube, are just sequences of images which get updated quickly on the screen, to create the illusion of motion. Each image is composed of "pixels" - individual dots of color. Higher resolution means more pixels, better visual quality, and bigger file sizes.</p>
<p><img alt="Pixel-Based" src="https://vectorly.io/docs/img/pixels.png"></p>
<p>Almost all video on the internet is of this format, known as "raster graphics". Video compression algorithms like h264 are just very efficient at using fewer data-points to reconstruct the pixels in any given frame, and at storing only the differences in pixels between frames of a video. </p>
<h3 id="vector-grapics-video">Vector Grapics video</h3>
<p>In contrast, we use a concept called "vector-graphics" to render video. Instead of pixels, we represent everything on the screen using shapes, lines and curves, which can be represented as mathematical equations (vector graphics).</p>
<p><img alt="Vector-Based" src="https://vectorly.io/docs/img/vector2.png"></p>
<p>Using these mathematical equations, we can re-draw any arbitrary shape on the screen - from the letter "T" to Bart Simpson's head. Furthermore, by adding information such as color, position on the screen, and how they move or change shape over time, you can create whole videos - including entire episodes of the Simpsons, with just sequences of mathematical equations.</p>
<h3 id="why-vectorization">Why vectorization?</h3>
<p>The core insight behind this project was that for a certain kind of "vector-friendly" video content, storing the video using vector graphics would be much more efficient than using raster graphics (in some cases, up to 2 orders of magnitude more efficient).</p>
<p>This idea is not substantively different from the idea of Flash based animations about 20 years ago. Why do this now?</p>
<p><strong>No need for a decoder</strong>: Most devices now support SVG, HTML5, WebGL/OpenGL and/or some form of hardware-accelerated vector-graphics rendering. That lets you render vector-graphics content on any device without require end-users, OEMs or browsers to install special software to enable playback of vector-graphics content, and to achieve native-level performance by doing so. App developers would only need to include an appropriate library or SDK in their website or app to enable playback within native or 3rd player video players.</p>
<p><strong>Computer vision</strong>: Our patented vectorization technology relies heavily on computer vision to convert raster-graphics videos to a vector format. Leveraging the advancement &amp; commoditization of Computer Vision, and the ease of running batch computer-vision heavy tasks on the cloud, it's feasible to 'vectorize' large volumes of video at scale now, in a way that wasn't possible even 5 years ago.</p>
<h3 id="vector-graphics-video-format">Vector graphics video format</h3>
<p>We are building a video-format based on existing standards (SVG, WebGL &amp; OpenGL), extending it with Javascript to enable video features such as a timeline and key-frames. We package the resulting video data within an MP4 container, which can be streamed and distributed using existing video infrastructure (such as HLS/DASH, and DRM systems).</p>
<pre><code>&lt;video src="vectorized.mp4" type="video/svg"&gt;
</code></pre>
<p>We are pragmatic, and don't want to create a standard <a href="https://xkcd.com/927/">for the sake of creating a standard</a>.  To that end, we've created libraries and SDKs that enable playback of our vector-graphics videos using standard / native interfaces like so</p>
<pre><code>&lt;script src="vectorly.js"&gt;

&lt;video src="vectorized.mp4" type="video/svg"&gt;
// This will work on all major browsers today
</code></pre>
<h2 id="demos-proof-of-concept">Demos / Proof of concept</h2>
<p><strong>Simpsons</strong></p>
<p>Our first vectorized proof of concept for animations is a 17 second clip of the Simpsons located <a href="https://files.vectorly.io/demo/v0-2-simpsons-250kbps/index.html">here</a>. Keep in mind, our technology is still at a very early stage, and this is much optimization work left to be done.</p>
<p><strong>Khan Academy</strong></p>
<p>Our technology also works very well for e-learning, and especially Khan Academy style content. You can find 30 second Khan Academy clip <a href="https://files.vectorly.io/demo/khan-20kbps/index.html">here</a></p></div></div>]]>
            </description>
            <link>https://vectorly.io/docs/technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895211</guid>
            <pubDate>Mon, 20 Jul 2020 06:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Praise of ZFS on Linux's ZED 'ZFS Event Daemon']]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23894790">thread link</a>) | @zdw
<br/>
July 19, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In praise of ZFS On Linux's ZED 'ZFS Event Daemon'</h2>

	<p><small>July 19, 2020</small></p>
</div><div><p>I've written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However, not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>,
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens, ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what's going on, and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files, you're
free to add your own without colliding with or having to alter the
standard 'ZEDLETs' provided by ZFS on Linux. Your additions can do
anything you want them to, ranging from the simple to the complex.
For instance, our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre>PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep 'ZEVENT_' | sort | fmt -999 |
    logger -p daemon.info -t 'cslab-zevents'
exit 0
</pre>
</blockquote>

<p>(There's a standard 'all-syslog.sh' ZEDLET, but it doesn't syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren't quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out, ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end, so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS, where there was no such simple
system for reacting to things happening in your ZFS pools, ZED was
a breath of fresh air for us. More than anything else, it feels
like how ZFS events should have been handled from the start, so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS, I believe that ZED will
probably eventually show up in FreeBSD (if it isn't already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894790</guid>
            <pubDate>Mon, 20 Jul 2020 05:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Want to Be a Founder]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23894387">thread link</a>) | @kipply
<br/>
July 19, 2020 | https://carolchen.me/blog/founding-bad/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/founding-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>I had a brief run with a startup (literally a month) and was faced with the decision of going into a YC Cohort. In that fiasco, I also spent at least twelve hours trying to convince other people to go. It's been half a year, and I've had a lot more time to reflect on reasons as to why one might want to run a startup. As you might've guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders. </p>
<p>This post definitely will not apply to everyone (I'd loosely say applicable to 80% of prospective startup founders), but I'd hope there's some valuable thinking in here. Also, note that this is fairly oriented towards technical founders. </p>
<p>Edit: This post also has a very limited scope as it's based off the thinking from my decision to continue interning at Shopify or to go to YC. It's very focused on the Silicon Valley "startup" where you get a VC to give you money and get big in a year, etc etc</p>

<h3 id="commitment">Commitment<a href="#commitment" aria-label="Anchor link for: commitment"> <i></i></a>
</h3>
<p>I'm not talking about commitment to your company. I'm talking about commitment to your cofounder (if you have one, which is likely). </p>
<p>Maybe I'm too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that's scary. It should be scary or should at least take a few years for it not to become scary. </p>
<p>Your cofounder is...kind of the same? In a seed-stage it's likely you <em>actually</em> live together, and if you don't, you're likely functionally living together with the amount of work involved. They're responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They're tied to your life goals, your dreams, and your passions.</p>
<p>My impression was that my relationship with my cofounder would be more intense than marriage, and <em>extra</em> bad in the event of failure since there's additional loss (and it's statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren't ready but were fine anyway, but I stand by the statement that it's more intense than marriage and not enough people put care into this. </p>
<h3 id="your-vc-is-not-the-one-at-risk-here">Your VC is Not the One at Risk Here<a href="#your-vc-is-not-the-one-at-risk-here" aria-label="Anchor link for: your-vc-is-not-the-one-at-risk-here"> <i></i></a>
</h3>
<p>I often hear sentiments that resemble "wow these VCs are taking a chance on me I better commit to this!". </p>
<p>VCs are not evil people trying to take advantage of you (actually they might be, but let's assume they're not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you're SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them. </p>
<p>They're not shy about it either, the entire reason they're investing in you is because they think you're more valuable than you cost. 
<img src="https://carolchen.me/blog/img/founding/paul.png" alt=""></p>
<p>Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your "bosses" as you answer to them (though <em>much</em> less than a regular "boss") and to the ones you hope to raise capital from in the future. </p>
<p>It's good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into "I'm going to work on this startup partially in service to these people who believed in me and gave me lots of money". These additional stresses that come from meeting VC expectations and the complications of the dynamics of the relationship can cause various problems.</p>
<h3 id="sense-of-self">Sense of Self<a href="#sense-of-self" aria-label="Anchor link for: sense-of-self"> <i></i></a>
</h3>
<p>This one is the one that got to me most but I can see it being irrelevant to a lot of other people. </p>
<p>Many founders have big egos -- I don't mean they're assholes or overly self-important but they do have very powerful confidence, because that's a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years <em>cough cough</em> Neumann). </p>
<p>My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are <em>good</em> and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could've occurred in my social life. </p>
<p>The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There's nothing wrong with that, but I also think it's exceptionally tragic to come down from that. It's not just dealing with failure and getting back up on your feet, it's losing a part of your identity. </p>
<h3 id="school-is-generally-a-good-idea-for-prospective-dropouts">School is Generally a Good Idea (for prospective dropouts)<a href="#school-is-generally-a-good-idea-for-prospective-dropouts" aria-label="Anchor link for: school-is-generally-a-good-idea-for-prospective-dropouts"> <i></i></a>
</h3>
<p>Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can't be worked around with "I am very smart and can learn fast" and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because it's harder to learn when you're in a rush to release features than if you could take your time on a course project. It's true that founders will learn more than they will in school, but the technical development may not be as strong. My model is that the best schooling experience is better technical education and the best founding experience. </p>

<h3 id="something-to-own">Something to Own<a href="#something-to-own" aria-label="Anchor link for: something-to-own"> <i></i></a>
</h3>
<p>Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client <code>hey.com</code>, Chromebooks, and countless amazing dev tools. </p>
<p>Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time. </p>
<p>The alternative is starting a project on the side. <a href="https://github.com/ziglang/zig">Ziglang</a> was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to "own" something significant without even having to leave your job. Examples includes Julia Evan's <a href="https://jvns.ca/">blog</a> (not actually a work-side-project) and line of zines, Cassidy William's <a href="https://drop.com/buy/drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo">keycap line</a>, Nick Frosst's successful and awesome <a href="https://goodkidofficial.com/">band</a> and many more. I understand that it's not the extent of "oh yeah Google? I built that", but I think the expected value is much higher in creating and owning something that isn't a startup. </p>
<h3 id="getting-rich">Getting Rich<a href="#getting-rich" aria-label="Anchor link for: getting-rich"> <i></i></a>
</h3>
<p>A lot of people claim that startups are less money, but I find for signicant number of founders, that's not true -- not because they'll definitely have a good exit, but because they're skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-founded early-stage startup) is usually higher. </p>
<h3 id="not-being-at-school-for-prospective-dropouts">Not Being at School (for prospective dropouts)<a href="#not-being-at-school-for-prospective-dropouts" aria-label="Anchor link for: not-being-at-school-for-prospective-dropouts"> <i></i></a>
</h3>
<p>This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don't always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself. </p>
<p>A better program can improve many things, such as <a href="http://www.olin.edu/">Olin College of Engineering</a> that has a project-based curriculum, <a href="https://www.makeschool.com/">Make School</a> that is a two year applied-engineering degree program or <a href="https://devdegree.ca/">Dev Degree</a>, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. </p>
<p>Another alternative is to just be worse at school and learn on the side and/or to morph your silly school assignments into productive skills and useful outputs. The <a href="http://coconut-lang.org/">Coconut Programming Language</a> was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have <a href="https://thume.ca/2017/06/17/tree-diffing/">industry applications</a>. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with <a href="https://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/">educational findings for engineers in general</a> (also see <a href="https://news.ycombinator.com/item?id=20192645">HackerNews thread</a>). In five weeks, my friend Maas was able to launch <a href="https://medium.com/@maaslalani/launch-5d02cc5e05f5">five relatively successful products</a> while enrolled in Dev Degree. </p>
<p>School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/founding-bad/">https://carolchen.me/blog/founding-bad/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/founding-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894387</guid>
            <pubDate>Mon, 20 Jul 2020 03:21:12 GMT</pubDate>
        </item>
    </channel>
</rss>
