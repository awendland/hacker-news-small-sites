<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 25 Aug 2020 00:52:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 25 Aug 2020 00:52:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Persisting as a Solo Founder]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to update U-Boot for PostmarketOS on the Pine Phone]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24244407">thread link</a>) | @dustfinger
<br/>
August 22, 2020 | https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/ | <a href="https://web.archive.org/web/*/https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 


<!--endtoc-->

<h2 id="introduction">Introduction</h2>

<p>If you are in a hurry to update U-Boot and the SPL on your PinePhone, then please proceed directly to <a href="#write-u-boot-plus-spl-to-bootable-storage">Write U-Boot+SPL to bootable storage</a>.</p>

<p>In this article, I am going to explain what U-Boot, SoC and the SPL are. After that, I will describe the sunxi bootable storage layout as well as the PinePhone boot procedure, so you will understand what you will be updating and why. Then, I will teach you how to determine if an upgrade is required, and I will explain two different ways of upgrading U-Boot. As a special treat for the curious, I will show you the first steps to reverse engineer the U-Boot+SPL firmware blob. I hope this article peeks your curiosity and encourages you to learn more.</p>

<p>Discussed on <a href="https://news.ycombinator.com/item?id=24244407">Hacker News</a> and <a href="https://forum.pine64.org/showthread.php?tid=11099">Pine64</a>.</p>

<h2 id="what-is-u-boot">What is U-Boot?</h2>

<p>U-Boot, or rather <a href="https://en.wikipedia.org/wiki/Das%5FU-Boot">Das U-Boot</a> a.k.a <em>the Universal Boot Loader</em>, is a small program that is loaded into <em>read-only memory</em> (ROM) and is ultimately responsible for loading the Linux kernel. Designed with flexibility in mind, U-Boot now supports <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/arch">a wide variety of architectures</a> for <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/board">embedded boards</a>, each of which may support multiple boot methods. This article is only concerned with U-Boot as it is configured for the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/board/sunxi/README.sunxi64">Allwinner 64-bit boards</a>, specifically the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>.</p>

<h2 id="what-is-a-soc">What is a SoC?</h2>

<p>No, it does not refer to the stinky fabric covering your feet. <em>SoC</em> stands for <em>System on a Chip</em>. The PinePhone contains the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>, featuring a Quad-Core <a href="https://en.wikipedia.org/wiki/ARM%5FCortex-A53">ARM Cortex-A53 ARMv8-A CPU</a> and an <a href="https://linux-sunxi.org/Mali400">ARM Mali400 MP2 GPU</a>. See the <a href="https://linux-sunxi.org/A64#Documentation">Allwinner A64 documentation</a> for more details.</p>

<h2 id="what-is-the-spl">What is the SPL?</h2>

<p>The <em>Secondary Program Loader’s</em> (SPL) primary function is to load U-Boot proper, the <em>flattened device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>Arm Trusted Firmware</em> (<a href="https://www.trustedfirmware.org/about/">ATF</a>), ultimately passing execution to the ATF. In particular, execution is passed to <em>Trusted Firmware-A</em> (<a href="https://trustedfirmware-a.readthedocs.io/en/latest/index.html">TF-A</a>), which is <a href="https://github.com/ARM-software/arm-trusted-firmware">the official reference implementation</a> used by SoCs with armv8- cores, such as <a href="https://trustedfirmware-a.readthedocs.io/en/latest/plat/allwinner.html">Allwinner Armv8-A SoCs</a>.</p>

<h2 id="what-installs-the-spl">What installs the SPL?</h2>

<p>The SPL is installed via the <code>u-boot-pinephone</code> package from the <a href="http://postmarketos1.brixit.nl/postmarketos/master/aarch64/">postmarketOS aarch64 APK repository</a>. The package is built from the <a href="https://gitlab.com/pine64-org/u-boot/">pine64 u-boot fork</a> in which they added a <a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/.gitlab-ci-pine64.yml">pine64 specific GitLab CI/CD pipeline configuration</a>. By listing the contents of the package using the <a href="https://wiki.alpinelinux.org/wiki/Alpine%5FLinux%5Fpackage%5Fmanagement#apk%5Finfo">apk info</a> command we can see where the SPL binary is actually installed to the root file system.</p>
<div><pre><code data-lang="sh">second-chance:~$ apk info -L u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone-2020.04_git20200421-r1 contains:
usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>However, this is just a convenient location to deliver the binary. The SPL must be deployed to a specific location on disk so that the BootROM can load it.</p>

<h2 id="a-bit-about-bytes">A bit about bytes</h2>

<p>I suspect that not all of those reading this article are familiar with the various standards when it comes to measuring information. Allow me to digress with a brief introduction to these standards with respect to how they both measure and represent a <em>kilobyte</em>. Many of the articles that I have linked herein use the <em><a href="https://en.wikipedia.org/wiki/JEDEC%5Fmemory%5Fstandards#Unit%5Fprefixes%5Ffor%5Fsemiconductor%5Fstorage%5Fcapacity">Joint Electron Device Engineering Council</a></em> (JEDEC) memory standards in which the unit for <em>kilobyte</em> is denoted by (<code>KB</code>), in upper case letters and represents <code>1024B</code>. This is not to be confused with the kilobyte from the <em><a href="https://en.wikipedia.org/wiki/Metric%5Fprefix/">International System of Quantities</a></em> (SI) in which <em>kilo</em> is denoted with a lower case <code>k</code>, such that <code>kB</code> means <code>1000B</code>. My preference is to use the <a href="https://en.wikipedia.org/wiki/Kibibyte">kibibyte</a> (pron. KI-BEE-BYTE), which was established by the <em><a href="https://en.wikipedia.org/wiki/International%5FElectrotechnical%5FCommission">International Electrotechnical commission</a></em> (IEC) and is recognized by all major standards organizations, including those aforementioned.</p>

<table>
<thead>
<tr>
<th>Decimal</th>
<th></th>
<th>Binary</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>Value</td>
<td>Metric</td>
<td>Value</td>
<td>IEC</td>
<td>JEDEC</td>
</tr>

<tr>
<td>1</td>
<td>B byte</td>
<td>1</td>
<td>B byte</td>
<td>B byte</td>
</tr>

<tr>
<td>1000</td>
<td>kB kilobyte</td>
<td>1024</td>
<td>KiB kibibyte</td>
<td>KB kilobyte</td>
</tr>

<tr>
<td>1000^2</td>
<td>MB megabyte</td>
<td>1024^2</td>
<td>MiB mebibyte</td>
<td>MB megabyte</td>
</tr>

<tr>
<td>1000^3</td>
<td>GB gigabyte</td>
<td>1024^3</td>
<td>GiB gibibyte</td>
<td>GB gigabyte</td>
</tr>

<tr>
<td>1000^4</td>
<td>TB terabyte</td>
<td>1024^4</td>
<td>TiB tebibyte</td>
<td>-</td>
</tr>
</tbody>
</table>

<p>The reasoning behind my preference is two fold:</p>

<ol>
<li>The JEDEC <a href="https://www.jedec.org/document%5Fsearch?search%5Fapi%5Fviews%5Ffulltext=JESD100B01">Terms, Definitions, and Letter Symbols for Microcomputers, Microprocessors, and Memory Integrated Circuits</a> only defines the first three higher order prefixes: <em>kilo</em> (K), <em>mega</em> (M), <em>giga</em> (G), referring to them for common usage. The prefix <em>tera</em> was later added to the JEDEC terms dictionary to reflect <a href="https://www.jedec.org/standards-documents/dictionary/terms/mega-m-prefix-units-semiconductor-storage-capacity">common prefix usage for modern semiconductor storage capacity</a>.</li>
<li>IEC prefixes cannot be confused with Metric prefixes.</li>
</ol>

<p>To make matters more confusing, sometimes lowercase <code>k</code> is used to mean 1024, e.g. see <a href="https://man7.org/linux/man-pages/man1/tar.1.html#OPTIONS">tar(1) OPTIONS</a> sub section <code>Size Suffixes</code> located <a href="https://man7.org/linux/man-pages/man1/tar.1.html#RETURN%5FVALUE">above the RETURN VALUE section</a>. Understanding which system of measurement is being used is essential when calculating offsets.</p>

<h2 id="layout-of-sunxi-bootable-storage">Layout of sunxi bootable storage</h2>

<p>The first 40 plus <code>KiB</code> of bootable storage for an Allwinner based board has the <a href="https://linux-sunxi.org/Bootable%5FSD%5Fcard#SD%5FCard%5FLayout">following default layout</a>:</p>

<table>
<thead>
<tr>
<th>Start</th>
<th>Size</th>
<th>Usage</th>
</tr>
</thead>

<tbody>
<tr>
<td>0KiB</td>
<td>8KiB</td>
<td>Reserved for optional MBR or GPT</td>
</tr>

<tr>
<td>8KiB</td>
<td>32KiB</td>
<td>Initial SPL</td>
</tr>

<tr>
<td>40KiB</td>
<td>-</td>
<td>U-Boot Proper</td>
</tr>
</tbody>
</table>

<p>From the layout, one can conclude that upgrading the SPL and U-Boot for the PinePhone must involve writing the <code>u-boot-sunxi-with-spl.bin</code> to bootable storage starting at <code>8192B</code>.</p>

<h2 id="pinephone-boot-procedure">PinePhone boot procedure</h2>

<p>Bootstrapping is complicated by initial memory address space limitations. The <a href="https://linux-sunxi.org/BROM#U-Boot%5FSPL%5Flimitations">SPL is limited to 32 KiB</a>, most likely because the BootROM, or BROM, loads the SPL into <a href="https://linux-sunxi.org/A64/Memory%5Fmap">SRAM A1</a>, which is a <code>32 KiB</code> subsection. If the SPL is larger than <code>32 KiB</code> the BROM will refuse to load it. After the SPL loads U-Boot proper and passes execution to the ATF, U-Boot proper in turn runs <a href="https://gitlab.com/postmarketOS/pmaports/-/blob/master/device/community/device-pine64-pinephone/uboot-script.cmd">the Pine Phone’s u-boot command script</a>. The command script sets the default bootargs for init and calls the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/cmd/booti.c">booti command</a>, which boots the Linux Kernel Image from memory given the <em>flattend device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>initial ramdisk</em> (<a href="https://en.wikipedia.org/wiki/Initrd">initrd</a>), ultimately passing execution to Linux init.</p>



<div>
  
<div><pre><code data-lang="text">+-----------------------+
|        BootROM        |
+-----------.-----------+
|
|
+-----------V-----------+
|     u-boot.itb+SPL    |
+-----------.-----------+
|
|
+-----------V-----------+
|       TF-A BL31       |
+-----------.-----------+
|
|
+-----------V-----------+
| U-Boot Proper (=BL33) |
+-----------.-----------+
|
|
+-----------V-----------+
|        Linux          |
+-----------------------+</code></pre></div>
</div>

<p>You might have noticed that <code>/usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code> is much larger than <code>32KiB</code>.</p>
<div><pre><code data-lang="text">second-chance:~$ ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin
-rw-r--r--    1 root     root      486.0K Jun 20 12:41 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>That is because the SPL binary image includes a <em>Flattened uImage Tree</em> (<a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/doc/uImage.FIT/source%5Ffile%5Fformat.txt">FIT image</a>) named <code>u-boot.itb</code> that contains the rest of the firmware.</p>

<h2 id="determine-which-bootable-storage-device-is-relevant">Determine which bootable storage device is relevant</h2>

<p>Before you can <a href="#how-to-determine-if-u-boot-needs-to-be-upgraded">determine if U-Boot needs to be upgraded</a>, you need to know which storage device your PinePhone is booting from. This can be easily determined by using the <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> command to list the running operating system’s current mount points. Below is the output of <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> run on my PinePhone booted from an <code>SD</code> card:</p>
<div><pre><code data-lang="sh">second-chance:~$ lsblk --output NAME,TYPE,MOUNTPOINT</code></pre></div><div><pre><code data-lang="text">NAME         TYPE MOUNTPOINT
mmcblk0      disk
├─mmcblk0p1  part /boot
└─mmcblk0p2  part
mmcblk2      disk
├─mmcblk2p1  part
├─mmcblk2p2  part
├─mmcblk2p1  part
└─mmcblk2p2  part
mmcblk2boot0 disk
mmcblk2boot1 disk</code></pre></div>
<p>The disk corresponding to the <code>/boot</code> mountpoint is the name of the block special device that postmarketOS is currently running form. The device path to the relevant boot storage device is therefore <code>/dev/mmcblk0</code>. We will be using this device name in the next two sections to determine if an upgrade is needed and again to perform the actual upgrade if warranted. You must be careful to use the device name that is relevant to your own running environment if you are following along.</p>

<h2 id="how-to-determine-if-u-boot-needs-to-be-upgraded">How to determine if U-Boot needs to be upgraded?</h2>

<p>You can determine if an upgrade is necessary simply by comparing the version of U-Boot installed by the <code>u-boot-pinephone</code> package with the version of U-Boot that is written to <a href="#determine-which-bootable-storage-device-is-relevant">the bootable storage device which is relevant to your running environment</a>.</p>

<p>To see which version of <code>U-Boot</code> was installed by the <code>u-boot-pinephone</code> package, simply run the <code>apk policy</code> sub command as shown below:</p>
<div><pre><code data-lang="sh">second-chance:~/$ apk policy u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone policy:
  2020.04_git20200421-r1:
    lib/apk/db/installed
    etc/apk/cache
    http://postmarketos1.brixit.nl/postmarketos/master</code></pre></div>
<p>Alternatively, you can use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>strings</code> command to search the binary’s printable strings for the regex pattern <code>U-Boot [[:digit:]]</code> by piping the output through a <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>grep</code> filter. As a side note, the PinePhone uses busybox, so when you find yourself looking up command line documentation with the intention of running the command from a PinePhone shell, always check the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> man pages first.</p>
<div><pre><code data-lang="sh">second-chance:~/packages$ strings /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin | grep -E <span>'U-Boot [[:digit:]]'</span></code></pre></div><div><pre><code data-lang="text">U-Boot 2020.04 (Jun 20 2020 - 12:41:48 +0000)</code></pre></div>
<p>Similarly, to determine the version of U-Boot that is currently written to bootable storage, you can search for the same regex pattern in the printable strings of the boot disk after the first <code>8 KiB</code>. However, since the bootable storage is significantly larger than <code>u-boot-sunxi-with-spl.bin</code>, it would not be efficient to use the <code>strings</code> command as we did previously. Instead, we will use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>dd</code> command, which will allow us to control where to begin and end the search. Since we can’t easily know the exact offset of the version string, which can very from build to build, my strategy has been to simply skip the first <code>8 KiB</code> and then read the same number of <code>KiB</code> as the size of the currently installed <code>u-boot-sunxi-with-spl.bin</code>. If my search turns up nothing, then that means that the previously installed version was larger, and I can simply increase the <code>count</code> to some reasonable number of <code>KiB</code> until I find what I am looking for.</p>

<p>First, let’s determine the size of <code>u-boot-sunxi-with-spl.bin</code>.</p>
<div><pre><code data-lang="sh">ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div><div><pre><code data-lang="text">-rw-r--r--    1 root     root      543.3K Jul 18  2020 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>The binary installed to disk is about <code>5…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</a></em></p>]]>
            </description>
            <link>https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244407</guid>
            <pubDate>Sat, 22 Aug 2020 14:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools around workflows, not workflows around tools]]>
            </title>
            <description>
<![CDATA[
Score 435 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24244329">thread link</a>) | @thesephist
<br/>
August 22, 2020 | https://thesephist.com/posts/tools/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><em>This March, I spent a couple of days traveling through western Iceland.</em></p>
<p><img src="https://thesephist.com/img/iceland.jpg" alt="Iceland, part 1"></p>
<p>While I was there, I thought a lot about tools – mechanical tools, software tools, tools that last, and tools that are fragile. The somber snow-covered scenery made me think about how quickly most of the tools we use today get outdated or replaced, and I thought about the kinds of tools that I’ve been building for myself for the last few years to help organize my life.</p>
<p>I took a walk around <em>Smábátahöfnin í Keflavík</em> (a small marina nearby) that night, unraveled myself into my hotel room, and started writing this post.</p>
<p>I want to share why I build my own tools and how I think we should think about building tools for life. It’s long, so here’s a roadmap. Feel free to jump around.</p>
<ol>
<li><a href="#my-tools-today">My tools, today</a></li>
<li><a href="#workflows--tools">Workflows &gt; tools</a>
<ol>
<li><a href="#tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</a></li>
<li><a href="#tools-that-grow-with-your-workflows">Tools that grow with your workflows</a></li>
</ol>
</li>
<li><a href="#own-your-load-bearing-tools-of-life">Own your load-bearing tools of life</a></li>
<li><a href="#cost-and-other-smaller-benefits">Cost and other smaller benefits</a></li>
<li><a href="#your-tools-are-an-extension-of-you">Your tools are an extension of you</a></li>
<li><a href="#appendix-the-technical-nitty-gritty">Appendix: the technical nitty-gritty</a></li>
</ol>
<hr>

<p>For the last few years, I’ve been on a journey to replace all of the essential digital tools I use for organizing my life with tools I develop, maintain, and deploy myself.</p>
<p>What started with a single-page notes app I made in high school has grown into a constellation of home-grown productivity tools I now rely on for my day-to-day work and learning. Here’s a sample.</p>
<ul>
<li>
<p><a href="https://github.com/thesephist/polyx#ligature">Ligature</a>, for long-term notes and tasks, goals, brainstorming, project planning, and other important writing.</p>
<p><img src="https://thesephist.com/img/ligature.jpg" alt="Ligature"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/pico">Pico</a>, for more ephemeral notes and tasks that change on a daily basis. I split up my notes into two apps (Ligature and Pico) because it works better for my workflow. (More on this later.)</p>
<p><img src="https://thesephist.com/img/pico.jpg" alt="Pico"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/mira">Mira</a> for keeping track of people I know, why they’re interesting, and what we’ve talked about.</p>
<p><img src="https://thesephist.com/img/mira.png" alt="Mira"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/lovecroft">Lovecroft</a> for managing and sending emails to my <a href="https://thesephist.com/#newsletter">mailing lists</a>.</p>
<p><img src="https://thesephist.com/img/lovecroft.jpg" alt="Lovecroft"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Noct</a> for backing up and syncing all my files across computers and the cloud. Noct doesn’t have a graphical UI, just a command-line tool.</p>
</li>
<li>
<p><a href="https://thesephist.com/posts/frieden/">Frieden</a> as a public availability calendar, showing when I’m free or busy.</p>
<p><img src="https://thesephist.com/img/frieden.png" alt="Frieden"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/thingboard">Thingboard</a> for more free-form Post-its-on-the-wall style brainstorming.</p>
<p><img src="https://thesephist.com/img/thingboard.jpg" alt="Thingboard"></p>
</li>
<li>
<p><a href="https://codeframe.co/">Codeframe</a> for spinning off simple JavaScript experiments like <a href="https://thesephist.com/posts/word-experiments/#word-plotter">the word plotter</a>.</p>
<p><img src="https://thesephist.com/img/codeframe.jpg" alt="Codeframe"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/draw">draw</a>, a collaborative whiteboard, best used with my iPad Pro and Apple Pencil.</p>
<p><img src="https://thesephist.com/img/draw.jpg" alt="Draw"></p>
</li>
</ul>
<p>Taken together, these apps do almost everything I need to do on my computer to keep myself organized. I don’t use any third-party notes, task management, or contacts apps, though I used to be a big fan of Simplenote and Todoist. I’ve used Notion, Dropbox Paper, Google Docs, and Airtable, but only for working in teams that centralized on them. These days, besides email and calendar, I live within a system of my own tools, and it works well for me.</p>
<p>I don’t want to imply that my tools are objectively better than the professional tools on the market like Notion and Dropbox. Those latter services have more features, and might even be more reliable today. But I think my tools fit me better for a different reason.</p>

<p>Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.</p>
<p>The Eureka moment that some of us feel when we finally find a notes app or todo system that fits our brains – that epiphany happens when the tools we use mirror the way our minds work, and how we want to move information through our lives. Good tools fit perfectly around our workflows, bad tools don’t.</p>
<p>When we resort to having other people build tools for us, the tools they build might never quite perfectly fit our workflows, because they’re not built for our individual minds. When other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways. The result is that mass-market productivity tools don’t fit the way our individual minds are predisposed to work. Instead, to use these tools, we need to bend our workflows to fit around the tools.</p>
<p>My biggest benefit from writing my own tool set is that <strong>I can build the tools that exactly conform to my workflows, rather than constructing my workflows around the tools available to me.</strong> This means the tools can truly be an extension of the way my brain thinks and organizes information about the world around me. My tools aren’t perfect yet, but as they grow and evolve, they’ll only become better reflections of my personal mental models.</p>
<p>For example, one place where my mind works differently than the tools on the market is the task/notes distinction.</p>
<h3 id="tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</h3>
<p>My workflow used to differentiate between tasks and notes. Tasks were action items that I could reference, take action on, and complete, and then erase from my list. Notes were things that were indefinitely relevant. I would take notes and then come back to reference them many times. A note by itself isn’t actionable.</p>
<p>But once I started building my own tools, I realized this distinction isn’t really the way my brain worked. For me, a huge grey area exists between actionable, completable tasks and purely encyclopedic notes. Here are some things that fall in the grey area for me, pulled from my real, actual notes I took this week.</p>
<ol>
<li>I recently learned some really useful tips about how to grow leaders within a community from the book <em><a href="https://gettogetherbook.com/">Get Together</a></em>. I definitely want to act on these learnings at some point in the communities I lead, but I don’t want them cluttering up my todo list because they’re not things I can just complete and check off quickly. I also want to remember these tips forever, even after the first time I act on them.</li>
<li>I’ve been brainstorming an idea for a side project related to <a href="https://en.wikipedia.org/wiki/Computer_algebra">symbolic mathematics</a>. I’ve been writing down my inspirations related to this project. I don’t want to tuck it away in my notes, because this is something I want to build soon, but I also don’t want to shove paragraphs of notes into a todo list item.</li>
<li>I keep a running list of ideas I have for future blog posts, but I don’t really have a “write the next blog post” task item under which I’d normally put these ideas, because I don’t write on schedule – I just write when I can. Where should these ideas go? They’re sort-of notes and sort-of tasks.</li>
</ol>
<p>You might think that these are either very clearly todo items or very clearly notes, and that’s ok. But I certainly felt differently, and I realized I was only separating things into these two buckets because my tools forced me to. Before I wrote my own tools, I had a todo app (Todoist) and I had a notes app (Simplenote), and there was nothing in between.</p>
<p>Eventually, I discovered a better mental model for my working style: I ask myself <em>how immediately</em> I need to take action on something.</p>
<p>The way that I see it, everything I learn and jot down is something for me to act on at some point in my life. If I read something that I never thought would influence the way I lived, it wouldn’t have value to me, and I simply wouldn’t write it down. Armed with this insight, these days, I have two different notes apps, and I don’t use a todo list app. These two apps are Ligature and Pico, mentioned above.</p>
<p>One is for notes that are changing often. Day-to-day tasks, things to remember for the next week, even long notes and links related to what I’m working on <em>now</em>. The other app is for notes that grow over time, like notes I take while reading books or watching talks, my annual goals, financial planning, reading list, and project outlines. <strong>My two notes apps mirror the way my brain works best – one is my short-term, working memory, the other is my long-term memory.</strong></p>
<p>I’ve had this system for a few months now, and haven’t felt any need for something better. It doesn’t have the crazy features of some notes services on the market today, but it just works the way my brain does.</p>
<p>But what if I need something different later on in life?</p>
<h3 id="tools-that-grow-with-your-workflows">Tools that grow with your workflows</h3>
<p>The other benefit of building homebrew tools is that <strong>tools you build yourself can grow and change as your workflow changes over time</strong>. So if my needs do change over time, my tools can grow to accommodate exactly what I need.</p>
<p>When I first started keeping more organized notes on the interesting people I met, I started with a document in my notes app. Over time, I noticed that these notes followed a pattern: I wrote down their name and primary contact info, how I first met them, what school they went to, and what we talked about the last time we spoke.</p>
<p>So when I built Mira, my own people-manager app, I designed it around that exact workflow I had developed. When I later realized I was also recording people’s Twitter usernames in the description field, I just added a Twitter username field to each contact.</p>
<p>This is typical of the way I <em>discover</em> my workflows. <strong>I start with a minimal, bare-bones solution, and try to pick up on patterns and tricks I create for myself. And then I encode those patterns and tricks into the tools over time.</strong></p>
<p>This way, my tools can grow organically as my workflows evolve. Neither of them gets in the way of each other most of the time, and I think that was hard to appreciate before I started relying wholly on my own tools.</p>

<p>My productivity tools, especially my notes and contacts, are the load-bearing tools of my life. If they break or disappear, it’ll take a long time and a lot of effort for me to rebuild those same workflows and tools, so it’s important that they’re reliable, and that I can depend on them working for me for a long time (measured in years and decades, not quarters).</p>
<p>I’ve written at length about <a href="https://thesephist.com/posts/ownership/">the importance of ownership</a> before. I want to own the pieces of my life that are most critical, and I want agency over how these tools change over time.</p>
<p>I want these notes and ideas and workflows to stick with me as I grow as a person through the next decades. If I had to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/tools/">https://thesephist.com/posts/tools/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244329</guid>
            <pubDate>Sat, 22 Aug 2020 14:23:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AngelCAD: Script-based 3D solid modeller]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24243077">thread link</a>) | @app4soft
<br/>
August 22, 2020 | https://arnholm.github.io/angelcad-docs/ | <a href="https://web.archive.org/web/*/https://arnholm.github.io/angelcad-docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>AngelCAD - user documentation</p>

        
        <p><a href="https://github.com/arnholm/angelcad-docs">View the Project on GitHub <small>arnholm/angelcad-docs</small></a></p>
        

        

        
      </header>
      <section>

      <p><strong>AngelCAD - script based 3D solid modeller</strong></p>

<p>AngelCAD is a powerful open source 3D solid modeller based on the Constructive Solid Geometry (<a href="https://en.wikipedia.org/wiki/Constructive_solid_geometry">CSG</a>) modelling technique, expressed in the <a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html">AngelScript</a> language. The software creates 3D models in STL or other file formats.</p>



<p>The csg_wikipedia.as sample</p>

<table>
  <thead>
    <tr>
      <th>AngelCAD resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html" target="_blank">AngelScript language</a></td>
      <td>AngelScript language reference</td>
    </tr>
    <tr>
      <td><a href="https://arnholm.github.io/angelcad-docs/docs/annotated.html" target="_blank">AngelCAD language extension</a></td>
      <td>Language extension for 3d modelling</td>
    </tr>
    <tr>
      <td><a href="https://forum.abmesh.com/" target="_blank">AngelCAD user forum</a></td>
      <td>Discuss AngelCAD topics</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad-samples" target="_blank">angelcad-samples</a></td>
      <td>Examples repository - GitHub</td>
    </tr>
    <tr>
      <td><a href="https://youtu.be/h-qDzG9bwnQ" target="_blank">Video</a></td>
      <td>script based 3D solid modeller</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad/releases" target="_blank">Downloads</a></td>
      <td>Prebuilt binaries - Windows and Linux</td>
    </tr>
  </tbody>
</table>

<p>(links above open in new tabs)</p>

<p><strong>AngelCAD IDE and Viewer</strong> - With the desktop IDE you edit/run the scripts and launch the 3d Viewer</p>

<p><img src="https://arnholm.github.io/angelcad-docs/images/angelcad_ide.png" alt="AngelCAD modeller"></p>

<p><strong>Technology</strong> - AngelCAD uses <a href="https://github.com/arnholm/xcsg" target="_blank">xcsg</a> for 3d computations. xcsg is based on the <a href="https://github.com/arnholm/carve" target="_blank">carve library</a> by Tobias Sargeant. Also used is <a href="http://angusj.com/delphi/clipper.php">Clipper</a> by Angus Johnson, qhull by C.B. Barber and libtess2 by Mikko Mononen.</p>

<p>The AngelCAD language interpreter - as_csg - is based on the <a href="http://www.angelcode.com/angelscript/" target="_blank">AngelScript language</a> by Andreas Jönsson, as_csg extends the language with 3d modelling primitives and operations for constructive solid geometry.</p>

<p>The AngelCAD IDE and Viewer applications use the <a href="https://wxwidgets.org/" target="_blank">wxWidgets cross-platform GUI library</a> to create native GUI for Windows and Linux.</p>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://arnholm.github.io/angelcad-docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243077</guid>
            <pubDate>Sat, 22 Aug 2020 10:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stef's Free Online Smalltalk Books]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24241561">thread link</a>) | @triyambakam
<br/>
August 21, 2020 | http://stephane.ducasse.free.fr/FreeBooks.html | <a href="https://web.archive.org/web/*/http://stephane.ducasse.free.fr/FreeBooks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
	   I started to be fed up to see all the books I like to be out of print, so I started to contact authors and 
	   collect their old books. I would like to thanks them all and their publishers as well. If you
       know an author that is willing to give to the community a book, please give
       him my email. You can support me. </p><p> Thanks in advance. 




</p><p>
You can find a lot more recent and free books at <a href="http://books.pharo.org/">http://books.pharo.org</a>: Spec, Pharo by Example Updated, Pharo with Style, Learning OOD with TDD, and many more. 
In addition most the new books around Pharo are hosted at <a href="http://github.com/SquareBracketAssociates">http://github.com/SquareBracketAssociates</a> and each project has an automatic build with the latest PDF version.


</p><p>
If you have more books and you want to get them archived and listed here please contact me.

</p><div width="95%" height="174">

	<tbody><tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/DynamicWebDevInSeaside/DynWebDevInSeaside.png" width="100"></td>
	    <td>
	      <p><a href="http://book.seaside.st/">[ Dynamic Web Development with Seaside ]</a> Stephane Ducasse, Lukas Renggli, David C. Shaffer and Rick Zaccone. Square Bracket Associates, 2009.</p>
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>
	

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PBE/PharoByExample.png" width="100"></td>
	    <td>
	      <p><a href="http://books.pharo.org/">[ Pharo by Example (original version and translation) ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz, Damien Pollet with Damien Cassou and Marcus Denker. Square Bracket Associates, 2009.</p> Pay attention there is also Pharo by Example Updated (for Pharo 50) and we are working on Pharo by Example for Pharo 80.
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/GNU.png" width="100"></td>
	    <td>
	     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/computer_programming_using_gnu_smalltalk.pdf">[ Computer Programming using GNU Smalltalk ]</a> Canol Gokel, free e-book. 2009. 
	   <a href="http://www.canol.info/books/computer_programming_using_gnu_smalltalk">home page of the book to have an up to date version</a>.
		</p> 
	    </td>
	  </tr> 


  	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SBE/sbe.png" width="100"></td>
	    <td>
	      <p><a href="https://hal.inria.fr/inria-00441576/document">[ Squeak by Example ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz and Damien Pollet. Square Bracket Associates, 2007.</p> Watch out this book is old. Better read <a href="http://books.pharo.org/">Pharo by Example book</a>.
	    </td>
	  </tr>
	
	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion/coversm.gif" width="100"></td>
	    <td>
	      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion">[ Smalltalk design pattern companion book drafts ]</a> Sherman Alpert, Kyle Brown, and Bobby Woolf. Addison-Wesley,  978-02011846241998.</p>
		The chapters listed here are not in their final form but more in draft form. Buy the book it is really excellent. 
	    </td>
	  </tr>
	
	
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/byExample.gif" width="100"></td>
    <td> 
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/">[ Smalltalk by
      Example: the Developer's Guide ]</a> Alex Sharp, McGraw Hill Text; ISBN:
      0079130364, 1997.</p>
      This book covers all kinds of issues basic level, design, testing... I
      liked it a lot. The code and the book as a single file containing everything are available. Thank again
      Lukas Renggli for his effort for converting everything from Word.
       Thanks a lot Alec and thanks McGraw-Hill <a href="http://books.mcgraw-hill.com/">http://books.mcgraw-hill.com/</a>
  They were really nice with us so think about it if you hesitate to buy
  one of their books. Not all the publishers are that open-minded. 
  </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/WithStyle.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/SmalltalkWithStyle.pdf">[ Smalltalk With Style ]</a> by Edward Klimas, Suzanne Skublics and David A. Thomas. 
		ISBN: 0-13-165549-3, Publisher: Prentice Hall, Copyright: 1996. A great and 
		small book that everybody should read. Thanks Ed, Suzanne and Dave to give it for free. 
		Thanks Don for the OCR!
	   </p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV1.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalk.pdf">[ Inside Smalltalk 
       (Volume One) ]</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1.
       Thanks Don for the OCR! 
	   </p>
    </td>
  </tr>
  
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV2.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkII.pdf">[ Inside Smalltalk (Volume Two)],</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1. Thanks Don for the OCR! </p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/littleST.jpeg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/ALittleSmalltalk.pdf">[ A Little Smalltalk ] </a> by Tim Budd, Addison-Wesley 1987.  
      <br>Many thanks to Tim Budd and his  publisher. Please have a look at <a href="http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html">http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html</a>. Thanks Don for the OCR!.
		</p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Art/Art.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Art/artAdded174186187Final.pdf">[ The Art and Science of Smalltalk ]</a>  by Simon Lewis, Prentice-Hall 1995-1999.  
      <br>Many thanks to the original publishers of this book Prentice-Hall, the responsible of the HP series and Simon Lewis.</p>
    </td>
  </tr>
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/practical.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/PracticalSmalltalk.pdf">[ Practical Smalltalk: Using Smalltalk/V ]</a>  by Dan Shafer and Dean A. Ritz, Springer Verlag; (July 1991).  
      <br>Many thanks to the original publishers of this book Springer Verlag,  and Dan. Thanks</p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.pdf">[ Smalltalk An Introduction to Application Development using VisualWorks ]</a> Trevor Hopkins and Bernard Horan,  Pearson Education, 1995. The answers of the exercises are at ftp://st.cs.uiuc.edu/pub/Smalltalk/books/Book_Answers.tar.gz
      <br>Many thanks to the original publishers of this book,  Pearson Education,  for permission to distribute this work, and of course the authors! </p>
    </td>
  </tr>

<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/st-and-oo.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/Smalltalk-and-OO.pdf"> [ Smalltalk and Object Orientation: an Introduction ] </a> Springer-Verlag, ISBN 3-540-76115-2, 1997.
</p>
      <br>This book provides a good survey of Smalltalk. Some information are now obsolete 
      but it is still worth reading. Enjoy it. Thanks John to support our request. We want to thank Springer Verlag Publishing
    for allowing us to give you this book for free.
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/SmalltalkVTutorial.pdf"> [ Smalltalk V Tutorial ]</a>
	   </p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/taste.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/"> [ The Taste of Smalltalk ] </a> Ted Kaehler and Dave Patterson, W W Norton Co.; ISBN: 0393955052; (May 1986).</p>
      This book is for collectors. The quotes are really excellent. 
      <br>All the chapters are ready (except chap.2 for now)
    Enjoy it. (Scanned ... by Stef, Alex, Gabriela, and Lukas).
    Thanks Ted.
    </td>
  </tr>

 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Joy/">[ The Joy Of Smalltalk ]</a> Ivan
    Tomek (September 2000). 700 pages</p>
    Ivan wrote this book and he gave it to the community. It contains a lot of useful material. 
    Thanks again ivan and continue to write good books. 
    </td>
  </tr>
  
  
  
   <!--<tr>
    <td width="45%"><img src="FreeBooks/SmalltalkObjectAndDesign/SmalltalkObjectAndDesign.jpg" width=100></td>
    <td width="55%">
      <p><a href="http://books.iuniverse.com/viewbooks.asp?isbn=1583484906&page=fm1">Smalltalk,objects and design</a>
	  Liu, iUniverse books</p>
      
	  </font>
    </td>
  </tr>-->
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/BitsOfHistory.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/"> [ Smalltalk-80, Bits of History, Words of Advice] </a> By Glen Krasner, Editor
ISBN 0-201-11669-3. 344 pp. 1983</p>
      This book is for collectors. Thanks Glenn.
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/blueBook.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/">[ Smalltalk-80: The Language and its Implementation ]</a>
	By Adele Goldberg and DavidRobson; 		Xerox Palo Alto Research Center
	ISBN 0-201-11371-6. 344 pp. 1983</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.pdf">[ Smalltalk-80, The Interactive Programming Environment ]</a> By Adele Goldberg 
ISBN  0201113724. 560 pp. 1983</p> This book is for collectors. Thanks Adele. Thanks Don for the OCR!
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/small-bluebook-cover.jpg" width="100"></td>
    <td>
    <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/">[ DRAFTS of Squeak, Open Personal Computing and Multimedia ]</a> Mirror of <a href="http://coweb.cc.gatech.edu/squeakbook/">http://coweb.cc.gatech.edu/squeakbook/</a> Edited by Mark Guzdial and Kim Rose. Prentice-Hall 2000.  It's available from Prentice-Hall.  </p>
    <br>
    </td>
  </tr>
  
  
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/mark1.jpg" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/">[ DRAFS of Squeak: Open Personal Computing for Multimedia ]</a>
	 taken from <a href="http://www.cc.gatech.edu/~mark.guzdial/drafts/">http://www.cc.gatech.edu/~mark.guzdial/drafts/</a> 
	 Mark Guzdial, Prentice-Hall 2000. It's available from Prentice-Hall. </p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/BuchLogo.png" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/Syntax.zip">[ (In German) Syntaxbasierte
      Programmierwerkzeuge ]</a> L. Schmitz, B.G. Teubner Stuttgart 1995.  
        1996.</p>
      <p>This book presents compilation techniques in german.
	 Lothar Schmitz is still developing a free visual compiler-compiler
	 (SIC and JACCIE).  <!-- <a
	 href="http://ist.unibw-muenchen.de/Research/Tools/SIC">http://ist.unibw-muenchen.de/Research/Tools/SIC</a> 
<a href="http://ist.unibw-muenchen.de/Research/Tools/JACCIE">http://ist.unibw-muenchen.de/Research/Tools/JACCIE</a> 
-->

</p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/emptyCover.gif" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/smalltalkBuch.pdf">[ (In German) Smalltalk
      Einfuehrung in die objekt-orientierte Programmierung ]</a> Peter P. Bothner, Wolf-Michael Kaehler 1999.  
        1996.</p>
      <p>This book presents object-oriented programming in german with VisualWorks.  
<!-- <a href="http://e-books.zfn.uni-bremen.de/e-book-SMALLTALK.html</a>  
-->

</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Swedish/">[  (In Swedish) Objektorienterad programmering i Smalltalk ]</a>
	  Bjoern Eiderbaeck, Per Haegglund, and Olle Baelter</p>
      <br>Thanks Bjoern Eiderbaeck.
	  
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/Programando.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/ProgramandoConSmalltalk-BORRADORFINAL07-Febrero-2006.pdf">[ (In Spanish) Programando con Smalltalk ]</a>
	  Diego Gomez Deck</p>
      <br>Thanks Diego. This book is distributed under the Creative Commons license.
	  
    </td>
  </tr>
  
</tbody></div><p>
 I added some other material because they illustrate the philosophy behind Smalltalk.

 </p></div>]]>
            </description>
            <link>http://stephane.ducasse.free.fr/FreeBooks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241561</guid>
            <pubDate>Sat, 22 Aug 2020 04:33:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debian Janitor: 60k Lintian Issues Automatically Fixed]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24241549">thread link</a>) | @zdw
<br/>
August 21, 2020 | https://www.jelmer.uk/janitor-update-3.html | <a href="https://web.archive.org/web/*/https://www.jelmer.uk/janitor-update-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div>
        <div>
            <section>
                
            </section>
            <p>The <a href="https://jelmer.uk/debian-janitor.html">Debian Janitor</a> is an automated
system that commits fixes for (minor) issues in Debian packages that can be
fixed by software. It gradually started proposing merges in early
December. The first set of changes sent out ran <a href="https://salsa.debian.org/jelmer/lintian-brush">lintian-brush</a> on sid packages maintained in
Git. This post is part of <a href="https://jelmer.uk/tag/janitor-update.html">a series</a> about the progress of the
Janitor.</p>
<div id="scheduling-lintian-fixes">
<h2>Scheduling Lintian Fixes</h2>
<p>To determine which packages to process, the  <a href="https://janitor.debian.net/">Janitor</a>  looks at the import of  <a href="https://lintian.debian.org/">lintian</a>  output across the archive that is available
in  <a href="https://wiki.debian.org/UltimateDebianDatabase/">UDD</a> <a href="#f1" id="id1">[1]</a>. It
will prioritize those packages with the most and more severe issues that it has
fixers for.</p>
<p>Once a package is selected, it will clone the packaging repository and run
<a href="https://manpages.debian.org/testing/lintian-brush/lintian-brush.1.en.html">lintian-brush</a>
on it.  Lintian-brush provides a framework for applying a set of “fixers” to a
package. It will run each of a set of “fixers” in a pristine version of the
repository, and handles most of the heavy lifting.</p>
</div>
<div id="the-inner-workings-of-a-fixer">
<h2>The Inner Workings of a Fixer</h2>
<p>Each fixer is just an executable which gets run in a clean
checkout of the package, and can make changes there. Most
of the fixers are written in Python or shell, but they
can be in any language.</p>
<p>The contract for fixers is pretty simple:</p>
<ul>
<li>If the fixer exits with non-zero, the changes are reverted and fixer is
considered to have failed</li>
<li>If exits with zero and made changes, then it should write a summary of its
changes to standard out</li>
</ul>
<p>If a fixer is uncertain about the changes it has made, it should report so on
standard output using a pseudo-header.  By default, lintian-brush will discard
any changes with uncertainty but if you are running it locally you can still
apply them by specifying <tt><span>--uncertain</span></tt>.</p>
<p>The summary message on standard out will be used for the commit message and
(possibly) the changelog message, if the package doesn’t use gbp dch.</p>
</div>
<div id="example-fixer">
<h2>Example Fixer</h2>
<p>Let’s look at an example. The package priority “extra” is deprecated since
Debian Policy 4.0.1 (released August 2 017) – see
<a href="https://www.debian.org/doc/debian-policy/ch-archive.html#priorities">Policy 2.5 "Priorities"</a>.
Instead, most packages should use the “optional” priority.</p>
<p>Lintian will warn when a package uses the deprecated “extra” value for the
“Priority”  - the associated tag is
<a href="https://lintian.debian.org/tags/priority-extra-is-replaced-by-priority-optional.html">priority-extra-is-replaced-by-priority-optional</a>.
Lintian-brush has a fixer script that can automatically replace “extra” with
“optional”.</p>
<p>On systems that have lintian-brush installed, the source for the fixer lives in
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/blob/master/fixers/priority-extra-is-replaced-by-priority-optional.py">/usr/share/lintian-brush/fixers/priority-extra-is-replaced-by-priority-optional.py</a>,
but here is a copy of it for reference:</p>
<table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td><div><pre><span></span><span>#!/usr/bin/python3</span>

<span>from</span> <span>debmutate.control</span> <span>import</span> <span>ControlEditor</span>
<span>from</span> <span>lintian_brush.fixer</span> <span>import</span> <span>report_result</span><span>,</span> <span>fixed_lintian_tag</span>

<span>with</span> <span>ControlEditor</span><span>()</span> <span>as</span> <span>updater</span><span>:</span>
    <span>for</span> <span>para</span> <span>in</span> <span>updater</span><span>.</span><span>paragraphs</span><span>:</span>
        <span>if</span> <span>para</span><span>.</span><span>get</span><span>(</span><span>"Priority"</span><span>)</span> <span>==</span> <span>"extra"</span><span>:</span>
            <span>para</span><span>[</span><span>"Priority"</span><span>]</span> <span>=</span> <span>"optional"</span>
            <span>fixed_lintian_tag</span><span>(</span>
                <span>para</span><span>,</span> <span>'priority-extra-is-replaced-by-priority-optional'</span><span>)</span>

<span>report_result</span><span>(</span><span>"Change priority extra to priority optional."</span><span>)</span>
</pre></div>
</td></tr></tbody></table><p>This fixer is written in Python and uses the  <a href="https://salsa.debian.org/jelmer/debmutate">debmutate</a>  library to easily modify
control files while preserving formatting — or back out if it is not possible
to preserve formatting.</p>
<p>All the current fixers come with tests, e.g. for this particular fixer the
tests can be found here:
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional">https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional</a>.</p>
<p>For more details on writing new fixers, see the  <a href="https://salsa.debian.org/jelmer/lintian-brush#writing-new-fixers">README</a>  for
lintian-brush.</p>
<p>For more details on debugging them, see the  <a href="https://manpages.debian.org/unstable/lintian-brush/lintian-brush.1.en.html">manual page</a>.</p>
</div>


            

            

            
            <p><a href="#">Go Top</a></p>        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.jelmer.uk/janitor-update-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241549</guid>
            <pubDate>Sat, 22 Aug 2020 04:30:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NAT Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24241105">thread link</a>) | @signa11
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what’s standing between them. Let’s talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let’s start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale’s case, we want to set
up a WireGuard® tunnel, but that doesn’t really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We’ll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let’s say you’re making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We’re going to focus on UDP for the rest
of this article.</p>
<p>If you’re reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that’s sending
and receiving network packets. As a rule, you can’t take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren’t part of the “main” protocol
you’re trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you’re building your
own, it’s helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let’s go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, …) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables),
BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all
very configurable, but the most common configuration allows all
“outbound” connections and blocks all “inbound” connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and “direction” are a figment of the protocol
designer’s imagination. On the wire, every connection ends up being
bidirectional; it’s all individual packets flying back and forth. How
does the firewall know what’s inbound and what’s outbound?</p>
<p>That’s where the stateful part comes in. Stateful firewalls remember
what packets they’ve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it’ll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are “facing” the same way. That’s
usually the case when you’re communicating with a server on the
internet. Our only constraint is that the machine that’s <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we’ve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our “clients” want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to “open a port” and allow
the other machine’s traffic. This is not very user friendly. It also
doesn’t scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don’t have control over the firewalls: you
can’t reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn’t involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn’t
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can’t carry any
precious information unless you’re prepared to retransmit them. This
is generally true of UDP, but especially true here. We’re <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let’s take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop’s first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation’s first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks “ah,
a response to that outbound request I saw”, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it’s a “response” to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We’ve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It’s not always so easy. We’re relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn’t it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting “side channel”
doesn’t need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own “signalling channel” (a name that reveals WebRTC’s IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241105</guid>
            <pubDate>Sat, 22 Aug 2020 02:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bread, How Did They Make It? Part IV: Markets, Merchants and the Tax Man]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24240677">thread link</a>) | @Kednicma
<br/>
August 21, 2020 | https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As the fourth and final part (<a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">I</a>, <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">II</a>, <a href="https://acoup.blog/2020/08/06/collections-bread-how-did-they-make-it-part-iii-actually-farming/">III</a>) of our look at the basic structure of food production in the pre-modern world (particularly farming grain to make bread), this week we’re going to look at how at least some of the delicious food we made in the last post might make its way into the hands of people who are <em>not</em> <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>or even<a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/"> farm owners</a>.</p>



<p>In the previous three posts, I have mostly just used the magic word ‘markets’ to describe how the food produced in the countryside gets to the cities and people who are not farmers.  As we’ll see in this post, that is a bit of an oversimplifying fib, both in that the phrase ‘markets’ covers a <em>lot </em>of complexity, but also (as we’ll see) some of the major drivers of moving that food from the countryside into towns doesn’t involve money <em>or</em> market interactions.  That said, we’re going to <em>start</em> with market transactions, because while they are actually the minority-type in many of these societies, they are more readily familiar and understandable, I suspect, to modern readers.  Then we’ll move to <em>extraction</em> as the other category.</p>



<p>Speaking of extraction, as always, if you like what you are reading here, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreo</a>n. And if you want updates whenever a new post appears, you can click the button below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts, as well as my occasional ancient history, foreign policy or pop-culture thoughts.</p>






<h2>Point of Sale</h2>



<p>I want to start by leaning on (with small modifications for clarity) Paul Erdkamp’s taxonomy of the various options by which food might get into the stream of commerce.  A small farmer might sell their grain (I) directly to city-dwellers, (II) indirectly, via urban middlemen and grain merchants, either in the market or (III) ‘at the gate’ (meaning selling to merchants who come out to the farm in order to buy; the difference being who transports the food to the city), (IV) to itinerant traders at periodic rural markets or (V) to other local small farmers.  As we’ll see, <em>large </em>landholders have a <em>somewhat</em> larger range of options within this taxonomy, but the fundamentals are the same.</p>



<p>While all of these sale methods certainly happened, in every society I have looked at, Option I – selling directly to city-dwellers – is fairly rare for grains and other bulk agricultural goods.  Market <em>gardeners</em>, selling fruits, vegetables (and sometimes flowers) often do sell this way, maintaining a high-intensity garden near town and a shop or stall in the town market.  Likewise, while Option V – small-scale trade between farmers – absolutely happens, it is typically non-monetary: the banqueting of neighbors discussed in the first post.  Where it is monetary, it is typically quite small scale and very short distance.  By and large, small and mid-sized farmers hadn’t the time, expertise or infrastructure to sell their goods directly.  They needed to be farming, not manning a market stall or trying to figure out how to store their goods close to the point of sale.  And of course large landowners, being rich, aren’t going to stand in the market square either (and in many cases don’t want their obvious representative doing so either,  see below).  So while I and V happen, they’re not too common or too large a portion of total trade and we may lay them aside for this discussion.</p>



<p>That leaves Options II, III and IV, all of which involve selling grain to a middle-man merchant of some sort.  The main difference is the location of sale (in town, at the gate, or at periodic rural markets).  Outside of large cities and major ports, markets were likely to be <em>periodic</em>, occurring only on certain days (typically around once per week).  In Roman Italy, these were the <em>nundinae</em> (‘ninth days,’ although it was an 8-day cycle as the Romans count inclusively); the <em>nundinae</em> were minor festivals, days of rest and merrymaking, but they were also the days when the rural markets would be open – the rest-day from agricultural labor enabled farmers to head into local towns to buy or sell whatever they needed (interestingly, at Rome, the <em>nundinae</em> were <em>dies nefasti</em> – state business couldn’t generally be conducted on them – so poor farmers hoping to use their day off to participate politically were out of luck).  Similar periodic markets are common in the Middle Ages (and even today; most ‘farmer’s markets’ in the United States are periodic, <a href="http://www.carrborofarmersmarket.com/">including my town’s</a>).  The periodic nature of these markets is an adaptation to agricultural rhythms; for a market to function there need to be a lot of people together all at once and the small towns that dotted the countryside simply didn’t have the density to do that all of the time.</p>



<figure><img data-attachment-id="4249" data-permalink="https://acoup.blog/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg" data-orig-size="2325,663" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:Fresco_from_the_House_of_Julia_Felix,_Pompeii_depicting_scenes_from_the_Forum_market.JPG">Via Wikipedia</a>, a fresco showing market activity, with merchants showing off wares of fabric (left) and goods in pots (center) from the House of Julia Felix at Pompeii, first century CE.  Please note: the importance of pottery in modern archaeology has given many students and the general public the idea that the ancients were always shipping pots around for sale, as if there was a vast market in pottery.  <strong>Generally, people were buying what was in the pot, not the pot itself</strong>.</figcaption></figure>



<p>But as noted, our farmers are unlikely to be selling their grain directly to customers.  Instead, they are likely to be using some sort of middle-man merchant, which brings us to:</p>



<h2>Merchants!</h2>



<p>Merchants are a bit of a break from the people we have so far discussed in that they, by definition, live in the realm of the <em>market</em> (in the economic sense, although often also in a physical sense).  As we’ve seen so much of the world of our farmers and even our millers and bakers was governed by <em>non-market</em> interactions: horizontal and vertical social ties that carried expectations that weren’t quite transactional and certainly not monetized.  By contrast, merchants work with transactions and tend to be the <em>first</em> group in any society to attempt to monetize their operations once money becomes available.  I find students are often quick to feel identity with the merchant class, because these folks are more likely to travel, more likely to use money, more likely to employ or be employed in wage-labor; they feel more like modern people.</p>



<p>It thus tends to come as something of a surprise that with <em>stunning</em> consistency, <strong>the merchant class tended to be at best cordially disliked and at worst <em>despised</em> by the broader community</strong> (although not typically to the point of suffering legal disability, as did some other jobs; see S. Bond, <em>Trade and Taboo: Disreputable Professions in the Roman Mediterranean</em> (2016) for this in Rome).  This often strikes students as strange, both because we tend to think rather better of our own modern merchants but also because the image they have of the merchant class certainly looks elite.</p>



<figure><img data-attachment-id="4257" data-permalink="https://acoup.blog/britlibaddms35166apocalypseunkfolio3sealblackhorse/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg" data-orig-size="1134,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="britlibaddms35166apocalypseunkfolio3sealblackhorse" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg 1134w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:BritLibAddMS35166ApocalypseUnkFolio3SealBlackHorse.jpg">Via Wikipedia</a>, a manuscript illustration showing the Horseman of Famine depicted as a grain merchant (from Revalations 6:5-6), holding the scales he would use to measure out grain.</figcaption></figure>



<p>For the farmers who need to sell their crops (for reasons we will get to in a moment) and purchase the things they need that they cannot produce, the merchant feels like an adversary: always pushing his prices to his best advantage.  We expect this, but remember that our pre-modern farmers are just <em>not that exposed to market interactions</em>; most of their relationships are reciprocal, not transactional – the horizontal relationships we discussed before.  The merchant’s ‘money-grubbing’ feels like a betrayal of trust in a society where you banquet your neighbors in the good years so they’ll help you in the bad years.  <strong>The necessary function of a merchant is to transgress the ‘rules’ of village interactions which – and this <em>resounds</em> from the sources – the farmers tend to understand as being ‘cheated.’</strong></p>



<p>At the same time, <strong>while most merchant types are humble, the high-risk and potentially high-reward involved in trade meant that <em>some</em> merchants </strong>(again, a small number) <strong>could become <em>very</em> rich</strong>.  That, as you might imagine, <strong>did not go over well for the traditionally wealthy in these societies</strong>, the large landholders.  Again, the values here often strike modern readers as topsy-turvy compared to our own, but to the elite large landholders (who dominate the literary and political culture of their societies), the <em>morally correct</em> way to earn great wealth is to inherit it (or capture it in war).  The <em>morally correct</em> way to hold that wealth is with large landed estates.  Anything else is <em>morally</em> suspect, and so the idea that a successful merchant could – by a process that again, strikes the large landholder, just like the small farmer, as ‘cheating’ – leap-frog the social pyramid and skip to the top, without putting in the work at either having distinguished wealthy ancestors <em>or</em> tremendous military success was an open insult to elite values.  Often laws were put in place to limit the ability of wealthy non-aristocrats (likely merchants or successful artisans) from displaying their wealth (<a href="https://en.wikipedia.org/wiki/Sumptuary_law">sumptuary laws</a>) so as to keep them from competing with the aristocrats; at Rome, senators were forbidden from owning ships with much the same logic (Roman senators being clever, they still invested in trade through proxies while at the same time disapproving of the activity in public politics).</p>



<p>Such disdain appears, with varying justification, in the sources of every pre-modern agrarian society I’ve studied, to one degree or another.  One commonplace of Greek and Roman thinking – despite these being very active, maritime societies – was that the first production of ships and the first sailing was in some essential way a profanation of the divine realm of the sea, a space humans ought not have ever ventured into – and certainly not for anything as mean as profit (e.g. Euripides, <em>Medea</em> 1-6; Catullus. 64.1-20; Valerius Flaccus, <em>Argonautica</em> 627-632; Seneca, <em>Medea</em> 1-12; 301-379, <em>inter alia</em> – thanks to my old grad school pals <a href="https://www.usf.edu/arts-sciences/departments/world-languages/about-us/hedrick.aspx">Buddy Hedrick</a> and <a href="http://gdrsd.org/gdrhs/faculty/michael-hoffman/">Michael Hoffman </a>for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240677</guid>
            <pubDate>Sat, 22 Aug 2020 01:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Traceroute in Go – Blog]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24239371">thread link</a>) | @rbanffy
<br/>
August 21, 2020 | https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/ | <a href="https://web.archive.org/web/*/https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><em>(<a href="https://github.com/kalbhor/tracesite">link</a> for all the code)</em></p>
<h3 id="what-is-traceroute">What is traceroute?</h3>
<p>If you’ve fiddled with networks you must be familiar with the famous <code>traceroute</code> tool. Its a script that traces the path to a host and prints info on every hop it encounters. To give an example if you run <code>traceroute kalbhor.xyz</code> you should see something like this :</p>
<pre><code>❯ traceroute kalbhor.xyz
traceroute to kalbhor.xyz (18.140.218.13), 64 hops max, 52 byte packets
 1  dlinkrouter.dlink (192.168.0.1)  2.035 ms  1.276 ms  1.097 ms
 2  10.194.0.1 (10.194.0.1)  5.985 ms  4.006 ms  3.817 ms
 3  broadband.actcorp.in (49.207.47.201)  4.320 ms  4.715 ms  4.243 ms
 4  broadband.actcorp.in (49.207.47.225)  5.115 ms  5.390 ms  4.893 ms
 5  14.142.187.85.static-delhi.vsnl.net.in (14.142.187.85)  3.789 ms  3.746 ms  4.004 ms
 6  172.31.180.57 (172.31.180.57)  40.903 ms  41.661 ms  41.531 ms
 7  * * ix-ae-4-2.tcore1.cxr-chennai.as6453.net (180.87.36.9)  177.280 ms
 8  if-ae-13-2.tcore1.svw-singapore.as6453.net (180.87.36.83)  164.288 ms  176.561 ms  82.274 ms
 9  180.87.106.5 (180.87.106.5)  81.871 ms  84.931 ms  83.477 ms
10  52.93.11.197 (52.93.11.197)  82.368 ms  84.777 ms
    52.93.11.211 (52.93.11.211)  82.945 ms
11  52.93.11.79 (52.93.11.79)  83.587 ms
    52.93.11.67 (52.93.11.67)  78.292 ms
    52.93.11.87 (52.93.11.87)  79.452 ms
12  52.93.11.80 (52.93.11.80)  82.862 ms
    52.93.11.82 (52.93.11.82)  86.355 ms
    52.93.11.72 (52.93.11.72)  88.732 ms
13  52.93.9.161 (52.93.9.161)  83.706 ms
    52.93.9.95 (52.93.9.95)  82.498 ms
    52.93.9.139 (52.93.9.139)  84.551 ms
14  203.83.223.77 (203.83.223.77)  84.500 ms
    52.93.10.95 (52.93.10.95)  79.663 ms  79.812 ms
</code></pre><p>These might differ for you but for me this is the route my computer takes to connect to <code>kalbhor.xyz</code>. A few interesting details here include <code>dlinkrouter.dlink (192.168.0.1)</code>. Yes, that looks similar! It is my routers local IP, which means my router at home is the first machine to process my request. That’s pretty obvious.</p>
<p>Next we see <code>broadband.actcorp.in (49.207.47.201)</code> which is my ISP. We can also see that my request forwards to a ISP router in Delhi (most probably a regional level ISP) and further moves through Chennai and Singapore (kalbhor.xyz is hosted on an AWS Singapore server).</p>
<p>This tool is very useful to inspect network paths and solve problems. But aside from that, this tool is extremely interesting and its actual implementation is pretty simple.</p>
<hr>
<h3 id="how-does-traceroute-work">How does traceroute work?</h3>
<p>Now that we understand what traceroute does, lets take a look under the hood. Every TCP/UDP packet that travels has a bunch of headers containing info about the packet. One such header is the <code>ttl</code> header which is the number of hops the packet travels before being dropped. So if we set this <code>ttl</code> header to 1 our packet will reach the first hop and be dropped, if we set it to 2 our packet will reach the second hop and drop, and so on.</p>
<p>Now that we know how our packets can reach any of the hops between us and our destination, how do we collect info on the hop?
When a server/router drops a packet, it returns a  <code>ICMP Time Exceeded</code> message back. Parsing this message will allow us to retrieve info on the particular hop. Once the destination is reached (last hop) we are returned a <code>ICMP Destination Unreachable</code> message.</p>
<hr>
<h3 id="implementing-traceroute">Implementing traceroute</h3>
<p>Now that we understand what’s happening under the hood, we can roughly design a way to implement traceroute.
The steps to implement it should look something like this:</p>
<ul>
<li>Open a socket connection between us and our destination and send UDP packets</li>
<li>Start from TTL=1 and keep increasing the TTL value on the UDP packets</li>
<li>Open a socket that listens for the ICMP messages and parses them</li>
</ul>
<hr>
<h3 id="writing-a-go-application-that-implements-traceroute">Writing a Go application that implements traceroute</h3>
<p>Now we know what we want and all we need to do is implement it in any language. I’m implementing this in Go. The <code>net</code> and <code>syscall</code> package will help us along the way.</p>
<p><em>Note: I will be using minimal code just to show the main implementation (so you probably wont see me handling errors, etc here). For a more refinded well developed version of this code check out <a href="https://github.com/kalbhor/tracesite">the repository</a>.</em></p>
<p>Lets start by creating the sockets we’ll use for sending and recieving data.</p>
<pre><code>sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
defer syscall.Close(recvSocket)
defer syscall.Close(sendSocket)
</code></pre><p>Lets create a ttl variable which we’ll iterate and a timevalue variable that defines our timeout</p>
<pre><code>ttl := 1
// For 2000Ms
tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) 
</code></pre><p>Next lets set the ttl and timeout value for the packets we’ll send in the socket</p>
<pre><code>syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)
</code></pre><p>At this point our sockets are ready to send and recieve data. What we need to do is find the destination address for our <code>sendSocket</code> and a network interface on our machine for our <code>recvSocket</code></p>
<pre><code>func socketAddr() ([4]byte, error) {
    socketAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return socketAddr, err
    }

    for _, a := range addrs {
        if ipnet, ok := a.(*net.IPNet); ok &amp;&amp; !ipnet.IP.IsLoopback() {
            if len(ipnet.IP.To4()) == net.IPv4len {
                copy(socketAddr[:], ipnet.IP.To4())
                return socketAddr, nil
            }
        }
    }
    err = errors.New("Not connected to the Internet")
    return socketAddr, err
}

func destAddr(dest string) ([4]byte, error) {
    destAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.LookupHost(dest)
    if err != nil {
        return destAddr, err
    }
    addr := addrs[0]

    ipAddr, err := net.ResolveIPAddr("ip", addr)
    if err != nil {
        return destAddr, err
    }
    copy(destAddr[:], ipAddr.IP.To4())
    return destAddr, nil
}
</code></pre><p>And in our main function we use these functions the get the addresses our sockets will use</p>
<pre><code>destAddr, err := destAddr("google.com")
socketAddr, err := socketAddr()
</code></pre><p>Lets bind our <code>recvSocket</code> so that it can recieve messages and lets send a null byte to our destination through our <code>sendSocket</code>. We connect to the port 33434.</p>
<pre><code>syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})
</code></pre><p>Now we need to parse the messages being sent on our <code>recvSocket</code></p>
<pre><code>p := make([]byte, options.Int(56)) // The integer here is the packet size
n, from, err := syscall.Recvfrom(recvSocket, p, 0)

ip := from.(*syscall.SockaddrInet4).Addr
ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
host, err := net.LookupAddr(ipString)

fmt.Println(host)
fmt.Println(ipString)
</code></pre><p>The Recvfrom method returns a <code>Sockaddr</code> type to our <code>from</code> variable. Hence if we parse our <code>from</code> variable we can get the IP info on the hop. We can use this with <code>net.LookupAddr</code> to run a reverse search and get the hostname (domain name) through the IP.</p>
<p>We’re almost done! All we need to do is wrap this functionality in a for loop and keep updating the <code>ttl</code> variable.</p>
<pre><code>func main() {
    sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
    recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
    defer syscall.Close(recvSocket)
    defer syscall.Close(sendSocket)

    ttl := 1
    tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) // For 2000Ms

    for {
        syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
        syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)

        destAddr, err := destAddr("google.com")
        socketAddr, err := socketAddr()
        destAddrString := fmt.Sprintf("%v.%v.%v.%v", destAddr[0], destAddr[1], destAddr[2], destAddr[3]) 


        syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
        syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})

        p := make([]byte, options.Int(56)) // The integer here is the packet size
        n, from, err := syscall.Recvfrom(recvSocket, p, 0)

        ip := from.(*syscall.SockaddrInet4).Addr
        ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
        host, err := net.LookupAddr(ipString)
        
        fmt.Println(host)
        fmt.Println(ipString)
        
        // We stop our loop if we reach destination or reach max value for ttl
        if ipString == destAddrString || ttl &gt;= 56 { 
                break
        }

        ttl += 1

    }

}
</code></pre><p>Note that we added an if statement block to end our for loop once we reach the destination address or exceed max value for hops.</p>
<hr>
<h3 id="conclusion">Conclusion</h3>
<p>This is definitely not the most elegant solution but it explains how simple the implementation of <code>traceroute</code> actually is. If you want to check out a more refinded version of this code that compiles well and has many options like set ttl, max hops, timeout, etc check out - <a href="https://github.com/kalbhor/tracesite">My Github Repo</a></p>
<h5 id="voila----we-just-implemented-the-traceroute-tool">Voila  💫  we just implemented the traceroute tool</h5>

      
      
      
    </div></div>]]>
            </description>
            <link>https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239371</guid>
            <pubDate>Fri, 21 Aug 2020 22:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over three billion people worldwide now play video games, study reports]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 359 (<a href="https://news.ycombinator.com/item?id=24239234">thread link</a>) | @Gamermeme
<br/>
August 21, 2020 | https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="588" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/08/gamers-588x330.jpg" alt="Three billion people worldwide now play video games, study reports">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>1 week ago</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>By mid-2020, the number of people playing video games had grown to 3.1 billion, according to <a href="https://www.dfcint.com/product/video-game-consumer-segmentation-2/">DFC Intelligence</a>. Considering that in July the total population of the Earth exceeded 7.8 billion, just under 40% are familiar with games.</p>




<p>Analysts point out that almost half of the accounted three billion are those who play only on smartphones or mobile devices. This segment is also ahead of all others in terms of growth.</p>



<p>However, only about 250 million people are active console users who regularly buy new games for them. Although they represent only 8% of the total number of gamers, this is the group with the highest revenue per person.</p>



<p>1.5 billion are playing on PC – 48% of all gamers. However, this number includes not only regular users but also those who also enjoy video games on consoles and mobile platforms.</p>



<p>More than half of the world’s gamers live in Asia – there are 1.42 billion players there. Moreover, this region also accounts for 53% of people who play only on smartphones. The top four also include Europe (668 million), Latin America (383 million) and North America (261 million).</p>



<ul><li><figure><img src="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg" alt="" data-id="4920" data-link="https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/smartphome-user/" srcset="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg 510w, https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user-300x231.jpg 300w" sizes="(max-width: 510px) 100vw, 510px"></figure></li></ul>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
								
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/03/direct-1-310x165.jpg" alt="Rumor points to a new Nintendo Direct for next week">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/" rel="bookmark">Rumor points to a new Nintendo Direct for next week</a></h2>
			<p>It seems that the rumors of Nintendo Direct continue to circulate. In the last few …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/zelda-skyword-310x165.jpg" alt="King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/" rel="bookmark">King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch</a></h2>
			<p>In recent days, a rumor has been circulating the network that Zelda: Skyward Sword was …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/animal-crossing-granny-island-310x165.jpg" alt="FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/" rel="bookmark">FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND</a></h2>
			<p>Animal Crossing fans may remember Audrey, the 89-year-old grandmother who has famously clocked more than …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/04/crysis-for-the-switch-310x165.jpg" alt="Crysis Remastered Coming To PC And Consoles On September 18">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/" rel="bookmark">Crysis Remastered Coming To PC And Consoles On September 18</a></h2>
			<p>Crytek not only announced the release date of the remaster, but also a teaser comparing …</p>
		</div>
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239234</guid>
            <pubDate>Fri, 21 Aug 2020 21:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F (2006)]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24238846">thread link</a>) | @tosh
<br/>
August 21, 2020 | http://www.nsl.com/k/f/f.htm | <a href="https://web.archive.org/web/*/http://www.nsl.com/k/f/f.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><a href="http://www.nsl.com/k/f/f.k">F</a> is a pure functional concatenative 
language originally designed as an extension of <a href="http://www.nsl.com/papers/false.htm">False</a>. F contains the list-operations of <a href="http://www.kx.com/">K3</a> and the <em>dip</em> combinator 
of <a href="http://www.latrobe.edu.au/philosophy/phimvt/joy.html">Joy</a>. Floating-point and symbolic datatypes are supported. One-time assignment
is enforced in syntax. A theory of function-valence and -charge is outlined. F also contains a general continuation
primitive $, and the pattern sublanguage of <a href="http://www.nsl.com/k/xy/xy.htm">XY</a>.  <a href="http://www.nsl.com/k/f/g.k">G</a> is a variant of F in which the K3 adverbs are implemented as primitives.</p>

<h2>0. Introduction</h2>

<p>F has the following properties:</p>

<blockquote>
    <ul>
        <li>The language is concatenative</li>
        <li>The language is purely functional</li>
        <li>All K verbs are implemented</li>
        <li>All primitives are denoted by single symbols</li>
        <li>Primitive symbols are as mnemonic as possible</li>
    </ul>
</blockquote>

<p><em>The language is concatenative.</em> F tokens are words,
words denote functions, and the concatenation of words denotes
the composition of functions. In classical concatenative
languages, everything is a function from stacks to stacks. In F,
everything is a function from triples of
(environment;stack;queue) to triples of
(environment;stack;queue).</p>

<p><em>The language is purely functional.</em> There are no
side-effects. F has assignment, but not reassignment. This means
that you can't use a variable to store dynamic state. F
assignment associates names with values in an environment which
is passed as an argument and returned as a value. F also has
commands for interacting with the run-time environment and the
file-system, but these operations are notationally differentiated
from the operators of F: "h", "r", &amp;c.
They are intended as debugging aids only.</p>

<p><em>All K verbs are implemented.</em> Some K verbs are
implemented as primitives, and some are derived in the F prelude.
For example, the <em>atom</em> primitive @ of K is defined as
[#ints~]; i.e. shape matches the empty integer vector. Where K
provides a pair of functions, one of which is easily defined in
terms of the other, F implements one as a primitive and derives the
other. For example, <em>and</em> is primitive (&amp;) and <em>or</em>
is derived.  The criterion for dividing related pairs is simply
this:  the derived definition must not be egregiously inefficient
when compared to the primitive it supplants.</p>

<p><em>All primitives are denoted by single symbols.</em>
Although list-notation ([x y z]) is supported, any list can be
constructed functionally with ' (<em>quote</em>) and , (<em>join</em>).</p>

<p><em>Primitive symbols are as mnemonic as possible.</em> There
are five ways the mapping of a function to a symbol can be
mnemonic:</p>

<blockquote>
    <ol>
        <li>The symbol is in common use for the mapped function
            (e.g. + for addition)</li>
        <li>The symbol is mapped to that function in K (e.g. ?
            for <em>find</em>) or False (e.g. ! for <em>unquote</em>)</li>
        <li>The name of the symbol is a homonym for the mapped
            function (e.g. ' for <em>quote</em>)</li>
        <li>A pair of related functions (inverses, or
            near-inverses) are mapped to a pair of related
            symbols (e.g. / and \ for <em>take</em> and <em>drop</em>)</li>
        <li>Where several K primitives are mapped to one symbol,
            the primitives should form an easily remembered group
            based on some common property; e.g. both <em>upgrade</em>
            and <em>enum</em> return indices based on an
            ascending relation, so both are mapped to &lt;. </li>
    </ol>
</blockquote>

<h2>1. Datatypes</h2>

<p>The initial state of the interpreter consists of an
environment containing the F words of the prelude, an empty
result stack, and a string (character-vector) to be evaluated.
The input string is tokenized and parsed to obtain the initial
queue. </p>

<p>The input queue is a K list, possibly containing integers,
floats, symbols, <em>null</em>, functions, and lists
("quotations"). The result stack is initially empty.
The environment is a K dictionary. F processes the environment,
stack, and queue repeatedly until the queue is empty. </p>

<p>If the first item on the queue is an integer, float, <em>null</em>,
the prototype symbol `, or a list, the item is pushed onto the
stack.</p>

<p>If the first item is an undefined symbol, then if it's a <em>shuffle</em>
it's applied; otherwise, a variable is created (in the environment)
having the top of the stack as the value. </p>

<p>If the first item is a defined symbol, its value is
retrieved (from the environment) and pushed onto the stack.</p>

<p>If the first item is a function, then it is applied to the
environment, stack, and queue to produce a new environment,
stack, and queue.</p>

<p>Observe that the domain of the result stack is a proper subset
of the domain of the input queue. On the queue we may find
character-atoms, such as "r", and strings, such as
"blah". But character-atoms are executed away when they
are evaluated, and no F primitive ever produces one, and strings
are comments, which are not processed.</p>

<p>The <em>trace</em> command displays the stack and queue for
selected objects in the trace list T:</p>

<blockquote>
    <pre>F&gt;[fac] "t"

F&gt;3 fac!
                                       3 ♦ fac !
                                     3 2 ♦ fac ! *
                                   3 2 1 ♦ fac ! * *
6
F&gt;

F&gt;[fac cond] "t"

F&gt;3 fac!
                                       3 ♦ fac !
       3 [1 =] [] [dup ! pred ! fac ! *] ♦ cond !
                                     3 2 ♦ fac ! *
     3 2 [1 =] [] [dup ! pred ! fac ! *] ♦ cond ! *
                                   3 2 1 ♦ fac ! * *
   3 2 1 [1 =] [] [dup ! pred ! fac ! *] ♦ cond ! * *
6
F&gt;

F&gt;[] "t"

F&gt;3 fac!
6</pre>
</blockquote>

<h2>2. Primitives</h2>

<h3>Operators (O)</h3>

<blockquote>
    <pre>09*-		int		123 -&gt; 123
09*.09*-	float		123.45 -&gt; 123.45

az.AZ*		name		myName -&gt; value or null
az*-AZ*		shuffle		10 20 ab-ba -&gt; 20 10

[..]		list		[10 + [3 a]] -&gt; [10 + [3 a]]

+		add		1 2 + -&gt; 3
-		sub		2 3 - -&gt; 1
*		mul		3 4 * -&gt; 12
%		div		5 3 % -&gt; 1.666667
^		power		2 3 ^ -&gt; 8
_		floor		3.2 _ -&gt; 3

=		equal		2 2 = -&gt; 1
&gt;		more		4 6 &gt; -&gt; 0
&amp;		and/min		4 3 &amp; -&gt; 3

~		match		[1 2][1 2] ~ -&gt; 1

#		shape		[1 2 3] # -&gt; [3]

|		reverse		[1 2 3] | -&gt; [3 2 1]

@		where		[0 1 1 0 1] @ -&gt; [1 2 4]
@		flip		[[1 2 3][4 5 6]] @ -&gt; [[1 4][2 5][3 6]]

/		take		2[1 2 3] / -&gt; [1 2]
/		reshape		[3 2][1 2 3] / -&gt; [[1 2][3 1][2 3]]

\		drop		2[1 2 3] \ -&gt; [3]
\		cut		[0 2][1 2 3] \ -&gt; [[1 2][3]]
\		rotate		[1 2 3 4] 2 \ -&gt; [3 4 1 2]

?		find		[10 20 30] 20 ? -&gt; 1
?		mod		2 [3 4 5] ? -&gt; [1 0 1]

;		unique		[10 20 10 10 30] ; -&gt; [10 20 30]
:		group		[10 20 10 10 30] : -&gt; [[0 2 3][1][4]]

&lt;		enum		3 &lt; -&gt; [0 1 2]
&lt;		upgrade		[10 30 20] &lt; -&gt; [0 2 1]

.		infra		1 2 [[2 3 +]] . 3 4 -&gt; 1 2 [5] 3 4
.		index		[[1 2 3][[1 0]]] . -&gt; [2 1]
.		monad		[[1 2 3][[1 0]][-1*]] . -&gt; [-1 -2 3]
.		dyad		[[1 2 3][[1 0]]+[3 8]] . -&gt; [9 5 3]

!		unquote		2 [3 +] ! -&gt; 5
`		dip		2 3 4 [+] ` -&gt; 5 4
'		quote		'+ -&gt; [+]

,		join  		[1][2 3] , -&gt; [1 2 3]

$		state		1 2 3 '\ $ 4 5 6 -&gt; 4 5 6 1 2 3

)		s -&gt; s		stack-&gt;stack pattern
(		s -&gt; q		stack-&gt;queue pattern

}		q -&gt; s		queue-&gt;stack pattern
{		q -&gt; q		queue-&gt;queue pattern</pre>
</blockquote>

<h3>System Functions (K)</h3>

<p>The K system functions have reserved names:</p>

<blockquote>
    <pre>type (4::)
log exp abs sqr sqrt floor dot mul inv lsq
sin cos tan asin acos atan sinh cosh tanh
draw
in lin bin binl dv dvl di vs sv</pre>
</blockquote>

<h3>Literals (L)</h3>

<p>F has nine reserved names for literals:</p>

<blockquote>
    <pre>Nan		minint (0N)
Inf		maxint (0I)

nan		NaN (0n)
inf		infinity (0i)

null		null (_n)
sym		prototype sym (`)

ints		empty integer vector (!0)
floats		empty float vector (0#0.)
syms		empty sym vector (0#`)</pre>
</blockquote>

<h3>Commands (I)</h3>

<p>F has the following interactive commands:</p>

<blockquote>
    <pre>".."		comment		1 "skip" 2	comment not processed

"b"		break		'x "b"		signal error ('x)
"c"		clear		1 2 "c" 3 4	clear, load f, prelude
"d"		defined		'foo "d"	is foo defined?
"e"		error		0 "e"		set/unset error trap (\e)
"f"		F		"f" 2 unit!	set F semantics, clear
"j"		Joy		"j" 2 unit	set Joy semantics, clear
"k"		K		1 2 "k" 3 4	exit to K
"l"		load		'x "l"		load f/x.f|x.j
"m"		measure		[10&lt;] "m"	measure time in ms
"o"		words		'map "o"	show word form
"p"		precision	3 "p"		print precision (\p)
"r"		read		1 2 "r" 3 4	read, parse, eval
"s"		store		y 'x "s"	store f/x.f|x.j
"t"		trace		null "t" 3 4	set trace-list (T)
"u"		undefine	x "u"		undefine vars in x
"v"		variables	1 2 "v" 3 4	show vars (!environment)
"x"		exit		1 2 "x" 3 4	_exit 0
"w"		write		1 2 "w" 3 4	format, write
"z"		halt		1 2 "z" 3 4	: to continue
</pre></blockquote>

<h3>Names and numbers</h3>

<p>Spaces (<em>blank</em>, <em>tab</em>, <em>return</em>) are
necessary to separate names from names and numbers from numbers,
but not names from numbers.</p>

<p>A name must begin with a letter and may contain letters, .,
or a single -.  A name containing a - is a shuffle-symbol.</p>

<p>A numerical expression must begin with either a digit or - 
followed by a digit, and must end with a digit.  A floating-point 
numerical expression must contain exactly one . which
must be flanked by digits.</p>

<h3>Operators</h3>

<p>The math, logic, and relational operators are <em>atomic
functions</em>. For example,</p>

<blockquote>
    <pre>F&gt;[1 2 3][[4 5 6] 7 8]+
[[5 6 7] 9 11]</pre>
</blockquote>

<p>In several instances, distinct K operations have been mapped
to one symbol: </p>

<blockquote>
    <pre>int &lt;			enum			!x
~atom &lt;			upgrade			&lt;x
atom &lt;			nonce

int/ints @		where			&amp;x
list @			flip			+x
			nonce

atom y ?		mod			y!x
~atom y ?		find			x?y

list atom \		rotate			y!x
atom list \		drop			x _ y
atom atom \		drop			x _(),y
list list \		cut			x _ y

1=#x .			infra
x .			index/monad/dyad	. x</pre>
</blockquote>

<h3>Iterators</h3>

<p>The False combinators <em>if</em> and <em>while</em> have been
eliminated, and <em>cond</em>, <em>if</em>, and <em>while</em>
have been defined as words in the prelude. The truth-values of F
are more general than those of K: 0 is <em>false</em>, any other
value is <em>true</em>.</p>

<h3>Assignment</h3>

<p>Assignment has the form <em>value unassigned_name</em>. An
assigned name may not be re-assigned.</p>

<p>Reserved names cannot be assigned:</p>

<blockquote>
    <pre>F&gt;12 inf
12 inf</pre>
</blockquote>

<p>Use of an assigned name (a variable) places the value assigned
to it on the stack:</p>

<blockquote>
    <pre>F&gt;10 a

F&gt;a
10
F&gt;12 a
10 12 10
F&gt;a
10 12 10 10</pre>
</blockquote>

<p>A symbol can be produced indirectly:</p>

<blockquote>
    <pre>F&gt;10 foo

F&gt;foo
10
F&gt;[foo] first!
foo
F&gt;!
10</pre>
</blockquote>

<h3>Quotation</h3>

<p>The <em>quote</em> primitive ' takes the next item on the
queue and quotes it:</p>

<blockquote>
    <pre>F&gt;'+
[+]
F&gt;
F&gt;'[1 2 3]
[[1 2 3]]
F&gt;
F&gt;''
[']</pre>
</blockquote>

<p>The <em>unquote</em> combinator ! is Joy's <em>i</em>. ! takes
the top item <em>x</em> on the stack and prepends the elements of
<em>x</em> to the queue:</p>

<blockquote>
    <pre>F&gt;2 3 '+ !
5</pre>
</blockquote>

<p>The <em>dip</em> combinator is defined as it is in Joy. `
takes the top two items <em>x</em> <em>y</em> on the stack and</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nsl.com/k/f/f.htm">http://www.nsl.com/k/f/f.htm</a></em></p>]]>
            </description>
            <link>http://www.nsl.com/k/f/f.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238846</guid>
            <pubDate>Fri, 21 Aug 2020 21:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai releases new deep learning course, libraries, and book]]>
            </title>
            <description>
<![CDATA[
Score 741 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24237207">thread link</a>) | @amardeep
<br/>
August 21, 2020 | https://www.fast.ai/2020/08/21/fastai2-launch/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/08/21/fastai2-launch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 21 Aug 2020 by <i>Jeremy Howard</i></span></p><p>fast.ai is a self-funded research, software development, and teaching lab, focused on making deep learning more accessible. We make all of our software, research papers, and courses freely available with no ads. We pay all of our costs out of our own pockets, and take no grants or donations, so you can be sure we’re truly independent.</p>
<p>Today is fast.ai’s biggest day in our four year history. We are releasing:</p>
<ul>
<li><a href="https://docs.fast.ai/">fastai v2</a>: A complete rewrite of fastai which is faster, easier, and more flexible, implementing new approaches to deep learning framework design, as discussed in the peer reviewed fastai <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">academic paper</a></li>
<li><a href="https://fastcore.fast.ai/">fastcore</a>, <a href="https://fastscript.fast.ai/">fastscript</a>, and <a href="https://fastgpu.fast.ai/">fastgpu</a>: Foundational libraries used in fastai v2, and useful for many programmers and data scientists</li>
<li><a href="https://course.fast.ai/">Practical Deep Learning for Coders</a> (2020 course, part 1): Incorporating both an introduction to machine learning, and deep learning, and production and deployment of data products</li>
<li><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD</a>: A book from O’Reilly, which covers the same material as the course (including the content planned for part 2 of the course)</li>
</ul>
<p>Also, in case you missed it, earlier this week we released the <a href="https://ethics.fast.ai/">Practical Data Ethics</a> course, which focuses on topics that are both urgent and practical.</p>
<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
<li><a href="#fastai-v2" id="markdown-toc-fastai-v2">fastai v2</a></li>
<li><a href="#practical-deep-learning-for-coders-the-course" id="markdown-toc-practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</a></li>
<li><a href="#deep-learning-for-coders-with-fastai-and-pytorch-the-book" id="markdown-toc-deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</a></li>
<li><a href="#fastcore-fastscript-and-fastgpu" id="markdown-toc-fastcore-fastscript-and-fastgpu">fastcore, fastscript, and fastgpu</a> <ul>
<li><a href="#fastcore" id="markdown-toc-fastcore">fastcore</a></li>
<li><a href="#fastscript" id="markdown-toc-fastscript">fastscript</a></li>
<li><a href="#fastgpu" id="markdown-toc-fastgpu">fastgpu</a></li>
</ul>
</li>
<li><a href="#acknowledgements" id="markdown-toc-acknowledgements">Acknowledgements</a></li>
</ul>
<h2 id="fastai-v2">fastai v2</h2>
<p>fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes:</p>
<ul>
<li>A new type dispatch system for Python along with a semantic type hierarchy for tensors</li>
<li>A GPU-optimized computer vision library which can be extended in pure Python</li>
<li>An optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 45 lines of code</li>
<li>A novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training</li>
<li>A new data block API</li>
<li>And much more…</li>
</ul>
<figure>
<img srcset="https://www.fast.ai/images/layered.png 2w" sizes="1px" src="https://www.fast.ai/images/layered.png">
<figcaption>fastai's layered architecture</figcaption>
</figure>
<p>fastai is organized around two main design goals: to be approachable and rapidly productive, while also being deeply hackable and configurable. It is built on top of a hierarchy of lower-level APIs which provide composable building blocks. This way, a user wanting to rewrite part of the high-level API or add particular behavior to suit their needs does not have to learn how to use the lowest level.</p>
<p>To see what’s possible with fastai, take a look at the <a href="https://docs.fast.ai/quick_start.html">Quick Start</a>, which shows how to use around 5 lines of code to build an image classifier, an image segmentation model, a text sentiment model, a recommendation system, and a tabular model. For each of the applications, the code is much the same.</p>
<figure>
<img srcset="https://www.fast.ai/images/segmentation-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/segmentation-fastai.png">
<figcaption>Example of using fastai for image segmentation</figcaption>
</figure>
<p>Read through the <a href="https://docs.fast.ai/tutorial">Tutorials</a> to learn how to train your own models on your own datasets. Use the navigation sidebar to look through the fastai documentation. Every class, function, and method is documented here. To learn about the design and motivation of the library, read the <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">peer reviewed paper</a>, or watch <a href="https://youtu.be/bHVqO5YyNbU">this presentation</a> summarizing some of the key design points.</p>
<p>All fast.ai projects, including fastai, are built with <a href="https://nbdev.fast.ai/">nbdev</a>, which is a full <a href="https://www.fast.ai/2019/12/02/nbdev/">literate programming environment</a> built on Jupyter Notebooks. That means that every piece of documentation can be accessed as interactive Jupyter notebooks, and every documentation page includes a link to open it directly on Google Colab to allow for experimentation and customization.</p>
<p>It’s very easy to migrate from plain PyTorch, Ignite, or any other PyTorch-based library, or even to use fastai in conjunction with other libraries. Generally, you’ll be able to use all your existing data processing code, but will be able to reduce the amount of code you require for training, and more easily take advantage of modern best practices. Here are migration guides from some popular libraries to help you on your way: <a href="https://docs.fast.ai/migrating_pytorch">Plain PyTorch</a>; <a href="https://docs.fast.ai/migrating_ignite">Ignite</a>; <a href="https://docs.fast.ai/migrating_lightning">Lightning</a>; <a href="https://docs.fast.ai/migrating_catalyst">Catalyst</a>. And because it’s easy to combine and part of the fastai framework with your existing code and libraries, you can just pick the bits you want. For instance, you could use fastai’s GPU-accelerated computer vision library, along with your own training loop.</p>
<p>fastai includes many modules that add functionality, generally through callbacks. Thanks to the flexible infrastructure, these all work together, so you can pick and choose what you need (and add your own), including: <a href="https://arxiv.org/abs/1710.09412">mixup</a> and <a href="https://arxiv.org/abs/1708.04552">cutout</a> augmentation, a uniquely flexible <a href="https://docs.fast.ai/vision.gan.html">GAN training</a> framework, a range of schedulers (many of which aren’t available in any other framework) including support for fine tuning following the approach described in <a href="https://arxiv.org/abs/1801.06146">ULMFiT</a>, mixed precision, gradient accumulation, support for a range of logging frameworks like Tensorboard (with particularly strong support for Weights and Biases, as <a href="https://app.wandb.ai/borisd13/demo_config/reports/Visualize-track-compare-Fastai-models--Vmlldzo4MzAyNA">demonstrated here</a>), <a href="http://docs.fast.ai/medical.imaging">medical imaging</a>, and much more. Other functionality is added through the <a href="https://github.com/nestordemeure/fastai-extensions-repository">fastai ecosystem</a>, such as support for <a href="https://ohmeow.github.io/blurr/">HuggingFace Transformers</a> (which can also be done manually, as shown in <a href="http://docs.fast.ai/tutorial.transformers">this tutorial</a>), <a href="https://github.com/rbracco/fastai2_audio">audio</a>, <a href="https://muellerzr.github.io/fastinference/inference/">accelerated inference</a>, and so forth.</p>
<figure>
<img srcset="https://www.fast.ai/images/medical-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/medical-fastai.png">
<figcaption>Medical imaging in fastai</figcaption>
</figure>
<p>There’s already some great learning material made available for fastai v2 by the community, such as the “Zero to Hero” series by Zach Mueller: <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-beginner.html">part 1</a>; <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-intermediate.html">part 2</a>.</p>
<h2 id="practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</h2>
<p>Previous fast.ai courses have been studied by hundreds of thousands of students, from all walks of life, from all parts of the world. Many students have told us about how they’ve become <a href="https://forums.fast.ai/t/my-first-gold-medal/54237">multiple gold medal winners</a> of <a href="https://towardsdatascience.com/my-3-year-journey-from-zero-python-to-deep-learning-competition-master-6605c188eec7">international machine learning competitions</a>, <a href="https://forums.fast.ai/t/how-has-your-journey-been-so-far-learners/6480/2">received offers</a> from top companies, and <a href="https://icml-compbio.github.io/2020/papers/WCBICML2020_paper_67.pdf">having</a> <a href="https://ui.adsabs.harvard.edu/abs/2020EGUGA..2221465A/abstract">research</a> <a href="https://arxiv.org/pdf/2004.14356.pdf">papers</a> <a href="https://pubs.rsna.org/doi/abs/10.1148/ryai.2019190113?journalCode=ai">published</a>. For instance, Isaac Dimitrovsky <a href="https://forums.fast.ai/t/thanks-ra2-dream-challenge-win/76875">told us</a> that he had “<em>been playing around with ML for a couple of years without really grokking it… [then] went through the fast.ai part 1 course late last year, and it clicked for me</em>”. He went on to achieve first place in the prestigious international <a href="https://www.synapse.org/#!Synapse:syn20545111/wiki/594083">RA2-DREAM Challenge</a> competition! He developed a <a href="https://www.synapse.org/#!Synapse:syn21478998/wiki/604432">multistage deep learning method</a> for scoring radiographic hand and foot joint damage in rheumatoid arthritis, taking advantage of the fastai library.</p>
<p><a href="https://course.fast.ai/">This year’s course</a> takes things even further. It incorporates both machine learning and deep learning in a single course, covering topics like random forests, gradient boosting, test and validation sets, and p values, which previously were in a separate machine learning course. In addition, production and deployment are also covered, including material on developing a web-based GUI for our own deep learning powered apps. The only prerequisite is high-school math, and a year of coding experience (preferably in Python). The course was recorded live, in conjunction with the <a href="https://www.usfca.edu/data-institute">Data Institute</a> at the University of San Francisco.</p>
<p>After finishing this course you will know:</p>
<ul>
<li>How to train models that achieve state-of-the-art results in:
<ul>
<li>Computer vision, including image classification (e.g.,classifying pet photos by breed), and image localization and detection (e.g.,finding where the animals in an image are)</li>
<li>Natural language processing (NLP), including document classification (e.g.,movie review sentiment analysis) and language modeling</li>
<li>Tabular data (e.g.,sales prediction) with categorical data, continuous data, and mixed data, including time series</li>
<li>Collaborative filtering (e.g.,movie recommendation)</li>
</ul>
</li>
<li>How to turn your models into web applications, and deploy them</li>
<li>Why and how deep learning models work, and how to use that knowledge to improve the accuracy, speed, and reliability of your models</li>
<li>The latest deep learning techniques that really matter in practice</li>
<li>How to implement stochastic gradient descent and a complete training loop from scratch</li>
<li>How to think about the ethical implications of your work, to help ensure that you’re making the world a better place and that your work isn’t misused for harm</li>
</ul>
<p>We care a lot about teaching, using a <a href="https://www.fast.ai/2016/10/08/teaching-philosophy/">whole game</a> approach. In this course, we start by showing how to use a complete, working, very usable, state-of-the-art deep learning network to solve real-world problems, using simple, expressive tools. And then we gradually dig deeper and deeper into understanding how those tools are made, and how the tools that make those tools are made, and so on. We always teach through examples. We ensure that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation. We also dive right into the details, showing you how to build all the components of a deep learning model from scratch, including discussing performance and optimization details.</p>
<p>The whole course can be completed for free without any installation, by taking advantage of the guides for the Colab and Gradient platforms, which provide free, GPU-powered Notebooks.</p>
<h2 id="deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</h2>
<p>To understand what the new book is about, and who it’s for, let’s see what others have said about it… Soumith Chintala, the co-creator of PyTorch, said in <a href="https://www.fast.ai/2020/08/20/soumith-forward/">the foreword</a> to <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch</a>:</p>
<blockquote>
<p>But unlike me, Jeremy and Sylvain selflessly put a huge amount of energy into making sure others don’t have to …</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/08/21/fastai2-launch/">https://www.fast.ai/2020/08/21/fastai2-launch/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/08/21/fastai2-launch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24237207</guid>
            <pubDate>Fri, 21 Aug 2020 17:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficiency is dangerous and slowing down makes life better]]>
            </title>
            <description>
<![CDATA[
Score 702 | Comments 300 (<a href="https://news.ycombinator.com/item?id=24236489">thread link</a>) | @joubert
<br/>
August 21, 2020 | https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>â€˜Slow down, you move too fast <em>â€¦</em>â€™ <br>â€“ â€˜The 59th Street Bridge Song (Feelinâ€™ Groovy)â€™ (1966) by Paul Simon</blockquote>
<p><strong>We worship efficiency</strong>. Use less to get more. Same-day delivery. Multitask; text on one device while emailing on a second, and perhaps conversing on a third. Efficiency is seen as good. Inefficiency as wasteful.</p>
<p>Thereâ€™s a sound rationale for thinking this way. Economists teach us that increased efficiency is the major way to improve our standard of living. If your company gives you a pay rise without becoming more efficient, it will also have to raise its prices to make up the shortfall. If all companies do the same, everyone ends up running in place â€“ youâ€™ll need your higher wages to match the higher prices of the things you buy. So, if we want to make material progress, we must become more efficient. Streamlined supply chains, just-in-time deliveries and no slack in the workforce all serve to raise efficiency. Achieve this, and all our lives will get better and better, or so weâ€™re promised.</p>
<p>For automobile manufacturers, who wish to squeeze as many miles per gallon as possible out of their car designs, air resistance and the grab of the road are the enemies of efficiency. In the world of finance, it is at the point of exchange that most friction arises. Before money, the potato farmer had to use sacks of potatoes to trade for eggs and milk. As the British historian Niall Ferguson reminds us in his <a href="https://www.penguin.co.uk/books/178/178638/the-ascent-of-money/9780141990262.html">book</a> <em>The Ascent of Money</em> (2008), the invention of money went a long way toward reducing this inefficiency, and much that has happened in the financial world over the past 200 years can be seen as a continuation of that revolution.</p>
<p>Credit, for example, meant that you could go shopping for eggs and milk even without having the money right now. Financial markets have since taken this efficiency to another level. The creation of â€˜option marketsâ€™ means that you donâ€™t have to go to the trouble of buying a stock that youâ€™re going to be selling soon anyway. You can just promise to buy it, and then sell it at a price and date specified by the option contract. And then you can trade the option rather than the underlying stock.</p>
<p>Each of these developments and many others have made it easier to do oneâ€™s business without wasted time and energy â€“ without friction. Each has made economic transactions quicker and more efficient. Thatâ€™s obviously good in some ways. But the financial crisis of 2008 suggested that maybe there could be too much of a good thing. If mortgages and other loans hadnâ€™t been transformed into tradable assets (â€˜securitiesâ€™), then bankers might have taken the time to assess the credit-worthiness of each applicant. If people had to visit a bank to withdraw cash, they might spend less and save more. This is not mere speculation â€“ for instance, <a href="https://doi.org/10.1002/(SICI)1099-0771(199909)12:3%3c183::AID-BDM318%3e3.0.CO;2-F">research</a> <a href="https://doi.org/10.1016/0167-2681(80)90051-7">reviewed</a> by the Nobel Prize-winning economist Richard Thaler shows that people will pay more for an item with a credit card than with cash. Arguably, a little friction to slow us down would have enabled both institutions and individuals to make better financial decisions.</p>
<p>A decade ago, the American psychologist Adam Grant and I argued in a journal <a href="https://journals.sagepub.com/doi/full/10.1177/1745691610393523?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub%20%200pubmed">paper</a> that this â€˜too much of a good thingâ€™ phenomenon might be a general rule. Some motivation produces excellent performance; too much motivation produces choking. Some group collaboration produces cohesion and enhances productivity; too much of it leads to staleness. Some empathy enables you to understand what another person is going through; too much could prevent you from saying and doing hard things. Similarly, in my <a href="https://www.harpercollins.com/products/the-paradox-of-choice-barry-schwartz?variant=32207920234530">book</a> <em>The Paradox of Choice</em> (2004), I argued that, whereas a life with no freedom to choose is not worth living, a life with too much choice leads to paralysis, bad decisions and dissatisfaction. Finding the right amount â€“ what Aristotle called the â€˜meanâ€™ â€“ of motivation, collaboration, empathy, choice and many other aspects of life, including efficiency, is a key challenge we face, both as individuals and as a society.</p>
<p>To be better prepared next time, we need to learn to live less efficiently in the here and now</p>
<p>But finding the mean isnâ€™t easy. As the English poet William Blake observed in <em>The Marriage of Heaven and Hell</em> (1790-93): â€˜You never know what is enough unless you know what is more than enough.â€™</p>
<p><strong>If the financial crisis</strong> taught us that we had become too efficient with our transactions, what of the COVID-19 pandemic? Why hadnâ€™t we stockpiled key supplies and machines, built up hospital capacity, or ensured the robustness of our supply chains? The reason, of course, is that it would have been seen as inefficient and profit-robbing. Money spent on masks and gowns gathering dust in a warehouse could always be put to more â€˜productiveâ€™ use in the marketplace. Likewise, employing more people than needed under â€˜ordinaryâ€™ circumstances, or making products yourself rather than relying on international supply chains, would have been seen as inefficient. One lesson, then, is that to be better prepared next time, we need to learn to live less â€˜efficientlyâ€™ in the here and now.</p>
<p>Seen in this light, at least some inefficiency is like an insurance policy. Think about your own situation. Every year that you donâ€™t get into a car accident and your house doesnâ€™t burn down and you stay healthy, you could think to yourself that you have â€˜wastedâ€™ your money on various pointless insurance products, and that youâ€™d be financially better off without all those insurance premiums to pay.</p>
<p>Most of us donâ€™t like the sense that weâ€™re wasting money on insurance. We would rather be wearing that money, or eating it, or driving it. Some years ago, with a struggle, I convinced my ageing mother to supplement her basic health insurance policy with a more comprehensive insurance product. Her resources were modest and the policy wasnâ€™t cheap. The year went by and, happily, she had no serious medical conditions that required the use of the extra cover. When the time came to renew, my mother resisted, because, indeed, the money she spent the year before had been â€˜wastedâ€™. My reply, perhaps unduly snarky, was to suggest to her that maybe the next year she would get lucky, have a really serious illness, and get her moneyâ€™s worth out of her insurance.</p>
<p>Thankfully, in many domains, government regulations protect us from our desire for ever-greater personal financial efficiency by forcing us to have insurance. Laws require that our cars be insured, and mortgagers require the same for our homes. In the United States, â€˜Obamacareâ€™ (the Affordable Care Act enacted in 2010, designed to increase the number of US citizens covered by health insurance) essentially compelled people to have health insurance, until the Supreme Court challenged this aspect of the Act as unconstitutional. I suspect that many of us are underinsured in general, but the problem would be much worse without these various, state-imposed insurance requirements.</p>
<p>One way to think about insurance, however inefficient it might feel, is that it enables us to be resilient against shocks that could befall us from a world that is radically uncertain. And the world <em>is</em> radically uncertain. As the British economists John Kay and Mervyn King point out in their <a href="https://wwnorton.com/books/9781324004776">book</a> <em>Radical Uncertainty</em> (2020), efforts to quantify risk by attaching probabilities to various unlikely future states of the world are mostly science fiction. The world is much messier than a roulette wheel or a pair of dice.</p>
<p>A little bit of friction can forestall disaster when you encounter an icy road</p>
<p><strong>What should we do</strong> in the face of this radical uncertainty? When making decisions, instead of asking ourselves which option will give us the best results, we should be asking which option will give us good-enough results under the widest range of future states of the world. Instead of trying to maximise return on investment in our retirement account, we should be setting a financial goal and then choosing investments that will allow us to achieve that goal under the widest set of future financial circumstances. Instead of looking for the â€˜bestâ€™ job, we should be looking for a job that will be good enough â€“ satisfying enough â€“ as co-workers and managers come and go, and the future economy gyrates. Instead of choosing the best college to go to, we should be choosing a college that will be good enough, even with an obnoxious roommate and a boring Bio 1 teacher.</p>
<p>The term used to describe this approach to decision-making is <em>satisficing</em>. And satisficing with an eye toward a radically uncertain future might be called <em>robust satisficing</em>. Satisficing is a form of insurance â€“ insurance against financial meltdowns, global pandemics, nasty bosses, boring teachers and crappy roommates. Insurance can seem stodgy â€“ like the guy who wears a belt <em>and</em> suspenders. Perhaps we donâ€™t need both, but what happens if we have neither?</p>
<p>I think the real flaw in capitalism revealed by the 2008 financial crisis was its unbridled, single-minded pursuit of profit and efficiency. And perhaps the real flaw revealed in our lack of readiness for the 2019-20 pandemic was a manifestation of the same thing. Capitalism neednâ€™t be either unbridled or single-minded. It isnâ€™t in other societies with high standards of living, and it hasnâ€™t been at all points in history in the US. So perhaps itâ€™s time to rekindle certain social norms that serve to slow us down. For example, if people thought about their homes less as financial investments and more as places to live, full of the friction of kids, dogs, friends, neighbours and community, there might be less property speculation with an eye toward buying and selling houses merely for profit. If companies felt the friction of being caretakers of their communities, they might look differently at streamlining their operations by eliminating jobs.</p>
<p>Weâ€™d all like a car that gets 100 miles to a gallon. The forces of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236489</guid>
            <pubDate>Fri, 21 Aug 2020 16:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ammonia as a fuel for compression ignition engines]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24236204">thread link</a>) | @airstrike
<br/>
August 21, 2020 | https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/ | <a href="https://web.archive.org/web/*/https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>The diesel engine, also known as the compression ignition (CI) engine, has been a workhorse of the modern energy economy for more than a hundred years.&nbsp;Its role in the coming sustainable energy economy will be determined by its ability to co-evolve with climate-friendly fuels.&nbsp;Two researchers from the National Institute of Advanced Industrial Science and Technology in Japan have now examined the fit between ammonia and the CI engine.&nbsp;</p><p>Pavlos Dimitriou and Rahat Javaid arrive at a two-part conclusion in their paper, “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sciencedirect.com/science/article/abs/pii/S0360319920300124" target="_blank">A review of ammonia as a compression ignition engine fuel</a>,” published in January in the <em>International Journal of Hydrogen Energy</em>. Part one is good news: “Ammonia as a compression ignition fuel can be currently seen as a feasible solution.”&nbsp;Part two is a dose of qualifying reality: to manage emissions of N2O, NOx, and unburnt NH3, “aftertreatment systems are mandatory for the adaptation of this technology,” which means that ammonia-fueled CI engines are likely to be feasible “only for marine, power generation and possibly heavy-duty applications where no significant space constraints exist.”</p><p>The paper provides a detailed and readable account of efforts over the last eight decades to develop a viable version of an ammonia-fueled CI engine.&nbsp;The authors state that, “to the best of [their] knowledge, this is the first review approach focusing entirely on ammonia utilisation for compression ignition.”&nbsp;A major challenge confronted by the development efforts derives from ammonia’s “poor combustion characteristics … such as high autoignition temperature, low flame speed, narrow flammability limits and high heat of vaporization.” They continue, “successful ammonia compression ignition operation could only be observed for engine designs that featured extremely high compression ratios from 35:1 to 100:1.”</p><p>To address this challenge, most researchers resorted to the expedient of co-combustion.&nbsp;With the addition of fuels like diesel, biodiesel, and dimethyl ether, “the combustion of ammonia … is a realistic conception, as the secondary fuel, with lower Autoignition temperature, can be used to trigger the combustion of the mixture.”&nbsp;Different researchers have used a variety of fuel ratios under a variety of conditions.&nbsp;Ammonia ratios as high as 95% have been achieved, but numbers in the range of 40 to 80% are more prevalent in the literature. Hydrogen has been used successfully as the complementary fuel.&nbsp;This includes hydrogen derived from on-board ammonia cracking, but the authors of one study determined that “the introduction of pure hydrogen [from an off-board source] seems to be the most promising in terms of emissions reduction and engine performance enhancement.”</p><p>The dual-fuel approach opens the door to CI for ammonia, but another challenge soon arises: when ammonia is burned as a CI fuel, it tends to produce problematic levels of nitrogen oxides and unburned ammonia. To compound the issue, NOx tends to be a product of high combustion temperatures and unburned ammonia of low temperatures – and there is no “sweet spot” temperature where neither species is a problem.&nbsp;</p><p>Contemporary researchers are attacking this problem with two methods.&nbsp;The first is with advanced fuel injection techniques.&nbsp;By injecting fuel at several points during the engine’s compression stroke, with fine control of the fuel increments, it is possible to achieve “simultaneous reduction of N2O and NH3 emissions in ammonia dual-fuel engines.”&nbsp;The second method is exhaust after-treatment.&nbsp;Selective catalytic reduction (SCR) technologies have been found that can reduce both NOx and unburned ammonia to acceptable levels, a result furthered by “the effect of ammonia in NOx reduction as observed in the modern after-treatment systems.”</p><p>The authors’ conclusion that ammonia is unlikely to become a major fuel for passenger cars will not come as a surprise to most members of the ammonia energy community.&nbsp;Ships, of course, are a different story.</p><p>Engine manufacturer MAN Energy Solutions expects to bring its dual-fueled maritime engine to market in 2024. (An <em>Ammonia Energy</em> <a href="https://www.ammoniaenergy.org/articles/man-ammonia-engine-update/">update on the MAN ammonia engine</a> appeared in January.)&nbsp;Success in the maritime realm will certainly encourage development of engines scaled for off-grid and back-up power generation.&nbsp;For other transportation applications, long the near-exclusive province of internal combustion, CI might have its hands full fighting off electrification via battery and fuel cell.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236204</guid>
            <pubDate>Fri, 21 Aug 2020 16:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But I was helping the compiler]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24235783">thread link</a>) | @aw1621107
<br/>
August 21, 2020 | https://pankajraghav.com/2020/08/16/RVO.html | <a href="https://web.archive.org/web/*/https://pankajraghav.com/2020/08/16/RVO.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Compilers are getting better with each release. Sometimes a noticeable difference can be observed in the assembly output for the same piece code in a different version of the same compiler (can be easily done via <a href="https://godbolt.org/">compiler explore</a>).</p>

<p>I have gotten into the practice of checking the assembly output lately to analyze the overhead of various implementations. Beware, sometimes it can get addictive. But I think it is a nice way of learning to read assembly and also be amazed at how clever the compilers are these days.</p>

<p>In this article, I am going to cover one such incident that happened when I was looking at the assembly output of a function during my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> implementation.</p>

<p>But the context of the problem first!</p>

<h2 id="the-magic-of-move-semantics">The magic of move semantics</h2>
<p>Move semantics was introduced in C++11. We can think of move semantics as a way of transferring ownership of an object. If you are really new to move semantics, consider the following example:</p>

<p>So your colleague has a document that you also want. We have two options here. The first option, you take that document to a copier, take a copy of the document for yourself, and return the original document to your colleague. The second option, assuming your colleague doesn’t need the document anymore, instead of throwing it away, your colleague can give it to you, thereby, saving paper.</p>

<p>Replace the document with a memory resource in a program, then the first option is doing a copy, and the second option is doing a move, where you transfer the ownership instead of wasting the resource.</p>
<h2 id="putting-what-i-learned-in-action">Putting what I learned in action</h2>
<p>While implementing my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> emulator, I saw an opportunity to replace an expensive copy operation into a cheap move operation (at least that is what I thought).</p>

<p>To give a bit of context: In each frame cycle, I had to return an array containing 2048 integers that will be used to draw the graphics on the screen. The pseudo-C++ code is shown below:</p>

<div><div><pre><code><span>// chip8.cpp</span>
<span>static</span> <span>constexpr</span> <span>display_size</span> <span>=</span> <span>2048</span><span>;</span>
<span>class</span> <span>Chip8</span> <span>{</span>
    <span>...</span> 
    <span>public</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>get_display_pixels</span><span>()</span> <span>{</span>
              <span>// Do some computation</span>
              <span>return</span> <span>gfx</span><span>;</span>
          <span>}</span>
    <span>...</span> 
    <span>private</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>gfx</span><span>{};</span>
<span>};</span>

<span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>This is what I assumed was going on when I did the call to <code>get_display_pixels()</code> member function:</p>
<ol>
  <li>The compiler <code>copies</code> the <code>gfx</code> private variable of the <code>Chip8</code> class to the return value of the <code>get_display_pixels()</code> member function.</li>
  <li>The compiler calls the <code>copy constructor</code> to copy the return value of the function call to the <code>disp_pixels</code> variable.</li>
</ol>

<p>So, I concluded that I could use a <code>move constructor</code> to transfer the contents to my local variable <code>disp_pixels</code> to avoid a copy in the second step as described above.</p>

<p>So I changed my code in the <code>main</code> function as follows:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>emulator</span><span>.</span><span>get_display_pixels</span><span>());</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>Before you get furious and stop reading the article further because what I assumed was completely wrong, I realized that too, and the rest of the article is about that.</p>

<p>As soon as I used a <code>std::move</code> as shown in my previous code snippet, I observed the compiler was generating more assembly code than my initial code without a <code>std::move</code>(with std::move: <a href="https://godbolt.org/z/WulpDX">link</a>, without std::move: <a href="https://godbolt.org/z/oU8Tq4">link</a>).</p>

<p>What went wrong? Hmm….</p>
<h2 id="nrvo-to-the-rescue">NRVO to the rescue</h2>
<p>NRVO stands for Named Return Value Optimization. It is a nice trick that the compiler uses to omit unnecessary copy or move if certain conditions are met. Compilers have been using this trick for a long time. If <code>NRVO</code> takes place in our function call, then effectively we just do one copy instead of two. Let’s see how it works.</p>

<p>Even though the function signature of <code>get_display_pixels</code> indicates that it does not take any parameters, the compiler will pass one extra parameter behind the scenes from the caller (initialization call of <code>disp_pixels</code> from <code>main.cpp</code>) to the callee (<code>get_display_pixels</code> function in <code>chip8.cpp</code>). The caller will allocate the memory for the return value and pass the address of that memory to the callee. The callee will use that memory to construct the object and copy the value of the private variable <code>gfx</code> (in this case). As the memory of the caller (<code>disp_pixels</code>) was used by the callee, there is no need to copy the return value again, thereby, saving one unnecessary copy/move operation.</p>

<p>We should see the assembly output to really understand how <code>NRVO</code> is happening under the hood. The assembly code from the caller side is as follows:</p>
<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span>
</code></pre></div></div>
<p>Before the function call, <code>rsi</code> and <code>rdi</code> registers are loaded with upper and lower bound of the memory address of the <code>disp_pixels</code> variable. And, the trimmed assembly output from the callee side is as follows:</p>

<div><div><pre><code><span>1</span>   <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span><span>:</span>
<span>2</span>   <span>push</span> <span>rbp</span>
<span>3</span>   <span>mov</span>  <span>rbp</span><span>,</span> <span>rsp</span>
<span>4</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>8</span><span>],</span> <span>rdi</span>
<span>5</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>16</span><span>],</span> <span>rsi</span>
<span>...</span>
</code></pre></div></div>
<p>As seen from the callee side, the <code>rdi</code> and <code>rsi</code> values are moved to the stack, and further operations are performed with that memory address. Pretty neat!</p>

<p>A <code>simple analogy</code> for <code>NRVO</code> I like to think of is when you are asking a friend to fill in water inside a water bottle, you would give your bottle to fill water from the tap directly. It would be inefficient to first fill the water in a temporary bottle and transfer the contents again to your bottle. In the C++ context, <code>bottle</code> is the <code>memory space</code> and the <code>water</code> it holds is the <code>return value</code>.</p>

<p>If we assume that the  <code>NRVO</code> will take place, then the most efficient way of writing my function call is:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>GCC and Clang even have an extra warning flag <code>-Wpessimizing-move</code> which detects when we are trying to use a <code>move</code> where compiler-generated NRVO is much more efficient.</p>

<p>Even though we can assume in many situations that a <code>NRVO</code> will take place, especially if optimizations are turned on, C++ standard does not guarantee <code>NRVO</code> in all situations<sup>1</sup>. But what if compiler does not perform a <code>NRVO</code>?</p>
<h2 id="lvalues-and-rvalues-and-all-other-value-categories-in-between">Lvalues and Rvalues (and all other value categories in between)</h2>
<p>Even though there are some <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2025r0.html">proposals</a> to guarantee <code>NRVO</code>, it is not yet guaranteed by the standard. As it is not guaranteed, should we explicitly indicate a move operation to save a copy just in case the compiler doesn’t do a <code>NRVO</code>? To answer that, I added the flag <code>-fno-elide-constructors</code> that disables copy elision (the super-set of NRVO) in our code, thereby, allowing to see what the compiler does otherwise.</p>

<p>I was surprised to see that compiler was still performing a <code>NRVO</code> for <code>C++17</code> standard with <code>-fno-elide-constructors</code> enabled. But this was not the case for <code>C++14</code>, the compiler generated different assembly with <code>-fno-elide-constructors</code> enabled. If someone knows the reason why this difference occurs between <code>C++17</code> and <code>C++14</code> even though <code>NRVO</code> is not guaranteed, please email me about it. Godbolt <a href="https://godbolt.org/z/hPW3rh">link</a>.</p>

<p>Let’s use <code>C++14</code> with <code>-fno-elide-constructors</code> flag to simulate the scenario where the compiler fails to apply <code>NRVO</code> so that we can check whether we needed to do something extra to avoid superfluous copies.</p>

<p>So I added <code>-fno-elide-constructors</code> to disable any <code>NRVO</code> to the final code of the previous section. The caller generated the following assembly code:</p>

<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display</span><span>()</span>
<span>6</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>7</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>8</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>9</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>10</span>  <span>call</span> <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;::</span><span>array</span><span>(</span><span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;&amp;&amp;</span><span>)</span>
</code></pre></div></div>

<p>As we can notice, the first 5 assembly instructions are the same as the version with NRVO enabled, and there are 5 more assembly instructions in this version as we disabled NRVO. The most important instruction we need to focus on is line number 10 where a <code>move constructor</code>(notice <code>&amp;&amp;</code> in the function signature). Wait, a <code>move constructor</code> is invoked? I did not use a <code>std::move</code> but the compiler decided to do it anyway. To really comprehend the reason, we need to understand <code>value categories</code> in C++.</p>

<p>In these two articles: <a href="https://eli.thegreenplace.net/2011/12/15/understanding-lvalues-and-rvalues-in-c-and-c">Understanding lvalues and rvalues in C and C++ </a> and <a href="http://eel.is/c++draft/basic.lval#1">basic.lval#1</a>, value categories are explained in detail<sup>2</sup>. In brief, quoting from the first article: “An lvalue (locator value) represents an object that occupies some identifiable location in memory. Rvalue is an expression that does not represent an object occupying some identifiable location in memory.”. Of course, there are more categories than just a <code>lvalue</code> and a <code>rvalue</code>. I would highly recommend reading both articles. Though you don’t need a perfect grasp of them to understand what comes later in this article. Let’s get back to our original example and analyze why the move constructor was called.</p>

<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>In the above code snippet, the function call to <code>get_display_pixels</code> belongs to the <code>rvalue</code> (more precisely a <code>prvalue</code>) category and it generates a temporary. The compiler can now safely <code>move</code> that temporary into the <code>disp_pixels</code> variable because that temporary will be destroyed anyway after this statement. If the type that is being returned does not have a move constructor (in our case <code>std::array</code> has a move constructor), then the compiler will call the <code>copy constructor</code>.</p>

<p>In principle, if any of the <code>moveable</code> types (standard or user-defined) is returned from a function by <code>value</code>, we can safely assume either <code>NRVO</code> or <code>move operation</code> will take place resulting in no superfluous copies for standard compilers that support <code>C++11</code> and above.</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pankajraghav.com/2020/08/16/RVO.html">https://pankajraghav.com/2020/08/16/RVO.html</a></em></p>]]>
            </description>
            <link>https://pankajraghav.com/2020/08/16/RVO.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24235783</guid>
            <pubDate>Fri, 21 Aug 2020 15:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Splitgraph Data Delivery Network – query over 40k public datasets]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 91 (<a href="https://news.ycombinator.com/item?id=24233948">thread link</a>) | @mildbyte
<br/>
August 21, 2020 | https://www.splitgraph.com/blog/data-delivery-network-launch | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#usage" as="#usage">Usage</a><ol><li><a href="#connecting" as="#connecting">Connecting</a></li><li><a href="#workspaces" as="#workspaces">Workspaces</a></li><li><a href="#running-queries" as="#running-queries">Running queries</a></li></ol></li><li><a href="#behind-the-scenes" as="#behind-the-scenes">Behind the scenes</a></li><li><a href="#future-and-roadmap" as="#future-and-roadmap">Future and roadmap</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Today, we are announcing the next step for Splitgraph: the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect"><strong>Splitgraph Data Delivery Network</strong></a>.</p><p>The Splitgraph DDN is a single SQL endpoint that lets you query over 40,000 public datasets hosted on or proxied by Splitgraph.</p><p>You can connect to it from most PostgreSQL clients and BI tools <strong>without having to install anything else</strong>. It supports all read-only SQL constructs, including filters and aggregations. It even lets you run joins across distinct datasets.</p><p>In this post, we will give you a quick introduction to the DDN as well as discuss how it works behind the scenes and our plan for its future.</p><section><h3 id="usage">Usage</h3><section><h4 id="connecting">Connecting</h4><p>The endpoint is at <code>postgresql://data.splitgraph.com:5432/ddn</code>. You will need a Splitgraph API key and secret to access it.</p><p>You don't need to install anything to use the endpoint. If you go to your Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">account settings</a>, you can generate a pair of credentials. You can then plug them into your SQL client.</p><p>If you're already using the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and had registered for Splitgraph before, you can check your <code>.sgconfig</code> file for the API keys. You can also upgrade your client to version 0.2.0 with <code>sgr upgrade</code> and run <code>sgr cloud sql</code> to get a libpq-compatible connection string.</p><p><a href="https://www.splitgraph.com/docs/getting-started/installation">Installing Splitgraph locally</a> will let you snapshot these datasets and use them in <a href="https://www.splitgraph.com/docs/concepts/splitfiles">Splitfiles</a>.</p><p>There are more setup methods available in <a href="https://www.splitgraph.com/docs/splitgraph-cloud/data-delivery-network">our documentation</a>. This includes connecting to Splitgraph with clients like DBeaver, BI tools like Metabase or Google Data Studio or even other databases through ODBC.</p></section><section><h4 id="workspaces">Workspaces</h4><p>When you connect to Splitgraph, your SQL client will show you some schemas. These are data repositories featured on our <a href="https://www.splitgraph.com/explore">explore page</a> as well as datasets that you upload to Splitgraph.</p><p>We call this feature "workspaces". It works by implementing the <a href="https://en.wikipedia.org/wiki/Information_schema" as="https://en.wikipedia.org/wiki/Information_schema">ANSI information schema</a> standard. We'll expand on workspaces more in the future. For example, we'll let you:</p><ul><li>bookmark repositories that you want to show up in your workspace</li><li>allow you to have multiple workspaces and manage access to them</li><li>search for Splitgraph repositories directly from your SQL client.</li></ul></section><section><h4 id="running-queries">Running queries</h4><p>You can run queries on Splitgraph images by referencing them as PostgreSQL schemata: <code>namespace/repository[:hash_or_tag]</code>. By default, we query the <code>latest</code> tag.</p><p>For example, if you want to query the <a href="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc" as="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"><code>cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc</code> repository</a>, proxied by Splitgraph to <a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc">Socrata</a>, you can run:</p><pre><code metastring=""><span>SELECT</span> <span>*</span> <span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations
</code></pre><p>We let you use SQL <code>SELECT</code> and <code>EXPLAIN</code> statements. You can use any SQL clauses, including group-bys, aggregations, filters and joins. Splitgraph pushes filters down to the origin data source.</p><p>This sample query that we used in our <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals">Metabase demo</a> runs a JOIN between two datasets:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    <span>"cambridgema-gov/covid19-cumulative-cases-by-date-tdt9-vq5y"</span><span>.</span>covid19_cumulative_cases_by_date cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>This will join the data between two distinct Socrata data portals (<a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc">Chicago, IL</a> and <a href="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y" as="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y">Cambridge, MA</a>).</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/2-dbeaver-join.png" alt="Splitgraph SQL endpoint JOIN query example"></p><p>We also support <a href="https://postgis.net/" as="https://postgis.net/">PostGIS</a>, letting you query and visualize geospatial data. For example, you can query the <a href="https://www.splitgraph.com/splitgraph/london_wards/" as="https://www.splitgraph.com/splitgraph/london_wards/">London ward boundary data</a> image as follows:</p><pre><code metastring=""><span>SELECT</span>
    name<span>,</span>
    gss_code<span>,</span>
    
    ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>4326</span><span>)</span><span>,</span>
    
    ST_Area<span>(</span>ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>3035</span><span>)</span><span>)</span> <span>/</span> <span>1000000</span> <span>AS</span> area_sqkm
<span>FROM</span>
    <span>"splitgraph/london_wards"</span><span>.</span>city_merged_2018
<span>ORDER</span> <span>BY</span> gss_code <span>ASC</span><span>;</span>
</code></pre><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/3-dbeaver-geodata.png" alt="PostGIS data on Splitgraph DDN"></p><p>There are more sample queries on our <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Connect page</a>.</p></section></section><section><h3 id="behind-the-scenes">Behind the scenes</h3><p>The Splitgraph Data Delivery Network is the result of all the work we've put into the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and the <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">Splitgraph Core</a> code over the past two years.</p><p>It would also have not been possible without some other open source technologies.</p><p>We use PostgreSQL foreign data wrappers. They let us perform query execution and planning across federated data sources. We wrote about <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> before: they're powerful and underused!</p><p>We manage connections using a fork of <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org">pgBouncer</a>, a PostgreSQL connection pooler. Our fork lets us perform authentication outside of PostgreSQL. We can issue and revoke API keys without having to manipulate database roles. Several inbound Splitgraph users can run queries as a single PostgreSQL user.</p><p>We also use pgBouncer to transform queries on the fly. We rewrite clients' introspection queries and let them reference Splitgraph images as PostgreSQL schemata.</p><p>Each client essentially operates within its own isolated virtual database. The obvious implementation of this would be spinning up one database per client. But our query transformations let us do this at a <strong>much lower infrastructure cost</strong>. We also use this feature to inspect and drop unwanted queries on the fly.</p><p>Finally, we use our own <code>sgr</code> client to orchestrate this. Splitgraph engines power the data delivery network. They manage foreign data wrapper instantiation and querying Splitgraph images via <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>. In the future, we will use Splitgraph's <a href="https://www.splitgraph.com/docs/concepts/objects">storage format</a> to snapshot remote datasets or cache frequent queries.</p></section><section><h3 id="future-and-roadmap">Future and roadmap</h3><p>There are a lot of directions we would like to pursue with Splitgraph.</p><p>You will be able to use Splitgraph to <strong>replace some of your data lake or ETL pipelines</strong> and query the data at source. This is similar to the idea of "data virtualization". But, unlike other software in this space, Splitgraph uses an open PostgreSQL procotol. This makes it immediately compatible with most of your BI tools and dashboards. It won't lock you into a proprietary query language.</p><p>We will soon have the ability to add <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a> to public or on-premises Splitgraph data catalogs. You will be able to query any dataset indexed in this catalog over the single SQL endpoint or our <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a>. You will be able to even use these datasets in <a href="https://www.splitgraph.com/concepts/splitfiles">Splitfiles</a>. This will let you define reproducible transformations on your data, enrich it with public datasets and track lineage.</p><p>You will be able to use Splitgraph as an <strong>SQL firewall and a rewrite layer</strong>. You won't need to use views to set up access policies for your data warehouse. Data consumers won't need to manage credentials to disjoint data silos. Splitgraph can inspect proxied queries and enforce granular access policies on individual columns. It will even be able to do PII masking and access auditing.</p><p>The single SQL endpoint is well suited for a <strong>data marketplace</strong>. Data vendors currently ship data in CSV files or other ad-hoc formats. They have to maintain pages of instructions on ingesting this data. With Splitgraph, data consumers will be able to acquire and interact with data directly from their applications and clients.</p></section><section><h3 id="conclusion">Conclusion</h3><p>Today, we launched the Splitgraph Data Delivery Network. It's a seamless experience of a single database with thousands of datasets at your fingertips, compatible with most existing clients and BI tools.</p><p>If you wish to try it out, you can get credentials to access it in less than a minute: just head on to the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">landing page</a>.</p><p>We're also building towards a <a href="https://www.splitgraph.com/about/company/private-cloud-beta">"Splitgraph Private Cloud" product</a> that will let setup your own private Splitgraph cluster, managed by us and deployed to the cloud region of your choice. <a href="mailto:support@splitgraph.com" as="mailto:support@splitgraph.com">Contact us</a> if you're interested!</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233948</guid>
            <pubDate>Fri, 21 Aug 2020 11:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Development of Warajevo: ZX Spectrum Emulator Made During the Bosnian War]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24233770">thread link</a>) | @krige
<br/>
August 21, 2020 | https://worldofspectrum.net/features/warajevo/Story.html | <a href="https://web.archive.org/web/*/https://worldofspectrum.net/features/warajevo/Story.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="Arial" size="3">
<hr><center><div>
<center><span color="#FFFFFF" size="+1"><b>(HI)STORY ABOUT DEVELOPING OF WARAJEVO</b></span></center>
</div></center><hr>
<span size="-1"><center>Best viewed in 800x600 resolution!</center></span>

<p>
Maybe this program is not too interesting in itself, but it is a fact
that this program comes from Bosnia and Herzegovina, from the city of
Sarajevo which has been surrounded for more than three years (click at the
picture below to learn more about surrounded Sarajevo). After reading this
story, you will understand why this emulator has such strange
name "Warajevo"...
</p>
<center><a href="http://www.saray.net/SurvivalMap/Index.html">
<img src="https://worldofspectrum.net/features/warajevo/surrmap.jpg" alt="Sarajevo Survival Map">
</a></center>
<p>
Even in our secondary school days, about ten years before, we began to build an
interest in computers thanks to the ZX Spectrum. For this reason, we are a
bit sentimentally tied with this computer. This computer reminds us of all of
the times when, in our neighbourhoods, the life was nice and normal.
</p>
<center><a href="http://www.geocities.com/SunsetStrip/2280/olympic.html">
<img src="https://worldofspectrum.net/features/warajevo/olimp.jpg" alt="Sarajevo before war">
</a></center>
<center>
<span size="-2">
Sarajevo, in time of 14th Winter olympic games (1984)
<br>
Panorama from the air, with olympic mountains in the background
</span>
</center>
<p>
When we bought AT 286 computers at the end of 1990, we did not forget our
Spectrums however. We had great interest when, in June 1991, we got a
Spectrum emulator, which, without underestimating anybody's work, had very
bad characteristics (it was slow, quite incompatible with the original
machine, with unpractical emulation of the tape recorder etc.). It's origin
is unknown to us (we suppose, in according to some newspapers, that the program
is from the Slovenia Republic, and that the author is Peter Kroselj), and when
starting it displays the copyright message '(C) 1991. Roman &amp; easy inc.'. When
the war started in our country, we wanted to remove the dark thoughts from our
heads as much as possible. So, in April 1993, we started the development of our
Spectrum emulator, symbolically called 'Warajevo Spectrum emulator' which should
have much better characteristics. We should mention that we were known as quite
good programmers, especially in assembly language.
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/loris.jpg" alt="Loris building">
</a>
<br>
<center>
<span size="-2">
Loris building - the first front line
<br>
(1 km far from Zeljko's house)
</span>
</center>
</td>
<td>
The program was developed in horrible conditions. The grenades fell
everywhere, there was little electrical power (at one time even the
hospitals didn't have power for two months!). When we had electricity it was
only for 2-3 hours during the night. However, we did not quit and caught
every moment when the electricity was on to develop the program. Zeljko worked at
home on his 80286/12 MHz, 1.44" floppy, 40 Mb hard disc, Hercules card and Citizen
180D printer. He used TASM assembler. It was very interesting waiting for days of
electricity. Samir worked mainly in army camp barack on 80286/16 MHz, 5,25" + 1.44"
floppy, 2400 bps modem, VGA mono monitor, WITHOUT HARD DISC because it crashed. The power
generator in the army camp was an improvised generator, with a voltage that varied from
150 V to 300 V! It was in fact car engine without carburator, connected to natural gas
pipeline. This car engine was tied with shunted electromotor giving about 30 kW for
100 rooms.
</td></tr>
</tbody></table>
<p>
It was often situation that when one user switch caffe aparat on, Samir's
computer resets itself. UPS? What is this??? As you can expect, such 'stable' voltage
distroyed Samir's hard disc...
</p>
<center>

</center>

<p>
Zeljko's task was mainly writting of the emulator kernel, and Samir's task was to write
conversion and tape file utilities. So, he used Turbo Pascal 5.5. First version of such
utility was called ZXTOOLS, and existed up to release 1.5. In this situation, we decided
that our tape file format will be compressed, as we had not enough diskettes, nor we
belived that we will ever have money for puchasing bigger hard disc.
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/vijecnica_detail.jpg" alt="Vijecnica inside - detail">
</a>
<center><span size="-2">
City hall inside - detail
</span></center>
</td><td>
As Zeljko has real Spectrum 128, we made cable for transfering Spectrum software using
RS232. During times when we was free of army activities, Samir visited the last Spectrum
software pirate in Sarajevo and borrowed casettes. But, this pirate was located in one
of the most dangerous places in the city, practically on the first front line. He had to
use a river bed (instead of streets) for moving, to skip continous sniper's fire. So, Samir
risked his life to bring up Spectrum software! Later he transfered programs using RS232,
mainly in the army camp.
</td></tr></tbody></table>
<p>
The summer of 1993 was the worst period during the whole Bosnian war, 1 kg of sugar had
price of even 60 DM, and about 3000-4000 grenades fall every day on the town. This was a
period when only miracle saved Sarajevo of fall. However, we progressed very well...
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/vijecnica_burning.jpg" alt="Burning Vijecnica">
</a>
<span size="-2"><center>
Burning city hall
</center></span>
</td><td>
Zeljko catched every second of presence of electrical power to finish the emulator
kernel, and Samir hed not even leave the army building during this period. While he
waited for a new battle tasks, he developed the compression algorythm. He spent more
than 30 days in developing algorythm, analysing of some archivers, optimizing
compression speed (it is still slow, but acceptable), and he worked mostly on paper,
because it was days mainly without any electric power, water and food.
Keep in mind that in this period we lost about 1 kg weekly!
<br>
</td></tr></tbody></table>
<br>
<center>

</center>
<p>
In November 1993, reading some newspapers that came from the enemy's territory, we got
some information about the emulator 'Z80', written by Gerton Lunter. The fact that we
didn't hear about Lunter's 'Z80' earlier is a fortune for today Warajevo users, because we
very probably would not even start this project if we have had information that a good
quality Spectrum emulator already exists. But, in even worse winter conditions,
we continued the development (in the rooms where we slept the water was frozen), hoping to
get this emulator to compare our program and his program.
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/tram_inside.jpg" alt="Tram inside">
</a>
<br>
<center>
<span size="-2">
Inside of a distroyed tramway
</span>
</center>
</td><td>
In 1994, one Samir's friend who worked with him in the army put his own hard disc
(40M) into the computer , and Samir developed ZXSHELL (the database program for the
emulator written in Clipper). In April 1994, the foundation Sorosh opened the first
electronic mail in Sarajevo. We sent a general request and in June 1994, we got
Lunter's emulator. From documentation we got information about many Spectrum emulators
around Europe, but we thought that our program was surely better than all the others,
except maybe Lunter's program. We think that it is a great success, considering the
conditions where the program was developed and the quality of Gerton's program. When
we contacted Gerton, he had the same opinion about it.
</td></tr></tbody></table>
</p><p>
The first public release of the Warajevo emulator was sent to the world at end of
1994 (release 1.0). Other releases made during war was 1.1 (March 1995), and 1.11
(May 1995). This was just a bugfixes of release 1.1 with slight improvements.
<br>
</p><center>

</center>
<p>
Dayton peace came (November 1995), and we was released from army. Release 1.2 was
prepared for uploading. It was 1.1 with a new design of utility ZXTOOLS. This release
was finished in December 1995. But, Samir decided to improve the emulator to be his
<a href="https://worldofspectrum.net/features/warajevo/diplom.zip">graduate thesis</a>
(Zeljko already finished study, he graduated in January 1995), and he
puchased 486SX-33 board, 4 Mb of RAM and 400 Mb hard disc. Zeljko continued development
on his old 286 machine, but Samir had now enough power to compile programs using extended
memory and we released version 1.5 (in July 1996) after Samir's graduating and getting
job. In this release, utilities ZXTOOLS and ZXSHELL are not separate tools. Instead, they
are integrated into the environment of the emulator.
</p>
<center>

</center>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/katedrala.jpg" alt="Cathedral">
</a>
<br>
<center>
<span size="-2">
Sarajevo cathedral
<br>
(rebuilded after the war)
</span>
</center>
</td><td>
Release 2.0 was developed in much better conditions. The war is finished, but the
economical situation is terrible. Our payments was under 50 DM. However, Zeljko
succeed to purchase faster computer, and he finally had goal to develop accurate speed
version of the Warajevo kernel. So, we worked on Pentium 133 MHz/1.2 Gb disc and Pentium
100 MHz/1.6 Gb hard disc, both
with 16 Mb of RAM, Sound Blaster cards and VGA graphic card (this is mainly our today
configuration too). First real-time release of Warajevo, release 2.0, was uploaded in
February 1998. As you can see, Warajevo 2.0 is
uploaded after a long delay (about nearly 1.5 year) from previous release. This is mainly consequence of
adaptation to post-war conditions. Finishing of the war brings a lot of new problems
which took a lot of our time, so developing of the emulator was stopped for a while...
</td></tr></tbody></table>
<p>
The last release of Warajevo is currently Warajevo 2.51. Recently, a number of new
emulators have appeared. Some of them are very good, especially X128 by James McKay,
and there are a number of emulators for the Windows platform (we want to point out ZX32
by Vaggelis Kapartzianis and MultiMachine by Paul Hodgson). However, we still think that
Warajevo 2.51. is the best emulator for pure DOS. We want to tell you that
the Warajevo emulator still does not have a good emulation of the video
system like in the ZX32 emulator (although it is much better than in release
2.0. which was a considerable improvment itself over release 1.5.), perfect
emulation of the bits 3 and 5 in the F register, emulation of the disc
interfaces, Multiface 128, AMX mouse, full emulation of the RS232 socket or
emulation of the Spectrum +3, which are supported in some other emulators.
However, we want to emphasize that Warajevo still has a lot of features which make it
unique. For more details see:
</p>
<p>
<a href="https://worldofspectrum.net/features/warajevo/Features.html">Features of the Warajevo emulator</a>
</p>
<p>
Well, what do you think, after this story, about today MS Windows programs that
require 100 Mb for relative simple task??? Obviously, the Spectrum times were the
best computer times. Nowadays, for playing a game in a PC you need a Pentium 200 MHz,
32 Mb of RAM and a fast graphic card. If you haven't got these requirements, you can`t
play the game. But, with the Spectrum everything was quite different. The Spectrum
wasn't upgradeable and the programmers had to make big efforts to develope a very good
game. And the games were also cheaper than the PC ones...
</p><center>

</center>
<center>

</center>
Between April 1995 and December 1997 we received E-MAIL messages from 28 countries, from
all 6 continents (Argentina, Australia, Austria, Canada, Czech, …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worldofspectrum.net/features/warajevo/Story.html">https://worldofspectrum.net/features/warajevo/Story.html</a></em></p>]]>
            </description>
            <link>https://worldofspectrum.net/features/warajevo/Story.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233770</guid>
            <pubDate>Fri, 21 Aug 2020 10:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Memory Fragmentation in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24232809">thread link</a>) | @tirumaraiselvan
<br/>
August 21, 2020 | https://www.well-typed.com/blog/2020/08/memory-fragmentation/ | <a href="https://web.archive.org/web/*/https://www.well-typed.com/blog/2020/08/memory-fragmentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Recently I’ve done a bit of work for <a href="https://hasura.io/">Hasura</a>, investigating some strange memory behavior in <a href="https://github.com/hasura/graphql-engine">graphql-engine</a>. When measuring memory usage, we can ask the operating system (OS) how much memory our process is using, but we can also use the GHC runtime system’s (RTS) heap profiler. After running a <code>graphql-engine</code> benchmark, the server’s memory usage reported by the OS was much higher than the “heap residency” reported by GHC’s heap profiler. This led us down a bit of a rabbit hole of understanding memory allocation and memory fragmentation in programs compiled with GHC.</p>
<p>In this blog post, we look at memory fragmentation in the Haskell heap and how it arises. We look at how fragmentation affects the discrepancy between heap residency reported by the RTS and memory usage reported by the OS. In particular, we focus on a pathological case of a program that makes use of pinned data and transitions from high heap residency to relatively low heap residency.</p>
<!-- more -->
<h3 id="memory-metrics">Memory Metrics</h3>
<p>On Linux there are multiple ways to measure memory usage of a process, but the one we’ll focus on is <em>virtual memory resident set size</em>, <code>VmRSS</code>. This can be sampled from <code>/proc/&lt;PID&gt;/status</code> where <code>&lt;PID&gt;</code> is a process ID. We won’t get into the details of this, but suffice it to say that we consider <code>VmRSS</code> the “true” memory usage of our Haskell program.</p>
<p><em>Heap residency</em> is a measurement taken by the runtime system’s heap profiler. It measures the size of all <em>live</em> data on the Haskell heap. <code>VmRSS</code> is always higher than heap residency. The reason is that heap residency is only a measure of <em>live</em> data on the Haskell heap while <code>VmRSS</code> is “all inclusive”. <a href="https://downloads.haskell.org/~ghc/8.10.2/docs/html/users_guide/profiling.html#actual-memory-residency">The GHC user’s guide</a> gives the following reasons for a higher <code>VmRSS</code>:</p>
<ol type="1">
<li>Overhead due to a profiled build. Each heap object uses an extra 2 words that are usually not counted in the heap profile.</li>
<li>Garbage collection. The copying collector (i.e.&nbsp;the default collector) makes a copy of all live unpinned data causing a peak in memory usage.</li>
<li>Thread stacks are not counted in the heap profile by default. Profiling with the <code>-xt</code> runtime system option includes stacks in the profile.</li>
<li>The program text itself, the C stack, any “non-heap” data (e.g.&nbsp;data allocated by foreign libraries and data allocated by the RTS itself), and <code>mmap()</code>‘d memory are not counted in the heap profile.</li>
</ol>
<p>In the following section is an example program which we focus on for this blog post. We’ll dive into the details shortly, but this program exhibits much higher <code>VmRss</code> than heap residency, so let’s consider why this might be:</p>
<ul>
<li><p>We’re not using a profiled build, so point 1 does not apply.</p></li>
<li><p>In general, stack usage can be significant and you should profile with <code>-xt</code> to diagnose this. The example program has negligible stack size, so point 3 also doesn’t apply.</p></li>
<li><p>The runtime system (RTS) is written in C and has it’s own stack and non-heap data, but this is negligible compared to the large amount of data we’re allocating on the Haskell heap. The program text is small and we’re also not calling any foreign code nor <code>mmap()</code>’ing any memory, so point 4 doesn’t apply.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
</ul>
<p>That leaves point 2 which is certainly applicable, but there is another reason that the above list does not mention: fragmentation.</p>
<p>Another metric from the RTS is the <em>heap size</em>. Heap size is an all inclusive metric of the Haskell heap. It includes fragmentation. <code>VmRSS</code> and heap size are about equal in our example program.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> Comparing <code>VmRSS</code> and heap size is a good way to check if the memory usage is truly in the Haskell heap or if there are other issues as listed in point 4.</p>
<h4 id="kilobyte-vs-kibibyte">Kilobyte vs Kibibyte</h4>
<p>As we’re closely counting bytes, we should make clear the awkward situation that memory is sometimes reported in base 10 units (e.g.&nbsp;kilobyte (kB) = 1000 bytes) and sometimes in base 2 units (e.g.&nbsp;kibibyte (KiB) = 1024 bytes). To make it worse, the “i” used in the symbols for base 2 units (e.g.&nbsp;“KiB”) is often omitted so they look just like the base 10 counterpart (e.g.&nbsp;“KB”). Confusingly, <code>/proc/&lt;PID&gt;/status</code> says “kB” but means “KiB”. The <code>eventlog2html</code> output says “G”, “M”, and “K” but means “GB”, “MB”, “kB”. The debugging output from the <code>-Dg</code> RTS option prints “MB” but means “MiB.”<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>With the exception of the heap profile graphs (generated with <code>eventlog2html</code>), all numbers in the blog post will be in base 2: gibibyte (GiB) = 1024 MiB, mebibyte (MiB) = 1024 KiB, and kibibyte (KiB) = 1024 bytes.</p>
<h3 id="example">Example</h3>
<p>Let’s consider the following application that allocates a list of <code>ByteString</code>s and then retains a smaller 1/10th subset of them:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>-- Main.hs</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>{-# LANGUAGE BangPatterns #-}</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span>{-# OPTIONS_GHC -Wall #-}</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span>import</span> <span>Control.Concurrent</span> (threadDelay)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span>import</span> <span>Control.DeepSeq</span> (force)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span>import</span> <span>Control.Monad</span> (forM_)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span>import</span> <span>qualified</span> <span>Data.ByteString</span> <span>as</span> <span>BS</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span>import</span> <span>System.Mem</span> (performGC)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span>import</span> <span>System.Environment</span> (getArgs)</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span>main ::</span> <span>IO</span> ()</span>
<span id="cb1-13"><a href="#cb1-13"></a>main <span>=</span> <span>do</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>  n <span>&lt;-</span> <span>read</span> <span>.</span> <span>head</span> <span>&lt;$&gt;</span> getArgs</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a>  <span>-- Allocate lots of ByteStrings (ByteStrings are backed with pinned data)</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>  <span>let</span> <span>!</span>superset <span>=</span> force <span>$</span> <span>take</span> n [BS.singleton x <span>|</span> x <span>&lt;-</span> <span>cycle</span> [<span>minBound</span><span>..</span><span>maxBound</span>]]</span>
<span id="cb1-18"><a href="#cb1-18"></a>  <span>putStrLn</span> <span>"1st Plateau start"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>  spin <span>3</span></span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>  <span>-- Extract only a small subset of the superset and allow superset to be</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>  <span>-- garbage collected. Specifically retain every 10th element.</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>  <span>let</span> subsetFactor <span>=</span> <span>10</span><span> ::</span> <span>Int</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>  <span>let</span> <span>!</span>subset <span>=</span> force <span>$</span> [x <span>|</span> (x, <span>1</span>) <span>&lt;-</span> <span>zip</span> superset (<span>cycle</span> [<span>1</span><span>..</span>subsetFactor])]</span>
<span id="cb1-25"><a href="#cb1-25"></a>  <span>putStrLn</span> <span>"2nd Plateau start"</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>  spin (<span>3</span> <span>*</span> subsetFactor)</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>  <span>-- Stop `subset` from being garbage collected by using it here.</span></span>
<span id="cb1-29"><a href="#cb1-29"></a>  <span>print</span> (<span>length</span> subset)</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span>-- Spin and allow heap profiler to collect samples.</span></span>
<span id="cb1-32"><a href="#cb1-32"></a><span>spin ::</span> <span>Int</span> <span>-&gt;</span> <span>IO</span> ()</span>
<span id="cb1-33"><a href="#cb1-33"></a>spin i <span>=</span> forM_ [<span>1</span><span>..</span>i] (\_ <span>-&gt;</span> threadDelay <span>1</span> <span>&gt;&gt;</span> performGC)</span></code></pre></div>
<p>Compile with <code>ghc -rtsopts -eventlog -debug Main.hs</code> and run with <code>./Main 10000000 +RTS -s -Dg -hT -l --disable-delayed-os-memory-return -RTS</code>. The <code>-hT -l</code> options produce an eventlog with a memory profile that we can be visualized with <code>eventlog2html</code>. The <code>-Dg</code> option prints garbage collector statistics to standard error. The <code>--disable-delayed-os-memory-return</code> option is explained later.</p>
<p>Consider what we expect when running a heap profile. The program should allocate some memory then spin a bit. Next, <code>superset</code> is garbage collected and we’re left with <code>subset</code>. We expect heap residency to drop to 1/10 of the size. After spinning for some more time the program will exit. That’s what we expect. Here is what the heap profile shows:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-heap-strip.svg"></p>
<p>The majority of memory is <code>PS</code>, <code>ARR_WORDS</code>, <code>:</code>, and <code>PlainPtr</code>. These are the type constructors found in a list of <code>ByteString</code>. <code>PS</code> is the <code>ByteString</code> constructor and <code>PlainPtr</code> and <code>ARR_WORDS</code> are internal to <code>ByteString</code>. We see that allocating <code>superset</code> results in about 1.04GiB (1.12GB) of heap residency corresponding to the first plateau in the heap profile between 27 and 39 seconds. After this, we take 1/10 of that data, <code>subset</code>, and allow the rest of <code>superset</code> to be garbage collected. Hence, we expect the heap residency to drop to about 1/10 of the size, 0.10GiB (0.11GB), but this is not what the profile shows! Heap residency decreases only to about 0.37GiB (0.4GB) and all of <code>ARR_WORDS</code> is unexpectedly retained.</p>
<p>This is not some subtle mistake in the code causing <code>ARR_WORDS</code> to be retained. This is in fact due to how the RTS handles pinned memory. Let’s look at the memory residency reported by the operating system. I sampled the <code>VmRSS</code> reported in <code>/proc/&lt;pid&gt;/status</code> every 0.01 seconds:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-vmrss-strip.svg"></p>
<p>The <code>VmRSS</code> has some discrepancies with the heap profile. The OS is reporting about 1.84GiB of memory at the first plateau. That’s almost 1.8 times more than the heap profile. In synch with the heap profile, between 40 and 61 seconds, there is a second plateau where <code>VmRSS</code> is about 1.5GiB. That’s about 4 times more than the heap profile. So not only is the <code>VmRSS</code> significantly higher than heap residency on the first plateau, but the discrepancy is much worse on the second plateau.</p>
<h3 id="the-heap">The Heap</h3>
<p>In order to make sense of the memory profile we need to understand the structure of GHC’s Haskell heap, how allocation works, and a bit about garbage collection. I’ll give a simplified overview of this. In particular I’m ignoring megablock/block groups, block descriptors, and am only considering the oldest garbage collector generation. I’m also assuming that the default copying garbage collector is in use.</p>
<h4 id="megablocks-blocks-and-objects">Megablocks, Blocks, and Objects</h4>
<p>The Haskell heap is made up of 1MiB “megablocks”. Within those are 4KiB “blocks”. Within those blocks are the actual data objects. Blocks are designated as exclusively containing either pinned or unpinned data. Here is an example of what the heap might look like in virtual memory space:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-legend.png"> <img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-example.png"></p>
<p>This is not to scale. In reality a megablock contains many more blocks, a block typically contains many more objects, and objects can vary in size. Notice that megablocks are not necessarily contiguous within virtual memory space. We call the unused gaps between megablocks “megablock level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/megablock-level-frag.png"></p>
<p>Likewise the unused gaps between blocks within megablocks is called “block level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/block-level-frag.png"></p>
<p>Dead objects within blocks are called “object level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/object-level-frag.png"></p>
<p>Note that some blocks have some unused space at the end because we have yet to add objects there or there was not enough space to add an object so the RTS allocated a new block instead. That extra space is called “slop” and we don’t count this as object level fragmentation. We mostly ignore slop for this post.</p>
<h4 id="pinned-data">Pinned Data</h4>
<p>What is pinned data? Thanks to referential transparency, the memory address of an object in Haskell is usually not important. This permits the RTS’s default copying garbage collector to move objects around in memory i.e.&nbsp;changing their memory location. In practice, we may want a chunk of memory that won’t be moved by the RTS. The most obvious example is when passing data to foreign code. The foreign code won’t be very happy if the RTS suddenly moves that data. As such, GHC supports the notion of “pinned” data which can be allocated via <code>GHC.Exts.newPinnedByteArray#</code> and similar variants. Pinned data is guaranteed not to be moved by the RTS. We refer to all other data as “unpinned”. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.well-typed.com/blog/2020/08/memory-fragmentation/">https://www.well-typed.com/blog/2020/08/memory-fragmentation/</a></em></p>]]>
            </description>
            <link>https://www.well-typed.com/blog/2020/08/memory-fragmentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232809</guid>
            <pubDate>Fri, 21 Aug 2020 07:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReMarkable MicroSD (2019)]]>
            </title>
            <description>
<![CDATA[
Score 363 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24232801">thread link</a>) | @devnonymous
<br/>
August 21, 2020 | http://www.davisr.me/projects/remarkable-microsd/ | <a href="https://web.archive.org/web/*/http://www.davisr.me/projects/remarkable-microsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>This page discusses how I added a microSD card to my <a href="https://arstechnica.com/gadgets/2017/12/remarkable-tablet-review-the-high-price-of-getting-that-paper-feeling/">reMarkable tablet</a>. I did this because I want to develop software for my rM without wearing out the internal eMMC. I chose an external card because I want to be able to swap them easily; it also makes backups faster.<br>
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/34.jpg" alt="Opened reMarkable tablet">




<h2><a name="opening">Opening the Case</a></h2>
<p>
The aluminum back panel is held to the plastic case with glue. I have 
not yet determined what melts this glue, or how to “properly” take the 
back off. I was able to lift it off, by starting slowly in a corner. 
Thereafter, I used a putty knife to slowly peel it away. The panel bent,
 but I was able to bend it mostly-flat again.
</p><p>
Next, there is a magnesium chassis screwed to the plastic case. 
Underneath the rubber feet are six silver screws. There are also XX 
black screws, that must be removed.
</p><p>
The epaper display is glued to the magnesium chassis; don’t try to pull 
it apart. There is also a white silicone-like substance around the edge 
of the epaper panel, which seems to disintegrate and flake off. I think 
it fills the gap, and perhaps offers a little waterproofing. This is 
non-replaceable. The screen can be pushed apart from the plastic 
chassis. It is held on the perimeter with plastic latches, so split it 
with a spudger and go slowly.
</p><p>
With the case off, the guts can be removed. There are five connectors to
 the logic board. In clockwise order starting at top-left: power button,
 touch panel, antenna, epaper display, USB daughterboard and buttons, 
and Wacom digitizer.
</p><p>
Finally, the logic board can be removed. It is held with six small 
screws and washers. Underneath the logic board is a plastic tape, a 
section of which must be removed around the SD pads.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/mmc-pads.jpg" alt="MMC solder pads">

<h2>
<a name="positioning">Positioning the Card</a>
</h2>
<p>
The bottom-right seemed like an appropriate placement for the card 
socket, because the area is already spacious. The right side was easier 
to route the cables to, because of the channels cut in the white plastic
 case. I reassembled the reMarkable 
prior to soldering, to ensure no bulges or deformities appered.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/placement.JPG" alt="Placing the microSD slot in the lower right corner">

<h2>
<a name="soldering">Soldering the Wires</a>
</h2>
<p>
Using ten 30 AWG wires and plenty of flux, I connected the board to the 
socket. The board indicates which pin is first. The board has a ninth 
pin, which is used for card-detect. This gets pulled low when a card is 
inserted.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/flatcable.JPG" alt="Wires underneath logic board">
<p>
To keep things as flat as possible, I used cellophane tape to mate the 
wires to the board. They feed out beneath the digitizer’s FFC cable in 
one beautiful ribbon. This also prevents elecrical contact to the grounded chassis.<br>
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/wires.JPG" alt="Wires on back">

<h2>
<a name="cutting">Cutting the Case</a>
</h2>
<p>
I drilled the SD slot by-hand with a rotary tool. Starting with a carving bit
 on the inside, I first hollowed out the area to give me a thin veneer, 
measured with a flashlight. Once I felt it was thin enough, I drilled 
from the front with a pointy sanding bit, and cut longitudinally.</p><p>
The magnesium chassis had a small section removed, which was easy with a
 tiny wire cutter. While it sacrifices a little
 bit of strength, it makes up for it in storage capacity.
</p><p>
After testing the fit once again, I fillited epoxy around the edge 
of the socket, gluing it down. I was careful not to get any inside the 
socket.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/externalshot.JPG" alt="microSD slot from the outside">

<h2>
<a name="loading">Loading the Kernel</a>
</h2>
<p>The stock rM kernel doesn't enable the SDHC1 slot, which is how these
 pins are designated in the device tree file. I recommend first being 
comforable with <a href="https://github.com/torwag/remarkableflash">this remarkable-flash guide</a>, the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_BSP_Porting_Guide_Linux.pdf">NXP porting guide for the i.MX6 processor</a>, and the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_Yocto_Project_User%27s_Guide_Linux.pdf">i.MX Yocto user guide</a>.<br>

</p>
  <p>The rM is a mostly-vanilla i.MX6 board (many share similaries, including the <a href="http://www.davisr.me/projects/remarkable-microsd/pico-imx6ul-emmc-hobbit-reva1-hardware-manual-20160328.pdf">Hobbitboard</a>).
 As such, it shares the same SDHC interface. What the microSD slot 
connects to, and what the stock kernel does not activate, is the SDHC1 
interface. This can be enabled in the device tree, and the kernel may be
 recompiled to include support for an SD card.<br>
  </p>
<p>
By default, the sdhc1 interface is disabled in the device tree. Enabling
 this is the first step. Copy the 
<code>arch/arm/boot/dts/zero-gravitas-factory.dts</code> over 
<code>arch/arm/boot/dts/zero-gravitas.dts</code>. Then, edit it to enable the sdhc1 
interface like shown in the diff below.
</p>
<pre> &amp;usdhc1 {<br>        pinctrl-names = "default", "state_100mhz", "state_200mhz";<br>        pinctrl-0 = &lt;&amp;pinctrl_usdhc1&gt;;<br>        pinctrl-1 = &lt;&amp;pinctrl_usdhc1_100mhz&gt;;<br>        pinctrl-2 = &lt;&amp;pinctrl_usdhc1_200mhz&gt;;<br>        bus-width = &lt;4&gt;;<br>        cd-gpios = &lt;&amp;gpio4 7 GPIO_ACTIVE_LOW&gt;;<br>        disable-wp;<br>        wp-controller;<br>        keep-power-in-suspend;<br>        enable-sdio-wakeup;<br>        no-1-8-v;<br>        /*disable-wp;*/<br>-       status = "disabled";<br>+       status = "okay";<br> };
</pre>


<p>Next, <code>make zero-gravitas_defconfig</code> and edit the <code>.config</code> file produced to include the following drivers.</p><pre>CONFIG_CFG80211=y
CONFIG_MAC80211=y
CONFIG_BRCMUTIL=y
CONFIG_BRCMFMAC=y
CONFIG_RTL_CARDS=y
CONFIG_BATTERY_BQ27XXX=y
CONFIG_BATTERY_BQ27XXX_I2C=y
CONFIG_USB_ACM=y
CONFIG_USB_F_ACM=y
CONFIG_USB_U_SERIAL=y
CONFIG_USB_CDC_COMPOSITE=y
CONFIG_CRYPTO_AEAD=y
CONFIG_CRYPTO_GF128MUL=y
CONFIG_CRYPTO_NULL=y
CONFIG_CRYPTO_CCM=y
CONFIG_CRYPTO_GCM=y
CONFIG_CRYPTO_SEQIV=y
CONFIG_CRYPTO_CTR=y
CONFIG_CRYPTO_GHASH=y
CONFIG_CRYPTO_ARC4=y
</pre>
<p>
Once done, rebuild the Linux kernel with <code>make</code>. Copy the artifacts to the rM's <code>/boot</code> directory: <code>arch/arm/boot/dts/zero-gravitas.dtb</code> and <code>arch/arm/boot/zImage</code>. I have included my artifacts <a href="http://www.davisr.me/projects/remarkable-microsd/boot.tar">here</a> for posterity, but it is foolish to install a kernel that someone else compiled.<br>
</p><p>
Reboot the rM, to make sure xochitl still runs. Then, check <code>dmesg | grep
 ‘mmc0’</code> to ensure the card was detected, and double-check it with <code>fdisk 
-l</code>. Partition your card as you like, then change the /etc/fstab option 
to mount that partition at /home.
</p>
<pre>root@reMarkable:~# dmesg | grep mmc0
[    2.091218] mmc0: SDHCI controller on 2190000.usdhc [2190000.usdhc] using DMA
[    2.377570] mmc0: new high speed SDXC card at address aaaa
[    2.391939] mmcblk0: mmc0:aaaa SC200 183 GiB 
</pre>
<pre>#/dev/mmcblk1p7 /home auto defaults,nofail 1 2
/dev/mmcblk0p7 /home auto defaults,nofail 1 2
</pre>
<p>
Reboot, and bask in the increased storage capacity.
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/storage-screen.png" alt="Storage screen showing 179 GB free">

<h2>
<a name="notes">Ending Notes</a>
</h2>
<ul>
<li>Now, the aluminum back is held on with gaffer tape. I am afraid to glue it shut, in case I want to access the guts again.
</li><li>Maybe the white stuff that came out around the bezel can be replaced with calk</li><li>I wish I had used multicolor wires, because it was difficult following them with my eyes.
</li><li>I didn’t cut close enough to the top of the plastic case, and 
so my SD slot is taller than it needs to be, but it isn't very 
noticable. I shimmed the extra vertical space with a folded up business 
card for a tighter fit.
</li><li>Before using solid-core wirewrap wire, I tried making my own 
ribbon cable with magenet wire and masking tape. This didn’t work well, 
because the enamel was hard to remove from just the ends, and the 
masking tape was too thick. The wirewrap wire turned out much nicer.
</li><li>Technically, I think the IMX needs to be changed too (and 
re-wrote over /dev/mmcblk1boot0) but I didn’t do this, and it seems to 
work alright. I'm fine using it just for the data partition so my OS updates work.
</li>
<li>I am glad this article has created encouragement from other people. I
 would like to extend an offer: if you would like a microSD card in your
 rM, and are willing to let me install one with the possibility of it 
not coming out exactly perfect (i.e. someone who finds ultimate use of 
rM in its utility, not pristine beauty) I would like to refine this 
process. One thing could be to install an internal card using quality 
flash media. I would like to know how many people could go for something
 like that, and if there could be a market doing that kind of thing. I 
will soon have installed my own CNC machine, and can practice doing this
 modification better, eventually charging for the service.<br>
</li>
</ul>

<h2><a name="images">More Images</a></h2>
<img src="http://www.davisr.me/projects/remarkable-microsd/backpanel.jpg" alt="Back panel">
<img src="http://www.davisr.me/projects/remarkable-microsd/connectors.jpg" alt="Connectors">
<img src="http://www.davisr.me/projects/remarkable-microsd/cracking-open.jpg" alt="Splitting the case open">
<img src="http://www.davisr.me/projects/remarkable-microsd/dontpullscreen.jpg" alt="Don't pull the screen like this">
<p>Don't peel the screen off!</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/openback.jpg" alt="Open back">
<img src="http://www.davisr.me/projects/remarkable-microsd/split-chassis.jpg" alt="Split chassis">

</article></div>]]>
            </description>
            <link>http://www.davisr.me/projects/remarkable-microsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232801</guid>
            <pubDate>Fri, 21 Aug 2020 07:20:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Hash Tables: understanding dictionaries]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24232752">thread link</a>) | @mastro35
<br/>
August 21, 2020 | http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/ | <a href="https://web.archive.org/web/*/http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://imgs.xkcd.com/comics/password_strength.png" alt="teaser"></p>

<p>Hi guys, have you ever wondered how can Python dictionaries be so fast and reliable? The answer is that they are built on top of another technology: <strong>hash tables</strong>.</p>

<p>Knowing how Python hash tables work will give you a deeper understanding of how dictionaries work and this could be a great advantage for your Python understanding because dictionaries are almost everywhere in Python.</p>

<h2 id="hash-functions">Hash Functions</h2>

<p>Before introducing hash tables and their Python implementation you have to know what is a hash function and how it works.</p>

<p>A hash function is a function that can map a piece of data of any length to a fixed-length value, called <strong>hash</strong>.</p>

<p>Hash functions have three major characteristics:</p>

<ol>
  <li>They are <strong>fast to compute</strong>: calculate the hash of a piece of data have to be a fast operation.</li>
  <li>They are <strong>deterministic</strong>: the same string will always produce the same hash.</li>
  <li>They produce <strong>fixed-length</strong> values: it doesn’t matter if your input is one, ten, or ten thousand bytes, the resulting hash will be always of a fixed, predetermined length.</li>
</ol>

<p>Another characteristic that is quite common in hash functions is that they often are <strong>one-way functions</strong>: thanks to a voluntary data loss implemented in the function, you can get a hash from a string but you can’t get the original string from a hash. This is not a mandatory feature for every hash functions but becomes important when they have to be cryptographically secure.</p>

<p>Some popular hash algorithms are <a href="https://en.wikipedia.org/wiki/MD5">MD5</a>, <a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a>, <a href="https://en.wikipedia.org/wiki/SHA-2">SHA-2</a>, <a href="https://it.wikipedia.org/wiki/NTLM">NTLM</a>.</p>

<p>If you want to try one of these algorithms by yourself, just point your browser to https://www.md5online.org, insert a text of any length in the textbox, click the <code>crypt</code> button and get your 128bit MD5 hash back.</p>

<h2 id="common-usages-of-hashes">Common Usages of Hashes</h2>

<p>There are a lot of things that rely on hashes, and hash tables are just one of them. Other common usages of hashes are for cryptographic and security reasons.</p>

<p>A concrete example of this is when you try to download open-source software from the internet. Usually, you find also a companion file that is the signature of the file. This signature is just the hash of the original file and it’s very useful because if you calculate the hash of the original file by yourself and you check it against the signature that the site provides, you can be sure that the file you downloaded hasn’t have tampered.</p>

<p>Another common use of hashes is to store user passwords. Have you ever asked yourself why when you forget the password of a website and you try to recover it the site usually lets you choose another password instead of giving back to you the original one you chose? The answer is that the website doesn’t store the entire password you choose, but just its hash.</p>

<p>This is done for security reasons because if some hacker got the access to the site’s database, they won’t be able to know your password but just the hash of your password, and since hash functions are often one-way functions you can be sure that they will never be able to get back to your password starting from the hash.</p>

<h2 id="the-python-hash-function">The Python <code>hash()</code> Function</h2>

<p>Python has a built-in function to generate the hash of an object, the <code>hash()</code> function.
This function takes an object as input and returns the hash as an integer.</p>

<p>Internally, this function invokes the <code>.__hash__()</code> method of the input object, so if you want to make your custom class hashable, all you have to do is to implement the <code>.__hash__()</code> method to return an integer based on the internal state of your object.</p>

<p>Now, try to start the Python interpreter and play with the <code>hash()</code> function a little bit. For the first experiment, try to hash some numeric values:</p>

<pre><code>&gt;&gt;&gt; hash(1)
1
&gt;&gt;&gt; hash(10)
10
&gt;&gt;&gt; hash(10.00)
10
&gt;&gt;&gt; hash(10.01)
230584300921368586
&gt;&gt;&gt; hash(-10.01)
-230584300921368586
</code></pre>

<p>If you are wondering why these hashes seems to have different length remember that the Python <code>hash()</code> function returns <strong>integers</strong> objects, that are always represented with 24 bytes on a standard 64 bit Python 3 interpreter.</p>

<p>As you can see, by default the hash value of an integer value is the value itself. Note that this works regardless of the type of the value you are hashing, so the integer <code>1</code> and the float <code>1.0</code> have the same hash: <code>1</code>.</p>

<p>What’s so special about this? Well, this shows what you learned earlier, that is that hash functions are often one-way functions: if two different objects may have the same hash, it’s impossible to do the reverse process starting from a hash and going back to the original object. In this case, the information about the type of the original hashed object has gone lost.</p>

<p>Another couple of interesting things you could note by hashing numbers is that decimal numbers have hashes that are different from their value and that negative values have negative hashes. But what happens if you try to hash the same number you got for the decimal value? The answer is that you get the same hash, as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; hash(0.1)
230584300921369408
&gt;&gt;&gt; hash(230584300921369408)
230584300921369408
&gt;&gt;&gt; hash(0.1) == hash(230584300921369408)
True
</code></pre>

<p>As you can see, the hash of the integer number <code>230584300921369408</code> is the same as the hash of the number <code>0.1</code>. And this is perfectly normal if you think of what you learned earlier about hash functions because if you can hash any number or any string getting a fixed-length value since you can’t have infinite values represented by a fixed-length value, that implies that there must be duplicated values. They exist in fact, and they are called <strong>collisions</strong>. When two objects have the same hash, it is said that they collide.</p>

<p>Hashing a string is not much different from hashing a numeric value. Start your Python interpreter and have a try hashing a string:</p>

<pre><code>&gt;&gt;&gt; hash("Bad Behaviour")
7164800052134507161
</code></pre>

<p>As you can see a string is hashable and produce a numeric value as well but if you have tried to run this command you could see that your Python interpreter hasn’t returned the same result of the example above. That’s because starting from Python 3.3 values of strings and bytes objects are <strong>salted</strong> with a random value before the hashing process. This means that the value of the string is modified with a random value that changes every time your interpreter starts, before getting hashed. If you want to override this behaviour, you can set the <code>PYTHONHASHSEED</code> environment variable to an integer value greater than zero before starting the interpreter.</p>

<p>As you may expect this is a security feature. Earlier you learned that websites usually store the hash of your password instead of the password itself to prevent an attack to the site’s database to stole all the site passwords. If a website stores just the hash as it is calculated it could be easy for attackers to know what was the original password. They just need to get a big list of commonly used passwords (the web is full of these lists) and calculate their corresponding hash to get what is usually called <strong>rainbow tables</strong>.</p>

<p>By using a rainbow table the attacker may not be able to get <strong>every</strong> password in the database, still being able to steal a <strong>vast majority of them</strong>. To prevent this kind of attack, a good idea is to <strong>salt</strong> the password before hashing them, which is modifying the password with a random value before calculating the hash.</p>

<p>Starting from Python 3.3 the interpreter by default salt every string and bytes object before hashing it, preventing possible DOS attacks as demonstrated by Scott Crosby and Dan Wallach on <a href="https://static.usenix.org/event/sec03/tech/full_papers/crosby/crosby_html/">this 2003 paper</a>.</p>

<p>A DOS attack (where DOS stands for Denial Of Service) is an attack where the resources of a computer system are deliberately exhausted by the attacker so that the system is no longer able to provide service to the clients. In this specific case of the attack demonstrated by Scott Crosby, the attack was possible flooding the target system with a lot of data whose hash collide, making the target system use a lot more of computing power to resolve the collisions.</p>

<h2 id="python-hashable-types">Python Hashable Types</h2>

<p>So at this point, you could wonder if any Python type is hashable.
The answer to this question is no, by default, just immutable types are hashable in Python. In case you are using an immutable container (like a tuple) also the content should be immutable to be hashable.</p>

<p>Trying to get the hash of an unashable type in Python you will get a <code>TypeError</code> from the interpreter as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; hash(["R","e","a","l","P","y","t","h","o","n"])
Traceback (most recent call last):
 File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: unhashable type: 'list'
</code></pre>

<p>However, every custom defined object is hashable in Python and by default its hash is derived from it’s id. That means that two different instance of a same class, by default have different hashes, as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; class Car():
...     velocity = 0
...     direction = 0
...     damage = 0
...
&gt;&gt;&gt; first_car = Car()
&gt;&gt;&gt; second_car = Car()
&gt;&gt;&gt; hash(first_car)
274643597
&gt;&gt;&gt; hash(second_car)
274643604
</code></pre>

<p>As you can see, two different instances of the same custom object by default have different hash values. However, this behavior can be modified by implementing a <code>.__hash__()</code> method inside the custom class.</p>

<h2 id="hash-tables">Hash Tables</h2>

<p>Now that you know what a hash function is, you can start examining hash tables. A hash table is a data structure that allows you to store a collection of key-value pairs.</p>

<p>In a hash table, the key of every key-value pair must be hashable, because the pairs stored are indexed by using the hash of their keys. Hash tables are very useful because the average number of instructions that are necessary to lookup an element of the table is independent of the number of elements stored in the table itself. That means that even if your table grows ten or ten thousand times, the overall speed to look up a specific element is not affected.</p>

<p>A hash table is typically implemented by creating a variable number of <strong>buckets</strong> that will contain your data and indexing this data by hashing their keys. The hash value of the key will determine the correct bucket to be used for that …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/">http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/</a></em></p>]]>
            </description>
            <link>http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232752</guid>
            <pubDate>Fri, 21 Aug 2020 07:05:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pilo: Raspberry Pi-Powered Lights-Out Remote Server Management]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24232066">thread link</a>) | @gilad
<br/>
August 20, 2020 | https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://zach.bloomqu.ist/assets/pilo-naked.jpg" alt="Pilo board before final tape-up"> <small>The completed Pilo controller, before final installation. The USB capture card and Arduino Nano USB serial are soldered to the underside of the 3B+.</small></p> <p>Like many geeks, I have a â€œhome serverâ€� made from off-the-shelf, consumer-grade PC parts, from which I run my weekend programming projects, game servers for friends, this website, and so on. Recently, I had a power event at the house that caused the server to reboot. When the power came back on, the server booted, but it was stuck at the boot screen waiting for me to enter the disk decryption passphrase!</p> <p>Luckily, I was at home and asleep at the time. Once I woke up and realized something was amiss, I was able to plug in a keyboard and enter the passphrase. But this event got me thinking - what if I wasnâ€™t home at the time? What if I was in another country? What if someday, I move this server outside of my house and need to regularly access the physical screen and keyboard?</p> <p>In the â€œreal serverâ€� world, the solution to this is known as <a href="https://en.wikipedia.org/wiki/Out-of-band_management">â€œlights-out managementâ€� (LOM)</a>. Every major server manufacturer has their own flavor of this, such as HPâ€™s iLO (Integrated Lights-Out). There are even industry standards like <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a> that define common interfaces for LOM implementations. Commonly supported functions for LOM systems include:</p> <ul> <li>Controlling keyboard and mouse input</li> <li>Controlling power button status (so you can restart, shutdown, force offâ€¦)</li> <li>Seeing the raw video output from the motherboard (even pre-boot - even for BIOS)</li> <li>Mounting ISOs as disks</li> </ul> <p>I decided to make my own Raspberry Pi-based LOM that can do some of these things, to help decrease my stress next time I leave my house for an extended period of time. Iâ€™d like to introduce Pilo - â€œPi Lights-Outâ€�.</p> <blockquote> <p>Note: This post describes how I arrived at the final design of this system. If you just want the instructions for setting this up on your own, start reading at â€œTutorialâ€�.</p> </blockquote> <h2 id="building-the-keyboard-controller">Building the Keyboard Controller</h2> <p>When I started looking for ways to use my Pi to send keyboard commands to a computer, the problem I discovered was that all of the existing methods rely on <a href="http://www.isticktoit.net/?p=1383">using the Raspberry Pi Zero as a USB host</a>, which disables using the onboard USB port for other purposes. Additionally, this method does not work on other boards, like the Raspberry Pi 3B+. This was problematic, because I wanted to use the 3B+ due to the on-board Ethernet - that, and the fact that I had one kicking around from a previous <a href="https://pi-hole.net/">Pi-hole</a> deployment.</p> <p>A more suitable solution would be to emulate a keyboard via the GPIO pins of the Pi. This would theoretically not affect existing USB devices, and could be used on any model of Pi, not just the Pi Zero. So I started looked into trying to <a href="http://www.jargon.net/jargonfile/b/bitbang.html">â€œbit-bangâ€�</a> the USB Human Interface Device protocol via the Piâ€™s GPIO pins.</p> <p>I pretty quickly hit a dead end with that. There are <a href="https://raspberrypi.stackexchange.com/q/82850/100317">many</a>, <a href="https://www.element14.com/community/thread/38228/l/raspberry-pi-usb-output-from-gpio">many</a> existing discussions on the web about bit-banging the USB protocol on the Pi. The consensus seems to be that the Raspberry Piâ€™s GPIO is too slow to emulate USB, and even if it <em>could</em> output bits fast enough to act as a USB device, the implementation would be extremely buggy because of the non-real-time nature of the Linux OS (<a href="https://raspberrypi.stackexchange.com/a/87865/100317">read more</a>).</p> <p>But USB isnâ€™t the only way to send keypresses to a computer - almost a decade before the USB standard was a twinkle in Compaqâ€™s eye, IBM was using the <a href="https://en.wikipedia.org/wiki/PS/2_port">PS/2</a> standard (not to be confused with the <a href="https://en.wikipedia.org/wiki/PlayStation_2">PS2</a>) to connect mice and keyboards to PCs. Itâ€™s still not feasible to use the Pi to bit-bang the PS/2 protocol, but we can use an Arduino as a daughterboard, and the <a href="https://github.com/Harvie/ps2dev"><code>ps2dev</code></a> library can handle the nitty-gritty of the serial protocol for PS/2.</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-pin-jam.jpg" alt="Left: Arduino soldered up. Right: Breadboard jumpers jammed into the PS/2 port"></p> <p>So thatâ€™s what I did. The Arduino Nano pictured on the left is plugged directly into the PS/2 combo port on the back of the motherboard (ignore the unused 5V wire, red). Originally, I planned on cutting the end off of a PS/2 cable and making it all nice, but the Goodwill near me didnâ€™t have any PS/2 junk and it turns out that breadboard wires just fit oh-so-snugly into the DIN holes. So this is how itâ€™s gonna be.</p> <p>The Arduino Nano is flashed with a <a href="https://create.arduino.cc/editor/flotwig__/093ababe-c724-476f-aeb8-a76b239bf192/preview">short program</a> that makes it act as a dumb pipe which blindly shuttles bytes from the Arduinoâ€™s USB serial port to the PS/2 connection on the motherboard. This means that all of the logic for which keyboard commands should be sent has to be written on the Pi-side, which is nice, because it means that we should never have to re-flash the Arduino to update some keyboard logic.</p> <p>Note that currently, Pilo is only built to control keyboard input, since it is oriented towards server use. It would be possible to add PS/2 mouse output with no additional hardware, just 2 or 3 wires for PS/2 mouse CLK, DATA, and GND (unless using combo port). The <a href="https://github.com/Harvie/ps2dev"><code>ps2dev</code></a> library contains functions for mouse control as well.</p> <h3 id="power-control-via-ps2">Power Control via PS/2</h3> <p>Originally, I thought I was going to have to wire a relay to the motherboardâ€™s RESET pin to allow Pilo to control the computerâ€™s power. This is the approach that <a href="https://github.com/Fmstrat/diy-ipmi"><code>diy-ipmi</code></a>, another similar project, uses. However, while researching the keyboard controller, I rediscovered a long-lost secret of the PS/2 standard: the â€œACPI keysâ€�. ACPI, or the Advanced Configuration and Power Interface, is a set of power management standards for PCs. The PS/2 standards define <code>Power</code>, <a href="https://ux.stackexchange.com/q/83200/117790"><code>WakeUp</code></a>, and <code>Sleep</code> key scancodes that can be used to control the power status of the PC - just like the power button on the front of the box, a short-press of the <code>Power</code> key requests the OS to shutdown. However, on my motherboard, a long-press of <code>Power</code> does <em>NOT</em> seem to force the power off.</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-bios-s5.png" alt="A screenshot of the BIOS with the ACPI S5 Wake-On-Keyboard option selected"></p> <p>Almost all BIOS support using the ACPI keys to power the system on from a powered down state. Above is what the option looks like in my BIOS (in ACPI, the powered-off state is known as â€œS5â€�). With this option enabled, sending the <code>Power</code> scancode will boot the computer up from an off state.</p> <p>So, now the Arduino has two responsibilities in Pilo: to send regular keypresses to the computer, and to send power commands to the computer. This saves us from having to install a relay for the motherboardâ€™s RESET pin.</p> <h2 id="capturing-video-output">Capturing Video Output</h2> <p>My server has a GPU with HDMI output, so I decided to use a USB HDMI capture card to get the video feed for Pilo. I found one on <a href="https://smile.amazon.com/gp/product/B08BZ52Q65/">Amazon for about $15</a>. When connected to the Pi, it acts as a regular USB webcam, available under <code>/dev/videoX</code>.</p> <p>Before this project, I had no experience with streaming video over the web. I decided to use <a href="https://www.linux-projects.org/uv4l/"><code>uv4l</code></a> (â€œUserspace Video4Linuxâ€�)â€™s <a href="https://www.linux-projects.org/home/documentation/uv4l-server/"><code>uv4l-server</code></a> component to set up an HTTP video server. <code>uv4l</code> makes it easy to set up a simple MJPEG stream, which is the goofiest possible video stream - each frame of the stream is a full JPEG image, sent to you in real time. As you can imagine, itâ€™s not the lightest on bandwidth, but it is easy to embed - all web browsers support embedding it in an <code>&lt;img&gt;</code> tag: <code>&lt;img src="/stream.mjpeg"/&gt;</code></p> <p>I configured the <code>uv4l-server</code> to only listen on <code>localhost</code>, with the idea that I could reverse-proxy connections to the video stream to provide security.</p> <h2 id="creating-the-application">Creating the application</h2> <p>For the Pilo interface, I decided to go with a web app, instead of something like VNC, or the actual IPMI protocol. This was mostly due to my background in web development, and the fact that the app can be accessed with a web browser, something every computer has installed. Here is a short video showing the completed Pilo app in action:</p> <video controls="" autoplay="" muted="" loop="" src="https://zach.bloomqu.ist/assets/pilo-demo.webm" type="video/webm"> <p>Your browser doesn't support WEBMs. <a href="https://zach.bloomqu.ist/assets/pilo-demo.webm">Download the video instead.</a></p> </video> <p>You can find the <a href="https://github.com/flotwig/pilo">GitHub repo for Pilo here</a>. It consists of two major components:</p> <ul> <li><a href="https://github.com/flotwig/pilo/tree/master/frontend"><code>frontend</code></a> - uses vanilla HTML/CSS/JS to display the interface, translate keypresses, and communicate with the server via websockets</li> <li><a href="https://github.com/flotwig/pilo/tree/master/server"><code>server</code></a> - the HTTP server, written in Node.js. Authenticates requests using HTTP basic auth, communicates with the keyboard controller via the <code>serialport</code> library, and manages reverse-proxying of the <a href="https://www.linux-projects.org/home/documentation/uv4l-server/"><code>uv4l-server</code></a> video stream</li> </ul> <p>There are also end-to-end tests in the <a href="https://github.com/flotwig/pilo/tree/master/e2e"><code>e2e</code></a> folder which use <a href="https://cypress.io/">Cypress</a> to test the application in real web browsers. This runs against Firefox and Chrome on every commit to CI via a <a href="https://github.com/flotwig/pilo/blob/master/.github/workflows/test.yml">GitHub Actions workflow</a>.</p> <p>The <a href="https://github.com/flotwig/pilo#pilo"><code>README</code></a> contains information on building and testing the project if you are interested in contributing. Built packages are also published to <code>npm</code> for production use.</p> <h2 id="packaging-the-pilo">Packaging the Pilo</h2> <p>One of my goals when building Pilo was to make it small enough to fit inside of my server case. Check out these photos to see how it fit in:</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-in-server.jpg" alt="Left: Before Pilo. Right: After Pilo."> <small>Left: Server case before embedding the Pilo. Right: Server case after embedding the Pilo. HDMI, Ethernet, and micro-USB power are routed through the left-most PCI-E slot, while PS/2 is routed through the I/O shield in the top-right. The Pilo itself sits atop a ledge in the bottom-right of the image.</small></p> <p>Here are some pictures of how the final assembly was made:</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-assembly.jpg" alt="Outer photo: Pi with USBs soldered on. Inner: Taped-up package. "> <small>Outer photo: Pi with the USB devices <a href="https://raspberrypi.stackexchange.com/a/62678/100317">soldered on to the underside</a> to save space. Inset photo: Final package taped up and ready for install, with PS/2 cable coming out. Hot glue and tape make me the solderer I ainâ€™t.</small></p> <p>The completed package fits within a bounding box only slightly larger than the Pi itself, about 88mm x 60mm x 20mm, which means the Pilo can fit conveniently into a standard 3.5â€� hard drive bay.</p> <h2 id="tutorial">Tutorial</h2> <h3 id="parts-list">Parts List</h3> <ul> <li>Raspberry Pi 3B+ ($25 at <a href="https://www.microcenter.com/product/505661/Raspberry_Pi_3_B_Plus?src=raspberrypi">MicroCenter</a>, $35 everywhere else) <ul> <li>Or other micro linux computer - even a Pi Zero could work, but youâ€™d be using WiFi, and youâ€™d need a USB hub for the Arduino serial, or set up the Arduino serial via GPIO</li> </ul> </li> <li>Arduino Nano (<a href="https://smile.amazon.com/gp/product/B015MGHH6Q/">Amazon</a> has them at $16.99 for 5 - $3.40 each) <ul> <li>Any other 5V-logic-level Arduino would work as well. Needs to be 5V or have the CLK + DATA outputs converted from 3V3 to 5V, since the PS/2 serial connection expects 5V.</li> </ul> </li> <li>USB HDMI Capture Card (<code>video4linux</code> compatible - most cards are) (<a href="https://smile.amazon.com/gp/product/B08BZ52Q65/">Amazon</a>, $13.99)</li> <li>(optional) PS/2 plug, to make a tidy connection</li> <li>Supplies: Wires, soldering iron if you need to solder, microSD card and micro-USB power supply for the Piâ€¦</li> </ul> <p>Comes out to roughly $60 if you buy everything at itâ€™s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html">https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html</a></em></p>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232066</guid>
            <pubDate>Fri, 21 Aug 2020 04:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I got the French Tech Visa to start my company in France]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 193 (<a href="https://news.ycombinator.com/item?id=24232025">thread link</a>) | @christpetron
<br/>
August 20, 2020 | https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/ | <a href="https://web.archive.org/web/*/https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Three years ago, things were different. I didn’t know any French, I didn’t have a business, and I didn’t have a job.</p>



<p>I had just quit a great job in Singapore to start my own company. My partner was starting her master’s in Paris and told me to come stay. So I packed up everything, shipped some of it to my mom in New York, and hopped on a flight to CDG.</p>



<figure><img src="http://christianpetroske.com/wp-content/uploads/2020/08/paris.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/paris.png 878w, https://christianpetroske.com/wp-content/uploads/2020/08/paris-300x74.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/paris-768x191.png 768w" sizes="(max-width: 878px) 100vw, 878px"></figure>



<p>Around this time, French President Macron released an iconic video as part of the <a rel="noreferrer noopener" href="https://makeourplanetgreatagain.fr/en/business" target="_blank">Make Our Planet Great Again campaign</a>. He told scientists, researchers, and innovators from around the world to come to France. I was supposed to be an innovator now. My ears perked up.</p>



<p>“Your new homeland” it said. It continued: “Entrepreneurs and skilled employees from all over the world, France is made for you!”</p>



<p>Made for me, huh? Okay, I’ll bite.</p>



<p>I bit.</p>



<p>A few clicks later I found myself reading about <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/" target="_blank">the French Tech Visa</a>, a visa scheme that awards founders of tech companies a visa for four years to live and start their business in France.</p>



<p>This seemed like the ultimate three-birds-one-stone: I would get to start my company, be with my partner, and live in effing Paris—learning French, discussing philosophy, eating croissants, whatever else people do in Paris. Life sorted for the next few years! Right?</p>



<p>In retrospect, I was right about the big stuff: starting the company, living with my partner, learning French, and the croissants (oh oui). </p>



<p>But it did not come easy. I learned a ton. I am incredibly grateful that it worked out. There were many moments when it almost didn’t. Through a combination of luck, hustle, privilege, and the kindness of others, I am where I am today: running my own business, living in France with my partner, speaking French, eating croissants, and looking back on it all muttering <em>putain</em> in happy disbelief.</p>



<p>Looking back too, I’m struck by how little information there was out there for people in my situation. I kept finding out critical information through chance conversations—and I’d done my research. I started thinking that the whole process should be a lot more transparent.</p>



<p>I’ve since had conversations with several people who were considering this path. So I decided to write down some of it to help others who are thinking about coming to France to start their company.</p>



<p>If that’s you, here are the basics of what you need to know. The challenge generally breaks down into 1) the visa, 2) the business, and 3) the language and culture.</p>



<p>(If you’re really serious about this, I’m writing a complete guide to the French Tech Visa which <a href="https://gum.co/SRUhE" target="_blank" rel="noreferrer noopener">you can preorder here</a>.)</p>



<h2>First: the visa</h2>



<p>There are three different French Tech visas: for <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-founders/" target="_blank">founders</a>, <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-employees/" target="_blank">employees</a>, and <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-les-investors/" target="_blank">investors</a>. I have the one for founders. That’s the one I know the most about, so it’s the one I focus on here.</p>



<p>The first step to getting the French Tech Visa for founders is to look at this list of incubators.</p>



<figure><a href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-founders/" target="_blank" rel="noopener noreferrer"><img src="http://christianpetroske.com/wp-content/uploads/2020/08/image-1024x707.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/image-1024x707.png 1024w, https://christianpetroske.com/wp-content/uploads/2020/08/image-300x207.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/image-768x530.png 768w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1536x1061.png 1536w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2048x1414.png 2048w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1200x829.png 1200w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1980x1367.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>These incubators are all partnered with the French government to support foreign founders. The kind of support varies, but your goal is to find one that can offer you the visa.</p>



<p>One week, I decided I would do this. So I came up with a startup idea, made a pitch deck, website, and email address, and started sending emails. I reached out to probably 30 of these and had conversations with about 10 until it got down to 2-3 that seemed promising. </p>



<p>I just found the deck I made in Canva. It was an employee engagement app called Purpose, Go! (I know right?).</p>



<figure><img src="http://christianpetroske.com/wp-content/uploads/2020/08/image-2-1024x768.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1024x768.png 1024w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-300x225.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-768x576.png 768w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1536x1152.png 1536w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1200x900.png 1200w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2.png 1754w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Lol ok, not bad. How an app was supposed to accomplish that, lord knows.</figcaption></figure>



<p>I ended up on the phone with <a rel="noreferrer noopener" href="https://theschoolab.com/en/" target="_blank">Schoolab</a> in Paris, who said they liked my idea and told me to come in to meet the team. I met them, did a tour, and got offered a spot. It cost me €650 a month for their 6 month program, including the visa, access to the community of startups and mentors, and office space. I took the deal.</p>



<p>Fees vary by incubator, but overall you’ll need around €5,000 in the bank to pay for the incubator program plus taxes and fees in the application process.</p>



<p>Then, you’ll need to prove that you have money equal to the French minimum wage (€18,254.60 in 2019). I didn’t have this. Instead, you can find someone who does have this kind of money to be your “guarantor”. The visa office will accept it as long as that person signs a letter saying they will support you if needed while you’re in France.</p>



<p>Once you get into the incubator, they will help you apply to get your three-page business proposal approved by the relevant government agency. They even helped me translate mine into French. It takes a couple of months, but once you have that approval letter, you are on the fast track for a four year visa.</p>



<p>There are differences by country, but being a US citizen, I had to go back to my home consulate in New York to complete the visa process.</p>



<p>I arrived in France in August, started the incubator in September, and didn’t get my provisional visa until February… So that gives you an idea. </p>



<h2>Second: the business</h2>



<p>Once I was in the incubator, the next challenge arose: What the hell was I going to do with this business?</p>



<p>For about two solid months I worked on Purpose, Go! alongside various client projects to keep some money coming in. I networked hard in the HR tech world in Paris and got to know some interesting people. But it became clear that these relationships were not going anywhere—and without relationships, I had no hope of selling into businesses.</p>



<p>So I started spending more time with a friend I’d made in the program, <a rel="noreferrer noopener" href="https://plentyworks.io/outer-space-mindset/" target="_blank">Buddhika</a>, who was working on a VR fitness company. When it became clear my thing wasn’t going to work (and they were struggling a bit too), we started talking in earnest about partnering up. Becoming co-founders.</p>



<p>So I started to work with them on the VR fitness idea. It was clear it was going to take a while to mature into something that could make money, so we looked around for income sources. One of our friends in the program needed an app built, so we decided to go into software development. That’s what led to our real French company.</p>



<p>We started out as individual micro-entrepreneurs, since it’s super easy to get started and get paid legally through that status. Eventually, we opened up a SAS entity in what seemed like an extremely painful and expensive process. It didn’t need to be.</p>



<p>The perfect time to start a SAS (the equivalent of a US Corporation) is when you’re building something you want to raise money for at some point. We wanted to keep our options open, so we did that. </p>



<p>Many small businesses start as SARL entities (rough equivalent of a US LLC) instead, since taxes are lower but fundraising ability is null.</p>



<p>Whatever you choose, the most important (and most difficult) thing is to find a way to actually get paid in the first place. French business is highly networked, even more so than the US, which means that people like to only do business with people they have a relationship with. So investing in building relationships is the number one most important thing you can do for the success of your French business.</p>



<p>Speaking of which…</p>



<h2>Third: the language</h2>



<p>To build relationships with people, you will need some level of French. It’s certainly possible to only run in circles where you can speak English, don’t get me wrong. But you will miss opportunities if you’re constrained by language.</p>



<p>One of the first places you may run into this problem is when looking for an incubator. Schoolab, for instance, has since shrunk or canceled their English-language programming since I was there because it was too difficult to maintain programs in two languages (and they couldn’t get everyone to switch over to English). </p>



<p>So how do you learn French quickly, cheaply, and effectively?</p>



<p>This is exactly what I tried to do, being hyper-conscious that my runway was dwindling with each passing month. Here was my rough language-learning regimen that got me conversational in about 6 months:</p>



<ul><li>Start out with cheap private lessons through iTalki. You can spend $10-15 an hour for a junior teacher to talk with you and teach you core grammar principles and vocab.</li><li>Listen to French podcasts constantly. This is key to improving comprehension. Read the transcript along if you can. My favorites at the beginning were <a rel="noreferrer noopener" href="https://savoirs.rfi.fr/fr/apprendre-enseigner/langue-fran%C3%A7aise/journal-en-fran%C3%A7ais-facile" target="_blank">Le Journal en Français Facile from RFI</a>, <a rel="noreferrer noopener" href="https://podcasts.apple.com/gb/podcast/learn-french-by-podcast/id160256534" target="_blank">Learn French by Podcast</a>, and <a rel="noreferrer noopener" href="https://podcasts.apple.com/gb/podcast/coffee-break-french/id263170419" target="_blank">Coffee Break French</a>. Now I love <a rel="noreferrer noopener" href="https://www.lesechos.fr/podcasts/la-story" target="_blank">La Story by Les Echos</a>, <a rel="noreferrer noopener" href="https://www.binge.audio/podcast/a-bientot-de-te-revoir/" target="_blank">A bientôt de te revoir</a>, and many more.</li><li>Read French news and blogs. Focus on what you’re interested in. I’m interested in technology and startups so I would read <a rel="noreferrer noopener" href="https://www.maddyness.com/" target="_blank">Maddyness</a>.</li><li>Get grammar lessons from YouTube. My hands-down favorite here is <a rel="noreferrer noopener" href="https://learnfrenchwithalexa.com/" target="_blank">Learn French with Alexa</a>. She explains even the advanced concepts so clearly.</li><li>And of course, take every opportunity to talk to real people! Having friends who are willing to suffer through your awful French (and laugh at you a bit, yes) is one of the things that will accelerate your learning the most. Go to events you find on Facebook. Take a dance class. Get out there. The more uncomfortable you are with your language ability, the more motivated you will be to learn faster.</li></ul>



<p>There’s also the culture to get used to, but maybe we’ll save that one for another post. </p>



<p>It’s wild that I’m coming up on three years in France. It has been an adventure. Hopefully some of this will help others navigating this for the first time. </p>



<p>If you liked this story and you want to stay in touch, follow me on <a href="https://twitter.com/christpetron" target="_blank" rel="noreferrer noopener">Twitter</a>.</p>



<hr>



<p>I’m compiling all this info and more into <a rel="noreferrer noopener" href="https://gum.co/SRUhE" target="_blank">the Complete Guide to the French Tech Visa</a>, which <a rel="noreferrer noopener" href="https://gum.co/SRUhE" target="_blank">you can pre-order right here</a>. It includes:</p>



<ul><li>Step-by-step instructions on how to obtain your French Tech Visa</li><li>The full list of documents you’ll need</li><li>The full timeline of how long you can expect it to take</li><li>The full set of visa-related costs you’ll face</li><li>Step-by-step guidance on creating your French business entity (Micro-entrepreneur, SAS and SARL)</li><li>Important information on taxes, insurance, employment, and liability</li><li>Opening a personal …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/">https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/</a></em></p>]]>
            </description>
            <link>https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232025</guid>
            <pubDate>Fri, 21 Aug 2020 04:38:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Did Mozilla Remove XUL Add-Ons?]]>
            </title>
            <description>
<![CDATA[
Score 388 | Comments 326 (<a href="https://news.ycombinator.com/item?id=24231017">thread link</a>) | @est31
<br/>
August 20, 2020 | https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/ | <a href="https://web.archive.org/web/*/https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>TL;DR: Firefox used to have a great extension mechanism based on the XUL and XPCOM. This mechanism served us well for a long time. However, it came at an ever-growing cost in terms of maintenance for both Firefox developers and add-on developers. On one side, this growing cost progressively killed any effort to make Firefox secure, fast or to try new things. On the other side, this growing cost progressively killed the community of add-on developers. Eventually, after spending years trying to protect this old add-on mechanism, Mozilla made the hard choice of removing this extension mechanism and replacing this with the less powerful but much more maintainable WebExtensions API. Thanks to this choice, Firefox developers can once again make the necessary changes to improve security, stability or speed.</p>

<p>During the past few days, I’ve been chatting with Firefox users, trying to separate fact from rumor regarding the consequences of the August 2020 Mozilla layoffs. One of the topics that came back a few times was the removal of XUL-based add-ons during the move to Firefox Quantum. I was very surprised to see that, years after it happened, some community members still felt hurt by this choice.</p>

<p>And then, as someone pointed out on reddit, I realized that we still haven’t taken the time to explain in-depth why we <em>had no choice</em> but to remove XUL-based add-ons.</p>

<p>So, if you’re ready for a dive into some of the internals of add-ons and Gecko, I’d like to take this opportunity to try and give you a bit more detail.</p>



<p>For a very long time, Firefox was composed of a very small core on top of which everything was implemented as extensions. Many of these extensions were written in C++, others in JavaScript and many involved the XUL interface language and the XBL binding language. C++ and JavaScript code were connected thanks to a technology called XPCOM. Whenever an extension developer wished to customize Firefox, it was simple and extremely powerful, as the exact same building blocks used to power Firefox could be used to customize it.</p>

<p>This is how Session Restore (the technology that lets you resume Firefox where you left it the last time, even in case of crash) or the Find Bar were first implemented in Firefox, among other features. This is the technology that powers Firefox and <a href="https://www.thunderbird.net/">Thunderbird</a>. This is how tools such as <a href="https://en.wikipedia.org/wiki/Songbird_(software)">Songbird</a> (an open-source iTunes competitor) or <a href="https://en.wikipedia.org/wiki/Instantbird">Instantbird</a> (a chat client) were developed. This is also how I customized Firefox to become an eBook reader a long time ago. And this is how thousands of Firefox add-ons were developed.</p>

<p>Many people call this extension mechanism “XUL-based Add-Ons”, or sometimes “XPCOM-based Add-Ons”, and I’ll use both terms in this blog entry, but I often think of this as the “Promiscuous Extension Mechanism”, for several reasons:</p>

<ul>
<li>very quickly, add-on developers realized that anything they did could break anything else in the system, including other add-ons and Firefox itself, and they often had no way to prevent this;</li>
<li>similarly, anything Firefox developers did could break add-ons, and they often had no way to prevent this;</li>
<li>also, some of the changes that Firefox needed to be as fast, as stable and as secure as possible were going to break most add-ons immediately, possibly all add-ons in the longer term;</li>
<li>oh, and by the way, since add-ons could do everything, they could very easily do anything to the operating system, from stealing passwords to pretending to be your bank.</li>
</ul>

<p>Note: Having read in comments that some users apparently do not care about security, let me add that being secure is a really, really important point for Mozilla and has been since the first day. Regardless of add-ons, <em>not</em> having security means that an exploit is eventually going to show up that will steal user’s passwords and use them to steal their bank accounts – and that exploit will get sold around and will soon show up everywhere. Firefox developers fight this threat daily by all sorts of means, including code reviews, defensive programming, crash scene investigations, several types of sandboxing, static analysis, memory-safe languages, … Consequently, for Mozilla, if a feature prevents us from achieving great security, we <em>always</em> pick security over features.</p>

<p>I’ll return to these points in more details later. For the moment, suffices to say that it had been clear to Firefox developers for a long time (at least since 2010) that this situation was untenable. So Mozilla came up with a backup plan called the <em>Firefox Jetpack</em>.</p>

<p>Firefox Jetpack was a very different manner of extending Firefox. It was much cleaner. It finally had a permissions mechanism (something that had been suggested even before Firefox was called Firefox and that was generally considered too hard to implement). Out of the box, add-ons could not break each other or Firefox (I seem to remember that it was still sometimes possible by exploiting the observer service, but you had to work hard at it), it made extensive use of async programming (which was great to achieve a feeling of high-performance) and thanks to the fact that it had a finite API, it could be tested, which meant that when Firefox developers broke add-ons, they knew about it immediately and could fix the breakages! That was several enormous steps forward. This came at the cost of a more limited API but in most cases, the tradeoff seemed worth it.</p>

<p>Unfortunately, it turned out that there was an unexpected incompatibility between the design of Jetpack and some of the major changes that were needed in Firefox. I’m not entirely clear about what this incompatibility was but this meant that we had to abandon Jetpack.
Instead, we introduced WebExtensions. Overall, WebExtensions had a similar objective as Jetpack-based add-ons, with a similarly restricted API and the added bonus that they could be made to work on both Chromium-based browsers and Firefox.</p>

<p>If you needed very advanced APIs, switching from the promiscuous extension mechanism to Jetpack or WebExtensions was not always possible, but for most extensions, the transition was simple – in my personal experience, it was even pleasant.</p>

<p>Firefox introduced WebExtensions in time for Firefox Quantum because this is when the promiscuous add-on model was scheduled to break.</p>

<p>At this stage, we’re done with the historical overview. I hope you’re ready for a more technical dive because that’s how I’m going to explain to you exactly which problems were solved as we switched from the promiscuous extension model to WebExtensions.</p>



<h2 id="how-it-started">How it started</h2>

<p>XPCOM, the Xross-Platform Component Object Model, is perhaps the feature of Firefox that can best be described as <em>the core</em> (for people who know Gecko in-depth, I’m counting XPConnect and the Cycle Collector as part of XPCOM), alongside SpiderMonkey, our JavaScript Virtual Machine.</p>

<p>XPCOM is a technology that lets you write code in two languages and have each other call the other. The code of Firefox is full of C++ calling JavaScript, JavaScript calling C++ and a long time ago, we had projects that added Python and .Net in the mix. This piece of machinery is extremely complicated because languages do not share the same definitions (what’s a 64-bit integer in JavaScript? what’s a JavaScript exception in C++?) or the same memory model (how do you handle a JavaScript object holding a reference to a C++ object that C++ might wish to <code>delete</code> from memory?) or the same concurrency model (JavaScript workers share nothing while C++ threads share everything).</p>

<p>Gecko itself was originally designed as thousands of XPCOM components that could each be implemented in C++ or in JavaScript, tested individually, plugged, unplugged or replaced dynamically and <em>it worked</em>. In addition, the XPCOM architecture made for much cleaner C++ programming than was available at the time, worked on dozens of platforms, and let us combine the convenience of writing code in JavaScript and the raw speed permitted by C++.</p>

<p>To write a XPCOM component, you typically define <a href="https://searchfox.org/mozilla-central/rev/6cc48251bb97600fdf11a5b4c5f621bfc8606d55/dom/interfaces/base/nsIFocusManager.idl">an interface</a>, then write the implementation in either C++ or JavaScript (or Rust, nowadays, and maybe soon Wasm). Some boilerplate is needed, but hey, it works.</p>

<p>When early Firefox developers decided to open the platform to extensions, XPCOM was immediately picked as the base technology for add-ons. Firefox just had to let add-on authors plug anywhere within the code and they would have tremendous power at their disposal.</p>

<p>And add-on developers (including myself) certainly did and had lots of fun with it!</p>

<h2 id="the-era-of-immutable-xpcom">…the era of immutable XPCOM</h2>

<p>Unfortunately, problems progressively started to creep up.</p>

<p>When you’re developing a large application, you need to change things, either to fix bugs or to add new features, or to improve performance. In the XPCOM world, this meant changing XPCOM components. Sometimes to add new features to a component. Sometimes to entirely remove one because this design has been replaced with a better design.</p>

<p>In the first era of the XPCOM-based extension mechanism, this was often forbiddden. If there was an XPCOM component used by add-ons, it simply <strong>could not</strong> be changed in incompatible ways. This was great for add-on developers but it quickly became a nightmare for Firefox developers. Because every single change had to be made in backwards-compatible way both externally (for web developers) and internally (for add-on developers). This meant that each XPCOM component <code>nsISomething</code> was quickly accompanied by a <code>nsISomething2</code>, which was the better component – and both needed to be made to work alongside each other - One case was even more complicated to handle by Firefox developers: XPCOM-based add-ons could replace <em>any existing XPCOM component</em>. Needless to say, this was a very good way to break Firefox in ways that puzzled Firefox crash investigators.</p>

<p>This meant that development became slower and slower as we needed to check each new feature or each improvement against not only current features, but also past/deprecated features or simply old ways to work …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</a></em></p>]]>
            </description>
            <link>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24231017</guid>
            <pubDate>Fri, 21 Aug 2020 01:30:38 GMT</pubDate>
        </item>
    </channel>
</rss>
