<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 11 Nov 2020 20:18:22 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 11 Nov 2020 20:18:22 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon – July 26, 2008<br>
Revised – September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming—a kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs—3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs—six
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master—though they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"—CHR$(07)—causes the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy—any value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes—which fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise …</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Recalculate a Spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 272 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25039393">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://lord.io/blog/2020/spreadsheets/ | <a href="https://web.archive.org/web/*/https://lord.io/blog/2020/spreadsheets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Let’s say I’m ordering burritos for my two friends while they quar up in Jersey City, and want to calculate the total price of my order:</p>
<p><img alt="screenshot of spreadsheet; burrito price is listed as $7, burrito price w ship as burrito price plus $3, num burritos is 2, and total is num burritos times burrito price w ship, for a total of $20" src="https://lord.io/images/2020/anchors_0.png"></p>
<p>It’s a little confusing to follow the flow of data in a spreadsheet when it’s written like that, so I hope you don’t mind this equivalent diagram that represents it as a graph:</p>
<p><img alt="the previous spreadsheet represented as a graph, with arrows from one cell to another replacing the spreadsheet cell references" src="https://lord.io/images/2020/anchors_1.png"></p>
<p>We’re rounding the cost of an El Farolito super vegi burrito to $8, so assuming the per-burrito delivery toll remains at just $2 per burrito, it looks like the total for our two burritos will be $20.</p>
<p>Oh no, I completely forgot! One of my friends loves to wolf down multiple burritos at a time, so I actually want to place an order for three burritos. If I update <code>Num Burritos</code>, a naïve spreadsheet engine might recompute the entire document, recalculating first the cells with no inputs, and then recalculating any cell whose inputs are ready until we’ve finished every cell. In this case, we’d first calculate <code>Burrito Price</code> and <code>Num Burritos</code>, then <code>Burrito Price w Ship</code>, and then a new final <code>Total</code> of $30.</p>
<p><img alt="same as previous graph, but num burritos is updated to 3, and every cell is tagged as &quot;recalc&quot;" src="https://lord.io/images/2020/anchors_2.png"></p>
<p>This simple strategy of recalculating the whole document may sound wasteful, but it’s actually already <em>better</em> than VisiCalc, the first spreadsheet software ever made, and the first so-called “killer app”, responsible for popularizing the Apple II. VisiCalc would repeatedly recalculate cells from left-to-right and top-to-bottom, sweeping over them again and again until none of them changed. Despite this “interesting” algorithm, VisiCalc remained the dominant spreadsheet software for four years. Its reign ended in 1983, when Lotus 1-2-3 swept the market with “natural-order recalculation”, <a href="https://aresluna.org/attached/computerhistory/articles/spreadsheets/tenyearsofrowsandcolumns">as described by Tracy Robnett Licklider in Byte Magazine</a>:</p>
<blockquote>
<p>Lotus 1-2-3 exploited natural-order recalculation, although it also supported VisiCalc’s row- and column-order modes. Natural-order recalculation maintained a cell dependency list and recalculated a cell before recalculating cells that depended on it.</p>
</blockquote>
<p>Lotus 1-2-3 implemented the “recalculate everything” strategy we’ve shown above, and for the first decade of spreadsheets, that was as good as it got. Yes, we recalculate every cell in the document, but at least we only recalculate every cell once.</p>
<h2>but what about “burrito price w ship”</h2>
<p>Great point, header 2. In my three burrito example there’s no reason to recompute <code>Burrito Price w Ship</code>, because changing the number of burritos we order can’t possibly influence the per-burrito price. In 1989, one of Lotus’ competitors realized this, and created SuperCalc5, presumably naming it after the theory of super burritos at the core of this algorithm. SuperCalc5 recalculated “only cells dependent on changed cells”, which would make updating the burrito count look more like this:</p>
<p><img alt="same as prior graph, with burrito count updated from 2 to 3, but now only the two affected cells &quot;num burritos&quot; and &quot;total&quot; are tagged as recalc" src="https://lord.io/images/2020/anchors_3.png"></p>
<p>By only updating a cell when one of its inputs changes, we can avoid recalculating <code>Burrito Price w Ship</code>. In this case, it saves just a single addition, but on larger spreadsheets it can save quite a bit of time! Unfortunately, we now have another problem. Let’s say my friends now want meat burritos, which cost a dollar more, and simultaneously El Farolito adds a $2 fee paid per-order, regardless of how many burritos you order. Before any formula outputs are recalculated, our graph might look like this:</p>
<p><img alt="same as prior graph (after burrito count update finished calculation), but now burrito price is being updated from $8 to $9, and simultaneously total is updated from &quot;burrito price w ship * num burritos&quot; to &quot;burrito price w ship * num burritos + $2 fee&quot;" src="https://lord.io/images/2020/anchors_4.png"></p>
<p>Since there are two updated cells here, we have a problem. Should we recalculate <code>Burrito Price</code> first, or <code>Total</code>? Ideally, we first calculate <code>Burrito Price</code>, notice that its output has changed, then recalculate <code>Burrito Price w Ship</code>, and finally recalculate <code>Total</code>. However, if we instead recalculate <code>Total</code> first, we’ll have to recalculate it a second time once the new $9 burrito price propagates down. If we don’t calculate cells in the right order, this algorithm isn’t better than recalculating the whole document. In some cases, it’s as slow as VisiCalc!</p>
<p>Clearly, it’s important for us to figure out the right order to update our cells. Broadly, there are two solutions to this problem: dirty marking and topological sorting.</p>
<p>This first solution involves marking all cells downstream from an edit as dirty. For instance, when we update <code>Burrito Price</code>, we would mark the downstream cells <code>Burrito Price w Ship</code> and <code>Total</code> as dirty, even before doing any recalculations:</p>
<p><img alt="same as prior graph with the two updates, but now three nodes are tagged as dirty: &quot;burrito price&quot;, &quot;burrito price w ship&quot;, and &quot;total&quot;. would also like to apologize for the rather confusing image alt text so far; it's really hard to write these for graph diagrams!! if you are a screen reader user and have advice on better ways to do this, would love to hear from you." src="https://lord.io/images/2020/anchors_5.png"></p>
<p>Then, in a loop, we find a dirty cell that has no dirty inputs, and recalculate it. When there are no dirty cells left, we’re done! This solves our ordering problem. There’s one downside though — if a cell is recalculated and we find its new output to be the same as its previous output, we’ll still recalculate downstream cells! A little bit of extra logic can avoid actually running the formula trouble in this case, but we unfortunately still waste time marking and unmarking a lot of cells as dirty.</p>
<p>The second solution is topological sorting. If a cell has no inputs, we mark its height as 0. If a cell has inputs, we mark its height as the maximum of the heights of its inputs, plus one. This guarantees all cells have a greater height than any of their inputs, so we just keep track of all cells with a changed input, always choosing the cell with the lowest height to recalculate first:</p>
<p><img alt="same as prior graph with the two updates, but instead of dirty tags, now every node has a height tag. &quot;burrito price&quot; and &quot;num burritos&quot;, the two cells with no in-nodes, have height 0. &quot;burrito price w ship&quot; has height 1. &quot;total&quot; has height 2." src="https://lord.io/images/2020/anchors_6.png"></p>
<p>In our double-update example, <code>Burrito Price</code> and <code>Total</code> would be initially added to the recalculation heap. <code>Burrito Price</code> has lesser height, and would be recalculated first. Since its output changes, we then would add <code>Burrito Price w Ship</code> to the recalculation heap, and since it too has less height than <code>Total</code>, it would be recalculated before we finally recalculate <code>Total</code>.</p>
<p>This has a big advantage over the first solution: no cell is ever marked dirty unless one of its inputs actually change. However, it requires we keep all cells pending recalculation in sorted order. If we use a heap, this results in an <code>O(n log n)</code> slowdown, so in the worst case, asymptotically slower than Lotus 1-2-3’s strategy of recalculating everything.</p>
<p>Modern-day Excel uses <a href="https://docs.microsoft.com/en-us/office/client-developer/excel/excel-recalculation">a combination of dirty marking and topological sorting</a>, which you can read more about in their docs.</p>
<h2>demand-driven complications</h2>
<p>We’ve now more or less reached the algorithms used in modern-day spreadsheet recalculation. Unfortunately, I suspect there is basically no business case to be made for ever improving it further. The few people with the problem “my Excel spreadsheet is too slow” have already written enough Excel formulas that migration to any other platform is impossible. Fortunately, I have no understanding of business, and so we’re going to look at further improvements anyway.</p>
<p>Beyond caching, one of the cool aspects of a spreadsheet-style computation graph is we can only calculate the cells that we’re interested in. This is sometimes called lazy computation, or demand-driven computation. As a more concrete example, here’s a slightly expanded burrito spreadsheet graph. This example is the same as before, but we’ve added what is best described as “salsa calculations”. Each burrito contains 40 grams of salsa, and we perform a quick multiplication to know how much salsa is in our entire order. In this case, since our order has three burritos, there’s a total of 120 grams of salsa in our entire order.</p>
<p><img alt="a new graph. similar structure to the old graph, but there are two new nodes: &quot;salsa per burrito&quot;, which is set to the constant &quot;40 grams&quot;, and &quot;salsa in order&quot;, which is &quot;salsa per burrito&quot; times &quot;num burritos&quot;" src="https://lord.io/images/2020/anchors_7.png"></p>
<p>Of course, astute readers will have spotted the problem here already: knowing the total weight of salsa in an order is a pretty useless measurement. Who cares that it’s 120 grams? What am I supposed to do with this information?? Unfortunately, a regular spreadsheet would waste cycles calculating <code>Salsa In Order</code>, even if we don’t want it recalculated most of the time.</p>
<p>This is where demand-driven recalculation can help. If we could somehow specify that we’re only interested in the output of <code>Total</code>, we could only recompute that cell and its dependencies, and skip touching <code>Salsa In Order</code> and <code>Salsa Per Burrito</code>. Let’s call <code>Total</code> an <em>observed</em> cell, since we’re trying to look at its output. We can also call both <code>Total</code> and its three dependencies <em>necessary</em> cells, since they’re necessary to compute some observed cell. <code>Salsa In Order</code> and <code>Salsa Per Burrito</code> would be aptly described as <em>unnecessary</em>.</p>
<p>Some folks on the Rust team created the <a href="https://github.com/salsa-rs/salsa">Salsa</a> framework to solve this problem, clearly naming it after the unnecessary salsa calculations their computers were wasting cycles on. Salsa is really cool, and I’m sure <a href="https://www.youtube.com/watch?v=i_IhACacPRY">they can explain</a> how it works better than I can. Very roughly, they use revision numbers to track whether a cell needs recalculation. Any mutation to a formula or input increments the global revision number, and every cell tracks two revisions: <code>verified_at</code> to track the revision its output was last brought up-to-date, and <code>changed_at</code> to track the revision its output last actually changed.</p>
<p><img alt="our new graph, but now there's a title of &quot;current revision: R6&quot;. each cell is tagged with a change revision and verified at revision. all change revisions are R1, except &quot;salsa per burrito&quot;, which is R6. all verified at revisions are R6, except &quot;salsa in order&quot;, which is R1." src="https://lord.io/images/2020/anchors_8.png"></p>
<p>When the user indicates they’d like a fresh value for <code>Total</code>, we’d first recursively recalculate any cell necessary to <code>Total</code>, skipping cells if their <code>last_updated</code> revision is equal to the global revision. Once the dependencies of <code>Total</code> are up-to-date, we only rerun the actual formula in <code>Total</code> if either <code>Burrito Price w Ship</code> or <code>Num Burrito</code> have a <code>changed_at</code> revision greater than the <code>verified_at</code> revision of <code>Total</code>. This is great for Salsa’s purposes in the rust-analyzer, where simplicity is important and each cell takes a significant amount of time to compute. However, we can see the disadvantages in our burrito graph above — if <code>Salsa Per Burrito</code> constantly changes, our global revision number will frequently tick up. This will make each observation of <code>Total</code> walk the three cells necessary to it, even though none of those cells have actually changed. No formulas will be recalculated, but if the graph is large, repeatedly walking all of a cell’s dependencies could get expensive.</p>
<h2>faster demand-driven solutions</h2>
<p>Instead of inventing new algorithms for demand-driven spreadsheets, what if we instead draw from the two classical spreadsheet algorithms mentioned earlier: dirty marking and topological sorting? As you might imagine, a demand-driven model complicates both of these, but both are still viable.</p>
<p>Let’s first look at dirty marking. As before, when we change a cell’s formula, we mark all downstream cells as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lord.io/blog/2020/spreadsheets/">https://lord.io/blog/2020/spreadsheets/</a></em></p>]]>
            </description>
            <link>https://lord.io/blog/2020/spreadsheets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039393</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Security Maturity Roadmap [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25038422">thread link</a>) | @sciurus
<br/>
November 9, 2020 | https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf | <a href="https://web.archive.org/web/*/https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038422</guid>
            <pubDate>Mon, 09 Nov 2020 19:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hidden gem in sound symmetry]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25037784">thread link</a>) | @gbh444g
<br/>
November 9, 2020 | https://soundshader.github.io/hn/acf/index.html | <a href="https://web.archive.org/web/*/https://soundshader.github.io/hn/acf/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<blockquote>
  <p><em><a href="https://pages.mtu.edu/~suits/autocorrelation.html">Autocorrelation</a> is used to compare a signal with a time-delayed version of itself. If a signal is periodic, then the signal will be perfectly correlated with a version of itself if the time-delay is an integer number of periods. That fact, along with related experiments, has implicated autocorrelation as a potentially important part of signal processing in human hearing.</em></p>
</blockquote>

<p>ACF is a simple method to visualize music that produces surprisingly good results. Perhaps the most unexpected property of ACF is that it accurately transfers the subjective “harmony level” from music to images. It’s almost an unreasonable property, if you think about it. Images below are ACF height maps in polar coordinates.</p>

<table>
  <thead>
    <tr>
      <th>Female vocal</th>
      <th>David Parsons</th>
      <th>Piano</th>
      <th>Bird</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/song-2.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bowl-3.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/piano-p.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bird-2.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>More examples: <a href="https://soundshader.github.io/gallery/">soundshader.github.io/gallery</a> (beware of large images).</p>

<p>Live demo: <a href="https://soundshader.github.io/">soundshader.github.io</a></p>



<p>Contrary to what you might think, our ears don’t seem to rely on an FFT-like process to extract isolated frequencies. Instead, our ears detect periodic parts in the signal, although in most cases those periodic parts closely match the FFT frequencies. There is a simple <a href="https://auditoryneuroscience.com/pitch/missing-fundamental-stimuli">experiment</a> that proves this point:</p>

<p><img src="https://auditoryneuroscience.com/sites/default/files/missingFundamental2.png" alt=""></p>

<p>As can be clearly seen on the FFT image, the A signal is a pure sinusoidal tone, while B is a mix of tones. Despite each tone in B is higher than A, our ears perceive B as a lower tone. If we plot both waveforms, we’ll see that A has about 9 peaks in a 20 ms window, while B has only 5. The definition of “peak” is moot, but it doesn’t stop our ears from counting them and using the “number of peaks per second” as a proxy to the tone height.</p>

<p>ACF detects those peaks. ACF sees that there are 5 equally spaced time shifts where <code>B[t] * B[t + shift]</code> reaches the maximum, so on the ACF output we’ll see those 5 peaks.</p>

<blockquote>
  <p>Given that I’ve shamelessly stolen the experiment’s illustration above, I feel obligated to recommend the book where the illustration came from: <a href="https://auditoryneuroscience.com/book-preview">Auditory Neuroscience</a>.</p>
</blockquote>

<p>One downside of ACF is that it drops the phase component of the input signal, and thus ACF is not reversible. This means that images that only render ACF, lose about 50% of the information from the sound and those 50% are important, e.g. dropping the phase from recorded speech makes that speech indiscernible. Real world sounds, such as voice, heavily use nuanced amplitude and phase modulation. ACF captures the former, but ignores the latter.</p>



<p>ACF of a sound sample <code>X[0..N-1]</code> can be computed with two FFTs:</p>

<div><div><pre><code>S = |FFT[X]|^2
ACF[X] = FFT[S]
</code></pre></div></div>

<p>And thus ACF contains exactly the same information as the spectral density <code>S</code> (the well known spectrogram).</p>

<blockquote>
  <p>If you’re familiar with the ACF definition, you’ll notice that I should’ve used the inverse FFT in the last step. There is no mistake. The inverse FFT can be computed as <code>FFT[X*]*</code>, where <code>X*</code> is complex conjugate, but since <code>S[i]</code> is real-valued (and positive, in fact), the conjugate has no effect on it, and since ACF is also real valued in this case, the second conjugate has no effect either.</p>
</blockquote>

<p>ACF is a periodic and even function and so it can be naturally rendered in polar coordinates. In most cases, ACF has a very elaborate structure. Below are some examples, where red = ACF &gt; 0 and blue = ACF &lt; 0.</p>

<table>
  <thead>
    <tr>
      <th>conventional music</th>
      <th>a bird song</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/acf-c-1.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/acf-c-3.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>Looking at the first example, we can tell that there are 5 prominent peaks in a 20 ms sound sample, which corresponds to 250 Hz. This means that our ears would necesserarily perceive this sound as a 250 Hz tone, regardless of what its spectrogram says. If it was a pure 250 Hz tone, we’d see perfectly round shapes of the <code>r = cos(250Hz * t)</code> line, but it’s not the case here: we see that the 5 peaks are modulated with small wavelets: there is one big wavelet in the middle (which consists of 3 smaller wavelets) and 4 smaller wavelets. Our ears would hear the big wavelet as the 2nd harmonic of the 250 Hz tone (i.e. it would be a 500 Hz tone with a smaller amplitude) and the 4 small wavelets as the 5th harmonic (1000 Hz) at barely discernible volume. In addition to that, the 500 Hz harmonic is also modulated by the 3 tiny wavelets, which means we’d hear a 1500 Hz tone, almost inaudible. We can say all this without even looking at the spectrogram or hearing the sound.</p>



<p>Music is a temporal ornament. There are many types of ornaments, e.g. the 17 types of wallpaper tesselations, but few of them look like music. However there is one particular type of ornament that resembles music a lot - I mean those “mandala” images. I don’t know how and why those are produced, but I noticed a connection between those images and music:</p>

<ul>
  <li>The 1st obvious observation is that a mandala is drawn in polar coordinates and is <code>2*PI</code> periodic. Sound is periodic too, so I thought the two facts are related.</li>
  <li>The 2nd observation is that patterns on those images evolve over the radial axis. Ans so is music is a sequence of evolving sound patterns.</li>
  <li>The 3rd observation is that a <code>2*PI</code> periodic function trivially corresponds to a set of frequencies. We usually use FFT to extract the frequencies and another FFT to restore the <code>2*PI</code> periodic function. Thus, a single radial slice of a mandala could encode a set of frequencies. If this is correct, a mandala is effectively an old school vinyl disk.</li>
</ul>

<p>Putting these observations together we naturally arrive with the ACF idea.</p>



<p>Open an issue on github or shoot me a email at ssgh@aikh.org</p>



<p>AGPLv3</p>


      
    </div></div>]]>
            </description>
            <link>https://soundshader.github.io/hn/acf/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037784</guid>
            <pubDate>Mon, 09 Nov 2020 18:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 224 (<a href="https://news.ycombinator.com/item?id=25037147">thread link</a>) | @adamnemecek
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev? | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037147</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government pledges to connect 98% of Canadians via High-Speed Internet]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 80 (<a href="https://news.ycombinator.com/item?id=25037074">thread link</a>) | @aDfbrtVt
<br/>
November 9, 2020 | https://www.cbc.ca/news/politics/broadband-internet-1.5794901 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/broadband-internet-1.5794901">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Liberal government is promising to spend more than a billion dollars to connect most Canadian to high-speed internet by 2026.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4962390.1546282434!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/broadband-expansion.jpg"></p></div><figcaption>The Liberal government has been promising to do something to approve broadband internet service in rural areas.<!-- --> <!-- -->(Toby Talbot/Associated Press)</figcaption></figure><p><span><p>After some pandemic-related delays, the Liberal government says it's now&nbsp;on track to connect 98 per cent of Canadians to high-speed internet by 2026.</p>  <p>The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.</p>  <p>Prime Minister Justin Trudeau and a handful of cabinet ministers&nbsp;held a news conference in Ottawa to launch the $1.75 billion universal broadband fund — a program unveiled in the federal government's 2019 budget and highlighted on the campaign trail and in&nbsp;September's throne speech. Most of the money&nbsp;was&nbsp;announced in last year's budget.</p>  <p>"We were ready to go&nbsp;in March&nbsp;with the new Universal Broadband Fund and then the pandemic hit,"&nbsp;Rural Economic Development Minister Maryam Monsef told reporters.</p>  <p>The prime minister said the government is now on track to connect&nbsp;98 per cent of Canadians&nbsp;to high-speed&nbsp;by 2026 — an increase over&nbsp;the previously promised 95 per cent benchmark — and to link up&nbsp;the rest by 2030.</p>  <p>"These are ambitious targets&nbsp;and we're ready to meet them,"&nbsp;Trudeau said.</p>  <p><em><strong>WATCH |&nbsp;Trudeau announces a large investment in broadband services for rural Canadians</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Trudeau announces a large investment in broadband services for rural Canadians"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/573/747/ftr%20TRUDEAU%20broadband_frame_0.jpg" alt=""></p></div></div></div><span>Prime Minister Justin Trudeau spoke with reporters during a media briefing in Ottawa on Monday.<!-- --> <!-- -->2:47</span></span></span></p>  <p>About&nbsp;$150 million from the fund will be freed up to fund projects aimed at getting communities connected by next fall.</p>  <p>Senior officials with the department of&nbsp;Innovation, Science and Economic Development&nbsp;said applications will be reviewed on an ongoing basis until Jan. 15, 2021, with a goal of having projects completed by mid-November, 2021.</p>  <p>Deciding who gets upgraded connectivity first will depend on the service providers applying, they said.</p>  <p>Josh Tabish is&nbsp;corporate communications manager at the Canadian Internet Registration Authority, the not-for-profit agency that manages the .ca internet domain. He said he's hoping&nbsp;that a&nbsp;rapid build will bring relief to many Canadians over the next year.</p>    <p>"In terms of action, I think&nbsp;this is great news for Canadians who are stuck at home suffering from slow, crappy internet," he said.&nbsp;</p>  <p>But Tabish also said he hopes the government will look at need when deciding which projects should get approval first.&nbsp;His group has been working to identify the&nbsp;communities that&nbsp;have the slowest&nbsp;rates in Canada.</p>  <p>"What we really want to see happen is communities who are suffering with slow, sluggish connectivity get those upgrades first," he said.</p>  <p>The prime minister said the government also&nbsp;has reached a $600 million agreement with Telesat for satellite capacity to improve broadband service in remote areas and in the North.</p>    <p>"Good reliable internet isn't a luxury. It's a basic service," he said.</p>  <p>"Now more than ever, a video chat cutting out during a meeting or a connection that's too slow to upload a school assignment — that's not just a hassle, that's a barrier."</p>  <h2>Tories call out timelines</h2>  <p>The Opposition Conservatives criticized the government's timelines, arguing Canadians need better access now more than ever.</p>  <p>"This is absolutely unacceptable and a slap in the face to the nearly one million Canadians who don't have internet access at home, much less a reliable cell phone signal," said MP John Nater, Conservative critic&nbsp;for rural economic development.</p>  <p>"For months, Canada's Conservatives have been demanding concrete action to connect Canadians.&nbsp;We will continue to advocate for lower cell phone prices and for real improvements to broadband internet services, so that Canadians living in rural and remote areas have consistent access to these essential services."</p>  <p>The&nbsp;CRTC <a href="https://www.cbc.ca/news/politics/crtc-internet-essential-service-1.3906664">declared</a> broadband internet a basic telecommunications service in 2016.&nbsp;But its data suggest&nbsp;just&nbsp;<a href="https://crtc.gc.ca/eng/internet/internet.htm">40.8 per cent of rural Canadian households have access to </a>download speeds of&nbsp;at least 50 megabits per second (Mbps) and upload speeds of&nbsp;10 Mbps.</p>  <p>The government said those speeds will allow Canadians to work and learn online and access telehealth services.</p>  <p><em><strong>WATCH | Rural Canadians react to today's announcement</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Liberals promise to connect 98% of Canadians by 2030"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/732/431/politics_THURTON_broadband_money_7000kbps_1280x720_1817544259879.jpg" alt=""></p></div></div></div><span>After some pandemic-related delays, the Liberal government says it's now on track to connect 98 per cent of Canadians to high-speed internet by 2026. The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.<!-- --> <!-- -->1:47</span></span></span></p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/broadband-internet-1.5794901</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037074</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture Playbook]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25035752">thread link</a>) | @yarapavan
<br/>
November 9, 2020 | https://nocomplexity.com/documents/arplaybook/index.html | <a href="https://web.archive.org/web/*/https://nocomplexity.com/documents/arplaybook/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        
          By Maikel Mardjan<br>
        
            © Copyright 2018,2019, 2020 BM-Support.org. Created by Maikel Mardjan. This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (cc-by-sa).<br>
      </p>
  </div></div>]]>
            </description>
            <link>https://nocomplexity.com/documents/arplaybook/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035752</guid>
            <pubDate>Mon, 09 Nov 2020 15:31:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't care what Elon Musk thinks anymore]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25035658">thread link</a>) | @avthar
<br/>
November 9, 2020 | https://avthar.com/blog/dont-outsource-thinking | <a href="https://web.archive.org/web/*/https://avthar.com/blog/dont-outsource-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f18334b57a4385ee2a76"><div><p><em>This blog originally appeared in my </em><a href="https://avthar.substack.com/"><em>weekly newsletter</em></a><em>, where I share ideas I’m reflecting upon, experiments I’m trying and lessons I’ve learned, all to help you level up your own life. To get posts like this straight to your inbox, </em><a href="https://avthar.substack.com/"><em>subscribe here</em></a><em>.</em></p><p>—</p><p>Youtube recommended to me&nbsp;<a href="https://www.youtube.com/watch?v=vVnDE8wSrVo">what Elon Musk would work on if he was 22 years old today</a>. The video has almost 3 million views. In the past, I would’ve immediately watched the whole video, gotten inspired by what Elon thought were industries important to the future of humanity and then spent a ton of time working on that and telling everyone about it. All because Elon Musk thought it was important.&nbsp;</p><p><strong>This is outsourcing your thinking</strong>. This trick served me well in highschool and throughout college, but it’s not sustainable for long term success and happiness.&nbsp;</p><p>There are two problems with outsourcing your thinking. Continuing with the example of past me, there are things I’m already interested in, have&nbsp;<a href="https://nav.al/specific-knowledge">specific knowledge</a>&nbsp;about or possess a competitive advantage in, that won’t be mentioned on Elon’s list. Consequently, the first problem is that I will look down on those things as less meaningful and important and not pursue them, despite my better suitability and chances of success in those areas.</p><p>The second problem with outsourcing your thinking is that once the novelty of the problem fades away, I’d be faced with navigating difficulty, naysayers and the friction of creating something new, without an internal compass to guide me toward the correct paths to take. Put simply, Elon Musk isn’t there to talk me through what he thinks the path forward to be. This all stems from the issue that I pursued something, not because I had interest in that thing, actually enjoyed it or thought it was important, but because Elon Musk (or whoever else) thought it was important to work on. And I followed his thinking, rather than thinking for myself.</p><p>The reason this is important is because most success in business is having&nbsp;<strong>product-market-founder fit</strong>, not just about working on what’s world changing or hot. It’s about building a product that solves a burning problem for the right market and&nbsp;<strong>being the right person, with the right intuition</strong>&nbsp;to bring that product to market, operate that company and delight those customers. Even if you’re working on an important problem, if you don’t have conviction that comes from your own mental models, you’ll get burned when chaos hits. Just ask all the crypto ‘experts’ of 2016/17.&nbsp;<strong>It’s better to build something that’s an expression of yourself, rather than something others think is smart.</strong></p><p>Outsourcing your thinking is a manifestation of the error of trusting others more than we trust ourselves.&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a>&nbsp;talks about how this phenomenon of outsourcing your thinking happens all the time in the investing world:</p><blockquote><p>“<em>If you take investors, there might be an investment, which one from the outside we think is objectively good. But it really isn't objectively good. It has to fit into one's portfolio of investments in a way that emerges from one's own mental models. Otherwise, it is not a form of self expression. Then, when you enter volatility, you're not gonna know what to do with it.</em>” -&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a></p></blockquote><p>Elon Musk is a placeholder for anyone telling you what you should do or think. That could be entrepreneurs or VCs you idolize or maybe your parents (especially true if you’re brown). The reality is that you should not care what Elon Musk or anyone else says is important, you should decide for yourself what you should work on, based on following your own curiosity and interest.&nbsp;<strong>Do the hard work of experimenting, exploring and thinking for yourself. Don’t outsource your thinking.</strong></p><p><a href="https://avthar.substack.com/"><em>Subscribe here</em></a><em> to get posts like this straight to your inbox, </em></p></div></div></div>]]>
            </description>
            <link>https://avthar.com/blog/dont-outsource-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035658</guid>
            <pubDate>Mon, 09 Nov 2020 15:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A US Visa in 937 Days]]>
            </title>
            <description>
<![CDATA[
Score 286 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25035307">thread link</a>) | @caution
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Here’s the complete timeline of events. From my first denial to travel to the US until I eventually received a tourist visa. And then I can’t go anyway.</p>



<h2>December 5-11, 2016</h2>



<p>I spent a week on Hawaii with Mozilla – my employer at the time. This was my 12th visit to the US over a period of 19 years. I went there on ESTA, the visa waiver program Swedish citizens can use. I’ve used it many times, there was nothing special this time. The typical procedure with ESTA is that we apply online: fill in a form, pay a 14 USD fee and get a confirmation within a few days that we’re good to go.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg" alt="" width="558" height="414"></a><figcaption>I took this photo at the hotel we stayed at during the Mozilla all-hands on Hawaii 2016.</figcaption></figure>



<h2>June 26, 2017</h2>



<p>In the early morning one day by the check-in counter at Arlanda airport in Sweden, I was refused to board my flight. Completely unexpected and out of the blue! I thought I was going to San Francisco via London with British Airways, but instead I had to turn around and go back home – slightly shocked. According to the lady behind the counter there was “something wrong with my ESTA”. I used the same ESTA and passport as I used just fine back in December 2016. They’re made to last two years and it had not expired.</p>



<figure><a href="https://twitter.com/bagder/status/879198063998513152"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-06-Twitter-Publish.png" alt="" width="553" height="199"></a><figcaption>Tweeted by me, minutes after being stopped at Arlanda.</figcaption></figure>



<p>People engaged by Mozilla to help us out could not figure out or get answers about what the problem was (questions and investigations were attempted both in the US and in Sweden), so we put our hopes on that it was a human mistake somewhere and decided to just try again next time.</p>



<h2>April 3, 2018</h2>



<p>I missed the following meeting (in December 2017) for other reasons but in the summer of 2018 another Mozilla all-hands meeting was coming up (in Texas, USA this time) so I went ahead and applied for a new ESTA in good time before the event – as I was a bit afraid there was going to be problems. I was right and I got denied ESTA very quickly. “Travel Not Authorized”.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/ESTA-travel-not-authorized.png" alt="" width="642" height="458"><figcaption>Rejected from the ESTA program.</figcaption></figure>



<h2>Day 0 – April 17, 2018</h2>



<p><strong>Gaaah</strong>. It meant it was no mistake last year, they actually mean this. I switched approach and instead applied for a tourist visa. I paid 160 USD, filled in a ridiculous amount of information about me and my past travels over the last 15 years and I visited the US embassy for an in-person interview and fingerprinting.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/Administrative-Processing.png" alt="" width="577" height="289"></figure>



<p>This is day 0 in the <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/" data-type="post" data-id="11076">visa process</a>, 296 days after I was first stopped at Arlanda.</p>



<h2>Day 90 – July 2018</h2>



<p>I missed the all-hands meeting in San Francisco when I didn’t get the visa in time.</p>



<h2>Day 240 – December 2018</h2>



<p>I <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/">quit Mozilla</a>, so I then had no more reasons to go to their company all-hands…</p>



<h2>Day 365 – April 2019</h2>



<p><a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/" data-type="post" data-id="12216">A year passed</a>. “someone is working on it” the embassy email person claimed when I asked about progress.</p>



<h2>Day 651- January 28, 2020</h2>



<p>I emailed the embassy to query about the process</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/651-days-email.png" alt="" width="611" height="166"><figcaption>Screenshotted email</figcaption></figure>



<p>The reply came back quickly:</p>



<blockquote><p>Dear Sir, </p><p>All applications are processed in the most expeditious manner possible. While we understand your frustration, we are required to follow immigration law regarding visa issuances. This process cannot be expedited or circumvented. Rest assured that we will contact you as soon as the administrative processing is concluded.</p></blockquote>



<h2>Day 730 – April 2020</h2>



<p><a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/" data-type="post" data-id="13456">Another year had passed</a> and I had given up all hope. Now it turned into a betting game and science project. How long can they actually drag out this process without saying either yes or no?</p>



<h2>Day 871 – September 3, 2020</h2>



<p>A friend of mine, a US citizen, contacted his Congressman – <a href="https://en.wikipedia.org/wiki/Gerry_Connolly">Gerry Connolly</a> – about my situation and asked for help. His office then subsequently sent a question to the US embassy in Stockholm asking about my case. While the response that arrived on September 17 was rather negative…</p>



<pre>your case is currently undergoing necessary administrative processing and regrettably it is not possible to predict when this processing will be completed.</pre>



<p>… I think the following turn of events indicates it had an effect. It unclogged something.</p>



<h2>Day 889 – September 22, 2020</h2>



<p>After 889 days since my interview on the embassy (only five days after the answer to the congressman), the embassy contacted me over email. <em> For the first time since that April day in 2018.</em></p>



<pre>Your visa application is still in administrative processing. However, we regret to inform you that because you have missed your travel plans, we will require updated travel plans from you.</pre>



<p>My travel plans – that had been out of date for the last 800 days or so – suddenly needed to be updated! As I was already so long into this process and since I feared that giving up now would force me back to square one if I would stop now and re-attempt this again at a later time, I decided to arrange myself some updated travel plans. After all, I work for an American company and I have a friend or two there.</p>



<h2>Day 900 – October 2, 2020</h2>



<p>I replied to the call for travel plan details with an official invitation letter attached, inviting me to go visit my colleagues at <a href="https://www.wolfssl.com/">wolfSSL</a> signed by our CEO, Larry. I really want to do this at some point, as I’ve never met most of them so it wasn’t a made up reason. I could possibly even get some other friends to invite me to get the process going but I figured this invite should be enough to keep the ball rolling.</p>



<h2>Day 910 – October 13, 2020</h2>



<p>I got another email. Now at 910 days since the interview. The embassy asked for my passport “for further processing”.</p>



<h2>Day 913 – October 16, 2020</h2>



<p>I posted my passport to the US embassy in Stockholm. I also ordered and paid for “return postage” as instructed so that they would ship it back to me in a safe way.</p>



<h2>Day 934 – November 6, 2020</h2>



<p>At 10:30 in the morning my phone lit up and showed me a text telling me that there’s an incoming parcel being delivered to me, shipped from “the Embassy of the United State” (bonus points for the typo).</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png" alt="" width="496" height="211"></a></figure>



<h2>Day 937 – November 9, 2020</h2>



<p>I received my passport. Inside, there’s a US visa that is valid for ten years, until November 2030.</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg" alt="" width="441" height="221"></a><figcaption>The upper left corner of the visa page in my passport…</figcaption></figure></div>



<p>As a bonus, the visa also comes with a NIE (National Interest<br>Exception) that allows me a single entry to the US during the PP (Presidential Proclamations) – which is restricting travels to the US from the European Schengen zone. In other words: I am actually allowed to travel right away!</p>



<p>The timing is fascinating. The last time I was in the US, Trump hadn’t taken office yet and I get the approved visa in my hands just days after Biden has been announced as the next president of the US.</p>



<h2>Will I travel?</h2>



<p>Covid-19 is still over us and there’s no end in sight of the pandemic. I will of course not travel to the US or any other country until it can be deemed safe and sensible.</p>



<p>When the pandemic is under control and traveling becomes viable, I am sure there will be opportunities. Hopefully the situation will improve before the visa expires.</p>



<h2>Thanks to</h2>



<p>All my family and friends, in the US and elsewhere who have supported me and cheered me up through this entire process. Thanks for keeping inviting me to fun things in the US even though I’ve not been able to participate. Thanks for pushing for events to get organized outside of the US! I’m sorry I’ve missed social gatherings, a friend’s marriage and several conference speaking opportunities. Thanks for all the moral support throughout this long journey of madness.</p>



<p>A special thanks go to David (you know who you are) for contacting Gerry Connolly’s office. I honestly think this was the key event that finally made things move in this process.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035307</guid>
            <pubDate>Mon, 09 Nov 2020 14:47:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Free Features]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25034809">thread link</a>) | @alangibson
<br/>
November 9, 2020 | https://landshark.io/2020/11/09/no-free-features.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/09/no-free-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://news.ycombinator.com/item?id=25032105">This thread recently hit the top of Hacker news</a>.</p>

<blockquote>
  <p>No More Free Work from Marak: Pay Me or Fork This</p>

  <p>Respectfully, I am no longer going to support Fortune 500s
( and other smaller sized companies ) with my free work.</p>
</blockquote>

<p>The gist is that Marak, who’s on the brink of homelessness after his apartment building caught fire, is no longer interested in doing unpaid work for businesses using his <a href="https://github.com/Marak/faker.js">faker.js</a> project. He seems to be getting a lot of support from the open source developer community.</p>

<h2 id="unpaid-interns">Unpaid Interns</h2>

<p>The foundational principle of open source is “fix your problem, then give the world a copy of the solution.” So let’s get one thing straight: <em>open source developers are not volunteering to fix your problem.</em> They are fixing their own problems, then letting you use the solution too because it costs them nothing. That near-zero cost of replicating software is why open source works.</p>

<p>Because of this, I don’t think developers claiming to do open source should expect compensation for features that they need for themselves. But developing a new feature that they don’t need is something different entirely. In IT we call that a Change Request, and CRs come with a fee to cover them. ‘Near-zero cost’ doesn’t apply anymore because now they’re taking on a lot of work they otherwise wouldn’t have done.</p>

<p>Not recognizing this difference has led to a situation where for-profit entities are using open-source devs as unpaid interns. Well it’s worse really: at least interns get resume filler.</p>

<h2 id="no-more-free-features">No More Free Features</h2>

<p>I look forward to a day when asking anyone to do unpaid labor is considered unethical by our industry. That goes for feature requests on open source projects, on unpaid internships, and on unpaid ‘take home’ interview assignments.</p>

<p>Requesting work in an economic context without offering compensation in some form is morally indefensible. It’s wrong because unpaid labor is wrong. It’s wrong because presuming on anyone’s helpful nature is wrong. We shouldn’t be using bounties to move our change requests to the head of the line because we shouldn’t even be making requests without a bounty attached.</p>

<p>(<a href="https://news.ycombinator.com/item?id=25034809">Official Hacker News discussion thread</a>)</p>

</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/09/no-free-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034809</guid>
            <pubDate>Mon, 09 Nov 2020 13:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When remote work doesn't cut it]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25034037">thread link</a>) | @FlyingSnake
<br/>
November 9, 2020 | https://samkhawase.com/blog/remote-work/ | <a href="https://web.archive.org/web/*/https://samkhawase.com/blog/remote-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>The COVID-19 crisis, while disrupting the global world unlike anything before, has opened up an unexpected window to remote work. Nearly all major<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>tech<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> giants<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> have<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> allowed their workers to do home office. Many people are considering this as a sign of the advent of <strong>Work 2.0</strong>, where physical offices spaces will be irrelevant, and people can work from their cozy dens. There are however significant challenges in adoption of generalized remote work and things will be back as usual once the COVID-19 ends.</p>
<p>The <strong>challenges surrounding remote work outweigh it’s promises</strong>. Not every company is a FAANG, and companies will struggle to transition given their limited resources.</p>
<h2 id="regulations">Regulations</h2>
<p>The most significant hurdle in hiring a global remote team is <strong>regulation</strong>. Labor regulations are wildly different amongst countries, and could be cumbersome for some companies. Some major hurdles include:</p>
<ul>
<li>
<p><strong>Payroll taxes</strong>, retirement bonuses: Germany has rentenversicherung, sozialversicherung whereas USA has 401k contributions. Can a German company afford to <strong>setup payroll</strong> taxes for a remote workers hired from India, Chile or US? Or will it lead to worker abuse through <strong>laissez-faire abuse</strong> through freelance contracts?</p>
</li>
<li>
<p><strong>Notice periods</strong>: Europeans (on average) have 3 months notice period while US Americans have 2 weeks. How would a US company deal with it? On top of that, several countries have <strong>protection against unlawful termination</strong>, and how can a Slovakian employee avail that benefit against a German company?</p>
</li>
<li>
<p><strong>IP protection</strong>: It’s hard to <strong>protect IP</strong> if employees are not in the same jurisdiction. A company operation from Czechia would find it hard to settle trade disputes with a remote worker from South Africa. Another example is of <strong>TISAX compliance</strong> that is required for specialized hardware projects for Automotive industries. Remote work fails to make a dent in this situation.</p>
</li>
</ul>
<h2 id="hardware-cant-remote">Hardware can’t remote</h2>
<p>Patio11’s law<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> states that the <strong>economy is much bigger than you think</strong>. There are companies which have widely different business models and they often have a hardware related product. My <a href="https://www.salonlab-server.de/en-GB/">current project</a> is an IoT device that talks to an iPad app. The <strong>hardware team</strong> needs <strong>specialized tools</strong> to work on the IoT device, and these tools can’t be moved to home office. Remote work is a strict no-no for such products.</p>
<h2 id="swim-against-the-tide">Swim against the tide</h2>
<p>The biggest hurdle employees face in remote/home offices is <strong>lack of focus and direction</strong>. Humans have evolved over thousands of years to collaborate based on interpersonal cues, and a video call simply does not have the same effect. Humans need <strong>feedback</strong> and <strong>constructive communication</strong> whereas isolation kills the spirit. People who are new to remote work often feel <strong>rudderless</strong> because <strong>self discipline is hard</strong> when there’s no structure. I’m doing remote work on-and-off since 2018, and it took me a lot of discipline to get productive. The simple fact is that remote work is not natural, and not suited for all work streams in a typical company. Add to it the fact that many <strong>families</strong> simply don’t have space to work from home, and on top of that there might be kids around.</p>
<p>Remote work might be one of the few positive outcomes of the COVID-19 crisis but unless we tend to it carefully, we’ll end up creating a unhappy and unproductive workspace.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300">https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html">https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201">https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever">https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://secondbreakfast.co/patio11-s-law">https://secondbreakfast.co/patio11-s-law</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://samkhawase.com/blog/remote-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034037</guid>
            <pubDate>Mon, 09 Nov 2020 12:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The power of HTTP headers and examples]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25033398">thread link</a>) | @loweisz
<br/>
November 9, 2020 | https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Almost everything in the web is sent with <strong>http</strong> and even non-developers have seen it when using the internet as keyword
inside urls or links.</p>
<p>Http stands for <strong>Hypertext Transfer Protocol</strong> and gives us the ability to transfer hypertext between a browser and a server.
This is a great technology that has been around almost since the invention of the web and is constantly evolving and
<a href="https://en.wikipedia.org/wiki/HTTP/2">offering more and more great features</a></p>

<p>As a developer you probably heard of http headers, at least in the moment you heard about the CORS policy.
This is a problem you must have heard about when developing websites.
But what exactly are http headers and what other ways are there to use them?</p>
<p>Let us first find out what they do and how you could use them. </p>
<p>When a browser requests a resource, for example a page of this blog, it asks the server with a request.
This request looks something like this: </p>
<div data-language="js"><pre><code><span>fetch</span><span>(</span><span>"https://www.lorenzweiss.de/race_conditions_explained/"</span><span>,</span> <span>{</span>
  credentials<span>:</span> <span>"include"</span><span>,</span>
  headers<span>:</span> <span>{</span>
    accept<span>:</span>
      <span>"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3"</span><span>,</span>
    <span>"accept-language"</span><span>:</span> <span>"en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7"</span><span>,</span>
    <span>"cache-control"</span><span>:</span> <span>"max-age=0"</span><span>,</span>
    <span>"sec-fetch-mode"</span><span>:</span> <span>"navigate"</span><span>,</span>
    <span>"sec-fetch-site"</span><span>:</span> <span>"same-origin"</span><span>,</span>
    <span>"sec-fetch-user"</span><span>:</span> <span>"?1"</span><span>,</span>
    <span>"upgrade-insecure-requests"</span><span>:</span> <span>"1"</span><span>,</span>
  <span>}</span><span>,</span>
  referrerPolicy<span>:</span> <span>"no-referrer-when-downgrade"</span><span>,</span>
  body<span>:</span> <span>null</span><span>,</span>
  method<span>:</span> <span>"GET"</span><span>,</span>
  mode<span>:</span> <span>"cors"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>So you can see the URL or location of the resource, some information about the request and also a lot of headers with some information about the request.
This is how your browser tells the server some more information about the request. For example what kind of data type it accepts or
how the client is handling the cache.</p>
<p>After sending the request, the server replies, and it also sets some headers in the reply, which could look like this: </p>
<div data-language="text"><pre><code>:authority: www.lorenzweiss.de
:method: GET
:path: /race_conditions_explained/
:scheme: https
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
accept-encoding: gzip, deflate, br
accept-language: en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7
cache-control: max-age=0
cookie: _ga=GA1.2.1173972759.1584812492; _gid=GA1.2.2076192721.1594044231
sec-fetch-mode: navigate
sec-fetch-site: same-origin
sec-fetch-user: ?1
upgrade-insecure-requests: 1
user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36</code></pre></div>
<p>There is also some information that the server wants to tell the browser what to do with the resource, for example
if there are cookies, it must be determined which encoding was used, etc</p>
<p>Basically, in the http-context the headers for the communication of the browser and the server are used to extend the simple
Requests for resources. You could see it as the sheet of paper that is added on top of a package that you oder from an online store,
giving you more information about the context and the resource that you ordered.
Most of the headers have quite good defaults which you don't need to think of, but there are some headers that
can get quite important, like CORS headers. But there are so much more headers that you might never heard of which are very useful
and good to know how to use. </p>

<p>Do not worry, this article will not deal with CORS headers. The following http headers are those that are rarely used, but
can be really powerful and helpful to significantly improve the communication between a server and the browser. </p>
<p>So let's dig into it. Here are some headers that you can set and that are very useful and practical.</p>
<h2 id="if-range"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/If-Range">If-Range</a><a href="#if-range" aria-label="if range permalink"></a></h2>
<h3>What and why?</h3>
<p>Imagine you start downloading a large resource, such as a video, an image, etc., and stop in between because of connection problems.
With <code>If-Range</code> you can tell the server if the representation is unchanged, to send the part(s) that are requested in Range.
Which means only the parts that were missing and not again the whole thing.</p>
<p>This can be very helpful when dealing with large resources and often bad connections as with mobile devices.
Because the resource can be downloaded in parts even if the connection is interrupted in between. </p>
<h4>How to use</h4>
<p>It can either be used with a date when the resources were last modified, or with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a>, which is a key to help if the resources was invalidated</p>
<div data-language="text"><pre><code>If-Range: &lt;day-name&gt;, &lt;day&gt; &lt;month&gt; &lt;year&gt; &lt;hour&gt;:&lt;minute&gt;:&lt;second&gt; GMT
If-Range: &lt;etag&gt;</code></pre></div>
<h4>Example</h4>
<div data-language="text"><pre><code>If-Range: Wed, 21 Oct 2015 07:28:00 GMT </code></pre></div>
<h2 id="vary"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Vary">Vary</a><a href="#vary" aria-label="vary permalink"></a></h2>
<p><code>Vary</code> Comes from a time when the web or http was used for a variety of things and not just for web pages.<br>
It is based on the idea of using http to exchange information in many different formats.
How does it do that? Well, it tells the server in which header to find the information, how to present the information. </p>
<p>Nowadays it can be really helpful if you have different resources for different customers, for example
mobile, tablet or desktop.
Imagine three different images for the same resource are stored on the server, depending on the device.
Then you can simply use the <code>Vary</code> header to tell the server to check the device and then decide which image size to send. </p>
<h4>Example</h4>
<p>For the example with the device dependent images, you can simply pass the 'user agent' to tell the server
that it should check the user-agent for device information. </p>

<h4>How to use</h4>

<p>Just enter the header, the server must check before deciding which resource to send.</p>
<h2 id="content-disposition"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Content-Disposition">Content-Disposition</a><a href="#content-disposition" aria-label="content disposition permalink"></a></h2>
<p>If we go back to the example of a request to a server, for example to load this website, it is clear to the browser,
that it must <strong>display</strong> the resource of the answer.
But it can also be the case that the server sends a resource that the browser should automatically download to the user's computer,
like a picture or pdf etc.
A server can tell the browser what the browser should do with the attached resource via the <code>Content Disposition</code> header.</p>
<h4>Example</h4>
<p>With defining the <code>Content-disposition</code> to <code>attachment</code> the browser knows that this is a resource to download instead of just
show. </p>
<div data-language="text"><pre><code>Content-Disposition: attachment; filename="data.pdf"</code></pre></div>
<h4>How to use</h4>
<p>You can define the header as <code>inline</code> or <code>attachment</code>, where `inline is always the default.  </p>
<div data-language="text"><pre><code>Content-Disposition: &lt;inline | attachment&gt;</code></pre></div>
<h2 id="feature-policy"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy">Feature-Policy</a><a href="#feature-policy" aria-label="feature policy permalink"></a></h2>
<p>This is a fairly new header and therefore only supported by modern browsers (sorry to all IE users). However
I want to mention this anyway because I think it can be really helpful for some use cases.<br>
Basically, the <code>feature-policy tells the browser which features or apis the browser should provide to the document and its</code>iframes` to be used. </p>
<p>For example, it can ban all scripts or iframes etc. within this website to allow sensitive apis like the camera or microphone.</p>
<h4>How to use</h4>
<div data-language="text"><pre><code>Feature-Policy: &lt;directive&gt; &lt;allowlist&gt;</code></pre></div>
<p>The <code>directive</code> is the name of the feature. You can see the full <a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy#Directives">list of features here</a>
The <code>allowlist</code> defines the origins which are allowed to use the directive.</p>
<h3>Example</h3>
<p>Suppose we want our website to use neither the microphone nor the camera. With this header the
document or a contained iframe cannot access these functions.</p>
<div data-language="text"><pre><code>Feature-Policy: microphone 'none'; camera 'none'</code></pre></div>
<h3>More Headers:</h3>
<p>Here are some more headers that are worth mentioning: </p>
<ul>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests">Upgrade-Insecure-Requests</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Age">Age</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Trailer">Trailer</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Location">Location</a></li>
</ul>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="conclusion permalink"></a></h2>
<p>Https headers are great and also very useful! But sometimes they can be quite complex, and it's really hard to get an overview of what headers are available and what benefits they bring.
Also when developing a website, especially in the frontend, you don't come in contact with them too often, except maybe with the CORS headers.
But I think that this missed some possibilities. http headers represent the communication between the server and the
customers much better, and we all know that communication is the key to a good relationship.</p>
<p>I hope I could shed some light on the darkness of http headers for you. In case I missed a good and helpful header,
please do not hesitate to send me a mail or contact me in any way.</p></div></div>]]>
            </description>
            <link>https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033398</guid>
            <pubDate>Mon, 09 Nov 2020 10:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Days in Desktop Web Browsers]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25033290">thread link</a>) | @svenfaw
<br/>
November 9, 2020 | https://www.radsix.com/dashboard1/ | <a href="https://web.archive.org/web/*/https://www.radsix.com/dashboard1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.radsix.com/dashboard1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033290</guid>
            <pubDate>Mon, 09 Nov 2020 10:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Towards 1.0]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 102 (<a href="https://news.ycombinator.com/item?id=25032956">thread link</a>) | @lelf
<br/>
November 9, 2020 | https://pijul.org/posts/2020-11-07-towards-1.0/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-11-07-towards-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
                We are looking for <strong>VC funding</strong>. If you are interested in helping us build the future of collaboration (for code and other documents), shoot us an email at <a href="mailto:contact@pijul.org">contact@pijul.org</a>.
                
            </p>


<p>Saturday, November 7, 2020</p>
<p>After fixing the performance and scalability problems, we’re on our way to getting a stable Pijul. In this post, I explain what I’ve been up to in the recent months.</p>
<h2 id="context">Context</h2>
<p>Pijul has always been advertised as a research project, trying to implement a theory of patches that would be sound and fast. This is an ambitious goal, and became even more ambitious than initially envisioned.</p>
<p>One of the hardest challenges is that source code is by essence stateful, which makes it much harder to iterate over algorithm designs, like normal research projecst need to. For example, in order to get from our last published version to our current design, we have gone through many different variants, and there wasn’t much to publish.</p>
<p>Moreover, the UX aspect is what matters most in the end, and testing it on a real world project is the only way to get it there. However, unlike in a compiler, where bootstrapping is done one step at a time, and previous versions are always available to compile your current one, a version control system has the additional problem that the previous versions might not always be easily accessible if there is a bug.</p>
<p>One of the criticisms I’ve heard since I realised that better datastructures were possible is that I was “working secretely”. I certainly understand this feeling, but this is based on a misunderstanding of how research works. When I first had the idea that I’m explaining in this post, I realised that a complete rewrite would be needed. But for a very long time, almost nothing other than unusable, unreadable prototypes happened.</p>
<p>Back then, there wasn’t much to show, since it wasn’t even clear that the basic datastructure would work. And even when they started working at a large enough scale, it took me quite a bit of testing on large repositories before they started actually working.</p>
<p>This also implies that there wasn’t much to show for quite a while, since the new algorithm wasn’t usable until very recently, and any repository started before now would have become obsolete in a matter of days.</p>
<p>There were also <a href="#a-personal-note">persoprofessional reasons</a> for this silence, described at the end of this post.</p>

<p>Pijul depends on two other projects I’ve started.</p>
<h3 id="sanakirja">Sanakirja</h3>
<p>One of these projects is Sanakirja, which is “just” a key-value store, but has the extra feature that databases can be cloned efficiently. I would have loved to just use an existing library, but there just isn’t any that has this cloning feature. However, the scope of Sanakirja is still quite modest, it does one thing and does it well. Obviously, it took some time to find the memory-management bugs, but I have good confidence that this is now done.</p>
<p>In previous releases of Pijul, databases were implemented with a single mmapped file containing the binary representation of B Trees. Despite their lower writing performance (compared to alternatives such as <em>Log-structured merge-trees</em>), and the complexity of the code for deletions, B Trees are very well suited to this use case: indeed, since they are trees, reference-counting the nodes is enough to implement efficient clones.</p>
<p>One of the remaining issues was that in order to grow the database, we needed to un-mmapped the file, grow it, and mmap it again. Since applying a single change in Pijul must be an atomic operation, we needed to cancel the transaction when that happened, and restart it with a bigger file.</p>
<p>Another issue is that I wanted the next libpijul to compile on platforms that don’t have mmap, such as WASM. However, if reallocating an mmapped file has a very low complexity (even though it does have a non-zero cost in terms of system calls), reallocating a chunk of memory often requires copying everything. This completely defeats the point of the algorithms in Pijul, which rely on a particular representation of the datastructures on the disk.</p>
<p>The main innovation in Sanakirja 0.13 is to use a vector of memory blocks (either in memory or mmapped from a file), of exponentially-increasing size. The overhead is just one extra indirection, the complexity of adding items is the same (since the operation of creating an extra block is $O(1)$). The exponentially-increasing sizes mean that the allocated memory is always at least half-full.</p>
<h3 id="thrussh">Thrussh</h3>
<p>The other one is Thrussh. That library implements the SSH protocol, and tries to handle a number of key formats. The former is a surprisingly easy goal, and keeping up with Tokio versions has historically been the hardest bit, while the latter is the most horrendous hydra-like task, with new heads and legacy formats showing up every time you think you’re done.</p>
<h2 id="how-repositories-used-to-work-and-still-do-to-some-extent">How repositories used to work (and still do, to some extent)</h2>
<p>Old-style repositories represented a single file by a directed graph $G = (V, E)$ of lines, where each vertex $v\in V$ represented a line, and an edge from $u \in V$ to $v\in V$, labelled by some change (also called patch) number $c$, could be read as “according to change $c$, line $u$ comes before $v$”.</p>
<p>This means that changes could introduce vertices and lines, as in the following example, where a line $D$ is introduced between $A$ and $B$:</p>
<p><img src="https://pijul.org/img/repos-line-add.svg">
</p>
<p>Here, the thick line represents the change from the file containing the lines $A$, $B$, $C$ to the file with the new line $D$.
An important feature to note is that <strong>vertices are uniquely identified</strong>, by the hash of the change that introduced them, along with a position in that change. This means that two lines with the same content, introduced by different changes, will be different. It also means that a lines keeps its identity, even if the change is applied in a totally different context.</p>
<p>Moreover, this system is append-only, in the sense that <em>deletions</em> are handled by a more sophisticated labelling of the edges. In the example above, if we want to delete line $D$, we just need to make a change mapping the edge introduced by $c_0$ to a deleted edge, which we label by the name $c_1$ of the change that introduces it:</p>
<p><img src="https://pijul.org/img/repos-line-del.svg">
</p>
<p>From now on, we call the full edges <strong>alive</strong>, and the dashed ones <strong>dead</strong>.</p>
<p>We have just described the two basic kinds of actions in Pijul. There are no other. One kind adds vertices to the graph, along with “alive” edges around them, and the other kind maps an existing edge label onto a different one.
In order to fully described the system, I also need to mention that the edge labels are given by two parameters: their status (alive, deleted, and a few others related to multiple files and technical details explained below) and the change that introduced them.</p>
<h3 id="dependencies">Dependencies</h3>
<p>This scheme allows to defines dependencies between changes:</p>
<ul>
<li>
<p>If a change $c$ adds a vertex, we must have its <em>“context”</em>, i.e. the lines before and after it, hence the changes that introduced these lines are in the dependencies of $c$.</p>
</li>
<li>
<p>If a change $c$ deletes a vertex, or in other words maps an existing edge introduced by a change $d$, then $c$ must depend on $d$.</p>
</li>
</ul>
<p>Of course, this is just the minimal set of dependencies needed to make sense of the text edits. Hooks and scripts may add extra language-dependent dependencies based on semantics.</p>
<h3 id="are-edge-labels-minimal">Are edge labels minimal?</h3>
<p>Our goals is to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance. Therefore, one immediate question comes to mind: why even keep the change number on the edges?</p>
<p>In order to answer that question, suppose we don’t keep the labels, meaning that the maps happen between statuses only. Then, consider the following two situations:</p>
<ul>
<li>
<p><strong>Change inverses</strong></p>
<p>The first issue happens when two authors delete a line in parallel, and one of the authors reverts their change. Applying these changes yields the following diagram, where the two deletions get merged into one, and the inverse applies to both:</p>
 <p><img src="https://pijul.org/img/inverse2.svg">
 </p>
<p>However, this is not what we expect, since one of the authors explicitly reverted the deletion, while the other performed the same deletion in parallel.
By keeping the labels, this is what we get instead:</p>
 <p><img src="https://pijul.org/img/inverse3.svg">
 </p>
</li>
<li>
<p><strong>Missing contexts</strong></p>
<p>For the sake of clarity, in the rest of this post, we name two users Alice (with pronouns “she/her”) and Bob (with pronouns “he/his”).</p>
<p>This situation, where Alice writes something in the middle of a paragraph $p$, while Bob deletes $p$ in parallel.
One issue here, is that the situation is not symmetric: when Bob applies Alice’s change, he can tell immediately that something is wrong, because the context of Alice’s edits is labelled as deleted in his repository.</p>
 <p><img src="https://pijul.org/img/known-vertices1.svg">
 </p>
<p>However, Alice’s situation is different: indeed, consider the case where instead of deleting $p$ <em>in parallel</em> of her changes, Bob deleted $p$ after applying Alice’s change. The edges deleted are exactly the same, but this is not a conflict, as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices2.svg">
 </p>
<p>The situation is further complicated by the fact that this system doesn’t behave symmetrically with the contexts above and below the new line. Indeed, if Bob deleted the <em>down context</em> of the line (i.e. if he deleted line $C$) instead of the <em>up context</em> (line $B$), Alice could detect the conflict, since in that case, $C$ would have both an alive and a dead edge pointing to it ($C$ is called a “zombie vertex” internally), as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices0.svg">
 </p>
<p>Keeping the change identifiers on each edge allows us to solve this. In Pijul 0.12, Bob would add the labels of all the edges around the deleted lines to the dependencies of his change. Then, Alice can tell whether Bob knows of her change before applying it. The changes are conflict if and only if Bob doesn’t know of the new lines.</p>
<p>However, this behaviour was counter-intuitive, <a href="https://discourse.pijul.org/t/why-these-patches-dont-commute/449">as noted by @tae</a>.</p>
<p>A finer analysis of what dependencies are led to a different behaviour in the new Pijul. Changes now have two different sets of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pijul.org/posts/2020-11-07-towards-1.0/">https://pijul.org/posts/2020-11-07-towards-1.0/</a></em></p>]]>
            </description>
            <link>https://pijul.org/posts/2020-11-07-towards-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032956</guid>
            <pubDate>Mon, 09 Nov 2020 09:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Beauty of Python's ExitStack (2015)]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25032924">thread link</a>) | @polm23
<br/>
November 9, 2020 | https://www.rath.org/on-the-beauty-of-pythons-exitstack.html | <a href="https://web.archive.org/web/*/https://www.rath.org/on-the-beauty-of-pythons-exitstack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I believe Python's <a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> feature does not get the recognition
it deserves. I think part of the reason for this is that its
documentation is somewhere deep down in the (already obscure)
<a href="http://docs.python.org/3/library/contextlib.html">contextlib</a> module because formally ExitStack is just one of many
available context managers for Python's <a href="http://docs.python.org/3/reference/compound_stmts.html#the-with-statement">with statement</a>. But
ExitStack deserves far more prominent notice than that. This post will
hopefully help with that.</p>
<p>So what makes ExitStack so important? In short, it's the best way to
handle allocation and release of external resources in Python.</p>
<div id="the-problem">
<h2>The Problem</h2>
<p>The main challenge with external resources is that you have to release
them when you don't need them anymore -- and in particular you must
not forget to do so in all the alternate execution paths that may be
entered in case of error conditions.</p>
<p>Most languages implement error conditions as "exceptions" that can be
"caught" and handled (Python, Java, C++), or as special return values
that you need to check to determine if an error occured (C, Rust,
Go). Typically, code that needs to acquire and release external
resources then looks like this:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>try</span><span>:</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>try</span><span>:</span>
        <span># do stuff with res1 and res2</span>
    <span>finally</span><span>:</span>
        <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>finally</span><span>:</span>
   <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
</pre></div>
<p>or, if the language doesn't have exceptions:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
   <span>goto</span> <span>error_out1</span><span>;</span>
<span>}</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>2</span><span>;</span>
   <span>goto</span> <span>error_out2</span><span>;</span>
<span>}</span>
<span>// do stuff with res1 and res2</span>
<span>retval</span> <span>=</span> <span>0</span><span>;</span> <span>// ok</span>

<span>error_out2</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res2</span><span>);</span>
<span>error_out1</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res1</span><span>);</span>
<span>return</span> <span>retval</span><span>;</span>
</pre></div>
<p>This approach has three big problems:</p>
<ol>
<li>The cleanup code is far away from the allocation code.</li>
<li>When the number of resources increases, indentation levels (or jump
labels) accumulate, making things hard to read.</li>
<li>Managing a dynamic number of resources this way is impossible.</li>
</ol>
<p>In Python, some of these issues can be alleviated by using the
<tt>with</tt> statement:</p>
<div><pre><span></span> <span>@contextlib.contextmanager</span>
 <span>def</span> <span>my_resource</span><span>(</span><span>id_</span><span>):</span>
     <span>res</span> <span>=</span> <span>acquire_resource</span><span>(</span><span>id_</span><span>)</span>
     <span>try</span><span>:</span>
         <span>yield</span> <span>res</span>
     <span>finally</span><span>:</span>
         <span>release_source</span><span>(</span><span>res</span><span>)</span>

<span>with</span> <span>my_resource</span><span>(</span><span>RES_ONE</span><span>)</span> <span>as</span> <span>res1</span><span>,</span> \
   <span>my_resource</span><span>(</span><span>RES_TWO</span><span>)</span> <span>as</span> <span>res2</span><span>:</span>
    <span># do stuff with res1</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>However, this solution is far from optimal: you need to implement
resource-specific context managers (note that in the above example we
silently assumed that both resources can be acquired by the same
function), you can get rid of extra indentation only if you allocate
all the resources at the same time and live with an ugly continuation
line (no parenthesis allowed in this context), and you still need to
know the number of required resources ahead of time.</p>
<p>Over in the world of exception-less programming languages (no pun
intended), <a href="http://www.golang.org/">Go</a> has developed a different remedy: the <a href="http://golang.org/ref/spec#Defer_statement">defer statement</a>
defers execution of an expression until the enclosing
function returns. Using <tt>defer</tt>, the above example can be written
as:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>1</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>2</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>// do stuff with res1 and res2</span>
<span>return</span> <span>0</span>
</pre></div>
<p>This is pretty nice: allocation and cleanup are kept close together,
no extra indentation or jump labels are required, and converting this
to a loop that dynamically acquires multiple resources would be
straightforward. But there are still some drawbacks:</p>
<ul>
<li>To control when exactly a group of resources is getting released you
have to factor out into separate functions all parts of code that
access the respective resources.</li>
<li>You cannot "cancel" a deferred expression, so there is no way to
e.g. return a resource to the caller if no error occured.</li>
<li>There is no way to handle errors from the cleanup functions.</li>
<li><tt>defer</tt> is available in Go, but not in Python.</li>
</ul>
</div>
<div id="exitstack-to-the-rescue">
<h2>ExitStack to the rescue</h2>
<p><a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> fixes all of the above issues, and adds some benefits on
top of it. An ExitStack is (as the name suggests) a stack of clean-up
functions. Adding a callback to the stack is the equivalent of calling
Go's <tt>defer</tt> statement. However, clean-up functions are not executed
when the function returns, but when execution leaves the <tt>with</tt>
block - and until then, the stack can also be emptied again.</p>
<p>Finally, clean-up functions itself may raise exceptions without
affecting execution of other clean-up functions. Even if multiple
clean-ups raise exceptions, you are will get a usable stacktrace.</p>
<p>Here's how to acquire multiple resources:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res1</span><span>)</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res2</span><span>)</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>Note that</p>
<ul>
<li>acquisition and release are close to each other</li>
<li>there's no extra indentation,</li>
<li>the pattern and it easily scales up to many resources (including a
dynamic number that's acquired in a loop)</li>
</ul>
<p>If there already is a context manager for your resource, there's also
a shortcut function:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'first_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'second_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>To open a bunch of files and return them to the caller (without
leaking already opened files if a subsequent open fails):</p>
<div><pre><span></span><span>def</span> <span>open_files</span><span>(</span><span>filelist</span><span>):</span>
    <span>fhs</span> <span>=</span> <span>[]</span>
    <span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
        <span>for</span> <span>name</span> <span>in</span> <span>filelist</span><span>:</span>
            <span>fhs</span><span>.</span><span>append</span><span>(</span><span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>name</span><span>,</span> <span>'r'</span><span>)))</span>
        <span>cm</span><span>.</span><span>pop_all</span><span>()</span>
        <span>return</span> <span>fhs</span>
</pre></div>
<p>Disclaimer: the <a href="https://bugs.python.org/issue13585">original idea for ExitStack</a> came from me.</p>
</div>
</div></div>]]>
            </description>
            <link>https://www.rath.org/on-the-beauty-of-pythons-exitstack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032924</guid>
            <pubDate>Mon, 09 Nov 2020 09:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm going to experiment by being Blind and Alone for 24 Hours]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25031774">thread link</a>) | @Osiris30
<br/>
November 8, 2020 | https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-896">

	
	<!-- .entry-header -->


			<div>

			
<figure><img data-attachment-id="901" data-permalink="https://dormin.org/bird-box/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg" data-orig-size="2000,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bird-box" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=760" src="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024 1024w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300 300w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=768 768w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For 24 hours I will be blind and alone in my apartment. I eventually want to try being blind for a week, but I’ll need seven days with no other obligations, and I won’t have that for a while. For now, I’ll suffice with a smaller-scale experiments with a few extra provisions for added difficulty.</p>







<ol type="1"><li>I must leave my blindfold on for 24 hours.<ul><li>If I remove the blindfold, I have failed the experiment</li><li>If the blindfold falls off or I can get partial sight, I have failed the experiment.</li><li>I am only allowed to readjust my blindfold if I can see light.</li></ul></li><li>I must not be in contact with any other people for 24 hours.<ul><li>I cannot answer my phone or any other messaging system.</li><li>I cannot receive in-person visitors.</li><li>If someone knocks at the door, I cannot answer verbally or physically.</li></ul></li><li>I will set an alarm for 24 hours. I cannot set any other alarms or use any other means to ascertain the time.<ul><li>It is up to me to keep my phone charged so the alarm goes off.</li></ul></li><li>I cannot leave my apartment.</li></ol>











<p>I have no good reason. I just want to see if I am capable of doing it and what will happen. Some things I’m curious about:</p>



<ul><li>Do I have the willpower to get through the experiment?</li><li>Will I become disoriented from losing all sense of time?</li><li>Will I be able to stave off boredom with podcasts, audiobooks, and music on my phone?</li><li>Will I enter some sort of meditative state due to a lack of sensory input?</li><li><a href="https://www.discovermagazine.com/the-sciences/scientists-made-people-wear-blindfolds-for-4-days-the-resulting-hallucinations-were-incredible">Will I hallucinate</a>?</li><li>Will my non-sight senses heighten?</li><li>Will I hurt myself by falling or banging into something?</li><li>Will I sleep?</li><li>Will I eat? Is consuming caffeine a good idea (for entertainment) or a bad idea (energy with no direction)?</li><li>Will this experience make me more interested in being blind for a week? Or less?</li></ul>



<figure><img src="https://digitalimpact.io/wp-content/uploads/2014/08/Blind.png" alt="Modern CEOs Are Blindfolded - Digital Impact"></figure>







<p>Attempt One started at 10:30 AM and failed at 1:13 PM. I purposefully took off my blindfold because I was worried that my multiple failures to input my Iphone’s password had resulted in a permanent lock or data wipe. But the password screen was just locked for a minute and all was well.</p>



<p>Given that I failed in the early afternoon, I considered restarting the experiment on another day in the morning. But I had already carved out a 24 hour period when I wouldn’t do any work or be disturbed, and it might have been a week or two longer before I got that opportunity again.</p>



<p>So I checked my messages, briefly went on Reddit, and then restarted.</p>



<div><figure><img data-attachment-id="903" data-permalink="https://dormin.org/t86752/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg" data-orig-size="521,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;CSA Images \/ CSA Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Blindfolded Woman&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 CSA Images \/ CSA Images&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;T86752&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="T86752" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" src="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg 521w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=128 128w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256 256w" sizes="(max-width: 521px) 100vw, 521px"></figure></div>







<p>Attempt Two was successful. I put on my blindfold at 1:23 PM on Thursday, November 5, 2020. I removed it at 1:28 PM on Friday, November 6.</p>



<p>It was an… interesting experience. I don’t recommend it, but I’m glad I did it. I’m not sure where to begin in describing it, especially since I couldn’t take notes, and part of the challenge was being confused. But I’ll do my best to break down the experience.</p>



<div><figure><img src="https://cdn.shopify.com/s/files/1/0818/3417/products/Les_Sublimes_Cashmere_Scarf_Dark_Blue_packshot_2048x.jpg?v=1539973736" alt="Large Cashmere Scarf in Dark Blue | Les Sublimes" width="427" height="427"></figure></div>



<h2><strong><span>Blindfold</span></strong></h2>



<p>To simulate blindness, I used a dark blue scarf as a blindfold. One layer wasn’t quite dark enough, so I folded it in half for extra light defense.</p>



<p>With the blindfold securely on, my vision was the same whether my eyes were open or closed. I kept my eyes closed 99.9% of the time since it was usually more comfortable and helped limit light. I occasionally opened my eyes to check the brightness level and to… I guess you could call it <em>stretch my eyelids.</em> They don’t feel good if you leave them closed for too long.</p>



<p>I couldn’t get a perfect scarf seal around my eyes, so sometimes when I tilted my head back while sitting I noticed a little light come into the bottom of my vision. To limit this, I often pinched the scarf around my nose in that position. But many/most blind people can see some light anyway, so I don’t think this was a significant violation of the experiment.</p>



<p>My eyes got quite dry under the scarf, so I applied moisturizer to this lids and sockets four or five times. I wanted to use eyedrops too, but there was no way to do so without failing the experiment.</p>



<figure><img loading="lazy" data-attachment-id="906" data-permalink="https://dormin.org/image/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" data-large-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" src="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" alt="BLACK N BLACK - #blackouttuesday ✊🏻✊🏼✊🏽✊🏾✊🏿 | Facebook" width="786" height="786" srcset="https://dorminorg.files.wordpress.com/2020/11/image.jpeg 225w, https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=150 150w" sizes="(max-width: 786px) 100vw, 786px"></figure>



<h2><strong><span>Blindness</span></strong></h2>



<p>Initially, everything was black, but as the day went on and the sun went down, I could tell it was nighttime even through two layers of scarf and my eyelids. I’m not sure if I could tell because my eyes had adjusted to become extremely sensitive to light, or if there were other subtle signals (ie. noises, air temperature, circadian rhythms, etc.) which my body picked up on. As evidence of the latter, I could not see any difference between the tv being on or off, nor the refrigerator being opened or closed, even when I was sitting right in front of either.</p>



<p>What I saw depended on how I applied my focus. If I did focus on my vision, I’d see the typical blackness you get from closing your eyes, but it was never perfectly black nor uniform; there was always some odd movement and occasional coloring (whiteness, pale blue, or sometimes red). The most common distortions were a swirling or flowing whiteness, sort of like cream in coffee. I hoped that being blindfolded for so long would make the distortions more extreme, but for the most part it looked no different than what you’d see if you closed your eyes right now for ten minutes.</p>



<p>There was one exception. It must have been about 20+ hours into the experiment, and my eyes were itching, so I rubbed both of them at the same time over the scarf. If you rub your closed eyes and focus on your sight any time you can see some weird stuff, but this was far more extreme than usual. I remember my entire vision filling up with white bubbles which then broke and briefly returned to black. Then white lightning bolt shapes stretched across my sight, expanded to make my vision purely white, and then slowly faded back to black. The strangest thing about it was the <em>brightness</em>. I literally felt like I was staring into lights despite being blindfolded in a dark room. Unfortunately, it only lasted about 30 seconds, but my heart was racing.</p>



<p>More notable than what I saw was what I didn’t see. By default, I was lost in thought and I focused on nothing. In such a state, I didn’t even register my vision or notice the darkness. I <em>think</em> this made my imagination and mental visualization more acute. On occasion, I’d be deep in thought and I’d get the <em>brightness</em> sensation again because I’d be mentally picturing something so vividly that the inevitable return to darkness felt like shutting off the lights in my brain. I’ll explain more about this in the <strong>Three Phases</strong> section.</p>



<p>Sadly, I did not hallucinate, or at least not as far as I could tell.</p>



<figure><img src="https://i1.wp.com/www.intelligentliving.co/wp-content/uploads/2014/07/sloth-sleeping.jpg?fit=1024%2C698&amp;ssl=1" alt="Fighting Bacteria With Sloth Fur"></figure>



<h2><strong><span>Energy</span></strong></h2>



<p>This was the most surprising aspect of the experiment.</p>



<p>I read that <a href="https://abcnews.go.com/Health/story?id=117902&amp;page=1#:~:text=Without%20light%20cues%20that%20the,as%20a%20result%2C%20researchers%20say.">blind people have trouble getting to sleep</a> because they don’t access any/enough light for their circadian rhythms. I seem to have the exact opposite problem. Without light, my body always thinks it’s time to sleep and has trouble doing anything else. Throughout most of the experiment, I felt extremely lethargic, lazy, and had to fight to stay awake.</p>



<p>I started my first failed experiment attempt at 10:30 AM. I had gotten 7.5 solid hours of sleep, I hadn’t done anything tiring the previous day, and I generally felt fine. Then I put on my blindfold, and within thirty minutes I was nodding off. I semi-slept for two hours before deciding to get an energy drink to get myself out of the funk. That worked, but as soon as it wore off, I was back in semi-sleep mode.</p>



<p>Even when I was firmly awake, I generally felt weak and lethargic. Movement around the apartment was annoying of course, but made so much more difficult by my energy levels. I ended up lying perfectly still in my comfy computer chair with my feet on a table 95% of the time. That is, when I wasn’t lying in bed.</p>



<p>On the other hand, when I removed my blindfold after 24 hours, I experienced a <em>burst</em> of energy. Seriously, it was like I had downed a double shot of espresso. It was like a switch had been flicked. The haziness and cobwebs were gone in an instant, and I felt the energy coursing through my body. I guess light has a big impact on me.</p>



<div><figure><img data-attachment-id="908" data-permalink="https://dormin.org/blind-man-2/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg" data-orig-size="615,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1604789422&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="blind-man-2" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" src="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg 615w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300 300w" sizes="(max-width: 615px) 100vw, 615px"></figure></div>



<h2><strong><span>Movement</span></strong></h2>



<p>I moved exactly how you’d expect… clumsily.</p>



<p>For the most part, I slowly walked around my apartment with a hand out to feel for walls and edges. Sometimes I’d get lazy and crawl just so it was easier. I know my apartment well enough that it wasn’t hard to get around, but every once in awhile I’d lose track of where I was and would be left slowly swinging my arm around searching for anything. It’s not a pleasant sensation.</p>



<p>Before the experiment, I had planned to pace around for fun, or maybe even do some exercise with the free time. But the confusion and especially the lethargy stopped all that. I just sat in my chair and didn’t move unless I needed to get a drink, go to the bathroom, or sleep.</p>



<p>I kind of wish I had done the experiment in an unfamiliar environment to add to the movement challenge, but oh well.</p>



<div><figure><img src="https://secure.img1-fg.wfcdn.com/im/99629273/compr-r85/1167/116715839/dual-flush-elongated-one-piece-toilet-seat-included.jpg" alt="DeerValley Dual-Flush Elongated One-Piece Toilet (Seat Included) &amp; Reviews  | Wayfair" width="729" height="729"></figure></div>



<h2><strong><span>Necessities</span></strong></h2>



<p>For food, I ate a big lunch at 10 AM before the experiment and then munched on dark chocolate throughout the night. I felt the heavy lethargy well before the lack of calories was an issue. I probably should have put some prepackaged meals in my fridge to eat, but I was worried about making a mess and not being able to clean up. Do I want ants? Because that’s how I get ants.</p>



<p>For drinks, I could manage to get to the kitchen and fill a cup with water when I needed to. I never took a full cup back to my chair just in case I knocked it over (clean up would be a nightmare). I also had some diet coke to serve as entertainment and put a little caffeine in me.</p>



<p>For the bathroom, I (a man) peed sitting down. I’m not ashamed to admit it.</p>



<div><figure><img src="https://imgaz2.staticbg.com/thumb/large/oaupload/banggood/images/F2/09/b934b522-e3e3-491d-b758-d0b92c259f0c.jpg" alt="Novel surreal melting distorted wall clock surrealist salvador dali style  wall clock amazing home decoration gift Sale - Banggood.com" width="802" height="801"></figure></div>



<h2><strong><span>Time</span></strong></h2>



<p>As part of the experiment, I never knew what time it was. This was intended to confuse me throughout the 24 hours, and it did, but it may have helped too. With no sense of time, it was easy to sit back and not think about it. Time drifted by and I existed. That was that.</p>



<p>I actually did ask Siri for the time once… it was late in the experiment, and it felt like I had put on the blindfold forever ago. As you’d expect, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031774</guid>
            <pubDate>Mon, 09 Nov 2020 05:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with pen and paper]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25031483">thread link</a>) | @sethetter
<br/>
November 8, 2020 | https://sethetter.com/posts/start-with-pen-and-paper/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/start-with-pen-and-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            


<article>
    
    <section>
        <p>tl;dr — If you feel unfocused, grab a pen and paper and start writing your thoughts down.</p>
<p>Is there a question you are stuck on? A ambiguous goal you're trying to accomplish? Maybe a task you know you need to do but from which you keep getting distracted?</p>
<p><strong>Nothing will provide focus like pen and paper.</strong></p>
<p>It's all too easy these days to have a clear intention only to be sidetracked by the whirlpool of apps and services clawing for our attention on our devices.</p>
<p>It helps to take the time to groom our notification settings for importance and timeliness, but a digital device that we can use to complete nearly any task will never stand up to pen and paper in terms of it's ability to provide focus.</p>
<p>My thoughts are a constant whirlwind, I'm certainly more distractible than most, and interacting with nearly any online service only fuels that fire. So how can I get anything done if I'm unable to control my focus?</p>
<p><strong>Pen and paper.</strong> Whenever I catch myself stuck in the whirlpool, feeling not-great because I <em>know</em> I'm not doing what I want to be doing, or what I should be doing, I step away, grab pen and paper, and start writing.</p>
<p>The simple act of writing can focus my thoughts and attention in a way that nothing else can. Free from distractions, just a canvas to pour my thoughts into, and turn them into something with a sense of direction and purpose.</p>
<p>Writing is like a superpower to me. If there's any task I want to accomplish, the first step is always to write it down. Anytime I need to recenter myself on that task, I simply return to paper.</p>
<p>Throughout my life I've found that the simplest solutions are often the most powerful. So far I've found no simpler solution to start tackling any problem than to simply write it down, and then keep on writing.</p>

    </section>
</article>


        </div></div>]]>
            </description>
            <link>https://sethetter.com/posts/start-with-pen-and-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031483</guid>
            <pubDate>Mon, 09 Nov 2020 04:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool Machine Learning Books]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25031455">thread link</a>) | @ridddle
<br/>
November 8, 2020 | http://matpalm.com/blog/cool_machine_learning_books/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/cool_machine_learning_books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p>awhile ago i posted
   <a href="http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/">my list of cool machine learning books</a>,
   but it's been awhile so it's probably time to update it...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mml.jpg"></p>
<p><b><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a>
   by Marc Peter Deisenroth, A. Aldo Faisal &amp; Cheng Soon Ong.</b>
</p>
<p>this is my personal favorite book on the general math required for machine learning,
   the way things are described really resonate with me.
   available as a free pdf but i got a paper copy to support the authors after reading the
   first half.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/laalfd.jpg"></p>
<p><b><a href="http://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data</a>
   by Gilbert Strang.</b>
</p>
<p>this is gilbert's most recent work. it's really great, he's such a good teacher, and
   <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/">his freely available lectures</a>
   are even better. it's a shorter text than his other classic intro below with
   more of a focus on how things are connected to modern machine learning techniques.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itla.jpg"></p>
<p><b><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a>
   by Gilbert Strang.</b>
</p>
<p>this was my favorite linear algebra book for a long time before his 'learning from
   data' came out. this is a larger book with a more comprehensive view of linear algebra.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ts.jpg"></p>
<p><b><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats: Probability and Statistics for Programmers</a> by Allen Downey.</b>
</p>
<p>this book focuses on practical computation methods for probability and statistics.
   i got a lot out of working through this one.
   it's all in python and available for free.
   ( exciting update! as part of writing this post i've discovered there's a new edition
   to read!)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dbda.jpg"></p>
<p><b><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>
   by John Kruscgke</b>
</p>
<p>on the bayesian side of things this is the book i've most enjoyed working through.
   i've only got the first edition which was R and
   <a href="https://en.wikipedia.org/wiki/OpenBUGS">BUGS</a> but i see
   the second edition is R,
   <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> and
   <a href="https://mc-stan.org/">Stan</a>.
   it'd be fun i'm sure to work through it doing
   everything in <a href="https://github.com/pyro-ppl/numpyro">numpyro</a>. i might do that in all
   my free time. haha. "free time" hahaha. sob.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/eosl.jpg"></p>
<p><b><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>
   by Hastie, Tibshirani and Friedman</b>
</p>
<p>this is still one of the most amazing fundamental machine learning books i've ever had.
   in fact i've purchased this book <em>twice</em> and given it away both times :/ i might buy another
   copy some time soon, even though it's been freely available to download for ages. an
   amazing piece of work.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pgm.jpg"></p>
<p><b>
   <a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a>
   by Daphne Koller &amp; Nir Friedman</b>
</p>
<p>this is an epic textbook that i'd love to understand better. i've read a couple of sections in
   detail but not the entire tome yet.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/praml.jpg"></p>
<p><b>
   <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">Pattern Recognition and Machine Learning</a>
   by Christopher Bishop</b>
</p>
<p>this is probably the best overall machine learning text book i've ever read. such a beautiful book
   and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">the pdf is FREE FOR DOWNLOAD!!!</a>
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mlapp.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/machine-learning-1">Machine Learning: A Probabilistic Perspective</a> by Kevin Murphy</b>
</p>
<p>this is my second favorite general theory text on machine learning.
   i got kevin to sign my copy when he was passing my desk once but
   someone borrowed it and never gave it back :(
   so if you see a copy with my name on the spine let me know!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/homl.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</b>
</p>
<p>this is the book i point most people to when they are interested in getting up
   to speed with modern applied machine learning without too much concern for the
   theory. it's very up to date (as much as a book can be) with the latest libraries
   and, most importantly, provides a good overview of not just neural stuff but fundamental
   <a href="https://scikit-learn.org/stable/">scikit-learn</a> as well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mle.jpg"></p>
<p><b><a href="http://www.mlebook.com/wiki/doku.php">Machine Learning Engineering</a> by Andriy Burkov</b>
</p>
<p>a great book focussing on the operations side of running a machine learning system. i'm a bit
   under half way through the free online version and very likely to buy a physical copy to finish
   it and support the author. great stuff and, in many ways, a more impactful book than any of
   the theory books here.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itdm.jpg"></p>
<p><b><a href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Introduction to Data Mining</a>
   by Pang-Ning Tan, Michael Steinbach &amp; Vipin Kumar</b>
</p>
<p>this is another one that was also on my list from ten years ago and though it's section
   on neural networks is a bit of chuckle these days there is still a bunch of really
   great fundamental stuff in this book. very practical and easy to digest. i also see there's
   a second edition now. i reckon this would compliment the "hands on" book above very well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/salp.jpg"></p>
<p><b><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>
   by Dan Jurafsky &amp; James Martin</b>
</p>
<p>still the best overview of NLP there is (IMHO). can't wait to read the 3rd edition which
   apparently will cover more modern stuff (e.g. transformers) but until then, for the
   love of god though, please don't be one of those "this entire book is
   irrelevant now! just fine tune BERT" people :/
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/no.jpg"></p>
<p><b><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5">Numerical Optimization</a>
   by Jorge NocedalStephen J. Wright</b>
</p>
<p>this book is super hard core and maybe more an operations
   research book than machine learning. though i've not read it cover to cover the
   couple of bits i've worked through really taught me a lot. i'd love to understand
   the stuff in this text better; it's so so fundamental to machine learning (and more)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dl.jpg"></p>
<p><b><a href="https://www.deeplearningbook.org/">Deep Learning</a>
   by Ian Goodfellow</b>
</p>
<p>writing a book specifically on deep learning is very dangerous since things move so fast but
   if anyone can do it, ian can... i think ian's approach to explaining neural networks
   from the ground up is one of my favorites. i got the first edition hardback but it's free to
   download from the website.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pr.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/probabilistic-robotics">Probabilistic Robotics</a>
   by Sebastian Thrun, Wolfram Burgard and Dieter Fox</b>
</p>
<p>when i first joined a robotics group i bought a stack of ML/robotics books and this
   was by far the best. it's good intro stuff, and maybe already dated in places given
   it's age (the 2006 edition i have) but i still got a bunch from it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/tml.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/tinyml/9781492052036/">TinyML</a>
   by Pete Warden &amp; Daniel Situnayake</b>
</p>
<p>this was a super super fun book to tech review! neural networks on microcontrollers?!?
   yes please!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ec.jpg"></p>
<p><b><a href="https://www.wiley.com/en-us/Evolutionary+Computation%3A+Toward+a+New+Philosophy+of+Machine+Intelligence%2C+3rd+Edition-p-9780471669517">Evolutionary Computation</a> by David Fogel</b>
</p>
<p>this is still by favorite book on evolutionary algorithms; i've had this for a loooong
   time now. i still feel like evolutionary approaches are due for a big big comeback
   any time soon....
</p>
<hr>


<h2>in the mail...</h2>
<p>the good thing about writing a list is you get people telling you cool ones you've missed :)
</p>
<p>the top three i've chosen (that are in the mail) are...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ciis.jpg"></p>
<p><b><a href="http://bayes.cs.ucla.edu/PRIMER/">Causal Inference in Statistics</a> by
   Judea Pearl, Madelyn Glymour &amp; Nicholas P. Jewell</b>
</p>
<p>recommended by <a href="https://twitter.com/animesh_garg">animesh</a> who quite rightly points out
   the lack of causality in machine learning books in the books above.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itiala.jpg"></p>
<p><b><a href="https://www.cambridge.org/au/academic/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information Theory, Inference and Learning Algorithms</a> by David MacKay</b>
</p>
<p>i've seen this book mentioned a number of times and was most recently recommended by
   my colleague <a href="https://twitter.com/danesherbs">dane</a> so it's time to get it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/bmlpa.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications</a> by Emmanuel Ameisen</b>
</p>
<p>a number of people i worked with have enjoyed this. first recommended by another
   colleague <a href="https://twitter.com/davidcolls">dave</a>.
   looks to be on the practical side rather than the theory but that's ok some times :)
</p>

  </div></div>]]>
            </description>
            <link>http://matpalm.com/blog/cool_machine_learning_books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031455</guid>
            <pubDate>Mon, 09 Nov 2020 04:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fun website that simulates fluid]]>
            </title>
            <description>
<![CDATA[
Score 302 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25031304">thread link</a>) | @svikashk
<br/>
November 8, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/ | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031304</guid>
            <pubDate>Mon, 09 Nov 2020 03:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention Is My Most Valuable Asset for Productivity as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 602 | Comments 237 (<a href="https://news.ycombinator.com/item?id=25030938">thread link</a>) | @zwbetz
<br/>
November 8, 2020 | https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/ | <a href="https://web.archive.org/web/*/https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
      <div>
        <div>
          <div>
            
  
  
  <p>
    
    
    
    <strong>Published: </strong>2020-11-08

    
    
      
      
        • <strong>Lastmod: </strong>2020-11-09

      
    
    
    
    
      <br>
      <span>
        <strong>Tags: </strong>
        
          
          
          
        
          
          
          
        
          
          
          
        
        <a href="https://zwbetz.com/tags/life/">life</a> • <a href="https://zwbetz.com/tags/attention/">attention</a> • <a href="https://zwbetz.com/tags/productivity/">productivity</a>
      
    </span>
  </p>
  
  
  
  

<p>Like a tightly written function, I prefer to exit early if no work should be done. So, if you disagree with these definitions and assumptions, now’s a good time to stop reading.</p>
<ul>
<li><strong>Sustainable productivity:</strong> The maximum rate of quality work output, without loss to the wellbeing of the developer</li>
<li><strong>Quality work:</strong> Software that meets requirements, is valuable to users, is maintainable, and is as bug free as possible</li>
<li><strong>Attention:</strong> The limited mental capacity to focus on a task</li>
<li>Sustainable productivity is desired</li>
<li>Attention is essential to sustainable productivity</li>
</ul>
<p>My high-level workflow looks something like this: identify the problem to solve; think on the problem and let ideas percolate; research, discuss, and experiment with these ideas; implement and test the solution; deliver and maintain the solution.</p>
<p>This cycle could repeat many times in a day. Or I could spend days stuck on a single cycle step. Every step in this cycle requires attention. The more attention I can devote, the more cycles I can complete, and the more productive I am.</p>
<p>How long you can focus on a task varies by person. Some people are very good at it out of the box, some people, not so much. Regardless of the hand you were dealt, I believe that focus (the act of devoting your attention) is a skill, and like any skill, can be improved with practice.</p>
<p>So, how can you increase your attention reserves? The most bang for your buck is to organize your outside world in such a way that it’s distraction free as possible. Once you do that, you’ll have more time to practice, and therefore more time to get better.</p>
<p><strong>Build physical strength.</strong> The damage done by sitting 8+ hours a day is underrated. You need a way to offset this damage, especially if you plan to work in this field for decades. Opinions abound on this topic, but I personally prefer deadlifts. There are few movements more primal than picking a heavy object off the ground and standing up with it. You can <a href="https://www.youtube.com/watch?v=wYREQkVtvEc">learn correct technique in little time</a>. I most like deadlifts because you can do them safely, at high weights, into old age. I also like the hand, back, and hip strength they give, to make it that much harder for sitting damage to have its way with you.</p>
<p><strong>Make your place of work boring and tidy.</strong> My office is a spare bedroom. The walls are blank. There’s no tv. There’s a desk, chair, laptop, laptop stand, keyboard, mouse, and mouse pad. There’s a window, which lets enough light in so that I don’t feel like I’m missing a beautiful day, but not too much light to cause screen glare. If I need to work with paper, it’s immediately filed somewhere when done. Like I said, boring and tidy.</p>
<p><strong>Make your smart phone dumb.</strong> My phone has all notifications disabled, except for calls and text messages. Well, and National Hurricane Center alerts, since I live in Louisiana. Unless you’re my wife, you know that I don’t respond to text messages immediately, that’s just how it is. I disabled my social media accounts some time ago. But if you have them, turning off notifications should help curve the urge to compulsively check them.</p>
<p><strong>Be an OS minimalist.</strong> Apps I use less commonly are a keypress combo away. Given this, my dock has only the apps I use on a daily basis:</p>
<ul>
<li>File system explorer</li>
<li>Internet browser</li>
<li>Terminal</li>
<li>Text editor for front-end code and notes</li>
<li>IDE for back-end code</li>
<li>IDE for database</li>
<li>Visual file differ for version control</li>
<li>Email client</li>
<li>Instant message client</li>
</ul>
<p>My desktop alternates between clean and dirty states. Files I’m currently working with live on the desktop. Then they’re filed away into sensible folders when done.</p>
<p><strong>Organize your browser bookmarks.</strong> When I read something useful that I may need to reference later, I file it under a general archive folder. Then more specific items get their own folders. Frequently accessed links are visible on my bookmarks bar under their own folder.</p>
<p><strong>Minimize meetings.</strong> Look, I know some things make sense to discuss face to face, or voice to voice. But if they don’t, then you don’t need a meeting. An email or instant message will suffice.</p>
<p><strong>Finally, use the <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a> to categorize your tasks.</strong> Imagine a grid of 4 quadrants:</p>
<ul>
<li>Important and Urgent</li>
<li>Important and Not Urgent</li>
<li>Not Important and Urgent</li>
<li>Not Important and Not Urgent</li>
</ul>
<p>Important and Urgent tasks have to be dealt with. For me, these are usually major production issues.</p>
<p>Important and Not Urgent tasks should absorb the bulk of your time. For me, this is the plain old development work of implementing features, fixing bugs, and making existing code more maintainable and performant. Also included are building relationships with others and planning ahead.</p>
<p>Not Important and Urgent tasks are nasty attention thieves. They shout out to you in immediacy, but offer little value in return. You know what these are for you. For me, these are most often lazily asked questions, where the asker did not do their due diligence, and expects a top-notch answer immediately. Also included are last-minute meetings, and over-talkative coworkers.</p>
<p>Not Important and Not Urgent tasks are usually not known to your users. Take internal documentation updates as an example. Thing is, they’re an investment in yourself, which means a more productive future “you”. So don’t forget to show them some love in your spare moments.</p>
<p><strong>Further reading.</strong> If you don’t know who Cal Newport is, you’re missing out. He has a whole blog dedicated to this type of thing, and has written books such as <em>Deep Work</em> and <em>Digital Minimalism</em>. Here are some of my favorite articles by him:</p>
<ul>
<li><a href="https://www.calnewport.com/blog/2009/02/04/have-we-lost-our-tolerance-for-a-little-boredom/">Have We Lost Our Tolerance For a Little Boredom?</a></li>
<li><a href="https://www.calnewport.com/blog/2010/06/10/is-allowing-your-child-to-study-while-on-facebook-morally-equivalent-to-drinking-while-pregnant/">Is Allowing Your Child to Study While on Facebook Morally Irresponsible?</a></li>
<li><a href="https://www.calnewport.com/blog/2008/04/07/monday-master-class-how-to-reduce-stress-and-get-more-done-by-building-an-autopilot-schedule/">Monday Master Class: How to Reduce Stress and Get More Done By Building an Autopilot Schedule</a></li>
<li><a href="https://www.calnewport.com/blog/2009/11/24/are-passions-serendipitously-discovered-or-painstakingly-constructed/">Are Passions Serendipitously Discovered or Painstakingly Constructed?</a></li>
<li><a href="https://www.calnewport.com/blog/2018/06/08/jerry-seinfelds-closed-door/">Jerry Seinfeld’s Closed Door</a></li>
</ul>



  
  
  

  
  




          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030938</guid>
            <pubDate>Mon, 09 Nov 2020 02:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restoring a 37 Year-Old IBM F Mechanical Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25029571">thread link</a>) | @opsdisk
<br/>
November 8, 2020 | https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html | <a href="https://web.archive.org/web/*/https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>I wanted to share my journey from start to finish to restore a 1983 IBM Model F XT mechanical keyboard to it's former glory.  It includes the steps, mistakes, and additional hardware required to make it functional with a modern computer.  This blog post is dedicated to my dad for teaching me about computers.</p>
<p><img alt="original.jpg" src="https://blog.opsdisk.com/images/keyboard/original.jpg"></p>

<p>A few months ago, my dad asked if I was interested in taking ownership of his <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer">IBM model 5150 PC</a>.  Without hesitation, I said "yes!".  The first project I wanted to tackle was to restore the
<a href="https://en.wikipedia.org/wiki/Model_F_keyboard">1983 Model F XT mechanical keyboard</a> keyboard.  In a sentimental and
journeyman/apprentice-sense, it felt like my dad was passing on the tools of his craft to continue the family line of
computer work and I couldn't pass that up.</p>
<p><img alt="datestamp.jpg" src="https://blog.opsdisk.com/images/keyboard/datestamp.jpg"></p>

<p>For those of you unfamiliar with the IBM Model F, <a href="https://www.modelfkeyboards.com/">modelfkeyboards.com</a> summarizes it
nicely:</p>
<blockquote>
<p>The IBM Model F keyboards not only used the best switches, the materials used in their production (well over 5lbs of
steel and other metals) means they will be working as good as new when it’s time to pass it on to your grandchildren.
The problem...they just aren't made that way any more.  The IBM Model F was discontinued in the 1980's.  If you do
find a Model F, it will be some combination of dirty, broken and/or expensive, requiring hours of work to get it
working again!</p>
</blockquote>
<p>This tank of a keyboard weighs in at over 6 pounds, sounds like <a href="https://youtu.be/XTVeSCqYSmE?t=7">this</a>, and at the
time of production, retailed for $300-400 in 1982 ($800-1000 dollars adjusted in today's dollars!) according to this
<a href="https://www.youtube.com/watch?v=y9Jds326gks">review</a>.</p>
<p>The restoration did take a few hours and fortunately none of it involved a soldering iron or replacing any of the
electrical or physical components because it was already in great functioning shape...a true testament to the design.
Even cooler, this blog post was typed up using the restored Model F keyboard!</p>

<p>Before beginning the project, I discovered <a href="https://www.clickykeyboards.com/">ClickyKeyboards</a>, a site "Specializing in
the restoration and collection of model M keyboards", the successor to the Model F.  On ClickyKeyboards, there is a
section dedicated to the adapters and converters that may be required to make older 5-pin DIN plug keyboards compatible
with modern USB ports.  One of the companies mentioned on ClickyKeyboards is
<a href="https://www.hagstromelectronics.com/">Hagstrom Electronics</a>, which sells keyboard encoders and protocol converters.
Without looking too closely at the other products, I quickly purchased the
<a href="https://www.hagstromelectronics.com/keyboard-encoder-ke18-xtat-ps2-shp.html">KE18-XTAT-PS/2</a> which "converts an XT
keyboard into a PS/2 protocol keyboard" for $55.  I was ecstatic that there was at least something to get me into PS/2
land, because at that point I knew I could easily find a PS/2 to USB converter.</p>
<p>After the KE18-XTAT-PS/2 arrived, I quickly fired up an ancient box (yes, that is Windows 2000!) with a PS/2 input on
the motherboard.  I tested all the keys to ensure they still worked and they did!  With confirmation that the keyboard
still worked, it was time to start the restoration.</p>
<p><img alt="win2000.jpg" src="https://blog.opsdisk.com/images/keyboard/win2000.jpg"></p>

<p><img alt="original2.jpg" src="https://blog.opsdisk.com/images/keyboard/original2.jpg"></p>
<p>The first step was to remove the metal casing and see what the state of the board was underneath the keys.  There was
years worth of debris, coffee stains, and gunk that had to be removed.  In addition, there were a few spots with
corrosion on the board that needed to be addressed.</p>
<p><img alt="preclean.jpg" src="https://blog.opsdisk.com/images/keyboard/preclean.jpg"></p>
<p>Once the casing was off, I utilized compressed air to clean out the key bunkers and get rid of any loose nastiness.
Next, I tried using rubbing alcohol and Q-tips to try and remove some of the stickier stuff, but that didn't
really work.</p>

<p>I borrowed a rotary tool to buff out the corrosion.  I used one of the provided bits that had soft plastic tentacles to
try and buff out the corroded spots as gently as possible.  There are likely better and more appropriate bits, but it
did the job.  The rotary tool's power and RPMs were a bit overkill even on the lowest setting.  Ideally, I would have
used one with fewer minimum RPMs and a more precise bit to get all the spots.</p>
<p><img alt="buffing_tool_and_bit.jpg" src="https://blog.opsdisk.com/images/keyboard/buffing_tool_and_bit.jpg"></p>
<p><img alt="bit.jpg" src="https://blog.opsdisk.com/images/keyboard/bit.jpg"></p>
<p>I was using the rotary tool under a bright overhead desk lamp, and with the way the light was reflecting, I didn't
notice it was taking off the black finish and revealing the silver metal base.  At that point, I just decided to buff
off the finish where I could to make it look more uniform.  The silver metal is visible when the keys and cover are back
on it, but it looks fine.  Unfortunately, with the rotary head and bit size, I wasn't able to buff every last square
inch of the board, but I knew it'd be covered so I wasn't too concerned with it looking perfect.</p>
<p><img alt="allbuffed.jpg" src="https://blog.opsdisk.com/images/keyboard/allbuffed.jpg"></p>

<p><img alt="postbuffing.jpg" src="https://blog.opsdisk.com/images/keyboard/postbuffing.jpg"></p>
<p>There was still some residue stuck to the board that I wanted to remove.  I started out using a small eye glass
screwdriver to scrape it off, but it took some of the black finish off as well and didn't look that nice.  At that point,
a chemical pivot was required and I reached for the <a href="https://googone.com/">Goo Gone</a>, which I should have done from the
beginning.  The Goo Gone and a bit of elbow grease with Q-Tips did the trick in removing the stubborn gunk on the board.</p>
<p><img alt="postgoogone.jpg" src="https://blog.opsdisk.com/images/keyboard/postgoogone.jpg"></p>

<p>With the board in good shape, it was time to tackle the actual keys.  I first gave them a good wipe-down using desk
cleaning wipes, which removed most of the discoloration and stains.  However, they still didn't look as good as they
could, and I read that just soaking them in a bowl of dish soap and water for a few hours can do wonders...and it did.
They keys look brand new.</p>
<p><img alt="keybath.jpg" src="https://blog.opsdisk.com/images/keyboard/keybath.jpg"></p>
<p>One mistake I made after washing them was to not let them completely dry on the inside.  I placed the keys back on the
board too soon, and some water leaked onto a few of the springs causing a small amount of rusting (slightly visible in
the post-Goo Gone image).  I gave them another soap soak and used the compressed air to really get out the water.  I
also let them air dry for 1-2 days before putting them back on the board.</p>

<p>After successfully testing the actual keyboard and the restoration almost complete, it was time to search for a PS/2 to
USB cable.  On a whim, I was back on the Hagstrom Electronic site and noticed they already had a small box, the
<a href="https://www.hagstromelectronics.com/ke-xtusb-keyboard-encoder-shp.html">KE-XTUSB</a>, that converted the XT signal to USB,
and it was the same price.  They graciously allowed me to return the KE18-XTAT-PS/2 in exchange for the KE-XTUSB which
was the same price.  A few days later the KE-XTUSB arrived in the mail and I eagerly connected it to my current computer.</p>
<p><img alt="xtusb.jpg" src="https://blog.opsdisk.com/images/keyboard/xtusb.jpg"></p>

<p>Everything worked beautifully except for two keys.  The "s" key's spring mechanism would either not detect a key press
or would be stuck in the depressed state blasting "sssssssssssssssssssssssssssssssssssss" across the screen.  With a
bit of finagling, I got the key cap placed correctly so now it works like a champ.  The other key that has issues is the
accountant's "+" near the 10 key pad.  The spring had come off somehow and I super glued it back, but something still
isn't right and it fails to register key strokes.  Not a huge loss since "+" can be achieved with another key
combination.</p>
<p>Overall, I'm really impressed with how it looks and, when comparing it to <a href="https://www.youtube.com/watch?v=E2bAhxK76hc">this</a>
unboxing video of a never before opened Model F, it looks about the same!</p>
<p>If you have any questions or comments, hit me up on Twitter <a href="https://twitter.com/opsdisk">@opsdisk</a>.</p>
<p><img alt="final.jpg" src="https://blog.opsdisk.com/images/keyboard/final.jpg"></p>
            </section></div>]]>
            </description>
            <link>https://blog.opsdisk.com/restoring-a-37-year-old-ibm-model-f-mechanical-keyboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25029571</guid>
            <pubDate>Sun, 08 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About iSH’s pending removal from the App Store]]>
            </title>
            <description>
<![CDATA[
Score 692 | Comments 454 (<a href="https://news.ycombinator.com/item?id=25028252">thread link</a>) | @tbodt
<br/>
November 8, 2020 | https://ish.app/app-store-removal | <a href="https://web.archive.org/web/*/https://ish.app/app-store-removal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><strong><span>Update</span></strong>: We got a call this evening from someone who runs App Review. They apologized for the experience we had, then told us they've accepted our appeal and won't be removing iSH from the store tomorrow. We'll stay in contact with them to work out details. Thanks everyone for your support!
</p>


<p>On Monday, October 26th, just four days after we launched iSH on the App Store, we received a call from Apple informing us that they had found our app noncompliant with section 2.5.2 of the App Store Review Guidelines and that they would remove the app from sale if we did not submit a satisfactory update within two weeks. Despite our best efforts, we do not believe we will be able to bring iSH into compliance by tomorrow, the conclusion of this 14 day period, and we expect iSH to no longer be available to download from the App Store after that time. We are working our hardest to get iSH back on the App Store as soon as possible and hope for your understanding and support as we navigate our next steps in this process.</p>

<p>Thanks for using iSH!<br>
Theodore Dubois, Saagar Jha &amp; Martin Persson</p>

<h2 id="why-is-ish-being-removed">Why is iSH being removed?</h2>
<p>Apple believes iSH is not compliant with section 2.5.2 of the App Store Review Guidelines, which governs applications which download and run executable code. Specifically, they believe that iSH “is not self-contained and has remote package updating functionality”, and suggest that we should “remove the remote network activity functionality which could allow for remote code importing into the app, such as wget or curl, or other remote network commands”. Additional communication with Apple has indicated that they believe that iSH is a security concern if we allow any sort of code importing by the user.</p>

<p><strong>We believe iSH is fully compliant with the App Store Review Guidelines.</strong> <a href="https://saagarjha.com/blog/2020/11/08/fixing-section-2-5-2/">Saagar has written</a> a more detailed analysis of why we believe this rejection is incorrect, how we believe Apple has misinterpreted and misapplied this rule to our app, and describe how 2.5.2’s poor wording coupled with the review team being unable to review functionality of scripting applications leads to mistaken classifications like these. At a high level, Apple has selectively targeted iSH using section 2.5.2 without fullying understanding our application, their own guidelines, or the consequences of what they are asking and how they affect the App Store ecosystem as a whole. <strong>Consistent enforcement of Apple’s incorrect interpretation would require the removal of all scripting apps, including many of the most popular applications in the App Store and some of Apple’s own applications.</strong></p>

<h2 id="what-have-we-done-to-get-ish-back-on-the-app-store">What have we done to get iSH back on the App Store?</h2>
<p>We’ve been working for the last two weeks to try to keep iSH available without interruptions. We have drafted numerous appeals, requests for clarifications, rule modifications, and explanatory emails. We’ve been on the phone with Apple for hours. Unfortunately, even with this we have been unable to resolve the issue, and the process has been significantly more stressful than we would have liked it to be. Theodore, the primary iSH liaison to Apple, <a href="https://tbodt.com/2020/11/08/app-review-experiences.html">has written about</a> how this process should be improved.</p>

<p>Our first interaction with the App Store review team actually dates back to May, not October: we wanted to know what Apple thought of iSH, since we weren’t sure how the rules would be enforced for it. Of course, iSH complies with the letter of the guidelines, but review found it to violate 2.5.2 because it could download Linux executable code. The problem appeared that apk lets you install packages, so we decided to remove it and work on other features to make the app more useful in its absence. We submitted this updated build in October and this was what is currently on the App Store.</p>

<p>After our build was flagged for noncompliance, we went through the usual review process: we first asked for clarification, and then after we realized that the rule was being misapplied we submitted a rule change request and of course appealed the decision as well. As the deadline approached we sent off an email to Phil Schiller as well detailing our situation. Unfortunately none of this led anywhere, which brings up to our current situation today.</p>

<h2 id="does-this-mean-i-cant-use-ish-anymore">Does this mean I can’t use iSH anymore?</h2>
<p>No, not at all. However, it will mean that you will no longer be able to get iSH from the App Store, which is something which we would still like to be able to provide. The App Store remains the easiest and most popular method of software distribution on iOS, and we’re working hard to save iSH’s listing because we think the app should have a permanent spot there for users who prefer this method of distribution.</p>

<p>Removal of iSH’s listing on the App Store should not affect your use of iSH if you download the app before it is removed. We have not received any compliance messages from Apple regarding <a href="https://testflight.apple.com/join/97i7KM8O">our TestFlight beta</a>, so we plan to continue offering prerelease versions of iSH there for up to 10,000 beta testers.</p>

<p>Precompiled builds of iSH (distributed as IPA files) will <a href="https://github.com/ish-app/ish/releases">remain available on GitHub</a> for <a href="https://ish.app/altstore">installation through AltStore</a> and for jailbroken users. Advanced users are welcome to <a href="https://github.com/ish-app/ish#build-for-ios">build iSH</a> themselves—it’s free and open source and always will be!</p>

<p><strong><span>Update</span>: <a href="https://twitter.com/a_Shell_iOS/status/1325526061099196416">a-Shell has mentioned</a> that they have received a similar rejection notice. Apple may be running extra review for scripting apps.</strong></p>

        <hr>
        <p><a href="https://ish.app/">Return home</a> | 2020-11-08</p>
    

</div>]]>
            </description>
            <link>https://ish.app/app-store-removal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25028252</guid>
            <pubDate>Sun, 08 Nov 2020 19:33:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How active noise cancellation for automotive works]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25026841">thread link</a>) | @giuliomagnifico
<br/>
November 8, 2020 | https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/ | <a href="https://web.archive.org/web/*/https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="mk-page-id-6588">
					<div itemprop="mainEntityOfPage">
							
	<article id="6588" itemscope="itemscope" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

	<div><p><a title="Advanced, broad-band active noise cancellation now available in cars" href="https://www.silentium.com/wp-content/uploads/2020/11/silentium-anc-system.jpg">&nbsp;</a><img alt="Advanced, broad-band active noise cancellation now available in cars" title="Advanced, broad-band active noise cancellation now available in cars" src="https://www.silentium.com/wp-content/uploads/bfi_thumb/dummy-transparent-oj3yxgsoeorp9werpevcwqrlmj5p4y57n6vjhiqmq0.png" data-mk-image-src-set="{&quot;default&quot;:&quot;https://www.silentium.com/wp-content/uploads/2020/11/silentium-anc-system.jpg&quot;,&quot;2x&quot;:&quot;&quot;,&quot;mobile&quot;:&quot;&quot;,&quot;responsive&quot;:&quot;true&quot;}" width="800" height="500" itemprop="image"></p></div>				
	





<div itemprop="mainEntityOfPage">
	<p>Silentium has introduced advanced, broad-band active road noise cancellation to the auto industry for the first time.</p>
<p>After several years in development, Jaguar and Land Rover are the first carmakers to integrate Silentium’s ‘Active Acoustics’ software in three of their new vehicles, meaning the technology is now available for car buyers to experience. Active road noise cancellation removes 90% of unwanted noise across a broad band of frequencies – from 20Hz up to 1kHz – providing a quieter and more refined experience for occupants, and therefore preventing driver fatigue.</p>
<p>In addition to wellbeing benefits, Silentium’s Active Acoustics technology offers vehicle manufacturers a way to reduce their reliance on costly passive noise damping and insulation materials, and reduce vehicle weight – an increasingly important R&amp;D factor as the industry enters a new era of electro-mobility.</p>
<p>Anthony Manias, Head of Automotive at Silentium, commented: “<em>Active Acoustics will change the way car manufacturers reduce, cancel and enhance sound inside their vehicles, and how customers perceive and interact with these sounds. Silentium has proven that it can make broadband in-car noise cancellation work – now the duty is on carmakers to adopt the technology and ensure their customers can enjoy the benefits.”</em></p>
<p><img src="https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1.jpg" alt="" width="1000" height="756" srcset="https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1.jpg 1000w, https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1-300x227.jpg 300w, https://www.silentium.com/wp-content/uploads/2020/11/graphic-silentium1-768x581.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p><strong>How active noise cancellation works</strong></p>
<p>Silentium’s industry-first technology is similar to that found in a pair of high-end noise-cancelling headphones, but more advanced as it manipulates a larger amount of air. Up to six strategically positioned accelerometers on a vehicle’s chassis monitor unwanted road noise and send a signal to an on-board control unit with Silentium’s software, which plays an equivalent anti-noise signal through the vehicle’s speaker system. The pressure waves from both the unwanted exterior noise and manufactured anti-noise reach occupants’ eardrums at exactly the same time and cancel each other out.</p>
<p>Silentium’s Active Acoustics software can reduce, cancel and enhance sound inside any vehicle, improving occupant comfort, safety and wellbeing, and creating a more enjoyable environment for all.</p>
<p><iframe title="Silentium Active Acoustics on road noise" width="1140" height="641" src="https://www.youtube.com/embed/5x9NEpfRZuc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><iframe title="Silentium Active Acoustics with road noise and music" width="1140" height="641" src="https://www.youtube.com/embed/uDzSkaWBD7E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div>



</article>

							
											</div>
										
				</div>
			</div></div>]]>
            </description>
            <link>https://www.silentium.com/advanced-broad-band-active-noise-cancellation-now-available-in-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026841</guid>
            <pubDate>Sun, 08 Nov 2020 16:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Alfred to open your GitHub repositories in the browser]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25026757">thread link</a>) | @mmazzarolo
<br/>
November 8, 2020 | https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/ | <a href="https://web.archive.org/web/*/https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>One thing I do multiple times a day is browsing my company’s GitHub organization repositories.<br>
My process for opening these repositories in the browser is:</p>
<ul>
<li>Open Chrome</li>
<li>Press <kbd>Command</kbd> + <kbd>L</kbd> to focus the address bar</li>
<li>Start typing the GitHub repository name</li>
<li>Look for the page suggestion and click on it</li>
</ul>
<p>This flow works well for repositories that I have starred as bookmarks or that I browsed recently…<br>
…But because I’m a total sucker for Alfred, today I wasted almost an hour moving this process into an Alfred workflow.</p>
<p><span>
      <span></span>
  <img alt="alfred" title="alfred" src="https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/fcda8/alfred.png" srcset="https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/12f09/alfred.png 148w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/e4a3f/alfred.png 295w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/fcda8/alfred.png 590w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/efc66/alfred.png 885w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/c83ae/alfred.png 1180w,
https://mmazzarolo.com/static/f6b79b275f646159f864ae32c3d83508/7ef4c/alfred.png 1748w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<h2>The Action Plan</h2>
<p>Knowing that:</p>
<ul>
<li>The entire repository list is huge and doesn’t change often</li>
<li>I wanted the Alfred repository search result to be instant</li>
</ul>
<p>Making an API request to filter the repositories each time I invoke the Alfred workflow wasn’t an option.</p>
<p>So I decided to 1) download the entire repository list into a JSON file, 2) transform it into an Alred-compatible format, and 3) use the <a href="https://github.com/deanishe/alfred-fuzzy" target="_blank" rel="nofollow noopener noreferrer">Alfred’s fuzzy search helper</a> to filter the results.</p>
<h2>Creating the GitHub repository list</h2>
<p>First of all, I <a href="https://github.com/settings/tokens/new" target="_blank" rel="nofollow noopener noreferrer">created a GitHub API token with a scope to access the repositories list</a>.</p>
<p><span>
      <span></span>
  <img alt="github repo access" title="github repo access" src="https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/fcda8/github-repo-access.png" srcset="https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/12f09/github-repo-access.png 148w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/e4a3f/github-repo-access.png 295w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/fcda8/github-repo-access.png 590w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/efc66/github-repo-access.png 885w,
https://mmazzarolo.com/static/5debf06855fa8eef2379c163d8d95943/69476/github-repo-access.png 926w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<blockquote>
<p>TIL: Selecting all the “repo” sub-scopes is not the same as selecting the entire scope — which is needed to use the API token to get the list of all the private repositories.</p>
</blockquote>
<p>The GitHub API pagination has a limit of 200 items per page. I needed to fetch way more than 200 repositories, so I modified <a href="https://gist.github.com/mbohun/b161521b2440b9f08b59" target="_blank" rel="nofollow noopener noreferrer">this cool (but outdated) bash script</a> to fetch all of them in a single command and print them out to the console:</p>
<div data-language="bash"><pre><code><span>#!/bin/bash</span>

<span>if</span> <span>[</span> <span>${<span>#</span>@}</span> -lt <span>2</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"usage: <span>$0</span> [your github credentials as 'user:token'] [REST expression]"</span>
    <span>exit</span> <span>1</span><span>;</span>
<span>fi</span>

<span>GITHUB_CREDENTIALS</span><span>=</span><span>$1</span>
<span>GITHUB_API_REST</span><span>=</span><span>$2</span>

<span>GITHUB_API_HEADER_ACCEPT</span><span>=</span><span>"Accept: application/vnd.github.v3+json"</span>

<span>temp</span><span>=</span><span><span>`</span><span>basename</span> $0<span>`</span></span>
<span>TMPFILE</span><span>=</span><span><span>`</span>mktemp /tmp/$<span>{</span>temp<span>}</span>.XXXXXX<span>`</span></span> <span>||</span> <span>exit</span> <span>1</span>

<span>function</span> <span>rest_call</span> <span>{</span>
    <span>curl</span> -s -u <span>$GITHUB_CREDENTIALS</span> <span>$1</span> -H <span>"<span>${GITHUB_API_HEADER_ACCEPT}</span>"</span> <span>&gt;&gt;</span> <span>$TMPFILE</span>
<span>}</span>


<span>last_page</span><span>=</span><span><span>`</span><span>curl</span> -s -I -u $GITHUB_CREDENTIALS <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200"</span> -H <span>"<span>${GITHUB_API_HEADER_ACCEPT}</span>"</span> <span>|</span> <span>grep</span> <span>'^Link:'</span> <span>|</span> <span>sed</span> -e <span>'s/^Link:.*page=//g'</span> -e <span>'s/&gt;.*$//g'</span><span>`</span></span>


<span>if</span> <span>[</span> -z <span>"<span>$last_page</span>"</span> <span>]</span><span>;</span> <span>then</span>
    
    rest_call <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200"</span>
<span>else</span>
    
    <span>for</span> <span>p</span> <span>in</span> <span><span>`</span><span>seq</span> <span>1</span> $last_page<span>`</span></span><span>;</span> <span>do</span>
        rest_call <span>"https://api.github.com<span>${GITHUB_API_REST}</span>?per_page=200&amp;page=<span>$p</span>"</span>
    <span>done</span>
<span>fi</span>

<span>cat</span> <span>$TMPFILE</span></code></pre></div>
<p>I named the script <code>githubapi-get.sh</code> and used it this way:</p>
<div data-language="bash"><pre><code>
githubapi-get.sh <span>"{USERNAME}:{TOKEN}"</span> <span>"/orgs/{ORGANIZATION}/repos"</span> <span>&gt;</span> ~/my-company-repos.txt</code></pre></div>
<p>FYI, you can also run it this way to get all the repositories you have access to (both on your personal account and on other organization accounts):</p>
<div data-language="bash"><pre><code>
githubapi-get.sh <span>"{USERNAME}:{TOKEN}"</span> <span>"/user/repos"</span> <span>&gt;</span> ~/my-github-repos.txt</code></pre></div>
<h2>Making the repository list compatible with Alfred</h2>
<p>To populate the Alfred list filter, for each repo I extracted the following information:</p>
<ul>
<li><code>uid</code>: Unique identifier for the item which allows Alfred to learn about this item for subsequent sorting and ordering of the user’s actioned results. I used the repository ID (<code>id</code>).</li>
<li><code>arg</code>: The argument which is passed through the workflow to open it in the browser. I used the repository URL (<code>html_url</code>).</li>
<li><code>title</code>: The title displayed in the result row. I used the repository name (<code>name</code>).</li>
<li><code>subtitle</code>: The subtitle displayed in the result row. I used the repository description (<code>description</code>).</li>
</ul>
<p>Using the following <code>jq</code> script:</p>
<div data-language="bash"><pre><code><span>cat</span> ~/my-company-repos.txt <span>|</span> jq -s <span>'.[] | map({ arg: .html_url, uid: .id, title: .name, subtitle: .description }) | { items: . }'</span> <span>&gt;</span> ~/my-company-repos.json</code></pre></div>
<p>The <code>jq</code> script generates a <code>~/my-company-repos.json</code> file compatible with the <a href="https://www.alfredapp.com/help/workflows/inputs/script-filter/json/" target="_blank" rel="nofollow noopener noreferrer">Alfred Script Filter JSON format</a>.</p>
<h2>Creating the Alfred workflow</h2>
<p>The Alfred standard script filtering doesn’t have a good fuzzy search option — which I really wanted given the huge amount of repositories.</p>
<p>As a workaround, I used <a href="https://github.com/deanishe/alfred-fuzzy" target="_blank" rel="nofollow noopener noreferrer">alfred-fuzzy</a>, a Python helper script for Alfred that replaces the “Alfred filters results” option with fuzzy search.</p>
<p>Here’s what I did, step by step:</p>
<ol>
<li>Create a new empty Alfred workflow</li>
<li>Right-click on the created workflow ⭢ “Open in Finder”</li>
<li>In the workflow directory, copy and paste both <a href="https://raw.githubusercontent.com/deanishe/alfred-fuzzy/master/fuzzy.py" target="_blank" rel="nofollow noopener noreferrer">fuzzy.py</a> and <code>my-company-repos.json</code>.</li>
<li>In the workflow, create the following “Script Filter”:
<span>
      <span></span>
  <img alt="workflow 0" title="workflow 0" src="https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/fcda8/workflow-0.png" srcset="https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/12f09/workflow-0.png 148w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/e4a3f/workflow-0.png 295w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/fcda8/workflow-0.png 590w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/efc66/workflow-0.png 885w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/c83ae/workflow-0.png 1180w,
https://mmazzarolo.com/static/79ea20fa5f1577ca4cb07a0fd9329861/2b608/workflow-0.png 1540w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
<li>In the workflow, create the following “Open URL” action:
<span>
      <span></span>
  <img alt="workflow 1" title="workflow 1" src="https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/fcda8/workflow-1.png" srcset="https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/12f09/workflow-1.png 148w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/e4a3f/workflow-1.png 295w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/fcda8/workflow-1.png 590w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/efc66/workflow-1.png 885w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/c83ae/workflow-1.png 1180w,
https://mmazzarolo.com/static/5f157cd5f9d5e2e8f928074cc6d37708/7960f/workflow-1.png 1274w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
<li>In the workflow, connect the “Script Filter” to the “Open URL” action:
<span>
      <span></span>
  <img alt="workflow 2" title="workflow 2" src="https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/fcda8/workflow-2.png" srcset="https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/12f09/workflow-2.png 148w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/e4a3f/workflow-2.png 295w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/fcda8/workflow-2.png 590w,
https://mmazzarolo.com/static/ca9a91ea4b4aed993050fc92f0780f4d/8ae3e/workflow-2.png 756w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></li>
</ol>
<p>That’s it.
I can now invoke the workflow using the keyword set in the “Script Filter” action and fuzzy search the repo I’m interested in.</p>
<p>Alfred is also smart enough to keep track of my workflow usage, surfacing the most clicked results to the top of the list 💥</p>
<blockquote>
<p>Yes, the workflow can be improved in several ways (e.g.: auto-update the repository list after n days)… but I’m happy enough with the current result for now.</p>
</blockquote></section></div>]]>
            </description>
            <link>https://mmazzarolo.com/blog/2020-09-28-alfred-github-repos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026757</guid>
            <pubDate>Sun, 08 Nov 2020 16:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Problem Solving Techniques]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25026561">thread link</a>) | @denvaar
<br/>
November 8, 2020 | https://denvaar.github.io/articles/problem_solving_example.html | <a href="https://web.archive.org/web/*/https://denvaar.github.io/articles/problem_solving_example.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>âœ�ï¸� Going meta - Working through a programming problem to understand problem solving techniques.</p><div>
        <p>The technical skills of computer programming fall under two broad categories, in my opinion.</p>
<p>The first category includes things like learning language syntax, constructs, and patterns. I would summarize it as the ability to connect and utilize the myriad, "tools of the trade" -- languages, frameworks, APIs, libraries -- to create software. There's usually tutorials for these things.</p>
<p>The second category includes things that are a little bit harder to put your finger on, but can probably be best described as problem solving. It's the ability to analyze, troubleshoot, debug, or solve a problem. It's the ability to reason with abstract ideas and turn them into code.</p>
<p>There is for sure some overlap between these two categories, but this is how I like to think about it.</p>
<p>It's hard to be specific about what it takes to be good at problem solving. I believe that's because we all have a slightly different perception of the world around us. Everyone learns differently. There must, however, be at least some techniques that I might learn from you, and vice versa.</p>
<p>Problems like the one I am about to share can be great tools for learning about problem solving. This one's from Project Euler. My intention is not to simply spoil the answer. I want to share my process of figuring it out, with the hope of being able to pinpoint some specific strategies that can be used to solve all kinds of problems.</p>
<h2 id="thechallenge">The challenge</h2>
<p>You can find the original problem statement <a href="https://projecteuler.net/problem=79">here</a>. It's short, so take a moment to read through.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_0.png" alt=""></p>
<p>The challenge is to determine what the shortest possible secret number is. Here's an excerpt from the keylogger file.</p>
<pre><code>...
160
689
716
731
736
...
</code></pre>
<h2 id="firststeps">First steps</h2>
<p>I began by sitting down with pencil and paper to write some numbers from the list. Writing helps me begin to think about the problem.</p>
<p>I thought about what these numbers in the list could tell me about the secret number. Maybe I could find a way to at least figure out its length. There are about fifty numbers in the list, so maybe that number is somehow correlated to the secret number.</p>
<p>These were a few of the questions going through my head. If the answers seem super obvious to you, then congratulations, you might be smarter than me. What's most important during the first steps is that you ask questions.</p>
<p>I realized pretty quickly that no, the length of the list I was given didn't tell me much, but you've got to start somewhere. Next, my thoughts turned to the fact that each number was three digits long.</p>
<p><em>What if I was given a list of two-digit numbers, or even a list of just one-digit numbers? What could that tell me about the length of the secret number? Is there something special about three-digit numbers in particular?</em> These were valuable questions to ask, because it helped me to simplify the problem.</p>
<p>I made a list of one-digit numbers and tried to think about how I might be able to solve the same problem with that instead.</p>
<pre><code>6
2
1
0
</code></pre>
<p>Given a list like this as clues, I could say for certain that the secret number has at least a 6,2,1, and 0, but I also loose essential information about the problem: The order that the numbers appear in. A list of one-digit numbers is too ambiguous. The secret number could be <code>6210</code>, <code>2601</code>, or any other combination, and I would have no way of knowing which one is correct.</p>
<p>A list of two-digit numbers might be nice. It's less to think about, yet is still able to convey the needed information. From this point forward, I decided to think about the list as two-digit numbers, rather than three-digit numbers.</p>
<h2 id="possibleoptionmaintainasortedarray">Possible option: Maintain a sorted array</h2>
<p>At this point, I still wasn't sure how to solve the problem on paper, so I decided to try and work backwards. I wrote down a random number and then picked a few pairs of digits from it to try and reconstruct my own version of the problem. I decided to go through each number in the list and write down the digits as if they were being inserted into some kind of array.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_1.png" alt=""></p>
<p>I realized an approach like this would not be very practical because it still leaves room for ambiguity.</p>
<p>In the example above, its clear that 5 is before 2, but if I continue to add the digits from the next number, I can't tell if the 1 should come before or after the 5. It's the same problem for the 8: I know it should come before the 2, but the data says nothing about if it should be before or after the 1, or the 5.</p>
<p>Even if I had another data point to disambiguate the clues -- <code>51</code>, for example -- sure, it would tell me that the 1 is in the correct spot between 5 and 2, but I already get the feeling that trying to write code to account for switching numbers around in an array is not going to be practical, and that there is probably an easier way.</p>
<p>Writing it out this way helped me realize that the help of some sort of data structure would be useful for solving this problem.</p>
<p>So now the question is, <em>what kind of data structure could help model this problem?</em> To help with this decision, I thought about what data is actually provided in the problem. Using the example above, the list of numbers reads as:</p>
<ul>
<li>5 "comes before" 2</li>
<li>1 "comes before" 2</li>
<li>8 "comes before" 2</li>
</ul>
<p>Each number in the list provides helpful clues, but the problem is that it's difficult to keep track of how each clue ultimately fits together. I tried to think of some kind of data structure that would be able to represent each clue individually, but also as a whole.</p>
<p>A directed graph seems to be a pretty natural fit to represent this information. Each node could be a digit, and the edges between nodes could represent the relationship between them.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_2.png" alt=""></p>
<p>I felt good about using a graph to solve the problem, but there were still some questions that I had to figure out.</p>
<ul>
<li>How would I know when the graph has enough information to to be able to get the secret number? In other words, how can I know when my answer is conclusive?</li>
<li>How could the graph be read or interpreted programmatically to produce the secret number?</li>
<li>What if a secret number had more than one of the same digit? Would that ruin my approach?</li>
</ul>
<h2 id="howtoknowwhentheanswerisconclusive">How to know when the answer is conclusive</h2>
<p>To help answer this question I used the same technique of creating a simplified version of the problem and working backwards. Pretend now that 157 is the secret number. How many edges between the nodes would it take to definitively say that 1 comes before both 5 and 7, and 5 comes before 7? The answer is three edges for this particular graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_3.png" alt=""></p>
<p>In this example, the order is known when number of edges are equal to the number of nodes. <em>Is it that simple? Can we know what the secret number is if the number of edges are equal to the number of nodes?</em></p>
<p>In this example, yes, but it doesn't hold true for the general case. By creating more examples, I start to find a relationship between the number of nodes, and the number of edges. Have a look at what four and five-digit secret numbers look like as a graph:</p>
<p><img src="https://denvaar.github.io/assets/secret_number_4.png" alt=""></p>
<p><img src="https://denvaar.github.io/assets/secret_number_5.png" alt=""></p>
<p>After drawing a few of these, I could begin to see a pattern emerge. As the number of nodes increase, the number of edges increase like, <code>1, 3, 6, 10, 15, 21, 28, ..</code>.</p>
<p>It can be helpful to look for patterns, because it means that there's an equation which can be used to represent some aspect of the problem. Here the pattern showed me what condition to use in order to know when my answer could be considered conclusive. This is the equation that represents that pattern, where n is the number of nodes in the graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_6.png"></p>
<h2 id="readingthegraphtofindtheanswer">Reading the graph to find the answer</h2>
<p>A hand-drawn graph helps to visualize the approach of solving this problem, but I knew that I would also need to keep in mind how the graph could be represented with code. Specifically, how to programmatically traverse the graph to produce a result.</p>
<p>After staring at the examples for a bit longer, I realized an obvious and helpful property about the graph.</p>
<p>The nodes with the most outward edges come before those with less outward edges. Additionally, the number of edges for each node differ by exactly one. This means that the first digit of the secret number should have the most outward edges, while the last digit would not have any outward edges.</p>
<p>This property made logical sense to me, and was something that could be easily translated into code.</p>
<h2 id="duplicatedigits">Duplicate digits</h2>
<p>A secret number with more than one of the same digit could cause problems with my approach. This was something that worried me as I was working, because it was not clear how to know which two nodes to put the edge between. For example, take a look at 1030 as the secret number, and imagine the digits given in the following order:</p>
<p><img src="https://denvaar.github.io/assets/secret_number_7.png" alt=""></p>
<p>There are multiple ways to draw the graph because there are two 0's. There should still be only one "correct" way. Creating a correct graph might depend on the order in which the digits are given. I might need to think of some way to backtrack and re-connect nodes in order to end up with the correct graph.</p>
<p>The correct and incorrect graphs can be compared to understand how exactly they differ. The incorrect graph has a circular dependency: 3 comes before both the orange and blue 0's, but then the blue 0 comes before 3, which is contradictory.</p>
<p>Another difference is that the correct version is the only one that satisfies the property mentioned above, where the number of each node's edges differ by exactly one. This property should always be true for any secret number modeled with the graph.</p>
<p><img src="https://denvaar.github.io/assets/secret_number_8.png" alt=""></p>
<p>At this point, I decided to put the question of duplicate digits on hold. It looked like this would break the approach that I had planned to use. I think its possible to figure out, but it was unclear if this use case needed to be supported at all.</p>
<p>My plan was now to turn my ideas into code to see if it would produce the correct answer.</p>
<h2 id="translateideastocode">Translate ideas to code</h2>
<p>This part went by pretty quickly because I had formed a good understanding of the problem, as well as an approach for how to solve it. I picked Python for no particular reason, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://denvaar.github.io/articles/problem_solving_example.html">https://denvaar.github.io/articles/problem_solving_example.html</a></em></p>]]>
            </description>
            <link>https://denvaar.github.io/articles/problem_solving_example.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026561</guid>
            <pubDate>Sun, 08 Nov 2020 15:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a programming language using Rust]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25026419">thread link</a>) | @azhenley
<br/>
November 8, 2020 | https://arzg.github.io/lang/ | <a href="https://web.archive.org/web/*/https://arzg.github.io/lang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A series about making a programming language called <a href="https://github.com/arzg/eldiro">Eldiro</a> using the <a href="https://rust-lang.org/">Rust</a> programming language.</p><p><a href="https://arzg.github.io/lang/9/">Part Nine: Function Calls</a></p><p><a href="https://arzg.github.io/lang/8/">Part Eight: Function Definitions</a></p><p><a href="https://arzg.github.io/lang/7/">Part Seven: A REPL</a></p><p><a href="https://arzg.github.io/lang/6/">Part Six: Blocks</a></p><p><a href="https://arzg.github.io/lang/5/">Part Five: Binding Usages</a></p><p><a href="https://arzg.github.io/lang/4/">Part Four: Backtracking</a></p><p><a href="https://arzg.github.io/lang/3/">Part Three: Defining Variables</a></p><p><a href="https://arzg.github.io/lang/2/">Part Two: Whitespace Support</a></p><p><a href="https://arzg.github.io/lang/1/">Part One: A Basic Parser</a></p><p><a href="https://arzg.github.io/lang/0/">Part Zero: Getting set up</a></p></div></div>]]>
            </description>
            <link>https://arzg.github.io/lang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026419</guid>
            <pubDate>Sun, 08 Nov 2020 15:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BGP Lego Bricks]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25026189">thread link</a>) | @bitcynth
<br/>
November 8, 2020 | https://blog.cynthia.re/post/bgp-lego | <a href="https://web.archive.org/web/*/https://blog.cynthia.re/post/bgp-lego">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>Nov 8 2020</h3>


<p>Since I was 7 years old, I have wanted a LEGO Mindstorms robot. I will admit that in the later years it was mainly that I wanted to prove to myself that I got somewhere as it seemed so infinitely expensive back when I was younger…</p>

<p><a href="https://twitter.com/bitcynth/status/1319956429252513792" title="Tweet about it"><img src="https://blog.cynthia.re/asset/g1ZkG7sMAD" alt="LEGO Robot Inventor"></a></p>

<p>Well I finally got one!</p>

<p>I knew this thing had some capability to run <a href="https://micropython.org/">MicroPython</a> since that was mentioned in the product description quite predominantly, which sounded like a pretty hackable platform.</p>

<p>However, shortly after opening the box, I realized that this wasn’t at all just an update to the <a href="https://www.lego.com/en-us/product/lego-mindstorms-ev3-31313">Mindstorms EV3</a>. Apparently the Robot Inventor was a slightly more expensive thing with less features and using a LiPo battery instead of AA cells.</p>

<p>Luckily I ordered it via the store’s website which means that by law I can return it within 14 days for any reason, and it allows me to open the box for inspection.</p>

<p>So after convincing some stubborn store employee that this is not a consumable product (which would remove my right to open the box), I got it returned and ordered the EV3.</p>

<p>Then two days later I finally had the thing which I have wanted for so long.</p>

<p>While I was waiting for the EV3, I was looking around at how it did MicroPython as it had this paragraph on the downloads page.</p>

<pre><code>You can now use your EV3 Brick to unleash the power of Python programming using MicroPython. Simply install the EV3 MicroPython image onto any micro SD card and boot up your EV3 Brick from it to start programming straight away. 
</code></pre>

<p>After just a few minutes of searching I found <a href="https://www.ev3dev.org/">ev3dev</a> which is an open source community project that allows you to run Debian on it!</p>

<p>It appears to be really well made and apparently good enough for LEGO to provide <a href="https://education.lego.com/en-us/support/mindstorms-ev3/python-for-ev3">official builds</a> of it, which is what they use for MicroPython support.</p>

<p>So I just went ahead and downloaded and flashed the disk image to a microSD card with <code>dd</code>.
I then plugged in the microSD card into the EV3 controller and turned it on…</p>

<p><img src="https://blog.cynthia.re/asset/rC3JqPiBNA" alt="EV3 kernel dmesg"></p>

<p>To my surprise, after applying power I was pleased to see kernel dmesg output scrolling out on the LCD of the EV3 on the first try!</p>

<pre><code>robot@ev3dev:~$ uname -a
Linux ev3dev 4.14.117-ev3dev-2.3.5-ev3 #1 PREEMPT Sat Mar 7 12:54:39 CST 2020 armv5tejl GNU/Linux

robot@ev3dev:~$ cat /etc/os-release 
PRETTY_NAME="ev3dev-stretch"
NAME="ev3dev-stretch"
ID=ev3dev
ID_LIKE=debian
HOME_URL="http://www.ev3dev.org"
SUPPORT_URL="http://www.ev3dev.org/support"
BUG_REPORT_URL="https://github.com/ev3dev/ev3dev/issues"
</code></pre>

<p>After playing around with it for about two minutes, I realized something… this thing runs Debian with a pretty damn complete package repository (it has ~64000 packages and normal amd64 Debian has ~66000 packages), can this thing run BIRD?</p>

<p>I assumed that if the ARM926EJ-S CPU can run Debian and stuff it can probably run a very minimal BIRD config, however I wasn’t so sure about the 56MB of RAM.</p>

<p>But well you won’t know if you don’t try :p</p>

<p>So I just went ahead and typed <code>sudo apt install bird</code> and pressed enter…</p>

<pre><code>robot@ev3dev:~$ sudo apt install bird
Reading package lists... Done
Building dependency tree       
Reading state information... Done
Suggested packages:
  bird-doc
</code></pre>

<p>(this was actually painfully slow as this thing doesn’t have a powerful CPU in the slightest)</p>

<p>As soon as I saw <code>bird-doc</code> I realized that yes it did at least have BIRD in the repo so that was a good first step.</p>

<p>I am only installing BIRD 1.6.3 here as it will probably use less resources than BIRD 2 if I only run the IPv6 daemon and disable the IPv4 daemon.</p>

<p>I then wrote a <a href="https://blog.cynthia.re/asset/gv3GvwzBGH">quick little bird config</a> to let the EV3 (AS202314) announce 2a0d:1a45:666::/48 to my home router (AS210089), and the home router will then deal with the rest.</p>

<p>I applied that and wrote the other end of the config on my home router and applied that too.</p>

<p>Then I went to the <a href="http://lg.ring.nlnog.net/">NLNOG RING Looking Glass</a> and I saw the /48 show up as announced by AS202314!</p>

<p><img src="https://blog.cynthia.re/asset/KVCU9bynjB" alt="NLNOG RING Looking Glass"></p>

<p>I then sent it to a friend who pointed out only about half of his sources could see the route, and well turns out I forgot to give AS202314 an <a href="https://en.wikipedia.org/wiki/Resource_Public_Key_Infrastructure">RPKI ROA</a> for the prefix, so I added that.</p>

<p>Then just for demo purposes I installed nginx which worked surprisingly well, so then I had a website I could access at http://[2a0d:1a45:666::]/ <sup><a href="#fn1">[1]</a></sup>.</p>

<p>This was surprisingly easy to get working. Hats off to the <a href="https://www.ev3dev.org/">ev3dev</a> people for making this Debian derivative for the EV3.</p>

<p>While having the EV3 sitting there announcing a /48 of IPv6 is not useful in itself, this shows off how flexible the platform is. The fact that I can do this silly thing means that I can do much cooler things that don’t involve BGP on this, like running web servers and other things.</p>

<hr>

<p>If this was to your liking then maybe you will find my other posts interesting, and you can also find my smaller projects and ramblings on twitter: <a href="https://twitter.com/bitcynth">@bitcynth</a>.</p>

<p>Thank you to <a href="https://twitter.com/Benjojo12">Ben Cox</a> and <a href="https://www.mollymiller.net/">Molly Miller</a> for the help in editing this blog post.</p>

<p><sup><a name="fn1">[1]</a></sup>: no longer online</p>

</div></div>]]>
            </description>
            <link>https://blog.cynthia.re/post/bgp-lego</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026189</guid>
            <pubDate>Sun, 08 Nov 2020 15:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS file diff app, Kaleidoscope, acquired by Letter Opener GmbH]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25026070">thread link</a>) | @dplgk
<br/>
November 8, 2020 | https://kaleidoscope.app/release-notes | <a href="https://web.archive.org/web/*/https://kaleidoscope.app/release-notes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="macos"><h3>Kaleidoscope 2.3.4<p>November 6 2020</p></h3><p>build 1444 (Direct)</p><ul><li>Fixed some potential bugs hiding behind warnings.</li><li>Fixed missing update functionality of version 2.3.2.</li><li><strong>Note:</strong> If you installed version 2.3.2 please download manually the latest version.</li></ul><h3>Kaleidoscope 2.3.3<p>October 24 2020</p></h3><p>build 1443.1 (Mac App Store)</p><ul><li>Update contact information to support@kaleidoscope.app, don't be shy and say hi!</li><li>Fixed newsletter sign-up in the Help &gt; Getting Started window.</li></ul><h3>Change of ownership<p>October 9 2020</p></h3><ul><li>Letter Opener GmbH acquired Kaleidoscope from Hypergiant LLC.</li></ul><h3>Kaleidoscope 2.3.2<p>April 17 2020</p></h3><p>build 1442 (Direct) / 1442.1 (Mac App Store)</p><ul><li><strong>Note:</strong> build 1442 (Direct) was pulled because it is missing update functionality. If you installed version 2.3.2 please download manually the latest version.</li><li>Fixed bug in integration window</li></ul><h3>Kaleidoscope 2.3.1<p>April 7 2020</p></h3><p>build 1441 (Direct) / 1441.2 (Mac App Store)</p><ul><li>Fixed a crash caused by opening a zero-length text file</li><li>Improved scrolling performance when using Find to search for text</li><li>Minor bug fixes</li></ul><h3>Kaleidoscope 2.3<p>February 21 2020</p></h3><p>build 1438 (Direct)</p><ul><li>Improved macOS Catalina compatibility</li><li>Notarized builds for improved security</li><li>Fixed blurred scrollbar endcap issue on Retina displays</li><li>Updated crash analytics package</li><li>Minor bug fixes</li></ul><h3>Kaleidoscope 2.2.2<p>November 7 2017</p></h3><p>build 1376 (Direct) / 1376.01 (Mac App Store)</p><ul><li>Bug Fixes.</li></ul><h3>Kaleidoscope 2.2.1<p>August 9 2017</p></h3><p>build 1158 (Direct) / 1158.01 (Mac App Store)</p><ul><li><strong>Note:</strong> Kaleidoscope now requires macOS 10.12 or above.</li><ul><li>Fixed crashes related to future macOS releases.</li><li>Fixed an issue where the user is unnecessarily prompted to update ksdiff.</li><li>Updated documentation.</li><li>Added analytics to help our developers improve future releases.</li></ul></ul><h3>Kaleidoscope 2.2<p>May 3 2017</p></h3><p>build 439 (Direct) / 439.01 (Mac App Store)</p><ul><li><strong>New:</strong> Added support for recent macOS updates.</li><ul><li>Overhauled the interface to better reflect the contemporary Mac environment.</li><li>Added stability with multiple under-the-hood improvements.</li><li>Modernized the codebase to make future work more manageable.</li><li>Fixed various issues related to macOS Sierra.</li></ul></ul><h3>Kaleidoscope 2.1.1<p>June 9 2015</p></h3><p>build 219 (Direct)</p><ul><li><strong>Note:</strong> We are working to get version 2.1.1 into the Mac App Store. For now, please <a href="http://www.kaleidoscopeapp.com/download">download</a> the direct sale version. Your purchase will carry over.</li><li>Fixed a couple issues with our Bazaar integration instructions.</li><li>⌘-D now triggers the Don't Resolve button when dismissing a merge warning.</li><li>Improved automatic graphics switching support (Early 2011 or newer MacBooks Pro): Kaleidoscope will now only use the discrete GPU when necessary.</li><li>Updated our mechanism for purchasing a Kaleidoscope registration.</li></ul><h3>Kaleidoscope 2.1<p>April 30 2014</p></h3><p>build 134 (Direct) / 133.01 (Mac App Store)</p><ul><li><strong>New Feature:</strong> Added support for ignoring whitespace (leading, trailing and line ending) in text comparisons.</li><li><strong>New Feature:</strong> Added an indicator to display remaining unresolved conflicts in a merge document.</li><li><strong>Text Scope</strong><ul><li>Added dropdown menus on either side of Choose Left/Choose Right buttons to make “Choose Both” options more discoverable.</li><li>Added better tooltips for the “Copy to” buttons when in Unified view.</li><li>Fixed various issues with Dark Theme which made text difficult to read.</li><li>Fixed issue where selecting different text scope views on one window could affect copy right/left buttons on other windows.</li><li>Fixed issue where holding option to modify the behavior of copy right/left buttons on one window could affect other windows.</li><li>Fixed issue that could prevent Kaleidoscope from picking up changes made to a document open in more than one window.</li><li>Fixed issue that could prevent Kaleidoscope from picking up changes made to documents externally, especially on the MAS build.</li></ul></li><li><strong>Folder Scope</strong><ul><li>Fixed issue where sometimes Folder Scope copies would not show up correctly after the copy had taken place.</li><li>Fixed issue where Folder Scope would not pick up external additions of empty files or directories.</li><li>Fixed issue that caused the app to reject dragging of folders to the dock icon.</li></ul></li><li><strong>Integration</strong><ul><li>Fixed issue that caused git integration to fail on 10.9 Mavericks.</li><li>Fixed issue where ksdiff was sometimes not able to connect to Kaleidoscope after reboots with window restoration enabled.</li><li>Fixed issue that where Kaleidoscope would not allow quitting when choosing “Review Conflicts” on a modified document.</li></ul></li><li><strong>General Improvements</strong><ul><li>Updated Automator actions to categorize correctly in Automator.</li><li>Added support for copy/paste shortcuts in the crash reporter window.</li><li>Kaleidoscope now avoids saving files without changes.</li><li>Kaleidoscope will now disallow edits to files that can be read but not written to (e.g. docx files).</li><li>Kaleidoscope now better remembers size and position of your windows.</li><li>Fixed issue that stopped the comparison windows from minimizing when double clicking their title bar.</li><li>Fixed issue where the path bar area could fail to update correctly when switching tabs.</li><li>Fixed issue where clicking the dock icon would not restore minimized documents.</li><li>Fixed issue where dragging a group of files that were already open in Kaleidoscope could cause issues resulting in not all new files being added.</li><li>Fixed issue that made it possible for the comparison window to grow vertically offscreen on 10.9 leaving you with a window you could not reposition afterwards.</li><li>Fixed issue that made it impossible to bring up the open dialog by clicking on an empty tab when fullscreen in 10.9.</li><li>Fixed issue where sometimes full-screen windows would not be full-screen.</li><li>Fixed small visual issues with the Ignored Files dialog window.</li><li>Fixed documentation issues with ksdiff help.</li><li>Improved Help Documentation.</li><li>Various performance and stability fixes.</li></ul></li></ul><h3>Kaleidoscope 2.0.2<p>October 23 2013</p></h3><p>build 116</p><ul><li>Improved compatibility with OS X 10.9 Mavericks</li><li>Improved stability</li></ul><h3>Kaleidoscope 2.0.1<p>February 19 2013</p></h3><p>build 114</p><ul><li><strong>Text Scope</strong><ul><li>Tweaked the visual appearance of the change count stepper in Text Scope.</li><li>Fixed the "Reset Selection" menu item in Text Scope to enable and disable properly.</li><li>The Save menu is now properly disabled when comparing text snippets.</li><li>Fixed a bug where the summary text in document titles and tabs might not properly update.</li><li>The Resolved document in Three Way Blocks now has better alignment with similar content in A and B.</li><li>Kaleidoscope can now properly diff .textClipping documents.</li></ul></li><li><strong>Folder Scope</strong><ul><li>User-defined system date formats will now be properly used.</li><li>Fixed a bug that prevented Folder Scope from having the correct keyboard focus by default.</li></ul></li><li><strong>Image Scope</strong><ul><li>Kaleidoscope now handles different color spaces more reliably in Image Scope.</li><li>Kaleidoscope now properly accounts for camera orientation when displaying images in Image Scope.</li></ul></li><li><strong>Changesets</strong><ul><li>Improved keyboard navigation in changesets.</li><li>Unsaved files will now be properly marked as dirty in changesets.</li><li>Changesets now properly select the list of files on the left when opening, allowing you to quickly review changes.</li></ul></li><li><strong>General Improvements</strong><ul><li>Direct Sale fulfillment emails will now properly activate Kaleidoscope for users with diacritics in their names.</li><li>Kaleidoscope will no longer move itself to ~/Applications if that folder exists. It will now move to /Applications in all cases.</li><li>Fixed a bug that caused temporary licenses to expire one day earlier than they should have.</li><li>Fixed a bug that caused the corner radii of windows in Full Screen to not match.</li><li>Fixed an issue that sometimes led to poor vertical alignment in the File Shelf.</li><li>Dragging files to Kaleidoscope will properly open to a comparison document and will no longer leave the launch window open in the background.</li><li>Fixed a bug that caused accessing files from the Recents list to sometimes stop working.</li><li>Improved the messaging if Kaleidoscope is unable to open a document that was previously available via AFP.</li></ul></li></ul><h3>Kaleidoscope 2.0<p>January 17, 2013</p></h3><p>build 107</p><ul><li>Resets trial period for users whose trial period expired during beta</li></ul><h3>Kaleidoscope 2.0<p>January 17, 2013</p></h3><p>build 104</p><ul><li><strong>New Feature:</strong> Added support for merging text documents using a Two-Way interface in Text Scope.</li><li><strong>New Feature:</strong> Added version control integration for merging and resolving conflicts using a Three-Way interface in Text Scope.</li><li><strong>New Feature:</strong> Folder Scope — now you can spot the differences between folders and copy files and folders between them. Double click any row to open a new comparison and look at any pair of files or folders more closely.</li><li><strong>New Feature:</strong> Kaleidoscope Snippets and Services</li><ul><li>You can now drag text and images directly into the Kaleidoscope window, or the Kaleidoscope dock icon, to create Snippets. This lets you quickly compare content without having to save and name files. Try dragging images or text directly from Safari or an email message!</li><li>Kaleidoscope now includes OS X System Services to make you more productive. They are enabled by default, but you can manually turn them On or Off in the Keyboard section of System Preferences. You can also set global keyboard shortcuts for them in the Keyboard pane of System Preferences if you want to get to these even faster.</li><li>Open in Kaleidoscope: Right click on any files or folders in Finder, and compare them in a single Kaleidoscope tab. This is the easiest way to compare folders!</li><li>Text and Image Compare: Right click on text or images and send them directly to Kaleidoscope as Snippets. Try this by selecting and right clicking on any text in TextEdit, then select “Compare Text in Kaleidoscope” from the Services menu.</li></ul><li><strong>New Feature:</strong> Clipboard Support</li><ul><li>You can use the new "Edit -&gt; Paste as File" and "File -&gt; New from Clipboard" menu items to compare directly from the Clipboard. This works similarly to the drag and drop Snippets functionality. Use this to quickly create a new comparison document or to add existing text or images to an open document.</li></ul><li><strong>New Feature:</strong> Kaleidoscope now supports resolving merge conflicts for images.</li><li><strong>New Feature:</strong> Added support for Full Screen on Lion and Mountain Lion.</li><li>Full support for Macs with Retina displays.</li><li>Substantially updated and modernized user interface.</li><li>Added support for sending arbitrary changesets and partial changsets with ksdiff.</li><li>Added support for arbitrary merges and diffs using ksdiff.</li><li>Integration with third-party tools now requires installation of the ksdiff command-line tool from the Integration …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kaleidoscope.app/release-notes">https://kaleidoscope.app/release-notes</a></em></p>]]>
            </description>
            <link>https://kaleidoscope.app/release-notes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25026070</guid>
            <pubDate>Sun, 08 Nov 2020 14:44:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python bytecode is executed]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25025451">thread link</a>) | @r4victor
<br/>
November 8, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>We started this series with <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">an overview of the CPython VM</a>. We learned that to run a Python program, CPython first compiles it to bytecode, and we studied how the compiler works in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">part two</a>. <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">Last time</a> we stepped through the CPython source code starting with the <code>main()</code> function until we reached the evaluation loop, a place where Python bytecode gets executed. The main reason why we spent time studying these things was to prepare for the discussion that we start today. The goal of this discussion is to understand how CPython does what we tell it to do, that is, how it executes the bytecode to which the code we write compiles.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h3>Starting point</h3>
<p>Let's briefly recall what we learned in the previous parts. We tell CPython what to do by writing Python code. The CPython VM, however, understands only Python bytecode. This is the job of the compiler to translate Python code to bytecode. The compiler stores bytecode in a code object, which is a structure that fully describes what a code block, like a module or a function, does. To execute a code object, CPython first creates a state of execution for it called a frame object. Then it passes a frame object to a frame evaluation function to perform the actual computation. The default frame evaluation function is <code>_PyEval_EvalFrameDefault()</code> defined in <a href="https://github.com/python/cpython/blob/3.9/Python/ceval.c#L889">Python/ceval.c</a>. This function implements the core of the CPython VM. Namely, it implements the logic for the execution of Python bytecode. So, this function is what we're going to study today.</p>
<p>To understand how <code>_PyEval_EvalFrameDefault()</code> works, it is crucial to have an idea of what its input, a frame object, is. A frame object is a Python object defined by the following C struct:</p>
<div><pre><span></span><span>// typedef struct _frame PyFrameObject; in other place</span>
<span>struct</span> <span>_frame</span> <span>{</span>
    <span>PyObject_VAR_HEAD</span>
    <span>struct</span> <span>_frame</span> <span>*</span><span>f_back</span><span>;</span>      <span>/* previous frame, or NULL */</span>
    <span>PyCodeObject</span> <span>*</span><span>f_code</span><span>;</span>       <span>/* code segment */</span>
    <span>PyObject</span> <span>*</span><span>f_builtins</span><span>;</span>       <span>/* builtin symbol table (PyDictObject) */</span>
    <span>PyObject</span> <span>*</span><span>f_globals</span><span>;</span>        <span>/* global symbol table (PyDictObject) */</span>
    <span>PyObject</span> <span>*</span><span>f_locals</span><span>;</span>         <span>/* local symbol table (any mapping) */</span>
    <span>PyObject</span> <span>**</span><span>f_valuestack</span><span>;</span>    <span>/* points after the last local */</span>
    <span>/* Next free slot in f_valuestack.  Frame creation sets to f_valuestack.</span>
<span>       Frame evaluation usually NULLs it, but a frame that yields sets it</span>
<span>       to the current stack top. */</span>
    <span>PyObject</span> <span>**</span><span>f_stacktop</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>f_trace</span><span>;</span>          <span>/* Trace function */</span>
    <span>char</span> <span>f_trace_lines</span><span>;</span>         <span>/* Emit per-line trace events? */</span>
    <span>char</span> <span>f_trace_opcodes</span><span>;</span>       <span>/* Emit per-opcode trace events? */</span>

    <span>/* Borrowed reference to a generator, or NULL */</span>
    <span>PyObject</span> <span>*</span><span>f_gen</span><span>;</span>

    <span>int</span> <span>f_lasti</span><span>;</span>                <span>/* Last instruction if called */</span>
    <span>int</span> <span>f_lineno</span><span>;</span>               <span>/* Current line number */</span>
    <span>int</span> <span>f_iblock</span><span>;</span>               <span>/* index in f_blockstack */</span>
    <span>char</span> <span>f_executing</span><span>;</span>           <span>/* whether the frame is still executing */</span>
    <span>PyTryBlock</span> <span>f_blockstack</span><span>[</span><span>CO_MAXBLOCKS</span><span>];</span> <span>/* for try and loop blocks */</span>
    <span>PyObject</span> <span>*</span><span>f_localsplus</span><span>[</span><span>1</span><span>];</span>  <span>/* locals+stack, dynamically sized */</span>
<span>};</span>
</pre></div>


<p>The <code>f_code</code> field of a frame object points to a code object. A code object is also a Python object. Here's its definition:</p>
<div><pre><span></span><span>struct</span> <span>PyCodeObject</span> <span>{</span>
    <span>PyObject_HEAD</span>
    <span>int</span> <span>co_argcount</span><span>;</span>            <span>/* #arguments, except *args */</span>
    <span>int</span> <span>co_posonlyargcount</span><span>;</span>     <span>/* #positional only arguments */</span>
    <span>int</span> <span>co_kwonlyargcount</span><span>;</span>      <span>/* #keyword only arguments */</span>
    <span>int</span> <span>co_nlocals</span><span>;</span>             <span>/* #local variables */</span>
    <span>int</span> <span>co_stacksize</span><span>;</span>           <span>/* #entries needed for evaluation stack */</span>
    <span>int</span> <span>co_flags</span><span>;</span>               <span>/* CO_..., see below */</span>
    <span>int</span> <span>co_firstlineno</span><span>;</span>         <span>/* first source line number */</span>
    <span>PyObject</span> <span>*</span><span>co_code</span><span>;</span>          <span>/* instruction opcodes */</span>
    <span>PyObject</span> <span>*</span><span>co_consts</span><span>;</span>        <span>/* list (constants used) */</span>
    <span>PyObject</span> <span>*</span><span>co_names</span><span>;</span>         <span>/* list of strings (names used) */</span>
    <span>PyObject</span> <span>*</span><span>co_varnames</span><span>;</span>      <span>/* tuple of strings (local variable names) */</span>
    <span>PyObject</span> <span>*</span><span>co_freevars</span><span>;</span>      <span>/* tuple of strings (free variable names) */</span>
    <span>PyObject</span> <span>*</span><span>co_cellvars</span><span>;</span>      <span>/* tuple of strings (cell variable names) */</span>
    <span>/* The rest aren't used in either hash or comparisons, except for co_name,</span>
<span>       used in both. This is done to preserve the name and line number</span>
<span>       for tracebacks and debuggers; otherwise, constant de-duplication</span>
<span>       would collapse identical functions/lambdas defined on different lines.</span>
<span>    */</span>
    <span>Py_ssize_t</span> <span>*</span><span>co_cell2arg</span><span>;</span>    <span>/* Maps cell vars which are arguments. */</span>
    <span>PyObject</span> <span>*</span><span>co_filename</span><span>;</span>      <span>/* unicode (where it was loaded from) */</span>
    <span>PyObject</span> <span>*</span><span>co_name</span><span>;</span>          <span>/* unicode (name, for reference) */</span>
    <span>PyObject</span> <span>*</span><span>co_lnotab</span><span>;</span>        <span>/* string (encoding addr&lt;-&gt;lineno mapping) See</span>
<span>                                   Objects/lnotab_notes.txt for details. */</span>
    <span>void</span> <span>*</span><span>co_zombieframe</span><span>;</span>       <span>/* for optimization only (see frameobject.c) */</span>
    <span>PyObject</span> <span>*</span><span>co_weakreflist</span><span>;</span>   <span>/* to support weakrefs to code objects */</span>
    <span>/* Scratch space for extra data relating to the code object.</span>
<span>       Type is a void* to keep the format private in codeobject.c to force</span>
<span>       people to go through the proper APIs. */</span>
    <span>void</span> <span>*</span><span>co_extra</span><span>;</span>

    <span>/* Per opcodes just-in-time cache</span>
<span>     *</span>
<span>     * To reduce cache size, we use indirect mapping from opcode index to</span>
<span>     * cache object:</span>
<span>     *   cache = co_opcache[co_opcache_map[next_instr - first_instr] - 1]</span>
<span>     */</span>

    <span>// co_opcache_map is indexed by (next_instr - first_instr).</span>
    <span>//  * 0 means there is no cache for this opcode.</span>
    <span>//  * n &gt; 0 means there is cache in co_opcache[n-1].</span>
    <span>unsigned</span> <span>char</span> <span>*</span><span>co_opcache_map</span><span>;</span>
    <span>_PyOpcache</span> <span>*</span><span>co_opcache</span><span>;</span>
    <span>int</span> <span>co_opcache_flag</span><span>;</span>  <span>// used to determine when create a cache.</span>
    <span>unsigned</span> <span>char</span> <span>co_opcache_size</span><span>;</span>  <span>// length of co_opcache.</span>
<span>};</span>
</pre></div>


<p>The most important field of a code object is <code>co_code</code>. It's a pointer to a Python bytes object representing the bytecode. The bytecode is a sequence of two-byte instructions: one byte for an opcode and one byte for an argument.</p>
<p>Don't worry if some members of the above structures are still a mystery to you. We'll see what they are used for as we move forward in our attempt to understand how the CPython VM executes the bytecode.</p>
<h3>Overview of the evaluation loop</h3>
<p>The problem of executing Python bytecode may seem a no-brainer to you. Indeed, all the VM has to do is to iterate over the instructions and to act according to them. And this is what essentially <code>_PyEval_EvalFrameDefault()</code> does. It contains an infinite <code>for (;;)</code> loop that we refer to as the evaluation loop. Inside that loop there is a giant <code>switch</code> statement over all possible opcodes. Each opcode has a corresponding <code>case</code> block containing the code for executing that opcode. The bytecode is represented by an array of 16-bit unsigned integers, one integer per instruction. The VM keeps track of the next instruction to be executed using the <code>next_instr</code> variable, which is a pointer to the array of instructions. At the start of each iteration of the evaluation loop, the VM calculates the next opcode and its argument by taking the least significant and the most significant byte of the next instruction respectively and increments <code>next_instr</code>. The <code>_PyEval_EvalFrameDefault()</code> function is nearly 3000 lines long, but its essence can be captured by the following simplified version:</p>
<div><pre><span></span><span>PyObject</span><span>*</span>
<span>_PyEval_EvalFrameDefault</span><span>(</span><span>PyThreadState</span> <span>*</span><span>tstate</span><span>,</span> <span>PyFrameObject</span> <span>*</span><span>f</span><span>,</span> <span>int</span> <span>throwflag</span><span>)</span>
<span>{</span>
    <span>// ... declarations and initialization of local variables</span>
    <span>// ... macros definitions</span>
    <span>// ... call depth handling</span>
    <span>// ... code for tracing and profiling</span>

    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>// ... check if the bytecode execution must be suspended,</span>
        <span>// e.g. other thread requested the GIL</span>

        <span>// NEXTOPARG() macro</span>
        <span>_Py_CODEUNIT</span> <span>word</span> <span>=</span> <span>*</span><span>next_instr</span><span>;</span> <span>// _Py_CODEUNIT is a typedef for uint16_t</span>
        <span>opcode</span> <span>=</span> <span>_Py_OPCODE</span><span>(</span><span>word</span><span>);</span>
        <span>oparg</span> <span>=</span> <span>_Py_OPARG</span><span>(</span><span>word</span><span>);</span>
        <span>next_instr</span><span>++</span><span>;</span>

        <span>switch</span> <span>(</span><span>opcode</span><span>)</span> <span>{</span>
            <span>case</span> <span>TARGET</span><span>(</span><span>NOP</span><span>)</span> <span>{</span>
                <span>FAST_DISPATCH</span><span>();</span> <span>// more on this later</span>
            <span>}</span>

            <span>case</span> <span>TARGET</span><span>(</span><span>LOAD_FAST</span><span>)</span> <span>{</span>
                <span>// ... code for loading local variable</span>
            <span>}</span>

            <span>// ... 117 more cases for every possible opcode</span>
        <span>}</span>

        <span>// ... error handling</span>
    <span>}</span>

    <span>// ... termination</span>
<span>}</span>
</pre></div>


<p>To get a more realistic picture, let's discuss some of the omitted pieces in more detail.</p>
<h4>reasons to suspend the loop</h4>
<p>From time to time, the currently running thread stops executing the bytecode to do something else or to do nothing. This can happen due to one of the four reasons:</p>
<ul>
<li>There are signals to handle. When you register a function as a signal handler using <a href="https://docs.python.org/3/library/signal.html#signal.signal"><code>signal.signal()</code></a>, CPython stores this function in the array of handlers. The function that will actually be called when a thread receives a signal is <code>signal_handler()</code> (it's passed to the <a href="https://www.man7.org/linux/man-pages/man2/sigaction.2.html"><code>sigaction()</code></a> library function on Unix-like systems). When called, <code>signal_handler()</code> sets a boolean variable telling that the function in the array of handlers corresponding to the received signal has to be called. Periodically, the main thread of the main interpreter calls the tripped handlers.</li>
<li>There are pending calls to call. Pending calls is a mechanism that allows to schedule a function to be executed from the main thread. This mechanism is exposed by the Python/C API via the <a href="https://docs.python.org/3/c-api/init.html#c.Py_AddPendingCall"><code>Py_AddPendingCall()</code></a> function.</li>
<li>The asynchronous exception is raised. The asynchronous exception is an exception set in one thread from another. This can be done using the <a href="https://docs.python.org/3/c-api/init.html#c.PyThreadState_SetAsyncExc"><code>PyThreadState_SetAsyncExc()</code></a> function provided by the Python/C API.</li>
<li>The currently running thread is requested to drop the GIL. When it sees such a request, it drops the GIL and waits until it acquires the GIL again.</li>
</ul>
<p>CPython has indicators for each of these events. The variable indicating that there are handlers to call is a member of <code>runtime-&gt;ceval</code>, which is a <code>_ceval_runtime_state</code> struct:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025451</guid>
            <pubDate>Sun, 08 Nov 2020 12:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clues to identify a destructive leader]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25025363">thread link</a>) | @BossingAround
<br/>
November 8, 2020 | https://articles.tilt365.com/identify-destructive-leadership-patterns/ | <a href="https://web.archive.org/web/*/https://articles.tilt365.com/identify-destructive-leadership-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://articles.tilt365.com/content/images/size/w300/2020/11/sharks-in-the-water-1.png 300w,
                            https://articles.tilt365.com/content/images/size/w600/2020/11/sharks-in-the-water-1.png 600w,
                            https://articles.tilt365.com/content/images/size/w1000/2020/11/sharks-in-the-water-1.png 1000w,
                            https://articles.tilt365.com/content/images/size/w2000/2020/11/sharks-in-the-water-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://articles.tilt365.com/content/images/size/w2000/2020/11/sharks-in-the-water-1.png" alt="4 Clues to Identify a Destructive Leader">
            </figure>

            <section>
                <div>
                    <p>In many aspects of our lives, we rely on those in positions of power to lead us. The role of leaders becomes especially salient in times of uncertainty. Throughout your life, you’ve probably seen several ways leaders can respond to challenging and ambiguous situations. A transformational leader can see the opportunities in turmoil and inspire people to follow them to a better future. On the other hand, an incompetent leader will leave you to deal with everything alone. In the worst-case scenario, a destructive leader will see the potential for self-enhancement and exploit others to maximize their gain. </p><figure><img src="https://articles.tilt365.com/content/images/2020/11/four-patterns-of-destructive-leadership.png" alt="" srcset="https://articles.tilt365.com/content/images/size/w600/2020/11/four-patterns-of-destructive-leadership.png 600w, https://articles.tilt365.com/content/images/size/w1000/2020/11/four-patterns-of-destructive-leadership.png 1000w, https://articles.tilt365.com/content/images/2020/11/four-patterns-of-destructive-leadership.png 1069w" sizes="(min-width: 720px) 720px"><figcaption>4 Clues to Identify a Destructive Leader</figcaption></figure><h3 id="people-leave-managers-not-companies-">People leave managers, not companies.</h3><p>Incompetent and destructive leaders both create negative consequences, but the distinction between the two is essential. An incompetent leader may lack the compelling charisma to engage others to follow, but we wouldn’t call someone lacking charisma actively destructive. A <a href="https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199755615.001.0001/oxfordhb-9780199755615-e-014">destructive leader</a> intentionally and systematically behaves in a way that violates the organization’s members and stakeholders’ best interests. The extent of damage that a destructive leader can cause often goes unnoticed until it is too late (e.g., Enron), but there are clues you can look for to help you identify destructive leaders earlier. These clues reflect behaviors and attitudes that can reveal the destructive nature of an otherwise seemingly competent leader.</p><h3 id="what-causes-destructive-leadership-patterns">What causes destructive leadership patterns?</h3><p>Everyone has some characteristics that are annoying to someone who prefers a different way of behaving and working. These characteristics are inherited in our DNA and influenced by the environment in which we grew up. The genetic influence was passed down from generation to generation and is a product of evolution that helped your ancestors survive the environments they encountered. And they can help you too, as long as they don’t become distorted from early experiences of chronic fear. </p><p>In destructive leadership, typical behavior patterns become distorted into extremes powered by the brain’s more primitive parts under such circumstances. When this happens, we are in fear-mode, and a blend of fear reactions becomes our norm. These distorted patterns become habitual, and our responses to others become unhealthy. For example, suppose we experienced excessive criticism in our early development. In that case, our ego will record a perception of being diminished by important caregivers and sense that our very survival depends on not being criticized. In this case, we may learn to strive excessively for superiority to alleviate the fear of feeling inferior in our assessment of ourselves.</p><p>While a reactive pattern like this helped us survive the precise environment we were born into, in a global world, that same pattern may not. The brain’s brilliant design constructs a set of behaviors that will ensure our survival in whatever we experience in the development years to maturity. But if we move to an entirely new environment as an adult, the patterns that served us before may not translate into helpful practices somewhere else. </p><h3 id="the-reason-anxiety-and-stress-are-at-an-all-time-high-">The reason anxiety and stress are at an all-time high.</h3><p>In the last century, this phenomenon has become even more complicated. With the advancement of technology comes exposure to human systems all over the world. Transportation enables moving to any part of the globe in a day or two. As we move about rapidly from one culture to another, we find ourselves unable to understand why we are perceived positively in one environment and the opposite in another. No wonder anxiety and stress are at an all-time high, especially for those who interact in global companies. Adaptation to other cultures becomes a necessity, making self-awareness and emotional intelligence some of the most critical skill sets of our time. </p><h3 id="first-look-for-the-underlying-intention-">First, look for the underlying intention.</h3><p>Because all human systems are imperfect, and most parents do the best they can do, many of us have traces of fear behaviors that can drive others nuts. There are a few prototypical examples of these types of behaviors, including, but not limited to </p><ul><li>The constant worrier who is always second-guessing themselves,</li><li>The storyteller who seems to live in an ideal world no one else can relate to,</li><li>The dominant driver who wants everything to go their way,</li><li>The prideful judge who doesn’t realize they can’t possibly know everything there is to know about everything. </li></ul><p>When we’re talking about destructive leadership, we’re not merely referring to annoying habits unless they have become very extreme or painfully frequent. Destructive leaders have little interest in how they are perceived, so they are rarely interested in how they could improve. </p><h3 id="destructive-leaders-are-single-mindedly-self-interested-">Destructive leaders are single-mindedly self-interested.</h3><p>Generally, healthy leaders may have annoying habits, but when you look beneath the surface, two things are different: </p><ol><li>They adopt a mindset that conveys they care about their impact on others and are willing to listen, learn, and exert the choice and character to change.</li><li>They hold a positive intention toward others and work for the good of the mission and the enterprise they serve. </li></ol><p>On the other hand, destructive leaders are either:</p><ol><li>Un-coachable because they adopt a rigid mindset that conveys they don’t care about their impact on others and will use their authority to manipulate others to bend to their will. They imply, “I am who I am, so deal with it.”</li><li>They have a hidden ulterior motive for wanting and using power to serve themselves at the expense of others, the mission, or the enterprise. </li></ol><p>So, as we lay out the four clues of destructive leaders, keep two things in mind. Do you have a hunch that they are well-intended, and are they willing to work on themselves? If the answer to both is affirmative, they are probably not destructive, but just like you and me, they are trying to serve their company and grow as best they can. In these circumstances, we can mind our own business and work on our self-improvement plan rather than thinking about how annoying they are. After all, it’s temporary unless they are genuinely destructive. And then you must do everything in your power to remove them from your company, or they could take the whole thing down. </p><h3 id="clue-1-behaviors-or-words-that-imply-i-m-kind-of-a-big-deal-">Clue 1: Behaviors or words that imply “I’m kind of a big deal!”</h3><p><strong>Excessive fabrication and exaggeration that is nowhere near the truth. </strong></p><p>This destructive pattern arises from an inner identity that seeks to resolve a childhood dilemma about not getting enough attention from caregivers, so they do not feel special. This dilemma results in insatiable attention-seeking and an inflated need to be special, unique, or novel. The inner fear is feeling trapped in the loneliness or sadness of not being “special” enough to those who matter. Because they perceive being attention-deprived or unworthy, they feel shame, and it becomes so painful, they rebel from authority figures whom they believe could not be trusted. Instead of following appropriately, they become rebellious and provocative, conning others to go along with their fantastic plans. </p><h3 id="clues-you-will-notice-">Clues you will notice: </h3><ul><li>Exaggeration of the truth to the point of fantasy</li><li>Unapologetic self-promoting and self-aggrandizing</li><li>Excessive talking to dominate others</li><li>Pontification and fabrication of elaborate stories</li><li>Disrespect for authority figures</li><li>Disregard for rules that are contrary to their aims</li><li>Automatically dismiss ideas from others</li><li>An insatiable need to be the center of attention</li><li>Terminally individualistic, unique, or novel</li><li>External image is unusually extreme in some way</li></ul><h3 id="results-in-a-chaotic-climate">Results in a Chaotic Climate</h3><p>These destructive leaders are challenging to work with because they demand attention but don’t want the restrictions that come with being front and center. When they are in the limelight, it can be exceedingly uncomfortable because they also unconsciously fail to believe they are impressive enough. So they attract attention, initiate excessive activity, and then thwart the attention this draws. This pattern makes them unpredictable, so the shadow of the climate they create around them is chaotic and confusing for others. </p><h3 id="clue-2-behaviors-or-words-that-imply-none-of-this-is-my-fault-">Clue 2: Behaviors or words that imply “None of this is my fault!”</h3><p><strong>Excessive conflict-avoidance by deflecting personal responsibility. </strong></p><p>This destructive pattern arises from an inner identity that seeks to resolve a childhood dilemma about not getting enough approval and acceptance. This dilemma results in insatiable approval-seeking and an excessive need to be liked by everyone, even strangers. The inner fear is to be rejected or ridiculed by others as unlovable by those who matter. Because they perceive being unacceptable to others, they feel powerless and unworthy of care. This experience can become painful and they are unable to communicate or ask others for what they need because they don’t feel they deserve it. They defer to those in authority roles and suffer quietly in dependence, hopelessness, and seen as “needy” for any shred of approval. </p><h3 id="clues-you-will-notice--1">Clues you will notice:</h3><ul><li>Complaining, blaming, gossiping about others</li><li>Disgruntled resentment of those in authority</li><li>Giving up their power and being dependent on others</li><li>Come across as “needy” and draining</li><li>Asking others to decide and then resenting it</li><li>Avoiding leadership to avoid culpability later</li><li>Unconsciously inviting others to dominate them</li><li>Blaming others for being the “bully”</li><li>Desire to be the “nice” or “good” one</li><li>An insatiable need to be liked, accepted, included</li></ul><h3 id="results-in-a-conflict-averse-climate">Results in a Conflict Averse Climate </h3><p>These destructive leaders are challenging to work with because they put extreme energy into taking care of or helping others with an unstated expectation that there will be a reward in return. For example, they take care of someone with the expectation that the other person will take the responsibility of making decisions for them. However, they may not tell the other person this expectation. There is an unconscious …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://articles.tilt365.com/identify-destructive-leadership-patterns/">https://articles.tilt365.com/identify-destructive-leadership-patterns/</a></em></p>]]>
            </description>
            <link>https://articles.tilt365.com/identify-destructive-leadership-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25025363</guid>
            <pubDate>Sun, 08 Nov 2020 12:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Week of NixOS]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 168 (<a href="https://news.ycombinator.com/item?id=25024639">thread link</a>) | @jaemoe
<br/>
November 8, 2020 | https://jae.moe/blog/2020/11/one-week-of-nixos/ | <a href="https://web.archive.org/web/*/https://jae.moe/blog/2020/11/one-week-of-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h4>One week of NixOS</h4><p>
            Reading time: 4 minutes.
            </p><p>As you may have seen I on Mastodon, I am testing NixOS for over a week now and here is a few comments about how the distro works and what doesn’t work for me.</p>










<p>First, everything is NixOS is declared in a configuration file located at <code>/etc/nixos/configuration.nix</code> where you declare packages you want to install, services to start, udev rules, ECT, you get it.</p>
<p>This is the first very weird thing as you don’t really install packages with the CLI directly (even if you can), instead you modify the config file and rebuild the system with <code>nixos-rebuild switch</code>.</p>
<p>NixOS is made in such a way that everything aims to be reproducible. An example: if you want to get the exact same setup as I have, you can just take <a href="https://forge.tedomum.net/jae/nixos-configs">my configs repo</a>, clone it on your NixOS installation, run <code>nixos-rebuild switch</code> and voilà, you will have the exact same programs as me installed in the same way with the same version (roughly).</p>
<p>In this distro, adding a user is really easy and goes like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"><span>{</span> <span>config</span><span>,</span> <span>pkgs</span><span>,</span> <span>...</span> <span>}:</span>

<span>{</span>

    <span>users</span><span>.</span><span>groups</span><span>.</span><span>plugdev</span> <span>=</span> <span>{};</span>

    <span>users</span><span>.</span><span>users</span><span>.</span><span>jae</span> <span>=</span> <span>{</span>
        <span>isNormalUser</span> <span>=</span> <span>true</span><span>;</span>
        <span>extraGroups</span> <span>=</span> <span>[</span> <span>"wheel"</span> <span>"docker"</span> <span>"adbusers"</span> <span>"plugdev"</span> <span>];</span>
        <span>shell</span> <span>=</span> <span>pkgs</span><span>.</span><span>zsh</span><span>;</span>
        <span>packages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span>
            <span># Games</span>
            <span>minetest</span> <span>stepmania</span> <span>lutris-free</span> <span>pcsx2</span>
            <span># Misc audio / video / image</span>
            <span>pulseeffects</span> <span>ffmpeg-full</span> <span>obs-studio</span> <span>inkscape</span> <span>krita</span>
            <span># Useful software</span>
            <span>mumble</span> <span>qbittorrent</span> <span>libreoffice</span> <span>ledger-live-desktop</span>
            <span># Dev</span>
            <span>jetbrains</span><span>.</span><span>idea-community</span> <span>lazygit</span> <span>gnome3</span><span>.</span><span>zenity</span> <span>insomnia</span> <span>jetbrains</span><span>.</span><span>rider</span> <span>mono</span> <span>msbuild</span> <span>dotnet-sdk_3</span> <span>ganttproject-bin</span> <span>kubectx</span>
            <span># SDR</span>
            <span>rtl-sdr</span> <span>gqrx</span> <span>gpredict</span> <span>noaa-apt</span> <span>welle-io</span>
        <span>];</span>
    <span>};</span>
    <span>users</span><span>.</span><span>extraGroups</span><span>.</span><span>vboxusers</span><span>.</span><span>members</span> <span>=</span> <span>[</span> <span>"jae"</span> <span>];</span>
<span>}</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>Let’s see what everything does!</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>users</span><span>.</span><span>groups</span><span>.</span><span>plugdev</span> <span>=</span> <span>{};</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
Creates a group named <code>plugdev</code>, don’t pay attention to it, it is just a test for the Ledger Live application.</p>
<p>
Tells the os that the current user is a normal one. It will create a home folder and set the default shell.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>extraGroups</span> <span>=</span> <span>[</span> <span>"wheel"</span> <span>"docker"</span> <span>"adbusers"</span> <span>"plugdev"</span> <span>];</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
Here, we are setting the groups the user is in to grant special permissions.</p>
<p>
As you may have guessed it, we are setting the default user shell to ZSH.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="nixos"> <span>packages</span> <span>=</span> <span>with</span> <span>pkgs</span><span>;</span> <span>[</span>
            <span># Games</span>
            <span>minetest</span> <span>stepmania</span> <span>lutris-free</span> <span>pcsx2</span>
            <span># Misc audio / video / image</span>
            <span>pulseeffects</span> <span>ffmpeg-full</span> <span>obs-studio</span> <span>inkscape</span> <span>krita</span>
            <span># Useful software</span>
            <span>mumble</span> <span>qbittorrent</span> <span>libreoffice</span> <span>ledger-live-desktop</span>
            <span># Dev</span>
            <span>jetbrains</span><span>.</span><span>idea-community</span> <span>lazygit</span> <span>gnome3</span><span>.</span><span>zenity</span> <span>insomnia</span> <span>jetbrains</span><span>.</span><span>rider</span> <span>mono</span> <span>msbuild</span> <span>dotnet-sdk_3</span> <span>ganttproject-bin</span> <span>kubectx</span>
            <span># SDR</span>
            <span>rtl-sdr</span> <span>gqrx</span> <span>gpredict</span> <span>noaa-apt</span> <span>welle-io</span>
        <span>];</span></code></pre></td></tr></tbody></table>
</div>
</div><p>
There, we are installing per-user packages because yes, NixOS supports that, any user can have its own packages that others users can’t access.</p>
<blockquote>
<p>Correction from <em>hvdijk</em> on Hacker News, “<em>Other users can access those packages if they want to. Those packages won’t show up in other users' $PATH, so other users will not be affected by them, but they could see what’s in /nix/store if they wanted to. This matters when you’re thinking of putting private data (such as an encryption key) in a package: it’s vital that you don’t do that on a multi-user system.</em>”</p>
</blockquote>
<p>Configuring NixOS for a daily use is at the end very easy (although I am getting some trouble to get Ledger Live working; which is the biggest problem I’ve had so far).</p>
<p>Now, let’s talk about where I got some trouble.
As you may know it, I am a dev and every day I need to compile, test, run and so on.
NixOS gave me some trouble to only run some programs from source such as <a href="https://element.io/">Element Desktop</a> or <a href="https://img.tedomum.net/">TeDomum IMG</a> as the way the system is built, lots of directories are read-only and programs can’t be installed globally through NPM or PIP.
I ended up using Docker to build the apps (even if it took a bit more time).</p>
<p>Needless to say, almost every other project worked.
If you want NodeJS to start a project for instance, you can just do <code>nix-shell -p nodejs</code> and here you go, a shell with nodejs installed, ready to do what you want.</p>
<p>At the end, NixOS brings very interesting concepts such as a really great reproducibility but new users can feel lost as its way to work is really different from conventional Linux distributions.
I’ll give NixOS more time and write a follow-up in some time to see how everything went.</p>
<p>If you want to give it a shot, the <a href="https://nixos.org/">official NixOS website awaits you</a>!</p>
<p>That’s all for today,
I’ll see you next time!
If you like my content, <a href="https://jae.moe/blog/index.xml">don’t forget to subscribe through RSS</a>!</p>

            
                <p><a href="https://news.ycombinator.com/item?id=25024639">Talk about it on Hacker News!</a>
            
        </p></div></div>]]>
            </description>
            <link>https://jae.moe/blog/2020/11/one-week-of-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024639</guid>
            <pubDate>Sun, 08 Nov 2020 10:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pro Rata and User Centric Distribution Models: A Comparative Study (2017)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25024552">thread link</a>) | @iamacyborg
<br/>
November 8, 2020 | http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf | <a href="https://web.archive.org/web/*/http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.digitalmedia.fi/wp-content/uploads/2018/02/UC_report_final_171213.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024552</guid>
            <pubDate>Sun, 08 Nov 2020 10:01:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL Configuration for Humans]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25024224">thread link</a>) | @sharjeelsayed
<br/>
November 8, 2020 | https://postgresqlco.nf/en/doc/param/ | <a href="https://web.archive.org/web/*/https://postgresqlco.nf/en/doc/param/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div id="welcome">
      
      <div lang="en">
        <h4><p>Your postgresql.conf documentation and recommendations.</p><p>Our mission is to help you tune and optimize your PostgreSQL configuration.</p><p>With around 270 configuration parameters in <span>postgresql.conf</span>, plus all the knobs in pg_hba.conf, it is definitely a difficult task!</p><p>How many parameters do you tune? 1? 8? 32? Ever tuned more than 64? We aim to make PostgreSQL configuration possible for HUMANS.</p></h4>
      </div>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://postgresqlco.nf/en/doc/param/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024224</guid>
            <pubDate>Sun, 08 Nov 2020 08:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing the Infamous Japanese Postal CSV]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25023673">thread link</a>) | @polm23
<br/>
November 7, 2020 | https://www.dampfkraft.com/posuto.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/posuto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dampfkraft.com/posuto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023673</guid>
            <pubDate>Sun, 08 Nov 2020 06:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote JavaScript to avoid JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25023594">thread link</a>) | @asaaki
<br/>
November 7, 2020 | https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/ | <a href="https://web.archive.org/web/*/https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Web technologies have come so far, that you realize: not everything needs to be done in JavaScript nowadays anymore.</p><blockquote><p><em>»Life is really simple, but we insist on making it complicated.« — Confucius</em></p></blockquote><p>My initial headline would have been:</p><p><em>How I wrote more JavaScript in the backend to eliminate JavaScript in the frontend.</em></p><p>But that's already a mouthful and also would have revealed too much and you might not have clicked my slightly clickbait-y title, right?</p><p>So here is my Public Service Announcement:</p><p> 📣 <strong>This site does not use any frontend JavaScript.<sup>*</sup></strong></p><p><em><small>*) There are only tiny exceptions on 2 pages, but for a good reason. More on that later.</small></em></p><p>First of all I am not against JavaScript (<span>JS</span>) at all. If you're building a web <strong>application</strong>, then this is not only totally fine but most likely a core requirement.</p><p>But I do have my pet peeve with <span>JS</span> for plain websites and blogs. Currently there is still such a strong draught in the static site generator world, telling us all our sites should be some kind of React or other frontend framework based project (looking at you, Gatsby, Next, Nuxt, VuePress, …). That you need to have that plentyful of code running in the browser of your visitors to have a smooth and <em>feels like a native app</em> user experience. That a site should be a <em>Single Page Application (SPA).</em> I can tell you, a plain HTML+CSS website does it really well, too. Surprise!</p><p>While on one hand the browser vendors add more and more <a href="https://developer.mozilla.org/en-US/docs/Web/API">Web APIs</a>, we also got a lot of improvement in the HTML and CSS area. Usually there is no big hype train around them, unless you are very enthusiastic and live in that niche.</p><p>Take a look at <a href="https://caniuse.com/">caniuse.com</a> to get an idea what is possible today and what might come tomorrow. <em>Did you know that HTML5 is still iterated on and we're moving towards <a href="https://www.w3.org/TR/html53/">version 5.3</a>?</em> On the other hand »HTML 5« is also used as an umbrella term for a <a href="https://spec.whatwg.org/" title="WHATWG Standards">wide variety of standards</a>. Also for CSS the story got very interesting: while CSS until 2.1 was a single specification, since CSS 3 there is a whole potpourri of recommendations and drafts. The <a href="https://wiki.csswg.org/spec">wiki of the CSS Working Group</a> might be a good starting point for further discovery.</p><p>But I want to give you some more practical examples and an experience report:</p><h2 id="sticky-navigation-bar">Sticky navigation bar</h2><p>This is something you can observe here on this blog:</p><video autoplay="" loop="" muted="" playsinline=""><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.hvec.mp4" type="video/mp4; codecs=hvc1"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.hvec.mp4" type="video/mp4; codecs=hevc"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.h264.mp4" type="video/mp4; codecs=avc1"><source src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/pos-sticky.webm" type="video/webm; codecs=vp9"></video><p>The key ingredient is the CSS <code>position: sticky</code> <a href="https://caniuse.com/css-sticky">🛈</a>. Even though most of them are labeled as <em>partial support,</em> this property value can be used in most scenarios except in some table related cases. If you want a sticky menu after scrolling and use only elements like <code>div</code> everything is just fine. I could throw away all the code for that after I realized that none of the common and modern browsers had any blocking issues. So I did. The only real latecomers were the web view components, no big deal for me here.</p><h3 id="before">Before</h3><h4 id="javascript">JavaScript</h4><pre><code><span>const </span><span>navbar </span><span>= </span><span>document</span><span>.querySelector(</span><span>'.navbar'</span><span>);
</span><span>let </span><span>sticky </span><span>= </span><span>navbar.offsetTop;
</span><span>const </span><span>navbarScroll </span><span>= </span><span>() </span><span>=&gt; </span><span>{
  </span><span>if </span><span>(</span><span>window</span><span>.pageYOffset </span><span>&gt;= </span><span>sticky) {
    navbar.classList.add(</span><span>'sticky'</span><span>)
  } </span><span>else </span><span>{
    navbar.classList.remove(</span><span>'sticky'</span><span>);
  }
};

</span><span>window</span><span>.onscroll </span><span>= </span><span>navbarScroll;
</span></code></pre><h4 id="stylesheet">Stylesheet</h4><pre><code><span>.navbar </span><span>{
  </span><span>position</span><span>: </span><span>relative</span><span>;
}
</span><span>.sticky </span><span>{
  </span><span>position</span><span>: </span><span>fixed</span><span>;
  </span><span>top</span><span>: </span><span>0</span><span>;
  </span><span>left</span><span>: </span><span>0</span><span>;
}
</span></code></pre><h3 id="after">After</h3><h4 id="javascript-1">JavaScript</h4><pre><code><span>// nope
</span></code></pre><h4 id="stylesheet-1">Stylesheet</h4><pre><code><span>.navbar </span><span>{
  </span><span>position</span><span>: </span><span>sticky</span><span>;
  </span><span>top</span><span>: </span><span>0</span><span>; </span><span>/* it does not reposition right away,
             but determines at which point it sticks */
</span><span>}
</span></code></pre><h3 id="resolution">Resolution</h3><p>The workaround with <span>JS</span> is no more. Yay!</p><p>Also notice how little code is actually needed now? Two CSS properties and the job is done.</p><hr><h2 id="service-workers">Service Workers</h2><p>Also in 2018 I played with <a href="https://markentier.tech/posts/2018/04/progressive-web-app/">Progressive Web Apps (PWA)</a>. The whole blog was one. A few days ago I teared down all of it. At the core of PWAs sit <a href="https://serviceworke.rs/">Service Workers (SW)</a>, though you can use SW also without building an app. And that's what I was aiming for, but in the end my home-grown dynamic cache solution was more annoying to me than helpful for anyone else. Every time I updated anything here, I had to wait and/or force refresh to see the result. I'm sure some people probably see visual inconsistencies due to a still running service worker in their browser. If you do, try to force clear all data for this website.</p><p>Long story short: if you do not build a web <strong>app</strong>, you most likely do not need service workers. So yet another thing down from the <span>JS</span> list.</p><p>No <em>before/after</em> comparison here, but several precious kilobytes of JavaScript shaved off by removing them.</p><hr><h2 id="sqip-svg-lqip">SQIP (SVG LQIP)</h2><p><em>Woa, what are all these random acronyms here?</em> Don't worry, the simple answer is:</p><p>If you have images and they are not very small in file size, you maybe want to provide a temporary placeholder with very low resolution and quality. This is pretty useful for slow internet connections; living here in Germany I know how difficult this situation can be. That thing called internet is still very Neuland to us. 🤦</p><p>Anyway, <code>SQIP</code> can be translated with »<code>SVG</code>-based <code>LQIP</code>.«</p><p><code>SVG</code> are Scalable Vector Graphics, an image format I really love a lot, my logo is done with it (<a href="https://markentier.tech/posts/2018/05/minimalism-focus-clean-redesign/">I wrote about it a while ago</a>).</p><p>LQIP finally stands for <em>»Low Quality Image Placeholders«</em> and is based on an algorithm to find primitive shapes to describe the source image. Basically try to find only a few triangles, rectangles, circles, ellipsis, and other low poly shapes. It is also an art form in its own, you can enjoy some <a href="https://github.com/fogleman/primitive#static-animation">nice examples there</a>. The advantage of SVG is that it is made to encode such figures in very few characters of human readable text, so a less complex image for a placeholder can be written in one kilobyte or less.</p><p>Compared to the original high resolution image which can easily weigh half a megabyte and more this is great. You can reserve the space in your page and very early in the loading process display some visual hint that there will be a proper picture soon. Especially for types which do not support progessive loading (as JPEG can) using SQIP/LQIP placeholders makes a lot of sense.</p><p>In this scenario at first it was not really about saving frontend <span>JS</span>, more about saving it on the backend site and replacing it with something else. Unfortunately in between some code creeped into the frontend anyway.</p><p>But what happened that this beautiful technique fell out of favor with me?</p><h3 id="picture"><code>&lt;picture&gt;</code></h3><p>Enter another interesting HTML tag combo: <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture"><code>&lt;picture&gt;</code></a> with <code>&lt;source&gt;</code>.</p><p>So one reason to use small low quality placeholders is because before such tags became a thing we solely relied on a single <code>&lt;img&gt;</code> and some trickery with CSS (and sometimes aided by sprinkles of JavaScript). I tried to avoid <span>JS</span> completely, but of course I had to use some styling hacks eventually.</p><p>The essence of it was some style attached to the image in question:</p><pre><code><span>&lt;</span><span>img </span><span>src</span><span>=</span><span>"highres-and-heavy.png"
     </span><span>style</span><span>=</span><span>"</span><span>background-size</span><span>: </span><span>cover</span><span>;
            </span><span>background-image</span><span>: </span><span>url</span><span>(</span><span>'data:image/svg+xml;base64,PHN2…'</span><span>);</span><span>"</span><span>&gt;
</span><span>&lt;!-- Usually in some post processing all style attributes were collected
     into a &lt;style&gt; tag or CSS file. --&gt;
</span></code></pre><p>The JavaScript entered this scenery at one point: after I used images with transparency. Sadly with this background image workaround you would've seen the low quality placeholder through the transparent parts, and this was extremly ugly to be honest. I could not stand it and deployed some snippet to trigger a background removal once the actual image was loaded:</p><pre><code><span>// remove the background image styling, so transparent images won't have
// strange SQIP artefacts shining through
</span><span>document</span><span>.querySelectorAll(
  </span><span>"img[loading=lazy][class]:not(.thumbnail):not(.loaded)"
</span><span>).forEach((</span><span>img</span><span>) </span><span>=&gt; </span><span>{
  </span><span>img</span><span>.</span><span>onload </span><span>= </span><span>(</span><span>_event</span><span>) </span><span>=&gt; </span><span>img.className </span><span>= </span><span>"loaded"</span><span>;
});
</span><span>document</span><span>.querySelectorAll(
  </span><span>"img[loading=lazy].thumbnail:not(.loaded)"
</span><span>).forEach((</span><span>img</span><span>) </span><span>=&gt; </span><span>{
  </span><span>img</span><span>.</span><span>onload </span><span>= </span><span>(</span><span>_event</span><span>) </span><span>=&gt; </span><span>img.className </span><span>= </span><span>"thumbnail loaded"</span><span>;
});
</span></code></pre><p>Theoretically it would have been tolerable, but I noticed some strange behaviour once I started wrapping my images into <code>picture</code> tags.</p><p>Let's <a href="https://en.wiktionary.org/wiki/yak_shaving">shave the yak</a> a bit further to understand why.</p><h4 id="webp-and-avif">WEBP and AVIF</h4><p><em>Come on, more acronyms?</em> I'm sorry, the web is a place with a lot of them.</p><p>All you need to know for now is that both of them are pretty modern image formats with quite good (lossy) compression rates while keeping a respectable quality. <a href="https://caniuse.com/webp"><code>WEBP</code></a> has been around for some time and most of the browsers do support it. <a href="https://caniuse.com/avif"><code>AVIF</code></a> is extremly new and right now only Chrome since version 85 and Opera 71 can display them. Firefox has a configuration flag, maybe they will enable it by default pretty soon.</p><p>So the current situation is that I have my original image (PNG or JPEG in most cases), a WEBP version, an AVIF version, and the SQIP placeholder. How do I deal with it? Back to our <code>&lt;picture&gt;</code> tag:</p><pre><code><span>&lt;</span><span>picture</span><span>&gt;
  &lt;</span><span>source </span><span>srcset</span><span>=</span><span>"./cover.avif" </span><span>type</span><span>=</span><span>"image/avif"</span><span>&gt;
  &lt;</span><span>source </span><span>srcset</span><span>=</span><span>"./cover.webp" </span><span>type</span><span>=</span><span>"image/webp"</span><span>&gt;
  &lt;</span><span>img </span><span>src</span><span>=</span><span>"./cover.png"
       </span><span>style</span><span>=</span><span>"</span><span>/* SQIP data: see example above */</span><span>"</span><span>&gt;
&lt;/</span><span>picture</span><span>&gt;
</span></code></pre><p>You can also use source sets for different view sizes based on media queries, but in my case I'm mainly concerned about supporting different image formats. My idea is to prioritize the formats with the smallest file size first, and given the compression ratios the order is usually: AVIF, WEBP, PNG/JPG. Not in every case will this be true; WEBP does not always have better savings then a decently compressed JPEG for example. AVIF has not disappointed so far, but sadly a part of my visitors will not see the effect yet.</p><p>What did not really happen anymore was a display of the placeholder before the final image was loaded. I experimented for quite some time until I realized that I do not want to spent more energy any further.</p><p><picture><source srcset="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.avif" type="image/avif"><source srcset="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.webp" type="image/webp"><img src="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/sizes-png-webp-avif.w.png" alt="Size comparison of an example image; PNG original (22 KB), WEBP (14 KB, 37% saved), AVIF (7.3 KB, 67% saved)" width="1024" height="120" loading="lazy"></picture></p><p>I made a <em>risk-return tradeoff</em> compromise and got rid of SQIP altogether. For the growing number of AVIF support the images are sometimes significantly smaller which makes it acceptable to allow for some display delay anyway.</p><p>In the following screenshot the JPEG was the source photo. The PNG was created for some transparency stuff; of course, for photos this format does not really make a lot of sense in general. Sadly also WEBP fails to compete in this scenario. That's why I have to make this picture group generation a bit smarter soon to reorder based on the actual file …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/">https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/</a></em></p>]]>
            </description>
            <link>https://markentier.tech/posts/2020/10/wrote-javascript-to-avoid-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023594</guid>
            <pubDate>Sun, 08 Nov 2020 06:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack Videos Horizontally, Vertically, in a Grid With FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25022665">thread link</a>) | @rrao84
<br/>
November 7, 2020 | https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<amp-img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" alt="stack videos using ffmpeg" title="stacking-videos" width="678" height="381" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" alt="stack videos using ffmpeg" title="stacking-videos" width="678" height="381" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM4MScgd2lkdGg9JzY3OCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img>
</figure>


<p>Often times, when you want to compare two videos side-by-side or you want to create an effect during post-processing, you might want to stack videos together. It can get expensive if you end up buying a tool to do this, but, guess what? </p>



<p><strong>FFmpeg offers a variety of tools to help stack videos together – horizontally, vertically, or in a grid fashion. In this tutorial, let’s learn about FFmpeg’s <code>hstack</code> and <code>vstack</code> filters for stacking videos. </strong></p>



<hr data-amp-original-style="height:50px">




<h2><span id="How_to_Stack_Videos_Horizontally_using_FFmpeg"></span><strong>How to Stack Videos Horizontally using FFmpeg?</strong><span></span></h2>



<p>“Horizontally stacking videos” refers to placing videos side-by-side (one on the left and the other on the right). </p>



<p>Before you do this, there are a couple of points that you need to consider. </p>



<ol><li>The videos that you want to stack need to have the same height. </li><li> The videos need to have the same pixel format. </li></ol>



<p>The command line is shown below where we try and stack two <code>mp4</code> videos. </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex hstack=inputs=2 horizontal-stacked-output.mp4</code></pre>



<p>The <code>hstack</code> filter has a simple format. You need to specify the number of inputs and it parses that from the beginning portion of the commandline. The order of stacking follows the order of inputs. </p>



<p>Here is a screenshot of what it looks like. </p>



<figure><amp-img src="https://lh6.googleusercontent.com/4FwbqByqDpDpOGTNvpSWSOh6RVE9yzesrQyAyGvaOF1ZjVsycKOlQUjrTmdJRFJWblHjC9gF6zMds0s5w2Yy2w6CVXXme-H-zF8nYoJ496khN0aHXHaWbnwEe41BYmu6c2mdoQb8" alt="stack videos using ffmpeg" width="1600" height="423" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://lh6.googleusercontent.com/4FwbqByqDpDpOGTNvpSWSOh6RVE9yzesrQyAyGvaOF1ZjVsycKOlQUjrTmdJRFJWblHjC9gF6zMds0s5w2Yy2w6CVXXme-H-zF8nYoJ496khN0aHXHaWbnwEe41BYmu6c2mdoQb8" alt="stack videos using ffmpeg" width="1600" height="423" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQyMycgd2lkdGg9JzE2MDAnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>And, here is a video! </p>











<p>Here is another use case. Companies or teams working on video compression often like to compare videos side-by-side in the lab or showcase their work in conferences. FFmpeg’s horizontal stacking is an easy way to do this and achieve a very good result. </p>



<p>Below are two videos encoded at different video quality settings and stacked horizontally. Comparison made simple, right? <em>(note: Vimeo’s choise of bitrate might mess with the comparison, but, when done offline (downloaded), the <code>hstack</code> filter makes comparisons easy!)</em></p>







<hr data-amp-original-style="height:50px">



<h2><span id="Stacking_Videos_Vertically_using_FFmpeg"></span><strong>Stacking Videos Vertically using FFmpeg</strong><span></span></h2>



<p>“Vertically stacked videos” results in placing videos one below the other. Unlike in horizontal stacking, inputs need to be having the same width. The command is as shown.&nbsp;</p>



<p>For vertical stacking, we need to use the <code>vstack</code> filter whose syntax is similar to the <code>hstack</code> filter we used in the previous horizontal stacking example.</p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex vstack=inputs=2 vertical-stack-output.mp4</code></pre>



<figure><amp-img src="https://lh5.googleusercontent.com/qtyxioWFR54pqwZhX7jgX6HkSG7gCw840GdK78HGHHP7X3sv3fr3Pou9hOMFu2O-e6O7nmCith3U6CM1SpDanhwmIFIBzZUQyaG4T0BJaF9QCdMIPrmMmH0qc9WTK5f-5Nf4-92y" alt="stack videos using ffmpeg" width="1248" height="1400" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://lh5.googleusercontent.com/qtyxioWFR54pqwZhX7jgX6HkSG7gCw840GdK78HGHHP7X3sv3fr3Pou9hOMFu2O-e6O7nmCith3U6CM1SpDanhwmIFIBzZUQyaG4T0BJaF9QCdMIPrmMmH0qc9WTK5f-5Nf4-92y" alt="stack videos using ffmpeg" width="1248" height="1400" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzE0MDAnIHdpZHRoPScxMjQ4JyB4bWxucz0naHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmcnIHZlcnNpb249JzEuMScvPg=="></amp-img></figure>



<p>Both functions pretty much use the same commands with a simple distinction, the <a href="https://ffmpeg.org/ffmpeg-filters.html#hstack" target="_blank" rel="noopener"><code>hstack</code></a> and the <a href="https://ffmpeg.org/ffmpeg-filters.html#vstack" target="_blank" rel="noopener"><code>vstack</code></a> under the <code>-filter_complex</code> argument.&nbsp;</p>



<p>Here’s a video of stacking two videos vertically using FFmpeg. </p>







<hr data-amp-original-style="height:50px">



<h2><span id="Stacking_Videos_of_Different_Lengths"></span><strong>Stacking Videos of Different Lengths</strong><span></span></h2>



<p>Well, there’s a really nifty ability for both of these to prioritize the length of the shortest video. And as luck would have it the parameter is named <code>shortest</code>, and it’s applicable to both the horizontal and vertical stacking filters. Using <code>shortest=1</code> ensures the shortest length is used. </p>



<p>For example – </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4 -filter_complex hstack=inputs=2:shortest=1 shortest-output.mp4</code></pre>



<p>As a <b>side note</b>, if you run into an error that claims frames are being duplicated, the easiest workaround is to slip the <code>vsync 2</code> parameter into your command, and it worked like a charm.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_Without_the_shortest_parameter"></span>Stacking Videos of Different Lengths Without the <code>shortest</code> parameter<span></span></h3>



<p>To test what happens in this situation, let’s stack two videos vertically – a 10 second clip and an 18 second clip. You’ll see that the shorter clip just stops after it completes, but the output video continues till the longest of the input clips complete.  </p>















<p>If you want to truncate the clips to the length of the shortest clip, then you need to use the <code>shortest=1</code> parameter. Let’s look at that in the next section.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_With_the_shortest=1_parameter"></span>Stacking Videos of Different Lengths With the <code>shortest=1</code> parameter<span></span></h3>



<p>In this example, we use the <code>shortest=1</code> command-line parameter and as you can see, the length of the final video is truncated to the length of the shortest of the inputs. </p>







<hr data-amp-original-style="height:50px">



<h2><span id="2%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong><strong>2×2 Grid of Videos using FFmpeg</strong></strong><span></span></h2>



<p>We can achieve a 2×2 grid of videos using a combination of the <code>hstack</code> and <code>vstack</code> filters. Let’s start by looking at the command-line and then break it down. It’s actually pretty simple! </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 -i input2.mp4 -i input3.mp4 \
-filter_complex \
"[0:v][1:v]hstack=inputs=2[top]; \
[2:v][3:v]hstack=inputs=2[bottom]; \
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p>What’s happening here?</p>



<ul><li>firstly, you need to provide 4 input videos with the same height and width</li><li>next, you stack the first two videos horizontally and call it “top” i.e. <code>[0:v][1:v]hstack=inputs=2[top]</code></li><li>then, you you stack the next two videos horizontally and call it “bottom” i.e. <code>[2:v][3:v]hstack=inputs=2[bottom]</code></li><li>then, you stack <code>top</code> and <code>bottom</code> vertically to create a 2×2 grid. — <code>[top][bottom]vstack=inputs=2[v]</code></li><li>then using the <code>map</code> command, we can extract and push the video track to the output container. </li></ul>



<p>Here is what the video looks like. </p>







<hr data-amp-original-style="height:50px">



<h2><span id="3%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong>3×2 Grid of Videos using FFmpeg</strong><span></span></h2>



<p>Along the same lines, here is a 3×2 grid of videos using <code>hstack</code> and <code>vstack</code> filters. </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 \
-i input2.mp4 -i input3.mp4 \
-i input4.mp4 -i input5.mp4 \
-filter_complex \
"[0:v][1:v][2:v]hstack=inputs=3[top];\
[3:v][4:v][5:v]hstack=inputs=3[bottom];\
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>







<hr data-amp-original-style="height:50px">



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>That’s it folks. Now you know how to stack videos together horizontally, vertically, and in a grid. This is very useful in comparing videos and also creating fun effects along the way! </p>



<p data-amp-original-style="background-color:#f8da89">If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about this amazing media editing and compression software!  </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022665</guid>
            <pubDate>Sun, 08 Nov 2020 03:36:37 GMT</pubDate>
        </item>
    </channel>
</rss>
