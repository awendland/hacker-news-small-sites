<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 21 Oct 2020 08:31:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 21 Oct 2020 08:31:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Discord Desktop App RCE]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24822755">thread link</a>) | @Wingy
<br/>
October 18, 2020 | https://mksben.l0.cm/2020/10/discord-desktop-rce.html | <a href="https://web.archive.org/web/*/https://mksben.l0.cm/2020/10/discord-desktop-rce.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6054437144226106686" itemprop="description articleBody">
<p>A few months ago, I discovered a remote code execution issue in the <a href="https://discord.com/">Discord</a> desktop application and I reported it via their <a href="https://discord.com/security">Bug Bounty Program</a>.</p><p>The RCE I found was an interesting one because it is achieved by combining multiple bugs. In this article, I'd like to share the details.</p><h3>Why I chose Discord for the target</h3><p>I kind of felt like finding for vulnerabilities of the Electron app, so I was looking for a bug bounty program which pays the bounty for an Electron app and I found Discord. Also, I am a Discord user and simply wanted to check if the app I'm using is secure, so I decided to investigate.</p><h3>Bugs I found</h3><p>Basically I found the following three bugs and achieved RCE&nbsp;by combining them.</p><ol><li>Missing contextIsolation</li><li>XSS in iframe embeds</li><li>Navigation restriction bypass (CVE-2020-15174)</li></ol><p>I'll explain these bugs one by one.</p><h3>Missing contextIsolation</h3><p>When I test Electron app, first I always check the options of the <a href="https://www.electronjs.org/docs/api/browser-window">BrowserWindow API</a>, which is used to create a browser window. By checking it, I think about how RCE can be achieved when arbitrary JavaScript execution on the renderer is possible.</p><p>The Discord's Electron app is not an open source project but the Electron's JavaScript code is saved locally with the asar format and I was able to read it just by extracting it.</p><p>In the main window, the following options are used:&nbsp;</p><blockquote>const mainWindowOptions = {<br>&nbsp;&nbsp;title: 'Discord',<br>&nbsp;&nbsp;backgroundColor: getBackgroundColor(),<br>&nbsp;&nbsp;width: DEFAULT_WIDTH,<br>&nbsp;&nbsp;height: DEFAULT_HEIGHT,<br>&nbsp;&nbsp;minWidth: MIN_WIDTH,<br>&nbsp;&nbsp;minHeight: MIN_HEIGHT,<br>&nbsp;&nbsp;transparent: false,<br>&nbsp;&nbsp;frame: false,<br>&nbsp;&nbsp;resizable: true,<br>&nbsp;&nbsp;show: isVisible,<br>&nbsp;&nbsp;webPreferences: {<br>&nbsp;&nbsp;&nbsp;&nbsp;blinkFeatures: 'EnumerateDevices,AudioOutputDevices',<br>&nbsp;&nbsp;&nbsp;&nbsp;<span><b>nodeIntegration: false</b></span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;preload: _path2.default.join(__dirname, 'mainScreenPreload.js'),<br>&nbsp;&nbsp;&nbsp;&nbsp;nativeWindowOpen: true,<br>&nbsp;&nbsp;&nbsp;&nbsp;enableRemoteModule: false,<br>&nbsp;&nbsp;&nbsp;&nbsp;spellcheck: true<br>&nbsp;&nbsp;}<br>};</blockquote><p>The important options which we should check here are especially <i>nodeIntegration</i> and <i>contextIsolation</i>. From the above code, I found that the <i>nodeIntegration</i> option is set to false and the <i>contextIsolation</i> option is set to false (the default of the used version) in the Discord's main window.</p><p>If the nodeIntegration is set to true, a web page's JavaScript can use Node.js features easily just by calling the <code>require()</code>. For example, the way to execute the calc application on Windows is:</p><blockquote>&lt;script&gt;<br>&nbsp; require('child_process').exec('calc');<br>&lt;/script&gt;</blockquote><p>In this time, the <i>nodeIntegration</i> was set to false, so I couldn't use Node.js features by calling the <code>require()</code> directly.</p><p>However, there is still a possibility of access to Node.js features. The <i>contextIsolation</i>, another important option, was set to false. This option should not be set to false if you want to eliminate the possibility of RCE on your app.</p><p>If the <i>contextIsolation</i> is disabled, a web page's JavaScript can affect the execution of the <a href="https://github.com/electron/electron/tree/83bb065b4f6ed512d545c46389a7fdc114c94a54/lib/renderer">Electron's internal JavaScript code on the renderer</a>, and preload scripts (In the following, these JavaScript will be referred to as the JavaScript code outside web pages).&nbsp;For example, if you override&nbsp; <code>Array.prototype.join</code>, one of the JavaScript built-in methods, with another function from a web page's JavaScript, the JavaScript code outside web pages also will use the overridden function when the <code>join</code> is called.</p><p>This behavior is dangerous because Electron allows the JavaScript code outside web pages to use the Node.js features regardless the <i>nodeIntegration</i> option and by interfering with them from the function overridden in the web page, it could be possible to achieve RCE even if the <i>nodeIntegration</i> is set to false.</p><p>By the way, a such trick was previously not known. It was first discovered in a pentest by Cure53, which I also joined in, in 2016. After that, we reported it to Electron team and the <i>contextIsolation</i> was introduced.</p><p>Recently, that pentest report was published. If you are interested, you can read it from the following link:</p><p>Pentest-Report Ethereum Mist 11.2016 - 10.2017<br><a href="https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view">https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view</a></p><p>You can also read the slides which I used at a CureCon event:</p><p>The <i>contextIsolation</i> introduces the separated contexts between the web page and the JavaScript code outside web pages so that the JavaScript execution of each code does not affect each. This is a necessary faeture to eliminate the possibility of RCE, but this time it was disabled in Discord.</p><p>Now I found that the <i>contextIsolation</i> is disabled, so I started looking for a place where I could execute arbitrary code by interfering with the JavaScript code outside web pages.</p><p>Usually, when I create a PoC for RCE in the Electron's pentests, I first try to achieve RCE by using the Electron's internal JavaScript code on the renderer. This is because the Electron's internal JavaScript code on the renderer can be executed in any Electron app, so basically I can reuse the same code to achieve RCE and it's easy.</p><p>In my slides, <a href="https://speakerdeck.com/masatokinugawa/electron-abusing-the-lack-of-context-isolation-curecon-en?slide=41">I introduced</a> that RCE can be achieved by using the code which Electron executes at the navigation timing. It's not only possible from that code but there are such code in some places. (I'd like to publish examples of the PoC in the future.)</p><p>However, depending on the version of Electron used, or the <i>BrowserWindow</i> option which is set, because the code has been changed or the affected code can't be reached correctly, sometimes PoC via the Electron's code does not work well. In this time, it did not work, so I decided to change the target to the preload scripts.</p><div><p>When checking the preload scripts, I found that Discord exposes the function, which allows some allowed modules to be called via <code>DiscordNative.nativeModules.requireModule('MODULE-NAME')</code>, into the web page.</p></div><p>Here, I couldn't use modules that can be used for RCE directly, such as <i>child_process</i> module, but I found a code where RCE can be achieved by overriding the JavaScript built-in methods and interfering with the execution of the exposed module.</p><p>The following is the PoC. I was able to confirm that the calc application is popped up when I call the <code>getGPUDriverVersions</code> function which is defined in the module called "<i>discord_utils</i>" from devTools, while overriding the <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>.</p><blockquote>RegExp.prototype.test=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return false;<br>}<br>Array.prototype.join=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return "calc";<br>}<br>DiscordNative.nativeModules.requireModule('discord_utils').getGPUDriverVersions();</blockquote><p>The <code>getGPUDriverVersions</code> function tries to execute the program by using the "<i>execa</i>" library, like the following:</p><blockquote>module.exports.getGPUDriverVersions = async () =&gt; {<br>&nbsp;&nbsp;if (process.platform !== 'win32') {<br>&nbsp;&nbsp;&nbsp;&nbsp;return {};<br>&nbsp;&nbsp;}<p>&nbsp;&nbsp;const result = {};<br>&nbsp;&nbsp;const nvidiaSmiPath = `${process.env['ProgramW6432']}/NVIDIA Corporation/NVSMI/nvidia-smi.exe`;</p><p>&nbsp;&nbsp;try {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = parseNvidiaSmiOutput(await execa(nvidiaSmiPath, []));<br>&nbsp;&nbsp;} catch (e) {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = {error: e.toString()};<br>&nbsp;&nbsp;}</p><p>&nbsp;&nbsp;return result;<br>};</p></blockquote><p>Usually the <i>execa</i> tries to execute "<i>nvidia-smi.exe</i>", which is specified in the <code>nvidiaSmiPath</code> variable, however, due to the overridden <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>, the argument is replaced to "<i>calc</i>" in the <i>execa</i>'s internal processing.</p><p>Specifically, the argument is replaced by changing the following two parts.</p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36</a></p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55</a></p><p>The remaining work is to find a way to execute JavaScript on the application. If I can find it, it leads to actual RCE.</p><h3>XSS in iframe embeds</h3><p>As explained above, I found that RCE could happen from arbitrary JavaScript execution, so I was trying to find an XSS vulnerability. The app supports the autolink or Markdown feature, but looked like it is good. So I turned my attention to the iframe embeds feature. The iframe embeds is the feature which automatically displays the video player on the chat when the YouTube URL is posted, for example.</p><p>When the URL is posted, Discord tries to get the <a href="https://ogp.me/">OGP</a> information of that URL and if there is the OGP information, it displays the page's title, description, thumbnail image, associated video and so on in the chat.</p><p>The Discord extracts the video URL from the OGP and only if the video URL is allowed domain and the URL has actually the URL format of the embeds page, the URL is embedded in the iframe.</p><p>I couldn't find the documentation about which services can be embedded in the iframe, so I tried to get a hint by checking the CSP's <i>frame-src</i> directive. At that time, the following CSP was used:</p><blockquote>Content-Security-Policy: [...] ; frame-src https://*.youtube.com https://*.twitch.tv https://open.spotify.com https://w.soundcloud.com https://sketchfab.com https://player.vimeo.com https://www.funimation.com https://twitter.com https://www.google.com/recaptcha/ https://recaptcha.net/recaptcha/ https://js.stripe.com https://assets.braintreegateway.com https://checkout.paypal.com https://*.watchanimeattheoffice.com</blockquote><p>Obviously, some of them are listed to allow iframe embeds (e.g. YouTube, Twitch, Spotify).&nbsp;I tried to check if the URL can be embeded in the iframe by specifying the domain into the OGP information one by one and tried to find XSS on the embedded domains. After some attempts, I found that the&nbsp;<a href="https://sketchfab.com/">sketchfab.com</a>, which is one of the domains listed in the CSP, can be embedded in the iframe and found XSS on the embeds page.&nbsp;I didn't know about Sketchfab at that time, but it seems that it is a platform in which users can publish, buy and sell 3D models. There was a simple DOM-based XSS in the footnote of the 3D model.</p><p>The following is the PoC, which has the crafted OGP. When I posted this URL to the chat, the Sketchfab was embedded into the iframe on the chat, and after a few clicks on the iframe, arbitrary JavaScript was executed.</p><p><a href="https://l0.cm/discord_rce_og.html">https://l0.cm/discord_rce_og.html</a></p><blockquote>&lt;head&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta charset="utf-8"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="og:title" content="RCE DEMO"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;[...]<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="<span><b>og:video:url</b></span>" content="https://<span><b>sketchfab.com</b></span>/models/2b198209466d43328169d2d14a4392bb/embed"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta ‚Ä¶</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mksben.l0.cm/2020/10/discord-desktop-rce.html">https://mksben.l0.cm/2020/10/discord-desktop-rce.html</a></em></p>]]>
            </description>
            <link>https://mksben.l0.cm/2020/10/discord-desktop-rce.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822755</guid>
            <pubDate>Mon, 19 Oct 2020 02:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gravity is not a force ‚Äì free-fall parabolas are straight lines in spacetime]]>
            </title>
            <description>
<![CDATA[
Score 641 | Comments 334 (<a href="https://news.ycombinator.com/item?id=24821141">thread link</a>) | @tim_hutton
<br/>
October 18, 2020 | https://timhutton.github.io/GravityIsNotAForce/ | <a href="https://web.archive.org/web/*/https://timhutton.github.io/GravityIsNotAForce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>For full functionality of this site it is necessary to enable JavaScript.
    Here are the <a href="http://www.enable-javascript.com/" target="_blank">
    instructions how to enable JavaScript in your web browser</a>.
    </p>



    <p>
    <canvas id="canvas" width="1360" height="480">(Canvas drawing not supported by your browser.)</canvas>
    </p><p>
      Change the frame acceleration: 
    </p>
    <p>
      Move the time window: 
    </p>
    

    <h4>Description:</h4>
    <p>
    Under general relativity, gravity is not a force. Instead it is a distortion of spacetime. Objects in free-fall move along geodesics (straight lines) in spacetime, as seen in the inertial frame of reference on the right. When standing on Earth we experience a frame of reference that is accelerating upwards, causing objects in free-fall to move along parabolas, as seen on the left.
    </p>

    <p>
    In this system there is only one space dimension, shown on the vertical axis and labeled in meters. The time dimension is the horizontal axis and labeled in seconds. The gravitational field is constant within the area of interest. 
    </p>

    <p>
    Use the first slider to change the acceleration of the frame of reference in the middle. When the frame has zero acceleration it is said to be an inertial frame of reference.
    </p>

    <p>
    Use the second slider to move the time window. Note that all the trajectories remain as straight lines in the inertial frame of reference.
    </p>

    <p>
    You can drag the start and end position of each object to change their trajectories. All free-fall trajectories in the inertial frame of reference are straight lines.
    </p>

    <p>
    Code, more details, feedback: <a href="https://github.com/timhutton/GravityIsNotAForce">https://github.com/timhutton/GravityIsNotAForce</a>
    </p>

    <p>
    More on these concepts: <a href="https://youtu.be/XRr1kaXKBsU">https://youtu.be/XRr1kaXKBsU</a>
    </p>





</div>]]>
            </description>
            <link>https://timhutton.github.io/GravityIsNotAForce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24821141</guid>
            <pubDate>Sun, 18 Oct 2020 21:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The local timeline is the key to enjoying Mastodon]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 93 (<a href="https://news.ycombinator.com/item?id=24819387">thread link</a>) | @carlesfe
<br/>
October 18, 2020 | https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html | <a href="https://web.archive.org/web/*/https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="divbodyholder">

<div id="divbody"><div>
<!-- entry begin -->
<h3><a href="https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">
You may be using Mastodon wrong
</a></h3>
<!-- bashblog_timestamp: #202010181913.37# -->
<p>October 18, 2020 ‚Äî 
Carlos Fenollosa
</p>
<!-- text begin -->

<p>I'm sure you have already heard about <a href="https://joinmastodon.org/">Mastodon</a>,
typically marketed as <em>a Twitter alternative</em>.</p>

<p>I will try to convince you that the word <em>alternative</em> doesn't mean here what you think it means,
and why you may be using Mastodon wrong if you find it boring.</p>

<h4>An alternative community</h4>

<p>You should not expect to "migrate from Twitter to Mastodon."</p>

<p>Forget about the privacy angle for now. Mastodon is an alternative community, where people behave
differently.</p>

<p><strong>It's your chance to make new internet friends.</strong></p>

<p>There may be some people for whom Mastodon is a safe haven. Yes, some users really do migrate
there to avoid censorship or bullying but, for most of us, that will not be the case.</p>

<p>Let's put it this way: Mastodon is to Twitter what Linux is to Windows.</p>

<p>Linux is libre software. But that's not why most people use it. Linux users mostly want 
to get their work done, and Linux is an excellent platform.
There is no Microsoft Word, no Adobe Photoshop, no Starcraft. If you need to use these tools, honestly,
you'd better stick with Windows. You can use emulation, in the same way that there are
utilities to post to Twitter from Mastodon, but that would miss the point.</p>

<p>The bottom line is, you can perform the same tasks, but the process will be different.
You can post <em>toots</em> on Mastodon, upload gifs, send DMs... but it's not Twitter, and that is fine.</p>

<h4>The Local Timeline is Mastodon's greatest invention</h4>

<p>The problem most people have with Mastodon is that they "get bored" with it quickly. I've seen it a lot, and
it means one thing: <strong>the person created their account on the wrong server</strong>.</p>

<p>"But," they say, "isn't Mastodon federated? Can't I chat with everybody, regardless of their server?"
Yes, of course. But discoverability works differently on Mastodon.</p>

<p>Twitter has only two discoverability layers: your network and the whole world. Either a small group of
contacts, or everybody in the whole world. That's crazy.</p>

<p>They try very hard to show you tweets from outside your network so you can discover new people.
And, at the same time, they show your tweets to third parties, so you can get new followers.
This is the way that
they try to keep you engaged once your network is more or less stable and starts getting stale.</p>

<p>Mastodon, instead, has an extra layer between your network and the whole world:
messages from <em>people on your server</em>. This is called the <em>local timeline</em>.</p>

<p><strong>The local timeline is the key to enjoying Mastodon.</strong></p>

<h4>How long it's been since you made a new internet friend?</h4>

<p>If you're of a certain age you may remember BBSs, Usenet, the IRC, or early internet forums.
Do you recall how exciting it was to log into the unknown and realize that there were people
all around the world who shared your interests?</p>

<p>It was an amazing feeling which got lost on the modern internet. Now you have a chance to relive it.</p>

<p>The local timeline dynamics are very different. There is a lot of respectful interactions among total strangers,
because there is this feeling of community, of being in a neighborhood. Twitter is just the opposite, strangers
shouting at each other.</p>

<p>Furthermore, since the local timeline is more or less limited in the amount of users, you have the chance
to recognize usernames, and being recognized. You start interacting with strangers, mentioning them, sending them
links they may like. You discover new websites, rabbit holes, new approaches to your hobbies.</p>

<p>I've made quite a few new <em>internet friends</em> on my Mastodon server, and I don't mean followers or contacts.
I'm talking about human beings who I have never met in person but feel close to.</p>

<p>People are humble and respectful. And, for less nice users, admins enforce codes of conduct and, 
on extreme cases, users may get kicked off a server. But they are not being banned by a faceless corporation
due to mass reports, everybody is given a chance.</p>

<h4>How to choose the right server</h4>

<p>The problem with "generalist" Mastodon servers like <a href="https://mastodon.social/">mastodon.social</a>
is that users have just too diverse interests and backgrounds.
Therefore, there is no community feeling. For some people, that may be exactly what they're looking for. But, 
for most of us, there is more value on the smaller servers.</p>

<p>So, how can you choose the right server? Fortunately, you can do a bit of research. 
There is an official <a href="https://joinmastodon.org/communities">directory of Mastodon servers</a> categorized by
interests and regions. </p>

<p>Since you're reading my blog, start by taking a look at these:</p>

<ul>
<li><a href="http://bsd.network/">bsd.network</a>, for fans of BSD systems</li>
<li><a href="http://linuxrocks.online/">linuxrocks.online</a>, for Linux fans</li>
<li><a href="http://fosstodon.org/">fosstodon.org</a>, for free software in general</li>
<li><a href="http://tilde.zone/">tilde.zone</a>, for oldschool internet users</li>
<li><a href="https://merveilles.town/">merveilles.town</a>, with a very particular mixture of art and technology</li>
<li><a href="https://metalhead.club/">metalhead.club</a>, to enjoy those classic riffs</li>
</ul>

<p>And the regionals</p>

<ul>
<li><a href="https://mastodont.cat/">mastodont.cat</a> for catalans</li>
<li><a href="https://mastodon.madrid/">mastodon.madrid</a> for madrile√±os</li>
</ul>

<p>There are many more. Simply search online for "mastodon server MY_FAVORITE_HOBBY." And believe me, servers
between 500 and 5,000 people are the best.</p>

<h4>Final tips</h4>

<p>Before clicking on "sign up", always browse the local timeline,
the about page, and the most active users list. You will get a pretty good idea of the kind of people
who chat there.
Once you feel right at home you can continue your adventure and start following users from other servers.</p>

<p>Mastodon has an option to only display toots in specific languages. It can be very useful to avoid being
flooded by toots that you just have no chance of understanding or even getting what they're about.</p>

<p>You can also filter your notifications by types: replies, mentions, favorites, reposts, and more.
This makes catching up much more manageable than on Twitter.</p>

<p>Finally, Mastodon has a built-in "Content Warning" feature. It allows you to hide
text behind a short explanation, in case you want to talk about sensible topics or just about spoiling
a recent movie.</p>

<p>Good luck with your search, and see you on the Fediverse! I'm at
<a href="https://mastodon.sdf.org/@cfenollosa">@cfenollosa@mastodon.sdf.org</a></p>

<p>Tags: <a href="https://cfenollosa.com/blog/tag_internet.html">internet</a></p>
<!-- text end -->
<p id="twitter"><a href="http://twitter.com/intent/tweet?url=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html&amp;text=%3CType%20your%20comment%20here%20but%20please%20leave%20the%20URL%20so%20that%20other%20people%20can%20follow%20the%20comments%3E&amp;via=cfenollosa">Comments? Tweet</a> 
<a href="https://twitter.com/search?q=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html"><span id="count-18287"></span></a>&nbsp;</p>
<!-- entry end -->
</div>

</div></div></div>]]>
            </description>
            <link>https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24819387</guid>
            <pubDate>Sun, 18 Oct 2020 17:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cursed Elixir]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24818706">thread link</a>) | @udfalkso
<br/>
October 18, 2020 | https://evuez.github.io/posts/cursed-elixir.html | <a href="https://web.archive.org/web/*/https://evuez.github.io/posts/cursed-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2020-08-12">2020-08-12</time>
      <p>Let's write some Elixir.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      bar(a, -1)
    else
      bar(a, 1)
    end
  end

  defp bar(a, b) do
    IO.inspect(a * b)
  end
end
</code></pre>
<p>Not very useful, but that's good enough for our purpose.</p>
<p>I like Elixir, but I think most of the time it just looks like functional Ruby. I want to make this code look like Elixir.</p>
<p>First, this code is lacking every Elixir developer's best friend: <code>|&gt;</code>. Let's add some <code>|&gt;</code>s.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Meh. It's definitely better, but I mean, that's only 3 <code>|&gt;</code>s. I want more <code>|&gt;</code>s.</p>
<p>We have an <code>if</code> in there, so maybe we can do something with it?</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    (a &lt; 0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>We sure can! That's one more <code>|&gt;</code>. Can we do better than this?</p>
<p>Well... <code>&gt;</code> and <code>*</code> are <code>Kernel</code> functions, so maybe...</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>This is great, can we keep going?</p>
<p>The Elixir docs say <code>defmodule</code> is just a macro. Does that mean I can just <code>|&gt;</code> into <code>defmodule</code>?</p>
<pre><code>FooBar |&gt; defmodule do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Yes you can!</p>
<p><code>def</code> and <code>defp</code> are macros too right?</p>
<pre><code>FooBar |&gt; defmodule do
  a |&gt; foo() |&gt; def do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  a |&gt; bar(b) |&gt; defp do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>So many pipes! üòç</p>
<p>We're getting somewhere, but something still doesn't feel right. This module really isn't doing much, so maybe it should not be that long? Also, I think we need more <code>:</code>. Atoms are very Elixir-y, so let's do more of that:</p>
<pre><code>FooBar |&gt; defmodule(do: (
  a |&gt; foo() |&gt; def(do: a |&gt; Kernel.&lt;(0) |&gt; if(do: a |&gt; bar(-1), else: a |&gt; bar(1)))

  a |&gt; bar(b) |&gt; defp(do: a |&gt; Kernel.*(b) |&gt; IO.inspect())
))
</code></pre>
<p>We're <code>:do</code>ing great!</p>
<p>You know what's also very Elixir-y? Lists. Lists and tuples.</p>
<pre><code>FooBar |&gt; defmodule([{:do, (
  a
  |&gt; foo()
  |&gt; def([{:do, a |&gt; Kernel.&lt;(0) |&gt; if([{:do, a |&gt; bar(-1)}, {:else, a |&gt; bar(1)}])}])

  a |&gt; bar(b) |&gt; defp([{:do, a |&gt; Kernel.*(b) |&gt; IO.inspect()}])
)}])
</code></pre>
<p>Who's going to say this looks like Ruby now? ‚öóÔ∏è</p>
<hr>
<p><a href="https://news.ycombinator.com/item?id=24818706">discussion on hackernews</a> /
<a href="https://www.reddit.com/r/elixir/comments/jd2hr4/cursed_elixir/">discussion on reddit</a></p>

    </article></div>]]>
            </description>
            <link>https://evuez.github.io/posts/cursed-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818706</guid>
            <pubDate>Sun, 18 Oct 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU shoots for ‚Ç¨10B ‚Äòindustrial cloud‚Äô to rival US]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 320 (<a href="https://news.ycombinator.com/item?id=24817290">thread link</a>) | @colinjoy
<br/>
October 18, 2020 | https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>BERLIN ‚Äî The European Union aims to spend up to ‚Ç¨10 billion over the next seven years to help build up a homegrown cloud computing sector that could rival foreign corporations such as Amazon, Google and Alibaba.</p>
<p>Twenty-five EU countries signed a <a href="https://ec.europa.eu/digital-single-market/en/news/towards-next-generation-cloud-europe" target="_blank">joint declaration</a> Thursday pledging public money to power up the cloud sector and establishing the "European Alliance on Industrial Data and Cloud," a partnership geared toward facilitating such projects.</p>
<p>The alliance ‚Äî whose funding is to be drawn from existing EU programs and hoped-for pledges from industry and national capitals ‚Äî will be launched by the end of the year. Cyprus and Denmark were the only EU member countries not to sign the declaration due to ‚Äútechnical reasons.‚Äù</p>
<p>The declaration ‚Äúis a foundation stone for the establishment of European cloud technology, which will be very high performing,‚Äù said Internal Market Commissioner Thierry Breton, following a meeting of European telecoms ministers organized by the German government, which currently holds the EU‚Äôs rotating Council presidency.</p>
<p>‚ÄúContrary to the prejudices, we are not late [on cloud development]. We are the first to get involved in the industrial cloud,‚Äù he added.</p>
<blockquote><p>‚ÄúEU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services‚Äù ‚Äî <em>Lise Fuhr, ETNO‚Äôs director general</em></p></blockquote>
<p>The cloud alliance is a key part of the European Commission‚Äôs data strategy, which aims to create a single market for industrial data. Commissioner Breton in particular has lobbied hard to make the EU a worldwide data hub, and to develop data processing capabilities that would give Europe an edge over foreign rivals that currently dominate the cloud business.</p>
<p>It also fits in with broader efforts by European policymakers to make the Continent less dependent on foreign technology. Currently, U.S. technology firms dominate the global market for cloud storage.</p>
<p>In the same vein, the bloc is set to unveil by December a rulebook for platforms dubbed the ‚ÄúDigital Services Act," as well as binding laws for artificial intelligence that are set to be released early next year.</p>
<p>The new alliance will have the mandate to develop business, investment and implementation plans for European cloud technologies in the public and private sectors.</p>
<p>Signatories also pledge to create common European standards and policy norms to create pan-European cloud services, and help small and medium-sized businesses, startups and the public sector embrace cloud technology.</p>
<p>‚ÄúIn order to achieve digital sovereignty, we need to start approaching data processing the way major American and Chinese companies ‚Äî the hyper-scalers ‚Äî approach it,‚Äù said German Economy Minister Peter Altmaier.</p>
<p>‚ÄúThis is an area where we‚Äôre far from being equals,‚Äù he added.</p>
<h3>Money, money, money</h3>
<p>The Commission‚Äôs plan is to invest up to ‚Ç¨10 billion to develop Europe's cloud and data infrastructures.</p>
<p>The EU‚Äôs executive arm would invest ‚Ç¨2 billion from programs in its long-term budget such as the Digital Europe Programme, Connecting Europe Facility 2 and InvestEU.</p>
<p>The rest of the money will come from both industry and member countries. National governments will be able to fund these projects through the EU‚Äôs coronavirus recovery plan, which has earmarked 20 percent toward digital projects.</p>
<p>The joint cloud declaration also issues demands to non-European cloud companies.</p>
<p>Cloud providers must ‚Äúguarantee European standards in terms of security, data protection, consumer protection, data portability and energy efficiency and contribute to European digital sovereignty.‚Äù</p>
<p>The companies must offer ‚Äúadequate assurance‚Äù that the EU will maintain control over its strategic and sensitive data.</p>
<p>‚ÄúWhile all cloud providers are welcome in European cloud federation, the resulting cloud capacities should not be subject to laws of foreign jurisdictions,‚Äù the declaration read.</p>
<p>One of the first initiatives to come out of Europe‚Äôs cloud push is Gaia-X, a much-hyped European effort spearheaded by Germany and France to build up a European platform that sets common standards for cloud technology. Gaia-X has <a href="https://www.politico.eu/?p=1449266">limited</a> the voting rights of non-European cloud computing companies, and they cannot become directors of the association.</p>
<p>ETNO, the association representing Europe‚Äôs leading telecom operators, applauded the move.</p>
<p>‚ÄúEU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services. We call for EU targets and commitments that reflect the demand side of the cloud investment story,‚Äù said Lise Fuhr, ETNO‚Äôs director general.</p>
<p>Tech lobby DigitalEurope was equally supportive, and announced it was applying for membership in Gaia-X.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#f585879ab5859a999c819c969adb9080" target="_blank"><span data-cfemail="97e7e5f8d7e7f8fbfee3fef4f8b9f2e2">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
 <div> <h3>  Also On POLITICO  </h3>   <div data-block-attributes="[]" data-page="0"> <div> <div> <p><a href="https://www.politico.eu/article/eu-cloud-new-front-with-us-tech-giants/"> <img src="https://www.politico.eu/wp-content/uploads/2020/09/iStock-1160479733-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="EU cloud regulation opens new front with US tech giants" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div><div> <p><a href="https://www.politico.eu/article/beyond-tiktok-us-chinese-app-crackdown/"> <img src="https://www.politico.eu/wp-content/uploads/2020/08/GettyImages-1068921922-1-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="Beyond TikTok, US eyes Chinese apps and cloud for crackdown" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div> </div> </div>    </div> 								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817290</guid>
            <pubDate>Sun, 18 Oct 2020 12:20:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Detection at 1840 FPS with TorchScript, TensorRT and DeepStream]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24817173">thread link</a>) | @briggers
<br/>
October 18, 2020 | https://paulbridger.com/posts/video-analytics-deepstream-pipeline/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 17, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>Previously, we took a <a href="https://paulbridger.com/posts/video-analytics-pytorch-pipeline/">simple video pipeline</a> and made it as fast as we could without sacrificing the flexibility of the Python runtime. It‚Äôs amazing how far you can go ‚Äî <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">9 FPS to 650 FPS</a> ‚Äî but we did not reach full hardware utilization and the pipeline did not scale linearly beyond a single GPU. There is evidence (measured using <a href="https://github.com/chrisjbillington/gil_load">gil_load</a>) that we were throttled by a fundamental Python limitation with multiple threads fighting over the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a> (GIL).</p>
<p>In this article we‚Äôll take performance of the same <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/">SSD300 model</a> even further, leaving Python behind and moving towards true production deployment technologies:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/jit.html"><strong>TorchScript.</strong></a> Instead of running directly in the Pytorch runtime, we‚Äôll export our model using TorchScript tracing into a form that can be executed portably using the <code>libtorch</code> C++ runtime.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/tensorrt"><strong>TensorRT.</strong></a> This toolset from Nvidia includes a ‚Äúdeep learning inference optimizer‚Äù ‚Äî a compiler for optimizing CUDA-based computational graphs. We‚Äôll use this to squeeze out every drop of inference efficiency.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/deepstream-sdk"><strong>DeepStream.</strong></a> While <a href="https://gstreamer.freedesktop.org/">Gstreamer</a> gives us an extensive library of elements to build media pipelines with, DeepStream expands this library with a set of GPU-accelerated elements specialized for machine learning.</p>
</li>
</ul>
<p>These technologies fit together like this:</p>
<p><img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/deepstream_hybrid.svg" alt="DeepStream Hybrid Architecture"></p>
<p>This article will not be a step-by-step tutorial with code examples, but will show what is possible when these technologies are combined. The associated repository is here: <a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>.</p>
<h3 id="torchscript-vs-tensorrt">
  üî•TorchScript vs TensorRTüî•
  <a href="#torchscript-vs-tensorrt">#</a>
</h3>
<p>Both TorchScript and TensorRT can produce a deployment-ready form of our model, so why do we need both? These great tools may eventually be competitors but in 2020 they are complementary ‚Äî they each have weaknesses that are compensated for by the other.</p>
<p><strong>TorchScript.</strong> With a few lines of <code>torch.jit</code> code we can generate a deployment-ready asset from essentially any Pytorch model that will run anywhere libtorch runs. It‚Äôs not inherently faster (it is submitting approximately the same sequence of kernels) but the libtorch runtime will perform better under high concurrency. However, without care TorchScript output may have performance and portability surprises (I‚Äôll cover some of these in a later article).</p>
<p><strong>TensorRT.</strong> An unparalleled model compiler for Nvidia hardware, but for Pytorch or <a href="https://onnx.ai/">ONNX</a>-based models it has incomplete support and suffers from poor portability. There is a plugin system to add arbitrary layers and postprocessing, but this low-level work is out of reach for groups without specialized deployment teams. TensorRT also doesn‚Äôt support cross-compilation so models must be optimized directly on the target hardware ‚Äî not great for embedded platforms or highly diverse compute ecosystems.</p>
<p>Let‚Äôs begin with a baseline from the previous post in this series ‚Äî <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">Object Detection from 9 FPS to 650 FPS in 6 Steps</a>.</p>
<h2 id="stage-0-python-baseline">
  Stage 0: Python Baseline
  <a href="#stage-0-python-baseline">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/pytorch-video-pipeline/blob/master/tuning_postprocess_2.py">tuning_postprocess_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.qdrep">tuning_postprocess_2.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.pipeline.dot.png">tuning_postprocess_2.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>The <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/#stage-2-postprocessing-on-gpu">Postprocessing on GPU</a> stage from my previous post is logically closest to our first DeepStream pipeline. This was a fairly slow, early stage in the Python-based optimization journey but limitations in DeepStream around batching and memory transfer make this the best comparison.</p>
<p>This Python-based pipeline runs at around 80 FPS:</p>








<p>After we get a basic DeepStream pipeline up and running we‚Äôll empirically understand and then remove the limitations we see.</p>
<h2 id="stage-1-normal-deepstream-mdash-100-torchscript">
  Stage 1: Normal DeepStream ‚Äî 100% TorchScript
  <a href="#stage-1-normal-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_1.py">ds_trt_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_1.py">ds_tsc_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_1.py">ds_ssd300_1.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.qdrep">ds_1_1gpu_batch16_host.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.pipeline.dot.png">ds_1_1gpu_batch16_host.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Our approach to using TorchScript and TensorRT together in a DeepStream pipeline will be to construct a hybrid model with two sequential components ‚Äî a TensorRT frontend passing results to a TorchScript backend which completes the calculation.</p>
<h3 id="hybrid-deepstream-pipeline">
  Hybrid DeepStream Pipeline
  <a href="#hybrid-deepstream-pipeline">#</a>
</h3>
<p>Our hybrid pipeline will eventually use the <code>nvinfer</code> element of DeepStream to serve a TensorRT-compiled form of the SSD300 model directly in the media pipeline. Since TensorRT cannot compile the entire model (due to unsupported <a href="https://onnx.ai/">ONNX</a> ops) we‚Äôll run the remaining operations as a TorchScript module (via <a href="https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html#page/DeepStream%20Plugins%20Development%20Guide/deepstream_plugin_details.html#wwpID0E0TDB0HA">the <code>parse-bbox-func-name</code> hook</a>).</p>
<p>However, the first pipeline will be the simplest possible while still following the hybrid pattern. The TensorRT model does no processing and simply passes frames to the TorchScript model, which does all preprocessing, inference, and postprocessing. 0% TensorRT, 100% TorchScript.</p>
<p>This pipeline runs at 110 FPS without tracing overhead. However, this TorchScript model has already been converted to <code>fp16</code> precision so a direct comparison to the Python-based pipeline is a bit misleading.</p>








<p>Let‚Äôs drill into the trace with <a href="https://developer.nvidia.com/nsight-systems">Nvidia‚Äôs Nsight Systems</a> to understand the patterns of execution. I have zoomed in to the processing for two 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch_hu85cb8d526cf1fda403db89df3e60bf80_432723_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>Looking at the red NVTX ranges on the <code>GstNvInfer</code> line we can see overlapping ranges where batches of 16 frames are being processed. However, the pattern of processing on the GPU is quite clear from the 16 utilisation spikes ‚Äî it is processing frame-by-frame.  We also see constant memory transfers between device and host.</p>
<p>Drilling in to see just two frames of processing, the pattern is even more clear:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame_hudc758a7e69d7157937e6a1d7caab6946_421239_896x540_fill_box_top_2.png" width="896" height="540">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>With a little knowledge of how DeepStream works the problem is clear:</p>
<ul>
<li><code>nvinfer</code> sends batches of frames to the configured model engine (our empty TensorRT component) ‚Äî great.</li>
<li><code>nvinfer</code> then sends the model output <em>frame by frame</em> to the postprocessing hook (our TorchScript component).</li>
</ul>
<p>Since we have put our entire model into a TorchScript postprocessing hook we are now processing frame by frame with no batching, and this is causing very low GPU utilisation. (This is why we are comparing against a Python pipeline with no batching).</p>
<p><strong>We are using DeepStream contrary to the design</strong>, but to build a truly hybrid TensorRT and TorchScript pipeline we need batched postprocessing.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing Hooks are Frame-by-Frame</strong></p>
<p>The design of <code>nvinfer</code> assumes model output will be postprocessed frame-by-frame. This makes writing postprocessing code a tiny bit easier but is inefficient by default. Preprocessing, inference and postprocessing logic should always assume a batch dimension is present.</p>

</blockquote>

<p>The Nsight Systems view above also shows a pointless sequence of device-to-host then host-to-device transfers. The purple device-to-host memory transfer is due to <code>nvinfer</code> sending tensors to system memory, ready for the postprocessing code to use it. The green host-to-device transfers are me putting this memory back on the GPU where it belongs.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing is Assumed to Happen on Host</strong></p>
<p>This is a legacy of early machine learning approaches. Modern deep learning pipelines keep data on the GPU end-to-end, including data augmentation and postprocessing. See Nvidia‚Äôs <a href="https://developer.nvidia.com/DALI">DALI library</a> for an example of this.</p>

</blockquote>

<p>Okay, time to hack DeepStream and remove these limitations.</p>
<h2 id="stage-2-hacked-deepstream-mdash-100-torchscript">
  Stage 2: Hacked DeepStream ‚Äî 100% TorchScript
  <a href="#stage-2-hacked-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_2.py">ds_trt_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_2.py">ds_tsc_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_2.py">ds_ssd300_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.qdrep">ds_2_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.pipeline.dot.png">ds_2_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Thankfully, Nvidia have provided source for the <code>nvinfer</code> pipeline element. I‚Äôve made two changes to better support our approach of doing significant work in the postprocessing hook and fix the above limitations:</p>
<ul>
<li><code>nvinfer</code> model engine output is now sent in a single batch to the postprocessing hook.</li>
<li>Model output tensors are no-longer copied to host, but are left on the device.</li>
</ul>
<blockquote>
  These <code>nvinfer</code> changes are unreleased and are not present in the companion repository (<a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>) because they are clearly derivative of <code>nvinfer</code> and I‚Äôm unsure of the licensing. Nvidia people, feel free to get in touch: <a href="mailto:paul@paulbridger.com">paul@paulbridger.com</a>.
</blockquote>

<p>With hacked DeepStream and no model changes at all this pipeline now hits 350 FPS when measured with no tracing overhead. This is up from 110 FPS with regular DeepStream. I think we deserve a chart:</p>








<p>The <code>Concurrency 1x2080Ti</code> stage from the Python pipeline is now the closest comparison both in terms of FPS and optimizations applied. Both pipelines have batched inference, video frames decoded and processed on GPU end-to-end, and concurrency at the batch level (note the overlapping NVTX ranges below). One additional level of concurrency in the Python pipeline is multiple overlapping CUDA streams.</p>
<p>The Nsight Systems view shows processing for several 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch_hudc758a7e69d7157937e6a1d7caab6946_445767_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>We now have good GPU utilization and very few needless memory transfers, so the path forward is to optimize the TorchScript model. Until now the TensorRT component has been entirely pass-through and everything from preprocessing, inference and postprocessing has been in TorchScript.</p>
<p>It‚Äôs time to start using the TensorRT optimizer, so get ready for some excitement.</p>
<h2 id="stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">
  Stage 3: Hacked DeepStream ‚Äî 80% TensorRT, 20% TorchScript
  <a href="#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_3.py">ds_trt_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_3.py">ds_tsc_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_3.py">ds_ssd300_3.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.qdrep">ds_3_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.pipeline.dot.png">ds_3_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>According to Nvidia, TensorRT <a href="https://developer.nvidia.com/tensorrt">‚Äúdramatically accelerates deep learning inference performance‚Äù</a> so why not compile 100% of our model with TensorRT?</p>
<p>The Pytorch export to TensorRT consists of a couple of steps, and both provide an opportunity for incomplete support:</p>
<ol>
<li>Export the Pytorch model to the <a href="https://onnx.ai/">ONNX</a> interchange representation via <a href="https://pytorch.org/docs/stable/onnx.html#tracing-vs-scripting">tracing or scripting</a>.</li>
<li>Compile the ONNX representation into a TensorRT engine, the optimized form of the model.</li>
</ol>
<p>If you try to create an optimized TensorRT engine for this entire model (SSD300 including postprocessing), the first problem you will run into is the export to ONNX of the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817173</guid>
            <pubDate>Sun, 18 Oct 2020 11:54:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Samsung phones force Mainland China DNS service upon Hong Kong WiFi users]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24816764">thread link</a>) | @signa11
<br/>
October 18, 2020 | http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/ | <a href="https://web.archive.org/web/*/http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1387">

	
<!-- .entry-header -->

	<div>

		<div>

			<p>This is a technical write up of the author‚Äôs investigation on how users of Samsung phones in Hong Kong (and Macau), using firmware released in September 2020, would be forced to use a public DNS service in Mainland China, which caused unease and privacy concerns among some of its users.</p>
<p>While this was investigated on a variant of a Galaxy Note 10+ phone targetting the Hong Kong market, it was reported that the issue exists for a wide range of recent Samsung phones, including those sold in other places when used in Hong Kong.</p>
<p>(Update: The firmware update released in Mid-October 2020 has fixed the DNS issue discussed in this Part, but the issue of DNS queries for <code>qq.com</code> discussed in <a href="http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/">Part 2</a> remained unchanged.)</p>

<blockquote><p>Shameless plug (for Hong Kong users): The author is the developer of Headuck Call blocker (useful only in Hong Kong). Earlier it got mistakenly flagged as malware by Google and lost many of its users, but the appeal was successful and the App is <a href="https://play.google.com/store/apps/details?id=com.headuck.headuckblocker.dev">on Google Play</a> again. Please re-consider the App if you got scared by the earlier Google Play malware warning.</p></blockquote>
<h3>Background</h3>
<p>In early October 2020, a Samsung phone user in Hong Kong, local forum (HKEPC) user dingwinslow209, <a href="https://www.hkepc.com/forum/viewthread.php?fid=168&amp;tid=2586830">reported that (link to forum post in Chinese)</a> an extra DNS server entry, <code>114.114.114.114</code> was added to the DNS setting of his Samsung mobile phone, which was updated with the latest firmware, whenever he was using a WiFi connection.&nbsp; This happened both when the DNS setting is static, or dynamic using DHCP (but not when VPN / mobile network was used).&nbsp; Even when both DNS1 and DNS2 were set to valid DNS servers (e.g. Google public DNS service using <code>DNS1 = 8.8.8.8</code> and <code>DNS2 = 8.8.4.4</code>), a new DNS3 entry pointing to <code>114.114.114.114</code> would appear in some utility app.</p>
<p>This immediately raised privacy concerns among some Samsung users in Hong Kong, as the public DNS server <code>114.114.114.114</code> is owned by Cogent Communications, under <a href="https://www.whois.com/whois/114.114.114.114">Nanjing XinFeng Information Technologies Inc</a>, in Mainland China.</p>
<p>Subsequently, in another local forum (lihkg), users captured DNS requests to <code>114.114.114.114</code>, and observed queries for ‚Äú<code>qq.com</code>‚Äù&nbsp; (domain owned by Chinese tech giant Tencent), even when no software from Tencent is installed in the devices.&nbsp; There were reports that these DNS queries were sent once per minute, so long as the phone screen remained on.</p>
<p>There are further reports that when DNS queries to qq.com were blocked, the phone would report no internet connectivity via the WiFi connection.</p>
<p>The observation of the extra DNS entry was later independently confirmed by other forum users and the local media, using recent Samsung phones which have been updated in recent months.&nbsp; (See the links in the HKPEC post above, in Chinese).&nbsp; The issue persisted even when users reset their Samsung phone to factory settings. This showed that the issue originates from Samsung firmware instead of some third-party software malware.</p>
<p>The following documents the technical investigation and verification of the issue directly from analysing the code from firmware.&nbsp; The information should be sufficient for the issue and its extent to be independently verified.</p>
<h3>Getting and extracting the firmware</h3>
<p>To confirm the issue, a recent Samsung Galaxy Note 10+ firmware (SM-N9750 TGY, Hong Kong version), at Security Patch level 2020-09-01 was downloaded from one of the Samsung firmware download sites. Galaxy Note 10+ is one of the Samsung models reportedly&nbsp;affected.</p>
<p>After unzipping the downloaded firmware (in zip format), expanding the tar file beginning with ‚Äú<code>AP_N9750ZSU3CTH1</code>‚Äú, decompressing the file <code>system.img.ext4.lz4</code> using <code>lz4</code>, converting it to ext4 format using <code>simg2img</code>, and mounting it as ext4 volume under Linux, one has access to the system image which would be installed when Note 10+ users update their phone to that patch level. (The same is accessible if a Note 10+ phone is rooted).</p>
<p>After some research, the culprit was found ‚Äì a vendor specific service level component, added by Samsung to the Android framework, located at <code>/system/framework/wifi-service.jar</code>. This seems to work at the android system service level, supplementing the usual <code>services.jar</code>.</p>
<p>The decompiled source of the jar file (using <a href="http://www.javadecompilers.com/apk">this site</a>, with Jadx decompiler) has been uploaded to <a href="https://github.com/headuck/SM-N9750-TGY">https://github.com/headuck/SM-N9750-TGY</a>.&nbsp; The following is a walkthrough of the relevant code when a user connects to a WiFi network, showing how the DNS entries were modified.</p>
<h3>Relevant flow of DNS entry addition</h3>
<p>The main culprit is the class <code>com.android.server.wifi.WifiConnectivityMonitor</code>, located in the file <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiConnectivityMonitor.java">WifiConnectivityMonitor.java</a>. The decompiled code contains the following:</p>
<p>line 129: the hardcoded address <code>114.114.114.114</code></p>
<pre>private static final String CHN_PUBLIC_DNS_IP = "114.114.114.114";</pre>
<p>line 878: addresses used for DNS probe (to be covered in next part).</p>
<pre>public final String DEFAULT_URL = "http://www.google.com";
public final String DEFAULT_URL_CHINA = "http://www.qq.com";
public String DEFAULT_URL_STRING = "www.google.com";
public final String DEFAULT_URL_STRING_CHINA = "www.qq.com";</pre>
<p>This large class is mainly a state machine of the various WiFi states. The state hierarchy are defined, and initial state set, at lines 1185-1197.</p>
<pre>addState(this.mDefaultState);
addState(this.mNotConnectedState, this.mDefaultState);
addState(this.mConnectedState, this.mDefaultState);
addState(this.mCaptivePortalState, this.mConnectedState);
addState(this.mEvaluatedState, this.mConnectedState);
....
setInitialState(this.mNotConnectedState);</pre>
<p>The base class for the StateMachine can be found under AOSP source (<a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/core/java/com/android/internal/util/StateMachine.java?q=StateMachine.java&amp;ss=android%2Fplatform%2Fsuperproject">StateMachine.java</a>).</p>
<p>When the device is connected to WiFi, it would enter <code>ConnectedState</code>.</p>
<p>line 1976 (under <code>processMessage()</code> of the initial <code>NotConnectedState</code>) would be invoked when a new WiFi connection is detected.</p>
<pre>wifiConnectivityMonitor.transitionTo(wifiConnectivityMonitor.mConnectedState);</pre>
<p>The <code>mConnectedState</code> variable is of class <code>ConnectedState</code>, defined from line 1988. The <code>enter()</code> method of <code>ConnectedState</code> contains the following code (from line 2090), which uses <code>CHN_PUBLIC_DNS_IP</code> (i.e. the Mainland Chinese controlled DNS server):</p>
<pre>if (WifiConnectivityMonitor.this.mWifiManager != null &amp;&amp; WifiConnectivityMonitor.this.inChinaNetwork()) {
    Message msg = new Message();
    msg.what = 330;
    Bundle args = new Bundle();
    args.putString("publicDnsServer", WifiConnectivityMonitor.CHN_PUBLIC_DNS_IP);
    msg.obj = args;
    WifiConnectivityMonitor.this.mWifiManager.callSECApi(msg);
}
</pre>
<p>From the code it seems to add the Mainland Chinese DNS service to the user‚Äôs list of DNS server automatically, when the device is connected to Chinese mobile network. There seems no option to disable the behaviour.</p>
<p><code>WifiConnectivityMonitor.inChinaNetwork()</code> is at line 11199.&nbsp; As suggested by its name, it should obtain the ISO code and return true only if the device is connected to a mobile network in China:</p>
<pre>public boolean inChinaNetwork() {
    String str = this.mCountryIso;
    if (str == null || str.length() != 2) {
        updateCountryIsoCode();
    }
    if (!isChineseIso(this.mCountryIso)) {
        return false;
    }
    if (!DBG) {
        return true;
    }
    Log.d(TAG, "Need to skip captive portal check. CISO: " + this.mCountryIso);
    return true;
}
</pre>
<p>Digging deeper, this is how the ISO code (<code>mCountryIso</code>) is obtained, under <code>updateCountryIsoCode()</code> at line 11219 (fallback skipped).</p>
<pre>public void updateCountryIsoCode() {
    if (this.mTelephonyManager == null) {
        try {
            this.mTelephonyManager = (TelephonyManager) this.mContext.getSystemService("phone");
        } catch (Exception e) {
            Log.e(TAG, "Exception occured at updateCountryIsoCode(), while retrieving Context.TELEPHONY_SERVICE");
        }
    }
    TelephonyManager telephonyManager = this.mTelephonyManager;
    if (telephonyManager != null) {
        this.mCountryIso = telephonyManager.getNetworkCountryIso();
        Log.i(TAG, "updateCountryIsoCode() via TelephonyManager : mCountryIso: " + this.mCountryIso);
    }
    /* fallback when there is no mobile network skipped. The fallback is to read the CountryISO setting from a Samsung config file (cscfeature.xml) */
    ....
}
</pre>
<p>(While not shown here, this code is also invoked when initializing and when change in ISO code of telephone network is detected, so it need not be called during each check.) The country code is get from <code>TelephonyManager.getNetworkCountryIso()</code> which is a standard Android API, documented <a href="https://developer.android.com/reference/android/telephony/TelephonyManager#getNetworkCountryIso()">here</a>. It returns the ISO-3166-1 alpha-2 country code equivalent of the MCC (Mobile Country Code) of the mobile operator. In Hong Kong, this is ‚ÄúHK‚Äù, and in Mainland China this is ‚ÄúCN‚Äù.</p>
<p>As one might suspect at this point, the problem lies in <code>isChineseIso()</code>, at line 11214:</p>
<pre>private boolean isChineseIso(String countryIso) {
    return "cn".equalsIgnoreCase(countryIso) || "hk".equalsIgnoreCase(countryIso) || "mo".equalsIgnoreCase(countryIso);
}</pre>
<p>This means that you are treated as being connected to a Chinese mobile network if you are connected to a Hong Kong mobile network for the purpose of adding the 114 DNS service.&nbsp; (BTW, ‚ÄúMO‚Äù is the ISO-3166-1 code for Macau.) Perhaps Samsung might want to address cases when people travel to Mainland China while forgetting to reset their hardcoded DNS settings, and kindly ‚Äúadd‚Äù a DNS service which works within the Great Firewall of China. But they seemed to forget that both Hong Kong and Macau are outside the Great Firewall, at least so far.</p>
<p>Back to the DNS setting code above (line 2090). It makes a binder call to <code>WifiManager.callSECApi()</code>, with message code = 330, with a <code>Bundle</code> setting <code>publicDnsServer</code> to our friend <code>114.114.114.114</code>. While <code>WifiManager</code> is a standard Android class the method <code>callSECApi()</code>, as suggested by its name, is Samsung specific.</p>
<p>The remote call to <code>WifiManager</code> would end up in the service class implementation at <code>com.android.server.wifi.WifiServiceImpl</code>, implementing WifiService, at <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiServiceImpl.java">WifiServiceImpl.java</a>. (The class is Samsung‚Äôs extension to the AOSP service class of the same ‚Ä¶</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</a></em></p>]]>
            </description>
            <link>http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816764</guid>
            <pubDate>Sun, 18 Oct 2020 10:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio‚Äôs opportunity and who will capture it]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24815888">thread link</a>) | @hunglee2
<br/>
October 17, 2020 | https://www.matthewball.vc/all/audiotech | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/audiotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
  &quot;playbackSpeed&quot;: 0.5,
  &quot;filter&quot;: 1,
  &quot;filterStrength&quot;: 0,
  &quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f88a99f19d4cd6d64631928"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1602791840799_3755"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image-dimensions="2500x1456" data-image-focal-point="0.5,0.5" alt="Edison.png" data-load="false" data-image-id="5f88ad99ea51f67834f2495a" data-type="image" src="https://www.matthewball.vc/all/Edison.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-ff1f1677bf36496f03d8"><div><p>As most of the major media categories ‚Äî music, video and video games ‚Äî have existed for decades, we tend to forget that media is technology. Instead, we think of technology as being used to express media, rather than media itself. Spotify, for example, is an <em>internet</em> <em>streaming </em>music service, while iTunes is a <em>download </em>music service, SiriusXM is <em>satellite</em> <em>broadcast</em> music service, and radio is a <em>terrestrial broadcast</em> technology. This focus on delivery ignores the classic definition of media: ‚Äú<span>outlets</span> or <span>tools</span> used to <span>store</span> and <span>deliver</span> information or data.‚Äù</p><p>While the above might seem preoccupied with theory and philosophy, all analysis of the past and future of a given media category must start from the fact that media is technology. This is because technology not only enables content categories, it defines their business models and shapes the content, too. And as we know, technology is in a constant process of change. </p><p><strong>Chapter 1: How Technology Created Recorded Media, Then Continually Redefined It</strong></p><p>Music offers a great view into the interplay between technology, business model and content. Consider the following triptych, which covers seven decades, two decades and one year, respectively.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602797899091_5458"><div><p>&nbsp;When the flat record first emerged in the 1850s, it standardized around the 78. The 78 (as in 78 rotations per minute) came in a 10-inch version that held three minutes of music and a 12-inch version that held four. This meant that after centuries of variability, music suddenly had a defined run-time.&nbsp;</p><p>This length was reaffirmed by the first mass market standard for consumer media: the 45 RPM vinyl single, which launched in 1948 and held roughly three minutes. The music industry coalesced around this format (and its runtime) for a variety of tech-based reasons. The 45 was far cheaper for consumers than a 78 album, which was important given the high cost of record players and the ubiquity of free (singles-focused) radio. The 45‚Äôs cost advantage also meant it was the primary way labels delivered singles to thousands of radio stations across the country for local airplay. In addition, RCA quickly figured out how to make a stackable version of 45s, which was important to jukebox manufacturers. The rise of the 45 naturally led the length of the average song to decline; a four-minute song simply couldn‚Äôt fit on the most important audio format in the world.</p><p>As the physical and financial limitations of the 78 and 45 were relieved, and the far more flexible cassette and CD emerged, the length of the average single grew rapidly, adding nearly two minutes (or 78%) from 1959 to 1992. Still, almost all tracks conformed to the three-to-four minute standard. After decades, the West had become used to the idea that a song was roughly between three minutes and 20 seconds and four minutes and 10 seconds long.</p><p>On its surface, the shift to digital audio should have led to further increases in song length. After all, there was no longer any limitation to run-time. However, the reverse occurred. Technology might have relaxed its grip on music‚Äôs length, but it had strengthened its hold on business models.</p><p>As is well known, iTunes unbundled the physical album in individually downloadable (and bought) tracks. But in doing so, it penalized artists for bundling a multi-part song into a single track. Pink Floyd‚Äôs decision to split the 26-minute and nine-part Shine on You Crazy Diamond into two discrete tracks didn‚Äôt matter in 1975; all nine parts fit on a single record and no one wanted to buy just a single half let alone a single part. But in 2005, such a move could mean missing out on 75% of revenues ‚Äî why sell two things when you could sell nine? And why would a consumer buy an entire $10 album if all they wanted was two $1 portions of Shine on You Crazy Diamond? These incentives naturally led to artists that were publishing new music to split their longer/multi-section songs into separate ‚Äî and shorter ‚Äî preludes, interludes and segments.</p><p>This behaviour has been greatly exacerbated by the advent of a new and even more disruptive digital music technology: on-demand streaming. While iTunes was technically innovative, its business model was not. Consumers, after all, primarily owned copies of individual tracks in the 1950s and 1960s. Spotify and Apple Music, meanwhile, meant consumers adopted not just a new music technology, but also bought an entirely different product: ongoing access to all music ever created.</p><p>But as technology has shifted consumers away from discrete and attributable transactions (buying record A on date B) to ongoing and general ones (subscribing to service C in perpetuity), musical talent needed a new compensation model. Spotify, therefore, decided to pay talent as and to the degree consumers listened to their works. Matching revenue with usage is intuitive, but it was never before possible in music. There was no way to track at-home record spins or CD plays, let alone charge for them. Nor was it practical for iTunes to ask users to download an individual song to their devices and pay several pennies per play when they later synched their iPod to iTunes. (This would have been rife with abuse, too.)</p><p>Engagement-based monetization is arguably more fair. Consider, for example, that the Beatles‚Äô <em>Yesterday </em>and Psy‚Äôs <em>Gangnam Style</em> would each generate $1 when sold on iTunes, even if the former was played 2,000 times over ten years and the latter 30 times in the month it was bought and then never again. But the more that business models change, the more that incentives and content change, too.</p><p>To support engagement-based monetization, Spotify and its label suppliers had to define engagement. And they chose to do this on a per stream basis with a minimum stream time of 30 seconds (to avoid accidental plays, track skipping, etc.). However, this meant that a 10-minute track, five-minute track and 31-second track generated the same royalties.&nbsp;</p><p>So as the music industry has transitioned the majority of its revenues from CDs and downloads to streaming, major artists have relentlessly shortened and split their tracks. Why release a five-minute song if you can make it a two and a half-minute song that‚Äôs played twice? Or two different two and a half-minute songs? This meant artists had yet another reason to reduce track lengths</p><p>All of this helps to explain the extraordinary success of the 2019‚Äôs top track, <em>Old Town Road </em>by Lil Nas X, which is also Billboard‚Äôs longest running #1 ever, at 19 consecutive weeks. While the song is awesome, it‚Äôs also only one minute and 53 seconds ‚Äî roughly half of 2019‚Äôs average song length. This means that four minutes of listening generated two times the average revenue and charting lift of every other hit song that year.</p><p><em>Old Town Road </em>isn‚Äôt an exception, either. Up until 2017, Billboard‚Äôs Hot 100 Chart has never had a year with more than 2% of its charting tracks shorter than two minutes and 30 seconds (most years had none). In the past three years, this sum has skyrocketed to over 12%, or roughly one in every eight tracks.</p><p>Notably, labels are also encouraging artists to simplify the name of their songs and albums in order to ensure they‚Äôre optimized for voice-controlled speakers and touchscreen-based searches. A track with five words is more likely to be misunderstood or suffer from autocorrect than one with two. Similarly, voice assistants are known to struggle with <a href="https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/">accents</a>, such as Irish or even Texan. Being hard to say means you might not get played.</p><p><em>Old Town Road </em>isn‚Äôt the first time technology made a hit. In fact, the modern day dominance of rap and R&amp;B comes from how changes in technology ‚Äì not for delivery, but sales recognition ‚Äì&nbsp; afforded Lil Nas X the opportunity to top the charts in the first place.</p><p>Prior to the 1990s, Black artists and music fans had spent decades arguing the record industry conspired against ‚Äúurban contemporary‚Äù music by refusing it radio play and ignoring its sales. It took only five weeks after Billboard adopted SoundScan, a computerized sales database, to prove this theory right.</p><p>Until 1991, Billboard charts weren‚Äôt based on actual unit sales or radio play. Instead, it was assembled using (white) retail clerk estimates of what was selling best and what (white) DJs considered to be ‚Äú<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/">hottest</a>‚Äù each week. According to <em>The Atlantic</em>, both groups had<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/"> reasons to lie</a>. For example, labels would pressure radio stations to favour ‚Äúhand-picked hits‚Äù if they wanted to keep receiving the newest single on time (stations sometimes<a href="https://en.wikipedia.org/wiki/Payola"> received bribes to play specific tracks</a>, too). Meanwhile, labels would force inventory on their retailers, who would then overreport sales to convince music fans to buy excess inventory.</p><p>Naturally, those who ran the music industry saw little need to overhaul how it worked. And thus while the book and film industries had shifted to computerized sales databases in the 1980s, not one of the top six record distributors signed onto SoundScan before its release in June 1991. But this resistance didn‚Äôt stop N.W.A.‚Äôs <em>N***az4life</em> from debuting #2 on the Billboard Top 100 the very next month under SoundScan. This was the highest charting performance in rap history ‚Äì and happened without any radio airplay, music video airings on MTV, or a concert tour. The failings of the old honour system were further demonstrated by the fact that N.W.A. debuted at only #21 on Billboard‚Äôs R&amp;B chart, which wasn‚Äôt yet on SoundScan. Somehow it was possible that <em>N***az4life</em> was the second biggest album in the country by units purchased, but 21st in its own genre when it came to what was ‚Äúselling‚Äù and ‚Äúhottest.‚Äù One week after it‚Äôs release, the album hit #1 on the Billboard chart (displacing R.E.M) as hundreds ‚Ä¶</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/audiotech">https://www.matthewball.vc/all/audiotech</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/audiotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815888</guid>
            <pubDate>Sun, 18 Oct 2020 06:22:27 GMT</pubDate>
        </item>
    </channel>
</rss>
