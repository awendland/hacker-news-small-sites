<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 17 Oct 2020 20:27:38 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 17 Oct 2020 20:27:38 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Elroy Lamp: A transparent LCD lamp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24798764">thread link</a>) | @schappim
<br/>
October 16, 2020 | https://www.kylescholz.com/wp/the-elroy-lamp/ | <a href="https://web.archive.org/web/*/https://www.kylescholz.com/wp/the-elroy-lamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-677">
		<!-- .entry-header -->

	
	<div>
		<p><iframe width="525" height="295" src="https://www.youtube.com/embed/90s7JjoEIBQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><span>Elroy is a table lamp with a unique feature — the shade can dynamically change, at the swipe of a finger, to a new style or pattern to complement your mood, the time of day, or an event, all from your phone or web browser.</span></p>
<p><span>Elroy is a concept and personal DIY project. I’ll share some learnings and details on how I built it. These aren’t step-by-step instructions, but I hope they’ll be helpful to anyone that’s inspired to build their own design.</span></p>
<p><a href="http://www.kylescholz.com/wp/the-elroy-lamp/elroy-lamp-4c_moment-5/"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-5-1024x576.jpg" alt="" width="525" height="295" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-5-1024x576.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-5-300x169.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-5-768x432.jpg 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-5.jpg 1920w" sizes="(max-width: 525px) 100vw, 525px"></a></p>
<h3><strong>Overview</strong></h3>
<p><span>Elroy is essentially a computer with a 4-way display, backlit by a bright LED bulb. The four sides of the lamp shade are made from translucent LCD displays, and acrylic and paper diffusion layers. The light source is a very bright 35W LED bulb. The displays are driven by a single board computer running Linux and custom software to display and manage images. The lamp is controllable over wifi via a simple web app.</span></p>
<h3><strong>Translucent LCDs</strong></h3>
<p><span>I salvaged some 13” LCD displays from old laptops and found additional matching displays on ebay. I disassembled each display, removing the frame, backing layer, diffusion film, and backlight. This took some practice to get right. The LCD glass is quite fragile. I broke 2 panels during disassembly and had to find replacements. The trick is to remove the electrical tape that holds the display together without flexing the LCD glass so much that it cracks.</span></p>
<figure id="attachment_712" aria-describedby="caption-attachment-712"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184217-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184217-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184217-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184217-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-712">What’s inside? From top: 1) A shiny white paper layer to reflect the back light 2) a transparent polycarbonate sheet with a film to scatter the back light 3) a stack of different diffusion films 4) metal frame 5) the LCD glass panel with circuit board.</figcaption></figure>
<figure id="attachment_711" aria-describedby="caption-attachment-711"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184315-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184315-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184315-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_184315-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-711">The backlight is a row of super bright LEDs tucked into a channel in the metal frame. Some other LCD panels use a cold florescent tube instead of LEDs.</figcaption></figure>
<p><span>The remaining LCD panel is translucent: LCD displays are a sandwich of transparent glass embedded with liquid crystals and tiny transistors, surrounded by layers of polarizing film. In the photo below, I wrote a message on a piece of letter paper, placed it on a clear piece of acrylic, on top of a bright backlight. You can see the LCD display on the right is translucent, but similar to a pair of sunglasses, the polarizing film only permits a fraction of the backlight to emit through the panel.</span></p>

<p><span>Polarizing film is </span><a href="https://en.wikipedia.org/wiki/Liquid-crystal_display"><span>necessary for the function of an LCD display</span></a><span>.</span></p>
<h3><strong>Lamp Light &amp; Diffusion</strong></h3>
<p><span>Given the low amount of light emitted through the display, to create a sufficiently bright lamp, a very bright light source is needed. Also, though an LCD display is typically backlit by a light with a cold color temperature (around 5000K), lamp light is typically a warm color temperature (like 2700K). So the ideal bulb must be bright and warm.</span></p>
<figure id="attachment_714" aria-describedby="caption-attachment-714"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165238-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165238-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165238-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165238-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-714">A 4-bulb array I experimented with.</figcaption></figure>
<figure id="attachment_713" aria-describedby="caption-attachment-713"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165342-1024x576.jpg" alt="" width="525" height="295" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165342-1024x576.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165342-300x169.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_165342-768x432.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-713">The gigantic 9″ long 35W LED bulb I chose beside an ordinary LED lamp bulb.</figcaption></figure>
<p><span>I experimented with multi-bulb arrays, and different bulb options, but settled on this 35W (300W equiv) LED bulb. This bulb is giant and takes up quite a bit of space within the shade. It’s bright enough that it shouldn’t be directly exposed — it would be uncomfortable (maybe dangerous?) to look at directly.</span></p>
<p><span>Next, without some work, the light from the bulb, when viewed through the LCD panels, would be a harsh point-light concentrated in the center. </span><span>I wanted to diffuse the light evenly across the surface and produce a textured, fabric-like aesthetic. I experimented with different acrylic and polycarbonate sheets and paper materials.</span></p>
<figure id="attachment_688" aria-describedby="caption-attachment-688"><a href="http://www.kylescholz.com/wp/the-elroy-lamp/img_20190523_214720/" rel="attachment wp-att-688"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190523_214720-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190523_214720-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190523_214720-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190523_214720-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"></a><figcaption id="caption-attachment-688">Diffusion through mulberry paper.</figcaption></figure>
<p><span>Here’s one experiment result I really liked, but didn’t end up using. This is mulberry paper, which has a unique texture that’s simultaneously woody and linen-like, has nice diffusion properties, and transmits a lot of light. This looked great with black and white patterns and particularly complemented a Japanese lantern aesthetic. I felt like the large and non-uniform fibers didn’t work as well with a diverse set of patterns.</span></p>
<p><span>I found the best combination was this sandwich (starting from the inside):</span></p>
<ul>
<li><span>Frosted acrylic 1/8″ 90% emission (film facing out)</span></li>
<li><span>Vellum tracing paper</span></li>
<li><span>LCD</span></li>
<li><span>Rice paper</span></li>
<li><span>Clear anti-glare polycarbonate 3/32”</span></li>
</ul>
<figure id="attachment_700" aria-describedby="caption-attachment-700"><a href="http://www.kylescholz.com/wp/the-elroy-lamp/elroy-lamp-4c_moment-2a/"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-2a-1024x576.jpg" alt="" width="525" height="295" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-2a-1024x576.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-2a-300x169.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-2a-768x432.jpg 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Elroy-Lamp-4c_Moment-2a.jpg 1920w" sizes="(max-width: 525px) 100vw, 525px"></a><figcaption id="caption-attachment-700">Close up of lamp where texture is visible.</figcaption></figure>
<p><span>The acrylic and polycarbonate sheets also add some structure to protect the LCD glass from flexing and breaking. I wrapped the edges of each sandwich in acetate cloth electrical tape to keep the sheets together.</span></p>
<h3><strong>Controlling</strong></h3>
<p><span>I needed a small SBC (single-board computer), capable of driving 4 displays. I happened to have an Nvidia Jetson Nano, which has DisplayPort 1.2 output with support for MST (multi-stream transport), which means it’s able to drive multiple displays. The Jetson Nano is a powerful, tiny computer that operates on 5V power and can run a standard Linux distribution like Ubuntu.</span></p>
<p><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/Screenshot_20191102-204056-576x1024.png" alt="" width="400" height="711" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Screenshot_20191102-204056-576x1024.png 576w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Screenshot_20191102-204056-169x300.png 169w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Screenshot_20191102-204056-768x1365.png 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/Screenshot_20191102-204056.png 1080w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p><span>I wrote some custom software based on </span><a href="https://www.pygame.org/"><span>Pygame</span></a><span> to display images, with a simple web app and server to give me control over the images.</span></p>
<p><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/71ID5ujheuL._AC_SL1500_-294x300.jpg" alt="" width="400" height="409" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/71ID5ujheuL._AC_SL1500_-294x300.jpg 294w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/71ID5ujheuL._AC_SL1500_-768x785.jpg 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/71ID5ujheuL._AC_SL1500_-1002x1024.jpg 1002w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/71ID5ujheuL._AC_SL1500_.jpg 1468w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p><span>The LCD panels take EDP (Embedded DisplayPort) video input. Each display required an adapter from DisplayPort to EDP. These adapters are bulky and have a lot of functionality I didn’t actually need, like 12V power and brightness control for a backlight (which I removed from each panel) and a control interface for display settings. I also needed an MST Hub to break out 4 DP ports from the 1 DP port on the Nvidia Jetson Nano. This configuration is something I think I could make cheaper and more compact in a future revision, but it worked great for this concept.</span></p>
<h3><strong>Woodwork</strong></h3>
<p><span>I designed the lamp structure in Rhino3D and chose to make wooden parts from walnut. This makes the shade rather heavy, but the lamp is stable with the walnut base.</span></p>
<figure id="attachment_692" aria-describedby="caption-attachment-692"><a href="http://www.kylescholz.com/wp/the-elroy-lamp/img_20190608_172549/" rel="attachment wp-att-692"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190608_172549-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190608_172549-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190608_172549-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20190608_172549-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"></a><figcaption id="caption-attachment-692">The shade frame, glued-up, sanded, and ready to stain.</figcaption></figure>
<p><span>I cut all parts for the shade and base, then shaped them on a router table. I’m not an experienced woodworker, but this came together pretty easily. I had an adventure making tongue-and-groove joints for the first time. This is the 3rd time I’ve used walnut for a project and I always like the result.</span></p>
<p><span>The side-edges of the frame have brass threaded inserts that enable the top and bottom to attach via M2 machine screws.</span></p>
<h3><strong>3D Printed Parts</strong></h3>
<p><span>Most of the electronic components, including the power supply, SBC, MST Hub, switches, and wiring are mounted in a 4.5” square 3D printed “sleeve” that fits inside the walnut base. There is also a vented platform that connects the sleeve to the bottom of the shade.</span></p>
<figure id="attachment_696" aria-describedby="caption-attachment-696"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/sleeves-and-platform-1024x780.jpg" alt="" width="525" height="400" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/sleeves-and-platform-1024x780.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/sleeves-and-platform-300x228.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/sleeves-and-platform-768x585.jpg 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/sleeves-and-platform.jpg 1334w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-696">Drawing of sleeve and vented platform. The sleeve was printed in 6 parts. The top of the sleeve peeks out 2 inches above the walnut base and houses the toggle switches.</figcaption></figure>
<figure id="attachment_715" aria-describedby="caption-attachment-715"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_175603-1-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_175603-1-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_175603-1-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_175603-1-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-715">The sleeve in 2 parts that fit inside the walnut base. In this photo you can see most of the main components. From the right: The DisplayPort hub, Nvidia Jetson Nano, and 5V / 12V power supply. The white cylinder on the left is a ceramic E26 light bulb socket.</figcaption></figure>
<figure id="attachment_716" aria-describedby="caption-attachment-716"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_180712-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_180712-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_180712-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/IMG_20191106_180712-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-716">The sleeve, ready to insert into the walnut base. I primed and painted the 3D printed sleeve. Only the top 2 inches is visible when the lamp is assembled, so the rough spots here aren’t a problem.</figcaption></figure>
<p><span>If I were building this lamp for production … or if I had access to the right tools, I’d want to make the sleeve and platform out of sheet metal to improve heat dissipation.</span></p>
<p><span>On top of the shade, I added a louvered cover. This enables the shade to emit additional light from the top, while obscuring the bulb, which is too bright to look at directly. This also permits heat to escape. I printed these parts out of translucent PETG, which has a higher plasticization temperature than some other common 3D printing filament materials. This isn’t strictly necessary because the surface temperature of the bulb doesn’t really get that hot. Even after hours of continuous use, the temperate is &lt;130 degrees Fahrenheit.</span></p>
<figure id="attachment_697" aria-describedby="caption-attachment-697"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/shade-with-louvers-1024x857.jpg" alt="" width="525" height="439" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/shade-with-louvers-1024x857.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/shade-with-louvers-300x251.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/shade-with-louvers-768x643.jpg 768w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/shade-with-louvers.jpg 1348w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-697">Drawing of shade with louvers and vented platform.</figcaption></figure>
<figure id="attachment_717" aria-describedby="caption-attachment-717"><img loading="lazy" src="http://www.kylescholz.com/wp/wp-content/uploads/2019/11/00100dPORTRAIT_00100_BURST20191106165519731_COVER-1024x768.jpg" alt="" width="525" height="394" srcset="https://www.kylescholz.com/wp/wp-content/uploads/2019/11/00100dPORTRAIT_00100_BURST20191106165519731_COVER-1024x768.jpg 1024w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/00100dPORTRAIT_00100_BURST20191106165519731_COVER-300x225.jpg 300w, https://www.kylescholz.com/wp/wp-content/uploads/2019/11/00100dPORTRAIT_00100_BURST20191106165519731_COVER-768x576.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-717">The 3D printed louvered vent while the interior bulb is off.</figcaption></figure>
<h3><strong>Making it better</strong></h3>
<p><span>This lamp is mostly a proof of concept, but it works and looks good enough that I plan to keep it and use it. If I make another, I have a few ideas for improvement.</span></p>
<ul>
<li><span>Sheet metal. Replace the 3D printed sleeve and vented platform with sheet metal to help dissipate heat.</span></li>
<li><span>Replace the DisplayPort MST hub and adapters. These take up a lot of space and add significant expense (~$250 for the hub and 4 adapters). One theoretical alternative is a DisplayLink adapter based on the </span><a href="https://www.displaylink.com/integrated-chipsets/dl-4000"><span>DL-4100</span></a><span>, which would drive displays over USB and support EDP. I haven’t been able to find such a device on the market yet. Another option to drive displays from USB3 would be to use an SBC with Displayport Alt Mode. I would still need to adapt Displayport to eDP. Adapter boards that do this are bulky and have a lot of components because they provide power and control to the backlight. Since I’m not using a backlight, I could make a simpler adapter that just maps pins for the different connectors.</span></li>
<li><span>Finally, reconsider the closed frame design. Elroy’s shade is basically a closed box. I made this choice&nbsp; to obscure the bulb and hide some electronic components like the EDP ribbon cables and adapters. An open frame design might be possible. One idea is to backlight the panels with edge lighting so I can reduce or eliminate the high wattage bulb.</span></li>
</ul>
<h3><strong>BOM</strong></h3>
<p>Display</p>
<ul>
<li><span>4 X </span><a href="https://www.amazon.com/gp/product/B00ZSUCMH6/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>13.3” LCD Display. (1366 x 768)</span></a></li>
<li><span>4 X </span><a href="https://www.amazon.com/gp/product/B06XC6SJF7/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>HDMI Controller for M133NWN1 (1366 x 768, 30 Pin EDP)</span></a>
<ul>
<li><span>(Note these adapters take HDMI input rather than DisplayPort, so we need to convert DP&gt;HDMI)</span></li>
</ul>
</li>
<li><span>4 X DisplayPort to HDMI Cable (12”)</span></li>
<li><span>1 X </span><a href="https://www.amazon.com/gp/product/B00XXPYTAG/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&amp;psc=1"><span>StarTech 4-Port MST Hub</span></a></li>
</ul>
<p>SBC</p>
<ul>
<li><span>1 X Nvidia Jetson Nano w/ SD Card</span></li>
</ul>
<p>DC Power</p>
<ul>
<li><span>1 X </span><a href="https://www.amazon.com/Enclosed-RD-65A-MEAN-WELL-Switching/dp/B01MS5JV0Q/ref=sr_1_1?keywords=meanwell+rd-65a&amp;qid=1563736666&amp;s=industrial&amp;sr=1-1-catcorr"><span>MEAN WELL RD-65A AC-DC Power Supply Dual Output 5V 12V</span></a></li>
</ul>
<p>Lights</p>
<ul>
<li><span>1 x </span><a href="https://www.amazon.com/gp/product/B06XGD91KN/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>35W (300w equiv) LED Bulb</span></a></li>
<li><span>1 X Ceramic E26 Socket</span></li>
</ul>
<p>Diffusion</p>
<ul>
<li><span>1 X </span><a href="https://www.amazon.com/gp/product/B0006PYKFK/ref=ppx_yo_dt_b_asin_title_o07_s00?ie=UTF8&amp;psc=1"><span>Yasutomo Sulphite Pulp Unryu Paper Roll</span></a><span>, Cut</span></li>
<li><span>4 x Sheets, vellum paper</span></li>
<li><span>4 X Frosted Acrylic 11 7/8″ X 6 7/8″, 1/8″, “90%”</span></li>
<li><span>4 X Clear, anti-glare Polycarbonate, 11 7/8″ X 6 7/8″, 3/32”</span></li>
</ul>
<p>Other</p>
<ul>
<li><a href="https://www.amazon.com/gp/product/B01E8W9XK8/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>Acetate cloth electronic tape</span></a><span>, 15MM</span></li>
<li><span>2X </span><a href="https://www.amazon.com/gp/product/B078KBC5VH/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>Rocker Switches</span></a></li>
<li><span>1X </span><a href="https://www.amazon.com/gp/product/B07MKLYD2N/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>Inlet Plug w/ Fuse</span></a></li>
<li><span>5X </span><a href="https://www.amazon.com/gp/product/B072BXB2Y8/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>5.5MM Wire Connectors</span></a></li>
<li><span>1X </span><a href="https://www.amazon.com/gp/product/B07D49F3TW/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1"><span>5.5MM inner diameter adapter (for Starlink MST Hub)</span></a></li>
<li><span>1 X Cord</span></li>
</ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kylescholz.com/wp/the-elroy-lamp/">https://www.kylescholz.com/wp/the-elroy-lamp/</a></em></p>]]>
            </description>
            <link>https://www.kylescholz.com/wp/the-elroy-lamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24798764</guid>
            <pubDate>Fri, 16 Oct 2020 08:20:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part IVb: Work Hardening, or Hardly Working?]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24797376">thread link</a>) | @shalmanese
<br/>
October 15, 2020 | https://acoup.blog/2020/10/16/collections-iron-how-did-they-make-it-part-ivb-work-hardening-or-hardly-working/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/16/collections-iron-how-did-they-make-it-part-ivb-work-hardening-or-hardly-working/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we close out our four(and a half)-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">III</a>, <a href="https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/">IVa</a>, IVb) look at pre-modern iron and steel production, although I ought to note that there will be at least one addendum discussing pre-modern cast iron and crucible steel (Wootz) production.  Last week, we looked at the processes used to create steel from iron by introducing carbon (rather than the modern method of producing steel from pig iron by <em>removing</em> carbon).  That process changes the characteristics of the metal, since steel is harder and more elastic (bending and springing back, rather than bending and staying bent) than iron.</p>



<p>But the chemical composition of the iron or steel isn’t the only factor in determining its hardness and ductility: mechanical processes and heat treatment also alter the internal structure of the metal.  Since the pre-modern blacksmith works with both of these – mechanical processes through hammer and heat through the ‘heats’ of forging – he cannot afford to disregard the changes that both bring.  As we noted in part III, the blacksmith’s job is not merely to bring the metal into the necessary <em>shape</em> for its final application, he also has to get it there with the right <em>characteristics</em> – the correct balance of hardness, strength, ductility and elasticity to get the job done, whatever that job might be.</p>



<p>And I should note again that different tools – and indeed, different parts of the same tool – might have very different demands in this regard.  Metal files needed to be prodigiously hard so that they could abrade already quite hard materials.  The tips of chisels and picks also needed to be very hard, to keep their shape under repeated impacts, but not so hard that they broke; some ductility to absorb the energy of impact was needed.  Armor needed typically to only be somewhat hardened (though demands of this sort get higher with gunpowder) and can be fairly malleable; the armor plate that deforms elastically on impact still absorbs the strike.  Swords made varied demands: their significant length demanded strong steel with good elasticity to be able to spring back into proper shape after absorbing the forces of swings and impacts, while keeping a good cutting edge demanded a high degree of hardness (hardness being the characteristic that determines how sharp an edge can be and also how well that sharpness can be held during use).</p>



<p>So a blacksmith couldn’t simply maximize one trait at the expense of the others. Nor could they have just one kind of steel, with just one set of characteristics for every application.  Rather the learned techniques – copied and practiced during their apprenticeship – were developed, probably over generations, by experimentation to produce tools, weapons and armor each with its own unique ‘right blend’ of characteristics, though two major methods we will discuss today (along with, of course, carbon content, which we discussed last week).</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>Work Hardening</h2>



<p><strong>Work hardening</strong> refers to the tendency of metals, when hammered (or strained into any kind of plastic deformation) to become harder.  In its pristine state, the atoms of a metal are generally arranged in a crystal structure, joined by metallic bonds.  These lattices of atoms are neat and regular.  When that neat, regular lattice of atoms is strained, resulting in plastic (rather than elastic) deformation, those neat regular lattices get scrunched and bent and otherwise dislocated.  This happens in iron, but also in most metals – indeed, work hardening is <em>much more</em> important in bronze-work than it is in iron-work, though it cannot be neglected in either.</p>



<p>That dislocation makes the metal resistant to further deformation (plastic <em>or</em> elastic), both increasing the hardness of the metal and its yield strength (the amount of energy you need to apply for plastic, rather than elastic deformation to take place), but at the same time makes the metal less malleable and more brittle (that is, more likely to break than bend).  This is a property that must have been apparent to the earliest copper-smiths: as they hammered their copper into shape, each blow made the metal slightly more resistant to hammering, until eventually it would refuse to budge almost completely (and possibly break instead).  But the same process works for iron, though because of the different production process for iron, it has to be a touch more intentional.</p>



<p>It is possible to reset this process through a process called <strong>annealing</strong>.  When a work hardened metal is heated up, the energy provided by the heat allows the atoms to break and reform their bonds, causing the crystal structure to return to its normal lattice and removing the various dislocations (while retaining its new shape).  To completely anneal iron, it is heated up to its annealing temperature (which varies based on the carbon content, as you can see in the chart below) and held there for an extended period, which will cause it to get a soft as possible for the given iron and carbon content.  This can be very handy if the iron needs to be cold worked (see below).</p>



<div><figure><img loading="lazy" data-attachment-id="4840" data-permalink="https://acoup.blog/full_annealing_temp_range/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png" data-orig-size="314,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="full_annealing_temp_range" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png?w=314" src="https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png?w=314" alt="" width="485" height="318" srcset="https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png 314w, https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/full_annealing_temp_range.png?w=300 300w" sizes="(max-width: 485px) 100vw, 485px"><figcaption><a href="https://en.wikipedia.org/wiki/Annealing_(metallurgy)#/media/File:Full_annealing_temp_range.PNG">Via Wikipedia</a>, a chart of the temperature ranges for annealing, which vary based on the carbon content of the iron.</figcaption></figure></div>



<p>If the iron is not held at the high temperature, but is allowed to cool slowly in the air, it is said to be <em>normalized</em> (this process, <em><strong>normalization</strong></em>, is a subset of annealing).  As with full annealing, the heating process works out all of the little strains in metal (heats for this process range from 700 to 900°C), but by cooling it slowly afterwards (rather than holding it at a high temperature), it causes the actual size of the atomic lattice of the metal to shrink (the technical term is ‘grain refinement’ as the individual grains of the lattice are ‘refined’ – meaning ‘get smaller’), which results in a metal <em>somewhat</em> harder than in a fully annealed state.  Normalization is an important step for metal that is going to be subsequently heat treated as well.</p>



<p>Now the attentive reader will be thinking, “but wait, if heating the metal up to forging heat and letting it cool in the air resets the work hardening process – well, we’re doing that every time we heat the metal for forging.”  Indeed!  <strong>Hot</strong> <strong>working </strong>(which is what we’ve been describing so far with forging) generally does not meaningfully work harden metal for this very reason.  And for a smith working with good steel that is going to be <em>heat treated</em> (which we’ll discuss in a minute) this doesn’t matter a whole lot.  </p>



<p>But – for reasons which we’ll discuss – iron with very low carbon contents <em>cannot</em> be heat treated for hardness.  <strong>For a smith working with nearly pure (no carbon) iron, work hardening is his best option for increasing hardness and yield strength.</strong>  In this case, the iron object would typically be brought essentially to its final shape and then finished by being hammered <em>cold</em> (‘<strong>cold working</strong>‘).  While copper and bronze are generally soft enough to be almost entirely cold worked, iron really isn’t, except in fairly thin sheets, so the bulk of the actual <em>shaping</em> will still be done with hot forging, but with a final phase of cold hammering which will induce work hardening (and also, incidentally, can remove tool marks from the hot working, which might be cosmetically desirable).</p>



<h2>Heat Treatment Basics</h2>



<p>The changes steel undergoes when it is heated and cools can also alter its characteristics.  Because, as we’ll see, a big part of the effect of heat treatment has to do with the carbon atoms diffused within the crystalline iron structure of steel, pure iron and low carbon steel cannot be effectively heat treated and has to instead be work hardened in order to achieve similar results.  Heat treatment allows the blacksmith fairly fine control over the hardness, strength and ductility of the steel and can even allow for different parts of a single steel object to be hardened to different degrees.</p>



<p>For high-carbon steel, the heat treatment cycle is often called ‘tempering and quenching’ although as we’ll see it would perhaps be more accurate to call the process <em><strong>hardening, quenching and tempering</strong></em> (and then quenching one more time) to get the correct order.  It is something of an irony that first, intense <em>quenching</em> of raw, red-hot steel (the second quenching is much less dramatic as it occurs at much lower temperatures) – almost always shown as the <em>final</em> step in blacksmithing in film or video games – is essentially never the final step, for reasons that will soon become apparent.</p>



<p>First, some complicated metallurgy and then we’ll get to the actual real world processes a blacksmith would use.  High carbon steel is initially a mix of two kinds of iron, <a href="https://en.wikipedia.org/wiki/Allotropes_of_iron"><strong>ferrite</strong> </a>and <strong><a href="https://en.wikipedia.org/wiki/Cementite">cementite</a></strong>, the former being a cubic atomic structure of pure iron, whereas the later is an iron-carbide (Fe<sub>3</sub>C for the curious).  If that steel is heated above 912°C (but not melted), something interesting starts to happen: the ferrite structure changes into <strong><a href="https://en.wikipedia.org/wiki/Austenite">austenite</a></strong>.  Avoiding the deep weeds of metallurgy here, all we need to know is that austenite is a <em>different</em> cube of iron that is able to absorb carbon atoms, pulling them out of the cementite and trapping them inside the individual austentite structures.</p>



<figure><img data-attachment-id="4836" data-permalink="https://acoup.blog/1920px-ironalfairongamma-svg_/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png" data-orig-size="1920,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1920px-ironalfairongamma.svg_" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/10/1920px-ironalfairongamma.svg_.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Austenite#/media/File:IronAlfa&amp;IronGamma.svg">Via Wikipedia</a>, the structure of ferrite (left, also called α-iron) vs. austenite (right, also called γ-iron).</figcaption></figure>



<p>Austenite is neat but unstable at room temperature without the addition of alloys (particularly nickel in stainless steel) that our blacksmith doesn’t have.  If the austenite is allowed to cool slowly, it will slowly reorder itself, forming back into cementite and ferrite, often in a layering pattern called <strong>pearlit…</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/16/collections-iron-how-did-they-make-it-part-ivb-work-hardening-or-hardly-working/">https://acoup.blog/2020/10/16/collections-iron-how-did-they-make-it-part-ivb-work-hardening-or-hardly-working/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/16/collections-iron-how-did-they-make-it-part-ivb-work-hardening-or-hardly-working/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24797376</guid>
            <pubDate>Fri, 16 Oct 2020 04:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UNIX Time-Sharing System (1974)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24797312">thread link</a>) | @chsasank
<br/>
October 15, 2020 | https://chsasank.github.io/classic_papers/unix-time-sharing-system.html | <a href="https://web.archive.org/web/*/https://chsasank.github.io/classic_papers/unix-time-sharing-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>Dennis M. Ritchie and Ken Thompson</span> |
    <time datetime="
      
        1974 July
      
    ">
      
        1974 July
      
    </time> |
    
    
      
          59
      
           minutes to read.
      
    
   
  </p><section>
    <blockquote>
  <p><strong>NOTE</strong>: This is <em>not</em> my article. This is a classic paper originally published in <em>Communications of the ACM</em>, 1974 by Dennis M. Ritchie and Ken Thompson. Blue highlights/annotations are my own.</p>
</blockquote>

<h2 id="abstract">Abstract</h2>

<p>UNIX is a general-purpose, multi-user, interactive operating system for the Digital Equipment Corporation PDP-11/40 and 11/45 computers. It offers a number of features seldom found even in larger operating systems, including: (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language select-able on a per-user basis; and (5) over 100 subsystems including a dozen languages. This paper discusses the nature and implementation of the file system and of the user command interface.</p>

<h2 id="1-introduction">1. Introduction</h2>

<p>There have been three versions of UNIX. The earliest version (circa 1969–70) ran on the Digital Equipment Corporation PDP-7 and -9 computers. The second version ran on the unprotected PDP-11/20 computer. This paper describes only the PDP-11/40 and /45 [l] system since it is more modern and many of the differences between it and older UNIX systems result from redesign of features found to be deficient or lacking.</p>

<p>Since PDP-11 UNIX became operational in February 1971, about 40 installations have been put into service; they are generally smaller than the system described here. Most of them are engaged in applications such as the preparation and formatting of patent applications and other textual material, the collection and processing of trouble data from various switching machines within the Bell System, and recording and checking telephone service orders. Our own installation is used mainly for research in operating systems, languages, computer networks, and other topics in computer science, and also for document preparation.</p>

<p>Perhaps the most important achievement of UNIX is to demonstrate that a powerful operating system for interactive use need not be expensive either in equipment or in human effort: UNIX can run on hardware costing as little as $40,000, and less than two man years were spent on the main system software. Yet UNIX contains a number of features seldom offered even in much larger systems. It is hoped, however, the users of UNIX will find that the most important characteristics of the system are its simplicity, elegance, and ease of use.</p>

<blockquote>
  <p>The most important achievement of UNIX is to demonstrate that a powerful operating system need not be expensive either in equipment or in human effort.
However, the users of UNIX will find that the most important characteristics of the system are its simplicity, elegance, and ease of use.</p>
</blockquote>

<p>Besides the system proper, the major programs available under UNIX are: assembler, text editor based on QED[2], linking loader, symbolic debugger, compiler for a language resembling BCPL[3] with types and structures (C), interpreter for a dialect of BASIC, text formatting program, Fortran compiler, Snobol interpreter, top-down compiler-compiler (TMG) [4], bottom-up compiler-compiler (YACC), form letter generator, macro processor (M6) [5], and permuted index program.</p>

<p>There is also a host of maintenance, utility, recreation, and novelty programs. All of these programs were written locally. It is worth noting that the system is totally self-supporting. All UNIX software is maintained under UNIX; likewise, UNIX documents are generated and formatted by the UNIX editor and text formatting program.</p>

<h2 id="2-hardware-and-software-environment">2. Hardware and Software Environment</h2>

<p>The PDP-11/45 on which our UNIX installation is implemented is a 16-bit word (8-bit byte) computer with 144 Kbytes of core memory; UNIX occupies 42K bytes. This system, however, includes a very large number of device drivers and enjoys a generous allotment of space for I/O buffers and system tables; a minimal system capable of running the software mentioned above can require as little as 50K bytes of core altogether.</p>

<p>The PDP-11 has a 1M byte fixed-head disk, used for filesystem storage and swapping, four moving-head disk drives which each provide 2.5M bytes on removable disk cartridges, and a single moving-head disk drive which uses removable 40M byte disk packs. There are also a high-speed paper tape reader-punch, nine-track magnetic tape,and D-tape (a variety of magnetic tape facility in which individual records may be addressed and rewritten). Besides the console typewriter, there are 14 variable-speed communications interfaces attached to 100-series datasets and a 201 dataset interface used primarily for spooling printout to a communal line printer. There are also several one-of-a-kind devices including a Picturephone® interface,a voice response unit, a voice synthesizer, a phototypesetter, a digital switching network, and a satellite PDP-11/20 which generates vectors, curves, and characters on a Tektronix 611 storage-tube display.</p>

<p>The greater part of UNIX software is written in the above-mentioned C language [6]. Early versions of the operating system were written in assembly language, but during the summer of 1973, it was rewritten in C. The size of the new system is about one third greater than the old. Since the new system is not only much easier to understand and to modify but also includes many functional improvements, including multiprogramming and the ability to share reentrant code among several user programs, we considered this increase in size quite acceptable.</p>

<h2 id="3-the-file-system">3. The File System</h2>

<p><span>
 S: Note how the paper considers files important. Unix exposes all the functionality through files.
</span></p>

<p>The most important job of UNIX is to provide a file system. From the point of view of the user, there are three kinds of files: ordinary disk files, directories, and special files</p>

<h3 id="31-ordinary-files">3.1 Ordinary Files</h3>

<p>A file contains whatever information the user places on it, for example symbolic or binary (object) programs. No particular structuring is expected by the system. Files of text consist simply of a string of characters, with lines demarcated by the new-line character. Binary programs are sequences of words as they will appear in core memory when the program starts executing. A few user programs manipulate files with more structure: the assembler generates and the loader expects an object file in a particular format. However, the structure of files is controlled by the programs which use them, not by the system.</p>

<blockquote>
  <p>A file contains whatever information the user places on it, for example symbolic or binary (object) programs. No particular structuring is expected by the system.</p>
</blockquote>

<h3 id="32-directories">3.2 Directories</h3>

<p>Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole. Each user has a directory of his own files; he may also create subdirectories to contain groups of files conveniently treated together. A directory behaves exactly like an ordinary file except that it cannot be written on by unprivileged programs, so that the system controls the contents of directories. However, anyone with appropriate permission may read a directory just like any other file.</p>

<blockquote>
  <p>Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole.</p>
</blockquote>

<p>The system maintains several directories for its own use. One of these is the <em>root</em> directory. All files in the system can be found by tracing a path through a chain of directories until the desired file is reached. The starting point for such searches is often the root. Another system directory contains all the programs provided for general use; that is, all the <em>commands</em>. As will be seen however, it is by no means necessary that a program reside in this directory for it to be executed.</p>

<p><span>
 S: This is a succinct description of path system of unix and Linux
</span></p>

<p>Files are named by sequences of 14 or fewer characters. When the name of a file is specified to the system, it may be in the form of a <em>path name</em>, which is a sequence of directory names separated by slashes <code>/</code> and ending in a file name. If the sequence begins with a slash, the search begins in the root directory. The name <code>/alpha/beta/gamma</code> causes the system to search the root for directory <code>alpha</code>, then to search <code>alpha</code> for <code>beta</code>, finally to find <code>gamma</code> in <code>beta</code>. <code>gamma</code> may be an ordinary file, a directory, or a special file. As a limiting case, the name <code>/</code> refers to the root itself.</p>

<p>A path name not starting with <code>/</code> causes the system to begin the search in the user’s current directory. Thus, the name <code>alpha/beta</code> specifies the file named <code>beta</code> in subdirectory <code>alpha</code> of the current directory. The simplest kind of name, for example <code>alpha</code>, refers to a file which itself is found in the current directory. As another limiting case, the null file name refers to the current directory.</p>

<p>The same nondirectory file may appear in several directories under possibly different names. This feature is called <em>linking</em>; a directory entry for a file is sometimes called a link. UNIX differs from other systems in which linking is permitted in that all links to a file have equal status. That is, a file does not exist within a particular directory; the directory entry for a file consists merely of its name and a pointer to the information actually describing the file. Thus a file exists independently of any directory entry, although in practice a file is made to disappear along with the last link to it.</p>

<blockquote>
  <p>UNIX differs from other systems in which linking is permitted in that all links to a file have equal status.</p>
</blockquote>

<p>Each directory always has at least two entries. The name in each directory refers to the directory itself. Thus a program may read the current directory under the name <code>.</code> without knowing its complete path name. The name <code>..</code> by convention refers to the parent of the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chsasank.github.io/classic_papers/unix-time-sharing-system.html">https://chsasank.github.io/classic_papers/unix-time-sharing-system.html</a></em></p>]]>
            </description>
            <link>https://chsasank.github.io/classic_papers/unix-time-sharing-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24797312</guid>
            <pubDate>Fri, 16 Oct 2020 04:00:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Luhmann's Original Zettelkasten Digitalized]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24794569">thread link</a>) | @nextos
<br/>
October 15, 2020 | https://niklas-luhmann-archiv.de/bestand/zettelkasten/zettel/ZK_1_NB_1_1_V | <a href="https://web.archive.org/web/*/https://niklas-luhmann-archiv.de/bestand/zettelkasten/zettel/ZK_1_NB_1_1_V">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://niklas-luhmann-archiv.de/bestand/zettelkasten/zettel/ZK_1_NB_1_1_V</link>
            <guid isPermaLink="false">hacker-news-small-sites-24794569</guid>
            <pubDate>Thu, 15 Oct 2020 21:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beware the Casual Polymath]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24793546">thread link</a>) | @elsewhen
<br/>
October 15, 2020 | https://applieddivinitystudies.com/2020/09/28/polymath/ | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/2020/09/28/polymath/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p>We live in times of great disaggregation, and yet, seem to learn increasingly from generalists.</p>
<p>In the past, an expert in one field of Psychology might have been forced to teach a broad survey class. Today, you could have each lecture delivered by the world’s leading expert.</p>
<p>Outside of academia, you might follow one writer’s account to learn about SaaS pricing, another to understand the intricacies of the electoral college, and yet another to understand personal finance. In economic terms, content disaggregation enabled by digital platforms ought to create efficiencies through intellectual hyper-specialization.</p>
<p>Instead, we have the endless hellscape of the casual polymath. A newsletter about venture capital will find time to opine on herd immunity. The tech blog you visit to learn about data science is also your source of financial strategies for early retirement. The Twitter account you followed to understand politics now seems more focused on their mindfulness practice. We have maxed out variety of interests within people, at the cost of diversity across them.</p>
<p>It’s not difficult to imagine how this happened. The flip side of disaggregation is that each would-be expert is able to read broadly as well. The world of atomized content through hyper-specialization isn’t a stable equilibrium. We are all casual polymaths now.</p>
<p>As romantic as the idea seems, I worry it’s grossly suboptimal. Sure, there are cases where combining ideas from disparate fields can lead to new insight, but today’s generalists are not curating a portfolio of skills so much as they are stumbling about. <strong>Behavioral Econ is the love child of economics and psychology, early AI researchers maintained a serious interest in cognitive science. What exactly are your cursory interests in space exploration, meta-science and bayesian statistics preparing you for?</strong></p>
<p>I understand that we can sometimes only “connect the dots looking backwards”. Perhaps there is valuable work in a statistical meta-analysis of aerospace research. But that’s only true if you’re going into some degree of depth in each field.</p>
<p>None of this is meant to dissuade you from becoming a polymath, just to be a little more distrustful of others who claim to be.</p>
<h4 id="1-Polymaths-use-status-in-one-field-to-gain-capital-in-another"><a href="#1-Polymaths-use-status-in-one-field-to-gain-capital-in-another" title="1. Polymaths use status in one field to gain capital in another"></a>1. Polymaths use status in one field to gain capital in another</h4><p>In 1947, with financial support from his father, JFK won a seat in the US House of Representatives with no political experience. As his father would later remark: “With the money I spent, I could have elected my chauffeur.”</p>
<p>If you saw JFK in 1947, you might have thought “wow, he’s rich, his father was the Chairman of the SEC, and he’s a member of the US House of Representatives, what an impressive guy!” A decade later, you could have added “<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Profiles_in_Courage">Pulitzer Prize winning author</a>“ to that list.</p>
<p>But this reasoning is totally backwards. JFK was only able to become a politician because of his wealth. In fact, his father only became SEC Chairman after extensive political donations to FDR. And obviously, his book was ghost-written by his speechwriter.</p>
<p>So you’re justified in being impressed by exactly one accomplishment, and everything else ought to be discounted.</p>
<p>We already understand this intuitively, but only in a limited set of cases. If a pop star becomes an actor, we are not impressed by their wide range of talents. Instead, we understand that popularity is a semi-fungible good.</p>
<h4 id="2-Polymaths-are-abusing-Gell-Mann-Amnesia"><a href="#2-Polymaths-are-abusing-Gell-Mann-Amnesia" title="2. Polymaths are abusing Gell-Mann Amnesia"></a>2. Polymaths are abusing Gell-Mann Amnesia</h4><p>As I wrote <a href="https://applieddivinitystudies.com/2020/09/17/markets-nasa/">earlier</a>:<br><em>You go on Twitter, you read someone’s tweet on a subject you know something about, and see that the author has no understanding of the facts. So you keep scrolling and read their tweets about cancel culture, space exploration and criminal justice reform, totally forgetting how wrong they were before.</em></p>
<p><em>In this sense, every tweet is an option with asymmetric returns. If you’re right, you cash out; if you’re wrong, everyone forgets and you lose nothing. The incentive is to ramp up variance, make bold claims in a variety of areas, and hope you’re right some of the time.</em></p>
<p>Accordingly, authors will make bold claims in a variety of areas, and you may be inclined to believe them even after seeing how wrong they are. Unless you are also a polymath, and a polymath in the same domains, you will probably not be capable of evaluating their competence.</p>
<p>Of course, you might rely on external opinions, which brings us to the last point.</p>
<h4 id="3-Polymaths-are-evaluated-by-non-polymaths"><a href="#3-Polymaths-are-evaluated-by-non-polymaths" title="3. Polymaths are evaluated by non-polymaths"></a>3. Polymaths are evaluated by non-polymaths</h4><p>Leonardo da Vinci is the most famous polymath of all time and the model omni-competent Renaissance Man.</p>
<p><strong>Leonardo da Vinci also didn’t know math.</strong> Issacson’s book details numerous episodes in which:</p>
<ul>
<li>Leonardo comes up with a million dollar business idea, later realizes his basic arithmetic was off by more than an order of magnitude.</li>
<li>Leonardo claims to be a military engineer to gain acceptance at the Milanese court. In fact, he has never built any kind of weapon or siege device.</li>
<li>Leonardo claims to have solved the ancient puzzle of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Doubling_the_cube">doubling the cube</a>. Except his “solution” only works if you can’t tell the difference between the square root of 3 and cube root of 2.</li>
</ul>
<p>This last example is especially notable because Issacson himself doesn’t seem to catch it, instead uncritically praising Leonardo’s discovery. [Details in Appendix]</p>
<p>And yet <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">Wikipedia writes</a>:<br><em>…many historians and scholars regard Leonardo as the prime exemplar of the “Renaissance Man” or “Universal Genius”, an individual of “unquenchable curiosity” and “feverishly inventive imagination.”[6] He is widely considered one of the most diversely talented individuals ever to have lived.[10] According to art historian Helen Gardner, the scope and depth of his interests were without precedent in recorded history</em></p>
<p>Of course <strong>the inflation of his mathematical and engineering ability makes sense when you consider the that judges in question are predominantly art historians</strong>. Rather than as a Renaissance Man, Leonardo would be better regarded as an exceptional painter with various hobbies.</p>
<hr>
<p>While an expert in one domain may just be a savant with a “kooky knack”, mastering multiple unrelated skills feels like evidence of general intelligence, or in Leonardo’s case, “Universal Genius”. If someone is good at computer science, epidemiology and finance, surely we can trust their opinion on politics as well?</p>
<p>Except what’s really happening is that we’ve chosen to privilege certain combinations of skills as impressive, while taking others for granted.</p>
<p>A physicist who studies math, can write code for analysis and understand complex systems is not hailed as a polymath. They’re just seen as obtaining the basic set of skills required for their profession. Similarly, a basketball player who can run, shoot and block is not any kind of “polymath”.</p>
<p>You might object that this is because physics and basketball are specific clusters of skills. Running quickly is more closely related to throwing a ball than software engineering is to epidemiology.</p>
<p>This might be true in specific cases, but in general, it’s a coincidence of which skills cluster into occupations. A small business owner who manages their own books, handles sales and manufactures their product is not considered a polymath, no matter how distinct those fields might be. Computational social scientists are not considered polymaths, neither is an OnlyFans creator who single handedly runs everything from marketing to modeling, nor a translator who has to master ancient greek, dive deeply into historical context, and also be a great poet in their own right.</p>
<hr>
<p>To be clear, there are still good reasons to learn a variety of skills. As Marc Andreessen <a target="_blank" rel="noopener" href="https://pmarchive.com/guide_to_career_planning_part2.html">put it</a>:<br><em>All successful CEO’s [sic] are like this. They are almost never the best product visionaries, or the best salespeople, or the best marketing people, or the best finance people, or even the best managers, but they are top 25% in some set of those skills, and then all of a sudden they’re qualified to actually run something important.</em></p>
<p>He goes on to provide examples, listing Communication, Management, Sales, Finance and International Experience.</p>
<p>I’m broadly in agreement. Learning these skills will probably benefit your career. Just understand that no one has ever been hailed as a polymath because they’re good at both communication and management. They’re just considered basically competent at their job.</p>
<p>I don’t want to dissuade anyone from learning broadly and reading widely. Of course athletes should cross train, and intellectuals should read outside their domain, and software engineers might benefit from public speaking classes.</p>
<p>My point is that we should not trust or glorify people on the basis of their apparent “Universal Genius”. Having a variety of interests is no more a sign of generalized intelligence than being able to walk and chew gum. And if someone does appear to have accomplishments in a variety of domains with fungible currency, their total status should not be a sum or multiple, but merely the status of their single most impressive feat.</p>
<p>So go read your SaaS/Meta-Science/Aerospace blog and revel in the genuine joy of intellectual curiosity. As Tyler Cowen would say, I’m just here to lower the status of polymaths.</p>
<h2 id="Appendix-Doubling-the-Cube"><a href="#Appendix-Doubling-the-Cube" title="Appendix: Doubling the Cube"></a>Appendix: Doubling the Cube</h2><p>Here’s the full quote from Issacson:<br><em>These obsessions led Leonardo to an ancient riddle described by Vitruvius, Euripides, and others. Faced with a plague in the fifth century BC, the citizens of Delos consulted the oracle of Delphi. They were told that the plague would end if they found a mathematical way to precisely double the size of the altar to Apollo, which was shaped as a cube. When they doubled the length of each side, the plague worsened; the Oracle explained that by doing so they had increased the size of the cube eightfold rather than doubling it. (For example, a cube with two-foot sizes has eight times the volume of a cube with one-foot sides.) To solve the problem geometrically required multiplying the length of each side by the cube root of 2.</em></p>
<p><em><strong>Despite his note to himself to “learn the multiplication …</strong></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://applieddivinitystudies.com/2020/09/28/polymath/">https://applieddivinitystudies.com/2020/09/28/polymath/</a></em></p>]]>
            </description>
            <link>https://applieddivinitystudies.com/2020/09/28/polymath/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24793546</guid>
            <pubDate>Thu, 15 Oct 2020 20:34:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Stupidity Expanding? Some Hypotheses]]>
            </title>
            <description>
<![CDATA[
Score 284 | Comments 270 (<a href="https://news.ycombinator.com/item?id=24793334">thread link</a>) | @onemind
<br/>
October 15, 2020 | https://www.greaterwrong.com/posts/BHqzGLNyQHjDXhEc8/is-stupidity-expanding-some-hypotheses | <a href="https://web.archive.org/web/*/https://www.greaterwrong.com/posts/BHqzGLNyQHjDXhEc8/is-stupidity-expanding-some-hypotheses">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>To be exÂ­plained: <strong>It feels to me that in reÂ­cent years, peoÂ­ple have gotÂ­ten stupiÂ­der, or that stupid has gotÂ­ten bigÂ­ger, or that the parts of peoÂ­ple that were always stupid have gotÂ­ten louder, or someÂ­thing like that.</strong></p><p>Iâ€™ve come up with a suite of hyÂ­potheÂ­ses to exÂ­plain this (with a litÂ­tle help from my friends). I thought Iâ€™d throw them out here to see which ones the wise crowd here think are most likely. Bonus points if you come up with some new ones. Gold stars if you can rule some out based on exÂ­istÂ­ing data or can proÂ­pose tests by which they might be renÂ­dered more or less plauÂ­siÂ­ble.</p><p>The hyÂ­potheÂ­ses come in two broad famÂ­iÂ­lies: 1) my feelÂ­ing that stupid is exÂ­pandÂ­ing is an illuÂ­sion or misÂ­perÂ­cepÂ­tion, and 2) stupid is exÂ­pandÂ­ing and here is why:</p><ol><li><p>I have beÂ­come more atÂ­tuned to stuÂ­pidity for [reaÂ­sons], so even though there is no more of it than usual, it stands out more to me. (<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases#Frequency_illusion">Baader-MeinÂ­hof pheÂ­nomenon</a>)</p></li><li><p>What used to look like non-stuÂ­pidity was acÂ­tuÂ­ally wideÂ­spread conÂ­forÂ­mity to a comÂ­mon menu of foolÂ­ishÂ­nesses. ToÂ­day the culÂ­tural beaÂ­cons of reÂ­spectable idiocy have been overÂ­thrown and there is inÂ­creasÂ­ing diÂ­verÂ­sity in foolÂ­ishÂ­ness. DiverÂ­gent fools seem more foolÂ­ish to each other when in fact weâ€™re all just as stupid as weâ€™ve always been.</p></li><li><p>Iâ€™m runÂ­ning in stupiÂ­der cirÂ­cles than I used to for some reaÂ­son, while in genÂ­eral things havenâ€™t changed much.</p></li><li><p>I am the one getÂ­ting stupiÂ­der, or was stupid all along, and so I donâ€™t have the cogÂ­niÂ­tive strength to acÂ­cuÂ­rately judge the stuÂ­pidity level around me, and just hapÂ­pen to be thinkÂ­ing it is getÂ­ting worse beÂ­cause I donâ€™t know any betÂ­ter. (<a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect">DunÂ­ning-Kruger effect</a>)</p></li><li><p>PeoÂ­ple arenâ€™t getÂ­ting any stupiÂ­der, itâ€™s just that the arÂ­tifiÂ­cial inÂ­telÂ­liÂ­gence of the bots Iâ€™m misÂ­takÂ­ing for peoÂ­ple on-line isnâ€™t all that good yet.</p></li><li><p>Theyâ€™re not getÂ­ting stupiÂ­der; Iâ€™m just getÂ­ting more conÂ­ceited.</p></li><li><p>PeoÂ­ple orÂ­diÂ­narÂ­ily use differÂ­ent modes of thinkÂ­ing in differÂ­ent comÂ­muÂ­niÂ­caÂ­tions conÂ­texts. In some, findÂ­ing the truth is imÂ­porÂ­tant and so they use raÂ­tioÂ­nal inÂ­telÂ­liÂ­gence. In othÂ­ers, decÂ­oÂ­raÂ­tive disÂ­play, ritÂ­ual, asÂ­sertÂ­ing domÂ­iÂ­nance or subÂ­misÂ­sion, disÂ­playÂ­ing tribal alleÂ­giances, etc. are more imÂ­porÂ­tant and so they use modes more apÂ­proÂ­priÂ­ate to those things. Itâ€™s not that peoÂ­ple are getÂ­ting stupiÂ­der, but that these non-inÂ­telÂ­liÂ­gent forms of comÂ­muÂ­niÂ­caÂ­tion (a) are more amÂ­plified than they used to be, (b) more comÂ­monly pracÂ­ticed than they used to be, or (c) are more promiÂ­nent where I hapÂ­pen to be trainÂ­ing my atÂ­tenÂ­tion.</p></li><li><p>I am acÂ­quiring greater wisÂ­dom with age as I ought, but the avÂ­erÂ­age age of the typÂ­iÂ­cal perÂ­son I enÂ­counter stays the same so they canÂ­not keep up. Iâ€™m noticÂ­ing the conÂ­trast inÂ­creasÂ­ing but misÂ­atÂ­tributÂ­ing it. (David WoodÂ­erÂ­son effect)</p></li><li><p>PeoÂ­ple use inÂ­telÂ­liÂ­gence for differÂ­ent things in differÂ­ent eras. Just as lanÂ­guage, muÂ­sic, art changes over time, so does thinkÂ­ing. Iâ€™m just not keepÂ­ing up, and asÂ­sumÂ­ing beÂ­cause kids these days canâ€™t dance the menÂ­tal Charleston that they canâ€™t dance at all.</p></li><li><p>We were just as stupid back in the day, and I just donâ€™t reÂ­memÂ­ber it that way. (<a href="https://en.wikipedia.org/wiki/Rosy_retrospection">Rosy retÂ­roÂ­specÂ­tion</a>)</p></li><li><p>There is no truth, only power. What Iâ€™ve been inÂ­terÂ­pretÂ­ing as truth and raÂ­tioÂ­nalÂ­ity has been my own atÂ­tempt to alÂ­ign my thinkÂ­ing with the poliÂ­tiÂ­cal clique that was in power when I was beÂ­ing edÂ­uÂ­cated. What Iâ€™m inÂ­terÂ­pretÂ­ing as risÂ­ing stuÂ­pidity has been the colÂ­lapse in power and staÂ­tus of that clique and the poliÂ­tiÂ­cal obÂ­soÂ­lesÂ­cence of the vaÂ­riÂ­ety of â€œtruthâ€� and â€œraÂ­tioÂ­nalÂ­ityâ€� I inÂ­terÂ­nalÂ­ized as a child. Those pomo philosoÂ­phers were right all along.</p></li><li><p>StuÂ­pidity doesnâ€™t have stayÂ­ing power, relÂ­aÂ­tive to non-stuÂ­pidity: thereâ€™s a sort of surÂ­vival of the fittest in which vast amounts of exÂ­presÂ­sions are beÂ­ing proÂ­duced all the time, most of which are stupid and fall away, but the ones that arenâ€™t stupid are more likely to surÂ­vive in memÂ­ory and to be mainÂ­tained in the hisÂ­torÂ­iÂ­cal record. This biÂ­ases things to make it apÂ­pear that the proÂ­porÂ­tion of non-stupid exÂ­presÂ­sions was lower in the past than it reÂ­ally was.</p></li><li><p>PoliÂ­tics and conÂ­sumer capÂ­iÂ­talÂ­ism are moÂ­tiÂ­vated to idenÂ­tify and tarÂ­get stupid peoÂ­ple so as to take adÂ­vanÂ­tage of them, so they have creÂ­ated sysÂ­tems that enÂ­courage stupid peoÂ­ple to self-idenÂ­tify and make themÂ­selves promiÂ­nent so that they can be picked off; that Iâ€™m noticÂ­ing this is just a side effect.</p></li></ol><ol><li><p>PeoÂ­ple have given up tryÂ­ing to unÂ­derÂ­stand things in this messed-up timeline and are just rolÂ­ling with it; itâ€™s a sort of inÂ­telÂ­lecÂ­tual learned helÂ­plessÂ­ness that apÂ­pears as exÂ­pandÂ­ing stuÂ­pidity.</p></li><li><p>StuÂ­pidity has its fashÂ­ions, and the latÂ­est fashÂ­ions are more in-your-face than they used to be.</p></li><li><p>PharÂ­maÂ­ceuÂ­tiÂ­cals that have beÂ­come popÂ­uÂ­lar in reÂ­cent decades have cogÂ­niÂ­tive side effects that are difficult to meaÂ­sure in the inÂ­diÂ­viÂ­dÂ­ual but cause noÂ­ticeÂ­able effects in the agÂ­greÂ­gate.</p></li><li><p>Itâ€™s real, and itâ€™s probÂ­aÂ­bly someÂ­thing in our diet, for exÂ­amÂ­pleâ€¦</p></li><li><p>Itâ€™s real, and itâ€™s probÂ­aÂ­bly all that exÂ­tra CO<sub>2</sub> in the atÂ­moÂ­sphere.</p></li><li><p>Itâ€™s real, and itâ€™s probÂ­aÂ­bly toxÂ­oÂ­plasÂ­moÂ­sis meow.</p></li><li><p>Itâ€™s real, and itâ€™s probÂ­aÂ­bly some other sort of change in our maÂ­teÂ­rial enÂ­viÂ­ronÂ­ment (exÂ­cludÂ­ing culÂ­tural changes).</p></li><li><p>Back in the day, when a perÂ­son had a stupid idea, they would be reÂ­lucÂ­tant to put it forÂ­ward as their own. Rather, they would wait to see if someÂ­one else would voice the idea so they could just agree with it. This used to be relÂ­aÂ­tively rare, but now you just have to google â€œ[my stupid idea]â€� to find that someÂ­one or other has said it first, and then youâ€™re off to the races.</p></li><li><p>If you have a smart idea, you may also be smart enough to reÂ­alÂ­ize that itâ€™s not useÂ­ful right now /â€‹ has already been betÂ­ter said /â€‹ is inÂ­apÂ­proÂ­priÂ­ate in conÂ­text. If you have a dumb idea, such thoughts may be less likely to ocÂ­cur to you due to the aura of dumbth that surÂ­rounds the dumb idea and reÂ­pels senÂ­siÂ­ble conÂ­sidÂ­erÂ­aÂ­tions. Back when exÂ­presÂ­sions of stuÂ­pidity were mostly ephemeral, this didnâ€™t matÂ­ter much, but now that they acÂ­quire inÂ­stant perÂ­maÂ­nence and global reach, they apÂ­pear to swamp evÂ­eryÂ­thing else.</p></li><li><p>Stupid choices used to reÂ­liÂ­ably have unÂ­deÂ­sirÂ­able reÂ­sults; now there is more of a disÂ­conÂ­nect where peoÂ­ple are shielded from the reÂ­sults of their stupid choices, or even reÂ­warded for them (man lights himÂ­self on fire in an easÂ­ily-forseeÂ­able misÂ­adÂ­venÂ­ture, beÂ­comes YouTube legÂ­end). So peoÂ­ple may be apÂ­pearÂ­ing stupid not as a reÂ­sult of beÂ­ing stupid but as the reÂ­sult of a perÂ­verse cost-benefit analÂ­yÂ­sis. PeoÂ­ple are no dumber than they used to be, but for [reaÂ­sons] it has beÂ­come adÂ­vanÂ­taÂ­geous to disÂ­play stuÂ­pidity and so smart peoÂ­ple someÂ­times mimic idiocy so as to reap such adÂ­vanÂ­tages. The smarter they are, the quicker they caught on to this and the betÂ­ter mimics they are, so this makes it look as though the smart peoÂ­ple are beÂ­ing reÂ­placed by moÂ­rons, when reÂ­ally itâ€™s more a matÂ­ter of camÂ­ouÂ­flage.</p></li><li><p>The way we edÂ­uÂ­cate chilÂ­dren went seÂ­riÂ­ously sideÂ­ways a while back, and so, yeah, stupid hapÂ­pened.</p></li><li><p>Newly-popÂ­uÂ­lar meÂ­dia and/â€‹or its conÂ­tent is someÂ­how diÂ­rectly damÂ­agÂ­ing to menÂ­tal facÂ­ulÂ­ties.</p></li><li><p>Changes in meÂ­dia/â€‹comÂ­muÂ­niÂ­caÂ­tions techÂ­nolÂ­ogy alÂ­low stupid peoÂ­ple to be much more promiÂ­nent than they used to be and/â€‹or comÂ­parÂ­aÂ­tively muffle smarter peoÂ­ple.</p></li><li><p>SoÂ­cial meÂ­dia dyÂ­namÂ­ics erode reaÂ­sonÂ­ing and truth-seekÂ­ing while reÂ­wardÂ­ing cogÂ­niÂ­tive biÂ­ases.</p></li><li><p>The news meÂ­dia were doÂ­ing a betÂ­ter job than we reÂ­alÂ­ized in filÂ­terÂ­ing out crap and conÂ­texÂ­tuÂ­alÂ­izÂ­ing new inÂ­forÂ­maÂ­tion inÂ­telÂ­liÂ­gently for us, and as the inÂ­terÂ­net deÂ­stroyed the busiÂ­ness model beÂ­hind inÂ­telÂ­liÂ­gent reÂ­portÂ­ing, we failed to come up with a subÂ­stiÂ­tute in time to preÂ­vent idiocy from filling the void and itâ€™s too big a job for inÂ­diÂ­viÂ­dÂ­uÂ­als to do withÂ­out inÂ­stiÂ­tuÂ­tional asÂ­sisÂ­tance.</p></li></ol></div></div>]]>
            </description>
            <link>https://www.greaterwrong.com/posts/BHqzGLNyQHjDXhEc8/is-stupidity-expanding-some-hypotheses</link>
            <guid isPermaLink="false">hacker-news-small-sites-24793334</guid>
            <pubDate>Thu, 15 Oct 2020 20:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Fired Using Switch Statements and Statement Expressions (2016)]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24790218">thread link</a>) | @lelf
<br/>
October 15, 2020 | https://blog.robertelder.org/switch-statements-statement-expressions/ | <a href="https://web.archive.org/web/*/https://blog.robertelder.org/switch-statements-statement-expressions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>


<h5>2016-10-27 - By Robert Elder</h5>


<p>Updated Oct 27, 2016: Fixed sample code comments in coroutine example as <a href="https://www.reddit.com/r/programming/comments/59p689/how_to_get_fired_using_switch_statements/d9ad8uc/">per suggestion</a>, edited text to note <a href="https://www.reddit.com/r/programming/comments/59p689/how_to_get_fired_using_switch_statements/d9aex9v/">D's similar behaviour</a>.</p>
<p>Updated Oct 28, 2016: <a href="https://news.ycombinator.com/item?id=12815726">Added missing colon.</a>, corrected <a href="https://news.ycombinator.com/item?id=12815814">Duff's device example</a>.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It doesn't matter whether you're trying to achieve job security; impressing others by showing them how smart you are; or passive aggressively asserting your dominance over a code base, writing unmaintainable code has a number of practical applications. &nbsp;One extremely unmaintainable and bug-ridden technique for C programming involves using both switch statements and statement expressions together.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this article, we will discuss how you can leverage switch statements and statement expressions to produce C code that is so difficult to understand, you'll need to look at the assembly to figure out what it does. &nbsp;Many of the examples of syntax in this article are not standards compliant or they won't pass even the simplest of static analysis tests. &nbsp;That should be ok though, because writing many of these examples in your company's code base will probably end up getting you fired anyway.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Let's start by reviewing the humble switch statement that we all know and love:</p>

<p><code><pre><span>int</span> i = ...;
<span>switch</span>(i){
	<span>case</span> <span>0</span>:{
		...
		<span>break</span>;
	}<span>case</span> <span>1</span>:{
		...
		<span>break</span>;
	}<span>case</span> <span>2</span>:{
		...
		<span>break</span>;
	}<span>default</span>:{
		...
	}
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The above is what most people are used to thinking about when 'switch statements' are mentioned in C. &nbsp;The rough idea is that switch statements are a sort of more appealing alternative to using lots of 'else if' statements when checking for some disjoint property. &nbsp;Some of you may be surprised to learn that the following is also a valid switch statement:</p>

<p><code><pre><span>int</span> i = ...;
<span>switch</span>(i){
        i++;
        <span>default</span>:{ }
        i++;
        <span>case</span> <span>0</span>:{
                <span>case</span> <span>3</span>: i;
        }
        <span>if</span>(i &lt; <span>10</span>){
                <span>case</span> <span>1</span>:{
                        <span>break</span>;
                }
                <span>for</span>(i=<span>0</span>; i &lt; <span>10</span>; i++){
                        <span>case</span> <span>2</span>:;
                }
        }
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It's worth pointing out that almost no other languages support switch statements the way that they work in C (although the <a href="https://en.wikipedia.org/wiki/D_(programming_language)">D language</a> is an example). &nbsp;Most other languages have a switch statement that works similar to the idea of a more appealing alternative to many 'else if' checks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A switch statement in C would be more appropriately called a 'goto field'. &nbsp;This means that the switch(...) part simply makes a decision about which label to branch to. &nbsp;After branching to that label nothing special happens related to the fact that you're inside a switch statement and the code will just keep executing whatever machine instructions come next. &nbsp;The one exception is, of course, the break statement which will jump to the point after the switch statement body. &nbsp;Here is an equivalent version of the switch statement written above using only ifs and gotos.</p>

<p><code><pre><span>int</span> i = ...;
<span>if</span>(i == <span>0</span>)
	<span>goto</span> label_0;
<span>if</span>(i == <span>1</span>)
	<span>goto</span> label_1;
<span>if</span>(i == <span>2</span>)
	<span>goto</span> label_2;
<span>if</span>(i == <span>3</span>)
	<span>goto</span> label_3;

<span>goto</span> label_default;

{
        i++;
        <span>label_default</span>:{ }
        i++;
        <span>label_0</span>:{
                <span>label_3</span>: i;
        }
        <span>if</span>(i &lt; <span>10</span>){
                <span>label_1</span>:{
                        <span>goto</span> break_from_switch;
                }
                <span>for</span>(i=<span>0</span>; i &lt; <span>10</span>; i++){
                        <span>label_2</span>:;
                }
        }
}
<span>break_from_switch</span>:
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you're already familiar with the famous <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff's device</a> the above this probably isn't news to you:</p>

<p><code><pre>
    <span>int</span> total_bytes = ...;
    <span>int</span> n = (total_bytes + <span>3</span>) / <span>4</span>;
    <span>switch</span> (total_bytes % <span>4</span>) {
            <span>case</span> <span>0</span>: <span>do</span> { *to = *from++;
            <span>case</span> <span>3</span>:      *to = *from++;
            <span>case</span> <span>2</span>:      *to = *from++;
            <span>case</span> <span>1</span>:      *to = *from++;
                    } <span>while</span> (--n &gt; <span>0</span>);
    }
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Drawing on Duff's device as inspiration you can use the unique behaviour of switch statements in C to implement coroutines:</p>

<p><code><pre><span>#include </span><span>&lt;stdio.h&gt;</span>

<span>#define coroutine_begin() </span><span>static</span><span> </span><span>int</span><span> state=</span><span>0</span><span>; </span><span>switch</span><span>(state) { </span><span>case</span><span> </span><span>0</span><span>:</span>
<span>#define coroutine_return(x) { state=</span><span>__LINE__</span><span>; </span><span>return</span><span> x; </span><span>case</span><span> </span><span>__LINE__</span><span>:; }</span>
<span>#define coroutine_finish() }</span>

<span>int</span> get_next(<span>void</span>) {
        <span>static</span> <span>int</span> i = <span>0</span>;
        coroutine_begin();
        <span>while</span> (<span>1</span>){
                coroutine_return(++i);
                coroutine_return(<span>100</span>);
        }
        coroutine_finish();
}

<span>int</span> main(<span>void</span>){
        printf(<span>"i is </span><span>%d</span><span>\n</span><span>"</span>, get_next()); <span>1</span>
        printf(<span>"i is </span><span>%d</span><span>\n</span><span>"</span>, get_next()); <span>100</span>
        printf(<span>"i is </span><span>%d</span><span>\n</span><span>"</span>, get_next()); <span>2</span>
        printf(<span>"i is </span><span>%d</span><span>\n</span><span>"</span>, get_next()); <span>100</span>
        <span>return</span> <span>0</span>;
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The example in this section draws on one found in <a href="http://www.chiark.greenend.org.uk/~sgtatham/coroutines.html">Coroutines in C by Simon Tatham</a>. &nbsp;The original source describes a few caveats of switch based coroutines that I won't discuss in this article.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If we resolve the macros, and indent the code a bit better, then remove some superfluous brackets and semicolons, the 'get_next' function becomes:</p>

<p><code><pre><span>#include </span><span>&lt;stdio.h&gt;</span>

<span>1234</span><span>4567</span>

<span>int</span> get_next(<span>void</span>) {
        <span>static</span> <span>int</span> i = <span>0</span>;
        <span>static</span> <span>int</span> state = <span>0</span>;
	<span>switch</span>(state) {
		<span>case</span> <span>0</span>:;
		<span>while</span>(<span>1</span>){
			state = <span>1234</span>;
			<span>return</span> ++i;
			<span>case</span> <span>1234</span>:;
			state = <span>4567</span>;
			<span>return</span> <span>100</span>;
			<span>case</span> <span>4567</span>:;
		}
        }
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The static variables are key here, because they allow us to communicate information between calls to the function 'get_next'. &nbsp;The switch statement effectively just gives us a convenient way to implement the goto statements that would be necessary to either jump to the start of the coroutine (state = 0), or the point just after the coroutine returns (state = 1234, and state = 4567). &nbsp;If you want to create more return/resume points you can simply add more calls to the 'coroutine_return' macro. &nbsp;You must also make sure that these calls appear between 'coroutine_begin' and 'coroutine_end'.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If the syntax of the case statements is throwing you off, just remember that</p>

<p><code><pre><span>case</span> <span>0</span>:;
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;does same thing as</p>

<p><code><pre><span>case</span> <span>0</span>: {
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The first represents a 'statement' with no expression, and the second represents a 'compound statement' with no declarations or expressions. &nbsp;Neither of these forms has a break statement, so execution will always just continue doing whatever is after the case label in the same way that a goto would work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now that we've seen how switch statements can get pretty weird, let's explore a few interesting examples of valid switch statement syntax that (depending on how much of a 1337 hacker you are) you may have never seen before:</p>

<p><code><pre>
<span>switch</span>(<span>0</span>);
</pre></code>

<code><pre>
<span>switch</span>(<span>0</span>)
	i++;
</pre></code>

<code><pre>
<span>switch</span>(<span>0</span>)
	<span>switch</span>(<span>0</span>)
		<span>switch</span>(<span>0</span>)
			<span>switch</span>(<span>0</span>)
				<span>switch</span>(<span>0</span>)
					<span>switch</span>(<span>0</span>);
</pre></code>

<code><pre>
<span>switch</span>(<span>0</span>)
	<span>case</span> <span>0</span>:;
</pre></code>

<code><pre><span>switch</span>(<span>0</span>)
	<span>case</span> <span>0</span>:
		<span>for</span>(i = <span>0</span>; i &lt; <span>10</span>; i++)
			<span>case</span> <span>1</span>:
				<span>for</span>(j = <span>0</span>; j &lt; <span>10</span>; j++)
					<span>case</span> <span>2</span>:
						<span>for</span>(k = <span>0</span>; k &lt; <span>10</span>; k++);
</pre></code>

<code><pre>
<span>switch</span>(<span>0</span>){
	<span>case</span> <span>0</span>:{
		<span>for</span>(i = <span>0</span>; i &lt; <span>10</span>; i++){
			<span>case</span> <span>1</span>:{
				<span>while</span>(j){
					<span>case</span> <span>2</span>:{
						<span>for</span>(k = <span>0</span>; k &lt; <span>10</span>; k++){
						}
					}
					j++;
				}
			}
		}
	}<span>case</span> <span>3</span>:{
		
	}<span>default</span>:{
		
	}
}
</pre></code>

<code><pre>


<span>switch</span>(i)
	<span>default</span>: <span>case</span> <span>0</span>: <span>case</span> <span>1</span>: <span>case</span> <span>2</span>: <span>case</span> <span>3</span>:;
</pre></code>

<code><pre>



<span>switch</span>(<span>0</span>){
	<span>case</span> UNIQUE_CASE_A:{
		<span>break</span>;
	}<span>case</span> UNIQUE_CASE_B:{
		<span>break</span>;
	}<span>case</span> SIMILAR_CASE1: <span>case</span> SIMILAR_CASE2: <span>case</span> SIMILAR_CASE3:{
		<span>break</span>;
	}
}
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html">Statement expressions</a> are a GNU extension that is not supported by the C standard, but they are supported by default in gcc and clang. &nbsp;They allow you to embed a compound statement within an expression. &nbsp;The value returned by the last expression is the value returned by the entire statement expression:</p>

<p><code><pre>
<span>int</span> i = <span>0</span>;

<span>int</span> j = ({<span>int</span> k; k = i + <span>1</span>; i;}<span>)</span>;
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You might ask "Why would you ever want to do such a thing?" &nbsp;There are a number of different answers and many of them are related to convenience: &nbsp;One use case is concerned with ensuring that expression statement side-effects are only evaluated once in the case of a function macro that may cause the expression to appear multiple times in the function macro body.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can stick statement expressions pretty much anywhere you could put a variable:</p>

<p><code><pre><span>#include </span><span>&lt;stdio.h&gt;</span>

<span>int</span> get_zero(<span>void</span>){ <span>return</span> <span>0</span>; }

<span>int</span> main(<span>void</span>){
        <span>0</span><span>9</span>
        <span>for</span>(<span>int</span> i = ({get_zero();}<span>)</span>; i &lt; <span>10</span>; i++<span>)</span>
                printf(<span>"</span><span>%d</span><span>\n</span><span>"</span>, i);
        <span>return</span> <span>0</span>;
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can do pretty much anything inside a statement expression that you could do in a regular compound statement:</p>

<p><code><pre><span>#include </span><span>&lt;stdio.h&gt;</span>

<span>int</span> main(<span>void</span>){
        <span>0</span><span>99</span>
        <span>int</span> i = ({<span>int</span> j = <span>0</span>; <span>for</span>(<span>int</span> i = <span>0</span>; i &lt; <span>100</span>; i++) j+=i; j;}<span>)</span>;
        printf(<span>"Sum is </span><span>%d</span><span>\n</span><span>"</span>, i);
        <span>return</span> <span>0</span>;
}
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unfortunately, most of these examples will only compile in clang, since gcc dis-allows branching to a label that is inside a statement expression (which is probably for the best).</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Let's try to embed a switch statement into a switch statement expression:</p>

<p><code><pre>
<span>switch</span>(({<span>switch</span>(<span>0</span>);<span>3</span>;}<span>))</span>;
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yup, this compiles in gcc and clang! &nbsp;This code doesn't do anything interesting, but it illustrates one approach to writing C code that is difficult to read.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now let's try building a more useful example that combines switch and statement expressions. &nbsp;Here is an example where you want to conditionally change the bounds of a loop. &nbsp;You could use a variable or a function but you could also use a statement expression with embedded case labels!</p>

<p><code><pre><span>#include </span><span>&lt;stdio.h&gt;</span>

<span>void</span> print_stuff(<span>int</span> type){
        <span>int</span> i = <span>0</span>;
        <span>int</span> r = <span>0</span>;
        <span>switch</span>(type){
                <span>for</span>(i = <span>0</span>; i &lt; ({<span>if</span>(<span>0</span>){ <span>case</span> <span>1</span>:r+=<span>2</span>; <span>case</span> <span>0</span>:r+=<span>3</span>;}r;}<span>)</span>; i++<span>)</span>{
                        printf(<span>"i is </span><span>%d</span><span>\n</span><span>"</span>, i);
                }
        }
}

<span>int</span> main(<span>void</span>){
        printf(<span>"First run</span><span>\n</span><span>"</span>);
        print_stuff(<span>0</span>);
        printf(<span>"Second run</span><span>\n</span><span>"</span>);
        print_stuff(<span>1</span>);
        <span>return</span> <span>0</span>;
}
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The above example gives me the following output:</p>

<p><code><pre>First run
i is 0
i is 1
i is 2
Second run
i is 0
i is 1
i is 2
i is 3
i is 4
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;However, if you run this program through valgrind you'll find that this it's doing uninitialized reads:</p>

<p><code><pre>==16228== Conditional jump or move depends on uninitialised value(s)
==16228==    at 0x4005AB: print_stuff (main.c:7)
==16228==    by 0x400619: main (main.c:15)
...
==16228== …</pre></code></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.robertelder.org/switch-statements-statement-expressions/">https://blog.robertelder.org/switch-statements-statement-expressions/</a></em></p>]]>
            </description>
            <link>https://blog.robertelder.org/switch-statements-statement-expressions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24790218</guid>
            <pubDate>Thu, 15 Oct 2020 16:13:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streamlit Sharing]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24789257">thread link</a>) | @danicgross
<br/>
October 15, 2020 | https://blog.streamlit.io/introducing-streamlit-sharing/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/introducing-streamlit-sharing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2020/10/Balloons-640--1--1.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2020/10/Balloons-640--1--1.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2020/10/Balloons-640--1--1.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2020/10/Balloons-640--1--1.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2020/10/Balloons-640--1--1.gif" alt="Introducing Streamlit Sharing">
            </figure>

            <section>
                <div>
                    <p>Machine learning and data science code is easy to share but hard to use. GitHub overflows with models, algorithms, and datasets. But code is static. Can you play with the models? See the algorithms? Interact with the data? Doing so requires following complex instructions, installing packages, or reading dense code snippets. Frustrated by this, we decided that <strong>we need a simple, sharable "play" button for machine learning code.</strong></p><p>There are two challenges here. The first is <strong>creating</strong> apps that make data science and machine learning code interactive. The second is <strong>sharing</strong> these apps so that the world can experience your work.</p><p>A year ago, we addressed the first challenge — <strong>creating —</strong> by releasing Streamlit, an open-source library that lets you transform Python scripts into interactive apps. Streamlit lets you easily demonstrate algorithms, play with models, manipulate data, and combine all of these superpowers into beautiful apps. The response has been tremendous. We just crossed our millionth download. Hundreds of thousands of Streamlit apps have been created all over the world. <strong>But creating great apps only solves half the problem.</strong></p><p>Today, we address the second challenge — <strong>sharing</strong> — by announcing a brand-new sharing platform for Streamlit. Streamlit sharing lets you deploy, manage, and share your apps – all for free! If you have a Streamlit app hosted publicly on GitHub, you are now one click away from sharing it with the world. </p><figure><img src="https://blog.streamlit.io/content/images/2020/10/App-dashboard-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/10/App-dashboard-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/10/App-dashboard-1.png 1000w, https://blog.streamlit.io/content/images/2020/10/App-dashboard-1.png 1348w" sizes="(min-width: 1200px) 1200px"></figure><h2 id="github-and-streamlit-better-together">GitHub and Streamlit - Better Together</h2><p>Streamlit sharing <strong>combines the best of Streamlit with the best of GitHub.</strong> From Streamlit you get a simple framework for creating incredibly rich and useful apps. From GitHub you inherit an incredible framework for social collaboration. Paste your GitHub link into Streamlit's sharing platform and almost instantly you have a live app. Or, click on the menu for any live app and see its source code on GitHub. Collaborate for free simply by forking and editing the code. It’s global, shareable, fork-able, collaborative data science!</p><figure><img src="https://blog.streamlit.io/content/images/2020/10/filmstrip--6--1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/10/filmstrip--6--1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/10/filmstrip--6--1.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2020/10/filmstrip--6--1.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2020/10/filmstrip--6--1.png 2400w" sizes="(min-width: 720px) 720px"></figure><h2 id="endless-possibilities">Endless Possibilities</h2><p>Taken together, Streamlit and GitHub enable an <a href="https://streamlit.io/gallery">incredibly rich and diverse ecosystem of useful apps</a> – from dashboards to deep nets and beyond! (As former Carnegie Mellon folks, we're especially proud that students taking the <a href="https://dig.cmu.edu/courses/2020-fall-interactive-ds.html">Interactive Data Science</a> class now submit their homework using Streamlit sharing 🤗) Here are some awesome examples of shared Streamlit apps that you can play with right now.</p><!--kg-card-begin: html--><!--
	Old one:
	https://static.streamlit.io/s4a-blog-post-app-grid/v1/
-->

<!--kg-card-end: html--><p>While this post has focused on open source applications, Streamlit is also used by thousands of companies to build sophisticated internal data tools. For example, Uber has deployed Streamlit company-wide, enabling data scientists to share their work throughout the company. <strong>Streamlit for Teams</strong> extends Streamlit’s sharing platform to bring secure, seamless app deployment, management, and collaboration <em>within</em> your enterprise. If you're interested please <a href="https://streamlit.io/for-teams">sign up for the beta for Streamlit for Teams</a>.</p><h2 id="get-your-invitation-to-streamlit-sharing">Get Your Invitation to Streamlit Sharing</h2><p>To celebrate the launch, we'll be<strong> releasing 1,000 invitations for Streamlit sharing</strong> -<strong> </strong>with more invites coming as our server capacity grows. If you don’t have one in your inbox already, please <a href="https://streamlit.io/sharing">request an invite</a> and we'll get you one soon. </p><figure><img src="https://blog.streamlit.io/content/images/2020/10/Sharing-invite.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/10/Sharing-invite.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/10/Sharing-invite.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2020/10/Sharing-invite.png 1600w, https://blog.streamlit.io/content/images/2020/10/Sharing-invite.png 2060w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-streamlit-play-button">The Streamlit Play Button</h2><p>This new sharing superpower completes the Streamlit circle – from creation to sharing, and back again. So go forth and share; let others see your work, fork, merge, and contribute the cycle of knowledge. In that spirit, we offer one last gift: <strong>This is our “play” button.</strong></p><!--kg-card-begin: html--><p><img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg">
</p><!--kg-card-end: html--><p>This brand-new badge helps others find and play with your Streamlit app. Embed it right into your GitHub <code>readme.md</code> as follows:</p><!--kg-card-begin: markdown--><pre><code>[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/yourGitHubName/yourRepo/yourApp/)
</code></pre>
<!--kg-card-end: markdown--><p>Thank you all for inspiring us with your amazing creations. We're excited to see what you build and share. 🎈</p><hr><p><em>A huge thank you from all of us at Streamlit to all of you in the community – and especially the inaugural Streamlit Creators, <a href="https://discuss.streamlit.io/u/ash2shukla/summary" rel="noopener noreferrer">Ashish</a>, <a href="https://discuss.streamlit.io/u/charly_wargnier/summary" rel="noopener noreferrer">Charly</a>, <a href="https://discuss.streamlit.io/u/andfanilo/summary" rel="noopener noreferrer">Fanilo</a>, <a href="https://discuss.streamlit.io/u/napoles3d/summary" rel="noopener noreferrer">José</a>, <a href="https://discuss.streamlit.io/u/jesse_jcharis/summary" rel="noopener noreferrer">Jesse</a>, and <a href="https://discuss.streamlit.io/u/synode/summary" rel="noopener noreferrer">Synode</a> – for your kindness, your feature requests, your bug reports, and your enthusiasm. Special thanks also to all the launch app creators, Alex, Dan, Ines | Explosion, and finally Tyler who created not only the <a href="https://share.streamlit.io/tylerjrichards/book_reco/master/books.py">Goodreads app</a> but also a great sharing tutorial.</em></p>
                </div>
            </section>

            <div>

                <section>

                    <ul>
                        <li>


                            <a href="https://blog.streamlit.io/author/adrien/">
                                <img src="https://blog.streamlit.io/content/images/size/w100/2020/10/BCCFD5BD-3431-449D-8D58-ECE47B1C0F2B.jpeg" alt="Adrien Treuille">
                            </a>

                        </li>
                    </ul>

                    <section>
                        
                        <p><time datetime="2020-10-15">15 Oct 2020</time>
                            <span><span>•</span> 3 min read</span>
                        </p>
                    </section>

                </section>
            </div>



            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.streamlit.io/introducing-streamlit-sharing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24789257</guid>
            <pubDate>Thu, 15 Oct 2020 14:57:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HP-28S Battery Compartment Door]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24788330">thread link</a>) | @criddell
<br/>
October 15, 2020 | https://www.teawea.com/hp-28s-battery-compartment-door/ | <a href="https://web.archive.org/web/*/https://www.teawea.com/hp-28s-battery-compartment-door/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.teawea.com/hp-28s-battery-compartment-door/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24788330</guid>
            <pubDate>Thu, 15 Oct 2020 13:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineer Amazon's Whispersync]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24787584">thread link</a>) | @ptbrowne
<br/>
October 15, 2020 | https://ptbrowne.github.io/posts/whispersync-reverse-engineering/ | <a href="https://web.archive.org/web/*/https://ptbrowne.github.io/posts/whispersync-reverse-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>May 26, 2020</h5>



  

  


  <p>I am a big fan of my Kindle. This is the device I’d bring over to a desert
island. I am also a fairly frequent user of the highlight feature where you can
select a bit of text you like and save it. One thing is bothering me though:
the lack of open API on the Kindle to retrieve the data about me. Amazon
provides the <code>my-clippings.txt</code> file on the Kindle and the “Export my
annotations via e-mail” feature, but both these features cannot be done in the
background automatically, and the last read position is not available. I want
moar !</p>
<p>I want to get the raw data:</p>
<ul>
<li>to print a little book with all my annotations</li>
<li>to retrieve my last read position and see in which periods of my life I tend
to read most (reading less would be a good indicator of stressful periods)</li>
<li>to put the data in my own personal space : my <a href="https://cozy.io/">cozy</a> (I work there).
I could for example randomly display favorite quotes in my Cozy-Home, or
have a “books” app with a public page with all my books. That would be the
digital equivalent of a bookshelf. The bookshelf as a means of sharing good
books that you’ve read is lost with the Kindle. I wish I could easily share
with my friends my reading list. goodreads.com would be another way to do
that, but I’d prefer to have the data at my disposal.</li>
</ul>
<p>The possibilities are endless… but first, I needed to get access to the
data. A long time ago, I tried to access this data via <a href="https://read.kindle.com/">Kindle web</a>
but could not pass the login screen via scraping: there was if I recall
well, credential encryption on the application side, and I had not managed to
redo it correctly.</p>
<p>Recently, I have seen a presentation on using <a href="http://mitm.it/">mitmproxy</a> to discover HTTP
APIs used by apps. It gave me motivation to start again on this project:  this
time, instead of web scraping, I’d try to understand how the Kindle
communicates with Amazon and try to emulate the same HTTP requests to access
my data.</p>
<h2 id="setup-a-man-in-the-middle-on-a-kindle-app">Setup a man in the middle on a Kindle app</h2>
<p>Disclaimer: do not attempt man-in-the-middle attacks on devices or accounts
that are not your own. To successfully conduct this project, you need to have
physical access to the device to install an SSL certificate authority.</p>
<p>To see the flow of communication between an Android device and a remote HTTP
based APIs, things are a bit more involved than from a web browser: in the web
world we have access to the network inspector which helps us record data,
replay calls, see requests and responses, etc… There is no such thing for
Android or iOS. The solution is to do a man-in-the-middle attack on our
device: proxying and recording all traffic through a controlled access point.</p>
<p>The setup is briefly described below:</p>
<ul>
<li>A Raspberry Pi runs as a wifi access point (through <a href="https://w1.fi/hostapd/">hostapd</a>)</li>
<li>Every packet going through the access point is redirected to mitmproxy (<a href="https://docs.mitmproxy.org/stable/howto-transparent/">in
the transparent mode fashion</a>)</li>
<li>HTTPs man-in-the-middle is made possible thanks to a custom CA authority
installed on the whispersync client device</li>
<li>A real or virtual (for example with <a href="https://genymotion.com/">Genymotion</a>) Android 5
device</li>
<li>Kindle for Android installed on the Android device (the Play store can be
installed on Genymotion)</li>
</ul>
<blockquote>
<p>ℹ️ It is also possible to use iOS but it is easier to have access to a
virtual Android device since you do not have to own a Mac</p>
</blockquote>
<blockquote>
<p>ℹ️ On Android, it is possible to use user certificates until Android 7
Nougat. After Android 7 Nougat, apps will not use user certificates by
default. More information
<a href="https://blog.jeroenhd.nl/article/android-7-nougat-and-certificate-authorities">here</a>.</p>
</blockquote>
<p>Here is <a href="https://www.dinofizzotti.com/blog/2019-01-09-running-a-man-in-the-middle-proxy-on-a-raspberry-pi-3/">a good article to set everything
up</a>.</p>
<p>After all this setup (a bit long and tedious but not hard), it is possible
to record HTTP dumps of the traffic between the Kindle app and Amazon.</p>
<div><pre><code data-lang="bash">ssh pi@192.168.50.10
tmux a -t <span>0</span>
<span># launch mitmdump and write request/response to outfile</span>
mitmdump --mode transparent -w outfile
<span># Use the Kindle app to generate traffic</span>
<span># ctrl-c to stop the proxy</span>
exit #
</code></pre></div><p>At this point, <code>outfile</code> contains all the requests and responses in the
mitmproxy format.</p>
<h2 id="recording-http-dumps">Recording HTTP dumps</h2>
<p>mitmproxy uses a custom format to store dumps. It is not very interoperable:
querying and extracting data from the dumps is a bit difficult. HAR is a
standard format used for example in Chrome and Firefox (Network inspector tabs
in both browser can import/export the HAR format). The HAR format underlying
format is JSON which makes it readable and interoperable with tools like <a href="https://stedolan.github.io/jq/">jq</a>
that are really handy for filtering / querying.</p>
<p>The mitmproxy repository contains a script to transform a mitmproxy
dumpfile into a HAR file.</p>
<p>To convert a mitmproxy dump into an HAR file:</p>
<div><pre><code data-lang="bash">git clone https://github.com/mitmproxy/mitmproxy.git mitmproxy <span># to have access to the HAR conversion script</span>
pip install mitmproxy <span># to have the mitmdump command</span>

<span># Extract the dump from the Raspberry Pi</span>
rsync -aPrs pi@192.168.50.10:outfile dump.mitmproxy

<span># Convert mitmproxy format to HAR format (JSON based format)</span>
mitmdump -vvv -n -r infile.dump  -s mitmproxy/examples/complex/har_dump.py --set hardump<span>=</span>./outfile.har
</code></pre></div><h2 id="understanding-the-flow">Understanding the flow</h2>
<p>With jq, we can extract requests URLs, which is handy to
start understanding the flow of communication between Amazon and our
device.</p>
<div><pre><code data-lang="bash">$ cat dumps/dump.har | jq -rc <span>'.log.entries | map(.request.url)'</span>
<span>"https://54.239.22.185/FirsProxy/registerDevice"</span>,
<span>"https://54.239.22.185/FirsProxy/registerDevice"</span>,
<span>"https://54.239.22.185/FirsProxy/registerDevice"</span>,
<span>"https://54.239.22.185/FirsProxy/registerDevice"</span>,
<span>"https://54.239.22.185/FirsProxy/getStoreCredentials"</span>,
<span>"https://52.46.133.19/FionaTodoListProxy/syncMetaData"</span>,

<span># Unique URLS</span>
cat dumps/dump5.har | jq <span>'.log.entries | map(.request.url) | sort | unique'</span>

<span># Filter all requests with a particular URL</span>
cat dumps/dump5.har | jq <span>'.log.entries | map(select(.request.url == "&lt;MY_URL&gt;"))'</span>
</code></pre></div><h2 id="registration-and-request-signing">Registration and request signing</h2>
<p>The first call the device makes when logging in is a <code>registerDevice</code> call. It
contains both login and password and is used to register a device on Amazon.
After replaying this request through <code>curl</code>, I had a “Wrong password”
response. It is because Amazon sends a two factor authentication email and you
have to replay (again) the registerDevice call with the value from the two
factor authentication email in the password field to get through.</p>
<p>At this point a new device is visible on Amazon Kindle site 🙌. The next things
to do is to fetch the list of books.</p>
<p>The problem now is that we can see that every subsequent request to Amazon has
a <code>X-ADP-Request-Digest</code>: every request is “signed” with the help of a
certificate received in the <code>registerDevice</code> call.</p>
<p>Below, you can see an example request on the <code>syncMetadata</code> route used to get the
list of books:</p>
<div><pre><code data-lang="json">{
  <span>"startedDateTime"</span>: <span>"2020-05-10T14:21:42.217752+00:00"</span>,
  <span>"time"</span>: <span>6532</span>,
  <span>"request"</span>: {
    <span>"method"</span>: <span>"GET"</span>,
    <span>"url"</span>: <span>"https://52.46.133.19/FionaTodoListProxy/syncMetaData"</span>,
    <span>"httpVersion"</span>: <span>"HTTP/1.1"</span>,
    <span>"headers"</span>: [
      {
        <span>"name"</span>: <span>"X-ADP-Request-Digest"</span>,
        <span>"value"</span>: <span>"SIG1tis85OWFqJqbzy0Z0xBzBCI3/88e9p/2jr8UvTAUQCuil5ED0833peNeKPp1dIMdVAs/INcUR//xvCJu+ngyP9olVSda/IBBxM2fftVGIDEVuQqMSC9P+O/pZMhaAJpvxIm78M52OB+lNIYXjE0Kr1OB0mmOo4iVu45aRio8hZDlmDG07zjVHnlQHE5sUjzOMnYBFC6VXw+srjYfo6dTptwSKNX11A0naG+tjcuxnglAE3R9U8/+pVr/uFNT4ou+0cQs2KbV0/4tYEIbOogC1JgjNNt4hyb2l91QED7Aj+A/DFcKBT+XNkjAUAAI1//HhCtxqCNtbu1E1sRReQ==:2020-04-10T14:21:40Z"</span>
      }
    ]
  }
}
</code></pre></div><p>Signing the request means that I needed to use the right key to sign (I was
pretty confident that the privateKey receive in the registerDevice call was the
one to use) sign the right data = find the fields from the request (and in
which order) that were used to make a fingerprint of the request</p>
<p>Fortunately, after a bit of searching I came across the repositories of
lolsborn (<a href="https://github.com/lolsborn/readsync">readsync</a> and <a href="https://github.com/lolsborn/fiona-client">fiona-client</a>) that had implementation of
request signing for the whispersync API.</p>
<div><pre><code data-lang="python">        data <span>=</span> <span>"</span><span>%s</span><span>\n</span><span>%s</span><span>\n</span><span>%s</span><span>\n</span><span>%s</span><span>\n</span><span>%s</span><span>"</span> <span>%</span> \
            (method, url, time, postdata, self<span>.</span>adp_token)  
        rsa <span>=</span> RSA<span>.</span>load_key_string(str(self<span>.</span>private_pem))
        crypt <span>=</span> rsa<span>.</span>private_encrypt(hashlib<span>.</span>sha256(data)<span>.</span>digest(),
            RSA<span>.</span>pkcs1_padding)
        sig <span>=</span> base64<span>.</span>b64encode(crypt)
</code></pre></div><p>From <a href="https://github.com/lolsborn/readsync/blob/7c0233bc8a6dcc8e8598d014b547bee34ebcadbb/models.py">readsync source code</a>.</p>
<p>From this bit of code, I could see which fields were used and in which order. I
now needed “only” to convert it to Javascript.</p>
<p>With the help of <a href="https://www.npmjs.com/package/node-forge">node-forge</a> and <a href="https://www.npmjs.com/package/node-rsa">node-rsa</a>, after a fair bit of
struggle, I managed to have the right signature. I found it difficult even
with two example implementations to get the signature exactly right (I am not
an expert in crypto technologies and did not know both libraries, so I spent a
little bit of time trying to jam the certificate and values in every possible
ways 🙃).</p>
<p>Having a bad signature is not immediately obvious since you have to send a
request to Amazon to check it (and if it’s bad, Amazon sends an <code>Internal Server Error</code>). Using a recorded dump to have an example of the right
signature and using it in a <a href="https://jestjs.io/">Jest</a> test with a fixed date (since the date is
used in the request) was very helpful as the feedback loop was very quick.</p>
<blockquote>
<p>⚠️ I had to use two different libraries to get the same signature. I am
sure it is possible to use only <code>node-forge</code> though.
ℹ️ The private key is a PKCS8 certificate in DER format encoded in base64.
❓I wonder why to sign the requests, the devices do not generate
a private/public key pair and transmit the public key to Amazon: it is
a bit unusual to have something private fly on the network.</p>
</blockquote>
<h2 id="sidecars">Sidecars</h2>
<p>After cracking the signing part, it was possible to call the <code>syncMedata</code>
route, with a proper digest header, to get all the books in our library
(yay!).</p>
<p>But, the challenge was not done yet: I was most interested in getting the
<em>metadata</em> on the book: my highlights, annotations and last page read. I
needed to find the call that was retrieving all this data.</p>
<p>When searching for the content of a highlight in the dump, I could not find
anything 🤔. When filtering the URLs of the dump with the identifier of the
book (the ASIN in Amazon parlance), some URLs looked interesting:</p>
<pre><code data-lang="code">https://72.21.194.248/FionaCDEServiceEngine/FSDownloadContent?type=EBOK&amp;key=&lt;MYASIN&gt;</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ptbrowne.github.io/posts/whispersync-reverse-engineering/">https://ptbrowne.github.io/posts/whispersync-reverse-engineering/</a></em></p>]]>
            </description>
            <link>https://ptbrowne.github.io/posts/whispersync-reverse-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24787584</guid>
            <pubDate>Thu, 15 Oct 2020 11:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LDM: My Favorite ARM Instruction]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24785357">thread link</a>) | @one_and_only
<br/>
October 14, 2020 | https://keleshev.com/ldm-my-favorite-arm-instruction/ | <a href="https://web.archive.org/web/*/https://keleshev.com/ldm-my-favorite-arm-instruction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  


  

<center>Vladimir Keleshev • 2020-10-13</center>


<p>LDM—or <em>load multiple</em>—is my favorite assembly instruction of the ARM instruction set. Here’s why.</p>
<p>First, let’s discuss what LDM does. An example:</p>
<pre><code>ldm r4, {r0, r1, r2, r3}</code></pre>
<p>Here, it takes a <em>base register</em> (in this case, <code>r4</code>) and a <em>register set</em> (in this case, <code>{r0, r1, r2, r3}</code>). It loads consecutive words from the address in the base register into the registers in the set. In this example, the effect could be described using the following C-like pseudo-code:</p>
<pre><code>r0 = r4[0];
r1 = r4[1];
r2 = r4[2];
r3 = r4[3];</code></pre>
<p>That’s quite a few assignments for a single instruction! And that’s why it’s called <em>load multiple</em>.</p>
<p>The set notation also allows for ranges. We can rewrite the previous example as follows:</p>
<pre><code>ldm r4, {r0-r3}</code></pre>
<p>Any and all of the 16 ARM registers are allowed in the set. So, the following is legal:</p>
<pre><code>ldm r0, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15}</code></pre>
<p>The register set is encoded as a 16-bit mask in a 32-bit instruction. Here’s a simplified encoding of the original example:</p>
<figure>
<img src="https://keleshev.com/ldm-my-favorite-arm-instruction/ldm-encoding-arm.svg" alt=""><figcaption>Simplified encoding of the LDM instruction</figcaption>
</figure>
<p>Such instruction is a perfect fit for a <a href="https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture">load-store architecture</a> like ARM, where the primary workflow is:</p>
<ul>
<li>load many values from memory into registers,</li>
<li>perform operations exclusively on registers,</li>
<li>store results back from registers into memory.</li>
</ul>
<p>The opposite of LDM is STM—<em>store multiple</em>.</p>
<!---Since both of them operate on *sets* of registers (which are implemented as bit masks), you can't directly select the order in which the values are loaded or stored.
The set `{r0, r1, r2}` is the same as `{r2, r1, r0}`.
That's why-->
<h2 id="block-copy">Block copy</h2>
<p>With these two, you can copy large blocks of memory fast. You can copy eight words (or 32 bytes!) of memory in just two instructions:</p>
<pre><code>ldm r0, {r4-r11}
stm r1, {r4-r11}</code></pre>
<p>LDM and STM also have auto-increment variants (denoted with “!”) where the base register is incremented by the number of words loaded/stored so that you can do the copying in a fast loop:</p>
<pre><code>ldm r0!, {r4-r11}
stm r1!, {r4-r11}</code></pre>
<h2 id="implementing-stacks">Implementing stacks</h2>
<p>ARM’s POP instruction is simply an alias for LDM with a stack pointer (and auto-increment). The following two are exactly the same:</p>
<pre><code>ldm sp!, {r0-r3}
pop {r0-r3}</code></pre>
<p>And the PUSH instruction is an alias for an STM variant (STMDB).</p>
<p>You can push and pop large quantities to and from the stack in one go. And if you replace SP by another register you can implement efficient stacks in other regions of memory. For example, you can implement a <a href="https://en.wikipedia.org/wiki/Shadow_stack">shadow stack</a> in the heap.</p>
<h2 id="saving-registers">Saving registers</h2>
<p>Are you hesitating to use the call-preserved registers because you need to save them, and you might as well use a stack slot anyway? Not any more, because you can save all call-preserved registers you want to use in one go:</p>
<pre><code>push {r4-r11}</code></pre>
<h2 id="prologue-and-epilogue">Prologue and epilogue</h2>
<p>On ARM, the first four arguments, the return address (LR) and the frame pointer (FP) are all passed in registers. That’s why it’s especially important to have efficient prologues and epilogues. Fortunately, you can save FP and LR in one go, using a fairly standard ARM prologue:</p>
<pre><code>push {fp, lr}</code></pre>
<p>And then restore both and return (for the epilogue):</p>
<pre><code>pop {fp, lr}
bx lr</code></pre>
<p>Even better, you can restore both and return in one go!</p>
<pre><code>pop {fp, pc}</code></pre>
<p>This works by popping the return address value (LR) into the program counter register (PC), so you don’t need an explicit return!</p>
<p>This is good enough in itself, but you can—<em>at the same time</em>—spill some arguments onto the stack (for example, if their address is taken):</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>Or, you can save FP and LR and—<em>at the same time</em>—allocate some space on the stack:</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>In this case, we push <code>r0-r3</code> not for their value but to advance the stack pointer by four words.</p>
<h2 id="arm64">ARM64</h2>
<p>I suspect it was a difficult trade-off, but when it was time to design the 64-bit version of the ARM instruction set, the decision was made to double the number of registers to 32. I remember reading a paper saying that this change improves the performance by about 6% across the board. With 32 registers it is no longer possible to encode a bitmask of all registers into a 32-bit long instruction. So, instead, ARM64 has LDP and STP: load pair and store pair, which are the spiritual successors of LDM and STM.</p>
<hr>
<p>This blog post started out originally as a <a href="https://twitter.com/keleshev/status/1285654345988673536">Twitter thread</a>. <a href="https://keleshev.com/" title="Home">■</a></p>
<hr>
<p><em>Did you like this blog post? If so, check out my new book:</em> Compiling to Assembly from Scratch. <em>It teaches you enough assembly programming and compiler fundamentals to implement a compiler for a small programming language. </em></p>


      
  <p><a href="https://keleshev.com/compiling-to-assembly-from-scratch">
       <img alt="Compiling to Assembly from Scratch, the book by Vladimir Keleshev" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300">
      </a>
  </p>
  <hr>


</div>]]>
            </description>
            <link>https://keleshev.com/ldm-my-favorite-arm-instruction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24785357</guid>
            <pubDate>Thu, 15 Oct 2020 06:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tasmota: Cloud-free open source smart home firmware for ESP8266 devices]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24785175">thread link</a>) | @noja
<br/>
October 14, 2020 | https://tasmota.github.io/docs/About/ | <a href="https://web.archive.org/web/*/https://tasmota.github.io/docs/About/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main"> <div>   <div> <article> <a href="https://github.com/tasmota/docs/blob/master/docs/About.md" title="Edit this page"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg> </a>  <div> <p>If you don't have the willingness to tinker and learn... TURN BACK!.</p> <p>Tasmota is not a commercial product and support is limited. You have to be willing to research and solve potential problems yourself. </p> </div> <p><img alt="Tasmota logo" src="https://tasmota.github.io/docs/_media/logo-blue.png"></p> <p>Tasmota is an open source firmware for <a href="https://en.wikipedia.org/wiki/ESP8266">ESP8266</a> based devices created and maintained by <a href="https://github.com/arendst">Theo Arends</a>. </p> <p>Everything began as <a href="https://github.com/arendst/Sonoff-MQTT-OTA">Sonoff-MQTT-OTA</a> with a <a href="https://github.com/arendst/Sonoff-MQTT-OTA/commit/9d4c0c60dc7ca8c24cf562a932f263d76f664473">commit</a> on 25th January 2016. by Theo Arendst. Its goal was to provide ESP8266 based <a href="https://www.itead.cc/sonoff-wifi-wireless-switch.html">ITEAD Sonoff</a> devices with MQTT and 'Over the Air' or OTA firmware. </p> <p>What started as a simple way to hack a cloud bound Sonoff Basic (one of the first cheap and accessible smart home devices in the market) into a locally controlled device has grown into a fully fledged ecosystem for virtually any ESP8266 based device.</p> <h2 id="contribute">Contribute<a href="#contribute" title="Permanent link">~</a></h2> <p><strong>Any contribution helps our team and makes Tasmota better for the entire community!</strong></p> <p>Everybody is welcome and invited to contribute to Tasmota Project by:</p> <ul> <li>providing Pull Requests (Features, Proof of Concepts, Language files or Fixes)</li> <li>testing new released features and report issues</li> <li>donating to acquire hardware for testing and implementing or out of gratitude</li> <li>contributing missing <a href="https://tasmota.github.io/docs/Contributing/">documentation</a> for features and devices</li> </ul> <h2 id="credits">Credits<a href="#credits" title="Permanent link">~</a></h2> <p>People helping to keep the show on the road:</p> <ul> <li>David Lang providing initial issue resolution and code optimizations</li> <li>Heiko Krupp for his IRSend, HTU21, SI70xx and Wemo/Hue emulation drivers</li> <li>Wiktor Schmidt for Travis CI implementation</li> <li>Thom Dietrich for PlatformIO optimizations</li> <li>Marinus van den Broek for his EspEasy groundwork</li> <li>Pete Ba for more user friendly energy monitor calibration</li> <li>Lobradov providing compile optimization tips</li> <li>Flexiti for his initial timer implementation</li> <li>reloxx13 for his <a href="https://github.com/reloxx13/TasmoAdmin">TasmoAdmin</a> management tool</li> <li>Joachim Banzhaf for his TSL2561 library and driver</li> <li>Gijs Noorlander for his MHZ19, SenseAir and updated PubSubClient drivers</li> <li>Erik Montnemery for his HomeAssistant Discovery concept and many code tuning tips</li> <li>Federico Leoni for continued HomeAssistant Discovery support</li> <li>Aidan Mountford for his HSB support</li> <li>Daniel Ztolnai for his Serial Bridge implementation</li> <li>Gerhard Mutz for multiple sensor &amp; display drivers, Sunrise/Sunset, and scripting</li> <li>Nuno Ferreira for his HC-SR04 driver</li> <li>Adrian Scillato for his (security) fixes and implementing and maintaining KNX</li> <li>Gennaro Tortone for implementing and maintaining Eastron drivers</li> <li>Raymond Mouthaan for managing Wemos Wiki information</li> <li>Norbert Richter for his <a href="https://github.com/tasmota/decode-config">decode-config.py</a> tool</li> <li>Andre Thomas for providing <a href="http://thehackbox.org/tasmota/">thehackbox</a> OTA support and daily development builds</li> <li>Joel Stein, digiblur and Shantur Rathore for their Tuya research and driver</li> <li>Frogmore42 for providing many issue answers</li> <li>Jason2866 for platformio support and providing many issue answers</li> <li>Blakadder for managing the new document site and providing template management</li> <li>Stephan Hadinger for refactoring light driver, enhancing HueEmulation and Zigbee support</li> <li>tmo for designing the official Tasmota logo</li> <li>Stefan Bode for his Shutter and Deep sleep drivers</li> <li>Jacek Ziółkowski for his <a href="https://github.com/jziolkowski/tdm">TDM</a> management tool and <a href="https://github.com/tasmota/tasmotizer">Tasmotizer</a> flashing tool</li> <li>Christian Staars for NRF24L01 and HM-10 Bluetooth sensor support</li> <li>Paul Diem for UDP Group communication support</li> <li>Jörg Schüler-Maroldt for his initial ESP32 port</li> <li>Many more providing Tips, Wips, Pocs, PRs and Donations</li> </ul> <h2 id="license">License<a href="#license" title="Permanent link">~</a></h2> <p>This program is licensed under GPL-3.0</p> </article> </div> </div> </div></div>]]>
            </description>
            <link>https://tasmota.github.io/docs/About/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24785175</guid>
            <pubDate>Thu, 15 Oct 2020 05:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eric Yuan's Visa Application Was Rejected 8 Times]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24783979">thread link</a>) | @shsachdev
<br/>
October 14, 2020 | https://www.careerfair.io/reviews/eric-yuan-effect | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/eric-yuan-effect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
I’ve been reading about Eric Yuan, founder of Zoom.
</p>
<p>
Yuan migrated to the USA from China in the 80s. He had heard Bill Gates speak about the internet and he wanted to be a part of the digital revolution. 
</p>
<p>
So he applied for his visa. He was rejected. He applied again. Rejected again.
</p>
<p>
9 tries. It took Eric Yuan 9 tries to finally get his visa for the USA.
</p>
<p>
Once in the USA, he started working at the video conferencing software company WebEx. 
</p>
<p>
He worked there for a decade and rose up the ranks to become the VP of Engineering. 
</p>
<p>
Under Yuan’s leadership, WebEx grew to more than 750 engineers and had an annual revenue of around $1B (and was later acquired by Cisco). Safe to say the company was doing well. 
</p>
<p>
But there was a problem. 
</p>
<p>
The video conferencing software <em>sucked</em>. 
</p>
<p>
Yuan would meet with customers and they would be unhappy. They’d complain about video and audio lag. Connectivity issues. All sorts of stuff. 
</p>
<p>
In Yuan’s own words:
</p>

<blockquote>
  Before I left Cisco I spent a lot of time talking to WebEx customers and every time I talked to them I felt very embarrassed because I did not see a single happy customer, and I tried to understand why that was.
    <span>Eric Yuan</span>
</blockquote>

<p>
So in 2011, Yuan left. He decided to start his own company with the mission of building the best video conferencing software in the world. 
</p>
<p>
After he left, 40 of the 800 engineers he worked with immediately joined him at Zoom. 
</p>
<p>
And according to <a href="https://twitter.com/dscheinm/status/1300544031458553859">this tweet</a>, almost all of the others sent in resumes to work with him. He had something like 1000 job inquiries within a week of announcing his leaving.
</p>
<p>
Talk about engineering loyalty. 
</p>
<p>
Today Zoom is valued at more than $40 billion. The pandemic may have accelerated the company’s growth but make no mistake: this was an overnight success 9 years in the making. 
</p>
<h2>Takeaway</h2>
<p>
I think the part that stands out the most to me is that Yuan actually had the courage to leave Cisco and go on to start Zoom. 
</p>
<p>
There is often great inertia that prevents us from leaving jobs we’re unhappy with. 
</p>
<p>
In Yuan’s case, he had by all measures a very successful career ever since he immigrated to the US. Most people in his shoes wouldn’t even bother resigning from a comfortable VP of Engineering position. 
</p>
<p>
So he could have settled and just resigned himself to the fact that maybe video conferencing software was supposed to be like this. After all, there was very little competition in the market. 
</p>
<p>
But he didn’t. He chose discomfort and hundreds of other engineers believed in him. 
</p>
<p>
Keep moving forward and don’t settle. You might be surprised at how many people follow you. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/eric-yuan-effect</link>
            <guid isPermaLink="false">hacker-news-small-sites-24783979</guid>
            <pubDate>Thu, 15 Oct 2020 01:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Twilio Acquired Segment]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24781493">thread link</a>) | @cpard
<br/>
October 14, 2020 | https://rudderstack.com/blog/why-twilio-acquired-segment/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/why-twilio-acquired-segment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/RudderStack-Cloud-teaser-images-2-750x355.jpg" alt="" title="Twilio + Segment">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Congratulations to the team at <strong>Segment</strong> for their massive acquisition by Twilio. From being founded in 2012 to getting acquired in 2020 (for billions) is a huge success and a testament to their team’s outstanding execution.  </p>



<p>When Segment initially released <code>analytics.js</code>, it was criticized for being only marginally better than a tag manager but developers on HackerNews <a href="https://news.ycombinator.com/item?id=4912076">loved the idea</a>. Hence, Segment’s success is also a testament to the power of the developer community on HN—hats off to everyone who supported the project, especially in the early days.</p>







<h2>Twilio &amp; Segment</h2>







<p>Segment recently <a href="https://segment.com/blog/customer-data-platform/">published a CDP report</a> where they shared some data around top destinations. Interestingly, the SMS &amp; push category was in a distant 11th place, with only 13% of businesses leveraging those types of connections. Even more interesting is that within the SMS and push category companies like Braze &amp; Customer.IO were listed, but not Twilio.</p>



<p>In fact, Twilio was not even a top destination for Segment, which means there is very little overlap between buyers of Segment and Twilio. Or, to put it differently, people who buy Twilio don’t have a significant need for Segment and vice-versa.&nbsp; Twilio didn’t make the acquisition simply to resell Segment to their existing customer base.&nbsp;</p>







<h2>So, Why Twilio?</h2>







<p>To a lot of people, Twilio was a surprise acquirer. Many expected Segment to be picked off by one of the usual suspects like Adobe or Salesforce.  We believe there are a few reasons underpinning this as a true <em>strategic </em>acquisition.</p>







<h3><strong>API to Application Stack </strong></h3>







<p>Twilio’s Sendgrid acquisition gives us a few hints into what’s happening here. Twilio was built as a platform providing telecom services over an API and other companies build applications on top of their APIs. </p>



<p>While Twilio has a near-complete monopoly on this API business, it is still a low-margin business where most of the money goes to gateways, providers, etc. Plus, the gateways like bandwidth.com started to compete by getting into the API business themselves. </p>



<p>The result has been aggressive discounting, which makes it hard to compete. So, while Twilio may have the best developer tools, the nature of the core product (low margin telecom) means that customers will naturally price shop as they scale and the offering becomes more commoditized. To move away from the low-margin API business, Twilio needs to go higher up the stack and build <em>applications</em>.</p>







<h3><strong>End-to-End Marketing Cloud</strong></h3>







<p>The demand for messaging in marketing automation products has grown significantly and is only growing, so it is natural for Twilio to go after the marketing use case. </p>



<p>They already owned the SMS/push channel and their Sendgrid acquisition covered the email channel. In full form, though, the marketing use case requires data collection and audience building in addition to messaging. </p>



<p>The Segment acquisition gives Twilio the missing half of the equation and will allow them to build a unified marketing platform. Perhaps most importantly, Twilio has the ability to reinvent significant pieces of the marketing cloud as API-first, which would give them a foot in the door to the market currently owned by Adobe, who has a $250 billion market cap.</p>







<h3><strong>The Sandwich</strong></h3>







<p>This is probably the most interesting impact of the acquisition: instead of sitting towards the <em>end</em> of the stack as an API endpoint, Twilio has bought a seat in the extreme <em>front seat</em> of the stack. Not only will this give them significant insight into what is being used effectively in the market amongst a plethora of tools, but could potentially enable Twilio to build/buy the important verticals that are considered indispensable, but are missing from their stack. This could— and should—make some of Segment’s partners wary. </p>



<p>This isn’t a new dynamic, as many companies in the ecosystem have already developed a healthy distrust of Segment, and now Twilio, along with their roadmaps and product ambitions. Amplitude and Braze are examples of the many products sitting downstream of Segment that will now feel the increasing pressure of “the sandwich.” As a result, we wouldn’t be surprised if Twilio continues to add more of the “missing middle” components of the marketing stack, most likely through acquisitions.</p>







<h3><strong>Ambitious Jeff</strong> </h3>







<p>Jeff is now interested in building a truly iconic business such as Salesforce and Wall Street has given him the checkbook to do M&amp;A. Twilio’s stock price has rapidly climbed from $100 to $300 in the last 6 months. </p>



<p>We have heard that Segment is at approximately $150M ARR and given Twilio’s current EV/ARR multiple of approximately 25x, Twilio will add about $3B-5B in market capitalization, making this a solid acquisition in terms of basic exchange of value. </p>



<p>Moreover, Twilio’s margins in their core business are arguably lower than Segment. We have also observed that Segment is struggling to make the transition to both enterprise as well as build a product beyond the pipe that has meaningful traction. All in all, we believe this is a win for both parties involved. Jeff is well on his way to building a once-in-a-lifetime business..</p>















<p>So once again, <strong>congratulations to Segment</strong> and everyone involved. We have a huge amount of respect for what their team has accomplished and for such a smart acquisition by Twilio.</p>



<p>Also, not to state the obvious, but if you’re interested in an <a href="http://www.rudderstack.com/">open-source alternative to Segment</a>, we’d love to talk 🙂 </p>




                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/04/soumyadeb.jpeg">
                    </p>
                    <p><span>Soumyadeb</span>
                                                                            <span>Mitra</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Founder and CEO of RudderStack. Passionate about finding engineering solutions to real-world problems.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/why-twilio-acquired-segment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781493</guid>
            <pubDate>Wed, 14 Oct 2020 20:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why software engineering processes and tools don’t work for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24781490">thread link</a>) | @ChefboyOG
<br/>
October 14, 2020 | https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <div>
			
<p>“AI is the new electricity.” At least, that’s what <a href="https://www.coursera.org/instructor/andrewng">Andrew Ng</a> suggested at this year’s <a href="https://remars.amazon.com/">Amazon re:MARS</a> conference. In his <a href="https://www.youtube.com/watch?v=j2nGxw8sKYU">keynote address</a>, Ng discussed the rapid growth of artificial intelligence (AI) — its steady march into industry after industry; the unrelenting presence of AI breakthroughs, technologies, or fears in the headlines each day; the tremendous amount of investment, both from established enterprises seeking to modernize (see: <a href="https://www.engadget.com/2019/11/19/sony-ai/">Sony</a>, a couple of weeks ago) as well as from venture investors parachuting into the market riding a wave of AI-focused founders.&nbsp;</p>



<p>“AI is the next big transformation,” Ng insists, and we’re watching the transformation unfold.</p>



<p>While AI may be the new electricity (and as a Data Scientist at <a href="http://comet.ml/">Comet</a>, I don’t need much convincing), significant challenges remain for the field to realize this potential.<strong> In this blog post, I’m going to talk about why data scientists and teams can’t rely on the tools and processes that software engineering teams have been using for the last 20 years for machine learning</strong> <strong>(ML).&nbsp;</strong></p>



<p>The reliance on the tools and processes of software engineering makes sense – data science and software engineering are both disciplines whose principal tool is<em> code</em>. Yet <em>what is being done</em> in data science teams is radically different from what is being done in software engineering teams. An inspection of the core differences between the two disciplines is a helpful exercise in clarifying how we should think about structuring our tools and processes for doing AI.&nbsp;</p>



<p>At Comet, we believe the adoption of tools and processes designed specifically for AI will help practitioners unlock and enable the type of revolutionary transformation Ng is speaking about.</p>



<h2>Different Disciplines, Different Processes</h2>



<p>Software engineering is a discipline whose aim is, considered broadly, the design and implementation of programs that a computer can execute to perform a defined function. Assuming the input to a software program is within the expected (or constrained) range of inputs, its behavior is knowable. In a <a href="https://leon.bottou.org/talks/2challenges">talk</a> at ICML in 2015, Leon Bottou formulated this well: in software engineering an algorithm or program can be proven <em>correct</em>, in the sense that given particular assumptions about the input, certain properties will be true when the algorithm or program terminates.</p>
<figure id="attachment_2550" aria-describedby="caption-attachment-2550"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" alt="ml vs software eng" width="500" height="422" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x863.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w"><figcaption id="caption-attachment-2550">Source: Futurice</figcaption></figure>
<p>

The provable correctness of software programs has shaped the tools and processes we have built for doing software engineering. Consider one corollary characteristic of software programming that follows from provable correctness: if a program is provably correct for some input values, then the program contains sub-programs that are also provably correct for those input values. This is why engineering processes like <a href="https://en.wikipedia.org/wiki/Scaled_agile_framework">Agile</a> are, broadly speaking, successful and productive for software teams. Breaking apart these projects into sub-tasks works. Most <a href="https://en.wikipedia.org/wiki/Waterfall_model">waterfall</a> and <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">scrum</a> implementations also include sub-tasking as well.</p>


<figure>
<figure id="attachment_2552" aria-describedby="caption-attachment-2552"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" alt="" width="700" height="376" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x550.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w"><figcaption id="caption-attachment-2552">Software Engineering vs. Machine Learning Lifecycle</figcaption></figure>
</figure>

<p>We see a lot of data science teams using workflow processes that are identical or broadly similar to these software methodologies. Unfortunately, they don’t work very well. The reason? The provable correctness of software engineering does not extend to AI and machine learning. In (supervised) machine learning, the only guarantee we have about a model we’ve built is that if the training set is an <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">iid</a> (independent and identically distributed) sample from some distribution, then performance on another iid sample from the same distribution will be <em>close</em> to the performance on the training set. Because uncertainty is an intrinsic property of machine learning, sub-tasking can lead to unforeseeable downstream effects.&nbsp;</p>

<h2><strong>Why is uncertainty intrinsic to machine learning?</strong>&nbsp;</h2>

<p>Part of the answer lies in the fact that the problems that are both (a) interesting to us and (b) amenable to machine learning solutions (self-driving cars, object recognition, labeling images, and generative language models, to name a few) do not have a clear reproducible mathematical or programmatic specification. In place of specifications, machine learning systems feed in lots of data in order to detect patterns and generate predictions. Put another way, the <em>purpose of machine learning is to create a statistical proxy that can serve as a specification for one of these tasks</em>. We hope our collected data is a representative subsample of the real-world distribution, but in practice we cannot know exactly how well this condition is met. Finally, the algorithms and model architectures we use are complex, sufficiently complex that we cannot always break them apart into sub-models to understand precisely what is happening.&nbsp;</p>

<p>From this description, obstacles to the <em>knowability</em> of machine learning systems should be somewhat obvious. Inherent to the types of problems amenable to machine learning is a lack of a clear mathematical specification. The statistical proxy we use in the absence of a specification is accumulating lots of environmental data we <em>hope</em> is iid and representative. And the models we use to extract patterns from this collected data are sufficiently complex that we cannot reliably break them apart and understand precisely how they work. My colleague at Comet, Dhruv Nair, has written a three-part series on uncertainty in machine learning (here’s a link to <a href="https://www.comet.ml/blog/?p=662">Part I</a>) if you’d like to dig deeper into this topic.&nbsp;</p>

<p>Consider, then, the implications for something like the Agile methodology used on a machine learning project. We cannot possibly hope to break machine learning tasks into <em>sub-tasks</em>, tackled as part of some larger sprint and then pieced together like legos into a whole product, platform, or feature, because we cannot reliably predict how the sub-models, or the model itself, will function.&nbsp;</p>

<figure>
<figure id="attachment_2553" aria-describedby="caption-attachment-2553"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" alt="" width="700" height="504" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x738.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w"><figcaption id="caption-attachment-2553">Source: Youtube</figcaption></figure>
<figcaption></figcaption>
</figure>

<p>Ng discussed this topic at re:MARS as well. He revealed how his team adopted a workflow system designed specifically for ML: <strong>1 day sprints</strong>, structured as follows:</p>

<ol>
<li>Build models and write code each day</li>
<li>Set up training and run experiments overnight</li>
<li>Analyze results in the morning and…</li>
<li>Repeat</li>
</ol>

<p>Ng’s 1 day sprints methodology reflects something crucial to understanding and designing teams that practice machine learning: it is an inherently <strong>experimental science</strong>. Because the systems being built lack a clear specification, because data collection is an imperfect science, and because machine learning models are incredibly complex, <em>experimentation is necessary</em>. Rather than structuring team processes around a multi-week sprint, it is usually more fruitful to test out many different architectures, feature engineering choices, and optimization methods rapidly until a rough image of what is working and what isn’t starts to emerge. 1 day sprints allow teams to move quickly, test many hypotheses in a short amount of time, and begin building intuition and knowledge around a modeling task.&nbsp;</p>

<h2><strong>Tools for ML: Experiment Management&nbsp;</strong></h2>

<p>Let’s say you adopt Andrew Ng’s 1 day sprints methodology or something similar (<em>and you should</em>). You’re setting new hyperparameters, tweaking your feature selections, and running experiments each night. What tool are you using to keep track of these decisions for each model training? How are you comparing experiments to see how different configurations are working? How are you sharing experiments with co-workers? Can your manager or co-worker reliably reproduce an experiment you ran yesterday?</p>

<p>In addition to processes, the tools you use to do machine learning matter as well. At Comet, our mission is to help companies extract business value from machine learning by providing a tool that does this for you. Most of the data science teams we speak to are stuck using a combination of git, emails, and (believe it or not) spreadsheets to record all of the artifacts around each experiment.&nbsp;</p>
<figure id="attachment_1994" aria-describedby="caption-attachment-1994"><img src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" alt="" width="700" height="314" srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x459.png" data-src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" data-srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w"><figcaption id="caption-attachment-1994">Comet: Hyperparameter space visualization for 20+ experiments.</figcaption></figure>
<p>

Consider a modeling task where you’re keeping track of 20 hyperparameters, 10 metrics, dozens of architectures and feature engineering techniques, all while iterating quickly and running dozens of models a day. It can become incredibly tedious to manually track all of these artifacts. Building a good ML model can oftentimes resemble tuning a radio with 50 knobs. If you don’t keep track of all of the configurations you’ve tried, the combinatorial complexity of finding the signal in your modeling space can become cumbersome.</p>
<figure id="attachment_2554" aria-describedby="caption-attachment-2554"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" alt="comet exp UI" width="700" height="372" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x544.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w"><figcaption id="caption-attachment-2554">Comet: Single experiment live metric tracking and dashboard</figcaption></figure>
<p><span>We’ve built Comet based on these needs (and what we wanted when we were working on data science and machine learning ourselves, at Google, IBM, and as part of research groups at Columbia University and Yale University). Every time you train a model, there should be </span><em>something</em><span> to capture all of the artifacts of your experiment and save them in some central ledger where you can look up, compare, and filter through all of your (or your team’s) work. Comet was built to provide this function to practitioners of machine learning.&nbsp;</span></p>

<p>Measuring workflow efficiency is a <a href="https://gravityflow.io/articles/measure-workflow-automations-roi/">notoriously difficult</a> thing to do, but on average our users report&nbsp;<em>20-30% time savings by using Comet</em> (note: Comet is free for individuals and researchers – <a href="https://www.comet.ml/pricing?opensignup=true&amp;utm_source=Software%20Eng%20vs%20ML&amp;utm_medium=Blog&amp;utm_campaign=Software%20Eng%20vs%20ML%20Blog%20Post">you can sign-up here</a>). This doesn’t take into account unique insights and knowledge that arise from having access to a visual understanding of your hyperparameter space, real-time metric tracking, team-wide collaboration and experiment comparison. Access to this knowledge enables time savings as well as, and perhaps more importantly, the ability to <em>build better models</em>.</p>

<h2><strong>Looking Ahead</strong></h2>

<p>It is tempting to ignore questions about ML tools and processes altogether. In a field responsible for self-driving cars, voice assistants, facial recognition, and many more groundbreaking technologies, one may be forgiven for leaping into the fray of building these tools themselves and not considering how best to build them.&nbsp;</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</a></em></p>]]>
            </description>
            <link>https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781490</guid>
            <pubDate>Wed, 14 Oct 2020 20:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24779624">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they’re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let’s start with an example. We have an app, and we want to export some data in a JSON format. Here’s what a function for that could look like:</p><pre><code><span>function</span><span> </span><span>exportFile</span><span>() { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>); </span><span>// '{"data": {...</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>); </span><span>// https://foo.com/export.json</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we’re done. </p><p>Okay, we’ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>isCSV</span><span>) { </span>
<span>  </span><span>...</span>
<span>  </span><span>let</span><span> </span><span>fileURL</span>
<span>  </span><span>if</span><span> (</span><span>isCSV</span><span>) { </span>
<span>    </span><span>const</span><span> </span><span>csvStr</span><span> </span><span>=</span><span> </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>csvStr</span><span>);</span>
<span>  } </span><span>else</span><span> { </span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>);</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>);</span>
<span>  }</span>
<span>  </span><span>...</span></code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2 id="the-key-advantage-is-that-our-logic-is-centralized">The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can’t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2 id="the-key-disadvantage-is-thatour-logic-is-centralized">The key <em>disadvantage</em> is that…our logic is centralized.</h2><p>This will work, but let’s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <strong><code>exportFile</code></strong> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn’t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They’d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> — now you have invariant conditions on your hands). By being so specific, you’ve chosen to make your function less abstract — this of course means that it is less powerful.  <strong><code>exportFile</code></strong> <strong>has become hard to extend</strong></p><h2 id="for-better-or-worse-configuration-gives-the-caller-the-least-amount-of-power">For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code><span>...</span>
<span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>...</span><span> </span><span>// *This can be different! Somehow we need to get a fileURL* </span>
<span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>...</span></code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>exportableDataToFileURL</span><span>) { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>exportableDataToFileURL</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Now, for JSON, we can write </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>and for CSV we can write: </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>Oky doke, this is cool. </p><h2 id="the-key-advantage-is-that-you-give-the-caller-more-power">The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won’t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We’ve given the caller much more power</p><h2 id="the-key-disadvantage-is-that-it-can-be-either-too-powerful-or-not-powerful-enough">The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We’ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format — instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it’s possible that there are numerous new usages of <code>exportFile</code>, which we’ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2 id="inversion-lies-in-the-middle-of-the-power-spectrum">Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it’s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code><span>function</span><span> </span><span>exportJSONFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveJSONFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span>
<!-- -->
<!-- -->
<span>function</span><span> </span><span>exportCSVFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveCSVFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span></code></pre><h2 id="the-key-advantage-is-that-the-user-gets-the-most-power">The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We’ve provided a lot of power for the user.</p><h2 id="the-key-disadvantage-is-that-you-are-the-most-vulnerable-to-mistakes">The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn’t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There’s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it’s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you’re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> — if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2 id="composition-is-at-the-end-of-the-spectrum">Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It’s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you’re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779624</guid>
            <pubDate>Wed, 14 Oct 2020 18:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read-Only Mode for Better Rails Downtime]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24778920">thread link</a>) | @christoomey
<br/>
October 14, 2020 | https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/ | <a href="https://web.archive.org/web/*/https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <p>Recently I was looking to upgrade the Postgres version on an application I’ve
been working on. This would require a small amount of downtime, likely about 10
minutes.</p>

<p>The default solution I’d reach for in these cases would be to go into Heroku’s
maintenance mode, which serves an HTML maintenance page with a <code>503 Service
Unavailable</code> status code. This works but makes the application entirely
unusable during the upgrade, and I was hoping to find a better solution. In this
particular case, I also wanted to be able to provide JSON responses as the
application mainly provides an API for a mobile app.</p>

<p>After <a href="https://www.bikeshed.fm/262">exploring a handful of half-baked options</a>, I settled on using a
read-only connection to the database to still allow reads but prevent any
writes from occurring. While using the read-only connection, the Postgres adapter
will raise an error any time we attempt to change data in the database, but we
can easily rescue this specific error and convert it to a user-facing notice. I
felt a bit odd using exceptions as the core of this workflow, but in the end, it
worked out really well, so I wanted to share the specifics.</p>

<p>It’s worth noting that this solution is particularly well suited to this
specific application, which only provides an API and has very read-heavy usage,
but I imagine it could be extended to work with other styles of app as well.</p>

<h2 id="configuring-rails-to-use-the-read-only-connection">Configuring Rails to Use the Read-Only Connection</h2>

<p>If present, Rails will use the connection string in a <code>DATABASE_URL</code> env var to
connect to the database. Following the <a href="https://guides.rubyonrails.org/configuring.html#connection-preference">Connection Preference</a> notes in the
Rails guides, I realized that I could make this <code>DATABASE_URL</code> usage explicit
and allow for a temporary override. To do this, I added an explicit <code>url</code>
property for the production environment with desired connection preference:</p>

<div><pre><code><span># config/database.yml</span>

<span>production</span><span>:</span>
  <span>&lt;&lt;</span><span>:</span> <span>*default</span>
  <span>url</span><span>:</span> <span>&lt;%= ENV["DATABASE_URL_READ_ONLY"] || ENV["DATABASE_URL"] %&gt;</span>
</code></pre></div>
<p>With this in place, I can enable the read-only mode simply by setting the
<code>DATABASE_URL_READ_ONLY</code> env var:</p>

<div><pre><code>heroku config:set <span>\</span>
  <span>DATABASE_URL_READ_ONLY</span><span>=</span><span>'postgres://read_only_user:abc123...'</span> <span>\</span>
  <span>--remote</span> production
</code></pre></div>
<p>Likewise, to disable the read-only mode, I can use:</p>

<div><pre><code>heroku config:unset DATABASE_URL_READ_ONLY <span>--remote</span> production
</code></pre></div>
<p><em>Note</em>: I was able to use <a href="https://devcenter.heroku.com/articles/heroku-postgresql-credentials#managing-permissions">Heroku’s Postgres Credentials</a> interface to create
the read-only user, but if you’re not working with Heroku you should be able to
use <a href="https://dba.stackexchange.com/a/160817">these instructions</a> to create your read-only user.</p>

<h2 id="error-handling">Error Handling</h2>

<p>With other approaches I considered I found that I had to close off multiple
different potential ways to issue writes to the database, but the read-only
connection worked well to cut everything off in one change. That said, it
was only half the solution, as I certainly didn’t want the errors making it to
users.</p>

<p>Thankfully it was relatively straightforward to provide a centralized <code>rescue</code>
that would allow me to handle all the errors. First, I created a module using
Rails’s <code>ActiveSupport::Concern</code> functionality:</p>

<div><pre><code><span># app/controllers/concerns/read_only_controller_support.rb</span>
<span>module</span> <span>ReadOnlyControllerSupport</span>
  <span>extend</span> <span>ActiveSupport</span><span>::</span><span>Concern</span>

  <span>included</span> <span>do</span>
    <span>if</span> <span>ENV</span><span>[</span><span>"DATABASE_URL_READ_ONLY"</span><span>].</span><span>present?</span>
      <span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
        <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
          <span>render</span><span>(</span>
            <span>status: :service_unavailable</span><span>,</span>
            <span>json: </span><span>{</span>
              <span>info: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
            <span>},</span>
          <span>)</span>
        <span>else</span>
          <span>raise</span> <span>error</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<p>When included, this module will use Rails’s <a href="https://api.rubyonrails.org/classes/ActiveSupport/Rescuable/ClassMethods.html#method-i-rescue_from"><code>rescue_from</code></a> method to capture
potentially relevant errors, and then we do a quick check within that block
to make sure we’re only capturing the relevant errors.</p>

<p>Note, the <code>rescue_from</code> logic is only enabled when the <code>DATABASE_URL_READ_ONLY</code>
is set, so we’re able to reuse the existence of that variable as a way to scope
this behavior.</p>

<p>I was then able to include that module in any relevant base controller:</p>

<div><pre><code><span># app/controllers/application_controller.rb</span>
<span>class</span> <span>ApplicationController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>

<span># app/controllers/api/base_controller.rb</span>
<span>class</span> <span>Api</span><span>::</span><span>BaseController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>
</code></pre></div>
<h2 id="non-api-error-handling">Non-API Error Handling</h2>

<p>My initial use case for this read-only mode only needed to support API requests,
but I could imagine extending it to HTML and form-based interfaces.</p>

<p>The first thing I would consider would be adding a sitewide banner that stated
that we were in a read-only maintenance mode to alert users to the current
status.</p>

<p>With that in place, I think we could extend the error handling in the
<code>ReadOnlyControllerSupport</code> module to redirect the user back and display a
relevant message:</p>

<div><pre><code><span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
  <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
    <span>respond_to</span> <span>do</span> <span>|</span><span>format</span><span>|</span>
      <span>format</span><span>.</span><span>json</span> <span>do</span>
        <span># JSON erorr message as shown above</span>
      <span>end</span>

      <span>format</span><span>.</span><span>html</span> <span>do</span>
        <span>redirect_back</span><span>(</span>
          <span>fallback_location: </span><span>root_path</span><span>,</span>
          <span>alert: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
        <span>)</span>
      <span>end</span>
    <span>end</span>
  <span>else</span>
    <span>raise</span> <span>error</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<h2 id="scheduler-and-background-jobs">Scheduler and Background Jobs</h2>

<p>One additional consideration here would be around background jobs and scheduler
processes. For background jobs things are relatively straightforward – we just
need to scale our worker pool down to zero for the read-only period.</p>

<p>Scheduler processes are a little trickier as I didn’t have a mechanism for
globally enabling or disabling them. With that in mind, I think the ideal
solution would be to only ever have scheduler processes enqueue jobs but not
actually do any work beyond that.</p>

<h2 id="migrations">Migrations</h2>

<p>The final sticking point we ran into was migrations. We have a <code>release</code> command
defined in our <code>Procfile</code> that was configured to run <code>rake db:migrate</code>.
Unfortunately, it turns out that even if no migrations run, Rails will still
attempt to write to the <code>ar_internal_metadata</code> table as part of the <code>db:migrate</code>
command, and Heroku will run the release command any time we change an env. In
my initial attempt, Heroku failed when I attempted to set the
<code>DATABASE_URL_READ_ONLY</code> as the associated release command hit the read-only
error when running <code>rake db:migrate</code>.</p>

<p>To work around this I wrote a small script that first checks if there
are any migrations that need to be run, and only if there are, then runs <code>rake
db:migrate</code>:</p>

<div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-e</span>

<span>if </span>bin/rails db:migrate:status | <span>grep</span> <span>'^\s\+down\s'</span><span>;</span> <span>then
  </span>bin/rails db:migrate
<span>fi</span>
</code></pre></div>
<p>This script was added to the repo as <code>bin/migrate-if-needed</code>, and then we
replaced our call to <code>rake db:migrate</code> with <code>bin/migrate-if-needed</code></p>

<h2 id="update-oct-14-2020">Update (Oct 14, 2020)</h2>

<p>After sharing this post, <a href="https://news.ycombinator.com/item?id=24780033">a commenter on Hacker News</a> pointed out <a href="https://github.com/discourse/rails_failover">the
rails_failover gem</a> that their team at Discourse maintains. It seems to offer
similar functionality, but in a more robust and fully thought out way. Looks
like a great option to implement this sort of system.</p>



    </div></div>]]>
            </description>
            <link>https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778920</guid>
            <pubDate>Wed, 14 Oct 2020 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Rolling Out End-to-End Encryption Offering]]>
            </title>
            <description>
<![CDATA[
Score 246 | Comments 152 (<a href="https://news.ycombinator.com/item?id=24778490">thread link</a>) | @giuliomagnifico
<br/>
October 14, 2020 | https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/mkrohn/" title="Max Krohn">
                                            <img src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" alt="Max Krohn" title="Max Krohn">
                                      </a>
                </p>
                
            </div>
                          <p><img src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" alt="Zoom Rolling Out End-to-End Encryption Offering">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>We’re excited to announce that starting next week, Zoom’s end-to-end encryption (E2EE) offering will be available as a technical preview, which means we’re proactively soliciting feedback from users for the first 30 days. Zoom users – free and paid – around the world can host up to 200 participants in an E2EE meeting on Zoom, providing increased privacy and security for your Zoom sessions.</p>



<p>We <a href="https://blog.zoom.us/zoom-acquires-keybase-and-announces-goal-of-developing-the-most-broadly-used-enterprise-end-to-end-encryption-offering/" target="_blank" rel="noreferrer noopener">announced in May</a> our plans to build an end-to-end-encrypted meeting option into our platform, on top of Zoom’s already strong encryption and advanced security features. We’re pleased to roll out Phase 1 of 4 of our E2EE offering, which provides robust protections to help prevent the interception of decryption keys that could be used to monitor meeting content.</p>



<h2>About E2EE</h2>



<p>To be clear, Zoom’s E2EE uses the same powerful GCM encryption you get now in a Zoom meeting. The only difference is where those encryption keys live.</p>



<p>In typical meetings, Zoom’s cloud generates encryption keys and distributes them to meeting participants using Zoom apps as they join. With Zoom’s E2EE, the meeting’s host generates encryption keys and uses public key cryptography to distribute these keys to the other meeting participants. Zoom’s servers become oblivious relays and never see the encryption keys required to decrypt the meeting contents.&nbsp;&nbsp;</p>



<p>“End-to-end encryption is another stride toward making Zoom the most secure communications platform in the world,” said Zoom CEO Eric S. Yuan. “This phase of our E2EE offering provides the same security as existing end-to-end-encrypted messaging platforms, but with the video quality and scale that has made Zoom the communications solution of choice for hundreds of millions of people and the world’s largest enterprises.”</p>



<p>Zoom’s E2EE will be available as a technical preview next week. To use it, customers must enable E2EE meetings at the account level and opt-in to E2EE on a per-meeting basis.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/t2TiiQUVghal7h8dVHrvTZL-14BVFCJELb7TtGg81kjh3EDA62hSNF-_vDucMMyjmLeyYhgGTQwBd214jVKbj4gfjq9o3wwshEo35R9XiijNxcbwl-I6kZzcrcshTDQ4XSo4UcDs"></figure><h2>FAQs</h2>



<p><strong>How does Zoom provide end-to-end encryption?</strong></p>



<p>Zoom’s E2EE offering uses public key cryptography. In short, the keys for each Zoom meeting are generated by participants’ machines, not by Zoom’s servers. Encrypted data relayed through Zoom’s servers is indecipherable by Zoom, since Zoom’s servers do not have the necessary decryption key. This key management strategy is similar to that used by most end-to-end encrypted messaging platforms today.</p>



<p><strong>How do I turn on E2EE?</strong></p>



<p>Hosts can enable the setting for E2EE at the account, group, and user level and can be locked at the account or group level. All participants must have the setting enabled to join an E2EE meeting. In Phase 1, all meeting participants must join from the Zoom desktop client, mobile app, or Zoom Rooms.</p>



<p><strong>When would I use E2EE?</strong></p>



<p>E2EE is best for when you want enhanced privacy and data protection for your meetings, and is an extra layer to mitigate risk and protect sensitive meeting content. While E2EE provides added security, some Zoom functionality is limited in this first E2EE version (more on that below). Individual Zoom users should determine whether they need these features before enabling this version of E2EE in their meetings.</p>



<p><strong>Do I have access to all the features of a regular Zoom meeting?</strong></p>



<p>Not right now. Enabling this version of Zoom’s E2EE in your meetings disables certain features, including join before host, cloud recording, streaming, live transcription, Breakout Rooms, polling, 1:1 private chat, and meeting reactions.</p>



<p><strong>Do free Zoom users have access to end-to-end encryption?</strong></p>



<p>Yes. Free and paid Zoom accounts joining from Zoom’s desktop client or mobile app, or from a Zoom Room, can host or join an E2EE meeting.</p>



<p><strong>How is this different from Zoom’s enhanced GCM encryption?</strong></p>



<p>Zoom meetings and webinars by default use AES 256-bit GCM encryption for audio, video, and application sharing (i.e., screen sharing, whiteboarding) in transit between Zoom applications, clients, and connectors. In a meeting without E2EE enabled, audio and video content flowing between users’ Zoom apps is not decrypted until it reaches the recipients’ devices. However, the encryption keys for each meeting are generated and managed by Zoom’s servers. In a meeting with E2EE enabled, nobody except each participant – not even Zoom’s servers – has access to the encryption keys being used to encrypt the meeting.</p>



<p><strong>How do I verify that my meeting is using end-to-end-encryption?</strong></p>



<p>Participants can look for a green shield logo in the upper left corner of their meeting screen with a padlock in the middle to indicate their meeting is using E2EE. It looks similar to our GCM encryption symbol, but the checkmark is replaced with a lock.</p>



<figure><img loading="lazy" alt="" width="325" height="324" data-src="https://lh3.googleusercontent.com/z-Qf8a0hn5w7dX4q7GAQjGc4iNM_b45r45Um6g7iai7jV9xtmHmcl8WI26vkdAtGfLZrzZTdrszHO6kpgAKspf8rGJ7XcSYrM6asib4EgPyEwFwQkOWmPQuwYI-WplnUflaStT3T"></figure><p>Participants will also see the meeting leader’s security code that they can use to verify the secure connection. The host can read this code out loud, and all participants can check that their clients display the same code.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/Mox0nHn2hmBZqje0OSqXI46iBlhD0YmFzqG0Cv04IIDhUgN76uvL2WCP9NPhZNtKcBV0QMGugkdsUxaeVjgTjnhMrF_DGZBxW7slPIPDYGDUrqYVEiSHFgu-pLAtyYJYgAJ0fJJQ"></figure><p><strong>How will you continue to provide a safe and secure platform?</strong></p>



<p>Zoom’s top priority is the trust and safety of our users, and our implementation of E2EE will allow us to continue to enhance safety on our platform. Free/Basic users seeking access to E2EE will participate in a one-time verification process that will prompt the user for additional pieces of information, such as verifying a phone number via text message. Many leading companies perform similar steps to reduce the mass creation of abusive accounts. We are confident that by implementing risk-based authentication, in combination with our current mix of tools — including our work with human rights and children’s safety organizations and our users’ ability to lock down a meeting, report abuse, and a myriad of other features made available as part of our security icon — we can continue to enhance the safety of our users.</p>



<p><strong>What is the rest of the timeline for E2EE?</strong></p>



<p>We plan to roll out better identity management and E2EE SSO integration as part of Phase 2, which is tentatively roadmapped for 2021.&nbsp;</p>



<p>To learn more about using end-to-end encryption and other security features for your Zoom meetings, visit <a href="https://zoom.us/security" target="_blank" rel="noreferrer noopener">Zoom’s security webpage</a>.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778490</guid>
            <pubDate>Wed, 14 Oct 2020 16:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerfile Security Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 397 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24776771">thread link</a>) | @gbrindisi
<br/>
October 14, 2020 | https://cloudberry.engineering/article/dockerfile-security-best-practices/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/dockerfile-security-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Container security is a broad problem space and there are many low hanging fruits one can harvest to mitigate risks. A good starting point is to follow some rules when writing Dockerfiles.</p>

<p>I’ve compiled a list of common security issues and how to avoid them. For every issue I’ve also written an <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> (OPA) rule ready to be used to statically analyze your Dockerfiles with <a href="https://conftest.dev/">conftest</a>. You can’t shift more left than this!</p>

<p>You can find the <code>.rego</code> rule set in <a href="https://github.com/gbrindisi/dockerfile-security">this repository</a>. I appreciate feedback and contributions.</p>

<h2 id="do-not-store-secrets-in-environment-variables">Do not store secrets in environment variables</h2>

<p>Secrets distribution is a hairy problem and it’s easy to do it wrong. For containerized  applications one can surface them either from the filesystem by mounting volumes or more handily through  environment variables.</p>

<p>Using <code>ENV</code> to store secrets is bad practice because Dockerfiles are usually distributed with the application, so there is no difference from hard coding secrets in code.</p>

<p>How to detect it:</p>

<pre><code>secrets_env = [
    "passwd",
    "password",
    "pass",
 #  "pwd", can't use this one   
    "secret",
    "key",
    "access",
    "api_key",
    "apikey",
    "token",
    "tkn"
]

deny[msg] {    
    input[i].Cmd == "env"
    val := input[i].Value
    contains(lower(val[_]), secrets_env[_])
    msg = sprintf("Line %d: Potential secret in ENV key found: %s", [i, val])
}
</code></pre>

<h2 id="only-use-trusted-base-images">Only use trusted base images</h2>

<p>Supply chain attacks for containerized application will also come from the hierarchy of layers used to build the container itself.</p>

<p>The main culprit is obviously the base image used. Untrusted base images are a high risk and whenever possible should be avoided.</p>

<p>Docker provides a <a href="https://docs.docker.com/docker-hub/official_images/">set of official base images</a> for most used operating systems and apps. By using them, we minimize risk of compromise by leveraging some sort of shared responsibility with Docker itself.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], "/")
    count(val) &gt; 1
    msg = sprintf("Line %d: use a trusted base image", [i])
}
</code></pre>

<p>This rule is tuned towards DockerHub’s official images. It’s very dumb since I’m only detecting the absence of a namespace.</p>

<p>The definition of trust depends on your context: change this rule accordingly.</p>

<h2 id="do-not-use-latest-tag-for-base-image">Do not use ‘latest’ tag for base image</h2>

<p>Pinning the version of your base images will give you some peace of mind with regards to the predictability of the containers you are building.</p>

<p>If you rely on latest you might silently inherit updated packages that in the best worst case might impact your application reliability, in the worst worst case might introduce a vulnerability.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], ":")
    contains(lower(val[1]), "latest"])
    msg = sprintf("Line %d: do not use 'latest' tag for base images", [i])
}
</code></pre>

<h2 id="avoid-curl-bashing">Avoid curl bashing</h2>

<p>Pulling stuff from internet and piping it into a shell is as bad as it could be. Unfortunately it’s a widespread solution to streamline installations of software.</p>

<pre><code>wget https://cloudberry.engineering/absolutely-trustworthy.sh | sh
</code></pre>

<p>The risk is the same framed for supply chain attacks and it <strong>boils down to trust</strong>. If you really have to curl bash, do it right:</p>

<ul>
<li>use a trusted source</li>
<li>use a secure connection</li>
<li>verify the authenticity and integrity of what you download</li>
</ul>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    matches := regex.find_n("(curl|wget)[^|^&gt;]*[|&gt;]", lower(val), -1)
    count(matches) &gt; 0
    msg = sprintf("Line %d: Avoid curl bashing", [i])
}
</code></pre>

<h2 id="do-not-upgrade-your-system-packages">Do not upgrade your system packages</h2>

<p>This might be a bit of a stretch but the reasoning is the following: you want to pin the version of your software dependencies, if you do <code>apt-get upgrade</code> you will effectively upgrade them all to the latest version.</p>

<p>If you do upgrade <strong>and</strong> you are using the <code>latest</code> tag for the base image, you amplify the unpredictability of your dependencies tree.</p>

<p>What you want to do is to pin the base image version and just <code>apt/apk update</code>.</p>

<p>How to detect it:</p>

<pre><code>upgrade_commands = [
    "apk upgrade",
    "apt-get upgrade",
    "dist-upgrade",
]

deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(val, upgrade_commands[_])
    msg = sprintf(“Line: %d: Do not upgrade your system packages", [i])
}
</code></pre>

<h2 id="do-not-use-add-if-possible">Do not use ADD if possible</h2>

<p>One little feature of the <code>ADD</code> command is that you can point it to a remote url and it will fetch the content at building time:</p>

<pre><code>ADD https://cloudberry.engineering/absolutely-trust-me.tar.gz
</code></pre>

<p>Ironically the official docs suggest to use curl bashing instead.</p>

<p>From a security perspective the same advice applies: don’t.
Get whatever content you need before, verify it and then <code>COPY</code>. But if you really have to, <strong>use trusted sources over secure connections</strong>.</p>

<p>Note: if you have a fancy build system that dynamically generate Dockerfiles, then <code>ADD</code> is effectively a sink asking to be exploited.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "add"
    msg = sprintf("Line %d: Use COPY instead of ADD", [i])
}
</code></pre>

<h2 id="do-not-root">Do not root</h2>

<p>Root in a container is the same root as on the host machine, but restricted by the docker daemon configuration. No matter the limitations, if an actor breaks out of the container he will still be able to find a way to get full access to the host.</p>

<p>Of course this is not ideal and your threat model can’t ignore the risk posed by running as root.</p>

<p>As such is best to always specify a user:</p>

<pre><code>USER hopefullynotroot
</code></pre>

<p>Note that explicitly setting a user in the Dockerfile is just one layer of defence and won’t solve the whole <a href="https://www.redhat.com/en/blog/understanding-root-inside-and-outside-container">running as root problem</a>.</p>

<p>Instead one can — and <em>should</em> — adopt a defence in depth approach and mitigate further across the whole stack: strictly configure the docker daemon or use a rootless container solution, restrict the runtime configuration (prohibit <code>--privileged</code> if possible, etc), and so on.</p>

<p>How to detect it:</p>

<pre><code>any_user {
    input[i].Cmd == "user"
 }

deny[msg] {
    not any_user
    msg = "Do not run as root, use USER instead"
}
</code></pre>

<h2 id="do-not-sudo">Do not sudo</h2>

<p>As a corollary to <code>do not root</code>, you shall not sudo either.</p>

<p>Even if you run as a user make sure the user is not in the <code>sudoers</code> club.</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(lower(val), "sudo")
    msg = sprintf("Line %d: Do not use 'sudo' command", [i])
}
</code></pre>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>This work has been inspired and is an iteration on <a href="https://blog.madhuakula.com/dockerfile-security-checks-using-opa-rego-policies-with-conftest-32ab2316172f">prior art</a> from <a href="https://blog.madhuakula.com/@madhuakula">Madhu Akula</a>.</p>
        </div>
        
    </div></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/dockerfile-security-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776771</guid>
            <pubDate>Wed, 14 Oct 2020 14:17:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unspoken Hard Bits of Bootstrapping a SaaS Product to Life]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24776605">thread link</a>) | @geoffroberts
<br/>
October 14, 2020 | https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ec2306edd8f63db4e902"><div><p>The challenges that I’ve faced as a bootstrapped founder simply aren’t the ones that are commonly talked about</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 17 min read</p><p>The internet is littered with horror stories detailing the many challenges of entrepreneurship. We’ve all read the tales of founders wrestling for years to find <a href="https://www.outseta.com/posts/product-market-appetite">product market fit</a>, of co-founders squabbling over equity, of the CEO riddled by anxiety as he drains his infant daughter’s college fund to keep his start-up afloat for another month.</p><p>Cautionary tales? Sure. But while these circumstances may be relatively common, ultimately they gain notoriety in the tech media simply because they are alarmist and clickbait.&nbsp;</p><p>As I approach year four as a founder of a bootstrapped SaaS start-up, I can’t help but reflect on the hardships that I’ve encountered myself. As I have, I’ve had an overwhelming feeling—the majority of challenges that I’ve faced are by no means unique to me, but <em>nobody is talking about them</em>. This article is about surfacing those common entrepreneurial challenges that are gasping for some air.&nbsp;&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180654131_6032"><div><p>I’d go so far as to say most entrepreneurial challenges that we hear being bemoaned are a direct result of your chosen path being incompatible with your business idea or life circumstances. When these items are in harmony, entrepreneurship becomes vastly easier.</p><p>If you’re building SpaceX, your idea dictates that you go the VC route—it’s too big, too ambitious, and too capital intensive to bootstrap such a company into existence. This is an extreme example, but this is the lens through which we should be assessing our start-up ideas as we decide how to fund them.</p><p>Generally speaking, “smaller” products are better suited to bootstrapping. Building a slack notification tool? Great! You can probably launch something like this in less than a month, give the project the opportunity to gain some traction, then make the decision to proceed or not from there. You’d be crazy <em>not</em> to bootstrap such a company.&nbsp;&nbsp;&nbsp;</p><p>But if you’re building a bigger and more ambitious piece of software you need to look closely at the reality that it could take years to bring something of value to fruition. Can you afford a year without a paycheck? How about three years, or five?&nbsp;</p><p>It’s worth noting that this isn’t solely a financial decision or one of product scope, but also one that will impact your day-to-day life potentially for years to come. Did you recently sign a mortgage? Do you plan on having kids? The stresses that come with entrepreneurship and how you choose to fund your business will have trickle down effects on all aspects of your life.</p><p>The question is not do you prefer bootstrapping or venture capital. The question is which path is most compatible with the product you’re building… and your life.&nbsp;</p><p>Bringing this full circle to Outseta, in many ways Outseta is not an idea compatible with the idea of bootstrapping. Outseta is a very large and ambitious project that we’re executing on with a small team—it’s really three or four different software products rather than one. We knew this going in and openly talked about how it would take years for us to truly be able to deliver on our value proposition and start to grow revenue in a meaningful way. It took us two years to deliver a sellable product, and four years in now we’re just starting to scale.&nbsp;</p><p>But we had one major advantage—the idea that we chose to build was not one that needed “validating”—the categories of software that we offer (CRM, billing, email marketing, etc) have staying power and have been validated long ago. This gave us confidence that we could play the long game and allowed us to design all aspects of our business and lives so that we could survive long enough to see Outseta blossom into what it’s become today.&nbsp;</p><p>We didn’t choose an easy route, but we’re now finding that Outseta is massively defensible because very few teams would commit 4+ years just to bring an idea to life. You could do it much more quickly with venture capital, sure, but you’d never be able to serve the audience that we do at our price point.&nbsp;</p><h2>The “Doldrums” of SaaS</h2><p>One of the most common and least talked about hardships of bootstrapping a SaaS start-up is what I’ve started describing as “the doldrums of SaaS.” This occurs when your start-up hits an inflection point in sign-ups and support requests scale up dramatically to the extent that they all but take over your ability to focus on other aspects of your business, from marketing to building new features.</p><p>Ironically enough, this stage in a bootstrapped start-up’s growth initially became apparent to me because of one of our competitors. We started getting dozens of sign-ups from founders all singing the same tune.&nbsp;</p><p><em>“I was using CompetitorX—I loved their product initially, but they’re unresponsive and haven’t released any new features in months.”</em></p><p>Then earlier this spring, we went through a similar stage. On the back of a new partnership with <a href="https://www.outseta.com/webflow">Webflow</a>, all of a sudden the number of sign-ups for Outseta scaled up dramatically—and in tandem with that growth came an influx of support tickets from new users learning the platform.</p><p>My summer was spent focused almost entirely on technical support, while my time spent marketing Outseta fell off a cliff. Likewise, my Co-founders were pushing fixes and helping out with new Outseta implementations cutting into their ability to roll out new features.</p><p>Ultimately this is a stage in a bootstrapped start-up’s growth that doesn’t get much lip service because there’s little benefit to speaking about increased support levels and decreased capacity for building new features. But that’s unfortunate because this is a “good problem” that nearly every scaling company will encounter—yet there’s very little advice out there on how to best handle this stage of the entrepreneurial journey.</p><p>If you’re a VC backed company, it’s an easy problem to fix—throw some money at hiring additional support capacity, because you have the ability to run your company at a loss. But for a bootstrapper this stage can feel like your legs are stuck in quicksand.</p><p>I don’t have a solution here, aside from taking some degree of solace in the thought that time spent helping customers is the most single important thing that you can do to build your business. And rather than hiring support capacity, using your engineering resources to solve underlying issues that result in increased support requests will always pay off in the long run.</p><h2>The psychological toll of not feeling like you’re “all-in”</h2><p>It’s well documented that many entrepreneurs feel extreme levels of stress, anxiety, worry, and even depression—which most often is tied to financial instability and the regular peaks and valleys of building a company. But for me personally—and I suspect many others—one of the strongest psychological tolls I’ve felt is stress that comes from feeling like I’m not yet able to be “all-in” on my start-up.</p><p>Make no mistake about it—since the day we started Outseta, I’ve undoubtedly been “all-in.” I’ve rearranged almost all aspects of my life over four years in support of bringing this company into existence. But as part of our strategy to <a href="https://www.outseta.com/posts/marketing-strategies-for-bootstrappers">bootstrap the business</a>, our entire team began working on Outseta in a part-time capacity while consulting or working on other projects to pay the bills. We’ve gradually ramped up the time we’ve each invested in the business as our growth has permitted, as most bootstrappers do.</p><p>For me personally, this meant that for years, literally, there was always this nagging feeling that I could be doing more. I could be doing more or doing better for Outseta, and I could be doing more in terms of the other projects I was working on as well. For me, that feeling has been tough. It feels really good to be able to say that you unequivocally, without question, are giving something your all. But most bootstrappers have to wait quite a long period of time until their business can truly support every last scrap of their attention at work. That’s a long period of time to wait to shed that nagging feeling!</p><h2>SaaS <em>is</em> a torture chamber</h2><p>The wonders of SaaS as a business model are well known—the stability and predictability of recurring revenue, products that can scale to thousands of users, high valuations—the whole nine yards. But the fact of the matter is that for bootstrapped founders, SaaS <em>is</em> a torture chamber and a game of delayed gratification.</p><p>Don’t misunderstand me and immediately suppose that there’s some sort of self-inflicted pain behind this comment—I’m the biggest proponent of work/life balance and generally the principles outlined in Jason Fried and DHH’s <a href="https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780"><em>It Doesn’t Have To Be Crazy At Work</em></a> that you’ll ever find. This is solely a matter of the business model.</p><p>When you’re bootstrapping, you’re going to start off without a paycheck. Most of us work towards a point where the revenue of the business can eventually start to pay us something, then we scale up our own compensation until it reaches some semblance of a normal salary. The problem with SaaS and bootstrapping is you are hugely incentivized not to pay yourself—every dollar that you pay yourself is money that isn’t being reinvested in the growth of your business, so you’re intentionally slowing down your own growth.</p><p>Of course there are human, real world circumstances to consider and your own financial and emotional needs directly correlate to your ability to work on your business successfully. But the hard reality is the longer you can delay your own gratification, the greater your advantage.&nbsp;</p><p>I asked my Co-founder, Dimitris, to speak to his experience of the long, slow ramp of death that’s so prevalent in SaaS. Dimitris Co-founded <a href="https://www.buildium.com/">Buildium</a> back in 2004.</p><p>“It took us 2.5 years to get to 50 customers,” says Dimitris. “Then it took us another year to get to 400 customers, and a year after that we reached 1,000 customers. When we had 400 customers we made a conscious decision to defer paying ourselves more than a token $1,000 per month salary and instead hired our first two full-time …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776605</guid>
            <pubDate>Wed, 14 Oct 2020 14:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 CPU User Manual (2016)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24776115">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://zany80.github.io/documentation/Z80/UserManual.html | <a href="https://web.archive.org/web/*/https://zany80.github.io/documentation/Z80/UserManual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zany80.github.io/documentation/Z80/UserManual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776115</guid>
            <pubDate>Wed, 14 Oct 2020 13:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 129 (<a href="https://news.ycombinator.com/item?id=24775556">thread link</a>) | @Tomte
<br/>
October 14, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f2d715d8-a1f9-49fb-89e6-743fbdf962b5&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;793e0af0-fcef-464b-9ef2-57a04649cf6e&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;d371e127-3b85-477b-9783-91d4e5abc4b3&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;2f669bba-fabe-4a7c-a027-c172d161c05a&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775556</guid>
            <pubDate>Wed, 14 Oct 2020 11:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Master System Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24775305">thread link</a>) | @Parseus
<br/>
October 14, 2020 | https://www.copetti.org/projects/consoles/master-system/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/master-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Master System comes from a long line of succession. What started as a collection of off-the-shelf components, has now gained a new identity thanks to Sega’s engineering.</p><hr><h2 id="models-and-variants">Models and variants</h2><p>I was a bit confused at first while reading about the different models that Sega ended up shipping, so here is a summary of the main models discussed to avoid further confusions:</p><ul><li><strong>Sega Mark III</strong>: The first console featuring this architecture, only released in Japan.</li><li><strong>Sega Master System</strong> (Europe and America): A rebranded Mark III with a new case, a BIOS ROM chip and a different cartridge slot.</li><li><strong>Sega Master System</strong> (Japan): An European/American Master system with the Mark III’s cartridge slot, a new FM chip and a jack port for ‘3D glasses’. However, it lacks the <code>RESET</code> button.</li></ul><p>From now one I’ll use the term ‘Master System’ or ‘SMS’ to refer to all of these, except when talking about exclusive features from a particular model.</p><hr><h2 id="cpu">CPU</h2><p>Sega decided on a fully-fledged <strong>Zilog Z80</strong> CPU running at <strong>~3.58 MHz</strong>. A popular choice by other machines like the ZX Spectrum and the Amstrad CPC. The Z80 has an instruction set compatible with the Intel 8080 but expanded with lots of more instructions.</p><p>The motherboard picture at the start of the article shows a NEC D780C-1 CPU, that’s just SEGA second-sourcing the chip to different manufacturers, other revisions even included the chip manufactured by Zilog. But for this article, it doesn’t matter who fabricated the CPU, as the internal features remain the same.</p><h4 id="memory-available">Memory available</h4><p>The Z80 has a 16-bit address bus, so the CPU can find up to 64 KB worth of memory. In the memory map you’ll find <strong>8 KB of RAM</strong> for general purpose use, this is mirrored in another 8 KB block. Finally, <strong>up to 48 KB of game ROM</strong> are mapped as well.</p><h4 id="accessing-the-rest-of-the-components">Accessing the rest of the components</h4><p>As you can read from the previous paragraph, only main RAM and some cartridge ROM is found on the address space, so how can the program access other components? Well, unlike Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/">Famicom/NES</a>, not all the hardware of the Master System is mapped using memory locations. Instead, some peripherals are found on the <strong>I/O space</strong>.</p><p>This is because the Z80 family contains an interesting feature called <strong>I/O ports</strong> which enables the CPU to communicate with other hardware without running out of memory addresses. For this, there’s a separate address space for ‘I/O devices’ called <strong>ports</strong> and both share the same data and address bus. The difference, however, is that ports are read and written using <code>IN</code> and <code>OUT</code> instructions, respectively - as opposed to the traditional load/store instruction (<code>LD</code>).</p><p>When an <code>IN</code> or <code>OUT</code> instruction is executed, the Z80 sets up the address lines pointing to the peripheral (which could be, for instance, a keyboard), flags its <code>IORQ</code> pin indicating that an I/O request has been initiated and also flags the <code>RD</code> pin or the <code>WR</code> pin whether it’s an <code>IN</code> or <code>OUT</code> instruction, respectively. The addressed peripheral must manually check for the address bus and the I/O pins and perform the required operation. In the case of an <code>IN</code> instruction, the CPU will store the received value on a pre-defined register.</p><div><a href="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png"><picture>
<img name="image_cover" alt="Image" width="944" height="315" src="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png" loading="auto"></picture></a><figcaption>SMS' Addressing layout</figcaption></div><p>The way SEGA interconnected the CPU with the rest of the components enables not only to access values, but also showing/hiding certain components from appearing in the memory map.</p><p>Curiously enough, the <a href="https://www.copetti.org/projects/consoles/game-boy/#cpu">Game Boy</a> had a Z80 ‘variant’ that completely omitted the I/O ports. Thus, it had to fit everything in the memory map.</p><h4 id="backwards-compatibility">Backwards compatibility</h4><p>The architecture of this console is very similar to its predecessor, the <strong>Sega SG-1000</strong>, so the Master System managed to gain backwards compatibility with the SG-1000. Although, this only applies to the Japanese variant since the others contain a different cartridge slot.</p><hr><h2 id="graphics">Graphics</h2><p>The drawings on the screen are produced by a proprietary chip called <strong>Video Display Processor</strong> or ‘VDP’. Internally, it has the same design of the Texas instrument TMS9918 (used in the SG-1000), but enhanced with more features which we will discuss in the following sections.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/vdp.a9e73f34b06e33eb7278cf345c26c9a9ab73ae955fdd1a2e97fdcd4626120053.png"><picture>
<img name="image_cover" alt="Image" width="1020" height="303" src="https://www.copetti.org/images/consoles/mastersystem/vdp.a9e73f34b06e33eb7278cf345c26c9a9ab73ae955fdd1a2e97fdcd4626120053.png" loading="auto"></picture></a><figcaption>Memory architecture of the VDP</figcaption></div><p>Next to the VDP is connected <strong>16 KB of VRAM</strong> which only the VDP can access using a 8-bit data bus. If you look at the motherboard picture again, you’ll notice that both RAM and VRAM chips are roughly the same, except that VRAM uses the chip model ending in ‘20’ which has lower latency.</p><p>In the case of the Master System, VRAM houses everything the VDP will require for rendering (except Colour RAM). The CPU fills VRAM by writing on VDP’s registers, which will in turn forward the values to VRAM. Since the VDP is accessed using I/O ports, the CPU must use <code>IN</code> and <code>OUT</code> instructions.</p><h4 id="constructing-the-frame">Constructing the frame</h4><p>The VDP renders frames with a resolution of <strong>up to 256x192 pixels</strong>, further revision added support for 256x224 px and 256x240 px, however, to maintain compatibility with all models, developers held on to the standard resolution. This chip has the same <em>modus operandi</em> of Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/#constructing-the-frame">PPU</a>, in other words, graphics are rendered on-the-spot.</p><p>On the other side, the VDP has four different modes of operation which will alter the characteristics of the frame (colour depth and resolution):</p><ul><li><strong>Mode 0 to III</strong>: Inherited from the TMS9918 found on the SG-1000. Included for backwards compatibility, although any SMS game can use them.</li><li><strong>Mode IV</strong>: Native mode of the Master System, which enables access to all the state-of-the-art features of the VDP. For the analysis, we’ll focus on this one!</li></ul><p>Now let’s see how a frame is drawn step by step, for this, I’ll borrow <em>Sonic The Hedgehog</em>’s assets. Also, to make explanations easier, I’m going to focus on the standard memory layout that Sega suggest for organising the graphics content (just remember that the VDP is very flexible with this, so games are allowed to optimise it).</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-background-layer-link"><a href="#tab-2-2-background-layer">Background Layer</a></li><li id="tab-2-3-sprite-layer-link"><a href="#tab-2-3-sprite-layer">Sprite Layer</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><p>Mode IV is based on the <strong>tile system</strong>. To recall <a href="https://www.copetti.org/projects/consoles/nes/#tab-2-1-tiles">previous explanations</a> about tile engines, tiles are just <strong>8x8 pixel bitmaps</strong> which the renderer fetches to draw the game’s graphics. In the case of the VDP, the frame is composed of two planes, the background layer and the sprite layer.</p><p>Inside VRAM, there’s an area dedicated for tiles called <strong>Character generator</strong> (Sega calls ‘Characters’ to tiles) and it’s set to be <strong>14 KB long</strong>. Each tile occupies 32 bytes, so we can store up to 448 tiles.</p><p>There are 64 pixels defined on every tile, the VDP rules that each pixel must weight 4 bits, that means that up to <strong>16 colours can be chosen</strong>. Those bits reference a single entry on <strong>Colour RAM</strong> or ‘CRAM’. That area is found inside the VDP and stores the colour palettes. Colour palette systems help reduce the size of tiles in memory and allows programmers to alternate its colours without storing multiple copies.</p><p>Colour RAM stores <strong>two palettes of 16 colours each</strong>. Each entry is 6-bit wide and each 2-bit set defines one colour from the RGB model. This means that there are 64 colours available to choose from.</p></div><div id="tab-2-2-background-layer"><h4>Background Layer</h4><p>The background layer is a large plane where static tiles are drawn. To place something here, there’s another area on VRAM called <strong>Screen map</strong> that takes 1.75 KB.</p><p>This enables to build a layer of 896 tiles (32x28 tiles), but if we do the math we’ll see that this layer is larger than the display resolution of this console. The reality is, only 768 tiles (32x24 tiles) are visible, so the visible area is manually selected at the programmer’s will. Hence, by slowly alternating the X and Y coordinates of the selected area, a <strong>scrolling effect</strong> is accomplished.</p><p>Each entry of the map is 2 bytes wide (as wide as the VDP data-bus) and contains the address of the tile in the Character generator and the following attributes:</p><ul><li><strong>Horizontal and Vertical flip</strong>.</li><li>The <strong>priority bit</strong> (whether to draw some or all the tile in front of sprites).</li><li>The <strong>colour palette</strong> used.</li></ul><p>Curiously enough, there are 3 unused bits in the entry which the game can use for other purposes (i.e. extra flags to assist the game engine).</p></div><div id="tab-2-3-sprite-layer"><h4>Sprite Layer</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>Sprites are just tiles that move freely. The VDP can raster <strong>up to 64 sprites</strong> using a single tile (8x8 px) or two tiles stacked vertically (8x16 px).</p><p>The <strong>Sprite Attribute Table</strong> is a 256-byte area in VRAM that contains an array of all the sprites defined, its entries are similar to the background layer, except each sprite contain two additional values representing the X/Y coordinates.</p><p>The VDP is limited to <strong>up to eight sprites per horizontal scan-line</strong>. Also, if two sprites overlap, the last one in the list will be the one displayed.</p></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png" loading="auto"></picture></a><figcaption>Tada!</figcaption></div><p>The VDP automatically blends the two layers to form the final frame. The rendering process is done scan-line by scan-line, so the VDP doesn’t really know how the frame is going too look, that’s only seen by the user when the picture is constructed on the TV.</p><p>If you look at the example image, you may notice the frame has a vertical column at the left side. This is because the screen map is only tall enough to provide vertical scrolling without producing artefacts, <strong>but not wide enough for horizontal scrolling</strong>. So, the VDP can <strong>mask</strong> the left-most side with an 8 px column to protect the image from showing intermediate tiles.</p><p>To update the graphics for the next frame without breaking the image currently being displayed, the VDP sends two types of <strong>interrupts</strong> to the CPU. One which notifies that the CRT TV has finished beaming a chosen number of scan-lines (called <strong>horizontal interrupt</strong>) and another when the CRT finished drawing the last scan-line (called <strong>vertical interrupt</strong>) indicating the frame is finished. During those events, the CRT’s beam is re-allocating to draw the next scan-line (<strong>blanking interval</strong>), so any alteration of the VDP’s state won’t tear the image down. Horizontal blanking has a shorter time-frame than vertical blanking, yet it still allows to change, let’s say, the colour palette. This still can achieve some effects.</p></div></div></div><h4 id="secrets-and-limitation">Secrets and limitation</h4><p>At first glance, the VDP may seem like another chip with minimal functionality that we now take for …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/master-system/">https://www.copetti.org/projects/consoles/master-system/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/master-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775305</guid>
            <pubDate>Wed, 14 Oct 2020 11:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visidata 2.0]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24774947">thread link</a>) | @polm23
<br/>
October 14, 2020 | https://www.visidata.org/blog/2020/v2.0/ | <a href="https://web.archive.org/web/*/https://www.visidata.org/blog/2020/v2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="body">
        
<p>This is a major milestone. After almost 2 years of development, version 2.0 of VisiData is finally released. It's got several major improvements, a bunch of new loaders, and tons of new features and quality of life improvements. And, most importantly, an API specification for plugins.</p>
<h2>1. Licensing Changes</h2>
<p>[tl;dr: no more MIT vdtui; GPL3 for everything]</p>
<p>Previously, there was a core vdtui single-file library that I licensed as MIT, as I thought it might be a platform for a variety of apps like VisiData. Approximately no one showed interest in that though, and it became unwieldy to maintain, so over the course of developing VisiData 2.0, the vdtui library was thoroughly dismantled. It's now just the visidata module as a whole, which I'm releasing under GPL3. The last released version of vdtui.py under MIT was 1.5.2 if anyone wants to use that.</p>
<h2>2. Plugin API</h2>
<p>[tl;dr: "2.0" has a stable documented API; expect a growing ecosystem of plugins for a wide variety of use cases.]</p>
<p>To be honest, this is what held off the 2.0 release for so long. I knew I wanted to go through every function and decide whether I wanted to include it in the 2.0 API to be supported for the rest of the 2.x lifecycle, which might be years. (We don't intend to strictly adhere to "semver", but it's still important to try to maintain backwards compatibility within a major version number.) So now, we have an API spec with over 200 functions, which will be of interest if you want to customize VisiData, or create a plugin for it, or just to know more about its internal components.</p>
<p>Take a look at the actual API, at <a href="https://visidata.org/docs/api">visidata.org/docs/api</a>. It still needs a bit more polish, but the meat and bones are there.</p>
<h2>3. Undo and Redo</h2>
<p>This is a "game changer" according to @jsvine.</p>
<p>Undo and redo, along with the new <code>guard-sheet</code> command, make it much easier to rely on VisiData for data cleaning and data entry.</p>
<p>If you upgrade to 2.0 and learn nothing else about it, your life will be better for knowing Shift+U (undo) and Shift+R (redo).</p>
<h2>4. Deferred modifications</h2>
<p>[tl;dr: if you add/edit/delete rows on a few specific sheets, the changes won't take place right away; you'll have to press z Ctrl+S]</p>
<p>Certain sheets which know how to incrementally update their source--notably, the DirSheet and SqliteSheet--<strong>defer</strong> changes made to them, requiring an explicit save/commit step with commit-sheet (z Ctrl+S).</p>
<p>These changes are colorized on the screen and can be saved as data (or not saved, in the case of deletes) with save-sheet (Ctrl+S), even if they haven't been committed back to the original source with commit-sheet.</p>
<p>This means vd can work quite naturally as an interactive file manager, or as a sqlite database editor. I've been using it to manage my mp3 collection and my personal contacts database, which was a tsv file until I wanted to add a multiline "notes" field, so I saved it as a .json file and used that for a few months, and now I've been using it in an sqlite database. Of course they all look the same in VisiData so I can go back and forth without any friction.</p>
<h2>5. Split Window</h2>
<p>Press Shift+Z to split the terminal window into a top panel and bottom panel.</p>
<p>One panel contains the current/top sheet, the other panel contains the sheet "under" the top sheet. Press Tab or Ctrl+^ to go between them.</p>
<p>The fancy chooser (now the default for choosing aggregators or jointypes) uses this split window, and I have many other ideas for it as well.</p>
<p>It may not seem like much now, but I predict that this becomes a sleeper hit.</p>
<p>[previously blogged at: <a href="https://visidata.org/blog/2020/splitwin">visidata.org/blog/2020/splitwin</a>)]</p>
<h2>6. So many other features</h2>
<p>Here's curated list of highlights, the ones that seemed like people would be interested to know about:</p>
<ul>
<li>more visibility for long values, with "v" to toggle multi-line rows and and z+hjkl to adjust cell offset</li>
<li>[iota] the "i" family of commands to add an increment column</li>
<li>[unfurl] zM, which does row-wise expansion of iterables in a column (very useful with nested data)</li>
<li>[join] add "merge" jointype</li>
<li>[numeric binning] ranged binning for numeric columns</li>
<li>[cli] custom options parsing allows for per-sheet options</li>
<li>[cli] pipe and redirect to stdout; use as an interactive chooser</li>
<li>[input] Ctrl+Y paste from cell clipboard and other improvements</li>
<li>Alt+ as new keyboard layer for user keybindings</li>
</ul>
<p>And, as with every release, there are a bunch of new loaders, including MIME, recutils, vcard, imap, mysql, pdf, npy/npz, and more! See the new <a href="https://visidata.org/formats">/formats</a> page for a full list of supported formats, in tidy tabular form.</p>
<p>Then if you still haven't seen enough, you can see the <a href="https://github.com/saulpw/visidata/blob/stable/CHANGELOG.md#v2.0">CHANGELOG</a> for the complete list of bugfixes and changes.</p>
<p>Okay, that about wraps it up for this release. If anything I've written about here sounds interesting and you'd like me to cover it first, or more in-depth, let me know! Send me <a href="https://www.visidata.org/blog/2020/v2.0/vd@saul.pw">an email</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/twitter.com/VisiData">tweet @VisiData</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/github.com/saulpw/visidata/issues">open a github issue</a>, or chat with us on Freenode #visidata; however you want to get in touch, we'd love to hear from you.</p>

     </section></div>]]>
            </description>
            <link>https://www.visidata.org/blog/2020/v2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24774947</guid>
            <pubDate>Wed, 14 Oct 2020 10:02:37 GMT</pubDate>
        </item>
    </channel>
</rss>
