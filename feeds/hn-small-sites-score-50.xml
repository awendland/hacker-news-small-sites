<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 20 Aug 2020 12:26:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 20 Aug 2020 12:26:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Architecture of the Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24195751">thread link</a>) | @Polylactic_acid
<br/>
August 17, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graphics</h2><p>This section is a bit unusual because not only this console has multiple screens to draw, but also a combination of traditional tile engines working …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195751</guid>
            <pubDate>Tue, 18 Aug 2020 06:06:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let’s Learn x86-64 Assembly: Part 0 – Setup and First Steps]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24195627">thread link</a>) | @nice_byte
<br/>
August 17, 2020 | https://gpfault.net/posts/asm-tut-0.txt.html | <a href="https://web.archive.org/web/*/https://gpfault.net/posts/asm-tut-0.txt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
    <main role="main">

        
        
<p><img src="https://gpfault.net/assets/post-img/asm-tut-0/header.png">
</p>

<p>
The way I was taught x86 assembly at the university had been completely outdated for many years by the time I had my first class. It was around 2008 or 2009, and 64-bit processors had already started becoming a thing even in my neck of the woods. Meanwhile, we were doing DOS, real-mode, memory segmentation and all the other stuff from the bad old days.
</p>

<p>
Nevertheless, I picked up enough of it during the classes (and over the subsequent years) to be able to understand the stuff coming out of the other end of a compiler, and that has helped me a few times. However, I've never manually written any substantial amount of x86 assembly for something non-trivial. Due to being locked up inside (on account of a global pandemic), I decided to change that situation, to pass the time.
</p>

<p>
I wanted to focus on x86-64 specifically, and completely forget/skip any and all legacy crap that is no longer relevant for this architecture. After getting a bit deeper into it, I also decided to publish my notes in the form of tutorials on this blog since there seems to be a desire for this type of content.
</p>

<p>
Everything I write in these posts will be a normal, 64-bit, Windows program. We'll be using Windows because that is the OS I'm running on all of my non-work machines, and when you drop down to the level of writing assembly it starts becoming incresingly impossible to ignore the operating system you're running on. I will also try to go as "from scratch" as possible - no libraries, we're only allowed to call out to the operating system and that's it.
</p>

<p>
In this first, introductory part (yeah, I'm planning a series and I know I will regret this later), I will talk about the tools we will need, show how to use them, explain how I generally think about programming in assembly and show how to write what is perhaps the smallest viable Windows program.
</p>

<h2>Getting the Tools</h2>
<p>There are two main tools that we will use throughout this series.</p>

<h3>Assembler</h3>

<p>
CPUs execute machine code - an efficient representation of instructions for the processor that is almost completely impenetrable to humans. The assembly language is a human-readable representation of it. A program that converts this symbolic representation into machine code ready to be executed by a CPU is called an <b>assembler</b>.
</p>

<p>
There is no single, agreed-upon standard for x86-64 assembly language. There are many assemblers out there, and even though some of them share a great deal of similarities, each has its own set of features and quirks. It is therefore important which assembler you choose. In this series, we will be using 
<a href="http://flatassembler.net/">Flat Assembler</a> (or FASM for short). I like it because it's small, easy to obtain and use, has a nice macro system and comes with a handy little editor.</p>

<h3>Debugger</h3>

<p>
Another important tool is the debugger. We'll use it to examine the state of our programs. While I'm pretty sure it's possible to use Visual Studio's integrated debugger for this, I think a standalone debugger is better when all you want to do is look at the disassembly, memory and registers. I've always used <a href="http://ollydbg.de/">OllyDbg</a> for stuff like that, but unfortunately it does not have a 64-bit version. Therefore we will be using <a href="https://www.microsoft.com/en-us/p/windbg-preview/9pgjgd53tn86?activetab=pivot:overviewtab">WinDbg</a>. The version linked here is a revamp of this venerable tool with a slightly nicer interface. Alternatively, you can get the non-Windows-store version <a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-download-tools">here</a> as part of the Windows 10 SDK. Just make sure you deselect everything else besides WinDbg during installation. For our purposes, the two versions are mostly interchangeable.
</p>

<h2>Thinking in Assembly</h2>

<p>
Now that we have our tools, I want to spend a bit of time to discuss some basics. For the purpose of these tutorials I'm assuming some knowledge of languages like C or C++, but little or no previous exposure to assembly, therefore many readers will find this stuff familiar.
</p>
<h3>A 10000-foot view</h3>
<p>
CPUs only "know" how to do a fixed number of certain things. When you hear someone talk about an "instruction set", they're referring to the set of things a particular CPU has been designed to do, and the term "instruction" just means "one of the things a CPU can do". Most instructions are parameterized in one way or another, and they're generally really simple. Usually an instruction is somthing along the lines of "write a given 8-bit value to a given location in memory", or "interpreting the values from registers A and B as 16-bit signed integers, multiply them and record the result into register A".
</p>

<p>
Below is a simple mental model of the architecture that we'll start with.
</p>

<p><img src="https://gpfault.net/assets/post-img/asm-tut-0/diag0.png">
</p>

<p>
 This skips a <i>ton</i> of things (there can be more than one core executing instructions and reading/writing memory, there's different levels of cache, etc. etc.), but should serve as a good starting point.
</p>

<p>
 To be effective at low-level programming or debugging you need to understand that every high-level concept eventually maps to this low-level model, and learning how the mapping works will help you.
</p>

<h3>Registers</h3>
<p>
 You can think of <b>registers</b> as a special kind of memory built right into the CPU that is very small, but extremely fast to access. There are many different kinds of registers in x86-64, and for now we'll concern ourselves only with the so-called <i>general-purpose</i> registers, of which there are sixteen. Each of them is 64 bits wide, and for each of them the lower byte, word and double-word can be addressed individually (incidentally, 1 "word" = 2 bytes, 1 "double-word" = 4 bytes, in case you haven't heard this terminology before).
 </p>
 
 <table>
 <tbody><tr>
  <td><b>Register</b></td>
  <td><b>Lower byte</b></td>
  <td><b>Lower word</b></td>
  <td><b>Lower dword</b></td>
 </tr>
 <tr>
  <td>rax</td> <td>al</td> <td>ax</td> <td>eax</td>
 </tr>
 <tr>
  <td>rbx</td> <td>bl</td> <td>bx</td> <td>ebx</td>
 </tr>
 <tr>
  <td>rcx</td> <td>cl</td> <td>cx</td> <td>ecx</td>
 </tr>
 <tr>
  <td>rdx</td> <td>dl</td> <td>dx</td> <td>edx</td>
 </tr>
 <tr>
  <td>rsp</td> <td>spl</td> <td>sp</td> <td>esp</td>
 </tr>
 <tr>
  <td>rsi</td> <td>sil</td> <td>si</td> <td>esi</td>
 </tr>
 <tr>
  <td>rdi</td> <td>dil</td> <td>di</td> <td>edi</td>
 </tr>
 <tr>
  <td>rbp</td> <td>bpl</td> <td>bp</td> <td>ebp</td>
 </tr>
 <tr>
  <td>r8</td> <td>r8b</td> <td>r8w</td> <td>r8d</td>
 </tr>
 <tr>
  <td>r9</td> <td>r9b</td> <td>r9w</td> <td>r9d</td>
 </tr>
 <tr>
  <td>r10</td> <td>r10b</td> <td>r10w</td> <td>r10d</td>
 </tr>
 <tr>
  <td>r11</td> <td>r11b</td> <td>r11w</td> <td>r11d</td>
 </tr>
 <tr>
  <td>r12</td> <td>r12b</td> <td>r12w</td> <td>r12d</td>
 </tr> 
 <tr>
  <td>r13</td> <td>r13b</td> <td>r13w</td> <td>r13d</td>
 </tr> 
 <tr>
  <td>r14</td> <td>r14b</td> <td>r14w</td> <td>r14d</td>
 </tr> 
 <tr>
  <td>r15</td> <td>r15b</td> <td>r15w</td> <td>r15d</td>
 </tr>   
</tbody></table>  

<p>Additionally, the higher 8 bits of <code>rax</code>, <code>rbx</code>, <code>rcx</code> and <code>rdx</code> can be referred to as <code>ah</code>, <code>bh</code>, <code>ch</code> and <code>dh</code>.</p>

<p>
Note that even though I said those were "general-purpose" registers, some instructions can only be used with certain registers, and some registers have special meaning for certain instructions. In particular, <code>rsp</code> holds the stack pointer (which is used by instructions like <code>push</code>, <code>pop</code>, <code>call</code> and <code>ret</code>), and <code>rsi</code> and <code>rdi</code> serve as source and destination index for "string manipulation" instructions. Another example where certain registers get "special treatment" are the multiplication instructions, which require one of the multiplier values to be in the register <code>rax</code>, and write the result into the pair of registers <code>rax</code> and <code>rdx</code>.
</p>

<p>
In addition to these registers, we will also consider the special registers <code>rip</code> and <code>rflags</code>. <code>rip</code> holds the address of the next instruction to execute. It is modified by control flow instructions like <code>call</code> or <code>jmp</code>. <code>rflags</code> holds a bunch of binary flags indicating various aspects of the program's state, such as whether the result of the last arithmetic operation was less, equal or greater than zero. The behavior of many instructions depends on those flags, and many instructions update certain flags as part of their execution. The flags register can also be read and written "wholesale" using special instructions.
</p>

<p>
There are a lot more registers on x86-64. Most of them are used for SIMD or floating-point instructions, and we'll not be considering them in this series.
</p>

<h3>Memory and Addresses</h3>

<p>
You can think of memory as a large array of byte-sized "cells", numbered starting at 0. We'll call these numbers "memory addresses". Simple, right?
</p>
<p>
Well... addressing memory used to be rather annoying back in the old days. You see, registers in old x86 processors used to be only 16-bit wide. Sixteen bits is enough to address 64 kilobytes worth of memory, but not more. The hardware was actually capable of using addresses as wide as 20 bits, but you had put a "base" address into a special segment register, and instructions that read or wrote memory would use a 16-bit offset into that segment to obtain the final 20-bit "linear" address. There were separate segment registers for code, data and stack portions (and a few more "extra" ones), and segments could overlap. 
</p>
<p>
In x86-64 these concerns are non-existant. The segment registers for code, data and stack are still present, and they're loaded with some special values, but as a user-space programmer you needn't concern yourself with them. For all intents and purposes you can assume that all segments start at 0 and extend for the entire addressable length of memory. So, as far as we're concerned, on x86-64 our programs see memory as a "flat" contiguous array of bytes, with sequential addresses, starting at 0, just like we said in the beginning of this section...
</p>
<p>
Okay, I may have distorted the truth a little bit. Things aren't quite as simple. While it is true that on 64-bit Windows your programs see memory as a flat contiguous array of bytes with addresses starting at 0, it is actually an elaborate illusion maintained by the OS and CPU working together.
</p>
<p>
The truth is, if you were really able to read and write any byte in memory willy-nilly, you'd stomp all over other programs' code and data (something that indeed could happen in the Bad Old Days). To prevent that, special protection mechanisms exist. I won't get too deep into their inner workings here because this stuff matters mostly for OS developers. Nevertheless, here's a very short overview:
</p>
<p>
Each process gets a "flat" address space as described above (we'll call it the "virtual address space"). For each process, the OS sets up a <a href="https://wiki.osdev.org/Paging">mapping</a> between its virtual addresses and actual physical addresses in memory. This mapping is respected by the hardware: the "virtual" addresses get translated to physical addresses dynamically at runtime. Thus, the same address (e.g. 0x410F119C) can map to two different locations in physical memory for two different processes. This, in a nutshell, is how the separation between processes in enforced.
</p>

<p>
The final thing I want to invite your attention to here is how the instructions and data which they operate on are held in the same …</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpfault.net/posts/asm-tut-0.txt.html">https://gpfault.net/posts/asm-tut-0.txt.html</a></em></p>]]>
            </description>
            <link>https://gpfault.net/posts/asm-tut-0.txt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24195627</guid>
            <pubDate>Tue, 18 Aug 2020 05:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using, Understanding, and Unraveling the OCaml Language]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24193795">thread link</a>) | @rabidsnail
<br/>
August 17, 2020 | http://caml.inria.fr/pub/docs/u3-ocaml/index.html | <a href="https://web.archive.org/web/*/http://caml.inria.fr/pub/docs/u3-ocaml/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td><h3><a href="http://cristal.inria.fr/~remy"><span size="5">Didier R</span><span size="5">é</span><span size="5">my</span></a><span size="5">
</span></h3><h3><a href="http://www-sop.inria.fr/oasis/Caminha00/index.html">APPSEM'2000 summer school</a><sup><a name="text1" href="#note1">1</a></sup></h3></td></tr>
</tbody></div><p>Copyright ©&nbsp;2000, 2001 by Didier Rémy.
</p><p>
To correctly preview mathematical symbols, you may need 
to adjust your 
<a href="http://pauillac.inria.fr/~maranget/hevea/doc/browser.html">browser configuration</a>. 
</p></div>]]>
            </description>
            <link>http://caml.inria.fr/pub/docs/u3-ocaml/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24193795</guid>
            <pubDate>Tue, 18 Aug 2020 00:08:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A circuit-like notation for lambda calculus (2015)]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24193313">thread link</a>) | @apsec112
<br/>
August 17, 2020 | https://csvoss.com/circuit-notation-lambda-calculus | <a href="https://web.archive.org/web/*/https://csvoss.com/circuit-notation-lambda-calculus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Lately, I’ve been playing around with inventing a visual writing system for lambda calculus.</p>

<p><a href="http://en.wikipedia.org/wiki/Lambda_calculus">Lambda calculus</a> (λ-calculus) is a sort of proto-functional-programming, originally invented by Alonzo Church while he was trying to solve <a href="http://en.wikipedia.org/wiki/Entscheidungsproblem">the same problem</a> that led Turing to invent Turing machines. It’s another way of reasoning about computation.</p>

<p>Python’s lambda is an idea that was borrowed from λ-calculus. In Python, you can use a <a href="https://docs.python.org/2/tutorial/controlflow.html#lambda-expressions">lambda expression</a> like the following in order to define a function that returns the square of a number:</p>



<p>In λ-calculus, the idea is the same: we create a function by using <code>λ</code> to specify which arguments a function takes in, then we give an expression for the function’s return value. Pure lambda calculus doesn’t include operators of any sort –&nbsp;just functions being applied to other functions –&nbsp;so if we try to write a <code>square</code> function, we have to suppose that <code>multiply</code> is a function of two variables that has already been defined:</p>

<div><div><pre><code>square = λx. multiply x x
</code></pre></div></div>

<p>The <code>square</code> function, once defined, can be applied to arguments and evaluated into something simpler.</p>

<div><div><pre><code>square 4 = (λx. multiply x x) 4
         = multiply 4 4
         = 16
</code></pre></div></div>

<p>One of the cool things about lambda calculus is that we can represent most common programming abstractions using λ-calculus, even though it’s nothing but functions: numbers, arithmetic, booleans, lists, if statements, loops, recursion… the list goes on. Before I introduce the visual writing system I’ve been using, let’s take a detour and discuss how we can represent numbers and arithmetic using lambda calculus.</p>

<h2 id="church-numerals-in-lambda-calculus">Church numerals, in lambda calculus</h2>
<p>Alonzo Church figured out how to represent numbers as lambda functions; these numbers are referred to as Church numerals.</p>

<p>We can represent any nonnegative integer as long as we have two things: (1) a value for <strong>zero</strong>, and (2) a <strong>successor</strong> function, which returns <code>n + 1</code> for any number <code>n</code>. To represent numbers as functions, then, we require that <code>z</code> (zero) and <code>s</code> (successor) be passed in as arguments, and go from there. Each number is actually secretly a function of those two inputs.</p>

<div><div><pre><code>zero = λs. λz. z
one = λs. λz. s z
two = λs. λz. s (s z)
three = λs. λz. s (s (s z))
</code></pre></div></div>

<p>The actual details of how to implement zero and successor should be implemented as are left as someone else’s problem — we can survive without them. All we care about is that our numbers do the right thing, given whatever zero and successor someone may provide.</p>

<p>What about <strong>addition</strong>? Addition is a function that takes in two numbers (let’s call them <code>x</code> and <code>y</code>), and produces a number representing their sum. To sum them together, we’ll want to produce a number that applies <code>s</code>, the successor function, a total of <code>x + y</code> times. For example, we could first apply it <code>y</code> times to the zero, then apply it <code>x</code> more times to that result.</p>

<div><div><pre><code>plus = λx. λy. (λs. λz. x s (y s z))
</code></pre></div></div>

<p>Let’s try proving that one plus one equals two. In λ-calculus, this proof looks like the following:</p>

<div><div><pre><code>one = λs. λz. s z
two = λs. λz. s (s z)

plus = λx. λy. (λs. λz. x s (y s z))

plus one one = (λx. λy. (λs. λz. x s (y s z))) one one
             = λs. λz. one s (one s z)
             = λs. λz. (λs. λz. s z) s (one s z)
             = λs. λz. s (one s z)
             = λs. λz. s ((λs. λz. s z) s z)
             = λs. λz. s (s z)
             = two
</code></pre></div></div>

<p>(Long, but at least conciser than <a href="http://en.wikipedia.org/wiki/Principia_Mathematica">Bertrand Russell’s</a>.)</p>

<h2 id="lambda-circuitry">Lambda circuitry</h2>

<p>There are a lot of lambdas, parentheses, and arguments being pushed around in that proof. Mentally matching up parentheses is annoying. Scope is especially annoying: which <code>s</code> am I looking at again in <code>λs. λz. (λs. λz. s z) s (one s z)</code>, the inner one or the outer one?</p>

<p>A linear string of lambdas and parentheses is an ineffective way to provide intuition for the computations that are taking place. This problem isn’t unique to lambda calculus, either; consider trying to represent a binary tree using a linear string:</p>

<div><div><pre><code>Node(2, Node(7, Leaf(2), Node(6, Leaf(5), Leaf(11))), Node(5, None, Node(9, Leaf(4), None)))
</code></pre></div></div>

<p>Unambiguous, but not very intuitive. Contrast that representation with the diagram we use when we’re trying to explain that same binary tree at a chalkboard, a more visual notation:</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Binary_tree.svg/288px-Binary_tree.svg.png" alt="Binary tree diagram, from Wikipedia"></p>

<p><em>Image from <a href="https://commons.wikimedia.org/wiki/File:Binary_tree.svg">Wikipedia</a>.</em></p>

<p>I remember programming constructs better when I can reason about them visually like this: when I imagine cutting an array in half for binary search, when I imagine pointers in a linked list being shuffled around to insert a new element, and when I imagine traversing up and down the branches of a binary tree.</p>

<p>Why can’t lambda calculus get some visual intuitions, in the same way? Lambda calculus is a dance of variables flowing through and being manipulated by functions, and I want a writing system for lambda calculus that will visually display this dance. It shouldn’t look like strings of parentheses and symbols: it should create visual intuition.</p>

<p>After some trial and error, here is the system I came up with. I aimed for something that would resemble circuitry.</p>

<p><strong>Values</strong> flow along wires, where they may be passed in as arguments to functions or applied as functions themselves. Some are inputs, some are outputs.</p>

<p><strong>Functions</strong> are represented as boxes which are applied to their inputs on one side and produce a single output on the other. The notation must indicate which function is applied; this may either be drawn within the box itself, or wired in to the middle of the box from some other value.</p>

<p><strong>Arguments</strong> are represented as inputs, coming in from the right side of the diagram; these arguments might pass through functions, or they might be functions-to-apply themselves. If an argument has not been passed in yet, it’s an empty arrow beginning a wire; if an argument has been passed in, its value is attached to the wire. Arguments are always passed in from top to bottom, in order.</p>

<p>As an example, here’s a function which takes in two functions, <code>f</code> and <code>g</code>, then a value <code>x</code>, and returns <code>f (g x)</code>:</p>

<p><img src="https://csvoss.com/images/lambda-f-g-x.png" alt="lambda f. lambda g. lambda x. f (g x)"></p>

<p>As another example, here’s the M combinator <code>M = λx. x x</code> (the “mockingbird” in <a href="http://smile.amazon.com/gp/product/B00A1P096Y"><em>To Mock a Mockingbird</em></a>):</p>

<p><img src="https://csvoss.com/images/m-combinator.png" alt="lambda x. x x"></p>

<h2 id="church-numerals-in-lambda-circuitry">Church numerals, in lambda circuitry</h2>

<p>Here’s the Church numeral <code>four = λs. λz. s (s (s (s z)))</code>, drawn out in lambda circuitry:</p>

<p><img src="https://csvoss.com/images/lambda-four.png" alt="Four, in lambda circuitry"></p>

<p>Let’s take that proof from earlier that one plus one is two. What does it look like to draw that proof in lambda circuitry, instead?</p>

<p><img src="https://csvoss.com/images/lambda-oneplusoneistwo.png" alt="Proof that one plus one is two, in lambda circuitry"></p>

<p>∎</p>

<p>We could also consider <strong>multiplication</strong>. A multiply function would take in two numbers, m and n, and computes a new number which is their product. In lambda calculus, we’d write:</p>

<div><div><pre><code>multiply = λm. λn. λs. λz. m (n s) z
</code></pre></div></div>

<p>In the notation of lambda circuitry, this looks like this:</p>

<p><img src="https://csvoss.com/images/lambda-multiply.png" alt="Multiplication function, in lambda circuitry"></p>

<p>Using this function, we can check that <code>multiply 2 3</code> evaluates to <code>6</code>:</p>

<p><img src="https://csvoss.com/images/lambda-multiply-1.png" alt="Multiply(2, 3), step 1"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-2.png" alt="Multiply(2, 3), step 2"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-3.png" alt="Multiply(2, 3), step 3"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-4.png" alt="Multiply(2, 3), step 4"></p>

<p><img src="https://csvoss.com/images/lambda-multiply-5.png" alt="Multiply(2, 3), step 5"></p>

<p>∎</p>

<h2 id="sidenote-de-bruijn-indices">Sidenote: De Bruijn indices</h2>
<p>One of the nice things about lambda circuitry is that it completely removes the need for variable names.</p>

<p>There’s another notation for lambda calculus that does this too: <a href="https://en.wikipedia.org/wiki/De_Bruijn_index"><em>De Bruijn indices</em></a>. A lambda expression written with De Bruijn indices indicates which variables are used where with a positive integer; the smaller the integer, the more recently the argument it refers to was passed in.</p>

<p>For example, the identity function <code>λx. x</code> may be written with De Bruijn indices like so:</p>



<p>The Church numeral for two, <code>λs. λz. s (s z)</code>, may be written like so:</p>



<p>The addition function, <code>λx. λy. (λs. λz. x s (y s z))</code>, may be written like so:</p>

<div><div><pre><code>plus = λ λ (λ λ 4 2 (3 2 1))
</code></pre></div></div>

<p>An evaluation of <code>plus one one</code> looks like this:</p>

<div><div><pre><code>plus one one = (λ λ (λ λ 4 2 (3 2 1))) (λ λ 2 1) (λ λ 2 1)
             = (λ (λ λ (λ λ 2 1) 2 (3 2 1))) (λ λ 2 1)
             = λ λ (λ λ 2 1) 2 ((λ λ 2 1) 2 1)
             = λ λ (λ λ 2 1) 2 (2 1)
             = λ λ 2 (2 1)
</code></pre></div></div>

<p>One of the tricky things about writing a lambda calculus interpreter is getting the renaming rules right; De Bruijn indices are convenient because they remove the need for this. Lambda circuitry is similar in spirit to De Bruijn indices in that it doesn’t require variable names at all, but instead indicates which variables are passed where by connecting values directly to an arrow indicating when they were passed in.</p>

<h2 id="argument-switching-function-in-lambda-circuitry">Argument-switching function, in lambda circuitry</h2>

<p>I’ll provide more examples just to further demonstrate how the notation works in different situations. Let’s consider the “argument-switching” function <code>C</code>, where <code>C f x y</code> returns <code>f y x</code>. (This is actually the <a href="https://en.wikipedia.org/wiki/B,C,K,W_system">C combinator</a>.)</p>



<p><img src="https://csvoss.com/images/c-combinator.png" alt="C combinator"></p>

<p>Suppose we try applying this to a silly function <code>f</code> where <code>f x y</code> discards <code>y</code> and just returns <code>x</code>. Then, <code>C f</code> should switch around <code>f</code>‘s arguments and create a function which returns <code>y</code> instead. Let’s check:</p>

<div><div><pre><code>f = λx. λy. x

C f = λf. λx. λy. (f y x) f
    = λx. λy. f y x
    = λx. λy. (λx. λy. x) y x
    = λx. λy. y
</code></pre></div></div>

<p><img src="https://csvoss.com/images/lambda-f.png" alt="f = lambda x. lambda y. x"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-1.png" alt="C(f), step 1"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-2.png" alt="C(f), step 2"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-f-3.png" alt="C(f), step 3"></p>

<p>∎</p>

<p>We could also try a function <code>g</code> where <code>g x y</code> returns <code>x y</code>. Then <code>C g x y</code> should return <code>y x</code>. Let’s check:</p>

<div><div><pre><code>g = λx. λy. x y

C g x y = λf. λx. λy. (f y x) g x y
        = g y x
        = (λx. λy. x y) y x
        = y x
</code></pre></div></div>

<p><img src="https://csvoss.com/images/lambda-g.png" alt="g = lambda x. lambda y. x(y)"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-1.png" alt="C(g), step 1"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-2.png" alt="C(g), step 2"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-3.png" alt="C(g), step 3"></p>

<p><img src="https://csvoss.com/images/c-combinator-of-g-4.png" alt="C(g), step 4"></p>

<p>∎</p>

<p><em>Exercise</em>: Show that applying <code>C</code> twice reverses it. That is, show that <code>C (C f)</code> returns <code>f</code>, for any <code>f</code>.
(Note that <code>C f</code> is a function which takes in two arguments, <code>x</code> and <code>y</code>, and returns <code>f y x</code>. Applying <code>C</code> only to <code>f</code> like this is <a href="http://en.wikipedia.org/wiki/Partial_application">partial application</a>.)</p>

<h2 id="prior-work">Prior work</h2>
<p>There are some other systems that give visual intuition to lambda calculus.</p>

<p><a href="http://dkeenan.com/Lambda/"><em>To Dissect a Mockingbird</em></a> describes a notation that is actually very similar to the one I’ve described, and demonstrates it on various problems from <em>To Mock a Mockingbird</em>. I like the way this looks, especially how every function is enclosed by two halves of a circle which make it obvious how that function might be applied. My notation doesn’t have this feature, but requires drawing fewer enclosing boxes as a result.</p>

<p>Visual Lambda (<a href="https://code.google.com/p/visual-lambda/">code</a>, <a href="http://bntr.planet.ee/lambda/visual_lambda_bubble_notation.gif">basics</a>, <a href="http://bntr.planet.ee/lambda/work/visual_lambda.pdf">paper</a>) represents lambda expressions as colored bubbles, and provides an interface for manipulating them.</p>

<p><a href="http://worrydream.com/AlligatorEggs/">Alligator Eggs</a> is a description of a puzzle game based on lambda calculus, which also happens to provide a visual way of working with and evaluating lambda expressions.</p>

<p>These last two don’t happen to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/circuit-notation-lambda-calculus">https://csvoss.com/circuit-notation-lambda-calculus</a></em></p>]]>
            </description>
            <link>https://csvoss.com/circuit-notation-lambda-calculus</link>
            <guid isPermaLink="false">hacker-news-small-sites-24193313</guid>
            <pubDate>Mon, 17 Aug 2020 23:02:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build an Iconic Company – Keith Rabois [audio]]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24189580">thread link</a>) | @craigcannon
<br/>
August 17, 2020 | https://nugget.fm/rabois/ | <a href="https://web.archive.org/web/*/https://nugget.fm/rabois/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="1"><p>Keith Rabois is a General Partner at Founders Fund. He's been a professional investor for the last seven years at Khosla Ventures and Founders Fund. Before that he spent thirteen years leading organizations such as PayPal, LinkedIn, and Square. He's served on the board of directors from inception to IPO of Yelp and Zoom. He's also an angel investor in Airbnb, Lyft, and other companies.</p></div></div>]]>
            </description>
            <link>https://nugget.fm/rabois/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24189580</guid>
            <pubDate>Mon, 17 Aug 2020 17:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s Flying Above Us?]]>
            </title>
            <description>
<![CDATA[
Score 487 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24188661">thread link</a>) | @zuhayeer
<br/>
August 17, 2020 | https://skycircl.es/donate/ | <a href="https://web.archive.org/web/*/https://skycircl.es/donate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <figure>
                <!-- <picture>
                    <source srcset="cbp-reaper-over-minneapolis.webp" type="image/webp">
                    <source srcset="cbp-reaper-over-minneapolis.jpg" type="image/jpeg">
                    <img class="hero" src="cbp-reaper-over-minneapolis.png">
                </picture> -->
                <picture>
                    <source srcset="https://skycircl.es/donate/buzzfeed-circles.webp" type="image/webp">
                    <source srcset="https://skycircl.es/donate/buzzfeed-circles.jpg" type="image/jpeg">
                    <img src="https://skycircl.es/donate/buzzfeed-circles.png">
                </picture>
                <figcaption>
                    DHS &amp; DOJ aircraft over Los Angeles (Buzzfeed)
                </figcaption>
            </figure>

            <p>
                What's flying above us?
            </p>
            <p>
                I'm working to make it easy to find out.
            </p>
            <p>
                Here's how:
            </p>

            
            <p>
                My <a href="https://twitter.com/lemonodor/status/1294002338215034880">Advisory Circular network of
                    twitter bots</a> post in real-time whenever they detect aircraft
                flying in circles over cities around the world, including Los Angeles, Baltimore, Portland, Minneapolis,
                and London. The bots often tweet about news and fire aircraft, and because they use an uncensored source
                of data they also tweet police, FBI, DHS, DEA, CBP, and military
                aircraft. They look for circles because it means an aircraft is <i>doing something</i> instead of
                <i>going somewhere</i>. If you've ever asked “what is that helicopter/plane?” there’s a good chance my
                bots can answer your question—even if it's an advanced military surveillance plane:
            </p>

            <blockquote>
                <p lang="en" dir="ltr">91-00504, a military Swearingen RC-26B Metroliner, is circling over Bancroft,
                    Minneapolis at 8675 feet, squawking 0243, 0.06 miles from 39 St E #91_00504 <a href="https://t.co/ZAAowIcvwi">https://t.co/ZAAowIcvwi</a> <a href="https://t.co/9WHKOSiskZ">pic.twitter.com/9WHKOSiskZ</a></p>— Advisory Circular
                Minneapolis-St. Paul (@SkyCirclesMPLS) <a href="https://twitter.com/SkyCirclesMPLS/status/1267681883862650887?ref_src=twsrc%5Etfw">June 2,
                    2020</a>
            </blockquote>
            

            
            <p>
                A few years ago I <a href="https://docs.google.com/presentation/d/1sowJrQQfgxnLCErb-CvUV8VGXdtca6SWYWWLRPZgaHI/edit?usp=sharing">discovered
                    a secret FBI aerial surveillance program</a>, involving more than 100 aircraft
                registered to front companies. I was one of the first people to <a href="https://news.ycombinator.com/item?id=9508812">post online</a> about the program.
            </p>
            <p>From a <a href="https://web.archive.org/web/20150605064602/http://fusion.net/story/143739/how-you-can-track-the-fbis-spy-planes/">Fusion
                    Media
                    article</a>:</p>
            <blockquote>
                This week, the Associated Press reported that the FBI is regularly flying “spy planes” over American
                cities.

                The report, which revealed the front companies the FBI uses to fly the planes, wasn’t a surprise to John
                Wiseman, a technologist in Los Angeles. Based on public records, he had already figured out some of the
                planes the FBI was flying and, using a
                device he programmed to intercept airplane transmissions, had identified over the last month the ones
                flying overhead in L.A. in real time.
                Wiseman wrote in a Hacker News comment in May about his findings, revealing a month ago what the AP
                reported today.
            </blockquote>

            <p>
                I continue to help journalists with stories related to government aerial surveillance.
            </p>
            
            <p>
                I created a <a href="https://twitter.com/lemonodor/status/1238149529469202433">Siri shortcut</a> that
                lets you ask what's overhead at any time, and it will tell you what
                the nearest aircraft is and who it's registered to. It uses the same uncensored data source as
                the Advisory Circular bots.
            </p>

            
            <p>
                I've always funded this work myself, but now I'm in the situation of having been furloughed without pay
                since April.
            </p>
            <p>
                I’ve spent hundreds of hours in development work trying to bring the public this essential
                information for free. I'd like to continue this work, both supporting existing projects and implementing
                new ideas (I'd also like to replace my broken laptop).
            </p>
            <p>
                If you would like to support this effort and help keep the servers running, please donate below. <b>You
                    can
                    give a one-time donation with PayPal or Venmo, or a recurring donation with PayPal.</b>
            </p>

            <p>
                Thanks for your help!<br>
                John Wiseman
            </p>
            <p>psst... if you're a nerd, coder, and/or planetracker and want some more details, check out
                <a href="https://skycircl.es/donate-nerd-mode/">this page.</a></p>

            

            <p><a href="https://skycircl.es/donate/venmo-qr-code.jpg"><img alt="Venmo button" src="https://skycircl.es/donate/venmo-button.png" width="200" height="59"></a></p><!-- <a href="bitcoin:13FjNbDnUrJxku6h8ceg7XzhKTCgJkVSRB"><img alt="bitcoin button" src="bitcoin-button.png" width="200" height="76""></a> -->
            
        </div></div>]]>
            </description>
            <link>https://skycircl.es/donate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188661</guid>
            <pubDate>Mon, 17 Aug 2020 16:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chat server on a WiFi-enabled SD card]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24188648">thread link</a>) | @l00sed
<br/>
August 17, 2020 | https://l-o-o-s-e-d.net/wartor | <a href="https://web.archive.org/web/*/https://l-o-o-s-e-d.net/wartor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <p><h2>warTOR</h2></p>
            
            <div>
              <p>09:00am | 02/08/2020<br>Daniel Tompkins</p>
              

 
            </div>
            <p>Oddly, I don't remember when or how I got my hands on the <a target="_blank" href="https://www.toshiba-memory.com/products/toshiba-wireless-sd-cards-flashair-w-04/">Toshiba <em>FlashAir</em></a> card. These WiFi-enabled SD cards are made to transfer photos from a digital camera to a computer.</p>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/flashair.png">
              <p><img data-src="assets/img/wartor/flashair.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/flashair.png">
              </p>
            </a>

            <div>
              <p>Imaginging that someone would use a 4MBps wireless connection to transfer photos when the hardware transfer is closer to 70MBps seems ridiculous.</p>
              <p>However, it could come in handy if you're in a situation where you don't have access to an SD card reader, or want to easily preview photos on a phone or tablet.</p>
            </div>

            <p>
              <h3>Digging into the <em>FlashAir</em></h3>
            </p>
            <div>
              <p>What's far more interesting about these Toshiba cards is the fact that they are essentially programmed to act as a <a target="_blank" href="https://en.wikipedia.org/wiki/Wireless_access_point">wireless access point (WAP)</a>. You can setup a custom SSID and password— connecting directly to the card over 2.4GHz.</p>
              <p>After peeking at the filesystem, I realized that the main photo gallery application hosted on the card is essentially a static website— served as basic HTML, CSS and JavaScript.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/flashair-filesystem.png">
              <p><img data-src="assets/img/wartor/flashair-filesystem.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/flashair-filesystem.png">
              </p>
            </a>

            <p>My excitement with this bit of tech was the possibility of building a totally discrete microserver that would be capable of hosting a few pages and services.</p>

            <p>
              <h3>Project Inspiration</h3>
            </p>
            <div>
              <p>My fourth-year undergraduate architecture studio, entitled <em>Dark Rooms</em>, was taught by <a target="_blank" href="https://m-a-u-s-e-r.net/">Mona Mahall</a>. The studio was split into three exhibitions: <em>Pyramid, Server and Backstage</em>. These exhibitions were meant to explore the "spaces between visibility and invisibility".</p>
              <p>In the second exhibition, <em>Server</em>, we were asked to consider the design of an anti-human space— a dark, cold, electronic archive built exclusively for machines. In my preliminary research, I was particularly interested in artists like <a target="_target" href="https://arambartholl.com/dead-drops/">Adam Bartholl</a>.</p>
              <p>His project, a USB "<a target="_blank" href="http://deaddrops.com/">dead drop</a>", drew inspiration from an information-sharing tactic used by spies. A predetermined secret location— such as a hollowed-out rock, brick, log or other object— would be used to discreetly stash an important item.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/USB-dead-drop.png">
              <p><img data-src="assets/img/wartor/USB-dead-drop.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/USB-dead-drop.png">
              </p>
            </a>

            <p>Once the item— perhaps a slip of paper or a key— is "dropped", a second party could then retrieve it without interacting directly with the other person or being detected in the exchange.</p>

            <p>
              <h3>Wireless Anonymous Repository</h3>
            </p>
            <div>
              <p>While a USB is already a much more "invisible" way of storing and exchanging information, I wanted to take this concept a step further. Using the <em>FlashAir</em> cards, I proposed a new wireless dead drop that could be just as affordable and simple as the USB, but with a myriad of superior qualities.</p>
              <p>Writing directly to the card requires an SD card slot; however, the wireless functionality can be powered without a desktop or laptop. A typical SD card takes 2.4-3.6V at about 30mA. I found that by using an SD-to-USB adapter, one could power the wireless module from a standard 5V USB outlet.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-AC.png">
              <p><img data-src="assets/img/wartor/wartor-AC.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-AC.png">
              </p>
            </a>

            <p>Depending on the location of the dead drop, this could be concealed within a false junction box that would be plugged in over the top of a standard 2-outlet 120V AC. If— in the spirit of the original USB dead drop— you wanted to embed the card in a brick wall, then the device could be powered from a USB powerbank.</p>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-outlet.png">
              <p><img data-src="assets/img/wartor/wartor-outlet.png" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-outlet.png">
              </p>
            </a>

            <p>I named the project <em>warTOR</em> for "wireless anonymous repo" + <a target="_blank" href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">TOR</a>. Though it's not connected to the Tor network in any way, I thought this title captured the spirit of anonymity (plus I wanted to use some Pokémon sprites). If someone would like to try it, the Toshiba cards <em>can</em> be setup as a wireless bridge... from a Tor gateway?</p>

            <p>
              <h3>Future Plans</h3>
            </p>
            <div>
              <p>Something else that I'd like to try is powering the card via a small solar cell, but I haven't gotten there yet... The greatest benefit of the wireless dead drop is that one could log into the WAP from their cellphone, upload or download a file, and no one could discern that any sort of exchange was happening. However, I'm also working on a clientside chat application that could be hosted on the cards.</p>
              <p>With this implemented, then two people could sit down in a café and send messages back and forth over the private network; or, someone could login to the network and type out a message for the other person to see at a later date.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-screenshots.jpg">
              <p><img data-src="assets/img/wartor/wartor-screenshots.jpg" src="https://l-o-o-s-e-d.net/assets/img/wartor/wartor-screenshots.jpg">
              </p>
            </a>

            <div>
              <p>Here are some screenshots from the application 👆. I'll be doing a follow-up post with a GitHub link to the <em>FlashAir</em> CONFIG file that I'm using on my card. I'll also upload the source code for the original <em>warTOR</em> server with instructions on how you can deploy your own <em>warTOR</em> in the wild!</p>
              <p>Hope you enjoyed this project. If you'd like, please subscribe for updates (livestreams, new posts) or follow me on Twitter or leave a note below! Thanks for reading <em>loosed</em>.</p>
            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://l-o-o-s-e-d.net/wartor</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188648</guid>
            <pubDate>Mon, 17 Aug 2020 16:17:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Yubikey as a touchless, magic unlock key for Linux]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24188172">thread link</a>) | @Pneumaticat
<br/>
August 17, 2020 | https://kliu.io/post/yubico-magic-unlock/ | <a href="https://web.archive.org/web/*/https://kliu.io/post/yubico-magic-unlock/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Yubikeys are great for security, but their benefits decrease somewhat when you leave them in your computer unattended.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> I unfortunately have a habit of forgetting my key when I walk away from the computer. I also have login passwords that are way too long and easy to typo.</p>
<p>Thankfully, there’s a way to solve both of these problems: use a Yubikey to unlock your computer when you put it in and lock your computer when you remove it!</p>
<h2 id="prior-art">Prior art<a href="#prior-art" arialabel="Anchor">⌗</a> </h2>
<p>The first example I remember seeing of this concept years ago was <a href="https://www.predator-usb.com/predator/en/index.php">Predator</a>, Windows software (with a delightfully retro website) that locks your computer when you remove a special USB drive. Similar examples for Linux include <a href="https://wiki.debian.org/pamusb">pamusb</a>, which allows you to login using Linux’s PAM by inserting a specially-formatted USB stick.</p>
<p>Of course, nowadays most people use Yubikeys to accomplish this, and Yubico has <a href="https://developers.yubico.com/yubico-pam/Authentication_Using_Challenge-Response.html">convenient guides</a> on how to accomplish this very task. However, I wanted to make it <em>touchless</em> – that is, I wanted to be able to plug in my Yubikey and instantly unlock my laptop, without clicking through logins or touching the Yubikey button. Upon removal, I wanted to instantly lock my computer.</p>

<p>There are some guides on how to do this online (unlock when you plug in, lock when you remove), but unfortunately most of them fall prey to the problem described in <a href="https://medium.com/@d0znpp/how-to-sacrifice-security-using-a-public-yubikey-linux-guides-c823c4c6e2">this article</a>. A lot of them use udev to detect when the Yubikey is plugged in, but they don’t actually authenticate the key beyond checking its vendor ID, model ID, and sometimes serial number, which all can <a href="https://forums.anandtech.com/threads/changing-creating-a-custom-serial-id-on-a-flash-drive-low-level-blocks.2099116/">easily be faked</a>.</p>
<p>To provide actual security, most official guides use either <code>pam_u2f</code> (which authenticates a Yubikey through the <a href="https://en.wikipedia.org/wiki/Universal_2nd_Factor">U2F protocol</a>) or <code>pam_yubico</code> (which uses either online validation through YubiCloud or offline validation through a challenge-response protocol). The U2F method requires a tap on the Yubikey, while the challenge-response process can be done without user interaction, so I went with the latter. I set up traditional Yubikey authentication using <a href="https://support.system76.com/articles/yubikey-login/">this great guide from System76</a>.</p>
<p>However, I still needed some way to test the challenge-response for success when I plugged in the key. Usually, <code>pam_yubico</code> is run when you login or unlock your computer (i.e. when pressing the enter key on the lockscreen). But I didn’t want <em>any</em> clicks, so I needed a way to run it without interaction.</p>
<p>Enter <code>udev</code> (again) and <code>pamtester</code>!</p>
<p>Here’s the udev rules I included:</p>
<pre><code>kevin@you:~ » cat /etc/udev/rules.d/yubikey.rules
ACTION=="remove", ENV{DEVTYPE}=="usb_device", ENV{PRODUCT}=="1050/407*", RUN+="/usr/local/sbin/ykunlock.sh lock"
ACTION=="add", ENV{DEVTYPE}=="usb_device", ENV{ID_BUS}=="usb", ENV{PRODUCT}=="1050/407*", RUN+="/usr/local/sbin/ykunlock.sh unlock"
</code></pre><p>These rules effectively call a script when inserting and removing the key, so I can trigger any action from the script. Note that the script <strong>should not immediately unlock the computer</strong>, to avoid the security issues mentioned earlier.</p>
<p>To actually test the challenge-response from the Yubikey on inserting, I decided to use <a href="http://pamtester.sourceforge.net/">pamtester</a>, a simple utility that pretends to trigger a PAM authentication from the command line. Since <code>pam_yubico</code> is installed, this will naturally test the challenge-response if a Yubikey is plugged in.</p>
<p>Here’s the final script:</p>
<div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>exec 1&gt; &gt;<span>(</span>logger -s -t <span>"</span><span>$(</span>basename <span>"</span>$0<span>"</span><span>)</span><span>"</span><span>)</span> 2&gt;&amp;<span>1</span>
echo <span>"RUN"</span>
<span>if</span> <span>[</span> <span>"</span>$1<span>"</span> <span>=</span> <span>"lock"</span> <span>]</span>; <span>then</span>
        pkill -USR1 swayidle
<span>else</span>
        <span># unlock</span>
        <span>if</span> echo <span>""</span> | pamtester login kevin authenticate; <span>then</span>
                <span># PAM login successful</span>
                <span># kill locker</span>
                kill -KILL <span>$(</span>pgrep swaylock<span>)</span>
                ps aux | grep swaylock
                <span># turn on displays</span>
                SWAYSOCK<span>=</span><span>$(</span>ls /run/user/1000/sway-ipc.*.sock<span>)</span> swaymsg <span>"output * dpms on"</span>
        <span>fi</span>
<span>fi</span>
exit <span>0</span>
</code></pre></div><ul>
<li>On lock, it immediately locks my desktop (by sending a SIGUSR1 to swayidle, the program that manages locking on the Sway window manager)</li>
<li>On unlock, it first sees if it can authenticate using pamtester without interaction (when no Yubikey is inserted or if the key is invalid, pamtester asks for a password). If it can, it kills the lockscreen and turns on all displays using Sway WM protocols.</li>
</ul>
<p>The final result is amazingly convenient, and has successfully made me remember to pull out my Yubikey when leaving my computer unattended more than once<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>! Mission success.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I’ve significantly downgraded this statement in severity after some excellent comments on Hacker News have pointed out that (1) <a href="https://news.ycombinator.com/item?id=24192390">stealing a Yubikey is incredibly unlikely unless you’re a person of interest</a>; (2) <a href="https://news.ycombinator.com/item?id=24192138">even if you have the Yubikey, you still can’t directly extract e.g. a private key</a>; and (3) a <a href="https://news.ycombinator.com/item?id=24190313">Yubikey protects against SSH/GPG fraud because it can require a PIN and lock out over time</a>. Case in point, Yubikeys are good. I’d argue that it’s still not good to have your key stolen (e.g. perhaps if you’re targeted by a government/<a href="https://news.ycombinator.com/item?id=24194081">industrial espionage</a>, or the malicious significant other attack, where they know your password and can steal your key for 2FA if unattended), but I see that it’s not as much of a risk as I originally thought. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You might call it Yubikey: Coronavirus Edition. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Yes, yes, I know there’s not too much of a danger because we’re all stuck at home right now. But who knows – maybe this will be helpful when we <em>eventually</em> get back on campus. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://kliu.io/post/yubico-magic-unlock/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24188172</guid>
            <pubDate>Mon, 17 Aug 2020 15:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pathological Lying: Theoretical and Empirical Support for a Diagnostic Entity]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24187224">thread link</a>) | @InInteraction
<br/>
August 17, 2020 | https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/ | <a href="https://web.archive.org/web/*/https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A new study has found that 13% of people think of themselves as pathological liars, or say that others consider them to be pathological liars. Those 13% reported telling about 10 lies per day.</p><p>The study, published in the journal <a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#.XvDDrEQ2jzE%20">Psychiatric Research and Clinical Practice</a>,&nbsp;included 623 people. The researchers recruited them in 2019 from various mental health forums, social media, and a university.</p><p>The participants spanned a range of ages, ethnicities, education levels, and income levels. The researchers asked them whether they thought of themselves as pathological liars, or if others thought of them that way. The respondents also took a lie frequency assessment and other questionnaires.</p><h2>Greater distress and impaired functioning</h2><p>The study found the pathological liars were more likely to experience distress and impaired functioning, especially in social relationships. This diminished functioning also applied to legal contexts, work, and finances. Their distress often had to do with worries about whether their lies would be be discovered.</p><p>The pathological liars in the group also reported telling lies for no specific reason, and said many of their lies grew out of an initial lie.</p><p>The majority of participants in the pathological liars group indicated that their problematic lying began during adolescence. People in this group were also more likely to say their lying was out of their control, indicating a kind of compulsiveness. Likewise, people in this group said they felt less anxious after lying.</p><h2>From <em>pseudologia phantastica</em> to pathological liars</h2><p>The phenomenon of the “pathological liar” was first recorded in 1891 by psychiatrist <a aria-label="undefined (opens in a new tab)" href="https://www.amazon.co.uk/pathologische-L%C3%BCge-psychisch-abnormen-Schwindler/dp/3226034618/ref=sr_1_2?dchild=1&amp;qid=1594994372&amp;refinements=p_27%3AAnton+Delbr%C3%BCck&amp;s=books&amp;sr=1-2" target="_blank" rel="noreferrer noopener">Anton Delbr?ck</a>. He initially called it <em>pseudologia phantastica</em>, and used the term to describe people who told so many outrageous lies that their behavior could be considered pathological.</p><p>Since then, research into pathological lying has been surprisingly scant. One <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0447.1988.tb05068.x">analysis</a> of prior case studies found <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Pathological_lying" target="_blank" rel="noreferrer noopener">pathological lying</a> equally represented among men and women, with the <a aria-label="undefined (opens in a new tab)" href="https://psychnewsdaily.com/category/iq/" target="_blank" rel="noreferrer noopener">IQs</a> of the liars in the average to above average range.</p><h2>Formal recognition</h2><p>Pathological lying has not (yet) been classified as a diagnostic entity in either the <a aria-label="undefined (opens in a new tab)" href="https://www.psychiatry.org/psychiatrists/practice/dsm" target="_blank" rel="noreferrer noopener">DSM-5</a> or the <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/ICD-10" target="_blank" rel="noreferrer noopener">ICD-10</a>, but the researchers behind the present study are hoping to change that. As they write, “we suggest that PL should be defined as a persistent, pervasive, and often compulsive pattern of excessive lying behavior that leads to clinically significant impairment of functioning in social, occupational, or other areas.”</p><p>Pathological lying also causes distress, they say, and poses a risk to the self or others; an example of this risk is if a pathological liar conceals the presence of suicidal thoughts.</p><p>Formal recognition of pathological lying as a disorder would bring many benefits, as researchers would then be better able to examine its features and causes. And effective treatments, such as cognitive-behavioral therapy and possibly pharmaceutical drugs, could then be more thoroughly investigated.</p><hr><p><strong>Study:</strong> P<em>athological Lying: Theoretical and Empirical Support for a Diagnostic Entity</em><br><strong>Authors: </strong><a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#">Drew A. Curtis</a> and <a href="https://prcp.psychiatryonline.org/doi/10.1176/appi.prcp.20190046#">Christian L. Hart</a> <br><strong>Published: </strong>22 Jun 2020, <a href="https://doi.org/10.1176/appi.prcp.20190046">https://doi.org/10.1176/appi.prcp.20190046</a><br><strong>Image: </strong>via <a aria-label="undefined (opens in a new tab)" href="https://www.flickr.com/photos/80641068@N07/with/8686708312/" target="_blank" rel="noreferrer noopener">Flickr</a>, Creative Commons Attribution 2.0 Generic <a aria-label="undefined (opens in a new tab)" href="https://creativecommons.org/licenses/by/2.0/deed.en" target="_blank" rel="noreferrer noopener">license</a>.</p></div></div>]]>
            </description>
            <link>https://psychnewsdaily.com/about-13-percent-of-people-are-pathological-liars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24187224</guid>
            <pubDate>Mon, 17 Aug 2020 13:55:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to OpenBSD [video]]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 90 (<a href="https://news.ycombinator.com/item?id=24185985">thread link</a>) | @asicsp
<br/>
August 17, 2020 | https://blog.lambda.cx/posts/openbsd-introduction-talk/ | <a href="https://web.archive.org/web/*/https://blog.lambda.cx/posts/openbsd-introduction-talk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://blog.lambda.cx/posts/openbsd-introduction-talk/cover.jpg" alt="The first slide of the OpenBSD introduction presentation" title="An Introduction to OpenBSD"></p><p>
  <iframe src="https://www.youtube.com/embed/EkDVKthufAM" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<p>
I recently gave a talk at work to help introduce OpenBSD to my
colleagues. It's a broad introduction to the fundamentals of security
in OpenBSD, as well as some basic system administration tips and
suggestions anyone coming from a Linux background might find useful.
</p>
<p>
It's roughly split up into four sections; the history of OpenBSD,
what sets it apart from other operating systems, a guided
installation, and the system administration introduction.
</p>
<p>
In the original presentation the guided installation was done
interactively with the participants installing OpenBSD in a VM on
their machines to follow along with the slides.
</p>
<p>
I've tried my best to make it as accessible as possible while still
covering the most important beats. If you find any errors please let
me know so I can correct them, my contact info is on the <a href="https://blog.lambda.cx/about/">about</a> page.
</p>
<p>
I've corrected several small issues with the slides since the
recording. I've replaced the file name <code>/etc/mygateway</code> with <code>/etc/mygate</code>,
replaced the smartquotes with regular quotes, and removed the rebound
program, to name the biggest fixes. These corrections are available at
the slides linked below.
</p>
<p>
<a href="https://blog.lambda.cx/posts/openbsd-introduction-talk/openbsd-introduction.pdf">An Introduction to OpenBSD slides</a>
</p>

    </div></div>]]>
            </description>
            <link>https://blog.lambda.cx/posts/openbsd-introduction-talk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185985</guid>
            <pubDate>Mon, 17 Aug 2020 10:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A-Levels: The Model is not the Student]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 127 (<a href="https://news.ycombinator.com/item?id=24185621">thread link</a>) | @tosh
<br/>
August 17, 2020 | http://thaines.com/post/alevels2020 | <a href="https://web.archive.org/web/*/http://thaines.com/post/alevels2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://thaines.com/post/alevels2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185621</guid>
            <pubDate>Mon, 17 Aug 2020 09:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Response to Google open letter]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 305 (<a href="https://news.ycombinator.com/item?id=24185374">thread link</a>) | @ajdlinux
<br/>
August 17, 2020 | https://www.accc.gov.au/media-release/response-to-google-open-letter | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/response-to-google-open-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-column">
              
            <div id="readspeaker-process">
        <section>
                                
                            </section>
        <div>
          <section>
                                                                                                    <div>
    <section id="block-system-main">

      
  <div>
    <article id="node-87993" about="/media-release/response-to-google-open-letter" typeof="sioc:Item foaf:Document">
    <header>
            <span property="dc:title" content="Response to Google open letter"></span>      </header>
    <div><div><div property="content:encoded"><p>The open letter published by Google today contains misinformation about the draft news media bargaining code which the ACCC would like to address.&nbsp;</p>

<p>Google will not be required to charge Australians for the use of its free services such as Google Search and YouTube, unless it chooses to do so.</p>

<p>Google will not be required to share any additional user data with Australian news businesses unless it chooses to do so.</p>

<p>The draft code will allow Australian news businesses to negotiate for fair payment for their journalists’ work that is included on Google services.</p>

<p>This will address a significant bargaining power imbalance between Australian news media businesses and Google and Facebook.</p>

<p>A healthy news media sector is essential to a well-functioning democracy.</p>

<p>We will continue to consult on the draft code with interested parties, including Google.</p>

<p><a href="https://www.accc.gov.au/focus-areas/digital-platforms/news-media-bargaining-code/draft-legislation">Consultation</a> closes on 28 August 2020.</p>

<p>More information about the draft news media bargaining code can be found here:&nbsp;<a href="https://www.accc.gov.au/media-release/australian-news-media-to-negotiate-payment-with-major-digital-platforms">Australian news media to negotiate payment with major digital platforms</a></p>
</div></div></div>    </article>
  </div>

</section> <!-- /.block -->
<section id="block-service-links-service-links">

        <p>
      <h2>Share</h2>
    </p>
    
  

</section> <!-- /.block -->
  </div>
                                  </section>
                  </div>
      </div>
    </section></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/response-to-google-open-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185374</guid>
            <pubDate>Mon, 17 Aug 2020 08:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade: A Community for Self-Rolled Performant Software (2016)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24184688">thread link</a>) | @TheUndead96
<br/>
August 16, 2020 | https://handmade.network/manifesto | <a href="https://web.archive.org/web/*/https://handmade.network/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
            <div>
                
                
    <div>
        
        
            

<p> Modern computer hardware is amazing. Manufacturers have orchestrated billions of pieces of silicon into terrifyingly complex and efficient structures that sweep electrons through innumerable tangled paths, branchings, and reunions with the sole purpose of performing computations at more than a billion times per second. This awe-inspiring piece of computational wizardry has at its disposal multiple billions of uniquely addressible silicon plates where it can store the results of millions of computations in an array of several vanishingly small chips. All of this hardware, though each component often sits no further than 7 or 8 centimeters away from the others, cycles so fast that the speed of light, a physical law of the universe, limits the rate at which they communicate with each other.
</p><p><span>So why is software still slow?</span>
</p><p>Why does it take your operating system 10 seconds, 30 seconds, a minute to boot up? Why does your word processor freeze when you save a document on the cloud? Why does your web browser take 3, 4, 10 seconds to load a web page? Why does your phone struggle to keep more than a few apps open at a time? And why does each update somehow make the problem worse?
</p><p><span>We made it slow</span>.
</p><p>Not necessarily you, not necessarily me, not necessarily any single person in particular. But we, the software development community, made it slow by ignoring the fundamental reality of our occupation. We write code, code that runs on computers. Real computers, with central processing units and random access memory and hard disk drives and display buffers. Real computers, with integer and bitwise math and floating point units and L2 caches, with threads and cores and a tenuous little network connection to a million billion other computers. Real computers not built for ease of human understanding but for blindingly, incomprehensibly fast speed.
</p><p><span>A lot of us have forgotten that</span>.
</p><p>In our haste to get our products, our projects, the works of our hands and minds, to as many people as possible, we take shortcuts. We make assumptions. We generalize, and abstract, and assume that just because these problems have been solved before that they never need to be solved again. We build abstraction layers, then forget we built them and build more on top.
</p><p>And it's true that many of us think we do not have the time, the money, the mental bandwidth to always consider these things in detail. The deadline is approaching or the rent is due or we have taxes to fill out and a manager on our back and someone asking us why we always spend so much time at the office, and we just have to stick the library or virtual machine or garbage collector in there to cover up the places we can't think through right now.
</p><p>Others of us were never taught to think about the computer itself. We learned about objects and classes and templates and how to make our code clean and pretty. We learned how to write code to make the client or the manager or the teacher happy, but made the processor churn. And because we did, that amazing speed we'd been granted was wasted, by us, in a death by a thousand abstraction layers.
</p><p><span>But some of us aren't satisfied with that.</span>
</p><p>Some of us take a few extra steps into the covered territory, the wheels sitting, motionless, in a pile behind us, examine their designs and decide there is a better way. The more experienced among us remember how software used to be, the potential that we know exists for computer programs to be useful, general, <em>and</em> efficient. Others of us got fed up with the tools we were expected to use without complaint, but which failed us time and time again. Some of us are just curious and don't know what's good for us. Don't trust what we've been told is good for us.
</p><p>We sat down and looked at our hardware, and examined our data, and thought about how to use the one to transform the other. We tinkered, and measured, and read, and compared, and wrote, and refined, and modified, and measured again, over and over, until we found we had built the same thing, but 10 times faster and incomparably more useful to the people we designed it for. And we had built it by hand.
</p><p>That is what Handmade means. It's not a technique or a language or a management strategy, it isn't a formula or a library or an abstraction. It's an idea. The idea that we can build software that works with the computer, not against it. The idea that sometimes an individual programmer can be more productive than a large team, that a small group can do more than an army of software engineers and *do it better*. The idea that programming is about transforming data and we wield the code, the tool we use to bend that data to our will.
</p><p> It doesn't require a degree, or a dissertation, or a decade of experience. You don't need an
expensive computer or a certificate or even prior knowledge. All you need is an open mind and a sense of
curiosity. We'll help you with the rest.
</p><p><span>Will you join us?</span>
</p><p>Will you build your software by hand?</p>

        
        
        <p>
            
                Last updated by Andrew Chronister on April 23, 2016, 1:39 a.m.
            
        </p>
    </div>

                
            </div>
        
    </div>
    
</div></div>]]>
            </description>
            <link>https://handmade.network/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24184688</guid>
            <pubDate>Mon, 17 Aug 2020 06:56:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How long since Google said a Google Drive Linux client is coming?]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 108 (<a href="https://news.ycombinator.com/item?id=24183399">thread link</a>) | @zdw
<br/>
August 16, 2020 | https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/ | <a href="https://web.archive.org/web/*/https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
        <p>
          have elapsed since <a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">Google said to "hang tight" about Linux support for Google Drive</a>.
        </p>
        <p>
          <strong><a href="https://tools.google.com/dlpage/drive">We're still waiting</a></strong>.
        </p>
        <p><a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">
          <img src="https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/img/waiting.gif">
        </a></p><hr>
        <p>
          Made with frustration by <a href="https://twitter.com/abevoelker">@abevoelker</a>
        </p>
      </div></div>]]>
            </description>
            <link>https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24183399</guid>
            <pubDate>Mon, 17 Aug 2020 02:47:20 GMT</pubDate>
        </item>
    </channel>
</rss>
