<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 12 Feb 2021 01:05:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 12 Feb 2021 01:05:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Get Startup Ideas]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26085118">thread link</a>) | @davidkolodny
<br/>
February 9, 2021 | https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Startups and technology canâ€™t solve <em>all</em> the worldâ€™s problems, but they can solve a good amount of them. Now more than ever, we need people to build the next generation of companies that will tackle some of the worldâ€™s biggest problems. There are a lot of unknowns right now, but at Wilbur Labs, we believe this is the best time to start a company â€“ ever. </p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have built and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, <a href="https://www.barkbus.com/">Barkbus</a>, and more.</p><p>We plan to launch several companies every year, which requires building a solid pipeline of ambitious ideas. Over the years, we have used three primary approaches to get startup ideas: build for the future, solve existing problems better, or solve personal problems.</p></div><h2>1. Build for the Future</h2><div><div><p>The future is not static. It is built by people who have a vision for what the future should look like, and those who have the willingness to work hard and take the risks necessary to get there. A great way to get startup ideas is to sit down and think about what the future should look like. Ask yourself the following questions: </p><p><em>How are behaviors changing? Which changes will stick? </em><br><em>What long-term problems have been created as a result of the COVID-19 pandemic? </em><br><em>What priorities and values have changed?</em><br><em>What are the biggest problems today?</em><br><em>What will be the biggest problems tomorrow?</em><br><em>What new problems can technology solve today?</em><br><em>How can new technology change the way existing problems are solved?</em></p></div><p>2020 is a year that consumer behaviors are changing and evolving at a faster rate than ever before. Emerging trends that would have taken 5 to 10 years to mature are instead maturing overnight. There is a large opportunity to think about changing trends and build companies ahead of the curve. eCommerce, Employment, Insurance, and Mobile On-Demand are just a few industries where we are boosting investments as a result of new long-term trends.</p><p>When thinking about the future, itâ€™s important to think and plan for the long-term. The best ideas can be built into big, sustainable businesses that can solve problems and create value over the long-term. Avoid short-termism, also known as ideas which may seem solid in the short-term but have a short expiration date.</p><p>Barkbus is a great example of a business that is building for the future. Back in 2017, the world was rapidly transitioning to direct-to-your-door services. Despite that, the way most people got their dogs groomed hadnâ€™t changed. Pet parents still went to the salon, which was a time consuming and stressful experience for both dogs and their parents. Barkbus launched to <a href="https://www.wilburlabs.com/announcements/why-we-acquired-barkbus">make mobile grooming the new norm</a> for pet parents and their dogs. </p></div><h2>2. Solve Existing Problems Better</h2><div><p>We believe the best companies solve real problems. These problems may be completely new problems, or they may be existing problems that have not been solved well by existing companies to date.</p><p>Do not discount existing problems when generating startup ideas. Some of the largest, most impactful companies throughout history were built by solving existing problems better than others. Google did not invent the search engine, search ads, web based email, or maps. Apple did not invent the smartphone, the tablet, or the smart watch. Facebook did not invent social networking. The list goes on and on. What these companies did is provide a better experience than the existing companies. At Wilbur Labs, we refer to this as â€œcreating a 10x experience.â€� </p><p>Next time you have an idea and someone says, â€œdoesnâ€™t X do that?â€� â€” instead of throwing away your idea, first decide if thereâ€™s an opportunity to 10x the experience. Competitors are a good sign as it means there is a real problem people care about. Challenging the status quo is a great way to solve big problems and build a large business. </p><p>When we built Joblist, we did so because despite multiple large job boards, the job search process hasnâ€™t changed in 20 years â€” when job listings first moved online. We saw an opportunity to 10x the job search experience by introducing more personalization and collaboration tools to a traditionally generic and lonely process. Job seekers have embraced this new approach, which allowed Joblist to help millions of job seekers by powering over 500,000 new applications <a href="https://www.joblist.com/news/why-we-launched-joblist">before their public launch</a>.</p></div><h2>3. Solve Personal Problems</h2><div><div><p>Many of the best startup ideas are personal problems that you have faced. What are the biggest problems that you wish were solved? How many others face the same problem? If you experience a problem, then you are uniquely positioned to solve it.</p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular job. The journey is absolutely worth it for the right person, but itâ€™s important that you care enough about what you are working on enough to dedicate 5 to 10 years of your life. This will be easier if you care deeply about the problem you are solving.</p></div>
<p>A great example of this is why we launched VacationRenter. At Wilbur Labs, we had quarterly company offsites where we book a vacation rental to work for a few days in a different city. Every time we searched for a rental, it took hours of planning and work. We found ourselves scrolling through pages of search results and jumping from site to site, trying to find the ideal place for the best price. This was a frustrating experience and we knew we could make the search for a vacation rental better for others like us â€” which is why <a href="https://www.vacationrenter.com/news/why-we-launched-vacationrenter">we launched VacationRenter</a>. If you experience a problem, it is likely that others are experiencing it too. </p>
<p>VacationRenter became the fastest growing travel startup ever, generating over $1 billion gross bookings in 2020. This milestone confirms that we werenâ€™t the only travelers who had a frustrating experience finding the perfect rental.</p></div><h2>Next Steps</h2><div><p>At Wilbur Labs, the best startup ideas check a few key boxes:</p><ul><li><strong>Solves a problem.</strong> Could your idea solve a big problem, and have a large positive impact on a significant number of people?</li><li><strong>Builds a sustainable business. </strong>Can the idea be turned into a sustainable business that creates value over the long-term?</li><li><strong>Uniquely positioned.</strong> Are you uniquely positioned to solve the problem and you want to dedicate 5 to 10 years of your life?</li></ul></div><figure><img alt="best-startup-ideas-venn-diagram" src="https://storage.googleapis.com/wl-blog/images/ideas-venn-diagram.png"></figure><div><p>No matter how good an idea is, we believe that ideas alone are worthless unless you take initiative to execute. Execution is everything. Everyone has big ideas â€” no startup ideas are truly unique. Being able to execute on those ideas is what will turn that idea into a business.</p><p>For any idea, the most important next step is thorough research where you pair your initial idea with independent and external information. To read more about how to evaluate and research a startup idea, and how to take the next step, follow our blueprint on <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">How to Turn An Idea Into A Business</a>.</p><p>Make sure to follow Wilbur Labs on <a href="https://www.linkedin.com/company/wilbur-labs/">LinkedIn</a>, <a href="https://twitter.com/wilburlabs">Twitter</a>, <a href="https://www.facebook.com/wilburlabs/">Facebook</a>, or <a href="http://instagram.com/wilburlabs">Instagram</a>, as we continue to release more blueprints in the future.</p><p>Want to work with us or have an idea? We are always looking for talented people to work with and exciting projects to partner on. Feel free to check out our <a href="https://www.wilburlabs.com/careers">available openings</a> or <a href="https://www.wilburlabs.com/contact">contact us</a>.</p></div></div><div><p>Wilbur Labs is a San Francisco-based startup studio. We turn bold ideas into market-leading companies.</p><p><a href="https://www.wilburlabs.com/about">Learn More â†’</a></p></div></div>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-26085118</guid>
            <pubDate>Wed, 10 Feb 2021 02:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turtle visual cortex is non-retinotopic]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26084739">thread link</a>) | @awinter-py
<br/>
February 9, 2021 | https://blog.jordan.matelsky.com/365papers/141/ | <a href="https://web.archive.org/web/*/https://blog.jordan.matelsky.com/365papers/141/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div>
                                    <p>Most of the visual cortex studies I’ve read have been about mammalian vision. But mammals are not the only organisms with cortex, or at least tissue resembling cortex. This paper explores <em>turtle</em> visual cortex, in an area known as dCx. This dorsal region plays the role of the turtle primary vision center — as close as you can find to the homolog of human V1.</p>

<p>But unlike V1, Fournier &amp; Müller et al confirm the existing knowledge that while dCx receives direct inputs from LGN, its layout is <em>not</em> retinotopic. They expand upon this understanding by recording from both individual cells (with electrophysiological recording) and populations of cells. They show that, aside from some slight preferences of caudal dCx for rostral LGN inputs (and vice versa), dCx doesn’t have any clear layout pattern.</p>

<p>This is interesting because the simple, three-layer cortex of a reptile is a much simpler substrate for understanding vision than the complex, deep cortex of mammals. What, if not “pixel-level” information, is dCx responding to?</p>

<p>While the turtles watched movies, the researchers watched the turtles. In particular, they noticed that certain cells of dCx responded to <em>scene-level</em> stimuli: When there was a cut, or the film started or stopped, there was a burst of activity. When the same stimulus was played repeatedly, these responses died away.</p>

<p>This style of scene-level parsing in mammals is reserved for “later”, down-stream brain areas. Does this mean that turtles are using dCx as both early signal processing as well as higher-level object recognition and interpretation? If so, does this mean that mammalian brains, with discrete areas for low-level and high-level vision, evolved from an earlier system where all of these tasks were colocated?</p>

                                </div>
                            </div>
                        </div></div>]]>
            </description>
            <link>https://blog.jordan.matelsky.com/365papers/141/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26084739</guid>
            <pubDate>Wed, 10 Feb 2021 01:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python behind the scenes #8: how Python integers work]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26081919">thread link</a>) | @rbanffy
<br/>
February 9, 2021 | https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>In the previous parts of this series we studied the core of the CPython interpreter and saw how the most fundamental aspects of Python are implemented. We made an overview of <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">the CPython VM</a>, took a look at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">the CPython compiler</a>, stepped through <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">the CPython source code</a>, studied <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">how the VM executes the bytecode</a> and learned <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/">how variables work</a>. In the two most recent posts we focused on <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">the Python object system</a>. We learned what Python objects and Python types are, how they are defined and what determines their behavior. This discussion gave us a good understanding of how Python objects work in general. What we haven't discussed is how particular objects, such as strings, integers and lists, are implemented. In this and several upcoming posts we'll cover the implementations of the most important and most interesting built-in types. The subject of today's post is <code>int</code>.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>Why Python integers are interesting</h2>
<p>Integers require no introduction. They are so ubiquitous and seem so basic that you may doubt whether it's worth discussing how they are implemented at all. Yet, Python integers are interesting because they are not just 32-bit or 64-bit integers that CPUs work with natively. Python integers are <a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic">arbitrary-precision integers</a>, also known as bignums. This means that they can be as large as we want, and their sizes are only limited by the amount of available memory.</p>
<p>Bignums are handy to work with because we don't need to worry about such things as integer overflows and underflows. They are extensively used in fields like cryptography and computer algebra where large numbers arise all the time and must be represented precisely. So, <a href="https://en.wikipedia.org/wiki/List_of_arbitrary-precision_arithmetic_software">many</a> programming languages have bignums built-in. These include Python, JavaScript, Ruby, Haskell, Erlang, Julia, Racket. Others provide bignums as a part of the standard library. These include Go, Java, C#, D, PHP. Numerous third-party libraries implement bignums. The most popular one is <a href="https://en.wikipedia.org/wiki/GNU_Multiple_Precision_Arithmetic_Library">the GNU Multiple Precision Arithmetic Library</a> (GMP). It provides a C API but has bindings for all major languages.</p>
<p>There are a lot of bignum implementations. They're different in detail, but the general approach to implement bignums is the same. Today we'll see what this approach looks like and use CPython's implementation as a reference example. The two main questions we'll have to answer are:</p>
<ul>
<li>how to represent bignums; and</li>
<li>how to performs arithmetic operations, such as addition and multiplication, on bignums.</li>
</ul>
<p>We'll also discuss how CPython's implementation compares to others and what CPython does to make integers more efficient. </p>
<h2>Bignum representation</h2>
<p>Think for a moment how you would represent large integers in your program if you were to implement them yourself. Probably the most obvious way to do that is to store an integer as a sequence of digits, just like we usually write down numbers. For example, the integer <code>51090942171709440000</code> could be represented as <code>[5, 1, 0, 9, 0, 9, 4, 2, 1, 7, 1, 7, 0, 9, 4, 4, 0, 0, 0, 0]</code>. This is essentially how bignums are represented in practice. The only important difference is that instead of base 10, much larger bases are used. For example, CPython uses base 2^15 or base 2^30 depending on the platform. What's wrong with base 10? If we represent each digit in a sequence with a single byte but use only 10 out of 256 possible values, it would be very memory-inefficient. We could solve this memory-efficiency problem if we use base 256, so that each digit takes a value between 0 and 255. But still much larger bases are used in practice. The reason for that is because larger base means that numbers have less digits, and the less digits numbers have, the faster arithmetic operations are performed. The base cannot be arbitrary large. It's typically limited by the size of the integers that the CPU can work with. We'll see why this is the case when we discuss bignum arithmetic in the next section. Now let's take a look at how CPython represents bignums.</p>
<p>Everything related to the representation of Python integers can be found in <a href="https://github.com/python/cpython/blob/3.9/Include/longintrepr.h"><code>Include/longintrepr.h</code></a>. Technically, Python integers are instances of <code>PyLongObject</code>, which is defined in <a href="https://github.com/python/cpython/blob/3.9/Include/longobject.h"><code>Include/longobject.h</code></a>, but <code>PyLongObject</code> is actually a typedef for <code>struct _longobject</code> that is defined in <code>Include/longintrepr.h</code>:</p>
<div><pre><span></span><span>struct</span> <span>_longobject</span> <span>{</span>
    <span>PyVarObject</span> <span>ob_base</span><span>;</span> <span>// expansion of PyObject_VAR_HEAD macro</span>
    <span>digit</span> <span>ob_digit</span><span>[</span><span>1</span><span>];</span>
<span>};</span>
</pre></div>


<p>This struct extends <a href="https://docs.python.org/3/c-api/structures.html#c.PyVarObject"><code>PyVarObject</code></a>, which in turn extends <a href="https://docs.python.org/3/c-api/structures.html#c.PyObject"><code>PyObject</code></a>:</p>
<div><pre><span></span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>PyObject</span> <span>ob_base</span><span>;</span>
    <span>Py_ssize_t</span> <span>ob_size</span><span>;</span> <span>/* Number of items in variable part */</span>
<span>}</span> <span>PyVarObject</span><span>;</span>
</pre></div>


<p>So, besides a reference count and a type that all Python objects have, an integer object has two other members: </p>
<ul>
<li><code>ob_size</code> that comes from <code>PyVarObject</code>; and </li>
<li><code>ob_digit</code> that is defined in <code>struct _longobject</code>.</li>
</ul>
<p>The <code>ob_digit</code> member is a pointer to an array of digits. On 64-bit platforms, each digit is a 30-bit integer that takes values between 0 and 2^30-1 and is stored as an unsigned 32-bit int (<code>digit</code> is a typedef for <code>uint32_t</code>). On 32-bit platforms, each digit is a 15-bit integer that takes values between 0 and 2^15-1 and is stored as an unsigned 16-bit int (<code>digit</code> is a typedef for <code>unsigned short</code>). To make things concrete, in this post we'll assume that digits are 30 bits long.</p>
<p>The <code>ob_size</code> member is a signed int, whose absolute value tells us the number of digits in the <code>ob_digit</code> array. The sign of <code>ob_size</code> indicates the sign of the integer. Negative <code>ob_size</code> means that the integer is negative. If <code>ob_size</code> is 0, then the integer is 0.</p>
<p>Digits are stored in a little-endian order. The first digit (<code>ob_digit[0]</code>) is the least significant, and the last digit (<code>ob_digit[abs(ob_size)-1]</code>) is the most significant.</p>
<p>Finally, the absolute value of an integer is calculated as follows: </p>
<p>$$val = ob\_digit[0] \times (2 ^{30})^0 + ob\_digit[1] \times (2 ^{30})^1 + \cdots + ob\_digit[|ob\_size| - 1] \times (2 ^{30})^{|ob\_size| - 1}$$</p>
<p>Let's see what all of this means with an example. Suppose we have an integer object that has <code>ob_digit = [3, 5, 1]</code> and <code>ob_size = -3</code>. To compute its value, we can do the following:</p>
<div><pre><span></span><span>$ python -q</span>
<span>&gt;&gt;&gt; </span><span>base</span> <span>=</span> <span>2</span><span>**</span><span>30</span>
<span>&gt;&gt;&gt; </span><span>-</span><span>(</span><span>3</span> <span>*</span> <span>base</span><span>**</span><span>0</span> <span>+</span> <span>5</span> <span>*</span> <span>base</span><span>**</span><span>1</span> <span>+</span> <span>1</span> <span>*</span> <span>base</span><span>**</span><span>2</span><span>)</span>
<span>-1152921509975556099</span>
</pre></div>


<p>Now let's do the reverse. Suppose we want to get the bignum representation of the number <code>51090942171709440000</code>. Here's how we can do that:</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>x</span> <span>=</span> <span>51090942171709440000</span>
<span>&gt;&gt;&gt; </span><span>x</span> <span>%</span> <span>base</span>
<span>952369152</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>337507546</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>44</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>x</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span> <span>//</span> <span>base</span><span>)</span> <span>%</span> <span>base</span>
<span>0</span>
</pre></div>


<p>So, <code>ob_digit = [952369152, 337507546, 44]</code> and <code>ob_size = 3</code>. Actually, we don't even have to compute the digits, we can get them by inspecting the integer object using the <a href="https://docs.python.org/3/library/ctypes.html#module-ctypes"><code>ctypes</code></a> standard library:</p>
<div><pre><span></span><span>import</span> <span>ctypes</span>


<span>MAX_DIGITS</span> <span>=</span> <span>1000</span>

<span># This is a class to map a C `PyLongObject` struct to a Python object</span>
<span>class</span> <span>PyLongObject</span><span>(</span><span>ctypes</span><span>.</span><span>Structure</span><span>):</span>
    <span>_fields_</span> <span>=</span> <span>[</span>
        <span>(</span><span>"ob_refcnt"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_ssize_t</span><span>),</span>
        <span>(</span><span>"ob_type"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_void_p</span><span>),</span>
        <span>(</span><span>"ob_size"</span><span>,</span> <span>ctypes</span><span>.</span><span>c_ssize_t</span><span>),</span>
        <span>(</span><span>"ob_digit"</span><span>,</span> <span>MAX_DIGITS</span> <span>*</span> <span>ctypes</span><span>.</span><span>c_uint32</span><span>)</span>
    <span>]</span>


<span>def</span> <span>get_digits</span><span>(</span><span>num</span><span>):</span>
    <span>obj</span> <span>=</span> <span>PyLongObject</span><span>.</span><span>from_address</span><span>(</span><span>id</span><span>(</span><span>num</span><span>))</span>
    <span>digits_len</span> <span>=</span> <span>abs</span><span>(</span><span>obj</span><span>.</span><span>ob_size</span><span>)</span>
    <span>return</span> <span>obj</span><span>.</span><span>ob_digit</span><span>[:</span><span>digits_len</span><span>]</span>
</pre></div>


<div><pre><span></span><span>&gt;&gt;&gt; </span><span>from</span> <span>num_digits</span> <span>import</span> <span>get_digits</span>
<span>&gt;&gt;&gt; </span><span>x</span> <span>=</span> <span>51090942171709440000</span>
<span>&gt;&gt;&gt; </span><span>get_digits</span><span>(</span><span>x</span><span>)</span>
<span>[952369152, 337507546, 44]</span>
</pre></div>


<p>As you might guess, the representation of bignums is an easy part. The main challenge is to implement arithmetic operations and to implement them efficiently.</p>
<h2>Bignum arithmetic</h2>
<p>We learned in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">part 6</a> that the behavior of a Python object is determined by the object's type. Each member of a type, called slot, is responsible for a particular aspect of the object's behavior. So, to understand how CPython performs arithmetic operations on integers, we need to study the slots of the <code>int</code> type that implement those operations.</p>
<p>In the C code, the <code>int</code> type is called <code>PyLong_Type</code>. It's defined in <code>Objects/longobject.c</code> as follows:</p>
<div><pre><span></span><span>PyTypeObject</span> <span>PyLong_Type</span> <span>=</span> <span>{</span>
    <span>PyVarObject_HEAD_INIT</span><span>(</span><span>&amp;</span><span>PyType_Type</span><span>,</span> <span>0</span><span>)</span>
    <span>"int"</span><span>,</span>                                      <span>/* tp_name */</span>
    <span>offsetof</span><span>(</span><span>PyLongObject</span><span>,</span> <span>ob_digit</span><span>),</span>           <span>/* tp_basicsize */</span>
    <span>sizeof</span><span>(</span><span>digit</span><span>),</span>                              <span>/* tp_itemsize */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_dealloc */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_vectorcall_offset */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_getattr */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_setattr */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_async */</span>
    <span>long_to_decimal_string</span><span>,</span>                     <span>/* tp_repr */</span>
    <span>&amp;</span><span>long_as_number</span><span>,</span>                            <span>/* tp_as_number */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_sequence */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_mapping */</span>
    <span>(</span><span>hashfunc</span><span>)</span><span>long_hash</span><span>,</span>                        <span>/* tp_hash */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_call */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_str */</span>
    <span>PyObject_GenericGetAttr</span><span>,</span>                    <span>/* tp_getattro */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_setattro */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_as_buffer */</span>
    <span>Py_TPFLAGS_DEFAULT</span> <span>|</span> <span>Py_TPFLAGS_BASETYPE</span> <span>|</span>
        <span>Py_TPFLAGS_LONG_SUBCLASS</span><span>,</span>               <span>/* tp_flags */</span>
    <span>long_doc</span><span>,</span>                                   <span>/* tp_doc */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_traverse */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_clear */</span>
    <span>long_richcompare</span><span>,</span>                           <span>/* tp_richcompare */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_weaklistoffset */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_iter */</span>
    <span>0</span><span>,</span>                                          <span>/* tp_iternext */</span>
    <span>long_methods</span><span>,</span>                               <span>/* tp_methods */</span>
    <span>0</span><span>,</span>                                          <span>/* …</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/">https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-8-how-python-integers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081919</guid>
            <pubDate>Tue, 09 Feb 2021 20:14:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creeping as a Service]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 113 (<a href="https://news.ycombinator.com/item?id=26081672">thread link</a>) | @dshipper
<br/>
February 9, 2021 | https://every.to/divinations/creeping-as-a-service-craas | <a href="https://web.archive.org/web/*/https://every.to/divinations/creeping-as-a-service-craas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><em>Hey, Nathan here! Remember a few months ago when we published a wonderful essay on&nbsp;</em><a href="https://every.to/divinations/linkedins-alternate-universe-21780381" rel="noopener noreferrer" target="_blank"><em>LinkedInâ€™s ridiculousness</em></a><em>? It was one of Divinations most popular posts ever, and it was written by </em><a href="https://twitter.com/fadeke_adegbuyi" rel="noopener noreferrer" target="_blank"><em>Fadeke Adegbuyi</em></a><em>, a brilliant observer of internet culture who also is a senior marketing manager at Doist. Today Iâ€™m thrilled to share with you Fadekeâ€™s latest workâ€”this time examining our obsession with identity through the lens of a Twitter bio tracking app called Spoonbill. Enjoy!</em></p><hr><p>Elon Musk updated his Twitter bio 23 times in 2020. He last changed it on February 4, 2021 at 6:31 AM PST. A few versions include â€œBorn 69 days after 4/20,â€� â€œSoundCloud Rockstar,â€� â€œBudgie Smuggler,â€� and â€œ#bitcoin.â€� I didnâ€™t spend months stalking Muskâ€™s page, developing an encyclopedic knowledge of his time spent in the Twitterverse. I looked it up on <a href="http://spoonbill.io/" rel="noopener noreferrer" target="_blank">Spoonbill</a>.&nbsp;</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_1.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_1.png"></a></p><p>I could use the app to give you similar information on any celebrity or public figure with a Twitter account. Or I could use it on you. If I wanted to, I could see all the changes youâ€™ve made to your profile since you first signed up: your name, your location, your website, your pinned tweets. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_2.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_2.png"></a></p><p>Spoonbillâ€™s creator, <a href="https://twitter.com/justinmduke" rel="noopener noreferrer" target="_blank">Justin M. Duke</a>, describes the app, which has nearly 93 thousand users, as a â€œtracking tool for online metadata.â€� Over 45K of those users have signed up to receive daily emails that aggregate updates across all the Twitter profiles they follow. The open rate for these daily emails hovers around 55%, <a href="https://www.campaignmonitor.com/resources/knowledge-base/what-are-the-average-click-and-read-rates-for-email-campaigns/" rel="noopener noreferrer" target="_blank">well above average</a> for email campaigns.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_3.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_3.png"></a></p><p>I asked <a href="https://twitter.com/hunterwalk" rel="noopener noreferrer" target="_blank">Hunter Walk</a>, a Partner at the seed-stage venture capital firm Homebrew and an avid Spoonbiller, why he uses the app :</p><blockquote><em>"It's fun to see people wordsmithing their bios, changing the order of the portfolio companies they list based on startup performance, subtly announcing personal life changes...Instead of letting Twitter decide what's worthy of notification, I get to see </em>every<em> change and decide for myself what's interesting, often with context that the algorithm is unaware of."</em></blockquote><p>The tracked changes that Twitterâ€™s algorithm might register as neutral additions and subtractions can indeed be revealing to onlookers. Spoonbill captures what the people we follow are changing their bios to express; an investment exit, a tongue-in-cheek joke, or the end of an internet cult affiliation.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_New.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_New.png"></a></p><p>Social apps have made creepers out of all of us. Whether itâ€™s scrolling to the start of someoneâ€™s Instagram feed or <a href="https://sarajbenincasa.medium.com/confessions-of-a-venmo-voyeur-cb0e4c23d04a" rel="noopener noreferrer" target="_blank">looking through Venmo transactions</a>, weâ€™re constantly peering into othersâ€™ online lives. Spoonbill not only satisfies our tendency for online lurking, but pushes it into voyeur territory; surfacing whatâ€™s meant to be hidden is intimate in a way that scrolling a timeline isnâ€™t. The tool provides a glimpse into the specific ways we represent ourselves to the world, the unseen effort with which we express our identities, and how the uncanny feeling of being watched informs our sense of self.</p><p>Twitter is an interesting observation ground for online identity. Snapshots at Big Sur are meant for Instagramâ€™s photogenic feed, while professional milestones belong on <a href="https://divinations.every.to/p/linkedins-alternate-universe" rel="noopener noreferrer" target="_blank">LinkedInâ€™s alternate universe</a>. But in the Twitterverse, life and work converge. People are just as likely to share career news as they are to live-tweet a Netflix binge; professional gripes commingle with criticism of political leaders; snark and sincerity live side-by-side. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_4.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_4.png"></a></p><p>Twitterâ€™s bio section, then, is a tall order: <em>compress your entire identity into a single line item</em>. Many use the space to convey their own complexityâ€“â€“smart yet funny, accomplished but approachable. Society has progressed past the need for the phrase â€œworks hard, plays hard,â€� but thatâ€™s what weâ€™re trying to convey in our own personalized way: we contain multitudes. We are real.</p><p>Spoonbill reveals the way that people play with their latest positioning of self, carving out character space for their newly important aspects of identity.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_7.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_7.png"></a></p><p>Hustle culture looms large and professional accomplishments convey worth. In turn, notable work, career highlights, and impressive affiliations take center stage in our Twitter bios, the structure and grammar of which are heavily coded. Freelance journalists add and shuffle their bylines, arranged in order of prestige â€“â€“ @nytimes is meant to come first. In my corner of Tech Twitter, where optionality is king, itâ€™s now effectively a meme to be <em>â€œstarting something new,â€�</em> marked increasingly by the addition of â€œSubstack:â€�, â€œScout:â€�, or â€œSide project:â€� to oneâ€™s bio. Users adding â€œ<em>permanent student</em>â€� or â€œ<em>forever learning</em>â€� to their bios arenâ€™t pupils at cruel and unusual institutions, theyâ€™re signalling intellectual curiosity.&nbsp;</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_8.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_8.png"></a></p><p>The ability to see Twitter bio updates across hundreds or thousands of profiles over time make Spoonbill updates insightful in aggregate. Certain patterns and conventions emerge.&nbsp;</p><p>Spoonbillâ€™s creator has observed interesting trends in his app:</p><blockquote><em>"On an individual/corporate basis, a particularly fun one is seeing angels and investors tinker with the parts of the portfolio they </em><a href="http://spoonbill.io/twitter/data/Jason/" rel="noopener noreferrer" target="_blank"><em>choose to highlight</em></a><em>. A very classic example of this was the sheer number of firms and investors who removed things mentioning WeWork during, well, the period of time that you didnâ€™t want your name associated with WeWork."</em></blockquote><p>WeWork reached a $47 billion valuation in 2019, but cancelled their plans to go public <a href="https://www.businessinsider.com/wework-ipo-timeline-delayed-ceo-adam-neumann-scandals-explained-2019-9" rel="noopener noreferrer" target="_blank">after their IPO filing drew questions and concerns</a>. In a bio block thatâ€™s meant for selling ourselves to a potential follower, a failed investment takes up valuable real estate. But while WeWork investors might wish we would all forget their involvement as quickly as they hit â€œsaveâ€� on their new bio, Spoonbill always knows.</p><p>In that same 160-character space, weâ€™re also meant to declare our commitment to cause: political, social, or economic. Often, emojis will do:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_9.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_9.png"></a></p><p>If you watch Spoonbill updates closely enough, they suggest that the labels and descriptors we choose to signal our allegiances can be fleeting, our attention spans short. As COVID-19 spread throughout the world in early 2020, many updated their bios with their own messages about the virus, encouraging their followers to take some form of action:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_10.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_10.png"></a></p><p>But almost as quickly as these bio changes were made, they were unmade, individuals returning to their regular profiles. Less charitably, people just got bored; short-term vigilance surrounding the virus eventually led to a return to normal life for many. More charitably, the longer the pandemic wore on, identities once swaddled in concern for the virus eventually needed some wiggle room.&nbsp;</p><p>Last year, as racial tensions bubbled to a boil throughout the United States and set off an international cascade, Spoonbill revealed how Twitter bios were used to show support for what was top of mindâ€“â€“or a stance on what was top of the fold:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_11.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_11.png"></a></p><p>As time went on, it was jarring but predictable to see lines through phrases like â€œBlack lives matterâ€� across swaths of profile updates in my inbox. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_12.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_12.png"></a></p><p>Politics similarly finds its way into our descriptions of self. With the 2020 U.S. presidential election, many translated their desired vote on the ballot to their bio: </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_13.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_13.png"></a></p><p>The story has already been written, and you know what comes next: dashed presidential dreams translated to crossed-out candidates. Adding presidential hopefuls or even political parties to how we identify can be an exercise in disappointment. Disappointment is inevitable (after all, there can only be one). But seeing how long people hold on to their hopefuls was interesting; some still signalling long after their candidate had dropped out.</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_14.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_14.png"></a></p><p>These tracked changes of our online selves provide a glimpse into the specific ways we represent ourselves to the world, how society manages to infect our identities, and, what we valueâ€”or what we want to be seen as valuing.</p><p>Spoonbill uncovers the tacit labor involved in our quest for the perfect personal positioning. In describing the way online influencers take effortless-looking selfies that are actually quite effortful, <a href="https://twitter.com/wishcrys" rel="noopener noreferrer" target="_blank">Dr. Crystal Abidin (aka wishcrys)</a>, a researcher and â€œanthropologist of influencer culturesâ€� (according to her own Twitter bio), <a href="https://journals.sagepub.com/doi/full/10.1177/2056305116641342" rel="noopener noreferrer" target="_blank">coined the term â€œtacit laborâ€�</a> as:&nbsp;</p><blockquote><em>â€œA collective practice of work that is understated and under-visibilized from being so thoroughly rehearsed that it appears as effortless and subconscious.â€�</em></blockquote><p>You donâ€™t need to be an influencer to know the labor involved in taking and selecting a selfie. Getting the right light, angle, and expression are just some of the considerations made while snapping and choosing from the photos that fill our camera rolls. After selecting the winning shot, we leave behind a stream of rejected selfies, never to see the light of day; the tacit labor stays hidden. After a photo has been cropped, filtered, and face-tuned, a refined â€œselfâ€�-ie joins the feed, adding to our curated online imageâ€“â€“polished, carefree, or somewhere in between.</p><p>Just like we strain for the perfect selfie, we tinker to find the perfect bio, treating it as a personal sales pitch and making micro edits to what we represent and â€œwho we are.â€� Spoonbill catalogues every time-stamped keystroke and tracked changeâ€“â€“from the removal of a single stuffy period to self-consciously swapping â€œMarketerâ€� for â€œStorytellerâ€� and reverting back again.&nbsp; Like the photos in your camera roll, your current Twitter bio has leftâ€“â€“for Spoonbill users to seeâ€“â€“a wake of rejected selves. </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_5.png" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/1495/optimized_5.png"></a></p><p>Spoonbill reveals the surprising scale and frenzying frequency with which all kinds of people make these online edits. We add in emojis, expand and shrink our past affiliations, and flirt briefly with humor, adding clever one-liners before eventually reverting to something more serious. Itâ€™s effortfulness on display. Seeing people iterate on their identities in Spoonbill, switching too-formal uppercase for carefree lowercase characters, makes our desire to control how …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://every.to/divinations/creeping-as-a-service-craas">https://every.to/divinations/creeping-as-a-service-craas</a></em></p>]]>
            </description>
            <link>https://every.to/divinations/creeping-as-a-service-craas</link>
            <guid isPermaLink="false">hacker-news-small-sites-26081672</guid>
            <pubDate>Tue, 09 Feb 2021 19:45:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vantage has acquired ec2instances.info]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26080571">thread link</a>) | @StratusBen
<br/>
February 9, 2021 | https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info | <a href="https://web.archive.org/web/*/https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Two things that aren’t changing are (1) customers are always going to want simpler ways to interact with their cloud infrastructure and (2) they’re always going to want tools to understand where their cloud costs are coming from to make better business decisions. Vantage is aiming to help with both of these challenges but customers also use other tools to help make informed business decisions. One of the most popular tools we found people using is Ec2instances.info and today I’m happy to announce that Ec2instances.info is joining forces with Vantage.</p><p>Ec2instances.info will now reside at instances.vantage.sh and exists in its same form. The site will continue to be completely free and we have plans to add more features and functionality to it, including additional service prices beyond virtual machine pricing. We’ve ensured that the redirects have backwards compatibility with the prior domain so everything should continue to work as expected.&nbsp;</p><p>Garret Heaton, the creator of Ec2instances.info, says:<br></p><blockquote>After running ec2instances.info as a side project for <a href="https://powdahound.com/2011/03/hosting-a-static-site-on-amazon-s3-ec2instances-info/">almost a decade</a> I'm thrilled to hand over the reins to the Vantage team. Watching the site help people year after year has been a real pleasure and I'm very grateful for all the bug reports and improvements submitted by the public. In recent years the amount of choice available in instance types has grown significantly so comparing them is especially important, but I haven't had time to improve the site at the same rate. I'm very excited to see Vantage invest in the site as well as help people control costs across their entire infrastructure.</blockquote><p>‍</p><p>Vantage is built by working backwards from customer feedback and we hope to use the same playbook for instances.vantage.sh - so please join our <a href="https://join.slack.com/t/vantagecommunity/shared_invite/zt-mc723hg0-64opi05ckDf3gE56xapntg">Slack Community</a>, follow us on <a href="https://twitter.com/joinvantage">Twitter</a> or email us at <a href="mailto:support@vantage.sh">support@vantage.sh</a> to let us know your use-cases and how we can help.</p><p><strong>Q&amp;A</strong><br></p><p><strong>What is Vantage?</strong></p><p>Vantage is an alternative AWS console with a focus on developer experience and cost transparency.&nbsp;<br></p><p>‍</p><p><strong>What is EC2Instances.info?</strong></p><p>Ec2Instances.info, now instances.vantage.sh, is a tool for comparing hundreds of EC2 Instance Types across different instance type attributes.&nbsp;</p><p>‍<br></p><p><strong>I use EC2Instances.info - how will this impact me?</strong></p><p>Only the domain is changing and all existing links will redirect in a way that preserves filters. For all intents and purposes, you shouldn’t be impacted.&nbsp;</p><p>‍<br></p><p><strong>Do I need to be a registered Vantage user to use instances.vantage.sh?</strong></p><p>No. That being said, we are offering a one-time coupon code of $25 to all EC2Instances users that you can apply to your Vantage account using the coupon code of INSTANCES. This offer will expire on March 31st, 2021.</p><p><strong>I have a feature request for ec2instances.info - how can I submit it to you?</strong></p><p>You can continue to leave feedback on the existing <a href="https://github.com/powdahound/ec2instances.info">Github repository</a>, email <a href="mailto:support@vantage.sh">support@vantage.sh</a> with the subject line “Product Feedback Request” or join the “instances-vantage-sh” channel in the Vantage <a href="https://join.slack.com/t/vantagecommunity/shared_invite/zt-mc723hg0-64opi05ckDf3gE56xapntg">Slack community</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.vantage.sh/blog/vantage-has-acquired-ec2instances-info</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080571</guid>
            <pubDate>Tue, 09 Feb 2021 18:00:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fedora on the PinePhone: Pipewire Calling]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 85 (<a href="https://news.ycombinator.com/item?id=26080207">thread link</a>) | @ashitlerferad
<br/>
February 9, 2021 | https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1 | <a href="https://web.archive.org/web/*/https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://odysee.com/@linmob:3/fedora-on-the-pinephone-pipewire-calling:1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26080207</guid>
            <pubDate>Tue, 09 Feb 2021 17:29:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js 14 is over 20x faster than Python3.8 for fib(n)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 103 (<a href="https://news.ycombinator.com/item?id=26079570">thread link</a>) | @brrrrrm
<br/>
February 9, 2021 | https://jott.live/markdown/nodejs_vs_python_ | <a href="https://web.archive.org/web/*/https://jott.live/markdown/nodejs_vs_python_">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jott.live/markdown/nodejs_vs_python_</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079570</guid>
            <pubDate>Tue, 09 Feb 2021 16:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John McWhorter: The Neoracists]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 232 (<a href="https://news.ycombinator.com/item?id=26079002">thread link</a>) | @paulpauper
<br/>
February 9, 2021 | https://www.persuasion.community/p/john-mcwhorter-the-neoracists | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/john-mcwhorter-the-neoracists">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d3f575ee-a995-499c-86fe-72680f8d5d12_700x312.jpeg&quot;,&quot;height&quot;:312,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:40221,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>[</strong>Excerpt from his new book, <em>The Elect: Neoracists Posing as Antiracists and their Threat to a Progressive America</em>]</p><p><strong>One can divide antiracism into three waves</strong>. First Wave Antiracism battled slavery and segregation. Second Wave Antiracism, in the 1970s and 1980s, battled racist attitudes and taught America that being racist was a flaw. Third Wave Antiracism, becoming mainstream in the 2010s, teaches that racism is baked into the structure of society, so whites’ “complicity” in living within it constitutes racism itself, while for black people, grappling with the racism surrounding them is the totality of experience and must condition exquisite sensitivity toward them, including a suspension of standards of achievement and conduct.</p><p>Third Wave Antiracist tenets, stated clearly and placed in simple oppositions, translate into nothing whatsoever:</p><ol><li><p>When black people say you have insulted them, apologize with profound sincerity and guilt. <strong>But </strong>don’t put black people in a position where you expect them to forgive you. They have dealt with too much to be expected to.</p></li><li><p>Black people are a conglomeration of disparate individuals. “Black culture” is code for “pathological, primitive ghetto people.” <strong>But </strong>don’t expect black people to assimilate to “white” social norms because black people have a culture of their own.</p></li><li><p>Silence about racism is violence. <strong>But </strong>elevate the voices of the oppressed over your own.</p></li><li><p>You must strive eternally to understand the experiences of black people. <strong>But </strong>you can never understand what it is to be black, and if you think you do you’re a racist.</p></li><li><p>Show interest in multiculturalism.&nbsp;<strong>But </strong>do not culturally appropriate. What is not your culture is not for you, and you may not try it or do it. But—if you aren’t nevertheless <em>interested</em> in it, you are a racist.</p></li><li><p>Support black people in creating their own spaces and stay out of them. <strong>But </strong>seek to have black friends. If you don’t have any, you’re a racist. And if you claim any, they’d better be <em>good</em> friends—in their private spaces, you aren’t allowed in.</p></li><li><p>When whites move away from&nbsp;black neighborhoods, it’s white flight.&nbsp;<strong>But </strong>when whites move into black neighborhoods, it’s gentrification, even when they pay black residents generously for their houses.</p></li><li><p>If you’re white and only date white people, you’re a racist. <strong>But </strong>if you’re white and date a black person you are, if only deep down, exotifying an “other.”</p></li><li><p>Black people cannot be held accountable for everything every black person does. <strong>But </strong>all whites must acknowledge their personal complicity in the perfidy throughout history of “whiteness.”</p></li><li><p>Black students must be admitted to schools via adjusted grade and test score standards to ensure a representative number of them and foster a diversity of views in classrooms. <strong>But </strong>it is racist to assume a black student was admitted to a school via racial preferences, and racist to expect them to represent the “diverse” view in classroom discussions.</p></li></ol><p>I suspect that deep down, most know that none of this catechism makes any sense. Less obvious is that it was not even composed with logic in mind. The self-contradiction of these tenets is crucial, in revealing that Third Wave Antiracism is not a philosophy but a religion. </p><p>The revelation of racism is, itself and alone, the point, the intention, of this curriculum. As such, the fact that if you think a little, the tenets cancel one another out, is considered trivial. That they serve their true purpose of revealing people as bigots is paramount—sacrosanct, as it were. Third Wave Antiracism’s needlepoint homily <em>par excellence</em> is the following:</p><blockquote><p>Battling power relations and their discriminatory effects must be the central focus of all human endeavor, be it intellectual, moral, civic or artistic. Those who resist this focus, or even evidence insufficient adherence to it, must be sharply condemned, deprived of influence, and ostracized.</p></blockquote><p><strong>Third Wave Antiracism is losing innocent people jobs.</strong> It is coloring, detouring and sometimes strangling academic inquiry. It forces us to render a great deal of our public discussion of urgent issues in doubletalk any 10-year-old can see through. It forces us to start teaching our actual 10-year-olds, in order to hold them off from spoiling the show in that way, to believe in sophistry in the name of enlightenment. On that, Third Wave Antiracism guru Ibram X. Kendi has written a book on how to raise antiracist children called <em>Antiracist Baby</em>. You couldn’t imagine it better: Are we in a Christopher Guest movie? This and so much else is a sign that Third Wave Antiracism forces us to pretend that performance art is politics. It forces us to spend endless amounts of time listening to nonsense presented as wisdom, and pretend to like it.</p><p>I write this viscerally driven by the fact that all of this supposed wisdom is founded in an ideology under which white people calling themselves our saviors make black people look like the dumbest, weakest, most self-indulgent human beings in the history of our species, and teach black people to revel in that status and cherish it as making us special. Talking of <em>Antiracist Baby</em>, I am especially dismayed at the idea of this indoctrination infecting my daughters’ sense of self. I can’t always be with them, and this anti-humanist ideology may seep into their school curriculum. I shudder at the thought: teachers with eyes shining at the prospect of showing their antiracism by teaching my daughters that they are poster children rather than individuals. </p><p>Ta-Nehisi Coates in <em>Between the World and Me</em> wanted to teach his son that America is set against him; I want to teach my kids the reality of their lives in the 21st&nbsp;rather than early-to-mid-20th century. Lord forbid my daughters internalize a pathetic—yes, absolutely pathetic in all of the resonances of that word—sense that what makes them interesting is what other people think of them, or don’t.</p><p>Many will see me as traitorous in writing this as a black person. They will not understand that I see myself as serving my race by writing it. One of the grimmest tragedies of how this perversion of sociopolitics makes us think (or, not think) is that it will bar more than a few black readers from understanding that I am calling for them to be treated with true dignity. However, they and everyone else should also realize: I know quite well that white readers will be more likely to hear out views like this when written by a black person, and consider it nothing less than my duty as a black person to write it.</p><p>A white version of this would be blithely dismissed as racist. I will be dismissed instead as self-hating by a certain crowd. But frankly, they won’t really mean it, and anyone who gets through <a href="https://johnmcwhorter.substack.com/p/the-elect-neoracists-posing-as-antiracists">my new book</a> on this subject, which I am now publishing in serial, will see that whatever traits I harbor, hating myself or being ashamed of being black is not one of them. And we shall move on. As in, to realizing that what I am documenting matters, and matters deeply. Namely, that America’s sense of what it is to be intellectual, moral, or artistic; what it is to educate a child; what it is to foster justice; what is to express oneself properly; what it is to be a nation—all is being refounded upon a religion. </p><p>This is directly antithetical to the very foundations of the American experiment. Religion has no place in the classroom, in the halls of ivy, in our codes of ethics, or in deciding how we express ourselves, and almost all of us spontaneously understand that and see any misunderstanding of the premise as backward. Yet since about 2015, a peculiar contingent has been slowly headlocking us into making an exception, supposing that this new religion is so incontestably good, so gorgeously surpassing millennia of brilliant philosophers’ attempts to identify the ultimate morality, that we can only bow down in humble acquiescence.</p><p>But a new religion in the guise of world progress is not an advance; it is a detour. It is not altruism; it is self-help. It is not sunlight; it is fungus. It’s time it became ordinary to call it for what it is and stop cowering before it, letting it make people so much less than they—black and everything else—could be.</p><p><strong>Third Wave Antiracism exploits modern Americans’ fear</strong> of being thought racist, using this to promulgate an obsessive, self-involved, totalitarian and unnecessary kind of cultural reprogramming. One could be excused for thinking this glowering kabuki is a continuation of the Civil Rights efforts of yore, the only kind of new antiracism there could be. Its adherents preach with such contemptuous indignation, and are now situated in the most prestigious and influential institutions in the land—on their good days they can seem awfully “correct.”</p><p>However, there is nothing correct about the essence of American thought and culture being transplanted into the soil of a religious faith. Some will go as far as to own up to it being a religion, and wonder why we can’t just accept it as our new national creed. The problem is that on matters of societal procedure and priorities, the adherents of this religion—true to the very nature of religion—cannot be reasoned with. They are, in this, medievals with lattes.</p><p>We need not wonder what the basic objections will be: Third Wave Antiracism isn’t really a religion; I am oversimplifying; I shouldn’t write this without being a theologian; it is a religion but it’s a good one; and so on. I will get all of that out of the way as we go on, and then offer some genuine solutions. But first, what this is not.</p><ol><li><p><em>It is not an argument against protest.</em> I am not arguing against the basic premises of Black Lives Matter, although I have had my differences with some of its offshoot developments. I am not arguing that the Civil Rights movement of the 1950s and 1960s would have been better off sticking to quiet negotiations. I am not arguing against the left. I am arguing against a particular strain of the left that has come to exert a grievous influence over American institutions, to the point that we are beginning to …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/john-mcwhorter-the-neoracists">https://www.persuasion.community/p/john-mcwhorter-the-neoracists</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/john-mcwhorter-the-neoracists</link>
            <guid isPermaLink="false">hacker-news-small-sites-26079002</guid>
            <pubDate>Tue, 09 Feb 2021 15:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leveraging the Go Type System]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 104 (<a href="https://news.ycombinator.com/item?id=26078865">thread link</a>) | @gopherguides
<br/>
February 9, 2021 | https://www.gopherguides.com/articles/leveraging-the-go-type-system | <a href="https://web.archive.org/web/*/https://www.gopherguides.com/articles/leveraging-the-go-type-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <div>
    <section>  </section> <string></string> <section><p>If you haven't worked in a typed language before, it may not be obvious at first the power that it brings.  This article will show you how to leverage the type system to make your code easier to use and more reusable.</p> <h4>Target Audience</h4> <p>This article is aimed at developers that are new to Go and have little to no Go experience.</p> <h2>The Problem</h2> <p>For this article, we will look at how to handle <code language="plain">categorical</code> data.  In this case, specifically how to handle the <code language="plain">genre</code> category for classifying a book.</p> <p>To start, we'll define a data structure for a <code language="plain">Book</code> , in which we'll want to categorize it via the <code language="plain">genre</code> :</p> <pre><code language="plain" snippet="book" src="./src/v1/books.go">package books

type Book struct {
	ID    int
	Name  string
	Genre string
}</code></pre>   <p>Now that we have the book defined, let's go ahead and define some constants for <code language="plain">genre</code> :</p> <pre><code language="plain" snippet="genre" src="./src/v1/books.go">const (
	Adventure     = "Adventure"
	Comic         = "Comic"
	Crime         = "Crime"
	Fiction       = "Fiction"
	Fantasy       = "Fantasy"
	Historical    = "Historical"
	Horror        = "Horror"
	Magic         = "Magic"
	Mystery       = "Mystery"
	Philosophical = "Philosophical"
	Political     = "Political"
	Romance       = "Romance"
	Science       = "Science"
	Superhero     = "Superhero"
	Thriller      = "Thriller"
	Western       = "Western"
)</code></pre>   <p>So far, this seems fine.  However, the <code language="plain">genre</code> constants are strings.  While this makes for a very "humanized" way of reading the code, it's not very efficient as it pertains to a computer program.  Strings will take up more storage space, and more memory in the program (not to mention if we stored millions of data records to a database).  As such, we really want to use a smaller data type to represent this data.</p> <p>In Go, one way we can do this is to create constants that are based on the <code language="plain">int</code> type.</p> <pre><code language="plain" snippet="genre" src="./src/v2/books.go">const (
	Adventure     = 1
	Comic         = 2
	Crime         = 3
	Fiction       = 4
	Fantasy       = 5
	Historical    = 6
	Horror        = 7
	Magic         = 8
	Mystery       = 9
	Philosophical = 10
	Political     = 11
	Romance       = 12
	Science       = 13
	Superhero     = 14
	Thriller      = 15
	Western       = 16
)</code></pre>   <p>We also need to change the <code language="plain">Book</code> structure to now represent <code language="plain">Genre</code> as an int:</p> <pre><code language="plain" snippet="book" src="./src/v2/books.go">type Book struct {
	ID    int
	Name  string
	Genre int
}</code></pre>   <p>While we now have a more effecient memory model for <code language="plain">Genre</code> , it's not as "human" friendly.  If I print out the value of a <code language="plain">Book</code> , we now just get an integer value.  To show this, we'll write a quick test showing the output:</p> <pre><code language="plain" snippet="test" src="./src/v2/books_test.go">package books

import (
	"testing"
)

func TestGenre(t *testing.T) {
	b := Book{
		ID:    1,
		Name:  "All About Go",
		Genre: Magic,
	}

	t.Logf("%+v\n", b)

	if got, exp := b.Genre, 8; got != exp {
		t.Errorf("unexpected genre.  got %d, exp %d", got, exp)
	}
}</code></pre>   <p>And here is the output.</p> <pre><code language="plain" snippet="output" src="./src/v2/books_test.go">$ go test -v ./...
=== RUN   TestGenre
    books_test.go:14: {ID:1 Name:All About Go Genre:8}
--- PASS: TestGenre (0.00s)
PASS
ok      github.com/gopherguides/corp/_blog/types/leveraging-types/src/v2     (cached)</code></pre>   <p>Notice that the <code language="plain">Genre</code> just shows a value of <code language="plain">8</code> .  Any time we debug the code, or write a report, etc, we now need to figure out what <code language="plain">8</code> actually represents for a human being.</p> <p>To do this, we can write a helper function that takes the <code language="plain">Genre</code> value, and determines what the "human" representation should be:</p> <pre><code language="plain" snippet="string" src="./src/v2/books.go">func GenreToString(i int) string {
	switch i {
	case 1:
		return "Adventure"
	case 2:
		return "Comic"
	case 3:
		return "Crime"
	case 4:
		return "Fiction"
	case 5:
		return "Fantasy"
	case 6:
		return "Historical"
	case 7:
		return "Horror"
	case 8:
		return "Magic"
	case 9:
		return "Mystery"
	case 10:
		return "Philosophical"
	case 11:
		return "Political"
	case 12:
		return "Romance"
	case 13:
		return "Science"
	case 14:
		return "Superhero"
	case 15:
		return "Thriller"
	case 16:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <h2>A Better Way</h2> <p>While all the above code works fine, it's really missing some key points.</p> <ul><li><p>If a value for a <code language="plain">Genre</code> has to change in the future, we not only have to change the constant value, but we also have to update the <code language="plain">GenreToString</code> function.  If we don't, this will create a bug in our code.</p></li> <li><p>We aren't leveraging the type system to encapsulate this behavior for <code language="plain">Genre</code> .  We'll show you what we mean by that shortly.</p></li></ul> <p>The first thing we really need to do is write a more resilient <code language="plain">GenreToString</code> function.  What we mean by resilient is that even if the value of the <code language="plain">Genre</code> constant changes in the future, the <code language="plain">GenreToString</code> function will not need to change.</p> <p>The correct way to do that is no longer use hard coded values, but use the value of the constant themselves:</p> <pre><code language="plain" snippet="string" src="./src/v3/books.go">func GenreToString(i int) string {
	switch i {
	case Adventure:
		return "Adventure"
	case Comic:
		return "Comic"
	case Crime:
		return "Crime"
	case Fiction:
		return "Fiction"
	case Fantasy:
		return "Fantasy"
	case Historical:
		return "Historical"
	case Horror:
		return "Horror"
	case Magic:
		return "Magic"
	case Mystery:
		return "Mystery"
	case Philosophical:
		return "Philosophical"
	case Political:
		return "Political"
	case Romance:
		return "Romance"
	case Science:
		return "Science"
	case Superhero:
		return "Superhero"
	case Thriller:
		return "Thriller"
	case Western:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <p>Ok, that's much cleaner (and readable), but we still haven't solved the fact that when we print it out, it shows a data value ( <code language="plain">int</code> ), and not a "human" readable value.</p> <h2>Types to the Rescue</h2> <p>Instead of using a generic <code language="plain">int</code> type for <code language="plain">Genre</code> , we can create our own type based on an existing type.  In this case, we'll create a new type called <code language="plain">Genre</code> based on the <code language="plain">int</code> type:</p> <pre><code language="plain" snippet="genre" src="./src/v4/books.go">type Genre int</code></pre>   <p>Now, we'll define our constants as <code language="plain">Genre</code> types:</p> <pre><code language="plain" snippet="constants" src="./src/v4/books.go">const (
	Adventure     Genre = 1
	Comic         Genre = 2
	Crime         Genre = 3
	Fiction       Genre = 4
	Fantasy       Genre = 5
	Historical    Genre = 6
	Horror        Genre = 7
	Magic         Genre = 8
	Mystery       Genre = 9
	Philosophical Genre = 10
	Political     Genre = 11
	Romance       Genre = 12
	Science       Genre = 13
	Superhero     Genre = 14
	Thriller      Genre = 15
	Western       Genre = 16
)</code></pre>   <p>So far, the code doesn't really feel different.  However, now that <code language="plain">Genre</code> is it's own type, we can add methods to it.  This allows us to encapsulate the "human" behavior we want to the type, and not as a generic function.</p> <p>To do this, we'll add a <code language="plain">String</code> method to the <code language="plain">Genre</code> type:</p> <pre><code language="plain" snippet="string" src="./src/v4/books.go">func (g Genre) String() string {
	switch g {
	case Adventure:
		return "Adventure"
	case Comic:
		return "Comic"
	case Crime:
		return "Crime"
	case Fiction:
		return "Fiction"
	case Fantasy:
		return "Fantasy"
	case Historical:
		return "Historical"
	case Horror:
		return "Horror"
	case Magic:
		return "Magic"
	case Mystery:
		return "Mystery"
	case Philosophical:
		return "Philosophical"
	case Political:
		return "Political"
	case Romance:
		return "Romance"
	case Science:
		return "Science"
	case Superhero:
		return "Superhero"
	case Thriller:
		return "Thriller"
	case Western:
		return "Western"
	default:
		return ""
	}
}</code></pre>   <p>Now, we'll be able to use the <code language="plain">String</code> method when we want to see what the "human" value of a <code language="plain">Genre</code> is:</p> <pre><code language="go">b := Book{
	ID:    1,
	Name:  "All About Go",
	Genre: Magic,
}
fmt.Println(b.Genre.String())</code></pre> <p>Output:</p> <pre><code language="sh">Magic</code></pre> <h2>Magic Formatting</h2> <p>In Go, if you add a <code language="plain">String</code> method to any type, the <code language="plain">fmt</code> package will now use your <code language="plain">String</code> method to "pretty print" the representation of your type.  Because of this, we will now see that if we print out the <code language="plain">book</code> in our tests, we get a "human-readable" <code language="plain">Genre</code> as well:</p> <pre><code language="plain" snippet="test" src="./src/v4/books_test.go">func TestGenre(t *testing.T) {
	b := Book{
		ID:    1,
		Name:  "All About Go",
		Genre: Magic,
	}

	t.Logf("%+v\n", b)

	if got, exp := b.Genre.String(), "Magic"; got != exp {
		t.Errorf("unexpected genre.  got %q, exp %q", got, exp)
	}
}</code></pre>   <p>Output:</p> <pre><code language="plain" snippet="output" src="./src/v4/books_test.go">$ go test -v -run=TestGenre -count=1 .
=== RUN   TestGenre
    books_test.go:16: {ID:1 Name:All About Go Genre:Magic}
--- PASS: TestGenre (0.00s)
PASS
ok      book    0.059s</code></pre>   <p>We now see the value for <code language="plain">Genre</code> in the printed output is <code language="plain">Magic</code> , and not <code language="plain">8</code> . It's also important to note that our test actually didn't change, only the way in which we leveraged our new type for <code language="plain">Genre</code> .</p> <h2>What about Iota?</h2> <p>For those of you that are familiar with Go already, you might have looked at this problem and asked "Why didn't you just use iota?". <a href="https://github.com/golang/go/wiki/Iota" target="_blank">Iota</a> is an identifier that you can use in Go to also create incrementing number constants.  While there are several reasons I didn't use iota here, I did dedicate an entire article to the topic.  Read all about it in <a href="https://www.gopherguides.com/articles/how-to-use-iota-in-golang" target="_blank">Where and When to use Iota in Go</a> .</p> <h2>Summary</h2> <p>While this example was purposefully basic in nature, it illustrates the power of defining your own type, and leveraging the type system in Go to create more resilient, readable, and reusable code.</p> <h3>Want More?</h3> <p>Check out our previous article, <a href="https://www.gopherguides.com/articles/embracing-the-go-type-system" target="_blank">Embracing the Go Type System</a> and learn how to use the type system to avoid common mistakes in Go.</p></section>
  </div>
  
</div></div>]]>
            </description>
            <link>https://www.gopherguides.com/articles/leveraging-the-go-type-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078865</guid>
            <pubDate>Tue, 09 Feb 2021 15:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple 11.2 GHz radio telescope (Hardware) (2020)]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26078761">thread link</a>) | @_Microft
<br/>
February 9, 2021 | https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/ | <a href="https://web.archive.org/web/*/https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
					
					<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg"><img data-attachment-id="14895" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/10ghzradiotelescope1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg" data-orig-size="1044,890" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10GHzRadiotelescope1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-300x256.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg" alt="" width="550" height="469" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-1024x873.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-300x256.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1-768x655.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope1.jpg 1044w" sizes="(max-width: 550px) 100vw, 550px"></a></p>
<p><em><strong>Abstract : </strong><span lang="en">In this post we describe the construction of a small amateur radio telescope operating at the frequency of 11.2 GHz. The construction of the radio telescope takes advantage of the satellite TV market which has made it easy and cheap to find parabolic reflector antennas with relative illuminator (feed horn) and LNB block (low noise amplifier-frequency converter). The performances of a similar instrument are naturally rather limited, however they still allow to make interesting observations of some of the most intense radio sources.</span></em></p>
<h3>Introduction</h3>
<p>Radio astronomy is a difficult and fascinating science. It requires the use of bulky and expensive antennas, uses sophisticated radio-electronic technologies and sophisticated algorithms for signal processing. At first glance it would seem completely beyond the reach of an “amateur”. In reality it is possible to make interesting radio astronomical observations even at an amateur level.<br>
On our site we have already described some radio astronomy projects for specific applications:</p>
<ul>
<li><a href="http://physicsopenlab.org/2020/05/03/loop-antenna-for-very-low-frequency/">Loop Antenna for Very Low Frequency</a></li>
<li><a href="http://physicsopenlab.org/2020/05/07/vlf-receiver-for-sid-monitoring/">VLF Receiver for SID Monitoring</a></li>
<li><a href="http://physicsopenlab.org/2020/07/20/horn-antenna-for-the-21cm-neutral-hydrogen-line/">Horn Antenna for the 21cm Neutral-Hydrogen Line</a></li>
<li><a href="http://physicsopenlab.org/2020/07/26/sdr-based-receiver-for-the-21-cm-neutral-hydrogen-line/">Low-Noise SDR-Based Receiver for the 21cm Neutral-Hydrogen Line</a></li>
<li><a href="http://physicsopenlab.org/2020/07/26/gnuradio-software-for-the-21-cm-neutral-hydrogen-line/">GNURadio Software for 21cm Neutral-Hydrogen Line</a></li>
</ul>
<p>Now we want to try to make an “amateur” radio telescope based on the principle of the <strong>radiometer</strong>. This is certainly not the place to give detailed information on radio astronomy and radio telescopes (there is a lot of information on the net and specific texts), so we limit ourselves to providing some hints on the main points that guided us in the construction of the radio telescope.</p>
<p>Radio astronomy studies celestial bodies by analyzing the radio waves emitted by objects in the sky: any object emits electromagnetic waves through various physical processes (thermal and non-thermal), these waves are picked up by the antenna and analyzed with appropriate instruments: in general the characteristics of the captured signal are no different from those that characterize a <strong>broad spectrum electrical noise</strong>. The purpose of the radio telescope is to pick up this radiation and measure the signal strength, such an instrument is called a radiometer. To be precise, we speak of power per unit area and per unit of bandwidth and is expressed in Jansky&nbsp;: <strong>1Jy = 10<sup>-26</sup> W/m<sup>2</sup> Hz</strong>.</p>
<p>The range of radio frequencies useful for radio astronomy observations is between <strong>20 MHz</strong> and about <strong>20 GHz</strong>: below 20 MHz there is absorption by the ionosphere, above 20 GHz there is absorption by of the gases present in the atmosphere.</p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">To choose the most suitable frequency band for an amateur radio telescope we must make a compromise between the observation possibilities and the cost and feasibility constraints. The frequency spectrum of the radio-source emissions depends on the underlying physical process: for “thermal” emissions such as the sun or the moon, the intensity follows the <strong>law of the black body</strong> with maximums at high frequencies (according to the approximation of Rayleigh-Jeans<strong> I ∝ 1/λ<sup>4</sup></strong>), while for non-thermal emissions (for example synchrotron emission) the maximums are at lower frequencies, as can be seen in the graph below which shows the intensity of some radio sources as a function of frequency.</span><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png"><img data-attachment-id="14927" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/radiosorgenti/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" data-orig-size="658,756" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="radiosorgenti" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti-261x300.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/radiosorgenti.png" alt="" width="450" height="515"></a></p>
<p>As we know the dimensions of the antenna are related to the wavelength of the radiation to be received, furthermore our antenna must be sufficiently directive, otherwise it would be practically useless: this means that to receive frequencies below 1 GHz the dimensions of the antenna should be significantly greater than 1m: large antennas are expensive and difficult to move.<br>
Another aspect to consider is external radio interference. The ether, especially in the city, is now saturated with transmissions and RF signals from the most heterogeneous origin: radio and TV broadcasting, cellular networks, WiFi networks, disturbances from power lines, etc …. Not having the possibility to install the radio telescope in “quiet” places we must choose a frequency band that is not too disturbed.</p>
<p>For the reasons described above, the choice is almost obligatory: the <strong>10-12 GHz frequency band</strong> is the one that seems most suitable for an amateur project like ours. At these frequencies, parabolic reflector antennas and devices designed for satellite television can be re-used. The costs of the equipment are affordable, the spatial resolution of the antenna is quite good and the interference is low (basically broadcasting satellites) and easily avoidable.<br>
Working at lower frequencies would make it possible to easily receive more radio sources but with a considerable increase in terms of costs, not to mention the problem of interference.</p>
<h3>Parabolic Dish Antenna</h3>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The antenna we found on the second-hand market is a <strong>prime focus dish</strong> with a diameter of 120 cm. For radio astronomy applications it is better that the dish is of the prime focus type: in these antennas the feed horn is placed in the focus of the dish. In offset-type dishes, the feed-horn is not placed in the center but on the side, this type has constructive advantages but is more difficult to aim to the source than the prime focus.</span></p>
<p dir="ltr" data-placeholder="Traduzione">For this antenna we can calculate the gain and the directivity intended as half power band width HPBW (half power band width) :</p>
<p><strong>G = η*(π*D/λ) = 40 dB</strong></p>
<p><strong>HPBW = 65*λ/D = 1.45°</strong></p>
<p>Where<br>
<strong>η : efficiency = 0.5</strong><br>
<strong>D : diameter = 120 cm</strong><br>
<strong>λ : wavelength = 2.68 cm (correspond to 11.2 GHz)</strong></p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The images below show the antenna and the metal structure used for manual movement.</span></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg"><img data-attachment-id="14907" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/parab1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg" data-orig-size="884,1346" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="parab1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-197x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg" alt="" width="500" height="761" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-673x1024.jpg 673w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-197x300.jpg 197w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1-768x1169.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab1.jpg 884w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg"><img data-attachment-id="14908" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/parab2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg" data-orig-size="844,1106" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="parab2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-229x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg" alt="" width="501" height="657" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-781x1024.jpg 781w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-229x300.jpg 229w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2-768x1006.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/parab2.jpg 844w" sizes="(max-width: 501px) 100vw, 501px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg"><img data-attachment-id="14909" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/10ghzradiotelescope2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg" data-orig-size="1062,1416" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="10GHzRadiotelescope2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-225x300.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg" alt="" width="500" height="667" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-768x1024.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2-225x300.jpg 225w, https://physicsopenlab.org/wp-content/uploads/2020/10/10GHzRadiotelescope2.jpg 1062w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<h3>LNB</h3>
<p dir="ltr" data-placeholder="Traduzione"><span lang="en">The first component of the system is the converter-amplifier block, the so-called <strong>LNB</strong>. This is the most important component because system performance largely depends on it. Our system receives in the 10-12 GHz band, at these frequencies the use of cables is problematic, for this reason the LNB block provides for a frequency down conversion in a lower band so that normal coaxial cables can be used.<br>
</span><span lang="en">The following image shows the basic scheme of the LNB block: there is a first <strong>RF amplification stage</strong>, followed by the mixer which multiplies the RF signal with the signal generated by a <strong>local oscillator (LO)</strong>. The resulting signal contains the sum and difference frequencies, the next filter eliminates the high frequency sum components to let pass only the frequencies in the band of interest, called <strong>intermediate frequencies (IF)</strong>, which are further amplified by another amplifier stage. In practice it is a heterodyne scheme, in which the frequency of the local oscillator is fixed.</span></p>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en"><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png"><img data-attachment-id="14947" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnbscheme/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" data-orig-size="377,213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LNBScheme" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme-300x169.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png" alt="" width="377" height="213" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme.png 377w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNBScheme-300x169.png 300w" sizes="(max-width: 377px) 100vw, 377px"></a></span></p>
<p>The LNB block we use is<strong> Invacom’s SNF-031</strong> model which has<strong> low noise</strong> and <strong>good stability</strong> of the gain parameters with respect to variations in operating temperature. The actual antenna is located inside the waveguide which has a C120 flange on the outside to which the feed horn is fixed, which has the task of collecting the waves reflected by the dish and conveying them to the inside the waveguide.</p>
<p>LNB features:</p>
<ul>
<li>Operating frequency band : 10.7 – 12.75 GHz</li>
<li>Intermediate frequencies (IF) : 950 – 2150 MHz, LO = 9.75 GHz</li>
<li><strong>Noise Figure NF = 0.3 dB</strong></li>
<li><strong>Gain G = 50 – 60 dB</strong></li>
</ul>
<p>The following images show the LNB block with its feed horn fixed to the focus of the dish.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg"><img data-attachment-id="14910" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb0/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" data-orig-size="466,397" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LNB0" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0-300x256.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg" alt="" width="399" height="340" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0.jpg 466w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB0-300x256.jpg 300w" sizes="(max-width: 399px) 100vw, 399px"></a></p>

<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg"><img data-attachment-id="15000" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb3/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg" data-orig-size="1128,850" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LNB3" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-300x226.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg" alt="" width="550" height="415" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-1024x772.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-300x226.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3-768x579.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB3.jpg 1128w" sizes="(max-width: 550px) 100vw, 550px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg"><img data-attachment-id="15001" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/lnb4/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg" data-orig-size="1184,902" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LNB4" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-300x229.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg" alt="" width="551" height="419" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-1024x780.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-300x229.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4-768x585.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/LNB4.jpg 1184w" sizes="(max-width: 551px) 100vw, 551px"></a></p>
<h3>The Receiver</h3>
<p id="tw-target-text" dir="ltr" data-placeholder="Traduzione"><span lang="en">The receiver consists of the few components, shown in the following image: there is a bias-T for feeding the LNB block, a bandpass filter centered at 1420 MHZ, a wide-band amplifier and the <strong>Airspy R2 SDR receiver</strong>. The “hardware” part has the function of limiting the receiving band and giving the signal a second amplification after the LNB stage. The signal is then acquired by Airspy and subsequently processed for the determination of the total power using <strong>GNURadio</strong> software. The <strong>radiometer</strong> function is practically realized through software.</span></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png"><img data-attachment-id="14917" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/radiometer/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png" data-orig-size="1088,668" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="radiometer" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-300x184.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png" alt="" width="600" height="369" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-1024x629.png 1024w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-300x184.png 300w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer-768x472.png 768w, https://physicsopenlab.org/wp-content/uploads/2020/10/radiometer.png 1088w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><strong>Features of our receiver :</strong><br>
Frequency Band = 80 MHz<br>
G<sub>LNB</sub> = 55 dB ; NF<sub>LNB</sub> = 0.3 dB<br>
G<sub>Filter</sub> = 3.5 dB (insertion loss)<br>
G<sub>Ampli</sub> = 15 dB ; NF<sub>Ampli</sub> = 0.75 dB<br>
<strong>Gain : G<sub>LNB</sub> – G<sub>Filter</sub> + G<sub>Ampli</sub> = 55 -3.5 +15 = 66.5 dB</strong><br>
<strong>Noise Figure : F = F<sub>LNB</sub> + (F<sub>Ampli</sub> – 1)/G<sub>LNB</sub> = 0.3 dB<br>
T<sub>e</sub> = (F – 1) * T<sub>0</sub> = 20.3 °K (Receiver equivalent temperature)</strong></p>
<h4>Bias-T</h4>
<p>The Bias-T has the function of “injecting” the supply voltage to the LNB block along the coaxial cable. In practice it is a simple circuit with a coupling capacitor to filter the DC component towards the RF side and an inductance at the DC input. Obtained on eBay, it can be easily self-built but attention must be paid to the “RF” quality of the components and the shielding.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg"><img data-attachment-id="14914" data-permalink="https://physicsopenlab.org/2020/10/10/un-semplice-radiotelescopio-a-11-2-ghz/bias-t/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" data-orig-size="709,661" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Bias-T" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T-300x280.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg" alt="" width="251" height="234" srcset="https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T.jpg 709w, https://physicsopenlab.org/wp-content/uploads/2020/10/Bias-T-300x280.jpg 300w" sizes="(max-width: 251px) 100vw, 251px"></a></p>
<h4>1420 MHz Band Pass Filter</h4>
<p>This filter is dedicated to amateur radioastronomers interested in the hydrogen line observations. It uses the TA2494A SAW component and measures only 50 x 10mm. It features edge pads for an easy soldering of a RF shield. Insertion loss is typically less than 3.5dB and bandwith 80MHz.</p>
<p><strong>Technical Data</strong> :<br>
Center Frequency <strong>1420MHz</strong><br>
Usable Bandpass <strong>1380-1460MHz</strong><br>
Insertion Loss, 1380 to 1460 MHz <strong>3.5dB</strong><br>
Amplitude Ripple, 1380 to 1460 MHz 1.0 dBpp<br>
VSWR, 1380 &nbsp;to 1420 MHz 1.9:1<br>
Rejection referenced to 0dB :<br>
DC to 1300 MHz 28dB<br>
1550 to 3000 MHz 30dB<br>
Impedance 50Ω<br>
Maximum Input Power Level 10 dBm</p>
<p>In the images below we show the unit and its frequency response. We have soldered two wires between the SMA female headers and we wrapped the filter with aluminum tape in order to shield the filter.</p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg"><img data-attachment-id="14378" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg" data-orig-size="1134,460" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="filter21cm" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-300x122.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg" alt="" width="601" height="243" srcset="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-1024x415.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-300x122.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm-768x312.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm.jpg 1134w" sizes="(max-width: 601px) 100vw, 601px"></a></p>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg"><img data-attachment-id="14432" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm1/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg" data-orig-size="1054,388" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="filter21cm1" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-300x110.jpg" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg" alt="" width="599" height="220" srcset="https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1024x377.jpg 1024w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-300x110.jpg 300w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-768x283.jpg 768w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1-1050x388.jpg 1050w, https://physicsopenlab.org/wp-content/uploads/2020/09/filter21cm1.jpg 1054w" sizes="(max-width: 599px) 100vw, 599px"></a></p>
<table>
<tbody>
<tr>
<td><b><i>Frequency (MHz)</i></b></td>
<td><b><i>Gain (dB)</i></b></td>
</tr>
<tr>
<td>1300</td>
<td><strong>-50</strong></td>
</tr>
<tr>
<td>1420</td>
<td><strong>-3.5</strong></td>
</tr>
<tr>
<td>1500</td>
<td><strong>-50</strong></td>
</tr>
</tbody>
</table>
<p><a href="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png"><img data-attachment-id="14379" data-permalink="https://physicsopenlab.org/2020/07/26/14302/filter21cm2/" data-orig-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" data-orig-size="873,620" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="filter21cm2" data-image-description="" data-medium-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-300x213.png" data-large-file="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" loading="lazy" src="http://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png" alt="" width="600" height="426" srcset="https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2.png 873w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-300x213.png 300w, https://physicsopenlab.org/wp-content/uploads/2020/08/filter21cm2-768x545.png 768w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<h4>Wideband Amplifier</h4>
<p>This unit HAB-FLTNOSAW built by UPUTRONICS is a preamp designed to go between a software defined radio receiver and an antenna. The LNA used inside is a MiniCircuits PSA4-5043. This particular model has the SAW filter removed to cover the 0.1MHz to 4GHz. There are 2 options for powering the unit : either by the USB header or via bias-tee. Devices such as the Airspy can enable bias-tee and power the device. Alternatively any mini USB cable can be used to power the device. We chose to power the unit via USB line.</p>
<p><strong>Technical Data</strong> :<br>
Gain 24db @ 100MHz -&gt; <strong>15.2db @ 1415MHz</strong><br>
<strong>NF 0.75dB</strong><br>
Supply Voltage USB or Bias tee 5V</p>
<p>In the images below we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/">https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/</a></em></p>]]>
            </description>
            <link>https://physicsopenlab.org/2020/10/10/a-simple-11-2-ghz-radiotelescope/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26078761</guid>
            <pubDate>Tue, 09 Feb 2021 15:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 2 (2020)]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 143 (<a href="https://news.ycombinator.com/item?id=26077823">thread link</a>) | @anuragsoni
<br/>
February 9, 2021 | https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <section>
        <div>
          <div>
            <div>
              <p>
                <a href="https://www.beginrust.com/">New: The "Begin Rust" book</a>
              </p>

              




  






      <p>
        <i>
          See a typo? Have a suggestion?
          <a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/blog/haskell-bad-parts-2.md">Edit this page on Github</a>
        </i>
      </p>

      



      <p>If you didn't see it, please check out <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">part 1 of this series</a> to understand the purpose of this. Now, for more bad parts!</p>
<h2 id="partial-functions-in-general">Partial functions (in general)</h2>
<p>Laziness very likely belongs in this list. My favorite part of criticizing laziness is how quickly people jump to defend it based on edge cases. So let's be a bit more nuanced before I later get far <em>less</em> nuanced. Laziness is <strong>obviously</strong> a good thing. Strictness is <strong>obviously</strong> a good thing. They also both suck. It depends on context and purpose. Each of them introduce different kinds of issues. The real question is: what's a more sensible default? We'll get to that another time.</p>
<p>I called this section partial functions. Am I having a senior moment? Maybe, but I intentionally started with laziness. In a strict language, function calls can result in exceptions being thrown, segfaulting occurring, or panicking. (And if I write a "Rust: The Bad Parts", believe me, I'll be mentioning panicking.) The fact that a function <em>acts</em> like it can successfully perform something, but in fact fails in a predictable way (like failing a <code>HashMap</code> lookup), it should be reflected at the type level. If not, ya dun goofed.</p>
<p>Also, if you have a language that doesn't let you reflect this information at the type level: ya dun goofed.</p>
<p>Partial functions are the antithesis of this concept. They allow you to say "yeah dude, I can <em>totally</em> give you the first value in an empty list." Partial functions are like politicians: you can tell they're lying because their lips are moving. ("But Michael," you say. "Functions don't have lips!" Whatever, I'm waxing poetical.)</p>
<p>Alright, so plenty of languages screw this up. Haskell tells those languages "hold my beer."</p>
<p><img src="https://www.snoyman.com/static/images/holdmybeer.jpg"></p><p>Haskell screws up partial functions way, way worse than other languages:</p>
<ol>
<li>It promotes a whole bunch of them in the standard libraries and <code>Prelude</code>.</li>
<li>Some libraries, like <code>vector</code> (I'm getting to you, don't worry) make it <em>really</em> confusing by providing an <code>index</code> and <code>unsafeIndex</code> function. Hint: <code>index</code> isn't really safe, it's just less unsafe.</li>
<li>There's no obvious way to search for usages of these partial functions.</li>
<li>And, by far, the worst...</li>
</ol>
<h3 id="values-are-partial-too">Values are partial too!</h3>
<p>Only in a lazy language does this exist. You call a function. You get a result. You continue working. In any other non-lazy language, that means you have a value. If I have a <code>u32</code> in Rust, I actually have a <code>u32</code> in Rust. Null pointers in languages like C and Java somewhat muddy this situation, but at least primitive types are really there if they say they're there.</p>
<p>No, not Haskell. <code>x :: Int</code> may in fact not exist. It's a lie. <code>let x = head [] :: [Int]</code> is a box waiting to explode. And you find out <em>much</em> later. And it's even worse than that. <code>let alice = Person { name = "Alice", age = someAge }</code> may give you a valid <code>Person</code> value. You can evaluate it. But Cthulhu help you if you evaluate <code>age alice</code>. Maybe, just maybe, <code>someAge</code> is a bottom value. Boom! You've smuggled a dirty bomb out.</p>
<p>I'm not advocating for removing laziness in Haskell. In fact I'm not really advocating for much of anything in this series. I'm just complaining, because I like complaining.</p>
<p>But <em>if</em> I was to advocate some changes:</p>
<ul>
<li>Deprecate partial functions</li>
<li>Introduce a naming scheme for partial functions to be more obvious</li>
<li>Introduce a compiler warning to note partial function use (with a pragma to turn off specific usages)</li>
<li>Warn by default on partial pattern matches</li>
<li>Advocate strict data fields by default</li>
</ul>
<h3 id="but-ackshualllly-infinite-loops">But ackshualllly, infinite loops</h3>
<p>Someone's gonna say it. So I'll say it. Yes, without major language changes, you can't prevent partial functions. You can't even detect them, unless Turing was wrong (and I have my suspicions.) But Haskell community, please, please learn this lesson:</p>
<p><strong>DON'T LET THE PERFECT BE THE ENEMY OF THE GOOD</strong></p>
<p>We can get rid of many of the most common partial functions trivially. We can detect many common cases by looking for partial pattern matches and usage of <code>throw</code> (again, horribly named function). "But we can't get everything" doesn't mean "don't try to get something."</p>
<h2 id="hubris">Hubris</h2>
<p>Given what I just said, we Haskellers have a lot of hubris. Each time you say "if it compiles it works," a thunk dies and collapses into a blackhole. We've got plenty of messes in Haskell that don't sufficiently protect us from ourselves. The compiler can only do as good a job as our coding standards and our libraries allow.</p>
<p>"But Haskell's at least better than languages like PHP." I mean, obviously I agree with this, or I'd be writing PHP. But since I'm being ridiculously hyperbolic here, let me make a ridiculous claim:</p>
<blockquote>
<p><strong>PHP is better than Haskell, since at least you don't get a false sense of security</strong></p>
<p><em>- Michael Snoyman, totally 100% what he actually believes, you should totally quote this out of context</em></p>
</blockquote>
<p>I've said this so many times. So I'll say it again. Using a great language with safety features is one tiny piece of the puzzle.</p>
<ul>
<li>Did you get the software requirements right?</li>
<li>Did you leverage the type system to prevent the bugs you're trying to prevent?</li>
<li>Do your underlying libraries have bugs?</li>
<li>Did you find a way to implement a function with correct types but incorrect semantics?</li>
<li>Did you host the thing on a dinky server sitting under your desk and forget that you have power outages on a daily basis?</li>
<li>Did you forget to write a single test case?</li>
<li>Do your test cases actually test anything meaningful?</li>
</ul>
<p>There are <em>so many ways</em> for software to fail outside the purview of the type system. We've got to stop thinking that somehow Haskell (or, for that matter, Rust, Scala, and other strongly typed languages) are some kind of panacea. Seriously: the PHP people at least know their languages won't protect them from anything. We should bring some of that humility back to Haskell.</p>
<p>Haskell provides me tools to help prevent certain classes of bugs, so I can spend more of my time catching a bunch of other bugs that I'm absolutely going to write. Because I'm dumb. And we need to remember: we're all dumb.</p>
<h2 id="more-partial-functions">More partial functions!</h2>
<p>You know what's worse than partial functions? Insidiously partial functions. We've all been screaming about <code>head</code> and <code>tail</code> for years. My hackles rise every time I see a <code>read</code> instead of <code>readMaybe</code>. I can't remember the last time I saw the <code>!!</code> operator in production code.</p>
<p>But there are plenty of other functions that are just as dangerous, if not more so. More dangerous because they aren't well known to be partial. They are commonly used. People don't understand why they're dangerous. And they fail only in edge cases that people aren't thinking about.</p>
<p>Exhibit A: I present <code>decodeUtf8</code>. (Thanks <a href="https://twitter.com/kerckhove_ts/status/1321390954172063745?s=20">Syd</a>.)</p>
<p>Go ahead, search your codebase. Be dismayed that you've found it present.</p>
<p>What's wrong with <code>decodeUtf8</code>? As we established last time, character encoding crap breaks stuff in production. UTF-8 works about 99% of the time, especially for people in Western countries. You'll probably forget to even test for it. And that function looks so benign: <code>decodeUtf8 :: ByteString -&gt; Text</code>.</p>
<p><strong>DO NOT BE FOOLED</strong></p>
<p>This function is a ticking time bomb. Use <code>decodeUtf8'</code> (yes, it's named that badly, just like <code>foldl'</code>) and explicitly handle error cases. Or use I/O functions that explicitly handle UTF-8 decoding errors and throw a runtime exception.</p>
<p>"I can't believe Michael still thinks runtime exceptions are a good idea." I'll get to that another time. I don't really believe they're a good idea. I believe they are omnipresent, better than bottom values, and our least-bad-option.</p>
<h2 id="law-abiding-type-classes">Law-abiding type classes</h2>
<p>Now I've truly lost it. What in tarnation could be wrong with law-abiding type classes? They're good, right? Yes, they are! The section heading is complete clickbait. Haha, fooled you!</p>
<p>There's a concept in the Haskell community that all type classes should be law-abiding. I've gone to the really bad extreme opposing this in the past with early versions of <code>classy-prelude</code>. In my defense: it was an experiment. But it was a bad idea. I've mostly come around to the idea of type classes being lawful. (Also, the original namespacing issues that led to <code>classy-prelude</code> really point out a much bigger bad part of Haskell, which I'll get to later. Stay tuned! Hint: Rust beat us again.)</p>
<p>Oh, right. Speaking of Rust: they do <em>not</em> believe in law-abiding type classes. There are plenty of type classes over there (though they call them <code>trait</code>s) that are completely ad-hoc. I'm looking at you, <code>FromIterator</code>. This is Very, Very Bad of course. Or so my Haskell instincts tell me. And yet, it makes code Really, Really Good. So now I'm just confused.</p>
<p>Basically: I think we need much more nuanced on this in the Haskell community. I'm leaning towards my <em>very</em> original instincts having been spot on. So:</p>
<ul>
<li>Law abiding type classes: great</li>
<li>Flippantly non-law-abiding type classes ala the original <code>classy-prelude</code>: bad</li>
<li>"You know what I meant" typeclasses like <code>ToContent</code> in Yesod: also great</li>
</ul>
<p>This isn't exactly in line with a "bad part" of Haskell. Up until now I've been giving a nuanced reflection on my journeys in Haskell. Let me try something better then. Ahem.</p>
<p><strong>DON'T LECTURE ME ON LAW ABIDING TYPE CLASSES AND FLAGRANTLY VIOLATE LAWS</strong></p>
<p>I'm staring at you, <code>Eq Double</code>. No, you cannot do equality on a <code>Double</code>. (And thanks again to Syd for this idea.) Rust, again, Got It Right. See <code>PartialEq</code> vs <code>Eq</code>. Floating point values do not allow for total equality. This makes things like <code>Map Double x</code> dangerous. Like, super dangerous. Though maybe not as dangerous as <code>HashMap Double x</code>, which deserves its own rant later.</p>
<p>So come down from your high horses. We don't have law abiding type classes. We have "if I close my eyes and pretend enough then maybe I have law abiding type classes."</p>
<h2 id="unused-import-warnings">Unused import warnings</h2>
<p>Haskell has a dumb set of default warnings enabled. ("I think you mean GHC, one implementation of Haskell, not …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26077823</guid>
            <pubDate>Tue, 09 Feb 2021 14:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pseudophilosophy encourages confused, self-indulgent thinking]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 214 (<a href="https://news.ycombinator.com/item?id=26076731">thread link</a>) | @pseudolus
<br/>
February 9, 2021 | https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>There are many kinds</strong> of pseudosciences: astrology, homeopathy, flat-Earthism, anti-vaxx. These â€˜fieldsâ€™ traffic in bizarre claims with scientific pretensions. On a surface level, these claims <em>seem</em> to be scientific and usually appear to comment on the same kind of things that science does. However, upon closer inspection, pseudoscience is revealed to be <a href="https://aeon.co/ideas/why-bullshit-is-no-laughing-matter" rel="noopener">bullshit</a>: it is indifferent to the truth. Analogous to pseudoscience, can there be such a thing as pseudophilosophy, in which one makes claims with philosophical pretensions which on closer inspection turn out to be bullshit? I think there is.</p>
<p>Letâ€™s begin with the concept of pseudophilosophy. If there is something deserving of that name, then it would be deficient with respect to philosophical issues in the same way that pseudoscience is deficient with respect to scientific issues. So, in order to get a grip on pseudophilosophy, we should first <a href="https://doi.org/10.1111/theo.12271" rel="nofollow noreferrer noopener">look</a> more closely at the way in which pseudoscience is deficient, and then see whether we can find something analogous in the philosophical domain.</p>
<p>What makes pseudoscientific beliefs deficient is that theyâ€™re formed in an <em>epistemically unconscientious</em> way. Thatâ€™s to say, these beliefs are made from culpably confused and uninformed reasoning. For example, the belief that the Earth is flat can be sustained only by self-willed disregard of the massive amounts of evidence to the contrary, accumulated over several centuries by several different sciences.</p>
<p>However, such unconscientiousness doesnâ€™t presuppose insincerity or charlatanry. A charlatan is someone who has a hidden, usually profit-seeking, agenda and who is fundamentally indifferent to whether their beliefs are true. Often bullshit is produced without such insincerity, however, since one can <em>care</em> about the truth of oneâ€™s beliefs without <em>taking care</em> with respect to it.</p>
<p>A problem is that most of us are lacking in epistemic conscientiousness, at least sometimes and to some extent. In order for something to count as pseudoscience, some minimal degree of unconscientiousness is therefore required. A good rule of thumb for being conscientious is to keep an eye out for classical fallacies such as <a href="https://aeon.co/ideas/how-ad-hominem-arguments-can-demolish-appeals-to-authority" rel="noopener">ad hominem</a>, straw man, false dilemma and cherry-picking. Such fallacies occur in all kinds of contexts, but in pseudoscience they occur more systematically.</p>
<p>Whether there is a God or whether there are objective moral truths have to be answered largely via a priori reflection, if at all</p>
<p>Epistemic unconscientiousness is an essential but not exhaustive component of pseudoscience. To count as pseudoscientific, a belief must also be about some scientific issue, and this is precisely where pseudoscience and pseudophilosophy differ. Just like pseudoscience, pseudophilosophy is defined by a lack of epistemic conscientiousness, but its subject matter is philosophical rather than scientific.</p>
<p>Roughly speaking, the difference between scientific and philosophical issues is that the latter arenâ€™t in any straightforward way resolvable via empirical investigation. Whether there is a God, for example, or whether there are objective moral truths, are questions that have to be answered largely via a priori reflection, if at all. These questions are thus different from questions such as whether the Earth is flat or spherical, or whether anthrax is caused by bacteria, which do have empirically accessible answers.</p>
<p><strong>There are two kinds of</strong> pseudophilosophy, one mostly harmless and the other insidious. The first variety is usually found in popular scientific contexts. This is where writers, typically with a background in the natural sciences, walk self-confidently into philosophical territory without realising it, and without conscientious attention to relevant philosophical distinctions and arguments. Often implicit empiricist assumptions in epistemology, metaphysics and the philosophy of language are relied upon as if they were self-evident, and without awareness of the threat that those very assumptions pose to the authorâ€™s own reasoning. We can call this phenomenon scientistic pseudophilosophy.</p>
<p>An illustrative example is Sam Harrisâ€™s <a href="https://samharris.org/books/the-moral-landscape/" rel="nofollow noreferrer noopener">book</a> <em>The Moral Landscape</em> (2010), in which straw men are lined up due to Harrisâ€™s failure to grasp the content of many of the philosophical claims and arguments that he criticises, such as Humeâ€™s law (or the is/ought problem) and <span>G E Mooreâ€™s</span> open-question argument (ie, that no moral property is identical to a natural property). Similarly, in <em>A Universe from Nothing</em> (2012), Lawrence Krauss engages with philosophical arguments for theism without understanding them properly. Most saliently, he ends up criticising a caricature version of the so-called cosmological argument about the existence of God.</p>
<p>Usually, the prose is infused with arcane terminology and learned jargon, creating an aura of scholarly profundity</p>
<p>The insidious kind of pseudophilosophy, which I will focus on here, is an academic enterprise, pursued primarily within the humanities and social sciences. I donâ€™t mean to suggest that the disciplines in question are <em>inherently</em> pseudophilosophical, only that, for some reason, a whole lot of pseudophilosophy goes on within them (although this will vary greatly between different universities and departments). Often philosophical issues are raised concerning knowledge, truth, objectivity, rationality and scientific methodology, and, again, without conscientious attention to relevant philosophical distinctions and arguments. A characteristic trait is a deferential attitude toward some supposedly great continental European thinker or thinkers, such as <span>G W F Hegel,</span> Karl Marx, Sigmund Freud, Carl Jung, Martin Heidegger or Jean-Paul Sartre (who might or might not have themselves been guilty of pseudophilosophy). Usually, the prose is infused with arcane terminology and learned jargon, creating an aura of scholarly profundity. We can <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/theo.12047" rel="nofollow noreferrer noopener">call</a> this phenomenon obscurantist pseudophilosophy.</p>
<p>While pseudoscience is particularly prone to causal fallacies and cherry-picking of data, the most common fallacy in obscurantist pseudophilosophy is equivocation. This fallacy <a href="https://journals.sagepub.com/doi/abs/10.1177/0392192112444984" rel="nofollow noreferrer noopener">exploits</a> ambiguities in certain key terms, where plausible but trivial claims lend apparent credibility to interesting but controversial ones. When challenged, the obscurantist will typically retreat to the safe house provided by the trivial interpretation of his claims, only to reoccupy the controversial ground once the critic has left the scene.</p>
<p>Let me <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9973.2005.00370.x" rel="nofollow noreferrer noopener">illustrate</a> how this works, focusing on <a href="https://aeon.co/essays/why-foucaults-work-on-power-is-more-important-than-ever" rel="noopener">Michel Foucault</a>, one of the central figures of French postmodernism. A central theme in Foucaultâ€™s writings is a critique of the notion of objective truth. Although there are controversies about interpretation, at least on the face of it Foucault maintains that truth is socially constructed and subject to ideological influence, and therefore not objective. However, his arguments for this claim focus entirely on the way in which what is assumed or believed to be true is influenced by what he refers to as â€˜powerâ€™. It is, of course, a plausible claim that our assumptions or beliefs are susceptible to ideological influence, especially in emotionally charged areas such as politics, but also in supposedly rational areas such as science. But Foucault doesnâ€™t explain how this rather mundane observation is supposed to imply or support the philosophically controversial claim that what is true, or which facts obtain (concerning the shape of the Earth, for example), is susceptible to ideological influence. Instead, by using the word â€˜truthâ€™ in an impressionistic fashion, the distinction between belief and truth is smudged over, allowing Foucault to make seemingly profound statements such as:</p>
<blockquote>[T]ruth isnâ€™t outside power, or lacking in power: contrary to a myth whose history and functions would repay further study, truth isnâ€™t the reward of free spirits, the child of protracted solitude, nor the privilege of those who have succeeded in liberating themselves. Truth is a thing of this world: it is produced only by virtue of multiple forms of constraint.</blockquote>
<p>I leave it as an exercise to the reader to disambiguate this statement and see what remains.</p>
<p>This kind of fallacious critique of the notion of objective truth is a particularly pernicious aspect of obscurantist pseudophilosophy in general. Often, itâ€™s due to simple misunderstandings (such as confusing truth with belief or knowledge), but sometimes itâ€™s due rather to wilful obscurity (as in the case of Foucault).</p>
<p>Perhaps due to its aura of academic legitimacy and profundity, obscurantist pseudophilosophy is often used to give credence to dogmatic and bellicose political agendas, both on the Left and on the Right. Beyond that, it encourages confused and self-indulgent thinking in university students, and consumes vast resources that could be put to better use.</p>
<p>While pseudoscience can perhaps be counteracted by science education, the cure for pseudophilosophy is not science education but philosophical education. More specifically, it is a matter of developing the kind of basic critical thinking skills that are taught to undergraduates in philosophy. This doesnâ€™t need to be anything fancy. Students should be taught things like learning to distinguish in a disciplined way between central philosophical concepts such as belief, truth, rationality and knowledge. They should be aware of the way ambiguities can be exploited by equivocating arguments, and become adept at how to spot other fallacies such as ad hominem and straw man. With these fundamental tools in hand, there would be a good deal less pseudophilosophy going around.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/pseudophilosophy-encourages-confused-self-indulgent-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076731</guid>
            <pubDate>Tue, 09 Feb 2021 12:34:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: "100 Page Python Intro" eBook]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26076721">thread link</a>) | @asicsp
<br/>
February 9, 2021 | https://learnbyexample.github.io/100_page_python_intro/introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/100_page_python_intro/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav id="sidebar" aria-label="Table of contents"></nav><div id="page-wrapper"><div class="page"><div id="content"><main><p><a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Wikipedia</a> does a great job of describing about Python in a few words. So, I'll just copy-paste relevant information here:</p><blockquote><p>Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.</p><p>Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming. Python is often described as a "batteries included" language due to its comprehensive standard library.</p><p>As of December 2020 Python ranked third in TIOBE’s index of most popular programming languages, behind <code>C</code> and <code>Java</code>.</p></blockquote><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> See also <a href="https://docs.python.org/3/faq/general.html">docs.python: General Python FAQ</a> for answers to questions like "What is Python?", "What is Python good for?", "Why is it called Python?", etc.</p></blockquote><h2><a href="#installation" id="installation">Installation</a></h2><p>On modern Linux distributions, you are likely to find Python already installed. It may be a few versions behind, but should work just fine for most of the topics covered in this book. To get the exact version used here, visit <a href="https://www.python.org/downloads/">Python downloads page</a> and install using the appropriate source for your operating system. Should you face any issues in installing, search online for a solution. Yes, that is something I expect you should be able to do as a prerequisite for this book, i.e. you should have prior experience with basic programming and computer usage.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> See <a href="https://docs.python.org/3/whatsnew/index.html">docs.python: What's New</a> to track changes across versions. As mentioned in the Preface chapter, <strong>3.9.0</strong> is the version used in this book.</p></blockquote><h2><a href="#online-tools" id="online-tools">Online tools</a></h2><p>In case you are facing installation issues, or do not want to (or cannot) install Python on your computer for some reason, there are plenty of options to execute Python programs using online tools. Some of the popular ones are listed below:</p><ul><li><a href="https://repl.it/languages/python3">Repl.it</a> — Interactive playground. Code, collaborate, compile, run, share, and deploy Python and more online from your browser</li><li><a href="http://www.pythontutor.com/visualize.html#mode=edit">Pythontutor</a> — Visualize code execution, also has example codes and ability to share sessions</li><li><a href="https://www.pythonanywhere.com/">PythonAnywhere</a> — Host, run, and code Python in the cloud</li></ul><p>The <a href="https://www.python.org/">offical Python website</a> also has a <em>Launch Interactive Shell</em> option (<a href="https://www.python.org/shell/">https://www.python.org/shell/</a>), which gives access to a REPL session.</p><h2><a href="#first-program" id="first-program">First program</a></h2><p>It is customary to start learning a new programming language by printing a simple phrase. Create a new directory, say <code>Python/programs</code> for this book. Then, create a plain text file named <code>hello.py</code> with your favorite text editor and type the following piece of code.</p><pre><code># hello.py
print('*************')
print('Hello there!')
print('*************')
</code></pre><p>If you are familiar with using command line on a Unix-like system, run the script as shown below. Other options to execute a Python program will be discussed in the next section.</p><pre><code>$ python3.9 hello.py
*************
Hello there!
*************
</code></pre><p>A few things to note here. The first line is a comment, used here to indicate the name of the Python program. <code>print()</code> is a built-in function, which can be used without having to load some library. A single string argument has been used for each of the three invocations. <code>print()</code> automatically appends a newline character by default. The program ran without a compilation step. As quoted earlier, Python is an <em>interpreted</em> language. More details will be discussed in later chapters.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> All the Python programs discussed in this book, along with related text files, can be accessed from my GitHub repo <a href="https://github.com/learnbyexample/100_page_python_intro/tree/main/programs">learnbyexample: 100_page_python_intro</a>. However, I highly recommend typing the programs manually by yourself.</p></blockquote><h2><a href="#ide-and-text-editors" id="ide-and-text-editors">IDE and text editors</a></h2><p>An <strong>integrated development environment</strong> (IDE) might suit you better if you are not comfortable with the command line. IDE provides features likes debugging, syntax highlighting, autocompletion, code refactoring and so on. They also help in setting up <strong>virtual environment</strong> to manage different versions of Python and modules (more on that later).</p><p>If you install Python on Windows, it will automatically include <strong>IDLE</strong>, an IDE built using Python's <code>tkinter</code> module. On Linux, see if you already have the program <code>idle3.9</code>. Otherwise you may have to install it separately, for example, <code>sudo apt install idle-python3.9</code> on Ubuntu.</p><p>When you open IDLE, you'll get a Python shell (discussed in the next section). For now, click the <strong>New File</strong> option under <strong>File</strong> menu to open a text editor. Type the short program <code>hello.py</code> discussed in the previous section. After saving the code, press <strong>F5</strong> to run it. You'll see the results in the shell window.</p><p>Screenshots from the text editor and the Python shell are shown below.</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/hello.png" alt="hello.py program on IDLE editor"></p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/Python_shell_run.png" alt="Python shell example with output from an executed program"></p><p>Popular alternatives to IDLE are listed below:</p><ul><li><a href="https://thonny.org/">Thonny</a> — Python IDE for beginners, lots of handy features like viewing variables, debugger, step through, highlight syntax errors, name completion, etc</li><li><a href="https://www.jetbrains.com/pycharm/">Pycharm</a> — smart code completion, code inspections, on-the-fly error highlighting and quick-fixes, automated code refactorings, rich navigation capabilities, support for frameworks, etc</li><li><a href="https://www.spyder-ide.org/">Spyder</a> — typically used for scientific computing</li><li><a href="https://jupyter.org/">Jupyter</a> — web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text</li><li><a href="https://vscodium.com/">VSCodium</a> — community-driven, freely-licensed binary distribution of VSCode</li><li><a href="https://github.com/vim/vim">Vim</a>, <a href="https://www.gnu.org/software/emacs/">Emacs</a>, <a href="https://www.geany.org/">Geany</a>, <a href="https://wiki.gnome.org/Apps/Gedit">Gedit</a> — text editors with support for syntax highlighting and more</li></ul><h2><a href="#repl" id="repl">REPL</a></h2><p>One of the best features of Python is the interactive shell. Such shells are also referred to as REPL, which is an abbreviation for <strong>R</strong>ead <strong>E</strong>valuate <strong>P</strong>rint <strong>L</strong>oop. The Python REPL makes it easy for beginners to try out code snippets for learning purposes. Beyond learning, it is also useful for developing a program in small steps, debugging a large program by trying out few lines of code at a time and so on. REPL will be used frequently in this book to show code snippets.</p><p>When you launch Python from the command line, or open IDLE, you get a shell that is ready for user input after the <code>&gt;&gt;&gt;</code> prompt.</p><pre><code>$ python3.9
Python 3.9.0 (default, Dec  2 2020, 10:42:13) 
[GCC 5.4.0 20160609] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 
</code></pre><p>Try the below instructions. The first one displays a greeting using the <code>print()</code> function. Then, a user defined variable is used to store a string value. To display the value, you can either use <code>print()</code> again or just type the variable name. Expression results are immediately displayed in the shell. Name of a variable by itself is a valid expression. This behavior is unique to the REPL and an expression by itself won't display anything when used inside a script.</p><pre><code>&gt;&gt;&gt; print('have a nice day')
have a nice day

&gt;&gt;&gt; username = 'learnbyexample'
&gt;&gt;&gt; print(username)
learnbyexample

# use # to start a single line comment
# note that string representation is shown instead of actual value
# details will be discussed later
&gt;&gt;&gt; username
'learnbyexample'

# use exit() to close the shell, can also use Ctrl+D shortcut
&gt;&gt;&gt; exit()
</code></pre><p>I'll stress again the importance of following along the code snippets by manually typing them on your computer. Programming requires hands-on experience too, reading alone isn't enough. As an analogy, can you learn to drive a car by just reading about it? Since one of the prerequisite is that you should already be familiar with programming basics, I'll extend the analogy to learning to drive a different car model. Or, perhaps a different vehicle such as a truck or a bus might be more appropriate here.</p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> Depending on the command line shell you are using, you might have the <code>readline</code> library that makes it easier to use the REPL. For example, <code>up</code> and <code>down</code> arrow keys to browse code history, re-execute them (after editing if necessary), search history, autocomplete based on first few characters and so on. See <a href="https://en.wikipedia.org/wiki/GNU_Readline">wikipedia: GNU readline</a> and <a href="https://wiki.archlinux.org/index.php/readline">wiki.archlinux: readline</a> for more information.</p></blockquote><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> You can use <code>python3.9 -q</code> to avoid <em>version and copyright messages</em> when you start an interactive shell. Use <code>python3.9 -h</code> or visit <a href="https://docs.python.org/3/using/cmdline.html">docs.python: Command line and environment</a> for documentation on cli options.</p></blockquote><h2><a href="#documentation-and-getting-help" id="documentation-and-getting-help">Documentation and getting help</a></h2><p>The offical Python website has an extensive documentation located at <a href="https://docs.python.org/3/">https://docs.python.org/3/</a>. This includes a tutorial, which is much more comprehensive than the contents presented in this book, several guides for specific modules like <code>re</code> and <code>argparse</code> and various other information.</p><p>Here's a couple of annotated screenshots:</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/py_docs_1.png" alt="Python documentation: part 1"></p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/py_docs_2.png" alt="Python documentation: part 2"></p><p>Python provides a <code>help()</code> function, which is quite handy to use from the REPL. If you type <code>help(print)</code> and press the Enter key, you'll get a screen as shown below. If you are using IDLE, the output would be displayed on the same screen. Otherwise, the content might be shown on a different screen depending on your <code>pager</code> settings. Typically, pressing the <code>q</code> key will quit the <code>pager</code> and get you back to the shell.</p><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/help_print.png" alt="help print"></p><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> Quotes are necessary, for example <code>help('import')</code> and <code>help('del')</code>, if the topic you are looking for isn't an object.</p></blockquote><p>If you get stuck with a problem, there are several ways to get it resolved. For example:</p><ol><li>read/search for that particular topic from documentation/books/tutorials/etc</li><li>reduce the code as much as possible so that you are left with minimal code necessary to reproduce the issue</li><li>talk about the problem with a friend/colleague/inanimate-objects/etc (see <a href="https://rubberduckdebugging.com/">Rubber duck debugging</a>)</li><li>search about the problem online</li></ol><p>You can also ask for help on forums. Make sure to read the instructions provided by the respective forums before asking a question. See also <a href="http://catb.org/%7Eesr/faqs/smart-questions.html#before">how to ask smart-questions</a>. Here's some forums you can use:</p><ul><li><a href="https://www.reddit.com/r/learnpython">/r/learnpython</a> and <a href="https://www.reddit.com/r/learnprogramming/">/r/learnprogramming/</a> — beginner friendly</li><li><a href="https://python-forum.io/">python-forum</a> — dedicated Python forum, encourages back and forth discussions based on the topic of the thread</li><li><a href="https://www.reddit.com/r/Python/">/r/Python/</a> — general Python discussion</li><li><a href="https://stackoverflow.com/tags/python">stackoverflow: python tag</a></li></ul><blockquote><p><img src="https://learnbyexample.github.io/100_page_python_intro/images/info.svg" alt="info"> The <a href="https://learnbyexample.github.io/100_page_python_intro/debugging.html#debugging">Debugging</a> chapter will discuss more on this topic.</p></blockquote></main><nav aria-label="Page navigation"><a rel="prev" href="https://learnbyexample.github.io/100_page_python_intro/preface.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left"> <i></i> </a><a rel="next" href="https://learnbyexample.github.io/100_page_python_intro/numeric-data-types.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div><nav aria-label="Page navigation"><a rel="prev" href="https://learnbyexample.github.io/100_page_python_intro/preface.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left"> <i></i> </a><a rel="next" href="https://learnbyexample.github.io/100_page_python_intro/numeric-data-types.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div>]]>
            </description>
            <link>https://learnbyexample.github.io/100_page_python_intro/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076721</guid>
            <pubDate>Tue, 09 Feb 2021 12:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[José Valim Reveals “Project Nx” (Numerical Elixir) [audio]]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26076680">thread link</a>) | @thibaut_barrere
<br/>
February 9, 2021 | https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
		<p>
José Valim visits and finally publicly reveals what Project Nx is! He and others have been working on it for 3 months and he’s finally ready to unveil it. José will speak more about it at the LambdaDays conference, demonstrating it with code and announcing the release and availability of the OpenSource code.</p>
<p>Nx stands for “Numerical Elixir”. The Nx project brings a unique numerical mode to Elixir along with GPU support. This important work lays the foundation for a powerful new era with data science in Elixir! Listen in as Jose discusses the details of how this works, how it came about, the goals of the project, what this means for the community, and what comes next.
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx">https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/122" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/122</a> – ElixirLS version 0.6.3 released</li>
<li><a href="https://github.com/elixir-lsp/elixir-ls/blob/master/CHANGELOG.md" target="_blank" rel="noopener noreferrer">https://github.com/elixir-lsp/elixir-ls/blob/master/CHANGELOG.md</a> – ElixirLS Changelog</li>
<li><a href="https://codesync.global/conferences/code-beam-v-america-2021/" target="_blank" rel="noopener noreferrer">https://codesync.global/conferences/code-beam-v-america-2021/</a> – CodeBEAM American conference dates March 10-12</li>
<li><a href="https://hexdocs.pm/oban/changelog.html#2-4-0-2021-01-26" target="_blank" rel="noopener noreferrer">https://hexdocs.pm/oban/changelog.html#2-4-0-2021-01-26</a> – Oban 2.4.0 released</li>
<li><a href="https://twitter.com/sorentwo/status/1354099475191652352" target="_blank" rel="noopener noreferrer">https://twitter.com/sorentwo/status/1354099475191652352</a> – Oban performance improvement charts</li>
<li><a href="https://github.com/wintermeyer/phx_tailwind_generators" target="_blank" rel="noopener noreferrer">https://github.com/wintermeyer/phx_tailwind_generators</a> – Phoenix TailwindCSS generator</li>
<li><a href="https://github.com/phoenixframework/phoenix/pull/4191" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix/pull/4191</a> – Phoenix JavaScript gets more modern with Phoenix ES modules</li>
<li><a href="https://fullstackphoenix.com/boilerplates/new" target="_blank" rel="noopener noreferrer">https://fullstackphoenix.com/boilerplates/new</a> – Feedback! We learned about the site FullStackPhoenix which helps you start new projects already setup with several options for how to configure it.</li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li>Nx stands for “Numerical Elixir”</li>
<li><a href="https://elixirforum.com/t/anyone-who-wants-to-speculate-about-this-tweet-from-jose/35772/68" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/anyone-who-wants-to-speculate-about-this-tweet-from-jose/35772/68</a> – A great text summary of the announcement found on ElixirForum.</li>
<li><a href="https://twitter.com/josevalim/status/1356880707474370560" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim/status/1356880707474370560</a> – José Valim released the new Nx logo during our recording. The cute animal is a Numbat!</li>
<li><a href="https://en.wikipedia.org/wiki/Numbat" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Numbat</a></li>
<li><a href="https://github.com/erlang/otp/pull/2890" target="_blank" rel="noopener noreferrer">https://github.com/erlang/otp/pull/2890</a> – José’s pull request to add 16-bit floats in bitstrings to OTP</li>
<li><a href="https://numpy.org/" target="_blank" rel="noopener noreferrer">https://numpy.org/</a></li>
<li><a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Softmax_function</a></li>
<li><a href="https://pragprog.com/titles/smgaelixir/genetic-algorithms-in-elixir/" target="_blank" rel="noopener noreferrer">https://pragprog.com/titles/smgaelixir/genetic-algorithms-in-elixir/</a></li>
<li><a href="https://elixirforum.com/t/pelemay-formerly-hastega-challenge-for-gpgpu-on-elixir/22986" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/pelemay-formerly-hastega-challenge-for-gpgpu-on-elixir/22986</a></li>
<li><a href="https://erlang.org/doc/man/erl_nif.html#dirty_nifs" target="_blank" rel="noopener noreferrer">https://erlang.org/doc/man/erl_nif.html#dirty_nifs</a> – Information on Dirty NIFs</li>
<li><a href="https://twitter.com/bcardarella" target="_blank" rel="noopener noreferrer">https://twitter.com/bcardarella</a></li>
<li><a href="https://www.tensorflow.org/xla" target="_blank" rel="noopener noreferrer">https://www.tensorflow.org/xla</a></li>
<li><a href="https://tvm.apache.org/" target="_blank" rel="noopener noreferrer">https://tvm.apache.org/</a></li>
<li><a href="https://mlir.llvm.org/" target="_blank" rel="noopener noreferrer">https://mlir.llvm.org/</a></li>
<li><a href="https://github.com/google/jax" target="_blank" rel="noopener noreferrer">https://github.com/google/jax</a></li>
<li><a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">https://julialang.org/</a></li>
<li><a href="https://www.lambdadays.org/lambdadays2021/jose-valim" target="_blank" rel="noopener noreferrer">https://www.lambdadays.org/lambdadays2021/jose-valim</a> – LambdaDays speaker page</li>
<li><a href="https://www.lambdadays.org/lambdadays2021#programme" target="_blank" rel="noopener noreferrer">https://www.lambdadays.org/lambdadays2021#programme</a> – José speaks on day 2</li>
<li>Promo code for 15% off LambdaDays tickets! Just use “thinkingelixir15”</li>
<li><a href="https://twitter.com/josevalim" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim</a></li>
<li><a href="https://twitter.com/sean_moriarity" target="_blank" rel="noopener noreferrer">https://twitter.com/sean_moriarity</a></li>
<li><a href="https://twitter.com/elixirlang" target="_blank" rel="noopener noreferrer">https://twitter.com/elixirlang</a></li>
</ul>
<p><strong>Guest Information</strong></p>

<ul>
<li><a href="https://twitter.com/josevalim" target="_blank" rel="noopener noreferrer">https://twitter.com/josevalim</a> – on Twitter</li>
<li><a href="https://github.com/josevalim" target="_blank" rel="noopener noreferrer">https://github.com/josevalim</a> – on Github</li>
<li><a href="https://dashbit.co/" target="_blank" rel="noopener noreferrer">https://dashbit.co/</a> – Dashbit website and blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://twitter.com/cadebward" target="_blank" rel="noopener noreferrer">@cadebward</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#034 José Valim reveals Project Nx"><meta itemprop="uploadDate" content="2021-02-09T04:15:48-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT1H15M59S"><meta itemprop="description" content="José Valim visits and finally publicly reveals what Project Nx is! He and others have been working on it for 3 months and he's finally ready to unveil it. José will speak more about it at the LambdaDays conference, demonstrating it with code and announcing the release and availability of the OpenSource code. This is an exciting development that brings Elixir into areas it hasn't been used before. We also talk about what this means for Elixir and the community going forward. A must listen!



Show Notes online - https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3"><meta itemprop="contentSize" content="35.0"><div id="powerpress_player_8468"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6278-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/034-project-nx-with-jose-valim.mp3" title="Download" rel="nofollow" download="034-project-nx-with-jose-valim.mp3">Download</a></p>	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076680</guid>
            <pubDate>Tue, 09 Feb 2021 12:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pi from High School Maths]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26076128">thread link</a>) | @vonadz
<br/>
February 9, 2021 | https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html | <a href="https://web.archive.org/web/*/https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<p>Warning: I don’t think the stuff in this post has any direct practical application by itself (unless you’re a
nuclear war survivor and need to reconstruct maths from scratch or something). Sometimes I like to go back to basics,
though. Here’s a look at <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math> and areas of curved shapes without any calculus or transcendental functions.</p><h2 id="a-simple-algorithm-for-calculating-pi">A simple algorithm for calculating <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math></h2>
<p>This algorithm starts with simple number theoretic musing. Some whole numbers form neat Pythagorean triples
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
,
</mo>
<mi>
y
</mi>
<mo>
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(x, y, z)
</annotation>
</semantics></math> where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mi>
z
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = z^2
</annotation>
</semantics></math>. E.g., <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
3^2 + 4^2 = 5^2
</annotation>
</semantics></math>. It’s easy to find all the solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = 5^2
</annotation>
</semantics></math> through brute-force search because we know that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> can’t be bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
5
</mn>
</mrow>
<annotation encoding="application/x-tex">
5
</annotation>
</semantics></math>. Here they are:</p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<semantics>
<mrow>
<mrow>
<mtable displaystyle="true" columnalign="right left right left right left right left right left" columnspacing="0em">
<mtr>
<mtd>
<msup>
<mn>
0
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
4
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
3
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mn>
0
</mn>
<mn>
2
</mn>
</msup>
</mtd>
<mtd>
<mo>
=
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mtd>
</mtr>
</mtable>
</mrow>
</mrow>
<annotation encoding="application/x-tex">
\begin{aligned} 0^2 + 5^2 &amp;= 5^2 \\ 3^2 + 4^2 &amp;= 5^2 \\ 4^2 + 3^2 &amp;= 5^2 \\ 5^2 + 0^2 &amp;= 5^2 \end{aligned}
</annotation>
</semantics></math>
<p>(Plus all the negative-number combinations, but let’s stick with non-negative integers and just count 4 solutions.)
If we relax the equation, and count solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mn>
5
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le 5^2
</annotation>
</semantics></math>, the answer turns out to be 26. Why care? Well, if <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
t
</mi>
</mrow>
<annotation encoding="application/x-tex">
t
</annotation>
</semantics></math> is the total number of solutions to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le n^2
</annotation>
</semantics></math>, then</p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
<semantics>
<mrow>
<munder>
<mi>
lim
</mi>
<mrow>
<mi>
n
</mi>
<mo>
→
</mo>
<mn>
∞
</mn>
</mrow>
</munder>
<mfrac>
<mrow>
<mn>
4
</mn>
<mi>
t
</mi>
</mrow>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<msup>
<mo stretchy="false">
)
</mo>
<mn>
2
</mn>
</msup>
</mrow>
</mfrac>
<mo>
=
</mo>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\lim_{n \to \infinity} \frac{4t}{(n+1)^2} = \pi
</annotation>
</semantics></math>
<p>Or, in code, here’s a simple program that estimates <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, getting more accurate for bigger values of the <code>n</code> variable:</p>
<figure>
<pre><code data-lang="d"><span>import</span> <span>std</span><span>;</span>

<span>ulong</span> <span>sq</span><span>(</span><span>ulong</span> <span>x</span><span>)</span> <span>pure</span>
<span>{</span>
    <span>return</span> <span>x</span> <span>*</span> <span>x</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
<span>{</span>
    <span>const</span> <span>n</span> <span>=</span> <span>args</span><span>.</span><span>length</span> <span>&gt;</span> <span>1</span> <span>?</span> <span>args</span><span>[</span><span>1</span><span>].</span><span>to</span><span>!</span><span>ulong</span> <span>:</span> <span>20</span><span>;</span>

    <span>ulong</span> <span>total</span><span>;</span>
    <span>foreach</span> <span>(</span><span>x</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
    <span>{</span>
        <span>foreach</span> <span>(</span><span>y</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
        <span>{</span>
            <span>if</span> <span>(</span><span>sq</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>sq</span><span>(</span><span>y</span><span>)</span> <span>&lt;=</span> <span>sq</span><span>(</span><span>n</span><span>))</span> <span>total</span><span>++;</span>
        <span>}</span>
    <span>}</span>

    <span>/*
    // Alternatively, for functional programming fans:
    const total =
        cartesianProduct(iota(n+1), iota(n+1))
                .count!(p =&gt; sq(p[0]) + sq(p[1]) &lt;= sq(n));
    */</span>

    <span>writef</span><span>(</span><span>"%.12f\n"</span><span>,</span> <span>4.0</span> <span>*</span> <span>total</span> <span>/</span> <span>sq</span><span>(</span><span>n</span><span>+</span><span>1</span><span>));</span>
<span>}</span></code></pre>
</figure>
<figure>
<pre><code data-lang="shell">
$ ./pi_calc 
3.038548752834
$ ./pi_calc 10000
3.141362256135
</code></pre>
</figure>
<p>Okay, that’s a little bit more accurate than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mn>
22
</mn>
<mn>
7
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{22}{7}
</annotation>
</semantics></math>. Unlike most formulae for <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, though, there’s a simple diagram that shows how it works. Imagine we lay out the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
,
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(x, y)
</annotation>
</semantics></math> integer pairs (where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> range from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>) on a 2D grid the obvious way. The figure below shows an example for <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
</mrow>
<annotation encoding="application/x-tex">
n=10
</annotation>
</semantics></math>, with the arrow <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
r
</annotation>
</semantics></math> pointing from the origin to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math>. <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
r
</annotation>
</semantics></math> and the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> components make a right-angled triangle, so <a href="https://www.cut-the-knot.org/pythagoras/">Pythagoras’s theorem</a> says that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
=
</mo>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 = r^2
</annotation>
</semantics></math>. For <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
r
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
<mo>
=
</mo>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
r = 10 = n
</annotation>
</semantics></math>, so <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mn>
6
</mn>
<mo>
,
</mo>
<mn>
8
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(6, 8)
</annotation>
</semantics></math> is on the boundary as a solution to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mn>
10
</mn>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le 10^2
</annotation>
</semantics></math>. That boundary (the set of real-valued points a constant distance <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mn>
10
</mn>
</mrow>
<annotation encoding="application/x-tex">
n=10
</annotation>
</semantics></math> from the origin) makes a quarter circle.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_calc_grid.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_calc_grid.svg" alt="Grid for calculating an estimate of pi"></a>
</figure>
<p>A circle is a simple, convex shape, and the grid points are evenly spaced, so the number of points inside the
quarter circle will be roughly proportional to the area. More specifically, the fraction of all the grid points inside
the quarter circle will be roughly the area of the quarter circle divided by the area of square around all points. The
quarter circle area is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
<mo>
÷
</mo>
<mn>
4
</mn>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2 \div 4
</annotation>
</semantics></math>, inside the square of area <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
r^2
</annotation>
</semantics></math> (remember, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
<mo>
=
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
n = r
</annotation>
</semantics></math>), so <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
π
</mi>
<mn>
4
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{\pi}{4}
</annotation>
</semantics></math> of all points represent solutions. The <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> values count from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, so there are <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<msup>
<mo stretchy="false">
)
</mo>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
(n+1)^2
</annotation>
</semantics></math> grid points. Rearrange the equations and you get a formula for estimating <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math> from a solution count. The grid points keep drawing an arbitrarily more accurate circle as
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math> gets bigger (just like a higher-resolution computer monitor does) so the estimate is exact in the
limit.</p>
<h2 id="a-faster-implementation">A faster implementation</h2>
<p>The code above is simple but slow because it brute-force scans over all <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
<mo>
×
</mo>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
(n+1) \times (n+1)
</annotation>
</semantics></math>possible <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> values. But we obviously don’t need to scan <em>all</em> values. If we know that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<msup>
<mi>
x
</mi>
<mn>
2
</mn>
</msup>
<mo>
+
</mo>
<msup>
<mi>
y
</mi>
<mn>
2
</mn>
</msup>
<mo>
≤
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
x^2 + y^2 \le n^2
</annotation>
</semantics></math>, then making <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> or <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> smaller will only give us another solution. We don’t need to keep testing smaller values after we
find a solution. Ultimately, we only need to find the integral points around the boundary. Here’s a faster algorithm
based on that idea.</p>
<p>Imagine we scan along the integral <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> values and find the maximum integral <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> value that still gives us a solution. This gives us a border line marked in red in the figure
below. If <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
<mo>
=
</mo>
<mn>
8
</mn>
</mrow>
<annotation encoding="application/x-tex">
y=8
</annotation>
</semantics></math> for a given <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value, we instantly know there are <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
8
</mn>
<mo>
+
</mo>
<mn>
1
</mn>
<mo>
=
</mo>
<mn>
9
</mn>
</mrow>
<annotation encoding="application/x-tex">
8 + 1 = 9
</annotation>
</semantics></math> solutions with that given <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mo lspace="0.11111em" rspace="0em">
+
</mo>
<mn>
1
</mn>
</mrow>
<annotation encoding="application/x-tex">
+ 1
</annotation>
</semantics></math> to count the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
<mo>
=
</mo>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
y=0
</annotation>
</semantics></math> solution).</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_fast_calc_grid.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/pi_fast_calc_grid.svg" alt="Estimating pi efficiently by tracing circle boundary"></a>
</figure>
<p>Note that as <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> scans from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> starts at <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math> and decreases to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math>. Importantly, it <em>only</em> decreases — it’s monotonic. So if we scan <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> from <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
0
</mn>
</mrow>
<annotation encoding="application/x-tex">
0
</annotation>
</semantics></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
n
</mi>
</mrow>
<annotation encoding="application/x-tex">
n
</annotation>
</semantics></math>, we can find the next boundary <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
y
</mi>
</mrow>
<annotation encoding="application/x-tex">
y
</annotation>
</semantics></math> point by starting from the previous boundary point and searching downwards. Here’s some code:</p>
<figure>
<pre><code data-lang="d"><span>ulong</span> <span>y</span> <span>=</span> <span>n</span><span>,</span> <span>total</span><span>;</span>
<span>foreach</span> <span>(</span><span>x</span><span>;</span> <span>0.</span><span>.</span><span>n</span><span>+</span><span>1</span><span>)</span>
<span>{</span>
    <span>while</span> <span>(</span><span>sq</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>sq</span><span>(</span><span>y</span><span>)</span> <span>&gt;</span> <span>sq</span><span>(</span><span>n</span><span>))</span> <span>y</span><span>--;</span>
    <span>total</span> <span>+=</span> <span>y</span> <span>+</span> <span>1</span><span>;</span>
<span>}</span></code></pre>
</figure>
<p>This version still has nested loops, so it might look like it’s still <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<msup>
<mi>
n
</mi>
<mn>
2
</mn>
</msup>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n^2)
</annotation>
</semantics></math>. However, the inner <code>while</code> loop executes a
varying number of times for each <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics></math> value. Often the <code>y--</code> doesn’t trigger at
all. In fact, because <code>y</code> starts from <code>n</code> and monotonically decreases to 0, we know the <code>y--</code> will be executed exactly <code>n</code> times in total. There’s no instruction in that code that executes more
than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n)
</annotation>
</semantics></math> times, total, so the whole algorithm is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
O
</mi>
<mo stretchy="false">
(
</mo>
<mi>
n
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
O(n)
</annotation>
</semantics></math>.</p>
<p>With 64b <code>ulong</code> integers, the largest value of <code>n</code> that works before overflow is 4294967294:</p>
<figure>
<pre><code data-lang="shell">
$ ./pi_calc 4294967294
3.141592653058
</code></pre>
</figure>
<p>There are ways to get faster convergence using numerical integration tricks, but I like the way this algorithm only
uses integer arithmetic (up until the final division), and can be understood directly from simple diagrams.</p>
<h2 id="area-of-a-circle-without-calculus">Area of a circle without calculus</h2>
<p>Perhaps you feel a bit cheated because that algorithm assumes the <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math> formula for the area of a circle. Sure, that’s arguably included in “high school maths”, but it’s
something students just get told to remember, unless they study integral calculus and derive it that way. But if we’re
going to assume <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math>, why not assume the theory of trigonometric functions as well, and just use <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<mo>
=
</mo>
<mn>
4
</mn>
<mo lspace="0em" rspace="0.16667em">
atan
</mo>
<mo stretchy="false">
(
</mo>
<mn>
1
</mn>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\pi = 4\atan(1)
</annotation>
</semantics></math>?</p>
<p>The great ancient Greek mathematician Archimedes figured out the circle area over two thousand years ago without
integral calculus (or trigonometric functions for that matter). He started with an elegant insight about regular (i.e.,
equal-sided) polygons.</p>
<p>The famous <a href="https://mathcs.clarku.edu/~djoyce/java/elements/bookI/propI37.html">“half base times height”
formula for the area of a triangle already had a well-known proof in the first book of Euclid’s Elements of
Geometry</a> (easily derived from <a href="https://mathcs.clarku.edu/~djoyce/java/elements/bookI/propI35.html">a
theorem about parallelograms</a>). Conveniently, any regular polygon can be split into equal triangles joined to the
centre. For example, a regular hexagon splits into six triangles, as in the figure below. We can take any one of the
triangles (they’re all the same) and call the “base” the side that’s also a side of the polygon. Then the “height” is
the line from the centre of the base to the centre of the polygon.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon.svg" alt="Explanation of perimeter-to-area ratio of regular polygons"></a>
</figure>
<p>Now here’s Archimedes’s neat insight: The ratio of the triangle area to the base is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math>. If you add up all the areas, you get the area of the polygon. Likewise, if you add up all the
bases, you get the perimeter of the polygon. Because the triangle area/base ratio is a constant <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math> for all triangles, the area/perimeter ratio for the whole polygon is the same <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
\frac{h}{2}
</annotation>
</semantics></math>. As a formula, the area of <em>any</em> regular polygon is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
P \times \frac{h}{2}
</annotation>
</semantics></math> (where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
</mrow>
<annotation encoding="application/x-tex">
P
</annotation>
</semantics></math> is the perimeter).</p>
<p>If you think of a circle as a regular polygon with infinitely many sides (so that <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
</mrow>
<annotation encoding="application/x-tex">
h
</annotation>
</semantics></math> becomes the radius of the circle), and use the circle circumference (<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
2\pi r
</annotation>
</semantics></math>) as your basic definition of <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
</mrow>
<annotation encoding="application/x-tex">
\pi
</annotation>
</semantics></math>, then that implies the area of a circle is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
<mo>
=
</mo>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2} = \pi r^2
</annotation>
</semantics></math>.</p>
<p>Of course, Archimedes was a respected mathematician who couldn’t get away with just assuming that anything true of a
polygon is true of a circle (counterexample: all polygons have bumpy corners, but circles don’t). He used the kind of
geometric proof by contradiction that was popular in his day. (He even took it further and analysed spheres, cylinders,
parabolas and other curved objects, almost inventing something like modern real analysis a couple of millenia early.)
Sadly, not all of his mathemetical work has survived, but <a href="https://flashman.neocities.org/ARCHCI1set.htm">the
key part of his Measurement of a Circle</a> has.</p>
<p>Here’s the high-level version. Archimedes claimed that the area of a circle is <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. Suppose you think his value is too small, and the circle is really bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. That means there’s enough room inside the circle to fit a regular polygon that’s also bigger than
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. But Archimedes said that’s contradictory because for any such polygon, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
<mo>
&lt;
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
h \lt r
</annotation>
</semantics></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
P
</mi>
<mo>
&lt;
</mo>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
P \lt 2\pi r
</annotation>
</semantics></math> (because each side of the polygon is a straight line that’s shorter than the circle arc that
connects the same points), so the area <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
A
</mi>
<mo>
=
</mo>
<mi>
P
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
h
</mi>
<mn>
2
</mn>
</mfrac>
<mo>
&lt;
</mo>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
A = P \times \frac{h}{2} \lt 2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>. The polygon’s area can’t be both bigger and smaller than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_inner.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_inner.svg" alt="A regular polygon inside a circle"></a>
</figure>
<p>Archimedes argued that there’s a similar contradiction if you think <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math> is too big, and the circle area is smaller than that. In that case he could make a polygon that’s
also smaller than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>, yet still wraps around the circle. For this polygon, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
h
</mi>
<mo>
=
</mo>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
h = r
</annotation>
</semantics></math>, but he said the perimeter of the polygon must be greater than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
</mrow>
<annotation encoding="application/x-tex">
2\pi r
</annotation>
</semantics></math><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>, so that the
polygon’s area must be bigger than <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mn>
2
</mn>
<mi>
π
</mi>
<mi>
r
</mi>
<mo>
×
</mo>
<mfrac>
<mi>
r
</mi>
<mn>
2
</mn>
</mfrac>
</mrow>
<annotation encoding="application/x-tex">
2\pi r \times \frac{r}{2}
</annotation>
</semantics></math>, even though it’s also meant to be smaller.</p>
<figure role="img">
<a href="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_outer.svg"><img src="https://theartofmachinery.com/images/pi_from_high_school_maths/polygon_outer.svg" alt="A regular polygon around a circle"></a>
</figure>
<p>If both of those cases lead to contradiction, we’re left with the only alternative that the circle area is
<math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
<semantics>
<mrow>
<mi>
π
</mi>
<msup>
<mi>
r
</mi>
<mn>
2
</mn>
</msup>
</mrow>
<annotation encoding="application/x-tex">
\pi r^2
</annotation>
</semantics></math>.</p>

</div></div>]]>
            </description>
            <link>https://theartofmachinery.com/2020/10/26/pi_from_high_school_maths.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26076128</guid>
            <pubDate>Tue, 09 Feb 2021 11:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiler Class]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26075930">thread link</a>) | @ingve
<br/>
February 9, 2021 | https://norswap.com/compilers/ | <a href="https://web.archive.org/web/*/https://norswap.com/compilers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>In 2021, I'm teaching a master-level compiler class at <a href="https://uclouvain.be/">Université catholique de
Louvain</a>.</p>
<p>All the course materials are made available online, for anyone interested to
peruse. I'm also happy to <a href="mailto:norswap+compiler+q@gmail.com">answer</a> your questions.</p>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLOech0kWpH8-njQpmSNGSiQBPUvl8v3IM">Youtube Playlist</a></li>
<li><a href="https://drive.google.com/drive/folders/1cMgLvEiaWsyfip8wJXXilVhvM2XDrS-6">Slides</a></li>
</ul>
<p>The course's project is to create your own programming language. A few libraries
are supplied to assist in this task:</p>
<ul>
<li><a href="https://github.com/norswap/autumn">Autumn</a> (parsing)</li>
<li><a href="https://github.com/norswap/uranium/">Uranium</a> (semantic analysis)</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://norswap.com/compilers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26075930</guid>
            <pubDate>Tue, 09 Feb 2021 10:43:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner's Guide to NFTs]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26073970">thread link</a>) | @donohoe
<br/>
February 8, 2021 | https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d | <a href="https://web.archive.org/web/*/https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>What are NFTs?</h3>
<p>Non-fungible token (NFT) is a term used to describe a unique digital asset whose ownership is tracked on a blockchain, such as Ethereum. Assets that can be represented as NFTs range from digital goods, such as items that exist within virtual worlds, to claims on physical assets such as clothing items or real estate. In the coming years, we will see NFTs used to unlock entirely new use cases that are only made possible by crypto.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/9799dae1-c2c9-4712-813b-10b23c279a36.jpeg" alt="Tokens redeemable for real world goods on Zora"></p><figcaption>Tokens redeemable for real world goods on Zora</figcaption></figure>
<p>While the Ethereum ecosystem is where most NFT activity has taken place to date, NFTs can exist on other smart contract platforms too. This is because, at their core, NFTs are just digital abstractions used to represent assets that are one of a kind. Non-fungible token isn’t the most intuitive term since we don’t commonly refer to the fungibility of objects in the physical world, but this is an important technical distinction when it comes to how an asset is represented on a blockchain. The goal for this post is not to detail every project within the NFT space, but to give a high level overview of what NFTs are, why they are interesting, and showcase some of their potential use cases.</p>
<h3>Why are NFTs interesting?</h3>
<p>NFTs are powerful because, when combined with other financial building blocks on Ethereum, they allow anyone to issue, own, and trade them. This makes interacting with NFTs significantly more efficient than in traditional platforms. The same reason why cryptocurrency used in payments is more efficient than traditional payments, that it is borderless and significantly easier to transfer, applies to NFTs. For example, if you want to create tradable in-game items as a game developer, then you can instantly have them be tradable through protocols that allow for decentralized exchange of NFTs. You don’t have to create your own marketplace or go through the onboarding process of a centralized platform in order to have the items be tradable.</p>
<p>NFT activity can go well past trading and include actions like being able to borrow and lend, support fractional ownership (e.g. <a href="https://www.niftex.com/">NIFTEX</a>), or use it as collateral in taking out a loan (e.g. <a href="https://nftfi.com/">NFTfi</a>). The possibilities are endless when you have the ability to combine NFTs with DeFi building blocks. For example, the game <a href="http://aavegotchi.com/">Aavegotchi</a> combines DeFi and NFT gaming where each Aavegotchi character represents a user’s collateral that is deposited within the lending platform <a href="https://aave.com/">Aave</a>, but you can also battle the characters, level them up, and equip wearables that change their traits.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/a1259686-6b61-455a-a204-f6e6da648f10.jpeg" alt="Aavegotchi gaming attributes change based on actions taken in DeFi"></p><figcaption>Aavegotchi gaming attributes change based on actions taken in DeFi</figcaption></figure>
<p>NFTs can cover an extremely wide variety of areas given they are simply digital representations of ownership but there has been significant growth within art and gaming in particular. Note that many digital works of art and gaming items are a subset of a larger category of NFT collectibles. There is also the emerging space of social tokens, which sometimes falls into the NFT category or that is closely related to it.</p>
<h3>Art</h3>
<p>NFTs can make fractionalized ownership more accessible, so if there is a valuable item that otherwise wouldn’t have been accessible for someone to own, now they can own a piece of it. Custody of a physical item still requires a trustworthy custodian, but being able to issue, hold, and trade it as a cryptoasset unlocks more use cases. One can also craft an NFT such that the creator receives a percentage of all secondary sales in a completely automated way. Artists typically don’t receive a cut of secondary sales in the traditional art world.</p>
<p>Programmable art is another interesting concept where a piece of artwork can incorporate on-chain data to dynamically update certain features or characteristics of the work. For example, one could create a piece of programmable art whose background changes if the price of ether goes above a certain dollar-value. There are countless creative possibilities.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/a51670c0-4a1c-4aaf-917d-0e551855b56d.jpeg" alt="Rutger van der Tas artwork that changes based on if it’s day or night"></p><figcaption>Rutger van der Tas artwork that changes based on if it’s day or night</figcaption></figure>
<p><a href="https://async.art/">Async Art</a> is a digital art marketplace known for programmable art. Many artists on Async sell artwork where someone is able to own the “master” copy which consists of a number of individual layers, but other people can own the individual layers and adjust their attributes over time. Imagine groups of people being able to own art collectively, where members of the group manage attributes of the work.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/fea07c75-8b3c-4592-b8f2-f5d6d92e544c.jpeg" alt="Osinachi artwork that includes a master and layers that can be individually adjusted"></p><figcaption>Osinachi artwork that includes a master and layers that can be individually adjusted</figcaption></figure>
<p>A common question about digital artwork is what can you do with it? These works can be displayed in digital frames in a physical setting for people to enjoy. The digital artist Beeple sold physical tokens along with his digital NFTs and made <a href="https://niftygateway.com/itemdetail/primary/0x6e5dc5405baefb8c0166bcc78d2692777f2cbffb/21">$3.5 million</a> from sales in an auction on the Nifty Gateway marketplace.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/8689be31-b33f-46ac-94aa-feea3a1b3dd1.jpeg" alt="Artist Beeple’s physical token that came with the NFT sale"></p><figcaption>Artist Beeple’s physical token that came with the NFT sale</figcaption></figure>
<p>Digital artwork can also be displayed in online collections like a <a href="https://superrare.co/thevault/collection">SuperRare profile</a> as well as in virtual worlds. There are a number of art galleries within <a href="http://cryptovoxels.com/">Cryptovoxels</a>, a virtual world where users can buy and sell land parcels as NFTs. As virtual reality spaces become more popular, having digital art to display will become more common. This wouldn’t be much different than someone spending money on video game items to customize a character’s appearance, already a multi-billion dollar industry.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/7386d358-d43d-4934-9ea5-b51c33932365.jpeg" alt="Digital art gallery in Cryptovoxels"></p><figcaption>Digital art gallery in Cryptovoxels</figcaption></figure>
<p>A common skepticism is that someone can just take a screenshot of the image or get a digital file so it’s not really scarce. However, the same argument could apply to physical items as well. Anyone can take a photo of the Mona Lisa or create a replica of it, but it isn’t the real item from the artist. People are willing to pay a premium for the original work. Another interesting aspect of digital art or collectibles is that you can easily verify the item’s ownership history. Some digital items might be worth more depending on who owned it in the past.</p>
<p>With NFTs, you can also prove that the item is real and tamper proof. This is an issue in the physical collectibles space. For example, a <a href="https://en.wikipedia.org/wiki/T206_Honus_Wagner">T206 Honus Wagner baseball card</a> was sold to Wayne Gretzky for $451k and sold again for several million dollars. One of the sellers of the card later admitted in court to trimming the card’s edges to make it look better. You can ensure NFT supply doesn’t change and there’s no counterfeit or continued printing. For example, there are many <a href="https://www.youtube.com/watch?v=AAvLC3fz068&amp;">counterfeit Black Lotus</a> cards in the popular game Magic: The Gathering. Common verification methods include bending the card to make sure it doesn’t crease or going through centralized grading services whose rating significantly affects the card's value.</p>
<h3>Gaming</h3>
<p>Steam, a popular video game platform, has a <a href="https://steamcommunity.com/market/?">Community Market</a> where in-game items can be bought and sold. Steam’s marketplace is centralized and collects a transaction fee of 5% for each item from the buyer. Games like Team Fortress 2 and Dota 2 take an additional fee of 10% for their items sold.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/4ad85fcf-b986-4b60-9fb5-925200fde3a9.jpeg" alt="Steam Community Market"></p><figcaption>Steam Community Market</figcaption></figure>
<p>Steam also restricts user wallet balances to $2,000 and the price of a single item to $1,800. While these cases are outliers, many in-game items can actually sell for significantly larger amounts such as the <a href="https://www.engadget.com/2013-11-06-dota-2-pink-war-dog-courier-sells-for-38-000.html">DotA 2 pink war dog courier</a> for $38,000. Within the crypto space there have also been high priced sales such as the $170,000 <a href="https://thenextweb.com/hardfork/2018/09/05/most-expensive-cryptokitty/">CryptoKitty</a>. Similarly Magic: The Gathering’s coveted <a href="https://www.polygon.com/2019/3/5/18251623/magic-the-gathering-black-lotus-auction-price">Black Lotus</a> card sold for $166,100. There is certainly demand for valuable in-game items. In decentralized marketplaces, there isn’t a limit imposed on what game items can be sold and for what amount.</p>
<p>Decentralized marketplaces can significantly reduce transaction fees due to the improved efficiency of starting up and operating a marketplace. Marketplaces can also improve overall user experience and increase interest in the game. Hearthstone is a wildly popular digital collectible card game created by Blizzard Entertainment that had over <a href="https://variety.com/2018/gaming/news/hearthstone-has-over-100-million-players-1203019919/">100 million players</a> in 2018. Hearthstone opted to not have a marketplace for their cards which leaves opportunity for other digital collectible card games that allow for an open marketplace. <a href="https://godsunchained.com/">Gods Unchained</a> and <a href="https://www.skyweaver.net/">SkyWeaver</a> are two trading card games (TCGs) that have cards that are freely tradable. You are also able to earn cards as you level up in the game. Players that did not purchase packs of cards will still be able to improve upon the game’s default decks. It’s an exciting feeling knowing that the earned cards have real world value and can be sold or traded for other cards. Gods Unchained also lets users earn tokens for when they win a match or refer their friend. The tokens themselves unlock rare in-game items and are also freely tradable.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/aa82c586-39b6-46b1-ae55-cb8a2e44c8e1.jpeg" alt="Gods Unchained"></p><figcaption>Gods Unchained</figcaption></figure>
<p>One of the most popular games in crypto is <a href="https://axieinfinity.com/">Axie Infinity</a>. You battle with a team of pet Axies and level them up. There's no aspect of the gameplay that feels like a blockchain game but there is the added benefit of being able to openly trade the Axies on NFT marketplaces such as <a href="https://opensea.io/">OpenSea</a>. The game has become popular in the <a href="https://www.coindesk.com/nft-game-filipinos-covid">Philippines</a> and earning tokens from the game has become a viable source of income for players even <a href="https://www.playtoearn.online/2020/07/08/axie-infinity-beats-minimum-wage-in-many-countries/">beating minimum wage</a> in many countries. There is also a decentralized autonomous organization (DAO) called <a href="https://yieldguild.io/">Yield Guild Games</a> which leases Axies to players that want to get started with the game but don’t have the funds to purchase them. Several rare Axies were even <a href="https://www.delphidigital.io/reports/why-we-spent-159k-on-digital-battle-pets-2/">purchased</a> for $159,000 total.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/26353bcc-0d05-47ea-89ac-fcdc9d2dd848.jpeg" alt="Axie Infinity battle"></p><figcaption>Axie Infinity battle</figcaption></figure>
<p>There’s another popular game <a href="https://zkga.me/">Dark Forest</a> where you can explore different planets and collect Artifact NFTs on new planets, which give bonuses when attached to the planet. Being able to discover and collect these items or even win them in a battle and then trade them in decentralized marketplaces can make the game even more fun.</p>
<figure><p><img src="https://images.mirror-media.xyz/publication-images/be66b61a-05f0-46b7-aa8f-f7ed542d5cd3.jpeg" alt="Planet in Dark Forest which has an Artifact NFT"></p><figcaption>Planet in Dark Forest which has an Artifact NFT</figcaption></figure>
<p>One concern with making in-game items tradable is that the ability to trade items can negatively affect the gameplay as people are focused on …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d">https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d</a></em></p>]]>
            </description>
            <link>https://linda.mirror.xyz/df649d61efb92c910464a4e74ae213c4cab150b9cbcc4b7fb6090fc77881a95d</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073970</guid>
            <pubDate>Tue, 09 Feb 2021 04:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning an old Amazon Kindle into a eInk development platform]]>
            </title>
            <description>
<![CDATA[
Score 362 | Comments 87 (<a href="https://news.ycombinator.com/item?id=26073463">thread link</a>) | @miles
<br/>
February 8, 2021 | https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1721">

	

	
			<figure>
				<img width="998" height="1331" src="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=998" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg 998w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=225 225w, https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=768 768w" sizes="(max-width: 998px) 100vw, 998px" data-attachment-id="1751" data-permalink="https://blog.lidskialf.net/kindle_serial_magnified/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg" data-orig-size="998,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_serial_magnified" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=225" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_serial_magnified.jpg?w=768">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I fancied getting an eink screen to use for future projects. I bought a wee one with a raspberry pi “hat” attached. However, I realised later that I could maybe just re-purpose an old Amazon Kindle ebook reader.</p>



<p>I’ve messed with Kindles before, ages ago: I ported an <a href="https://blog.lidskialf.net/2010/10/09/kif-an-infocom-text-adventure-interpreter-for-the-kindle/">Infocom interpreter</a> and a <a href="https://blog.lidskialf.net/2010/10/20/mangle-a-better-manga-reader-for-the-kindle/">Manga</a> reader to it. I managed to get Amazon’s own software to load them as “Kindlets” and show them integrated into their ebook reader. However, now I just want a nice cheap Linux based eink development platform.</p>



<p>Cheap Kindle From Ebay (and why)</p>



<p>So, off to ebay I went! I saw a number of really cheap ones marked “BLOCKED BY AMAZON”; I decided not to go for these since theoretically they might have been stolen. In the end, I went for £7 Kindle 4 “non-touch”.</p>



<p>A few days later, it turned up. And I discovered <em>why</em> it might have been so cheap: its stuck in some sort of unquittable demo mode:</p>



<figure><img data-attachment-id="1725" data-permalink="https://blog.lidskialf.net/kindle_demo_mode/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg" data-orig-size="892,1239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_demo_mode" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=216" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737" src="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=737 737w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=108 108w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=216 216w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2021/02/kindle_demo_mode.jpg 892w" sizes="(max-width: 737px) 100vw, 737px"></figure>



<p>I did some googling and although it seems later Kindle versions can be un-demo-mode-ed, nothing seemed to work for this version. I don’t actually care though; I don’t want to run the original Kindle ebook software on this.</p>



<p>So, the next step is to gain access. Browsing the <a href="https://www.mobileread.com/forums/showthread.php?t=166687">mobileread forums</a> showed it has a debug serial port: time to open the case!</p>



<p>Physical Access Granted!</p>



<p>This was kinda tricky! There are multiple clips all round it and the case is glued onto the battery compartment, so judicious application of a Big Knife was required to persuade it to let go. I cleaned the glue up with some Acetone.</p>



<figure><img data-attachment-id="1729" data-permalink="https://blog.lidskialf.net/kindle_illustrated/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg" data-orig-size="998,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_illustrated" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=225" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768" src="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg?w=225 225w, https://adq454703481.files.wordpress.com/2021/02/kindle_illustrated.jpg 998w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<ul><li>Red: annoying clips</li><li>Purple: <strong>really</strong> annoying glue.</li><li>Yellow: the serial port!</li></ul>



<p>As usual for this sort of thing, the serial port is missing its socket, so we need to solder onto the tiny contacts on the board. I like to use ~0.2mm wirewrap wire for this sort of thing, and the surface mount rework bit for my soldering iron:</p>







<p>I don’t want to leave any wires flapping about, but I also know at some point I’m going to screw up and need serial port console access, so I came up with a solution and attached it:</p>







<p>I superglued a piece of Veroboard onto the kindle’s PCB, then soldered wirewrap wires from the tiny PCB contacts onto one end. Finally, I soldered a larger, more conventional “Dupont” cable socket on the other end so I could easily attach and detach from it. Oh, the top cable on the Kindle PCB is 0v/GND, the others are TX and RX (I forget the order of those two).</p>



<p>Final hurdle: the kindle serial port runs at 1.8v, so I needed a serial port adaptor which supports that:</p>



<figure><img data-attachment-id="1737" data-permalink="https://blog.lidskialf.net/kindle_usbserial/" data-orig-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg" data-orig-size="545,828" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kindle_usbserial" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=197" data-large-file="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=545" src="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=545" alt="" srcset="https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg 545w, https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=99 99w, https://adq454703481.files.wordpress.com/2021/02/kindle_usbserial.jpg?w=197 197w" sizes="(max-width: 545px) 100vw, 545px"></figure>



<p>The one I bought does 5v. 3.3v, 2.5v, and 1.8v: it’s pretty neat!</p>



<p>Root Access Granted!</p>



<p>Next, I attached the serial adapter to my laptop, ran the <strong>minicom</strong> serial port software and rebooted the Kindle. Then, once I (inevitably) swapped the TX and RX wires around, I was greeted by this!</p>



<pre><code>U-Boot 2009.08-lab126 (Aug 29 2012 - 12:55:24)

CPU:   Freescale i.MX50 family 1.1V at 800 MHz
mx50 pll1: 800MHz
mx50 pll2: 400MHz
mx50 pll3: 216MHz
ipg clock     : 50000000Hz
ipg per clock : 50000000Hz
uart clock    : 24000000Hz
ahb clock     : 100000000Hz
axi_a clock   : 400000000Hz
axi_b clock   : 200000000Hz
weim_clock    : 100000000Hz
ddr clock     : 800000000Hz
esdhc1 clock  : 80000000Hz
esdhc2 clock  : 80000000Hz
esdhc3 clock  : 80000000Hz
esdhc4 clock  : 80000000Hz
MMC:  FSL_ESDHC: 0, FSL_ESDHC: 1
Board: Tequila
Boot Reason: [POR]
Boot Device: MMC
Board Id: 0031701123730Z56
S/N: B02317022392005M
Initing MDDR memory
ZQ calibration complete: 0x128=0xfffe0010 0x12C=0xffffffff
DRAM:  256 MB
Using default environment

In:    serial
Out:   logbuff
Err:   logbuff
Quick Memory Test 0x70000000, 0x10000000
POST done in 13 ms
Hit any key to stop autoboot:  0 
## Booting kernel from Legacy Image at 70800000 ...
   Image Name:   Linux-2.6.31-rt11-lab126
   Image Type:   ARM Linux Kernel Image (uncompressed)
   Data Size:    4777568 Bytes =  4.6 MB
   Load Address: 70008000
   Entry Point:  70008000
   Verifying Checksum ... OK
   Loading Kernel Image ... OK
OK
Starting kernel ...

[snip]

Welcome to Kindle!

kindle login: </code></pre>



<p>Great, so that’s booting the uboot bootloader, then booting into linux and asking me to login.</p>



<p>Trying to login as root prompts for a password: Hmm… However, I already knew from previous Kindle stuff that you can generate the password from the serial number. I found <a href="https://www.sven.de/kindle/">this website</a> which generates a number of possible passwords for a specific device: Mine was the third on the list.</p>



<p>In case that site dies here’s the key snippet of Javascript:</p>



<pre><code>var md5 = hex_md5(serial);
document.getElementById("rootpw").innerHTML = "fiona" + md5.substring(7,11);
document.getElementById("rootpw2").innerHTML = "fiona" + md5.substring(7,10);
document.getElementById("rootpw3").innerHTML = "fiona" + md5.substr(13,3);</code></pre>



<p>Oh: I forgot to mention how I extracted the device’s serial number. Well, plugging it into USB doesn’t really “work”: you can’t mount these demo devices as disks. But, under linux, it still outputs the serial number in linux’s <strong>dmesg</strong> output (you can also get it using <strong>printenv</strong> in uboot if you press enter when it says “Hit any key to stop autoboot”):</p>



<pre><code>[128033.676587] usb 1-2: new high-speed USB device number 51 using xhci_hcd
[128033.829631] usb 1-2: New USB device found, idVendor=1949, idProduct=0004, bcdDevice= 1.00
[128033.829638] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3
[128033.829642] usb 1-2: Product: Amazon Kindle
[128033.829645] usb 1-2: Manufacturer: Amazon
[128033.829648] usb 1-2: SerialNumber: XXXXXXXXXXXXXXXX
</code></pre>



<p>Cool! We have root and can login! Now to figure out how to make it a bit easier to do stuff on it.</p>



<p>Dumping The System</p>



<p>First step is usually to dump the disks for analysis on another computer.</p>



<p>Checking <code>/proc/mounts</code> shows multiple partitions of the main disk on <code>/dev/mmcblk0</code>.</p>



<p>Running <code>fdisk /dev/mmcblk0</code> gives the following:</p>



<pre><code>Units = cylinders of 64 * 512 = 32768 bytes

        Device Boot      Start         End      Blocks  Id System
/dev/mmcblk0p1   *        1025       12224      358400  83 Linux
/dev/mmcblk0p2           12225       14272       65536  83 Linux
/dev/mmcblk0p3           14273       15296       32768  83 Linux
/dev/mmcblk0p4           15297       59776     1423360   b Win95 FAT32</code></pre>



<ul><li>So, four partitions, three linux, and one FAT32. </li><li>The first disk starts quite far into the disk: turns out the kernel is stored in that “missing” area. </li><li>Poking about a bit more shows partition 1 is the normal system, 2 is a sort of diagnostic tool partition, 3 is for storing internal private state of the kindle (eg wifi passwords). Finally, 4 is the one you see when you plug a kindle in over USB: its where your books would reside.</li><li>Partition 4 is mounted at /mnt/us.</li></ul>



<p>I dumped the start of the disk and partitions 1-3 onto /mnt/us using dd (I like to take a complete raw image if I can so I can restore it in case something goes wrong):</p>



<pre><code>dd if=/dev/mmcblk0 of=/mnt/us/kindle.img bs=32768 count=15297</code></pre>



<p>Although this Kindle doesn’t show a disk over USB, since I have root, I can simply make it do it:</p>



<pre><code>rmmod g_file_storage
modprobe g_file_storage file=/dev/mmcblk0p4</code></pre>



<p>It popped up on my laptop so I copied everything off.</p>



<p>System Analysis</p>



<p>Finally, I mounted the partitions in kindle.img on my laptop with:</p>



<pre><code>kpartx -v kindle.img</code></pre>



<p>I could then mount the individual partitions on my laptop. I extracted all the files into a folder so I could poke around them and grep them easily. I figured out:</p>



<ul><li>It uses <code>rc.d</code> as its system init system, so there are lots of nice plain text scripts.</li><li>Init level 5 is the “normal” system running the ebook software</li><li>The ebook software is in <code>/opt/amazon</code> and is in Java (I kinda already knew this, but needed a quick refresher).</li><li>There’s a whole load of interesting plain text “diag” scripts for testing.</li><li>There’s a rather nifty <code>wifid</code> daemon for managing the wifi connection: I figured out how to talk to this from the diag scripts.</li><li>You can write to the eink screen from the command line using the <code>/usr/sbin/eips</code> command (<a href="https://wiki.mobileread.com/wiki/Eips">docs here</a>).</li><li>I couldn’t find an obvious “turn off demo mode” switch: it appears the demo mode is a customised build of the Java ebook software.</li><li>The following system services are to do with unsupported features, the ebook software, or talking back to amazon: <code>S50wan S70wand S75phd S81usbnetd S93webreaderd S94browserd S95framework S96boot_finished</code>.</li></ul>



<p>Talking To Wifid</p>



<p>You can use the built in wifid to connect to wifi and manage your wifi profiles. Oh, also, remember many Kindles only support 2.4Ghz wifi when you wonder why it isn’t working 😉</p>



<p><strong>List number of WIFI profiles:</strong></p>



<p><code>lipc-get-prop com.lab126.wifid profileCount</code></p>



<p><strong>Show contents of a WIFI profile:</strong></p>



<p><code>echo "{index=(0)}" | lipc-hash-prop com.lab126.wifid profileData</code></p>



<p><strong>Delete a WIFI profile:</strong></p>



<p><code>lipc-set-prop com.lab126.wifid deleteProfile WIFIESSID</code></p>



<p><strong>Create a WIFI profile:</strong></p>



<p><code>echo '{essid="WIFIESSID", smethod="wpa2", secured="yes", psk="WIFIPSK"}' | lipc-hash-prop com.lab126.wifid createProfile</code></p>



<p>smethod can be one of open,wep,wpa,wpa2 (if you choose open, set secured to “no”)</p>



<p>WIFIPSK is the WIFI PSK as generated with the <code>wpa_passphrase</code> utility (which is actually on the kindle): a normal “wifi passphrase” will not work.</p>



<p><strong>Connect a WIFI profile:</strong></p>



<p><code>lipc-set-prop com.lab126.wifid cmConnect WIFIESSID</code></p>



<p><strong>Show WIFI connection status:</strong></p>



<p><code>echo "{index = (0)}" | lipc-hash-prop -n com.lab126.wifid currentEssid</code></p>



<p>Making Changes To Root</p>



<p>Many of the following instructions need to change the root disk on the kindle. However, by default it is mounted in read only mode, preventing modification. To fix, run this command on the kindle:</p>



<pre><code>mntroot rw</code></pre>



<p>When done, set it back to read only mode to prevent any unwanted changes:</p>



<pre><code>mntroot ro</code></pre>



<p>Installing Dropbear SSH</p>



<p>I wanted to be able to ssh into my kindle, so I needed to install the <a href="https://matt.ucc.asn.au/dropbear/dropbear.html">dropbear</a> ssh daemon. Of course this is an ARM based device, so I either had to compile it myself or find it somewhere. Luckily …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/">https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/</a></em></p>]]>
            </description>
            <link>https://blog.lidskialf.net/2021/02/08/turning-an-old-kindle-into-a-eink-development-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26073463</guid>
            <pubDate>Tue, 09 Feb 2021 03:21:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't want to do front-end anymore]]>
            </title>
            <description>
<![CDATA[
Score 387 | Comments 372 (<a href="https://news.ycombinator.com/item?id=26071906">thread link</a>) | @askonomm
<br/>
February 8, 2021 | https://www.askonomm.com/blog/i-dont-want-to-do-frontend-anymore | <a href="https://web.archive.org/web/*/https://www.askonomm.com/blog/i-dont-want-to-do-frontend-anymore">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I started coding when I was 14, around 2007 or so. The very first thing I wrote was HTML, then CSS. I liked
making stupid little web pages containing youtube embeds and guest books (anyone remembers those?) full of
<a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/marquee">marquees</a>, <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/blink">blinks</a>
and gifs. Lots of gifs. The pages were very simple, but joyful to make and also to use. At the time I had no idea that
you could make any money with making web pages, I simply thought it was a silly hobby people could have.</p>
<p>Fast-forward 3 years I got my first few gigs as a web developer. By then I was pretty good at HTML and CSS already,
had dabbled enough with PHP to know my way around of most sticky problems I would find myself in and while I didn't
really know much of vanilla JavaScript, it was okay, because everyone used almost exclusively <a href="https://jquery.com/">jQuery</a> anyway. Yet still,
the websites were rather simple and joyful to make.</p>
<p>It was easy to get started, too - you just created the files and refreshed the page. HTML? PHP? JavaScript? Just create the
file and save it, then refresh the browser. Rinse and repeat until you are happy with the result. But then, almost
out of nowhere, something changed. At first, it came slowly and before it could even speed up, it was already here.
<strong>The complicated web was here</strong>.</p>
<p>Nowadays I make a living mainly with JavaScript and TypeScript using React.js as a front-end framework. That's right,
front-ends are so complex they now need frameworks to be able to manage their seemingly infinite component hierarchies.
JavaScript no longer is liked by the community, so the community created a poor man's version of a typed language which
duct-tapes around an <a href="https://whydoesitsuck.com/why-does-javascript-suck/">already poorly made language</a>. </p>
<p>Starting a new project? Make sure to write your project idea down because by the time you are finished setting up the vast
boilerplate you have probably forgotten it. Vast boilerplate? Oh yeah, you better set-up your project with <a href="https://www.typescriptlang.org/">TypeScript</a>,
<a href="https://eslint.org/">ESlint</a>, <a href="https://webpack.js.org/">Webpack</a> and <a href="https://babeljs.io/">Babel</a>, because
if you don't then obviously you haven't learned anything since 2005 and suck. Don't have <a href="https://www.npmjs.com/">NPM</a>? Better install that, too,
because nobody installs libraries without a package manager anymore. Oh and while you're at it, install also <a href="https://yarnpkg.com/">Yarn</a>,
because why not make use of two package managers at the same time. <em>Phew</em>, you did all that? Damn, that's commitment!
You can finally write what is essentially just HTML and JavaScript!</p>
<p>Now, don't forget we also want to style our project, but if you thought you could get away with writing good ol' CSS,
you were wrong. We no longer write CSS, because it's lame. We now write <a href="https://sass-lang.com/">SCSS</a> instead,
so that we could write dynamic stylesheets that convert to CSS, because <a href="https://hospodarets.com/you-might-not-need-a-css-preprocessor">of course 99% of the web needs that</a>. </p>
<p>But enough of the hating. If I wanted I could hate on anything most likely, and the web has come a long way since 2007,
in lots of good ways, and I don't want to discredit that. I suppose with the increase of complexity in what we want to
achieve on the web the stack to achieve it with has had to also increase in complexity. For me, personally, it's
too much. I want to have a personal life and not have to spend my nights reading up on some new flavour of *.js in
fear that if I don't I would soon be made irrelevant. I don't want to learn nor use a million different tools. I don't want
to know a bit about everything and a lot about nothing. </p>
<p>Thus, I don't want to do front-end development anymore. The joy is gone. I've given in my resignation at my current place of
employment and will be seeking an exclusively back-end role for my next adventure, starting April. The language doesn't
matter much to me, I know enough of them to know that they are all very similar and thus easy enough to learn. If you know of a
good opportunity, <a href="mailto:asko@askonomm.com">let me know</a>.</p></div></div>]]>
            </description>
            <link>https://www.askonomm.com/blog/i-dont-want-to-do-frontend-anymore</link>
            <guid isPermaLink="false">hacker-news-small-sites-26071906</guid>
            <pubDate>Mon, 08 Feb 2021 23:40:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's an SPF Record?]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 45 (<a href="https://news.ycombinator.com/item?id=26071103">thread link</a>) | @albertgoeswoof
<br/>
February 8, 2021 | https://blog.ohmysmtp.com/blog/whats-an-spf-record/ | <a href="https://web.archive.org/web/*/https://blog.ohmysmtp.com/blog/whats-an-spf-record/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>February 08, 2021</p><p>A Sender Policy Framework (SPF) record is a piece of text that you can add to your Domain Name System (DNS). It tells email clients (such as Gmail or Outlook) who can send email from your domain, and those clients can check each email received against this record to see if it is likely to be spam or forged.</p><h2>Background</h2><p>SPAM has been sloshing around on the internet since forever (well <a href="https://www.themarysue.com/first-spam-email/">since 1978, apparently</a>, and so have methods to fight it. SPF is a neat way to help prevent your domain name from being abused for appearing to send spam or forged emails.</p><p>The thing with email is that anyone can pretend to send emails from anyone else, there’s nothing in the specifications that prevent this. To impersonate someone, all you have to do is change the <code>From</code> email header to say it came from them. To make matters worse, emails are handed between lots of different servers when being sent, and are rarely encrypted to prevent modifications en-route.</p><p>Why is this allowed? Well email is really, really old! No one designing email could have possibly anticipated the kind of spam we see today, and computers just didn’t have the power or resources to do complex cryptography and a gazillion network requests back in the day.</p><p>Fortunately there are some technologies (including SPF) that work together to help validate that an email has come from the person/place it claims to have come from.</p><h2>So how do SPF records help prevent spam?</h2><p>An SPF record says which mail servers are allowed to send email on your behalf. So when an email arrives from a particular server, the receiving server can look up the SPF record of the domain in the <code>From</code> field and validate that the server is allowed to send email for that specific Domain.</p><p>If no match is found, then depending on the SPF policy in the record, the email will be marked as spam, outright rejected or have its spam score lowered. </p><p>Without SPF there would be no way to check that the server that sent an email is actually allowed to send emails for the domain. By adding an SPF record you’re telling the world that this particular IP, service or set of IPs is allowed to send email for that domain.</p><h2>What does an SPF record look like?</h2><p>Here’s a simple record:</p><pre data-language="" data-index="0"><code><span>v=spf1 ip4:192.168.0.1 ~all</span></code></pre><p>Let’s break it down:</p><ul><li><code>v=spf1</code> tells whoever is looking this up that this is an SPF record, and it’s a Version 1 record. There’s only one version at present, so this will always be the same for the forseeable future</li><li><code>ip4:192.168.0.1</code> is an IP address that’s allowed to send emails from this domain. You can list multiple IPs here by including a space between them, add ranges or even full domains</li><li><code>~</code> is one of four <em>qualifiers</em> which tells the email client how to mark an email that matches the term to the right (in this case <code>all</code>). The options are pass (+), fail (-), softfail (~) or neutral (?) - using these allows you to do things like whitelist or blacklist addresses, or completely disable all emails from a given domain</li><li><code>all</code> simply says match all emails</li></ul><p>Email clients will evaluate this record <strong>from left to right</strong>, looking for a match against the IP address that the email actually originated from. So if an email came from 192.168.0.1 it will match this record and pass SPF, but if it didn’t arrive from there it will match <code>all</code> and be marked as a softfail (because of the <code>~</code>). Softfail means that the email should not be rejected for this reason alone, but it will be factored into the spam score.</p><p>To add this to your DNS record, open up your domain registrar or DNS management console, and add a new <code>TXT</code> record with the text as your content. If you’re using a service to send emails on your behalf your email service provider will give you the exact record details you need, if you’re sending emails from your own server you’ll need to craft your own record, you can use <a href="https://tools.ietf.org/html/rfc7208">RFC7208</a> as a reference to get it perfect.</p><p>Easy-peasy lemon squeezy!</p><h2>Why don’t you need to setup an SPF record with OhMySMTP?</h2><p>The good news is that you don’t need to know any of this or do anything to use OhMySMTP and have your emails pass SPF validation.</p><p>We set a specific header in the email called <code>Return-Path</code> with all emails sent through our email service. If you take a peek at a raw email sent over OhMySMTP you’ll find that the return path ends in <code>@mailer.ohmysmtp.com</code>, and if you look this up in the DNS system, you’ll find an SPF record that points to our server IP address.</p><p>Luckily email clients accept the return path header as the source of the email, so SPF checks pass on all our emails. without our users needing to do anything.</p><h2>Other technologies and further reading</h2><p>If you want to learn everything there is to know about SPF, you can read the RFC (“Request For Comments”, basically the SPF specification) here: <a href="https://tools.ietf.org/html/rfc7208">https://tools.ietf.org/html/rfc7208</a></p><p>But SPF alone doesn’t completely solve spam, we also need DKIM, and to a lesser extent DMARC. More on those later!</p><hr><ul><li><a rel="prev" href="https://blog.ohmysmtp.com/blog/send-emails-over-smtp/">← <!-- -->Send emails over SMTP with OhMySMTP.com</a></li><li></li></ul></div></div>]]>
            </description>
            <link>https://blog.ohmysmtp.com/blog/whats-an-spf-record/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26071103</guid>
            <pubDate>Mon, 08 Feb 2021 22:26:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla spent $1.5B in clean car credits on Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 153 (<a href="https://news.ycombinator.com/item?id=26070744">thread link</a>) | @ForHackernews
<br/>
February 8, 2021 | https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5855">
		<div>
		
<p>Tesla bought $1.5 billion worth of bitcoin, the company said in a <a rel="noreferrer noopener" href="https://secfilings.nasdaq.com/filingFrameset.asp?FilingID=14678414&amp;RcvdDate=2/8/2021&amp;CoName=TESLA,%20INC.&amp;FormType=10-K&amp;View=html" target="_blank">regulatory filing</a> on Monday, effectively putting nearly all of the money it earned on clean car credits towards the world’s filthiest asset. </p>



<p>Where to begin? Let’s start with the firm’s SEC filing. As of January 2021, the Silicon Valley-based company updated its investment policy to allow it more flexibility in diversifying its returns on cash. Those changes allow Tesla to buy bitcoin and other cryptocurrencies, which it immediately did.</p>



<p>“Thereafter, we invested an aggregate $1.50 billion in bitcoin under this policy and may acquire and hold digital assets from time to time or long-term. Moreover, we expect to begin accepting bitcoin as a form of payment for our products in the near future, subject to applicable laws and initially on a limited basis, which we may or may not liquidate upon receipt.”</p>



<p>The filing does not say how Tesla bought the bitcoin or how they are custodying it. It also does not tell us how many bitcoin it purchased or for what average price. We only know Tesla bought bitcoin sometime between Jan. 1 and early February, when the price was between $30,000 to $41,000.&nbsp;</p>



<p>Tesla says its customers will be able to buy its vehicles with bitcoin. However, “liquidate upon receipt” means that if you purchase a Tesla with bitcoins, the company is likely to sell those bitcoins for cash immediately, something that is usually done by sending the funds through a payment processor first. </p>



<p>This is what most large merchants do when they say they are accepting bitcoin. They convert it to cash, so they don’t have to deal with bitcoin’s wild volatility. So if you buy a Tesla with bitcoin in the future, it will likely be the same as selling your bitcoin for fiat and then handing the cash over to Tesla. </p>



<h2>Clean car credits for bitcoin</h2>



<p>Tesla earns tradable credits under various regulations related to zero-emission vehicles, greenhouse gas, fuel economy, renewable energy, and clean fuel. It then turns around and sells those credits to other automakers when they can’t comply with auto emissions and fuel economy standards.</p>



<p>In 2020, Tesla reported making $1.58 billion in selling these tradable credits it received. And here is the important bit: without those tradeable credits, the company would not have been profitable. <a href="https://apnews.com/article/coronavirus-pandemic-67705113fb4f895bd051a1bee1d23518" target="_blank" rel="noreferrer noopener">Tesla would have lost money.</a> So what does it do with that money? It turns around and buys bitcoin. </p>



<p>Bitcoin is an environmental disaster. The bitcoin network currently burns around 116.87 terawatt-hours per year, according to the <a href="https://cbeci.org/">University of Cambridge’s Centre for Alternative Finance.</a> To give you an idea of how devastating that is to our climate, that is as much energy as a small country or <a href="https://news.bitcoin.com/the-bitcoin-network-now-consumes-7-nuclear-plants-worth-of-power/#:~:text=The%20Cambridge%20Bitcoin%20Electricity%20Consumption%20Index%20(CBECI)%20shows%20the%20estimated,is%207.46%20gigawatts%20(GW).&amp;text=The%20amount%20of%20power%20consumed,photovoltaic%20(PV)%20solar%20panels." target="_blank" rel="noreferrer noopener">seven nuclear power plants. </a></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Bitcoin is such an environmental disaster it really is a crime against humanity.  So what does Tesla do with their $1.5B in revenue last year from clean car credits sold to other automakers?  Put it into “Destroy the Planet Inc”</p>— Nicholas Weaver (@ncweaver) <a href="https://twitter.com/ncweaver/status/1358780808144723968?ref_src=twsrc%5Etfw">February 8, 2021</a></blockquote></div>
</div></figure>



<p>Keep in mind, bitcoin’s energy consumption increases right alongside the price of bitcoin. As bitcoin goes up in price, more people want to mine the virtual currency for profit, leading to greater energy consumption as they pile more money into power-hungry ASIC rigs.</p>



<p>Bitcoin is not only filthy for its energy waste but also because it is the currency of choice in underground economies. <a href="https://www.forbes.com/sites/andreatinianow/2020/07/01/bitcoin-demand-drives-14-billion-ransomware-industry-in-the-us/?sh=40346fca32d8" target="_blank" rel="noreferrer noopener">Ransomware</a> would probably not exist if it were not for bitcoin. </p>



<p>And bitcoin fits the very definition of <a rel="noreferrer noopener" href="https://www.ic.unicamp.br/~stolfi/bitcoin/2020-12-31-bitcoin-ponzi.html" target="_blank">a Ponzi scheme.</a> It has no intrinsic value—any money new investors put into the system immediately goes out via bitcoin miners selling their 900 newly minted bitcoin per day. Tesla’s massive influx of cash will fund the bitcoin miners for about a month and a half, at most. </p>



<h2>Elon Musk shilling crypto</h2>



<p>Two years ago, Musk and Tesla paid a combined <a rel="noreferrer noopener" href="https://www.sec.gov/news/press-release/2018-226" target="_blank">$40 million penalty</a> to the SEC after Musk’s cryptic tweets about taking Tesla private led to stock fluctuations. The regulator <a href="https://www.sec.gov/litigation/complaints/2018/comp-pr2018-219.pdf">charged him</a> with securities fraud. As part of the settlement, Musk agreed to step down as chairman of the company, although he continued to hold the title of CEO. </p>



<p>Apparently, Musk has learned nothing from that experience. Last month, presumably around the time Tesla was buying up hoards of bitcoin unbeknownst to the general public, Musk caused the price of bitcoin to go up 20% when he <a rel="noreferrer noopener" href="https://www.cnbc.com/2021/01/29/bitcoin-spikes-20percent-after-elon-musk-adds-bitcoin-to-his-twitter-bio.html" target="_blank">changed his&nbsp;Twitter bio</a>&nbsp;to include the word “bitcoin.”</p>



<p>Soon after changing the bio, Musk said in a&nbsp;<a rel="noreferrer noopener" href="https://twitter.com/elonmusk/status/1355068728128516101" target="_blank">tweet:</a> “In retrospect, it was inevitable.” In retrospect, that tweet looks like an early hint that Tesla was funneling money into the digital asset.  </p>



<figure><div>

</div></figure>



<p>Will Musk get into trouble for his bitcoin tweets? </p>



<p>It is unlikely, Columbia University Law Professor John Coffee, Jr., told the <a href="https://www.wsj.com/articles/tesla-buys-1-5-billion-in-bitcoin-11612791688">Wall Street Journal</a>, especially given that a federal judge rebuked the SEC when it sought to hold Musk in contempt in 2019. “I don’t think the commission would dare push it that far,” he said. </p>



<p>The latest Tesla news caused bitcoin to spike 18% this morning, <a rel="noreferrer noopener" href="https://www.cnbc.com/2021/02/08/bitcoin-surges-above-43000-to-a-record-after-elon-musks-tesla-buys-1point5-billion.html" target="_blank">sending the price to over $44,000,</a> and setting a new all-time high. </p>



<p><em>Updates Feb. 8: Bitcoin topped $44,000 on Monday, even higher than the $43,000 I mentioned earlier. I added that in the SEC settlement Musk agreed to step down as chairman of Tesla. And I added the Coffee quote from WSJ.</em></p>



<p><em>If you like my work, please support my writing by subscribing to my&nbsp;<a rel="noreferrer noopener" href="https://www.patreon.com/amycastor" target="_blank">Patreon account</a>&nbsp;for as little as $5 a month.&nbsp; </em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26070744</guid>
            <pubDate>Mon, 08 Feb 2021 21:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Clerk – all of user management as-a-service, not just authentication]]>
            </title>
            <description>
<![CDATA[
Score 566 | Comments 222 (<a href="https://news.ycombinator.com/item?id=26069621">thread link</a>) | @colinclerk
<br/>
February 8, 2021 | https://clerk.dev/blog/all-of-user-management-not-just-authentication | <a href="https://web.archive.org/web/*/https://clerk.dev/blog/all-of-user-management-not-just-authentication">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><br>While working on side projects, we've always felt that adding <strong>great</strong> user management was too complex and too cumbersome.</p><p>The task came with a sense of helplessness. We knew what "great" looked like, but it was impractical to build all of that functionality.<br></p><figure id="w-node-a41d4bea-17b7-40a7-4d5c-8c6e66f6adf6-12ab58b9"><p><img src="https://uploads-ssl.webflow.com/5fd7bfc6e6f1ce2fd6ab58c5/6019dfd34486031760de5797_blog-google.png" loading="lazy" alt=""></p><figcaption>Google user management</figcaption></figure><p>We thought authentication-as-a-service vendors might ease our pain, but over and over again, we were disappointed by how much extra work was necessary. We never understood why until one friend quipped, <em>"auth-as-a-service really just solves half of 2-factor auth."</em></p><p>Then it clicked. <strong>We needed all of user management, not <em>just</em> authentication. </strong>And we realized if we could solve this problem, countless others could benefit, too.</p><p>Today, we're absolutely thrilled to launch Clerk: <strong>user management as-a-service</strong>. We're solving the whole problem, from frontend to backend, with beautiful UIs and elegant APIs. Our architecture pulls user management out of the way, so developers can focus on what makes their software truly special.</p><figure id="w-node-_139be728-0c3f-7abd-62db-458a61e69a47-12ab58b9"><p><img src="https://uploads-ssl.webflow.com/5fd7bfc6e6f1ce2fd6ab58c5/6019dff6fd671523538092e1_blog-clerk.png" loading="lazy" alt=""></p><figcaption>Clerk user management</figcaption></figure><p>Our launch today includes UI components for Sign Up, Sign In, User Profile, and what we're calling the "User Button." They can be mounted directly in your application, or you can redirect users to a Clerk-hosted page on <strong>accounts.yourdomain.com</strong>.</p><p>Best of all, the components will automatically update as our team optimizes their design, develops new features, and adds support for the latest in account security.</p><p>While today marks an exciting milestone for Clerk, this is truly just a "minimum viable product." The roadmap ahead will bring many features to better support developers and their end users:</p><ul role="list"><li>SDKs for additional languages and frameworks</li><li>Additional OpenID Connect and OAuth providers</li><li>Additional 2-step verification factors like TOTP and WebAuthN</li><li>Session management and revocation in the User Profile</li><li>Team management and enterprise authentication like SAML</li></ul><p>Need help with something you don't see listed? <a href="https://dashboard.clerk.dev/feedback">Make a request.</a></p></div></div>]]>
            </description>
            <link>https://clerk.dev/blog/all-of-user-management-not-just-authentication</link>
            <guid isPermaLink="false">hacker-news-small-sites-26069621</guid>
            <pubDate>Mon, 08 Feb 2021 20:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists develop transparent wood that is stronger and lighter than glass]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 29 (<a href="https://news.ycombinator.com/item?id=26068435">thread link</a>) | @ooboe
<br/>
February 8, 2021 | https://www.cbc.ca/radio/quirks/scientists-develop-transparent-wood-that-is-stronger-and-lighter-than-glass-1.5902739 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/quirks/scientists-develop-transparent-wood-that-is-stronger-and-lighter-than-glass-1.5902739">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Bob McDonald's blog: A simple backyard procedure results in see-through wood with enormous potential as a building material.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5902788.1612553036!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/transparent-wood-university-of-maryland.jpg"></p></div><figcaption>A flower is visible behind a piece of the transparent material.<!-- --> <!-- -->(Qinqin Xia, University of Maryland/Science Advances)</figcaption></figure><p><span><p>Researchers at the University of Maryland have turned ordinary sheets of wood into <a href="https://advances.sciencemag.org/content/7/5/eabd7342" target="_blank"><u>transparent material</u></a> that is nearly as clear as glass, but stronger and with better insulating properties. It could become an energy efficient building material in the future.</p>  <p>Wood is made of two basic ingredients: cellulose, which are tiny fibres, and lignin, which bonds those fibres together to give it strength.</p>  <p>Tear a paper towel in half and look closely along the edge. You will see the little cellulose fibres sticking up. Lignin is a glue-like material that bonds the fibres together, a little like the plastic resin in fibreglass or carbon fibre. The lignin also contains molecules called chromophores, which give the wood its brown colour and prevent light from passing through.</p>  <p>Early attempts to make transparent wood involved removing the lignin, but this involved hazardous chemicals, high temperatures and a lot of time, making the product expensive and somewhat brittle. The new technique is so cheap and easy it could literally be done in a backyard.</p>  <p>Starting with planks of wood a metre long and one millimetre thick, the scientists simply brushed on a solution of hydrogen peroxide using an ordinary paint brush. When left in the sun, or under a UV lamp for an hour or so, the peroxide bleached out the brown chromophores but left the lignin intact, so the wood turned white.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transparent-wood-university-of-maryland.jpg 300w,https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transparent-wood-university-of-maryland.jpg 460w,https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transparent-wood-university-of-maryland.jpg 620w,https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-university-of-maryland.jpg 780w,https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transparent-wood-university-of-maryland.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5902789.1612553066!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-university-of-maryland.jpg"></p></div><figcaption>Researchers demonstrated after brushing a coat of hydrogen peroxide on the opaque wood material, and exposing it to one hour of sunlight, it turns transparent.<!-- --> <!-- -->(Qinqin Xia, University of Maryland/Science Advances)</figcaption></figure></span></p>  <p>Next, they infused the wood with a tough transparent epoxy designed for marine use, which filled in the spaces and pores in the wood and then hardened.&nbsp;This made the white wood transparent.</p>  <p>You can see a similar effect by taking that same piece of paper towel, dip half of it in water and place it on a patterned surface.&nbsp;The white paper towel will become translucent with light passing through the water and cellulose fibres without being scattered by refraction.</p>  <p>The epoxy in the wood does an even better job, allowing 90 per cent of visible light to pass through. The result is a long piece of what looks like glass, with the strength and flexibility of wood.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transparent-wood-usda-forest-service-jpg.jpg 300w,https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transparent-wood-usda-forest-service-jpg.jpg 460w,https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transparent-wood-usda-forest-service-jpg.jpg 620w,https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-usda-forest-service-jpg.jpg 780w,https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transparent-wood-usda-forest-service-jpg.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5902790.1612552994!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-usda-forest-service-jpg.jpg"></p></div><figcaption>A researcher holds up a square of transparent wood material against a green leaf.<!-- --> <!-- -->(USDA Forest Service)</figcaption></figure></span></p>  <p>As window material, it would be much more resistant to accidental breakage. The clear wood&nbsp;is lighter than glass, with better insulating properties, which is important because windows are a major source of heat loss in buildings. It also might take less energy to manufacture clear wood because there are no high temperatures involved.</p>  <p>Transparent wood could become an alternative to glass in energy efficient buildings, or perhaps coverings for solar panels in harsh environments. There could be no end of uses.</p>      <p>Many different types of wood, from balsa to oak, can be made transparent, and it doesn't matter if it is cut along the grain or against it. If the transparent wood is made a little thicker, it would be strong enough to become part of the structure of a building, so there could be entire transparent wooden walls.</p>  <p>While this technology has yet to&nbsp; be scaled up to industrial levels, the researchers say it has great potential as a new building material. In fact, they say that theoretically, an entire house could be made transparent. It is not clear why anyone would want to live in a transparent house, but for people who do, it would be OK to throw stones…</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transparent-wood-qinqin-xia-university-of-maryland.jpg 300w,https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transparent-wood-qinqin-xia-university-of-maryland.jpg 460w,https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transparent-wood-qinqin-xia-university-of-maryland.jpg 620w,https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-qinqin-xia-university-of-maryland.jpg 780w,https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transparent-wood-qinqin-xia-university-of-maryland.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5902787.1612553101!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transparent-wood-qinqin-xia-university-of-maryland.jpg"></p></div><figcaption>A researcher holds up a 10-centimetre long slab of the see-through wood.<!-- --> <!-- -->(Qinqin Xia, University of Maryland/Science Advances)</figcaption></figure></span></p>  <p>Images copyright Xia et al.&nbsp;<a href="https://creativecommons.org/licenses/by-nc/4.0/" rel="license">Creative Commons Attribution-NonCommercial license</a>,&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/quirks/scientists-develop-transparent-wood-that-is-stronger-and-lighter-than-glass-1.5902739</link>
            <guid isPermaLink="false">hacker-news-small-sites-26068435</guid>
            <pubDate>Mon, 08 Feb 2021 18:50:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic differentiation does incur truncation errors (kinda)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 42 (<a href="https://news.ycombinator.com/item?id=26068382">thread link</a>) | @oxinabox
<br/>
February 8, 2021 | https://www.oxinabox.net/2021/02/08/AD-truncation-error.html | <a href="https://web.archive.org/web/*/https://www.oxinabox.net/2021/02/08/AD-truncation-error.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content">
      <p>Griewank and Walther’s 0th Rule of algorithmic differentiation (AD) states:</p>

<blockquote>
  <p>Algorithmic differentiation does not incur truncation error.</p>
</blockquote>

<p>(<a href="https://dl.acm.org/doi/book/10.5555/1455489">2008, “Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation”, Andreas Griewank and Andrea Walther.</a>)</p>

<p>In this blog post I will show you a case that looks like it does in fact incur truncation error.
Though this case will arguably be a misinterpretation of that rule.
This blog post will thus highlight why careful interpretation of the rule is necessary.
Further it will motivate why we need to often add more custom sensitivity rules (custom primitives) to our AD systems, even though you can AD anything with just a few basic rules.</p>

<p>Credit to <a href="https://mikeinnes.github.io/">Mike Innes</a> who pointed this out to me at JuliaCon 2018.
<!--more--></p>



<p>We will start by implementing a simple forwards mode AD.
This implementation is based on <a href="https://juliadiff.org/ChainRulesCore.jl/dev/autodiff/operator_overloading.html#ForwardDiffZero">ForwardDiffZero from the ChainRules docs.</a>, but without ChainRules support.
Though it is also the simplest most stock-standard implementation once can conceive of.</p>

<div><div><pre><code><span>struct</span><span> Dual</span> <span>&lt;:</span> <span>Number</span>
    <span>primal</span><span>::</span><span>Float64</span>
    <span>partial</span><span>::</span><span>Float64</span>
<span>end</span>

<span>primal</span><span>(</span><span>d</span><span>::</span><span>Dual</span><span>)</span> <span>=</span> <span>d</span><span>.</span><span>primal</span>
<span>partial</span><span>(</span><span>d</span><span>::</span><span>Dual</span><span>)</span> <span>=</span> <span>d</span><span>.</span><span>partial</span>

<span>primal</span><span>(</span><span>d</span><span>::</span><span>Number</span><span>)</span> <span>=</span> <span>d</span>
<span>partial</span><span>(</span><span>d</span><span>::</span><span>Number</span><span>)</span> <span>=</span> <span>0.0</span>

<span>function</span><span> Base.:+</span><span>(</span><span>a</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>},</span> <span>b</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>})</span> <span>where</span> <span>T</span><span>&lt;:</span><span>Real</span>
    <span>return</span> <span>Dual</span><span>(</span><span>primal</span><span>(</span><span>a</span><span>)</span><span>+</span><span>primal</span><span>(</span><span>b</span><span>),</span> <span>partial</span><span>(</span><span>a</span><span>)</span><span>+</span><span>partial</span><span>(</span><span>b</span><span>))</span>
<span>end</span>

<span>function</span><span> Base.:</span><span>-</span><span>(</span><span>a</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>},</span> <span>b</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>})</span> <span>where</span> <span>T</span><span>&lt;:</span><span>Real</span>
    <span>return</span> <span>Dual</span><span>(</span><span>primal</span><span>(</span><span>a</span><span>)</span><span>-</span><span>primal</span><span>(</span><span>b</span><span>),</span> <span>partial</span><span>(</span><span>a</span><span>)</span><span>-</span><span>partial</span><span>(</span><span>b</span><span>))</span>
<span>end</span>

<span>function</span><span> Base.:*</span><span>(</span><span>a</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>},</span> <span>b</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>})</span> <span>where</span> <span>T</span><span>&lt;:</span><span>Real</span>
    <span>return</span> <span>Dual</span><span>(</span>
        <span>primal</span><span>(</span><span>a</span><span>)</span><span>*</span><span>primal</span><span>(</span><span>b</span><span>),</span>
        <span>partial</span><span>(</span><span>a</span><span>)</span><span>*</span><span>primal</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>primal</span><span>(</span><span>a</span><span>)</span><span>*</span><span>partial</span><span>(</span><span>b</span><span>)</span>
    <span>)</span>
<span>end</span>

<span>function</span><span> Base.:/</span><span>(</span><span>a</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>},</span> <span>b</span><span>::</span><span>Union</span><span>{</span><span>Dual</span><span>,</span> <span>T</span><span>})</span> <span>where</span> <span>T</span><span>&lt;:</span><span>Real</span>
    <span>return</span> <span>Dual</span><span>(</span>
        <span>primal</span><span>(</span><span>a</span><span>)</span><span>/</span><span>primal</span><span>(</span><span>b</span><span>),</span>
        <span>(</span><span>partial</span><span>(</span><span>a</span><span>)</span><span>*</span><span>primal</span><span>(</span><span>b</span><span>)</span> <span>-</span> <span>primal</span><span>(</span><span>a</span><span>)</span><span>*</span><span>partial</span><span>(</span><span>b</span><span>))</span> <span>/</span> <span>primal</span><span>(</span><span>b</span><span>)</span><span>^</span><span>2</span>
    <span>)</span>
<span>end</span>

<span># needed for `^` to work from having `*` defined</span>
<span>Base</span><span>.</span><span>to_power_type</span><span>(</span><span>x</span><span>::</span><span>Dual</span><span>)</span> <span>=</span> <span>x</span>


<span>"Do a calculus. `f` should have a single input."</span>
<span>function</span><span> derv</span><span>(</span><span>f</span><span>,</span> <span>arg</span><span>)</span>
    <span>duals</span> <span>=</span> <span>Dual</span><span>(</span><span>arg</span><span>,</span> <span>1.0</span><span>)</span>
    <span>return</span> <span>partial</span><span>(</span><span>f</span><span>(</span><span>duals</span><span>...</span><span>))</span>
<span>end</span>
</code></pre></div></div>

<p>We can try out this AD and see that it works.</p>
<div><div><pre><code><span>julia</span><span>&gt;</span> <span>foo</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>x</span><span>^</span><span>3</span> <span>+</span> <span>x</span><span>^</span><span>2</span> <span>+</span> <span>1</span><span>;</span>

<span>julia</span><span>&gt;</span> <span>derv</span><span>(</span><span>foo</span><span>,</span> <span>20.0</span><span>)</span>
<span>1240.0</span>

<span>julia</span><span>&gt;</span> <span>3</span><span>*</span><span>(</span><span>20.0</span><span>)</span><span>^</span><span>2</span> <span>+</span> <span>2</span><span>*</span><span>(</span><span>20.0</span><span>)</span>
<span>1240.0</span>
</code></pre></div></div>

<h2 id="2-implement-sin-and-cos-for-demonstration-purposes">2. Implement Sin and Cos, for demonstration purposes</h2>

<p>Now we are going to implement the <code>sin</code> and <code>cos</code> functions for demonstration purposes.
<a href="https://github.com/JuliaLang/julia/blob/v1.5.3/base/special/trig.jl">JuliaLang has an implementation of <code>sin</code> and <code>cos</code> in Julia</a>, that could be ADed though by a source to source AD (like <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>).
But because it is restricted to <code>Float32</code> and <code>Float64</code> an operator overloading AD like ours can’t be used with it.
That’s Ok we will just code up a simple one using Taylor polynomials.
we know that eventually the code run does have to look something like this, since all operations are implemented in terms of <code>+</code>, <code>*</code> and <code>^</code>, <code>/</code>, bit-shifts and control-flow.
(Technically <a href="https://en.wikipedia.org/wiki/X86_instruction_listings#Added_with_80387">x86 assembly</a> does have a primitive for <code>sin</code> and <code>cos</code> but as far as I know no LibM actually uses them. There is a <a href="https://reviews.llvm.org/D36344">discussion of why LLVM</a> doesn’t ever emit them if you go looking)
The real code would include control flow to wrap around large values and stay close to zero, but we can skip that and just avoid inputting large values.</p>

<p>So using Taylor polynomials of degree 12 for each of them:</p>

<div><div><pre><code><span>my_sin</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>x</span> <span>-</span> <span>x</span><span>^</span><span>3</span><span>/</span><span>factorial</span><span>(</span><span>3</span><span>)</span> <span>+</span> <span>x</span><span>^</span><span>5</span><span>/</span><span>factorial</span><span>(</span><span>5</span><span>)</span> <span>-</span> <span>x</span><span>^</span><span>7</span><span>/</span><span>factorial</span><span>(</span><span>7</span><span>)</span> <span>+</span> <span>x</span><span>^</span><span>9</span><span>/</span><span>factorial</span><span>(</span><span>9</span><span>)</span> <span>-</span> <span>x</span><span>^</span><span>11</span><span>/</span><span>factorial</span><span>(</span><span>11</span><span>)</span>  <span># + 0*x^12</span>

<span>my_cos</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span>-</span> <span>x</span><span>^</span><span>2</span><span>/</span><span>factorial</span><span>(</span><span>2</span><span>)</span> <span>+</span> <span>x</span><span>^</span><span>4</span><span>/</span><span>factorial</span><span>(</span><span>4</span><span>)</span> <span>-</span> <span>x</span><span>^</span><span>6</span><span>/</span><span>factorial</span><span>(</span><span>6</span><span>)</span> <span>+</span> <span>x</span><span>^</span><span>8</span><span>/</span><span>factorial</span><span>(</span><span>8</span><span>)</span> <span>-</span> <span>x</span><span>^</span><span>10</span><span>/</span><span>factorial</span><span>(</span><span>10</span><span>)</span> <span>+</span> <span>x</span><span>^</span><span>12</span><span>/</span><span>factorial</span><span>(</span><span>12</span><span>)</span>
</code></pre></div></div>

<p>Check the accuracy
we know that  <code>sin(π/3) == √3/2</code>, and that <code>cos(π/3) == 1/2</code>
(note that yes, <code>π</code> and <code>√3/2</code> are  approximating here but they are very accurate one. And this doesn’t change the result that follows.)</p>
<div><div><pre><code><span>julia</span><span>&gt;</span> <span>my_sin</span><span>(</span><span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.8660254034934827</span>

<span>julia</span><span>&gt;</span> <span>√3</span><span>/</span><span>2</span>
<span>0.8660254037844386</span>

<span>julia</span><span>&gt;</span> <span>abs</span><span>(</span><span>√3</span><span>/</span><span>2</span> <span>-</span> <span>my_sin</span><span>(</span><span>π</span><span>/</span><span>3</span><span>))</span>
<span>2.9095592601890985e-10</span>

<span>julia</span><span>&gt;</span> <span>my_cos</span><span>(</span><span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.5000000000217777</span>

<span>julia</span><span>&gt;</span> <span>abs</span><span>(</span><span>0.5</span> <span>-</span> <span>my_cos</span><span>(</span><span>π</span><span>/</span><span>3</span><span>))</span>
<span>2.177769076183722e-11</span>
</code></pre></div></div>

<p>This is not terrible.
<code>cos</code> is slightly more accurate than <code>sin</code>. 
We have a fairly passable implementation of <code>sin</code> and <code>cos</code>.</p>

<h2 id="3-now-lets-do-ad">3. Now lets do AD.</h2>

<p>We know the derivative of <code>sin(x)</code> is <code>cos(x)</code>.
So if we take the derivative of <code>my_sin(π/3)</code> we should get <code>my_cos(π/3)≈0.5</code>.
<em>It should be as accurate as the original implementation, right?</em>
because Griewank and Walther’s 0th Rule:</p>

<blockquote>
  <p>Algorithmic differentiation does not incur truncation error.</p>
</blockquote>

<div><div><pre><code><span>julia</span><span>&gt;</span> <span>derv</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.4999999963909431</span>
</code></pre></div></div>
<p>Wait a second.
That doesn’t seem accurate, we expected 0.5, or at least something pretty close to that.
<code>my_cos</code> was accurate to $2 \times 10^{-11}$.
<code>my_sin</code> was accurate to $3 \times 10^{-10}$
How accurate is this:</p>
<pre><code>julia&gt; abs(derv(my_sin, π/3) - 0.5)
3.609056886677564e-9
</code></pre>

<p>What went wrong?</p>

<h2 id="4-verify">4. Verify</h2>

<p>Now, I did implement an AD from scratch there.
So maybe you are thinking that I screwed it up.
Maybe a reverse mode AD would not suffer from this problem; or maybe one that uses source to source?
Lets try some of Julia’s many AD systems then.</p>

<div><div><pre><code><span>julia</span><span>&gt;</span> <span>import</span> <span>ForwardDiff</span><span>,</span> <span>ReverseDiff</span><span>,</span> <span>Nabla</span><span>,</span> <span>Yota</span><span>,</span> <span>Zygote</span><span>,</span> <span>Tracker</span><span>,</span> <span>Enzyme</span><span>;</span>

<span>julia</span><span>&gt;</span> <span>ForwardDiff</span><span>.</span><span>derivative</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.4999999963909432</span>

<span>julia</span><span>&gt;</span> <span>ReverseDiff</span><span>.</span><span>gradient</span><span>(</span><span>x</span><span>-&gt;</span><span>my_sin</span><span>(</span><span>x</span><span>[</span><span>1</span><span>]),</span> <span>[</span><span>π</span><span>/</span><span>3</span><span>,])</span>
<span>1</span><span>-</span><span>element</span> <span>Vector</span><span>{</span><span>Float64</span><span>}</span><span>:</span>
 <span>0.4999999963909433</span>

<span>julia</span><span>&gt;</span> <span>Nabla</span><span>.</span><span>∇</span><span>(</span><span>my_sin</span><span>)(</span><span>π</span><span>/</span><span>3</span><span>)</span>
<span>(</span><span>0.4999999963909433</span><span>,)</span>

<span>julia</span><span>&gt;</span> <span>Yota</span><span>.</span><span>grad</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)[</span><span>2</span><span>][</span><span>1</span><span>]</span>
<span>0.4999999963909433</span>

<span>julia</span><span>&gt;</span> <span>Zygote</span><span>.</span><span>gradient</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span>
<span>(</span><span>0.4999999963909433</span><span>,)</span>

<span>julia</span><span>&gt;</span> <span>Tracker</span><span>.</span><span>gradient</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span>
<span>(</span><span>0.4999999963909432</span> <span>(</span><span>tracked</span><span>),)</span>

<span>julia</span><span>&gt;</span> <span>Enzyme</span><span>.</span><span>autodiff</span><span>(</span><span>my_sin</span><span>,</span> <span>Active</span><span>(</span><span>π</span><span>/</span><span>3</span><span>))</span>
<span>0.4999999963909432</span>
</code></pre></div></div>

<p>Ok, I just tried <strong>7</strong> AD systems based on totally different implementations.
I mean <a href="https://github.com/wsmoses/Enzyme.jl/">Enzyme</a> is reverse mode running at the LLVM level.
Totally different from <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff</a> which is the more mature version of the forward mode operator overloading AD I coded above.
Every single one agreed with my result, up to <a href="https://en.wikipedia.org/wiki/Unit_in_the_last_place">1 ULP</a>.
I think that last digit changing is probably to do with order of addition (IEEE floating point math is funky), but that is another blog-post.
So I think we can reliably say that this is what an AD system will output when asked for the derivative of <code>my_sin</code> at <code>π/3</code>.</p>

<h2 id="5-explanation">5. Explanation</h2>

<p>Why does AD seem to be incurring truncation errors?
Why is the derivative of <code>my_sin</code> much less accurate than <code>my_cos</code>?</p>

<p>The AD system is (as you might have surmised) not incurring truncation errors.
It is giving us exactly what we asked for, which is the derivative of <code>my_sin</code>.
<code>my_sin</code> is a polynomial.
The derivative of the polynomial is:</p>
<div><div><pre><code><span>d_my_sin</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span>-</span> <span>3</span><span>x</span><span>^</span><span>2</span><span>/</span><span>factorial</span><span>(</span><span>3</span><span>)</span> <span>+</span> <span>5</span><span>x</span><span>^</span><span>4</span><span>/</span><span>factorial</span><span>(</span><span>5</span><span>)</span> <span>-</span> <span>7</span><span>x</span><span>^</span><span>6</span><span>/</span><span>factorial</span><span>(</span><span>7</span><span>)</span> <span>+</span> <span>9</span><span>x</span><span>^</span><span>8</span><span>/</span><span>factorial</span><span>(</span><span>9</span><span>)</span> <span>-</span> <span>11</span><span>x</span><span>^</span><span>10</span><span>/</span><span>factorial</span><span>(</span><span>11</span><span>)</span>
</code></pre></div></div>
<p>which indeed does have</p>
<div><div><pre><code><span>julia</span><span>&gt;</span> <span>d_my_sin</span><span>(</span><span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.4999999963909432</span>
</code></pre></div></div>
<p><code>d_my_sin</code> is a lower degree polynomial approximation to <code>cos</code> than <code>my_cos</code> was, so it is less accurate.
Further, you can see that while n-derivative of <code>sin</code> is always defined as <code>sin(x+n*π/2)</code>, as we keep taking derivatives of the polynomial approximations terms keep getting dropped.
AD is making it smoother and smoother til it is just a flat <code>0</code>.</p>

<p>The key take away here is that <em>the map is not the territory</em>.
Most nontrivial functions on computers are implemented as some function that that approximates (<em>the map</em>) the mathematical ideal (<em>the territory</em>).
Automatic differentiation gives back a completely accurate derivative of the that function (<em>the map</em>) doing the approximation.
<em>Furthermore, the accurate derivative of an approximation to the idea (e.g <code>d_my_sin</code>), is less accurate than and approximation to the (ideal) derivative of the ideal (e.g. <code>my_cos</code>).</em>
There is no truncation error in the work the AD did; but there is a truncation error in the sense that we are now using a more truncated approximation that we would write ourselves.</p>

<p>So what do?
Well-firstly, do you want to do anything?
Maybe the derivative of the approximation is more useful.
(I have been told that this is the case for some optimal control problems).
But if we want to fix it can we?
Yes, the answer is to insert domain knowledge, telling the AD system directly what the approximation to the derivative of the ideal is.
The AD system doesn’t know its working with an approximation, and even if it did, it doesn’t know what the idea it is approximating is.
The way to tell it is with a custom primitive i.e. a custom sensitivity rule.
This is what the ChainRules project in Julia is about, being able to add custom primitives for more things.</p>

<p>Every real AD system already has a primitive for <code>sin</code> built in
(which is one of the reasons I had to define my own above).
but it won’t have one for every novel system you approximate.
E.g. for things defined in terms of differential equation solutions or other iterative methods.</p>

<p>We can define in our toy AD at the start this custom primitive via:</p>
<div><div><pre><code><span>function</span><span> my_sin</span><span>(</span><span>x</span><span>::</span><span>Dual</span><span>)</span>
    <span>return</span> <span>Dual</span><span>(</span><span>my_sin</span><span>(</span><span>primal</span><span>(</span><span>x</span><span>)),</span> <span>partial</span><span>(</span><span>x</span><span>)</span> <span>*</span> <span>my_cos</span><span>(</span><span>primal</span><span>(</span><span>x</span><span>)))</span>
<span>end</span>
</code></pre></div></div>
<p>and it does indeed fix it.</p>
<div><div><pre><code><span>julia</span><span>&gt;</span> <span>derv</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span>
<span>0.5000000000217777</span>

<span>julia</span><span>&gt;</span> <span>abs</span><span>(</span><span>derv</span><span>(</span><span>my_sin</span><span>,</span> <span>π</span><span>/</span><span>3</span><span>)</span> <span>-</span> <span>0.5</span><span>)</span>
<span>2.177769076183722e-11</span>
</code></pre></div></div>

<h3 id="bonus-will-symbolic-differentiation-save-me">Bonus: will symbolic differentiation save me?</h3>

<p>Most symbolic differentiation systems will have a rule just like the custom primitive for <code>sin</code> built in.
It basically has to do something like this, where-as a forward/reverse AD system could do as we did and fall back to <code>+</code> and <code>*</code>.
<em>But</em>, it certainly would <em>not</em> help you to apply symbolic AD to an approximation, that would give exactly the result we derived for <code>d_sin</code> above.</p>

<p>More interestingly, languages where symbolic differentiation is common tend also th have interesting representations of functions in the first place.
This does open up avenues for interesting solutions.
A suitably weird language could be using representation of <code>sin</code> that is a lazily evaluated polynomial of infinite degree underneath.
And in that case there is a rule for its derivative, expressed in terms of changes to its coefficient generating function; which would also give back a lazily evaluated polynomial.
I don’t know if anyone does that though; I suspect it doesn’t generalized well.
Further, for a lot of things you want to solving systems via iterative methods, and these …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oxinabox.net/2021/02/08/AD-truncation-error.html">https://www.oxinabox.net/2021/02/08/AD-truncation-error.html</a></em></p>]]>
            </description>
            <link>https://www.oxinabox.net/2021/02/08/AD-truncation-error.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26068382</guid>
            <pubDate>Mon, 08 Feb 2021 18:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Opinion on Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 104 (<a href="https://news.ycombinator.com/item?id=26067770">thread link</a>) | @hoenir
<br/>
February 8, 2021 | https://vladcalin.ro/blog/2021-02-07-about-blockchain | <a href="https://web.archive.org/web/*/https://vladcalin.ro/blog/2021-02-07-about-blockchain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>This post was inspired by a question on Reddit: How much of your investment portofolio is crypto?</p><p>Well, my answer is 0%, and it will remain 0% forever.</p><p>I don't see the value in it, and the people who advocate for them are hypocrites: they say they get into
crypto as a rebellion act against the current FIAT system that is controlled by governments, while
day-dreaming about selling it for a huge profit (in FIAT currency).
Every advocate promotes holding, which is not what a currency is for: currencies are meant to be
a medium of exchange and to change hands.</p><p>Also, I see rampant misunderstanding of basic economics in people who advocate for it:</p><ul><li><p>they say that the fact that it is deflationary and can not see inflation is a good thing, when it is
actually a bad thing. There is a reason the target inflation is at ~2% almost everywhere.
We need inflation to keep the economy going.</p></li><li><p>they say that it's a currency, when it's not. It is not accessible to everybody
(not everybody has access to internet).</p></li><li><p>if you lose your key, you lose the access to your wallet for good and nobody can help you.
People seem to not understand how bad this is. Imagine people losing everything because of one silly mistake.</p></li><li><p>Volatility is the enemy of any economy market: we need stability and predictability to avoid mayhem:
businesses need predictability to prepare their stocks, factories need predictability to produce goods,
people need predictability to budget and make long-term plans. Sure, long term plans usually don't go as planned,
but you don't want to rethink your entire strategy on a weekly basis because of some wild fluctuation (this week a
car costs 0.5BTC, next week it will be 5BTC). Because of volatility you can't even save for the future.</p></li></ul><p>Also, as a technology, blockchain itself it's not that impressive. At its core, it is a decentralized
slow read-only database which needs as lot of power to run, which do not have many real-life useful applications.
Yeah, some would argue that having a decentralized zero-trust database would be an advantage, but
I am yet to see a system using blockchain, where a normal database is not enough.</p><p>The only real-life application I could see is in audit trailing, where the decentralization part
is useless (only the chaining of blocks by hashing is useful there, to avoid tampering with past entries),
but that use-case is not related to the reason blockchain advocates promote it.</p><p>Every time some company announces that they will build their own blockchain solution, the blockchain
community celebrates, because they consider it to be proof that blockchain is the future, but in fact,
it's a massive counter-argument against the core belief they promote: decentralization.
The fact that a company is building their own, it means that they will control it.</p><h3>Conclusion</h3><p>In my opinion, Bitcoin is a fad and it's value is given by two things: people who have too much faith in an asset that
is not really an asset and has no use except offering a field for speculation, and the FOMO of people who get caught in
the heat of the moment and buy when a friend tells them to buy or mass-media brings it to the public attention
once very few months.</p><p>This article is a personal opinion, and represents no financial advice. I am in not saying "sell" or "buy".
Do your own research (thoroughly).</p></div></div></div>]]>
            </description>
            <link>https://vladcalin.ro/blog/2021-02-07-about-blockchain</link>
            <guid isPermaLink="false">hacker-news-small-sites-26067770</guid>
            <pubDate>Mon, 08 Feb 2021 17:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reminder: Terraria Dev’s Google Story Is Not Unusual at All]]>
            </title>
            <description>
<![CDATA[
Score 314 | Comments 8 (<a href="https://news.ycombinator.com/item?id=26067188">thread link</a>) | @teddyh
<br/>
February 8, 2021 | https://codewriteplay.com/2021/02/08/reminder-terraria-devs-google-story-is-not-unusual-at-all/ | <a href="https://web.archive.org/web/*/https://codewriteplay.com/2021/02/08/reminder-terraria-devs-google-story-is-not-unusual-at-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://codewriteplay.com/2021/02/08/reminder-terraria-devs-google-story-is-not-unusual-at-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26067188</guid>
            <pubDate>Mon, 08 Feb 2021 17:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using computer vision to help win $1M in Mountain Dew's Super Bowl contest]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 92 (<a href="https://news.ycombinator.com/item?id=26066970">thread link</a>) | @rocauc
<br/>
February 8, 2021 | https://blog.roboflow.com/mountain-dew-contest-computer-vision/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.com/mountain-dew-contest-computer-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div>
                <div><p>Last night during Super Bowl LV, Mountain Dew ran an ad featuring John Cena riding through a Mountain Dew-themed amusement park. Bottles are scattered all over the scene: neon signs on buildings, in fun house mirrors, and flying out of the car trunk.</p><p>At the end of the ad, John Cena challenges the audience: <strong>The first person to tweet at Mountain Dew the exact number of bottles that appear in the commercial is eligible to win $1 million.</strong></p><p>Watch the ad for yourself here:</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/9cEiYQwYLPk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>When we heard that a task called for careful visual inspection and counting, we knew <a href="https://blog.roboflow.com/intro-to-computer-vision/">computer vision</a> would be a helpful tool. So, we did what any developer would do: trained an <a href="https://models.roboflow.com/object-detection">object detection model</a> to recognize bottles that appear throughout the scene. </p><figure><img src="https://blog.roboflow.com/content/images/2021/02/Winning_1_Million_with_Computer_Vision_Mountain_Dew_Super_Bowl_Contest.gif" alt="Counting Mountain Dew Contest with Computer Vision"><figcaption>A three-second example of the model finding Mountain Dew bottles in the scene.</figcaption></figure><p>In this case, <strong>we're using a <a href="https://models.roboflow.com/">computer vision model</a> to help us find any bottles we may have otherwise missed.</strong> The viewer should still identify the unique occurrences of each bottle across the scene when tweeting a submission.</p><p>Per the <a href="https://www.lifechangingdew.com/rules">Official Rules</a>, any type of bottle counts – but each bottle should only be counted once. (For example, the bottle in the car John Cena drinks from is present multiple different times, but it should only be counted once towards the tally.) </p><p>Let's dive in.</p><h3 id="preparing-a-dataset">Preparing a Dataset</h3><p>First, we need a dataset of images from the ad. In this case, we can grab the exact video file of the commercial. We'll need to <a href="https://blog.roboflow.com/using-video-computer-vision/">split the video file into individual image frames</a> in order to annotate the images and train a model.</p><p>I created a dataset and dropped the Mountain Dew video into Roboflow, which asks what frame rate I'd like to sample. I decided on doing three frames per second, which creates 92 images from the roughly 30-second Super Bowl spot.</p><figure><img src="https://blog.roboflow.com/content/images/2021/02/Winning_1_Million_with_Computer_Vision_Mountain_Dew_Super_Bowl_Contest-upload.gif" alt="Turning video into images for computer vision."><figcaption>Selecting a three frames per second rate for the commercial.</figcaption></figure><p>Having each of the individual frames from the video is independently helpful: it means we can have a closer look at all of the places where the Mountain Dew bottles may be present.</p><p>Once we have these images, we need to <a href="https://docs.roboflow.com/annotate">annotate</a> all of the bottles we can find in each of the scenes. While this is fairly similar to counting all of the bottles manually, remember we might not be perfect in finding all of the bottles with our own eyes. So, hopefully, in teaching a computer vision model what bottles look like and then asking that same model to find bottles for us, we'll see any we may have missed.</p><figure><img src="https://blog.roboflow.com/content/images/2021/02/annotating-bottles.png" alt="Labeling bottles for computer vision" srcset="https://blog.roboflow.com/content/images/size/w600/2021/02/annotating-bottles.png 600w, https://blog.roboflow.com/content/images/size/w1000/2021/02/annotating-bottles.png 1000w, https://blog.roboflow.com/content/images/2021/02/annotating-bottles.png 1573w" sizes="(min-width: 720px) 720px"><figcaption>Annotating all of the Mountain Dew bottles in each of our images.</figcaption></figure><p>After labeling (and deleting one completely black image from the vid), we have 869 annotations across 91 images. We've open sourced this final <a href="https://public.roboflow.com/object-detection/mountain-dew-commercial">Mountain Dew bottles image dataset</a>:</p><figure><a href="https://public.roboflow.com/object-detection/mountain-dew-commercial"><div><p>Mountain Dew Commercial Object Detection Dataset</p><p># Overview ## Mountain Dew is running a $1,000,000 counting contest. Computer Vision can help you win.:fa-spacer: ### Watch [our video](https://youtu.be/jqVKdMjPXHA) explaining how to use this dataset. ![Mountain Dew](https://i.imgur.com/ED4jpM3.png…</p></div><p><img src="https://storage.googleapis.com/roboflow-platform-sources/Ly2DeBzbwsemGd2ReHk4BFxy8683/WF57VFawbh9kJl5K4fie/original.jpg"></p></a></figure><h3 id="training-an-object-detection-model">Training an Object Detection Model</h3><p>Once we have our images collected and labeled, we can train a model to find bottles for us. Before training, however, we can use <a href="https://blog.roboflow.com/boosting-image-detection-performance-with-data-augmentation/">image augmentation</a> to increase the size of our training dataset.</p><p>By applying random distortions like <a href="https://docs.roboflow.com/image-transformations/image-augmentation">brightness changes</a>, <a href="https://blog.roboflow.com/why-and-how-to-implement-random-rotate-data-augmentation/">perspective changes</a>, <a href="https://blog.roboflow.com/how-flip-augmentation-improves-model-performance/">flips</a>, and more, we can increase the volume and variability of our training dataset so that our model has more examples to learn from.</p><figure><div><div><p><img src="https://blog.roboflow.com/content/images/2021/02/dew-aug1.png" width="760" height="760" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/02/dew-aug1.png 600w, https://blog.roboflow.com/content/images/2021/02/dew-aug1.png 760w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2021/02/dew-aug2.png" width="818" height="818" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/02/dew-aug2.png 600w, https://blog.roboflow.com/content/images/2021/02/dew-aug2.png 818w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://blog.roboflow.com/content/images/2021/02/dew-aug3.png" width="820" height="818" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/02/dew-aug3.png 600w, https://blog.roboflow.com/content/images/2021/02/dew-aug3.png 820w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2021/02/dew-aug4.png" width="821" height="817" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/02/dew-aug4.png 600w, https://blog.roboflow.com/content/images/2021/02/dew-aug4.png 821w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Our <a href="https://docs.roboflow.com/image-transformations/image-augmentation">augmented images</a> have been brightened, sheared, flipped, rotated, and more to increase dataset size and variability.</figcaption></figure><p>We then made use of <a href="https://docs.roboflow.com/train">Roboflow Train</a>, which gives us the option to one-click have a trained model available. Critically, when starting model training, we can start from a previous model checkpoint. This <a href="https://blog.roboflow.com/a-primer-on-transfer-learning/">transfer learning</a> will accelerate model training and improve model accuracy. For this dataset, starting training from the <a href="https://blog.roboflow.com/coco-dataset/">COCO Dataset</a> (a dataset of "Common Objects in Context") will give the model a healthy head start.</p><figure><img src="https://blog.roboflow.com/content/images/2021/02/roboflow-train-results.png" alt="Roboflow Train results"><figcaption>The results of our model training. 89.5% <a href="https://blog.roboflow.com/mean-average-precision/">mean average precision</a>. Not bad!</figcaption></figure><h3 id="using-our-model">Using Our Model</h3><p>Once the model finishes training, we have an <a href="https://blog.roboflow.com/hands-on-with-the-roboflow-infer-web-application-interface/">API</a> we can call to perform detections on our original video. With a little shell scripting, we can passthrough the original commercial video frame-by-frame and reconstruct the result with the bounding boxes present.</p><p>The result? See for yourself:</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/jqVKdMjPXHA?start=773&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>A full video walkthrough of our process. The resulting video is available at the 12:53 mark.</figcaption></figure><p>Good luck! We hope you win that $1 million.</p></div>
                
              </div>
            </div></div>]]>
            </description>
            <link>https://blog.roboflow.com/mountain-dew-contest-computer-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26066970</guid>
            <pubDate>Mon, 08 Feb 2021 16:52:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[State of the Common Lisp ecosystem, 2020]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 127 (<a href="https://news.ycombinator.com/item?id=26065511">thread link</a>) | @lelf
<br/>
February 8, 2021 | https://lisp-journey.gitlab.io/blog/state-of-the-common-lisp-ecosystem-2020/ | <a href="https://web.archive.org/web/*/https://lisp-journey.gitlab.io/blog/state-of-the-common-lisp-ecosystem-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>This is a description of the Common Lisp ecosystem, as of January, 2021,
from the perspective of a user and contributor.</p>

<p>The purpose of this article is both to give an overview of the
ecosystem, and to help drive consolidation in each domain.</p>

<p>Each application domain has recommendations for consolidating that
part of the ecosystem, and pointers for interesting future work.</p>

<p>This article is derived from
Fernando Borretti’s <a href="https://borretti.me/article/common-lisp-sotu-2015">State of the Common Lisp ecosystem from 2015</a>, hence the introduction that sounded familiar.
This new one will be an opportunity to look at what was achieved, or what is
still lacking.</p>

<p><strong>Disclaimer</strong>: This article is not a list of every project or article of interest that came out in the last years. I wrote an overview of 2018 closer to that goal <a href="https://lisp-journey.gitlab.io/blog/these-years-in-common-lisp-2018/">here</a>. More libraries can be discovered on the <a href="https://github.com/CodyReichert/awesome-cl">Awesome-cl</a> list, on GitHub and on <a href="https://www.cliki.net/">Cliki</a>.</p>

<p><strong>Acknowledgements</strong> I would like to thank @borodust, @ambrevar and @digikar for their kind feedback.</p>

<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->

<p><strong>Table of Contents</strong></p>

<ul>
<li><a href="#application-domains">Application domains</a>

<ul>
<li><a href="#command-line">Command line</a></li>
<li><a href="#databases">Databases</a></li>
<li><a href="#concurrency">Concurrency</a></li>
<li><a href="#file-formats">File formats</a></li>
<li><a href="#gui">GUI</a></li>
<li><a href="#machine-learning">Machine Learning</a></li>
<li><a href="#system">System</a></li>
<li><a href="#web-development">Web Development</a>

<ul>
<li><a href="#backend">Backend</a></li>
<li><a href="#frontend">Frontend</a></li>
<li><a href="#javascript">JavaScript</a></li>
<li><a href="#isomorphic-web-frameworks">Isomorphic web frameworks</a></li>
</ul></li>
</ul></li>
<li><a href="#languages-interop">Languages interop</a>

<ul>
<li><a href="#apl">APL</a></li>
<li><a href="#c-c-objective-c">C, C++, Objective C</a></li>
<li><a href="#clojure">Clojure</a></li>
<li><a href="#python">Python</a></li>
<li><a href="#net-core">.Net Core</a></li>
</ul></li>
<li><a href="#development">Development</a>

<ul>
<li><a href="#implementations">Implementations</a></li>
<li><a href="#editors">Editors</a></li>
<li><a href="#developer-utilities">Developer utilities</a></li>
<li><a href="#package-management">Package Management</a></li>
<li><a href="#build-system">Build System</a></li>
<li><a href="#type-system">Type system</a></li>
<li><a href="#testing-ci">Testing, CI</a></li>
</ul></li>
<li><a href="#community">Community</a>

<ul>
<li><a href="#online-presence">Online presence</a>

<ul>
<li><a href="#new-common-lispnet-website">New common-lisp.net website</a></li>
<li><a href="#cookbook">Cookbook</a></li>
<li><a href="#awesome-cl">awesome-cl</a></li>
<li><a href="#more">More</a></li>
</ul></li>
<li><a href="#new-books">New books</a></li>
<li><a href="#companies">Companies</a></li>
<li><a href="#growth">Growth</a></li>
</ul></li>
<li><a href="#last-words">Last words</a></li>
</ul>

<!-- markdown-toc end -->



<h2 id="command-line">Command line</h2>

<p>There used to be several options to ease building and distribution of command line programs,
but now <a href="https://github.com/snmsts/roswell">Roswell</a> has gained most momentum,
and that’s a good thing. Roswell is an implementation
manager, installer and a script runner, and one of its neat features is support for
very easily compiling tiny scripts into executables.</p>

<p>Now, <a href="https://guix.gnu.org/">GNU Guix</a> has gained many CL libraries, and becomes a contender to Roswell. Guix can be used as a package manager on top of your Unix distribution. It brings reproducible builds, rollbacks, the ability to install exact versions of any library (including system dependencies), contained environments and user profiles. It makes it easy too to install the latest version of a CL implementation and libraries and, to a certain extent, to share scripts. See the article <a href="https://ambrevar.xyz/lisp-repl-shell/index.html">A Lisp REPL as my main shell</a> for insights.</p>

<p>To parse command line arguments, <a href="https://github.com/mrkkrp/unix-opts">unix-opts</a> shows decent activity. As a reminder, the CLI arguments are stored portably in <code>uiop:command-line-arguments</code>.</p>

<p><a href="https://github.com/cl-adams/adams">Adams</a> is a new UNIX system administration tool, not unlike Chef or Ansible.</p>

<p><strong>Consolidation</strong></p>

<p>More features to the <a href="https://github.com/CodyReichert/awesome-cl#scripting">sripting libraries</a>.</p>

<p><strong>Future work</strong></p>

<p>The <a href="https://github.com/cxxxr/lem/">Lem editor</a> has built a great user interface and REPL on top of ncurses, with the cl-charms library. It would be great to re-use its components, so that Lispers could easily build similar rich terminal-based interfaces.</p>

<h2 id="databases">Databases</h2>

<p><a href="https://github.com/fukamachi/mito">Mito</a> is an ORM for Common Lisp
with migrations, relationships and PostgreSQL support. It is based on
cl-dbi (a uniform interface to the various database server-specific
libraries such as cl-postgres and cl-mysql) and SxQL (a DSL for
building safe, automatically parameterized SQL queries).</p>

<p>It also has a tutorial in the Cookbook:
<a href="https://lispcookbook.github.io/cl-cookbook/databases.html">Cookbook/databases</a>.</p>

<!-- On my blog, [an article](https://lisp-journey.gitlab.io/blog/composing-queries-with-mito-aka-replacing-lazy-querysets-and-q-objects/) -->

<!-- on how to compose queries with Mito and SxQL, and on how we only need -->

<!-- lisp knowledge to replace Django functionalities. -->

<p>There are of course more libraries in that field. Some new ones since 2015 are:</p>

<p><a href="https://github.com/ruricolist/cl-yesql">cl-yesql</a> (by the author of
Serapeum, Spinneret and other great libraries) is based on Clojure’s
Yesql.</p>

<p><a href="https://github.com/kraison/vivace-graph-v3">vivace-graph</a> is a <strong>graph
database</strong> and Prolog implementation, taking design and inspiration from
CouchDB, neo4j and AllegroGraph.</p>

<p>Vsevolod Dyomkin, the author of Rutils, the Programming Algorithms
book and other libraries, is writing
<a href="https://github.com/vseloved/cl-agraph">cl-agraph</a>, a minimal client
to Franz Inc’s <a href="https://allegrograph.com/">AllegroGraph</a>. AllegroGraph is a
“horizontally distributed, multi-model (document and graph),
entity-event <strong>knowledge graph</strong> technology”. It is proprietary and has a
free version with a limit of 5 million triples. Surely one of those Lisp hidden gems we should know more about.</p>

<p>A general migration tool was lacking. We now have
<a href="https://github.com/dnaeon/cl-migratum">cl-migratum</a>, a “system which
provides facilities for performing database schema migrations,
designed to work with various databases”.</p>

<p>And of course, <a href="https://github.com/dimitri/pgloader">pgloader</a> is still a Common Lisp success story.</p>

<p><strong>Achievement</strong></p>

<p>Among the emerging ORMs, Mito is the one actively maintained that Lispers seem to have chosen. Good. CLSQL certainly still works, but we don’t hear about it and it looks outdated. So, Mito it is.</p>

<p><strong>Consolidation</strong></p>

<p>Mito has 11 contributors and is actively watched, but it probably should have another(s) core maintainers.</p>

<p><strong>Future work</strong></p>

<p>Bindings for the new databases coming out.</p>

<h2 id="concurrency">Concurrency</h2>

<p>In the last year, Manfred Bergmann developed
<a href="https://github.com/mdbergmann/cl-gserver">cl-gserver</a>. It is a
“message passing” library/framework with <strong>actors</strong> similar to
<strong>Erlang</strong> or <strong>Akka</strong>. It is an important achievement.</p>

<p>Its v1 features:</p>

<ul>
<li>actors can use a shared pool of message dispatchers which effectively allows to create millions of actors.</li>
<li>the possibility to create actor hierarchies. An actor can have child actors. An actor now can also “watch” another actor to get notified about its termination.</li>
</ul>

<p>Many other libraries exist in this area:</p>

<ul>
<li><a href="https://common-lisp.net/project/bordeaux-threads/">BordeauxThreads</a> - Portable, shared-state concurrency

<ul>
<li>the “de-facto” concurrency library.</li>
</ul></li>
<li><a href="https://github.com/lmj/lparallel">lparallel</a> - A library for parallel programming.

<ul>
<li>also solid, battle-tested and popular, aka de-facto.</li>
</ul></li>
<li><a href="https://github.com/hawkir/calispel">calispel</a> - <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes">CSP</a>-like channels for common lisp. With blocking, optionally buffered channels and a “CSP select” statement. ISC-style.

<ul>
<li>“It is complete, flexible and easy to use. I would recommend Calispel over Lparallel and ChanL.” @Ambrevar. <a href="https://github.com/CodyReichert/awesome-cl/issues/290">discussion</a></li>
</ul></li>
<li><a href="https://github.com/zkat/chanl">ChanL</a> - Portable, channel-based concurrency.</li>
<li><a href="https://github.com/orthecreedence/cl-async">cl-async</a> - A library for general-purpose, non-blocking programming.

<ul>
<li>works atop libuv</li>
</ul></li>
<li><a href="https://github.com/TBRSS/moira">Moira</a> -  Monitor and restart background threads. In-lisp process supervisor.</li>
<li><a href="https://gitlab.com/ediethelm/trivial-monitored-thread">trivial-monitored-thread</a> -
a Common Lisp library offering a way of spawning threads and being
informed when one any of them crash and die.</li>
<li><a href="https://github.com/lmj/lfarm">lfarm</a> - distributing work across machines (on top of lparallel and usocket).</li>
<li><a href="https://github.com/taksatou/cl-gearman">cl-gearman</a> - a library for the <a href="http://gearman.org/">Gearman</a> distributed job system.

<ul>
<li>Alexander Artemenko used it instead of lfarm for Ultralisp:
<a href="https://40ants.com/lisp-project-of-the-day/2020/06/0095-cl-gearman.html">https://40ants.com/lisp-project-of-the-day/2020/06/0095-cl-gearman.html</a>,
because “lfarm is not well suited to environments where worker
hosts can go down and return back later”.</li>
</ul></li>
<li><a href="https://github.com/brown/swank-crew">swank-crew</a> - distributed computation framework implemented using Swank Client.</li>
<li><a href="https://github.com/takagi/cl-coroutine">cl-coroutine</a> - a coroutine library. It uses the CL-CONT continuations library in its implementation.</li>
<li><a href="https://github.com/cosmos72/stmx">CMTX</a>: high performance transactional memory for Common Lisp.

<ul>
<li>In our opinion, a library not well known and under-appreciated.</li>
</ul></li>
</ul>

<p>(see <a href="https://github.com/CodyReichert/awesome-cl#parallelism-and-concurrency">awesome-cl#parallelism-and-concurrency</a>)</p>

<p><strong>Consolidation</strong></p>

<p>Bordeaux-Threads is <em>the</em> “de-facto” library, but there is some choice
paralysis between Lparallel, Calispel, Bordeaux-Threads and SBCL’s
contribs. Use the libraries in the wild and write about them.</p>

<h2 id="file-formats">File formats</h2>

<p>There exist Common Lisp libraries for all the major file formats:</p>

<ul>
<li>XML: <a href="https://github.com/Shinmera/plump">Plump</a> (and <a href="https://github.com/Shinmera/lquery/">Lquery</a>), as well as <a href="https://common-lisp.net/project/cxml/">CXML</a>, which can parse large files incrementally.</li>
<li>JSON: <a href="https://github.com/Rudolph-Miller/jonathan">Jonathan</a>, <a href="https://common-lisp.net/project/cl-json/">cl-json</a> or <a href="https://sabracrolleton.github.io/json-review">more</a>. With utilities:

<ul>
<li><a href="https://github.com/y2q-actionman/cl-json-pointer">json-pointer</a> - A JSON Pointer implementation.</li>
<li><a href="https://github.com/gschjetne/json-mop">json-mop</a> - A metaclass for bridging CLOS and JSON objects (remind that JSON libraries can already serialize your own objects).</li>
<li><a href="https://github.com/fisxoj/json-schema">json-schema</a></li>
</ul></li>
<li>YAML: cl-yaml</li>
<li>CSV: <a href="https://github.com/AccelerationNet/cl-csv">cl-csv</a></li>
</ul>

<p><strong>Achievement</strong></p>

<p>New in 2015, Jonathan is now a good first choice for an easy to use and fast JSON encoder and decoder.</p>

<p><strong>Consolidation</strong></p>

<p>There is not a predominant JSON library. This leads to choice paralysis.</p>

<p>They all represent null values differently. We need a library that
“does the right thing”. See maybe the massive <a href="https://github.com/xh4/web-toolkit#json">web-toolkit</a> for its JSON handling ?</p>

<blockquote>
<p>It distinguishes null, false and [] from Lisp’s NIL thus supports identical transformation between JSON values. It provides object constructor and accessor to build and access nesting JSON objects.</p>
</blockquote>

<p>Give the <a href="https://github.com/sharplispers/xpath">XPath</a> library some love and documentation.</p>

<p><strong>Future Work</strong></p>

<p>Still valid from 2015:</p>

<blockquote>
<p>A YAML parser so that cl-yaml doesn’t depend on the libyaml library would make distribution far simpler.</p>
</blockquote>

<h2 id="gui">GUI</h2>

<p>A usual complain in Common Lisp land is the lack of a complete,
cross-platform GUI solution. Ltk is a very good library, but Tk is
limited. Qtools is great, but is only for Qt4.</p>

<p>A lot has happened, and is still happening (if you watch the right
repositories, you know that a Qt5 wrapper is in the works (ECL already has Qt5 bindings: <a href="https://gitlab.com/eql/EQL5/">EQL5</a>, with an <a href="https://gitlab.com/eql/EQL5-Android">Android port</a>)).</p>

<p>edit: see also <a href="https://gitlab.com/eql/eql5-sailfish">EQL5-sailfish</a> for Sailfish OS. <a href="https://openrepos.net/user/13436/programs">Here</a> are two example apps.</p>

<p>Matthew Kennedy wrote excellent FFI bindings to the IUP Portable User
Interface library: <a href="https://github.com/lispnik/iup/">IUP</a>. IUP is
cross-platform (Windows, macOS, GNU/Linux, with new Android, iOS,
Cocoa and Web Assembly drivers), has many widgets (but less than Qt), has a small API and
is actively developed. IUP was created at the PUC university of Rio de Janeiro.</p>

<p>Nicolas Hafner started <a href="https://github.com/Shirakumo/alloy">Alloy</a>, a
new user interface protocol and toolkit implementation, which he uses in his Kandria game.</p>

<p>Very recently, David Botton released <a href="https://github.com/rabbibotton/clog">CLOG</a>, “the Common Lisp Omnificent GUI”:</p>

<blockquote>
<p>CLOG uses web technology to produce graphical user interfaces for applications locally or remotely. CLOG can take the place, or work alongside, most cross-platform GUI frameworks and website frameworks. The CLOG package starts up the connectivity to the browser or other websocket client (often a browser embedded in a native template application.)</p>

<p>It is complete enough for most uses.</p>
</blockquote>

<p>There are more GUI libraries and frameworks: <a href="https://github.com/CodyReichert/awesome-cl#Gui">https://github.com/CodyReichert/awesome-cl#Gui</a> (and more under the works). In particular, LispWorks’ CAPI is still presented as the best in town by the ones who tried it.</p>

<p><strong>Consolidation</strong></p>

<p>Since roughly October, 2020, Nicolas Hafner works full time on
<a href="https://kandria.com/">Kandria</a>. Supporting his work, through <a href="https://github.com/sponsors/Shinmera">GitHub
sponsors</a> or
<a href="https://ko-fi.com/shinmera">ko-fi</a> would be 1) a great sign of recognition and 2) useful for the ecosystem, especially for Alloy.</p>

<p>I wrote an introduction to these frameworks in the Cookbook:
<a href="https://lispcookbook.github.io/cl-cookbook/gui.html">Cookbook/gui</a>. More
examples or demo projects would be welcome.</p>

<p>There are two actively maintained diverged forks of the GTK bindings. A …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lisp-journey.gitlab.io/blog/state-of-the-common-lisp-ecosystem-2020/">https://lisp-journey.gitlab.io/blog/state-of-the-common-lisp-ecosystem-2020/</a></em></p>]]>
            </description>
            <link>https://lisp-journey.gitlab.io/blog/state-of-the-common-lisp-ecosystem-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26065511</guid>
            <pubDate>Mon, 08 Feb 2021 15:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking at GSM security 30 years later]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26064725">thread link</a>) | @8sfLes
<br/>
February 8, 2021 | https://harrisonsand.com/gsm-security/ | <a href="https://web.archive.org/web/*/https://harrisonsand.com/gsm-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Looking at 2G GSM traffic three decades since its inception might not sound terribly interesting, but the protocol is still surprisingly common today. It's often used a fallback for when coverage is limited and more modern protocols aren't available, as well as for legacy IoT devices.</p><p>In Norway, Telia and Telenor are in the process of phasing our their 3G networks. At they same time they are keeping their 2G networks operational <a href="https://www.telenor.no/bedrift/iot/m2m/3g/">until at least 2025</a>. Meaning all devices that don't support VoLTE will use 2G for calls and SMS.</p><p>There are well documented security flaws in GSM, and publicly available tools to exploit them. At the same time, it has become considerably cheaper and easier to analyze GSM traffic over the past few years. Open source tools such as <a href="https://github.com/ptrkrysik/gr-gsm">gr-gsm</a> have matured, and the community has developed methods for capturing the GSM spectrum without the need for expensive SDR radios.</p><p>With less than $100 and a weekend it's possible to capture and analyze GSM traffic. With some extra effort it's possible to decrypt your own traffic, and depending on how your mobile provider has set up their network it may even be possible for somebody else to illegally decrypt traffic they don't own.</p><h3 id="the-gsm-spectrum">The GSM spectrum</h3><figure><img src="https://harrisonsand.com/content/images/2021/02/Screenshot_20210208_122702.png" alt="" srcset="https://harrisonsand.com/content/images/size/w600/2021/02/Screenshot_20210208_122702.png 600w, https://harrisonsand.com/content/images/size/w1000/2021/02/Screenshot_20210208_122702.png 1000w, https://harrisonsand.com/content/images/size/w1600/2021/02/Screenshot_20210208_122702.png 1600w, https://harrisonsand.com/content/images/2021/02/Screenshot_20210208_122702.png 1920w" sizes="(min-width: 1200px) 1200px"><figcaption>GSM spectrum, showing multiple channels</figcaption></figure><p>More often than not traffic will "hop" between different channels during a transmission. Hops occur quite quickly, every few milliseconds or so. In practice, this normally means if you're interested in looking at more than a base station's broadcast control channel (BCCH) you need a way to simultaneously capture multiple channels at once.</p><p>You can visually see the hopping in the screenshot above. Stationary control traffic is on the left, and hopping traffic is on the right. These "slices" are produced as the base stations hop between different channels during transmission.</p><p>A local tower of mine is configured to hop between ARFCN channels 57 and 112. This corresponds to downlink frequencies of 946.4 and 957.4 MHz. Channels have a bandwidth of 0.2 MHz, so that means if I want to look at both channels at once I need a radio with a bandwidth of at least 11.2 MHz (946.3 to 957.5). Keep in mind towers will be configured differently, potentially using more channels spread further apart.</p><p>Inexpensive SDRs tend to have a maximum bandwidth of about 2.4 MHz. You can overcome this limitation by using multiple radios and <a href="https://github.com/ptrkrysik/multi-rtl">multi-rtl</a>, which combines their signals together to get a larger effective bandwidth.</p><p>In my case I had access to a <a href="https://www.ettus.com/product-categories/usrp-bus-series/">USRP radio</a> that can capture up to 56 MHz of bandwidth, and that's what I'll be using for my tests. However, the core concepts are identical no matter what radio you use.</p><h3 id="other-hardware">Other hardware</h3><p>If you want to decrypt your own traffic you'll need a way to get the Kc encryption key from your SIM card. Several guides out there use a series of AT+CRSM commands that access the SIM card through the phone's modem. I have gotten this to work in the past, but many phones don't expose the modem's serial interface by default, and even if you can get access it tends to be a messy process. I prefer to use a smart card reader to pull the key from the SIM directly.</p><p>I purchased a HID OMNIKEY 6121 USB smart card reader, and some adapters from the <a href="https://piswords.aliexpress.com/store/829772">Piswords AliExpress store</a> to make it a bit less fiddly to swap SIMs in and out.</p><h3 id="software">Software</h3><p>Recent versions of Ubuntu have gr-gsm in their repositories by default. Installation on Kubuntu 20.10 was as easy as:</p><pre><code>sudo apt install gr-gsm wireshark gqrx-sdr cardpeek</code></pre><p>You'll need Wireshark for looking at traffic, gqrx if you want to visually see the spectrum, and Cardpeek for pulling keys off the SIM card.</p><p>For the USRP you'll need a bit more setup. First download the latest firmware images and then set the UHD_IMAGES_DIR environment variable.</p><pre><code>sudo uhd_images_downloader
export UHD_IMAGES_DIR=/usr/share/uhd/images</code></pre><p>Next, we configure the system so non-root users can access the radio.</p><pre><code>sudo cp /usr/lib/uhd/utils/uhd-usrp.rules /etc/udev/rules.d/
sudo udevadm control --reload-rules
sudo udevadm trigger</code></pre><p>You can test if everything is working by scanning for nearby base stations with the <code>grgsm_scanner</code> utility. It takes about a minute to start displaying data.</p><figure><img src="https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_160020.png" alt="" srcset="https://harrisonsand.com/content/images/size/w600/2021/02/Screenshot_20210207_160020.png 600w, https://harrisonsand.com/content/images/size/w1000/2021/02/Screenshot_20210207_160020.png 1000w, https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_160020.png 1177w"></figure><h3 id="find-the-base-station">Find the base station</h3><p>Before we can capture traffic we need to know what base station our phone is connected to. This is <em>probably</em> the station with the best signal strength, so in my scan above that would be CID 2106 on ARFCN channel 57. But to be sure lets double check.</p><p>On an iPhone you can dial <code>*3001#12345#*</code> which takes you to field test mode. Go to the "All Metrics" tab and scroll down to GSM Serving Cell Info.</p><figure><img src="https://harrisonsand.com/content/images/2021/02/21-02-07-16-25-45-1531-2.png" alt="" srcset="https://harrisonsand.com/content/images/size/w600/2021/02/21-02-07-16-25-45-1531-2.png 600w, https://harrisonsand.com/content/images/size/w1000/2021/02/21-02-07-16-25-45-1531-2.png 1000w, https://harrisonsand.com/content/images/2021/02/21-02-07-16-25-45-1531-2.png 1125w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the ARFCN is set to 57, as we suspected. You can also look under "GSM Idle Config" to verify that the ci matches the CID from the scan, in this case 2106.</p><p>On Android the <a href="https://play.google.com/store/apps/details?id=com.wilysis.cellinfolite">Network Cell Info Lite</a> app provides similar information.</p><h3 id="base-station-arfcns">Base station ARFCNs</h3><p>Next, we need to find out what channels the base station is configured to use. This is so we know what frequencies to configure our capture for. A list of these channels is periodically broadcast inside the System Information Type 1 packets from the BCCH. </p><p>The <code>grgsm_livemon</code> utility allows us to monitor data from the BCCH. Use the <code>-f</code> flag to set the frequency of the base station. You can find this in the output from <code>grgsm_scanner</code>, or by using the <a href="https://www.cellmapper.net/arfcn">cellmapper.net</a> ARFCN frequency calculator. (use the downlink frequency)</p><pre><code>grgsm_livemon -f 946.4M</code></pre><p>Traffic is piped to the system's loopback interface inside UDP packets on port 4729. You can use this display filter to only show Type 1 packets: <code>gsm_a.dtap.msg_rr_type == 0x19</code>.</p><figure><img src="https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_164557.png" alt="" srcset="https://harrisonsand.com/content/images/size/w600/2021/02/Screenshot_20210207_164557.png 600w, https://harrisonsand.com/content/images/size/w1000/2021/02/Screenshot_20210207_164557.png 1000w, https://harrisonsand.com/content/images/size/w1600/2021/02/Screenshot_20210207_164557.png 1600w, https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_164557.png 1960w" sizes="(min-width: 1200px) 1200px"></figure><p>Looking under Cell Channel Description we can see that this base station is configured to use two ARFCNs: 57 and 112.</p><h3 id="capturing-traffic">Capturing traffic</h3><p>Using the ARFCN calculator we can see that the downlink frequencies for those channels are 946.4 and 957.4 MHz. The minimum frequency range to capture both would be 946.3 to 957.5 MHz. Adding 0.1 MHz to each end to account for the 0.2 MHz channel bandwidth.</p><p>For the capture itself, we'll use the <code>grgsm_capture</code> utility. We can use the <code>-f</code> flag to set the center frequency between our two channels, and the <code>-s</code> flag to set a sufficient sample rate / bandwidth.</p><pre><code>Usage: grgsm_capture [options] output_filename

RTL-SDR capturing app of gr-gsm.

Options:
  -h, --help            show this help message and exit
  -f FREQ, --freq=FREQ  Set frequency [default=none]
  -a ARFCN, --arfcn=ARFCN
                        Set ARFCN instead of frequency (for PCS1900 add0x8000
                        (2**15) to the ARFCN number)
  -g GAIN, --gain=GAIN  Set gain [default=30.0]
  -s SAMP_RATE, --samp-rate=SAMP_RATE
                        Set samp_rate [default=1.0M]
  -T REC_LENGTH, --rec-length=REC_LENGTH
                        Set length of recording in seconds [default=infinity]
  -p FREQ_CORR, --freq-corr=FREQ_CORR
                        Set frequency correction in ppm [default=0]

  Additional osmosdr source options:
    Options specific to a subset of SDR receivers supported by osmosdr
    source.

    -w BANDWIDTH, --bandwidth=BANDWIDTH
                        Set bandwidth [default=samp_rate]
    --bb-gain=BB_GAIN   Set baseband gain [default=20.0]
    --if-gain=IF_GAIN   Set intermediate freque gain [default=20.0]
    --ant=ANTENNA       Set antenna [default=]
    --args=DEVICE_ARGS  Set device arguments [default=]. Use --list-devices
                        the view the available devices
    -l, --list-devices  List available SDR devices, use --args to specify
                        hints
</code></pre><p>The center frequency is set to 951.9 MHz, and the sample rate / bandwidth is set to 12 MHz. Technically we could go down to 11.2 MHz, but 12 is a nice even number so that's what I'll use here. You can also configure the gain, but I found the default of 30 dBi to work fine.</p><p>If you see 0's printed in your console it means your dropping samples in the capture. This basically means your computer can't keep up with the data streaming from the SDR. A common cause of dropped samples are spikes in disk writes from the capture utility, and the disk can't save the data fast enough. Increasing the buffer on the USRP can help, which we do via the <code>--args</code> flag. You could also try capturing data with the <code>uhd_rx_cfile</code> utlity, which may perform slightly better.</p><p>If you still get dropped samples, you could also try saving capture files to the <code>/dev/shm/</code> directory. This will store the capture files in memory instead of disk, which has performance benefits. The downside here is there will be less storage space for the capture.</p><pre><code>grgsm_capture --args="uhd,num_recv_frames=1024" -f 951.9M -s 12.0M call.cfile</code></pre><p><strong>Note: </strong>Before taking the capture you need to make sure your phone is communicating over GSM/2G. Most phones let you set this within the cellular data options, though depending on your exact phone and carrier settings the option may be hidden. If you don't see the option try using a different phone. The lowest I could go on my iPhone was 3G, but Android let me set 2G. Also worth noting is that my iPhone would have automatically downgraded to 2G if I disabled 4G and was in an area without 3G coverage.</p><p>Start the capture, and Ctrl+C out once you're done. Keep in mind at this point we're just capturing the downlink traffic from the base station to the phone. Some good tests would be to either place a call or receive a text message.</p><h3 id="channelize-capture">Channelize capture</h3><p><code>call.cfile</code> is "wideband" capture that contains two ARFCNs. For further processing with gr-gsm we need to split each channel into its own capture file.</p><p>We can use the <code>grgsm_channelize</code> utility for this. Set the frequency and sample rate so they're the same as when we did the capture. At the end of the command append the list of ARFCNs to extract.</p><figure><img src="https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_193136.png" alt="" srcset="https://harrisonsand.com/content/images/size/w600/2021/02/Screenshot_20210207_193136.png 600w, https://harrisonsand.com/content/images/size/w1000/2021/02/Screenshot_20210207_193136.png 1000w, https://harrisonsand.com/content/images/2021/02/Screenshot_20210207_193136.png 1113w"></figure><p>A new folder will be created that contains separate capture files for each ARFCN.</p><h3 id="analyzing-bcch-traffic">Analyzing BCCH traffic</h3><p>Now we can decode the BCCH traffic from our capture. The BCCH, or broadcast control channel is where the phone listens to get told what to do. So if you receive …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://harrisonsand.com/gsm-security/">https://harrisonsand.com/gsm-security/</a></em></p>]]>
            </description>
            <link>https://harrisonsand.com/gsm-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26064725</guid>
            <pubDate>Mon, 08 Feb 2021 14:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Requests dropped when using Cloudflare’s free tier for a commercial project]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 119 (<a href="https://news.ycombinator.com/item?id=26063239">thread link</a>) | @pawurb
<br/>
February 8, 2021 | https://pawelurbanek.com/cloudflare-free-plan | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/cloudflare-free-plan">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div role="main">
<p>
The claims contained in this article were incorrect. After another contact with Cloudflare support, it turned out that the Bot Fight Mode behaves differently for Free and PRO plans. That's what caused the instant improvement after upgrading. Another way to resolve the issues I was experiencing would have been to disable the bot fight mode altogether or add a custom page rule disabling it. My website never experienced any traffic throttling. I've decided to remove the article, to stop spreading the misinformation about CF services.
</p>
</div>
</div></div>]]>
            </description>
            <link>https://pawelurbanek.com/cloudflare-free-plan</link>
            <guid isPermaLink="false">hacker-news-small-sites-26063239</guid>
            <pubDate>Mon, 08 Feb 2021 11:36:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Online glassboard (like Lightboard) but using just free software]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26063177">thread link</a>) | @theBashShell
<br/>
February 8, 2021 | http://blogs.lobsterpot.com.au/2021/01/30/presentation-trickery-online-glassboard-like-lightboard-but-using-just-free-software/ | <a href="https://web.archive.org/web/*/http://blogs.lobsterpot.com.au/2021/01/30/presentation-trickery-online-glassboard-like-lightboard-but-using-just-free-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4134">
	
	<!-- .entry-header -->

	<div>
		
<p>I don't know if you've ever seen me present. I like to use whiteboards or flip charts, and that doesn't necessarily translate well to online presentations.</p>



<p>It was at least ten years ago when I had an idea about giving online presentations with a whiteboard, but where the whiteboard would be between me and the camera. A glassboard rather than a whiteboard, obviously, so that I would still be visible through the glass but not obscuring the text. And the image would be mirrored so that the things I wrote would be readable to the audience, given that I'd be drawing on the other side of it. Recently I've found out this is a real thing called <a rel="noreferrer noopener" aria-label="Lightboard (opens in a new tab)" href="https://library.iated.org/view/KOC2017LIG" target="_blank">Lightboard</a>, using ultra-clear glass and lights to make sure what's drawn glows enough. And considering this seems to have only appeared around 2015 (a good five years after I was musing about the concept), I really should've explored things further. </p>



<figure><img src="https://wiki.nus.edu.sg/download/attachments/135954958/lightboard.jpg?version=1&amp;modificationDate=1458616080983&amp;api=v2" alt=""><figcaption>This picture is from a site belonging to the <a rel="noreferrer noopener" aria-label="National University of Singapore (opens in a new tab)" href="https://wiki.nus.edu.sg/pages/viewpage.action?pageId=135954958" target="_blank">National University of Singapore</a>, but an image search gives plenty of examples</figcaption></figure>



<p>In a world where technical presentations are more online than in-person, I've struggled a bit with how to give my usual style of presentation. I know I could set up something like this, and I've been tempted, but it would be a lot of effort, and it's not exactly portable, and I just haven't (although I know at least one person who has…)</p>



<p>I know what you're thinking – and that's that tools like Teams do have whiteboards in their meetings. That's not what I want though – in those situations the main screen becomes white (or whatever colour the whiteboard background is), and the bit showing me disappears or shrinks to the corner. It's like sharing a screen. And my style isn't just writing on a whiteboard, it's pointing at the whiteboard, it's gesturing, it's all of that stuff that doesn't work if I'm constrained to the corner of the screen. If I had a greenscreen behind me I could do the "weatherperson" trick of moving in front of the screen to point things out, etc, but it's still not quite what I want.</p>



<p>And so I got to thinking about what could be done.</p>



<p>Enter OBS. That free piece of software that many people use now. Plus, from version 26 on, it can act as a Virtual Camera, so that Teams (or Zoom or GoTo or whatever) can show whatever OBS is doing. So if I figured if I could get this to behave the right way, I would be able to use it in live presentations. The button that appeared in version 26 is in the Controls pane in the bottom right of the OBS window. </p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-12.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-12.png 306w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-12-300x162.png 300w" sizes="(max-width: 306px) 100vw, 306px"></figure>



<p>There is no mode where I can just use my stylus to draw on the screen where my face is. At least I don't believe there is, but I found a workaround.</p>



<p>The basic concept here is that I use my webcam as a source, but overlay a window capture from an application where I can draw with my stylus (PowerPoint will do, and is good for other reasons too). Then I set the application's background to a <a rel="noreferrer noopener" aria-label="chroma key (opens in a new tab)" href="https://en.wikipedia.org/wiki/Chroma_key" target="_blank">chroma key</a> colour (like bright green #00FF00) and filter that out like a traditional greenscreen. I stretch that source in OBS bit so that the main drawing area is over my webcam feed, and all the menus and stuff is outside.</p>



<p>To explain with pictures:</p>



<p>I started with a plain PowerPoint presentation and set the background to bright green. I'm going to leave the PowerPoint application in this mode because I find it behaves better. And as I'm about to draw on it with a stylus, I don't want it to do anything weird by switching into 'presenter mode' or 'annotation mode' or anything like that.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-2-1024x598.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-2-1024x598.png 1024w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-2-300x175.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-2-768x449.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then in OBS, with the webcam as the bottom layer of the Sources, I add a Window Capture and use the PowerPoint screen.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-1.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-1.png 483w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-1-300x116.png 300w" sizes="(max-width: 483px) 100vw, 483px"></figure>



<p>Now select the WindowCapture and resize it to match the slide to the webcam. This slide is going to disappear though, when we add the filter.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/ResizingOBS.gif" alt=""></figure>



<p>Right-clicking on the "Window Capture" source, I can go to Filters and add a Chroma Key filter, using the default Green. You'll notice that the bits that are green in PowerPoint have gone grey, indicating that they'll be invisible.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-3.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-3.png 863w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-3-300x263.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-3-768x675.png 768w" sizes="(max-width: 863px) 100vw, 863px"></figure>



<p>Now back in OBS, I see myself again..</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-4.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-4.png 975w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-4-300x223.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-4-768x572.png 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p>…but when I write in PowerPoint, it appears in front of me. (Oh, because I want to point at the things I draw, I flip the webcam horizontally. You might have noticed the writing on my shirt is backwards.)</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-5-1024x593.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-5-1024x593.png 1024w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-5-300x174.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-5-768x444.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>And it's not just text that works. I can have standard bullet-point text.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-6-1024x594.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-6-1024x594.png 1024w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-6-300x174.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-6-768x446.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>And I can write in other colours too, just not green.</p>



<p>But that brings me to an interesting set of tricks.</p>



<p>The first one is to grab a screenshot of me on the webcam, and make it very saturated, and green. I can do this using just about any image editing tool. So now I have an image that looks like this.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-7.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-7.png 759w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-7-300x169.png 300w" sizes="(max-width: 759px) 100vw, 759px"></figure>



<p>I set this to my PowerPoint background, and I can easily see where I can draw and where I can't (assuming I don't move around too much).</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-9-1024x614.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-9-1024x614.png 1024w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-9-300x180.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-9-768x461.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I can also add gridlines to help my handwriting stay neater, and help me make sure I don't run out of room.</p>



<p>But in many ways the biggest trick is around the flow of my presentation.</p>



<p>Part of why I use whiteboards and flipcharts is because I feel like they help the audience connect with me better. There's something about writing live that means that people feel like I'm doing it on the fly, being more responsive to how the audience is responding, changing tack as I go. </p>



<p>But it's not like that at all. When I present without slides, or even without a computer, I have to know my material really well. I have to know where I'm going. I don't have the crutch of a slide deck of bullet points. I need to know what I'm planning to write. How I'm going to make the various points. Even how the audience is likely to respond to various things. By knowing the narrative of my presentation really well, it gives me the freedom to move around the content if I feel like I need to, but I have to know my anchor points in my head, because I don't have them on the screen.</p>



<p>So… as long as they're still green, and therefore invisible to the audience, I can indeed have them on the screen now. And whether I use consecutive slides with different colours (first green, then white/black/whatever) to make it look like it's building, or whether I trace over the top using my stylus, I can have all the notes I like – even notes to myself that the audience can't see. I can have as many slides as I want and can move around them just like regular folk do.</p>



<figure><img src="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-11-1024x594.png" alt="" srcset="http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-11-1024x594.png 1024w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-11-300x174.png 300w, http://blogs.lobsterpot.com.au/wp-content/uploads/2021/01/image-11-768x445.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>When it comes to giving demos, I still need to add a separate screen or do traditional screensharing through Teams or GoTo or Zoom or whatever. But with a bit more effort I could do my demo in the background and still draw over the top. Or get a physical greenscreen behind me so that I can have a solid background or demo screen behind me and still have my drawings in the foreground. This can definitely go a lot further.</p>



<p>But for my whiteboard-based presentations, this should work nicely.</p>



<p><a href="http://twitter.com/rob_farley" target="_blank" rel="noreferrer noopener" aria-label="@rob_farley (opens in a new tab)">@rob_farley</a> </p>



<p>PS: I just made a short video at <a rel="noreferrer noopener" aria-label="https://youtu.be/LdtmEf2XhSU (opens in a new tab)" href="https://youtu.be/LdtmEf2XhSU" target="_blank">https://youtu.be/LdtmEf2XhSU</a> to show drawing on the screen. It would've been better if I had taken a few minutes to sort out my lighting and background, but you can see the rough concept there.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://blogs.lobsterpot.com.au/2021/01/30/presentation-trickery-online-glassboard-like-lightboard-but-using-just-free-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26063177</guid>
            <pubDate>Mon, 08 Feb 2021 11:25:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrate Everything from Linux to BSD]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 156 (<a href="https://news.ycombinator.com/item?id=26060307">thread link</a>) | @zdw
<br/>
February 7, 2021 | https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.unixsheikh.com/articles/why-you-should-migrate-everything-from-linux-to-bsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26060307</guid>
            <pubDate>Mon, 08 Feb 2021 03:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Change your MAC address with a shell script (2019)]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 101 (<a href="https://news.ycombinator.com/item?id=26060152">thread link</a>) | @mooreds
<br/>
February 7, 2021 | https://josh.works/shell-script-basics-change-mac-address | <a href="https://web.archive.org/web/*/https://josh.works/shell-script-basics-change-mac-address">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  

  <time datetime="2019-12-18T13:00:00+00:00">December 2019</time>
  <section>
    
    <!-- https://planetjekyll.github.io/snippets/reading-time -->
<p>
  
  
    Reading time: 8 mins
  
</p>

  </section>
  
  
  <h2>Article Table of Contents</h2>
<ul>
  <li><a href="#get-your-current-mac-address">Get your current MAC address</a></li>
  <li><a href="#figure-out-which-adapter-your-machine-is-using-to-connect-to-the-wifi">Figure out which adapter your machine is using to connect to the wifi</a></li>
  <li><a href="#generate-a-random-new-mac-address">Generate a random new MAC address</a></li>
  <li><a href="#set-current-mac-address-to-temporarynew-mac-address">Set current mac address to temporary/new MAC address</a></li>
  <li><a href="#feb-9-2021-update">Feb 9, 2021 update</a></li>
  <li><a href="#related-reading">Related Reading</a></li>
</ul>
  <p>For a while, I’ve had notes from <a href="https://www.online-tech-tips.com/computer-tips/how-to-change-mac-address/">Change or Spoof a MAC Address in Windows or OS X</a> saved, so if I am using a wifi connection that limits me to thirty minutes or an hour, I can “spoof” a new MAC address, and when I re-connect to the wifi, the Access Point thinks I’m on a new, unique device.</p>

<p>For the record - when I’m posted up at a coffee shop for an extended period of time, I make sure to <em>buy products regularly</em> in payment for my time. So, if you’re spoofing your MAC address to use wifi for a longer period of time, maybe make sure to spend $5 or $10 when you run the script.</p>

<p>Now, in case you think that I’m actually saving myself time here, I’m totally not. Here’s why:</p>

<p><img src="https://imgs.xkcd.com/comics/automation.png" alt="XKCD Automation" title="'Automating' comes from the roots 'auto-' meaning 'self-', and 'mating', meaning 'screwing'."></p>

<p><em><a href="https://xkcd.com/1319/">XKCD: Automation</a></em></p>

<p>And:</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png" alt="XKCD Is it worth the time?" title="Don't forget the time you spend finding the chart to look up what you save. And the time spent reading this reminder about the time spent. And the time trying to figure out if either of those actually make sense. Remember, every second counts toward your life total, including these right now."></p>

<p><em><a href="https://xkcd.com/1205/">XKCD: Is it worth the time?</a></em></p>

<p>Here’s the steps, for someone who’s on a MAC, to spoof your MAC address:</p>
      <h3 id="get-your-current-mac-address">
        
        
          Get your current MAC address <a href="#get-your-current-mac-address">#</a>
        
        
      </h3>
    

<p>Hold down <code>option</code> key, click your wifi icon:</p>

<p><img src="https://josh.works/images/2019-12-11-bash-basics-01.jpg" alt="wifi details"></p>
      <h3 id="figure-out-which-adapter-your-machine-is-using-to-connect-to-the-wifi">
        
        
          Figure out which adapter your machine is using to connect to the wifi <a href="#figure-out-which-adapter-your-machine-is-using-to-connect-to-the-wifi">#</a>
        
        
      </h3>
    

<div><div><pre><code>ifconfig en0 | <span>grep </span>ether <span># one of these will return a MAC address that matches</span>
ifconfig en1 | <span>grep </span>ether <span># the value you saw when looking for your current</span>
ifconfig en2 | <span>grep </span>ether <span># mac address.</span>
ifconfig en3 | <span>grep </span>ether <span># Keep incrementing the `en0` value until you run out of </span>
                          <span># devices</span>
</code></pre></div></div>

<p>Here’s me working through the list:</p>

<p><img src="https://josh.works/images/2019-12-11-basic-bash-02.jpg" alt="checking all ports"></p>

<p>For me, the very first result matched the MAC address I got from <code>option+click</code>ing the wifi network.</p>

<p>That means I’ll be using <code>en0</code> as the [E]ther[N]et adapter I’ll update shortly.</p>

<!--more-->
      <h3 id="generate-a-random-new-mac-address">
        
        
          Generate a random new MAC address <a href="#generate-a-random-new-mac-address">#</a>
        
        
      </h3>
    

<p>A MAC address has a standard-looking format.</p>

<p>It looks like six blocks of two digits, which happen to be <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal representations</a> of <code>00000000</code> through <code>11111111</code>.</p>

<p>Here’s some randomly-generated MAC addresses:</p>

<div><div><pre><code>e2:81:f6:f6:f9:e8
1f:24:37:47:d6:25
03:20:3f:48:46:ad
</code></pre></div></div>

<p>To generate a random string of characters that produces a <a href="http://sqa.fyicenter.com/1000208_MAC_Address_Validator.html">valid MAC address</a>, run:</p>

<div><div><pre><code>openssl rand -hex 6 | sed 's/\(..\)/\1:/g; s/.$//'
</code></pre></div></div>

<p>And boom. You’ve got a MAC address.</p>

<p>Now we need to update our current MAC address to this new MAC address.</p>
      <h3 id="set-current-mac-address-to-temporarynew-mac-address">
        
        
          Set current mac address to temporary/new MAC address <a href="#set-current-mac-address-to-temporarynew-mac-address">#</a>
        
        
      </h3>
    

<p>You can use <code>ifconfig</code> to set the ethernet address (is that interchangable with the MAC address?) to the randomly-generated string you got from the <code>openssl</code> command:</p>

<div><div><pre><code><span># you need to sudo it, unfortunately. No quotes around the mac address</span>
<span>sudo </span>ifconfig en0 ether xx:xx:xx:xx:xx:xx

<span># here's the full command</span>
<span>sudo </span>ifconfig en0 ether 8c:85:90:5a:79:56
</code></pre></div></div>

<p>And with that, you can re-connect to the wifi network, and it <em>should</em> recognize you as a new device, and let you onto the network.</p>

<p>Here’s what I first ended up with:</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>echo</span> <span>"Hi! lets change our mac address."</span>
<span>echo</span> <span>"Step 1: hold down option key, click wifi logo. Note the mac address"</span>
<span>echo</span> <span>"Step 2: click 'disconnect from network' "</span>
<span>echo</span> <span>"Step 3: note which ethernet adapter lines up with the mac address you just saw"</span>

<span>en0</span><span>=</span><span>$(</span> ifconfig en0 | <span>grep </span>ether <span>)</span>
<span>en1</span><span>=</span><span>$(</span> ifconfig en1 | <span>grep </span>ether <span>)</span>
<span>en2</span><span>=</span><span>$(</span> ifconfig en2 | <span>grep </span>ether <span>)</span>
<span>en3</span><span>=</span><span>$(</span> ifconfig en3 | <span>grep </span>ether <span>)</span>
<span>en4</span><span>=</span><span>$(</span> ifconfig en4 | <span>grep </span>ether <span>)</span>
<span>en5</span><span>=</span><span>$(</span> ifconfig en5 | <span>grep </span>ether <span>)</span>

<span>echo </span>en0 is: <span>$en0</span>
<span>echo </span>en1 is: <span>$en1</span>
<span>echo </span>en2 is: <span>$en2</span>
<span>echo </span>en3 is: <span>$en3</span>
<span>echo </span>en4 is: <span>$en4</span>
<span>echo </span>en5 is: <span>$en5</span>

<span>read</span> <span>-p</span> <span>'Step 4: Enter which ethernet device lined up with the given mac address: '</span> ether_adapter
<span>export </span><span>ether_adapter</span><span>=</span><span>$ether_adapter</span>

<span>mac</span><span>=</span><span>$(</span> openssl rand <span>-hex</span> 6 | <span>sed</span> <span>"s/</span><span>\(</span><span>..</span><span>\)</span><span>/</span><span>\1</span><span>:/g; s/.</span><span>$/</span><span>/"</span> <span>)</span>
<span>export </span><span>mac</span><span>=</span><span>$mac</span>

<span>echo</span> <span>"btw, here's the new mac address we're going to use: </span><span>$mac</span><span>"</span>
<span>echo</span> <span>"OK, we will change the mac address associated with: </span><span>$ether_adapter</span><span>"</span>

<span>old_mac</span><span>=</span><span>$(</span> ifconfig <span>$ether_adapter</span> | <span>grep </span>ether <span>)</span>

<span>echo</span> <span>"The old value was: </span><span>$old_mac</span><span>"</span>

<span>sudo </span>ifconfig <span>$ether_adapter</span> ether <span>$mac</span>

<span>new_mac</span><span>=</span><span>$(</span> ifconfig <span>$ether_adapter</span> | <span>grep </span>ether <span>)</span>

<span>echo</span> <span>"The new value is: </span><span>$new_mac</span><span>"</span>
<span>echo</span> <span>"go ahead and re-connect to the wifi. You should be able to join the network."</span>
</code></pre></div></div>

<p>Believe it or not, this script was far from perfect.</p>

<p>First off, not all randomly-generated mac addresses are valid, even though they were passing an online mac address validator I was testing against. <a href="https://askubuntu.com/a/536221">AskUbuntu</a> nicely shared what was going on.</p>

<p>I didn’t want to deal with manually building a valid MAC address; I just noticed that about 2 out of 3 attempts to change my mac address, using the above script, the MAC address didn’t change.</p>

<p>So, my next version of this script pulls the <code>generate mac address</code> and <code>set current mac address to generated mac address</code> steps into a function, and keeps calling the function until the mac address has changed.</p>

<p>Why be elegant and precise when you can brute force a crappy solution?</p>

<p>Here’s my finished “solution”:</p>

<div><div><pre><code><span>#!/bin/bash</span>
<span># skipping some lines</span>
<span>read</span> <span>-p</span> <span>'Step 4: Which device lined up would you like to change? (hit return for en0) '</span> ether_adapter

<span>if</span> <span>[</span> <span>-z</span> <span>$ether_adapter</span> <span>]</span>
<span>then
  </span><span>ether_adapter</span><span>=</span><span>"en0"</span>
<span>fi

</span><span>export </span><span>ether_adapter</span><span>=</span><span>$ether_adapter</span>

generate_and_set_new_mac_address<span>()</span> <span>{</span>
  <span>mac</span><span>=</span><span>$(</span> openssl rand <span>-hex</span> 6 | <span>sed</span> <span>"s/</span><span>\(</span><span>..</span><span>\)</span><span>/</span><span>\1</span><span>:/g; s/./0/2; s/.</span><span>$/</span><span>/"</span><span>)</span>
  <span>export </span><span>mac</span><span>=</span><span>$mac</span>
  <span>echo</span> <span>"OK, we will change the mac address associated with: </span><span>$ether_adapter</span><span>"</span>

  <span>old_mac</span><span>=</span><span>$(</span> ifconfig <span>$ether_adapter</span> | <span>grep </span>ether <span>)</span>

  <span>echo</span> <span>"The old value was: </span><span>$old_mac</span><span>"</span>
  <span>sudo </span>ifconfig <span>$ether_adapter</span> ether <span>$mac</span>

  <span>new_mac</span><span>=</span><span>$(</span> ifconfig <span>$ether_adapter</span> | <span>grep </span>ether <span>)</span>
  <span>echo</span> <span>"The new value is: </span><span>$new_mac</span><span>"</span>
<span>}</span>
<span>echo</span> <span>$new_mac</span>
<span>echo</span> <span>$old_mac</span>

<span>while</span> <span>[</span> <span>"</span><span>$new_mac</span><span>"</span> <span>==</span> <span>"</span><span>$old_mac</span><span>"</span> <span>]</span>
<span>do
  </span><span>echo</span> <span>"not the same"</span>
  generate_and_set_new_mac_address
<span>done

</span><span>echo</span> <span>"go ahead and re-connect to the wifi. You should be able to join the network."</span>
</code></pre></div></div>

<p>and this seems to work pretty well:</p>

<p><img src="https://josh.works/images/2019-12-17-bash_script_success.jpg" alt="success"></p>

<p>I hope that in the near future, I’ll look at this bash script and have many ways to improve it. For now, it’ll do the trick.</p>
      <h3 id="feb-9-2021-update">
        
        
          Feb 9, 2021 update <a href="#feb-9-2021-update">#</a>
        
        
      </h3>
    

<p>Following <a href="https://twitter.com/serent/status/1359208380435361792">this tweet</a> by <code>@serent</code>, I updated the script a little. To generate a valid MAC address:</p>

<div><div><pre><code><span>@@ -160,7 +162,7 @@</span> fi
 export ether_adapter=$ether_adapter

 generate_and_set_new_mac_address() {
<span>-  mac=$( openssl rand -hex 6 | sed "s/\(..\)/\1:/g; s/.$//" )
</span><span>+  mac=$( openssl rand -hex 6 | sed "s/\(..\)/\1:/g; s/./0/2; s/.$//")
</span>   export mac=$mac
   echo "OK, we will change the mac address associated with: $ether_adapter"
</code></pre></div></div>

<p>There’s other pain points in the script. I’ll fix them at some point.</p>
      
    

<ul>
  <li><a href="https://news.ycombinator.com/item?id=26060152#26060229">Hacker News comments from 2021 on this post</a></li>
  <li><a href="https://ryanstutorials.net/bash-scripting-tutorial/bash-script.php">Bash Scripting Tutorial</a></li>
  <li><a href="https://www.online-tech-tips.com/computer-tips/how-to-change-mac-address/">Change or Spoof a MAC Address in Windows or OS X</a></li>
  <li><a href="https://stackoverflow.com/questions/13781216/meaning-of-too-many-arguments-error-from-if-square-brackets">Resolution to <code>[: too many arguments</code> error</a></li>
  <li><a href="https://askubuntu.com/questions/423530/cant-change-my-mac-address-cant-assign-requested-address/536221">AskUbuntu: “Can’t change my mac address - can’t assign requested address”</a></li>
</ul>
  

</article></div>]]>
            </description>
            <link>https://josh.works/shell-script-basics-change-mac-address</link>
            <guid isPermaLink="false">hacker-news-small-sites-26060152</guid>
            <pubDate>Mon, 08 Feb 2021 02:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm an interviewer at my company and burnt out]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 87 (<a href="https://news.ycombinator.com/item?id=26060099">thread link</a>) | @mooreds
<br/>
February 7, 2021 | https://dear.mariechatfield.com/interviewer-burn-out/ | <a href="https://web.archive.org/web/*/https://dear.mariechatfield.com/interviewer-burn-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>Dear Marie,</p>
<p>I am one of a handful of women engineers at my company and I have been interviewing 1-2 candidates per week for the past several months. Since I started interviewing, we have only hired white or Asian men.</p>
<p>Bringing in underrepresented identities to my workplace is important to me, and leadership at my company constantly says they value ‘Diversity and Inclusion’. I’ve offered ideas on how to attract a wider group of candidates, but I don’t feel like I am heard or taken seriously. I’m exhausted being part of the interview team with the results we have. At this point, I only want to interview underrepresented candidates, but that seems inappropriate to ask for.</p>
<p>Am I complicit in a racist, sexist system? How can I push for change and preserve my energy?</p>
</blockquote>
<!-- question -->

<p>Hey there,</p>
<p>Interviewing one or two candidates per week for months sounds absolutely exhausting. It’s no wonder that you’re tired and burnt out—especially if it seems like your company isn’t actually hiring anyone outside their established pattern, despite their avowed dedication to diversity and inclusion.</p>
<p><strong>I have found conducting interviews to be difficult and energy-consuming work, particularly if you are invested in treating candidates equitably and with empathy.</strong> It’s not just that the hour-long calendar block in the middle of the day, it’s also:</p>
<ul>
<li>preparing for the interview ahead of time, making sure you have all the resources you need and your environment is set up.</li>
<li>being deeply focused during the interview, paying attention to the smallest of interactions to discern signals (of varying reliability) about a person’s areas of technical expertise and approach to work and collaboration.</li>
<li>responding to candidates on the fly, figuring out the right balance of giving them a hint when they’re stuck and seeing how they solve a problem themselves, and ensuring they have an excellent experience with your company.</li>
<li>writing up feedback afterwards and deliberating your evaluation and whether you’ve let unconscious bias influence you and if your feedback is well-calibrated with the rest of the hiring group so that you’re not consistently scoring everyone higher or lower than the average.</li>
<li>participating in decisions and conversations around interviewing as a whole, and how to make it more equitable and inclusive.</li>
</ul>
<p>It sounds like you aren’t hiring specifically for roles on your immediate team, but rather part of a group of interviewers who support hiring across the whole company. This structure makes sense for larger organizations who have a steady stream of open roles. If everyone helps out a little bit all the time, then no one team’s productivity is completely sunk when they need to hire.</p>
<p>The downside, of course, is that the hiring never really stops. <strong>You don’t get to celebrate by welcoming your new teammate; you just keep interviewing. And interviewing. And interviewing.</strong></p>
<p>At one company, I completed over 100 technical interviews in about two years. I had prided myself on being a very good interviewer, in part because of all the practice. By the end, I was completely miserable and I hated everything about it. I couldn’t convince myself to care about candidates anymore and I was having trouble focusing and giving them my full attention. So, I stopped interviewing. And it was <em>such</em> a relief. It wasn’t even necessarily the time back that I cared about; it was <strong>letting go of the immense responsibility of contributing to hiring decisions, but with so little authority to change anything.</strong></p>
<p>Consider a few of these options, and what each one feels like:</p>
<ul>
<li>What if you reduced your availability to one interview a week?</li>
<li>What if you reduced your availability to two interviews a month?</li>
<li>What if you stopped interviewing for a month?</li>
<li>What if you stopped interviewing for a quarter?</li>
</ul>
<p><strong>Did you feel a sense of relief or joy when you imagined those? Which ones feels the most like what you need right now?</strong></p>
<p>You say that you’ve offered ideas about how to improve your hiring practices and that you <em>“don’t feel like I am heard or taken seriously.”</em> I am guessing that you are not a manager, or any other person who makes the final call on hiring decisions. If you were, my advice would be very different<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p>
<p>But if I’m right, your main job responsibility is probably to write, release, and maintain software—<em>not</em> to build a team or manage their collective effectiveness. A manager <em>must</em> hire at some point if they want to ensure their team has the right balance of expertise and experience. You probably help out managers at your company by giving them quality feedback about the people they are considering hiring; but it’s unlikely that your annual evaluation centers on your participation in the hiring process or the hiring outcomes at your company.</p>
<p>So… take a break. Don’t stop entirely or forever; you are doing the important work of advocating for inclusion and equity, I would hate for you to give that up entirely. But it sounds like what you’re doing now isn’t working the way you had hoped, and you’re too tired to imagine a bigger and bolder approach right now.</p>
<p><strong>I have quipped that my main career goal is to do such outstanding work that I can be a complete and total pain in the ass about the things that truly matter, like accessibility and inclusion and equity.</strong> That doesn’t mean that I’m waiting until I’ve “arrived” to advocate for what I know is right and to put my privilege to use. It means that I don’t waste my battles on inconsequential things and I try to make myself valuable enough that I’m harder to push out when I do dig in my heels.</p>
<p>But in order to spend social capital, you have to build it up first—and for you, that might mean giving up interviewing for a bit, focusing on your main job responsibility and building relationships with your coworkers, then coming back with a fresh perspective, renewed energy, and a group of like-minded peers with a common goal of improving the hiring process.</p>
<p>Assuming that you don’t have the authority to make a hire/no-hire decision or to revamp your recruiting process, you’re a bit limited in what you can do on your own. <strong>But there is strength in numbers, and it’s harder to ignore a group.</strong> See if you can find or organize a few people who <em>also</em> care about diversity and inclusion in recruiting and hiring. It doesn’t have to be anything formal<sup id="fnref-2"><a href="#fn-2">2</a></sup>, it can just be three people who all +1 each other’s ideas and bring up the same important questions again and again.</p>
<p><strong>You also asked: <em>“Am I complicit in a racist, sexist system?”</em> I’m not sure that I can answer that one for you.</strong> You know your situation much better than I do; if that’s a concern that keeps coming up for you, sit with it. It may be that there’s something you need to do that you haven’t yet.</p>
<p>I think you would definitely be complicit if you stopped raising concerns about inclusion entirely; if you ignored or minimized the concerns raised by other marginalized people because it makes you feel uncomfortable about your own choices or privilege; or if you had the authority to make a change for the better and you didn’t use it.</p>
<p><strong>If you do come to the conclusion that you have not been living up to your values and have instead prioritized your comfort or advancement over the equity of all—welcome to the club.</strong> We mess up a lot, and we learn with empathy and gratitude for the people who corrected us. That’s another benefit to finding some peers who can advocate alongside you—you’ll each have areas of insight the others won’t and you can teach each other.</p>
<p>I hope that you’re able to take a break from interviewing. I hope that when you’re ready to resume, it’s because you’re genuinely excited to have some influence over hiring at your company and you feel equipped to push for practices that you know are worthwhile<sup id="fnref-3"><a href="#fn-3">3</a></sup>. I hope you find support from other engineers who care about inclusion. I hope your company figures out a way to stop using whatever metrics they love that so consistently undervalue Black and Indigenous people, Hispanic/Latinx people, women and people with other minoritized genders, disabled people, LGTBQ+ people, and those who span more than one of those communities.</p>
<p>In short: I hope you get good rest, and that rest fuels you for another round. There is much work to be done. Let’s do it together. 💖</p>
<p>With so much warmth,<br>
Marie</p>
</div></div>]]>
            </description>
            <link>https://dear.mariechatfield.com/interviewer-burn-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26060099</guid>
            <pubDate>Mon, 08 Feb 2021 02:16:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Kill a Unicorn]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26060038">thread link</a>) | @chrisfrantz
<br/>
February 7, 2021 | https://www.chrisfrantz.com/how-to-kill-a-unicorn/ | <a href="https://web.archive.org/web/*/https://www.chrisfrantz.com/how-to-kill-a-unicorn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-179"><div><p>I took a deep dive on freemium pricing and decided to document it in this post. Why freemium? I think it's how the little guys can win against market leaders.</p><p>Basically, it's how you kill a unicorn.</p><p>Notion, Figma, Canva, Mailchimp, and Segment. What do all of these platforms have in common, besides being category leaders? Each one has unseated the previous category leaders with less money and smaller teams. Each has also opted for a product led growth strategy that is fueled by product virality and an innovative pricing strategy.</p><p>But let's back up. How did we get here?</p><p>The year is 2012 and the preeminent name in design isn't Sketch or Figma - it's Adobe. 2012 era Adobe is a much different beast to where we are now. There was no real SaaS model and licenses were hundreds of dollars each, locked to a machine, and didn't get upgrades. Still, Adobe is unequivocally the category leader. But in just a few years, that would all change due to an enterprising young entrepreneur and her new business model.</p><p>Canva launched in 2012 and spread like wildfire. In 3 years, the company was able to accumulate accumulated 10 million users, with almost 1 million coming in the first year alone. By the next year, they had 17 thousand videos about their product.</p><p>This kind of fervent user adoption is the stuff of legend. I started hearing about Canva around that time. My then-girlfriend (now wife) had put together a project and it looked much better than anything I could knock out in Photoshop or Illustrator. She mentioned it was not only really easy to use, but it was free! At the time I think I was still bouncing from Adobe license to Adobe license, each of which was half a month's rent, so I was blown away.</p><p>Then I started seeing it everywhere. It was being used for school projects, large advertising campaigns, and was the first recommendation in online groups whenever someone needed a design tool.</p><p>That space used to be occupied by Adobe, but in a matter of a few years, they were being overtaken in the B2C and even a bit in the B2B space by a brand new company with a limited amount of funding.</p><figure><img width="1024" height="570" src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-1024x570.png" alt="" srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-1024x570.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-300x167.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-768x427.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1.png 1215w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-1024x570.png" data-srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-1024x570.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-300x167.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1-768x427.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled1.png 1215w"></figure><figure><img width="1024" height="572" src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-1024x572.png" alt="" srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-1024x572.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-300x167.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-768x429.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2.png 1227w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-1024x572.png" data-srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-1024x572.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-300x167.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2-768x429.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled2.png 1227w"></figure><p>Meanwhile, another company, Sketch, was eating away at their market share by offering design-focused tools for modern internet companies. Adobe had Photoshop and Illustrator, neither of which was purpose-built for the internet and both of which were expensive af. Adobe XD wasn't quite production-ready at that point, so Sketch was able to make inroads by offering a lower-priced license for its software.</p><p>Out of left-field comes the Canva of professional design tools: Figma.</p><figure><img width="1024" height="565" src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-1024x565.png" alt="" srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-1024x565.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-300x165.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-768x423.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3.png 1255w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-1024x565.png" data-srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-1024x565.png 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-300x165.png 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3-768x423.png 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled3.png 1255w"></figure><p>Figma quickly overtakes Sketch by offering a few unique features and an unbeatable pricing model. Freemium, with a twist.</p><p>Figma, like Canva before it, quickly discovered the power that a free product with shareable outputs offers. Users create content with the tool, share the content and then inevitably get asked how it was made. Of course, the user is both happy to share and give a positive recommendation since the output content is being appreciated, and the platform gains another user.</p><p>A couple points to understand about the shiny world of marketing:</p><ul><li>Recommendations from trusted people always lead to higher conversion rates. It's easy to recommend free things since the only exchange is time.</li><li>Backlinks are everything, still. Google hasn't cracked how to build page authority without backlinks and having them everywhere, attached with positive recommendations and high user dwell time once a user clicks a link, is seen as a positive signal.</li><li>Creating content in the app means content can be shared outside the app. That's a simple growth mechanism that can be leveraged mightily once a certain user volume has been hit.</li><li>Finally, email is the best marketing channel still. Freemium platforms exchange email addresses for access and make lead generation a snap.</li></ul><p>So Adobe now is taking fire from all sides and they eventually pivot to a cloud-based subscription model while also focusing all their efforts upmarket on the professional landscape, effectively ceding their B2C audience to Canva.</p><p><em>Quick note: There are many other factors that go into making a platform successful, from the founder to tech to the support. Pricing is just one of the pieces.</em></p><h2><strong>How Freemium really works</strong></h2><p>The common misconception with freemium is that it’s an easy way to not generate any revenue. How many stories have you heard about independent projects that have been worked on for years, only to launch with only a few dollars in revenue, followed by months of slogging before eventually shutting down. That’s very likely&nbsp;<em>not</em>&nbsp;a pricing problem, but a positioning problem. You need to position your product in front of the right audiences and the price becomes a natural fit for your expansion strategy.</p><p>In reality, there are a number of different ingredients in the recipe you need to nail before you can actually execute a freemium strategy effectively. You don’t need a team of hundreds of people, but it does help to lay out the strategy ahead of time.</p><p>Let's break out the different factors involved in setting up a freemium plan.</p><ul><li>Pricing that scales with usage</li><li>Shareable content</li><li>In-app upsells</li><li>Massive market opportunity</li><li>Pricing innovation on the primary value</li></ul><p>First, if you are missing even one of these, it might not be the pricing strategy for you. Each part is key in building out a converting freemium funnel.</p><p><strong>Pricing that scales with usage</strong></p><p>If a user wants to dip a toe in and play around with your platform, they can do that at zero cost (outside of an email address). That’s the basic premise of a freemium plan, but what happens when a user is converted and wants to expand their usage?</p><p>Your pricing should accommodate that natural urge and your product should gracefully allow them to expand their usage with as few barriers as possible.</p><p><strong>In-app upsells aka feature gating</strong></p><p>You need to rope off some of your app so there’s a reason to pay! However, you should charge based on either&nbsp;<strong>secondary user value or</strong>&nbsp;expanding the primary user value, but ideally both.</p><p>Let me explain. Google Analytics made analytics free and accessible to everyone. They charge based on primary user value, but only if you want to expand to a much higher tier of usage. For 99% of people, it will always be free.</p><p>That’s great, but really they only offer expanding their primary user value (analytics) as an upsell. Profitwell, one of my favorite companies utilizing this technique, charges entirely on secondary user value. They offer Profitwell Retain, a dunning service, on top of their analytics. Analytics are totally free. After all, you already have all your financial information integrated into it and onboarded your team.</p><p>Canva however offers all that and more. They let users expand their primary usage through additional templates, but also access other tools like scheduling posts on social media once you upgrade. Why pay 12K a year for Hootsuite when you can just upgrade Canva?</p><figure><img width="1024" height="673" src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1024x673.jpg" alt="" srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1024x673.jpg 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-300x197.jpg 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-768x505.jpg 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1536x1009.jpg 1536w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-2048x1346.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1024x673.jpg" data-srcset="https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1024x673.jpg 1024w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-300x197.jpg 300w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-768x505.jpg 768w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-1536x1009.jpg 1536w, https://www.chrisfrantz.com/wp-content/uploads/2021/01/Untitled4-2048x1346.jpg 2048w"></figure><p>With each of these product incentives, users are motioned into the next stage of the tool.</p><p><strong>Shareable content</strong></p><p>This could be considered a growth loop, since we’re building in some type of publishing into the platform so users can share links. Our goal with shareable content is to increase the k factor of a user, effectively turning a free user into a marketing machine. Every time they create content in the app and share it externally, you have another potential opportunity for user acquisition which helps balance out the slightly lower conversion rate you’ll see with a freemium plan.</p><p>You can do this with reports, tables, images, videos, etc. If it can be shared inside a team, you should enable it to be published from your platform.</p><p><strong>Massive Market Opportunity</strong></p><p>Freemium works best when you can boil the ocean. No really, let it rip. The ocean should be a massive existing user base or the early signs of a large user base. You will need the volume to make it work with freemium pricing. Here are the TAMs for a few of the examples.</p><ul><li>Canva: Anyone that needs to create images.</li><li>Profitwell: Anyone that wants to know their businesses metrics</li><li>Google Optimize: Anyone that wants to test anything on their site.</li><li>Microsoft Teams: Anyone that uses Slack. 😉</li></ul><p>Each of these audience segments is huge and represents uniquely large opportunities. Freemium pricing becomes much more difficult to pull off once you have to compete for a small audience with specific needs. You want to create a product that will work with 90% of users.</p><p><strong>Pricing Innovation on Primary Value</strong></p><p>What does this mean?</p><p>A competitive advantage that can’t be innovated against. This is the most important point. How does Slack compete with Teams when users have Teams included in their subscription? How does Baremetrics compete with Profitwell when most of what Baremetrics offered is free with Profitwell?</p><p>Well...they don’t. Baremetrics sold. Slack sold. You can’t compete against freemium when you’re able to offer the primary value for free. The existing market leaders can’t match your pricing without giving up millions in recurring revenue and they’re not going to do that.</p><p>That’s how you beat Adobe or fill-in-the-blank industry behemoth.</p><p>Create a great competitor (the hardest part), offer the primary value for free, then monetize on expanding that primary value or offer a secondary value.</p><h2><strong>I want to be free</strong></h2><p>So I'm putting my money where my mouth is. I'm switching over all my projects to freemium.</p><p>As of today:</p><ul><li><a href="http://snazzy.ai/">Snazzy.ai</a>, content marketing powered by GPT-3, now has a free tier</li><li><a href="http://ga-insights.com/">GA-Insights.com</a>, all your ad networks into Slack, has a free tier being built out</li><li><a href="http://weld.ai/">Weld.ai</a>, in beta as a Supermetrics alternative, will now be completely free at launch.</li></ul><p>The riskiest part of a freemium pricing tier as a bootstrapped founder is getting the volume you need to make up any initial drop in conversion rate.</p><h2><strong>Reference: The market leaders (and the victims)</strong></h2><ul><li>Profitwell: Baremetrics, Chartmogul</li><li>Canva: Photoshop, Illustrator, Word</li><li>Google Optimize: Optimizely, VWO</li><li>Microsoft Teams: Slack</li><li>Figma: Photoshop, Illustrator, Sketch Invision</li></ul><p>Early …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrisfrantz.com/how-to-kill-a-unicorn/">https://www.chrisfrantz.com/how-to-kill-a-unicorn/</a></em></p>]]>
            </description>
            <link>https://www.chrisfrantz.com/how-to-kill-a-unicorn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26060038</guid>
            <pubDate>Mon, 08 Feb 2021 02:03:23 GMT</pubDate>
        </item>
    </channel>
</rss>
